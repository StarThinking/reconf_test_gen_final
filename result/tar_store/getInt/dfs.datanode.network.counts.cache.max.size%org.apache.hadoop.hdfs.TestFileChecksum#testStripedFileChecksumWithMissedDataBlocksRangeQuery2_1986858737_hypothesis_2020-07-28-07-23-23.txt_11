reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1636474691-172.17.0.15-1595921063163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33929,DS-6a67c264-bcd2-45ce-81bc-7b962df64230,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-b03b0882-25c9-44b3-92f6-56555d53dd24,DISK], DatanodeInfoWithStorage[127.0.0.1:39406,DS-4db68b01-a1c2-406c-912d-e0dfb3291f12,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-9d4f1f30-a7b4-46b6-870e-4813f25f667b,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-4c919871-2472-4c46-911c-3c00b6cfdb21,DISK], DatanodeInfoWithStorage[127.0.0.1:36767,DS-c2cebb3e-2724-4065-aa75-f42598559d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40038,DS-130ad318-aafd-41df-b631-36aba8bfaeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:37744,DS-5745bd07-4c55-48f6-9819-489749ba69e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1636474691-172.17.0.15-1595921063163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33929,DS-6a67c264-bcd2-45ce-81bc-7b962df64230,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-b03b0882-25c9-44b3-92f6-56555d53dd24,DISK], DatanodeInfoWithStorage[127.0.0.1:39406,DS-4db68b01-a1c2-406c-912d-e0dfb3291f12,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-9d4f1f30-a7b4-46b6-870e-4813f25f667b,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-4c919871-2472-4c46-911c-3c00b6cfdb21,DISK], DatanodeInfoWithStorage[127.0.0.1:36767,DS-c2cebb3e-2724-4065-aa75-f42598559d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40038,DS-130ad318-aafd-41df-b631-36aba8bfaeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:37744,DS-5745bd07-4c55-48f6-9819-489749ba69e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1810050974-172.17.0.15-1595921459497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42449,DS-a040126b-ff6e-4d3c-b91c-b98bac08edb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-78066942-a19e-4185-81be-1306abca097f,DISK], DatanodeInfoWithStorage[127.0.0.1:40684,DS-fe2665a5-bdeb-4534-966d-22fdcfca1d90,DISK], DatanodeInfoWithStorage[127.0.0.1:41680,DS-a2b48c33-8ca4-4e3a-9359-de270a16e6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-5efea633-b88a-4819-bacf-ea963eb7e2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-d01aa550-0fc4-49b9-b652-65611420fd17,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-3b24cc76-08c3-4b9a-8d56-7501376f64b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-c9860877-ad35-436a-9700-c11524306d0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1810050974-172.17.0.15-1595921459497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42449,DS-a040126b-ff6e-4d3c-b91c-b98bac08edb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-78066942-a19e-4185-81be-1306abca097f,DISK], DatanodeInfoWithStorage[127.0.0.1:40684,DS-fe2665a5-bdeb-4534-966d-22fdcfca1d90,DISK], DatanodeInfoWithStorage[127.0.0.1:41680,DS-a2b48c33-8ca4-4e3a-9359-de270a16e6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-5efea633-b88a-4819-bacf-ea963eb7e2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-d01aa550-0fc4-49b9-b652-65611420fd17,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-3b24cc76-08c3-4b9a-8d56-7501376f64b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-c9860877-ad35-436a-9700-c11524306d0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-848824404-172.17.0.15-1595921548517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38632,DS-fbc396b9-c2ae-468b-9a15-1138beb53522,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-93d98d22-ceb4-450a-b6eb-5b017fbd6cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-645eafcc-4e1f-4992-825d-d5d15778f9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-42d66bd4-87e0-48fa-b81b-ffcb11538e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-f9b2e409-771e-4207-bc64-5e67260d83aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45979,DS-7375135a-9914-4b85-be95-c983642df2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-16ba780b-7a8c-4151-a852-b81bbb3808a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-fccd521c-6f72-4d90-81d8-606c72248454,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-848824404-172.17.0.15-1595921548517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38632,DS-fbc396b9-c2ae-468b-9a15-1138beb53522,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-93d98d22-ceb4-450a-b6eb-5b017fbd6cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-645eafcc-4e1f-4992-825d-d5d15778f9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-42d66bd4-87e0-48fa-b81b-ffcb11538e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-f9b2e409-771e-4207-bc64-5e67260d83aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45979,DS-7375135a-9914-4b85-be95-c983642df2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-16ba780b-7a8c-4151-a852-b81bbb3808a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-fccd521c-6f72-4d90-81d8-606c72248454,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1099179136-172.17.0.15-1595921815576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33144,DS-61337653-ce76-4796-b112-2dfa672f3763,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-9e2cb260-91ef-41f8-b6d9-207ee800408a,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-1742887d-d48d-4e55-aaac-592655e02b75,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-b1f0e8a1-bd84-4035-b545-9fcf0b9d58d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-b5dba8aa-88a4-4bc0-8781-4f584071f877,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-eebb150a-0d33-4a53-8750-56cd718869df,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-2b3e7a79-98a2-46a6-9fbd-68f781ad422a,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-d986e989-b3f8-4551-9800-1a64be188548,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1099179136-172.17.0.15-1595921815576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33144,DS-61337653-ce76-4796-b112-2dfa672f3763,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-9e2cb260-91ef-41f8-b6d9-207ee800408a,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-1742887d-d48d-4e55-aaac-592655e02b75,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-b1f0e8a1-bd84-4035-b545-9fcf0b9d58d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-b5dba8aa-88a4-4bc0-8781-4f584071f877,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-eebb150a-0d33-4a53-8750-56cd718869df,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-2b3e7a79-98a2-46a6-9fbd-68f781ad422a,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-d986e989-b3f8-4551-9800-1a64be188548,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1283537026-172.17.0.15-1595921858388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34620,DS-c2b59329-e696-4826-9bff-6f2c0363928d,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-c8471fe9-c169-41e8-9eee-56194c7c7f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-f37cfcee-da24-46b4-8646-b1262288c154,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-a69bd744-4569-4629-a3c5-17f23e05e9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-61ba1266-5893-4020-96de-ccf2c639b60f,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-9f1d2f74-34da-44cf-9916-587048270891,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-1f756fbc-069c-4046-a737-050170aaf794,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-35c594f4-727d-4cd3-9629-0c583c8aefdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1283537026-172.17.0.15-1595921858388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34620,DS-c2b59329-e696-4826-9bff-6f2c0363928d,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-c8471fe9-c169-41e8-9eee-56194c7c7f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-f37cfcee-da24-46b4-8646-b1262288c154,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-a69bd744-4569-4629-a3c5-17f23e05e9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-61ba1266-5893-4020-96de-ccf2c639b60f,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-9f1d2f74-34da-44cf-9916-587048270891,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-1f756fbc-069c-4046-a737-050170aaf794,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-35c594f4-727d-4cd3-9629-0c583c8aefdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2009576463-172.17.0.15-1595921959020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38163,DS-810b5551-646c-41e8-9aa0-a18d81f65cef,DISK], DatanodeInfoWithStorage[127.0.0.1:36355,DS-7c605972-1cd1-44ad-a99d-73c7edeceea1,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-7726afca-d41c-40ab-8d54-5dfd61db8e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33487,DS-dd5f9e48-53a2-46a2-bd5b-d51c0788697d,DISK], DatanodeInfoWithStorage[127.0.0.1:40289,DS-7ba98be0-0e94-4112-85db-517b8412c17b,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-c055519d-0a91-4ed2-a03a-bdf5700ab2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-6a4d1466-26a8-4c1d-91ff-3ec79d69bef7,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-b790d8c0-714c-4b3f-b270-4bc59802365e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2009576463-172.17.0.15-1595921959020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38163,DS-810b5551-646c-41e8-9aa0-a18d81f65cef,DISK], DatanodeInfoWithStorage[127.0.0.1:36355,DS-7c605972-1cd1-44ad-a99d-73c7edeceea1,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-7726afca-d41c-40ab-8d54-5dfd61db8e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33487,DS-dd5f9e48-53a2-46a2-bd5b-d51c0788697d,DISK], DatanodeInfoWithStorage[127.0.0.1:40289,DS-7ba98be0-0e94-4112-85db-517b8412c17b,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-c055519d-0a91-4ed2-a03a-bdf5700ab2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-6a4d1466-26a8-4c1d-91ff-3ec79d69bef7,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-b790d8c0-714c-4b3f-b270-4bc59802365e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-437114108-172.17.0.15-1595922624166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43627,DS-8c4bbeac-da58-4b00-8501-748b49cb7228,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-ffc07e71-0083-4b4b-8df2-78361db3900f,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-8e16cd60-c3c3-47f5-ba69-6e2df1b581e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-f6605399-4fea-41de-ad54-5d75c284f952,DISK], DatanodeInfoWithStorage[127.0.0.1:39541,DS-e36433f7-9489-4767-91ec-353bb38bbdc4,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-5238832e-cb6e-4f3a-ad2d-195f6e0b2898,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-55987239-96e9-4545-8181-a336a7448f79,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-60b9dbb4-2083-4abe-a72b-4491f5393b50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-437114108-172.17.0.15-1595922624166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43627,DS-8c4bbeac-da58-4b00-8501-748b49cb7228,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-ffc07e71-0083-4b4b-8df2-78361db3900f,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-8e16cd60-c3c3-47f5-ba69-6e2df1b581e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-f6605399-4fea-41de-ad54-5d75c284f952,DISK], DatanodeInfoWithStorage[127.0.0.1:39541,DS-e36433f7-9489-4767-91ec-353bb38bbdc4,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-5238832e-cb6e-4f3a-ad2d-195f6e0b2898,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-55987239-96e9-4545-8181-a336a7448f79,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-60b9dbb4-2083-4abe-a72b-4491f5393b50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548135417-172.17.0.15-1595922722032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40409,DS-1ecba753-f822-4233-b8cf-e86c2830ad05,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-729a41e6-942a-4247-b828-75c70ae1d014,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-4c2e0e95-e777-41c9-a191-7f9a7546a14c,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-fee17a01-a21d-4bab-ae44-bd37c16381a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-de824750-dec9-428f-8823-1aadf9c68c75,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-e5e870e5-7359-4e44-9b92-48fb94494126,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-39bf8bf5-414a-4c1d-8cdf-36311ec4f98c,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-9e1e3db3-4a43-4883-bc9f-ad4c21b3b2fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548135417-172.17.0.15-1595922722032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40409,DS-1ecba753-f822-4233-b8cf-e86c2830ad05,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-729a41e6-942a-4247-b828-75c70ae1d014,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-4c2e0e95-e777-41c9-a191-7f9a7546a14c,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-fee17a01-a21d-4bab-ae44-bd37c16381a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-de824750-dec9-428f-8823-1aadf9c68c75,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-e5e870e5-7359-4e44-9b92-48fb94494126,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-39bf8bf5-414a-4c1d-8cdf-36311ec4f98c,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-9e1e3db3-4a43-4883-bc9f-ad4c21b3b2fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-629175930-172.17.0.15-1595922766365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38092,DS-cc81085b-6346-470b-9f72-5f2e406a2c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-c7b22acc-f7aa-4fe4-9671-aaea7840c3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-61c5dbee-779c-4062-b6e6-3d927a1f2059,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-22cfeafe-c280-4f82-8157-7348e0ca3a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-4984b837-8842-4913-a054-b9cb306aae05,DISK], DatanodeInfoWithStorage[127.0.0.1:34786,DS-63d843c0-3a09-47e3-abb1-0589911ac6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-fd4b18a3-bfc6-4e0f-807d-ec62307e233f,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-fb54ca24-9352-46d7-b0b0-dd792994ac21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-629175930-172.17.0.15-1595922766365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38092,DS-cc81085b-6346-470b-9f72-5f2e406a2c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-c7b22acc-f7aa-4fe4-9671-aaea7840c3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-61c5dbee-779c-4062-b6e6-3d927a1f2059,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-22cfeafe-c280-4f82-8157-7348e0ca3a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-4984b837-8842-4913-a054-b9cb306aae05,DISK], DatanodeInfoWithStorage[127.0.0.1:34786,DS-63d843c0-3a09-47e3-abb1-0589911ac6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-fd4b18a3-bfc6-4e0f-807d-ec62307e233f,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-fb54ca24-9352-46d7-b0b0-dd792994ac21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1156236603-172.17.0.15-1595923465112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34738,DS-56ebaac7-c140-41dd-bec8-596a72b88b23,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-ef4277cd-2220-4147-bcfc-d179098867d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-396231f3-b0f0-4b6c-a0bf-6f0eab044957,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-b2827ffe-a9cd-4925-aabf-aed7a6cb5d86,DISK], DatanodeInfoWithStorage[127.0.0.1:46082,DS-5369f23c-3bba-4303-8f71-ab3b71d77a77,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-7983b47f-bb98-4d43-8a65-27d6b5af1d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-123881c6-6014-4c32-9dcc-677bc9475f38,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-5577fddf-d013-45c5-8217-aad8ed41b9f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1156236603-172.17.0.15-1595923465112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34738,DS-56ebaac7-c140-41dd-bec8-596a72b88b23,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-ef4277cd-2220-4147-bcfc-d179098867d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-396231f3-b0f0-4b6c-a0bf-6f0eab044957,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-b2827ffe-a9cd-4925-aabf-aed7a6cb5d86,DISK], DatanodeInfoWithStorage[127.0.0.1:46082,DS-5369f23c-3bba-4303-8f71-ab3b71d77a77,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-7983b47f-bb98-4d43-8a65-27d6b5af1d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-123881c6-6014-4c32-9dcc-677bc9475f38,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-5577fddf-d013-45c5-8217-aad8ed41b9f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1719956900-172.17.0.15-1595923513788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37742,DS-a03cddd8-e3a2-4613-94ec-b6d1b4f89a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39242,DS-b21cec60-9d10-4ee6-89ae-89880ca3562d,DISK], DatanodeInfoWithStorage[127.0.0.1:40304,DS-c41fe016-7bc8-4e55-94c1-d8f4be22a85a,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-1921a640-d817-4a3f-a7e7-e2270d858735,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-38d5ea68-3a3d-4d68-82a9-4634844124a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44631,DS-242d4cdf-0378-4e4c-8e56-fb991de7318d,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-31321c8f-2f12-4e56-9952-28cd70d539cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-29cecb80-458c-494f-8800-0c3281ff67c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1719956900-172.17.0.15-1595923513788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37742,DS-a03cddd8-e3a2-4613-94ec-b6d1b4f89a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39242,DS-b21cec60-9d10-4ee6-89ae-89880ca3562d,DISK], DatanodeInfoWithStorage[127.0.0.1:40304,DS-c41fe016-7bc8-4e55-94c1-d8f4be22a85a,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-1921a640-d817-4a3f-a7e7-e2270d858735,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-38d5ea68-3a3d-4d68-82a9-4634844124a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44631,DS-242d4cdf-0378-4e4c-8e56-fb991de7318d,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-31321c8f-2f12-4e56-9952-28cd70d539cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-29cecb80-458c-494f-8800-0c3281ff67c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-109244993-172.17.0.15-1595924155148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44164,DS-d5fa60e0-fdc1-40ae-951a-fb7287c60300,DISK], DatanodeInfoWithStorage[127.0.0.1:37471,DS-4ac55172-f128-4abe-b26c-61082d991c26,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-e31849da-f2a5-4956-90e1-99b60bde22a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-34de586c-bf1a-4acf-82c0-23d14bfd333f,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-63dbfa97-b0d1-4fe4-b1d2-a17dc3f93a31,DISK], DatanodeInfoWithStorage[127.0.0.1:38893,DS-f857d460-f5ea-44d9-a0eb-68ec82b06462,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-0f57c65e-491d-4143-b8bf-4cd1814df2da,DISK], DatanodeInfoWithStorage[127.0.0.1:40389,DS-699bc7f7-d860-4c0e-a6ce-25a74bf7f965,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-109244993-172.17.0.15-1595924155148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44164,DS-d5fa60e0-fdc1-40ae-951a-fb7287c60300,DISK], DatanodeInfoWithStorage[127.0.0.1:37471,DS-4ac55172-f128-4abe-b26c-61082d991c26,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-e31849da-f2a5-4956-90e1-99b60bde22a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-34de586c-bf1a-4acf-82c0-23d14bfd333f,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-63dbfa97-b0d1-4fe4-b1d2-a17dc3f93a31,DISK], DatanodeInfoWithStorage[127.0.0.1:38893,DS-f857d460-f5ea-44d9-a0eb-68ec82b06462,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-0f57c65e-491d-4143-b8bf-4cd1814df2da,DISK], DatanodeInfoWithStorage[127.0.0.1:40389,DS-699bc7f7-d860-4c0e-a6ce-25a74bf7f965,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1701862227-172.17.0.15-1595924429950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45460,DS-a18cf0da-2bf8-4fae-b49c-c3021a08a6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-a9eba15a-198e-48e4-ae16-d67728b1f0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-afb2aaaa-7ae5-4438-867b-7ac97f03cdb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-9b84790c-2b24-4423-9484-b586a472fc20,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-fbe48f07-5820-4a4e-9239-75255211cd90,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-4bcdca19-4a8e-46ec-a03d-32861f9c42fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-d1456b72-f9b6-4c62-af76-11e1602e5b77,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-851e8234-04ea-4e13-b183-574353a0833c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1701862227-172.17.0.15-1595924429950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45460,DS-a18cf0da-2bf8-4fae-b49c-c3021a08a6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-a9eba15a-198e-48e4-ae16-d67728b1f0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-afb2aaaa-7ae5-4438-867b-7ac97f03cdb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-9b84790c-2b24-4423-9484-b586a472fc20,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-fbe48f07-5820-4a4e-9239-75255211cd90,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-4bcdca19-4a8e-46ec-a03d-32861f9c42fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-d1456b72-f9b6-4c62-af76-11e1602e5b77,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-851e8234-04ea-4e13-b183-574353a0833c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-675277480-172.17.0.15-1595924573612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41096,DS-4bce37f6-a8a3-48b9-a9a7-ff5518845609,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-479fc965-e882-4b2c-a3f9-4aa931bcab94,DISK], DatanodeInfoWithStorage[127.0.0.1:42523,DS-da4dd53c-479c-485d-823b-6d1215912c12,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-77b1f2bf-6dc9-4d5f-bf12-4e33f464171a,DISK], DatanodeInfoWithStorage[127.0.0.1:40120,DS-ad2cbfa5-6c5c-457c-90c1-43b84acac78b,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-a628e639-b92d-4b37-b617-0b4575e4c328,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-7517b257-767a-4c05-8acd-85da7003e35f,DISK], DatanodeInfoWithStorage[127.0.0.1:44954,DS-917cb32b-b22d-48f4-8126-561b6bd75c2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-675277480-172.17.0.15-1595924573612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41096,DS-4bce37f6-a8a3-48b9-a9a7-ff5518845609,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-479fc965-e882-4b2c-a3f9-4aa931bcab94,DISK], DatanodeInfoWithStorage[127.0.0.1:42523,DS-da4dd53c-479c-485d-823b-6d1215912c12,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-77b1f2bf-6dc9-4d5f-bf12-4e33f464171a,DISK], DatanodeInfoWithStorage[127.0.0.1:40120,DS-ad2cbfa5-6c5c-457c-90c1-43b84acac78b,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-a628e639-b92d-4b37-b617-0b4575e4c328,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-7517b257-767a-4c05-8acd-85da7003e35f,DISK], DatanodeInfoWithStorage[127.0.0.1:44954,DS-917cb32b-b22d-48f4-8126-561b6bd75c2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-176608621-172.17.0.15-1595924615220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36211,DS-1c4bfcbd-a8c9-492c-a7a6-1e1096cd52dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-b40d6d31-e504-49ac-b024-1e540370b3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-0b6d5756-a871-4125-ab5a-fd2ea74104c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-1ef884cb-fa06-4b98-a20f-3061421d565d,DISK], DatanodeInfoWithStorage[127.0.0.1:42410,DS-ae1ada01-c30b-46b6-8366-1312c4eb4ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:39337,DS-e842c96f-2edb-4fe2-8b15-7fd2f377eee9,DISK], DatanodeInfoWithStorage[127.0.0.1:45954,DS-189c46b1-e92d-4bc5-954f-796bc6e4a72b,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-b47a54db-b6f0-47cb-a805-5d8f5037cb50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-176608621-172.17.0.15-1595924615220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36211,DS-1c4bfcbd-a8c9-492c-a7a6-1e1096cd52dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-b40d6d31-e504-49ac-b024-1e540370b3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-0b6d5756-a871-4125-ab5a-fd2ea74104c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-1ef884cb-fa06-4b98-a20f-3061421d565d,DISK], DatanodeInfoWithStorage[127.0.0.1:42410,DS-ae1ada01-c30b-46b6-8366-1312c4eb4ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:39337,DS-e842c96f-2edb-4fe2-8b15-7fd2f377eee9,DISK], DatanodeInfoWithStorage[127.0.0.1:45954,DS-189c46b1-e92d-4bc5-954f-796bc6e4a72b,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-b47a54db-b6f0-47cb-a805-5d8f5037cb50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980053018-172.17.0.15-1595924811056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39899,DS-07c19c58-e14a-438e-994a-f557a3097240,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-af0beffb-acd6-4cf0-92a0-838ffab67fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-62c20293-ba2f-4f5c-acdb-16f149290824,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-cb0029a4-9c67-4ccd-a4c0-e4a8883af4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-b8a84fa3-1ba3-4a58-b86d-5e2f646f82f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-21d79583-dad0-4d4a-b0d3-eed56b595ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-2d170182-a01e-4c61-abca-b1cd83f0aba8,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-9db3e44a-c6b6-4295-a14b-a5bec4cd760a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980053018-172.17.0.15-1595924811056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39899,DS-07c19c58-e14a-438e-994a-f557a3097240,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-af0beffb-acd6-4cf0-92a0-838ffab67fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-62c20293-ba2f-4f5c-acdb-16f149290824,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-cb0029a4-9c67-4ccd-a4c0-e4a8883af4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-b8a84fa3-1ba3-4a58-b86d-5e2f646f82f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-21d79583-dad0-4d4a-b0d3-eed56b595ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-2d170182-a01e-4c61-abca-b1cd83f0aba8,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-9db3e44a-c6b6-4295-a14b-a5bec4cd760a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-661216617-172.17.0.15-1595925035952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41688,DS-e1e319a3-cb68-4baa-b090-720a4fc42e26,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-c1b938e3-7cbe-4f34-b9e0-4332b4ae01bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-966e53ec-338a-48ff-a1fb-c9ad4945814e,DISK], DatanodeInfoWithStorage[127.0.0.1:39613,DS-125dd0bf-b4ca-4a05-9b6f-075c68f97fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-591b53ea-8559-48a3-8381-68f8a203605b,DISK], DatanodeInfoWithStorage[127.0.0.1:40498,DS-e5cc12f7-3f89-4d10-b322-d3ca7b4ee0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43716,DS-40aafa45-d5ac-4a7b-93a9-8392ee417a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-eada4490-3812-42eb-bb2e-f3cd1089d42e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-661216617-172.17.0.15-1595925035952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41688,DS-e1e319a3-cb68-4baa-b090-720a4fc42e26,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-c1b938e3-7cbe-4f34-b9e0-4332b4ae01bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-966e53ec-338a-48ff-a1fb-c9ad4945814e,DISK], DatanodeInfoWithStorage[127.0.0.1:39613,DS-125dd0bf-b4ca-4a05-9b6f-075c68f97fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-591b53ea-8559-48a3-8381-68f8a203605b,DISK], DatanodeInfoWithStorage[127.0.0.1:40498,DS-e5cc12f7-3f89-4d10-b322-d3ca7b4ee0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43716,DS-40aafa45-d5ac-4a7b-93a9-8392ee417a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-eada4490-3812-42eb-bb2e-f3cd1089d42e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-567410917-172.17.0.15-1595925298202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34586,DS-1002847b-5791-4d65-bf11-8ee042231c90,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-66863e04-bcaf-4bc9-aacb-4229b9fb6b92,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-421f6a08-614d-4d09-9dde-2727041540f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-9af3fd14-dce4-4a47-a909-b890dc1c7c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-205ba0a6-6b74-4bbb-aaeb-18fd3f553cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-870bcfa7-7c4a-48b6-87f0-237ab1dee302,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-97d0d052-e814-4e68-860b-a556d77cbe4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-0b46425f-bd8a-4aa3-ad39-c8f97c64a917,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-567410917-172.17.0.15-1595925298202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34586,DS-1002847b-5791-4d65-bf11-8ee042231c90,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-66863e04-bcaf-4bc9-aacb-4229b9fb6b92,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-421f6a08-614d-4d09-9dde-2727041540f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-9af3fd14-dce4-4a47-a909-b890dc1c7c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-205ba0a6-6b74-4bbb-aaeb-18fd3f553cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-870bcfa7-7c4a-48b6-87f0-237ab1dee302,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-97d0d052-e814-4e68-860b-a556d77cbe4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-0b46425f-bd8a-4aa3-ad39-c8f97c64a917,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-605090051-172.17.0.15-1595925960442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36032,DS-9009a226-51aa-4d9d-bf66-f231d349aee0,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-30aa7d7e-d654-43d1-adb4-e87ebc3c1db4,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-0ba23811-2958-4878-aab1-6b31d6761f59,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-9746fdd4-4584-41bf-8114-785f9776eef6,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-2e073c41-6cfa-4693-96a9-7c9d116dfc01,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-8473f01c-72d1-43e3-b011-563361f15bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-6e37f39a-5fa3-4344-855b-14c8f4bfd1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-208225ad-8b82-4264-8e80-5ded4db52787,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-605090051-172.17.0.15-1595925960442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36032,DS-9009a226-51aa-4d9d-bf66-f231d349aee0,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-30aa7d7e-d654-43d1-adb4-e87ebc3c1db4,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-0ba23811-2958-4878-aab1-6b31d6761f59,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-9746fdd4-4584-41bf-8114-785f9776eef6,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-2e073c41-6cfa-4693-96a9-7c9d116dfc01,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-8473f01c-72d1-43e3-b011-563361f15bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-6e37f39a-5fa3-4344-855b-14c8f4bfd1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-208225ad-8b82-4264-8e80-5ded4db52787,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-591499649-172.17.0.15-1595926089834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36092,DS-2706142a-42f7-4e20-9708-16e25bdd1d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-de19ac3c-063d-4d39-a557-0ce2edb93591,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-2a8803a1-e165-4d4b-bcaa-5437d7e02e08,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-0a7f2774-577a-4f7c-8c7f-aa8da81d791b,DISK], DatanodeInfoWithStorage[127.0.0.1:40836,DS-83e1ddc5-827c-4b72-8be9-35bc2ee75746,DISK], DatanodeInfoWithStorage[127.0.0.1:35530,DS-b4e2f194-81dc-4d92-b0c1-9539c6b218b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-24b749c9-4dd3-4e0e-afd5-5a41ec1fa5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-92b8b80d-d106-4797-a819-22cfa68190d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-591499649-172.17.0.15-1595926089834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36092,DS-2706142a-42f7-4e20-9708-16e25bdd1d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-de19ac3c-063d-4d39-a557-0ce2edb93591,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-2a8803a1-e165-4d4b-bcaa-5437d7e02e08,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-0a7f2774-577a-4f7c-8c7f-aa8da81d791b,DISK], DatanodeInfoWithStorage[127.0.0.1:40836,DS-83e1ddc5-827c-4b72-8be9-35bc2ee75746,DISK], DatanodeInfoWithStorage[127.0.0.1:35530,DS-b4e2f194-81dc-4d92-b0c1-9539c6b218b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-24b749c9-4dd3-4e0e-afd5-5a41ec1fa5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-92b8b80d-d106-4797-a819-22cfa68190d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-10170891-172.17.0.15-1595926136893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46554,DS-aadf038e-b4c1-483b-a33f-4a28df724d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-07846afb-1fbc-43e9-b4a9-b635d0eaff25,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-ef1cd72d-a3a8-4a41-b9dd-4e515fc566dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-a2f13ffc-6bb0-4856-8230-6a1e01bbf5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-7739e278-aa5e-4490-9a4d-1bc8bf5f2f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-cd90cfb8-b953-4b2d-816d-d0ad0f5cac9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-1c1662b6-3092-47d4-9128-c8a8a4b0907f,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-a51e19fb-8cf8-41d8-9af1-c6723a1b5917,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-10170891-172.17.0.15-1595926136893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46554,DS-aadf038e-b4c1-483b-a33f-4a28df724d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-07846afb-1fbc-43e9-b4a9-b635d0eaff25,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-ef1cd72d-a3a8-4a41-b9dd-4e515fc566dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-a2f13ffc-6bb0-4856-8230-6a1e01bbf5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-7739e278-aa5e-4490-9a4d-1bc8bf5f2f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-cd90cfb8-b953-4b2d-816d-d0ad0f5cac9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-1c1662b6-3092-47d4-9128-c8a8a4b0907f,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-a51e19fb-8cf8-41d8-9af1-c6723a1b5917,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1727236893-172.17.0.15-1595926437029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34704,DS-0ada4d50-85c7-45db-80e9-c9c996e16c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-8530ab42-a256-4bf0-8d91-01928fefa0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-7a507e28-b4ce-49e1-a07d-349a0a16c323,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-59728e79-32ef-4004-88a8-a766af1620c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-ca67c5a3-674a-43b6-be37-fe15be145193,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-b48da05c-9fce-47b6-94f5-808016e08ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:45360,DS-7e3dca28-6cc2-4584-8510-ed847f7771db,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-580a534c-f552-4441-bf65-610fc0819409,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1727236893-172.17.0.15-1595926437029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34704,DS-0ada4d50-85c7-45db-80e9-c9c996e16c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-8530ab42-a256-4bf0-8d91-01928fefa0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-7a507e28-b4ce-49e1-a07d-349a0a16c323,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-59728e79-32ef-4004-88a8-a766af1620c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-ca67c5a3-674a-43b6-be37-fe15be145193,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-b48da05c-9fce-47b6-94f5-808016e08ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:45360,DS-7e3dca28-6cc2-4584-8510-ed847f7771db,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-580a534c-f552-4441-bf65-610fc0819409,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-437679934-172.17.0.15-1595927090860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34937,DS-0c676b3f-0f75-41ee-a67d-e8c252925067,DISK], DatanodeInfoWithStorage[127.0.0.1:38165,DS-a6d7f1ca-cc2e-4134-bc91-8cdb22ab8290,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-ba01b0de-eeae-49f5-b1db-b8184b51c628,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-6717c344-8019-40d4-a20a-31d6579878ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-c54a7e0e-cc0c-4c70-b42c-62a4d40663d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34859,DS-f52c67a6-293f-4579-bac6-a56201d137fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-69bbbe7b-eb6c-4ad1-908d-97bf01c190ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-eed6e081-4c3f-405d-92f0-48cbfa17923e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-437679934-172.17.0.15-1595927090860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34937,DS-0c676b3f-0f75-41ee-a67d-e8c252925067,DISK], DatanodeInfoWithStorage[127.0.0.1:38165,DS-a6d7f1ca-cc2e-4134-bc91-8cdb22ab8290,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-ba01b0de-eeae-49f5-b1db-b8184b51c628,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-6717c344-8019-40d4-a20a-31d6579878ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-c54a7e0e-cc0c-4c70-b42c-62a4d40663d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34859,DS-f52c67a6-293f-4579-bac6-a56201d137fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-69bbbe7b-eb6c-4ad1-908d-97bf01c190ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-eed6e081-4c3f-405d-92f0-48cbfa17923e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2087803277-172.17.0.15-1595927138015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44004,DS-3cafa2cd-6bc6-4194-b618-3ccf613d89e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-691ef947-cfe9-4297-8787-4e0a3314202b,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-2e8b0a50-2001-4054-9cc6-c2e19a5fd48e,DISK], DatanodeInfoWithStorage[127.0.0.1:46355,DS-4efe0077-6dc2-40c5-9a5f-46391a108d55,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-ca82f23e-3ef6-4e4a-9752-8589a87d4547,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-d9edd879-07d7-4a85-a50a-c7056c84acdd,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-14add4bf-0fb3-4829-a9ab-e6eaa0487e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-a3e7e692-898a-4423-be41-6f5ce64d2198,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2087803277-172.17.0.15-1595927138015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44004,DS-3cafa2cd-6bc6-4194-b618-3ccf613d89e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-691ef947-cfe9-4297-8787-4e0a3314202b,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-2e8b0a50-2001-4054-9cc6-c2e19a5fd48e,DISK], DatanodeInfoWithStorage[127.0.0.1:46355,DS-4efe0077-6dc2-40c5-9a5f-46391a108d55,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-ca82f23e-3ef6-4e4a-9752-8589a87d4547,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-d9edd879-07d7-4a85-a50a-c7056c84acdd,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-14add4bf-0fb3-4829-a9ab-e6eaa0487e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-a3e7e692-898a-4423-be41-6f5ce64d2198,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-79572024-172.17.0.15-1595927186733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39147,DS-23623897-c117-41c8-8947-b33bc78ce1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-096625c5-3468-47f1-a6f5-2b0ba97341a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-c1613147-6f43-4a7b-98d9-62f0237de01c,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-b52e68cd-0cdf-4a9c-bc4d-e6f065434d51,DISK], DatanodeInfoWithStorage[127.0.0.1:46374,DS-3122c3af-1c43-4612-a175-513119c8b58c,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-b058cf55-e5b3-4b12-a7bb-8d8c75167691,DISK], DatanodeInfoWithStorage[127.0.0.1:41187,DS-ddd09f9d-6627-45c0-bcf7-f4c78a6d4684,DISK], DatanodeInfoWithStorage[127.0.0.1:34554,DS-f6e675cf-42dc-460c-aa91-8e36d5f682a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-79572024-172.17.0.15-1595927186733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39147,DS-23623897-c117-41c8-8947-b33bc78ce1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-096625c5-3468-47f1-a6f5-2b0ba97341a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-c1613147-6f43-4a7b-98d9-62f0237de01c,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-b52e68cd-0cdf-4a9c-bc4d-e6f065434d51,DISK], DatanodeInfoWithStorage[127.0.0.1:46374,DS-3122c3af-1c43-4612-a175-513119c8b58c,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-b058cf55-e5b3-4b12-a7bb-8d8c75167691,DISK], DatanodeInfoWithStorage[127.0.0.1:41187,DS-ddd09f9d-6627-45c0-bcf7-f4c78a6d4684,DISK], DatanodeInfoWithStorage[127.0.0.1:34554,DS-f6e675cf-42dc-460c-aa91-8e36d5f682a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 6745
