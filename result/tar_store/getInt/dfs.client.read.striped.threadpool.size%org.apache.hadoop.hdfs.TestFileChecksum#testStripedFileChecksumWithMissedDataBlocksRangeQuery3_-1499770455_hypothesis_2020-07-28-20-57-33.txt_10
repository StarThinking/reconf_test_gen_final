reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1252497079-172.17.0.8-1595969937875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37420,DS-a8178703-540d-4c02-8448-011dd7133992,DISK], DatanodeInfoWithStorage[127.0.0.1:45405,DS-2f7e0f76-8a6c-4636-b0b3-523cd20f1965,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-de313401-b298-4fe6-b1ad-157451fadae6,DISK], DatanodeInfoWithStorage[127.0.0.1:37458,DS-afb12a63-f787-4ee7-8970-af55fb880694,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-d79ff073-5368-46be-993c-a45576320e62,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-45f758bb-e49f-4570-a689-434de7af7109,DISK], DatanodeInfoWithStorage[127.0.0.1:38398,DS-05c1f2bb-ac32-4f29-a3bc-953e815df262,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-111db6cc-30a9-43ef-b18e-1a4ad0f444ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1252497079-172.17.0.8-1595969937875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37420,DS-a8178703-540d-4c02-8448-011dd7133992,DISK], DatanodeInfoWithStorage[127.0.0.1:45405,DS-2f7e0f76-8a6c-4636-b0b3-523cd20f1965,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-de313401-b298-4fe6-b1ad-157451fadae6,DISK], DatanodeInfoWithStorage[127.0.0.1:37458,DS-afb12a63-f787-4ee7-8970-af55fb880694,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-d79ff073-5368-46be-993c-a45576320e62,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-45f758bb-e49f-4570-a689-434de7af7109,DISK], DatanodeInfoWithStorage[127.0.0.1:38398,DS-05c1f2bb-ac32-4f29-a3bc-953e815df262,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-111db6cc-30a9-43ef-b18e-1a4ad0f444ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-467254419-172.17.0.8-1595970042623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42658,DS-354cc59b-fab3-463b-bc98-c18b52372036,DISK], DatanodeInfoWithStorage[127.0.0.1:38016,DS-a609a1de-e957-4e87-a584-ee0cdbaf83ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38797,DS-f08c6214-2504-476b-8f0a-5e116e274cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-0883344e-2356-4d8a-b517-97299f49d74b,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-a21bff50-e3ac-40ea-a049-add0099ffd91,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-7041e49e-7e76-4daa-ba56-8a3a280c3f86,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-098d6c47-3c4f-44cf-be0e-0cc74ade04af,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-a4279163-d785-45ca-a2cd-0e34c815b497,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-467254419-172.17.0.8-1595970042623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42658,DS-354cc59b-fab3-463b-bc98-c18b52372036,DISK], DatanodeInfoWithStorage[127.0.0.1:38016,DS-a609a1de-e957-4e87-a584-ee0cdbaf83ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38797,DS-f08c6214-2504-476b-8f0a-5e116e274cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-0883344e-2356-4d8a-b517-97299f49d74b,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-a21bff50-e3ac-40ea-a049-add0099ffd91,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-7041e49e-7e76-4daa-ba56-8a3a280c3f86,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-098d6c47-3c4f-44cf-be0e-0cc74ade04af,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-a4279163-d785-45ca-a2cd-0e34c815b497,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-889527925-172.17.0.8-1595970118876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45375,DS-b3caa64d-2e57-4931-9255-557774ea138c,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-8569a7c0-46ef-420f-baa5-a0b906f42d19,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-80e61fa6-80e7-4954-96c3-ae4bcd60f2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-f350a972-7bff-476a-9684-329d9905cae7,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-eacb917d-2aa7-4acc-9395-be4c3adbc3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-6e396832-9352-4d64-8b12-57f154f57ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-eb0e4b49-118a-4f05-bfa2-9dc265d593e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-8592b98e-fac7-44e6-87f7-f2daa3519088,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-889527925-172.17.0.8-1595970118876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45375,DS-b3caa64d-2e57-4931-9255-557774ea138c,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-8569a7c0-46ef-420f-baa5-a0b906f42d19,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-80e61fa6-80e7-4954-96c3-ae4bcd60f2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-f350a972-7bff-476a-9684-329d9905cae7,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-eacb917d-2aa7-4acc-9395-be4c3adbc3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-6e396832-9352-4d64-8b12-57f154f57ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-eb0e4b49-118a-4f05-bfa2-9dc265d593e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-8592b98e-fac7-44e6-87f7-f2daa3519088,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1335658182-172.17.0.8-1595970156925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35949,DS-de611586-c3ad-4aa5-a6ee-afacd3208b53,DISK], DatanodeInfoWithStorage[127.0.0.1:37775,DS-195187fd-44f3-4d95-b975-0fcbdf8eb309,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-42ba18f2-26f4-4da9-8354-5e61d8048d08,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-f88274f2-e740-4e81-a442-afa691640a87,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-6e31acef-63d4-4089-a8b5-4c53185d04e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-eb4218e5-f564-4017-9188-d2cdc74aebb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-55d27d3c-84bb-4af4-b4b8-8f09a1952641,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-b5a9d549-4ee7-4ea0-bb9c-33c53cc4fdce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1335658182-172.17.0.8-1595970156925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35949,DS-de611586-c3ad-4aa5-a6ee-afacd3208b53,DISK], DatanodeInfoWithStorage[127.0.0.1:37775,DS-195187fd-44f3-4d95-b975-0fcbdf8eb309,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-42ba18f2-26f4-4da9-8354-5e61d8048d08,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-f88274f2-e740-4e81-a442-afa691640a87,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-6e31acef-63d4-4089-a8b5-4c53185d04e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-eb4218e5-f564-4017-9188-d2cdc74aebb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-55d27d3c-84bb-4af4-b4b8-8f09a1952641,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-b5a9d549-4ee7-4ea0-bb9c-33c53cc4fdce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1226121792-172.17.0.8-1595970253558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41241,DS-b2bd3253-644b-4019-b243-b3b50352c3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-5d79dc09-dfa5-4ffb-ab6c-4c8c22e46924,DISK], DatanodeInfoWithStorage[127.0.0.1:36594,DS-483dfa4d-a34f-42c6-bb7f-92e23c86e6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-012df3f8-6c5d-4886-820b-ea0515279593,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-0d8b751c-0875-479f-8ec4-8dffad2e0951,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-f25239b0-90fb-4a37-a22a-eef9c0c2a432,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-ae2d7821-09b5-40f3-a762-1e835cd5713b,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-19fb8a21-be02-4073-bb60-62f0d67e6583,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1226121792-172.17.0.8-1595970253558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41241,DS-b2bd3253-644b-4019-b243-b3b50352c3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-5d79dc09-dfa5-4ffb-ab6c-4c8c22e46924,DISK], DatanodeInfoWithStorage[127.0.0.1:36594,DS-483dfa4d-a34f-42c6-bb7f-92e23c86e6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-012df3f8-6c5d-4886-820b-ea0515279593,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-0d8b751c-0875-479f-8ec4-8dffad2e0951,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-f25239b0-90fb-4a37-a22a-eef9c0c2a432,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-ae2d7821-09b5-40f3-a762-1e835cd5713b,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-19fb8a21-be02-4073-bb60-62f0d67e6583,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-932508383-172.17.0.8-1595970829684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44952,DS-3a4a5211-bcfd-4ef5-883a-975355c66af3,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-8ce27f2f-f46a-49dc-b08f-34bfb2b1354c,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-0c21ca63-b7e8-400d-8bca-6c5958f3f4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-51d64fdc-d053-46f8-a41e-f5bfd8a0c115,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-7e8f3fe8-2c87-4e76-bd35-7708422f5ead,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-89e636eb-67f7-4694-9aa3-a12666265e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-cdae2239-e593-4c1f-b867-fa199cc42cad,DISK], DatanodeInfoWithStorage[127.0.0.1:32975,DS-70b32bc9-0876-4f95-9899-53ec5acca7e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-932508383-172.17.0.8-1595970829684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44952,DS-3a4a5211-bcfd-4ef5-883a-975355c66af3,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-8ce27f2f-f46a-49dc-b08f-34bfb2b1354c,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-0c21ca63-b7e8-400d-8bca-6c5958f3f4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-51d64fdc-d053-46f8-a41e-f5bfd8a0c115,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-7e8f3fe8-2c87-4e76-bd35-7708422f5ead,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-89e636eb-67f7-4694-9aa3-a12666265e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-cdae2239-e593-4c1f-b867-fa199cc42cad,DISK], DatanodeInfoWithStorage[127.0.0.1:32975,DS-70b32bc9-0876-4f95-9899-53ec5acca7e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-105673675-172.17.0.8-1595971072281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40344,DS-33439dbb-e640-4f37-8878-af9810751c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-7b1a7031-ed91-464c-8378-a06a5508b66e,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-926f2029-7919-4f8a-94af-7fdbfe7bb0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-1ad40cc5-7254-415d-9156-25efd944d1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-58a25a83-7b8e-4be2-8bc8-383abe7446e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40572,DS-f26d0fc3-7a22-48f9-9ec1-13406e0b84fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-c1454358-2175-4904-9f4a-cef47c09170f,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-e5c645ff-5fac-49e0-8e12-d33ea3421fde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-105673675-172.17.0.8-1595971072281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40344,DS-33439dbb-e640-4f37-8878-af9810751c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-7b1a7031-ed91-464c-8378-a06a5508b66e,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-926f2029-7919-4f8a-94af-7fdbfe7bb0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-1ad40cc5-7254-415d-9156-25efd944d1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-58a25a83-7b8e-4be2-8bc8-383abe7446e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40572,DS-f26d0fc3-7a22-48f9-9ec1-13406e0b84fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-c1454358-2175-4904-9f4a-cef47c09170f,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-e5c645ff-5fac-49e0-8e12-d33ea3421fde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-399118258-172.17.0.8-1595971213792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42500,DS-8ae15ceb-9678-42a9-a315-f0c18c4c6eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-b6d6437c-da75-4f69-82cf-5eb16da99f95,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-e01d6698-5e70-4e25-b37f-70e11575d9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-511048a3-303f-4b0a-950f-6102658f3064,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-03ca5d02-2a86-4ad9-9db8-a640fe9a79aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37973,DS-44225587-c1ba-4282-b7b8-a9eef6772589,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-cbecd1d0-dfad-466e-a3c7-b98f6fc51c37,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-82e6b687-ef5f-4f0a-b67d-c8bd9e6a9cec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-399118258-172.17.0.8-1595971213792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42500,DS-8ae15ceb-9678-42a9-a315-f0c18c4c6eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-b6d6437c-da75-4f69-82cf-5eb16da99f95,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-e01d6698-5e70-4e25-b37f-70e11575d9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-511048a3-303f-4b0a-950f-6102658f3064,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-03ca5d02-2a86-4ad9-9db8-a640fe9a79aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37973,DS-44225587-c1ba-4282-b7b8-a9eef6772589,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-cbecd1d0-dfad-466e-a3c7-b98f6fc51c37,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-82e6b687-ef5f-4f0a-b67d-c8bd9e6a9cec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1832817597-172.17.0.8-1595971878577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35668,DS-9b9f4fd2-f604-4141-913d-cf65ed1eed71,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-8b92a5be-a73c-45b9-a1c0-5a682d29d00a,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-e784e35b-8b71-46bd-988b-c57f7121512e,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-5a1b6bc5-35d8-4e20-953a-2033e49796ff,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-b1f08dd1-5ed8-411b-a2f8-d380e99f90ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-0a9cffd8-9069-4dbc-9ef3-0cfdaa5e3fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-664c8a15-d15f-426e-995d-63542ab543fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-a2ef14d5-d463-41de-8b60-bbe82499796e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1832817597-172.17.0.8-1595971878577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35668,DS-9b9f4fd2-f604-4141-913d-cf65ed1eed71,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-8b92a5be-a73c-45b9-a1c0-5a682d29d00a,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-e784e35b-8b71-46bd-988b-c57f7121512e,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-5a1b6bc5-35d8-4e20-953a-2033e49796ff,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-b1f08dd1-5ed8-411b-a2f8-d380e99f90ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-0a9cffd8-9069-4dbc-9ef3-0cfdaa5e3fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-664c8a15-d15f-426e-995d-63542ab543fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-a2ef14d5-d463-41de-8b60-bbe82499796e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800471274-172.17.0.8-1595972229905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33848,DS-77f2f544-057c-4111-a6e4-3215d7fe9215,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-79ee43c7-8504-49ad-852a-9c70c34de209,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-608531ed-8c4b-41a2-8d89-04a656178a02,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-1cd3a397-8a82-4537-8954-2dfa345055c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-0a5fe7b0-8963-4d02-baa7-a362f2e8a3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-3c9c9ced-36b3-4a07-97b6-88906755d097,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-185a3c2e-22a2-43d4-b44b-56e8bf9ef8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-450e9ff7-e162-42d1-9fb5-7e53e2a69cb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800471274-172.17.0.8-1595972229905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33848,DS-77f2f544-057c-4111-a6e4-3215d7fe9215,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-79ee43c7-8504-49ad-852a-9c70c34de209,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-608531ed-8c4b-41a2-8d89-04a656178a02,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-1cd3a397-8a82-4537-8954-2dfa345055c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-0a5fe7b0-8963-4d02-baa7-a362f2e8a3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-3c9c9ced-36b3-4a07-97b6-88906755d097,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-185a3c2e-22a2-43d4-b44b-56e8bf9ef8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-450e9ff7-e162-42d1-9fb5-7e53e2a69cb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184864108-172.17.0.8-1595972578658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44443,DS-8a36bb0a-a665-452d-aa99-05d1c46c2a41,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-9fab5089-3bdf-459a-a017-a4dc6cc6c610,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-8297ec77-cfef-4e95-8124-234ed5e97766,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-bc104c3a-5f32-4186-9a0b-6f90eb1818ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33648,DS-71c2d8da-632d-4d96-9348-681f7b4f8d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-04346810-0968-40f9-a88a-a9ce68a4b0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37284,DS-3a635503-7be4-4ee5-ab3a-1b2e556eab34,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-ec571301-382e-4d05-a6e0-9c03f883b60c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184864108-172.17.0.8-1595972578658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44443,DS-8a36bb0a-a665-452d-aa99-05d1c46c2a41,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-9fab5089-3bdf-459a-a017-a4dc6cc6c610,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-8297ec77-cfef-4e95-8124-234ed5e97766,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-bc104c3a-5f32-4186-9a0b-6f90eb1818ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33648,DS-71c2d8da-632d-4d96-9348-681f7b4f8d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-04346810-0968-40f9-a88a-a9ce68a4b0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37284,DS-3a635503-7be4-4ee5-ab3a-1b2e556eab34,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-ec571301-382e-4d05-a6e0-9c03f883b60c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951971470-172.17.0.8-1595972839935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35861,DS-2e1248ec-e3f9-43d6-aa5c-6f8eb2b8aafc,DISK], DatanodeInfoWithStorage[127.0.0.1:43639,DS-c7ed89d5-6b65-4281-bd0a-0be4026eb2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-6042a449-10b7-43fa-a3a9-22d1360e2652,DISK], DatanodeInfoWithStorage[127.0.0.1:44265,DS-a11c0edc-4df4-447b-b07a-497a7ca6c42f,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-d1437988-428f-4d07-bb0e-92df8a9f14ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-01ddd957-e66d-42d0-b75d-060b02a1e09b,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-51d270a3-097a-42d7-833e-d59966e21177,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-6e4fce6a-ebde-425f-ab5d-dfe744572a57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951971470-172.17.0.8-1595972839935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35861,DS-2e1248ec-e3f9-43d6-aa5c-6f8eb2b8aafc,DISK], DatanodeInfoWithStorage[127.0.0.1:43639,DS-c7ed89d5-6b65-4281-bd0a-0be4026eb2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-6042a449-10b7-43fa-a3a9-22d1360e2652,DISK], DatanodeInfoWithStorage[127.0.0.1:44265,DS-a11c0edc-4df4-447b-b07a-497a7ca6c42f,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-d1437988-428f-4d07-bb0e-92df8a9f14ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-01ddd957-e66d-42d0-b75d-060b02a1e09b,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-51d270a3-097a-42d7-833e-d59966e21177,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-6e4fce6a-ebde-425f-ab5d-dfe744572a57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-428085234-172.17.0.8-1595972906476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36210,DS-c0d2850d-a095-4280-bdf5-72c6dc77067a,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-b23c2da8-d4c2-46e5-9b1b-9002b8ca0f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-52aa36f3-ee54-44f1-8616-1dac025bbac0,DISK], DatanodeInfoWithStorage[127.0.0.1:40142,DS-8abd9a6e-eff4-42fb-a730-20a0c066432d,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-166d31d3-6fd8-484a-9395-94c762316e23,DISK], DatanodeInfoWithStorage[127.0.0.1:46050,DS-776cb4c5-b529-4130-b77c-b2da5cca9b82,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-1b59863a-9547-4067-a31f-762a682d08b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-512e3a34-da77-4786-831b-2b579d7ee8ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-428085234-172.17.0.8-1595972906476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36210,DS-c0d2850d-a095-4280-bdf5-72c6dc77067a,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-b23c2da8-d4c2-46e5-9b1b-9002b8ca0f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-52aa36f3-ee54-44f1-8616-1dac025bbac0,DISK], DatanodeInfoWithStorage[127.0.0.1:40142,DS-8abd9a6e-eff4-42fb-a730-20a0c066432d,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-166d31d3-6fd8-484a-9395-94c762316e23,DISK], DatanodeInfoWithStorage[127.0.0.1:46050,DS-776cb4c5-b529-4130-b77c-b2da5cca9b82,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-1b59863a-9547-4067-a31f-762a682d08b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-512e3a34-da77-4786-831b-2b579d7ee8ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1275900606-172.17.0.8-1595973344114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42547,DS-e2720392-3f46-4b17-81a2-eb60b4ebf1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-64ddc493-16a8-4b0c-80e9-a9c67df74b84,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-25159425-91f3-4e4e-b4ae-ba174080e5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-df720c50-2610-4985-8153-2326c6f2bcd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-a9435d06-fdab-452f-8674-afaa5de6b81d,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-ff1c4b64-cf39-43ca-a6a9-9151a8e62a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-6ff5d4a5-4802-42d7-9144-65ca93d47148,DISK], DatanodeInfoWithStorage[127.0.0.1:35000,DS-fff5275b-dc95-4fcd-a018-de345082d5e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1275900606-172.17.0.8-1595973344114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42547,DS-e2720392-3f46-4b17-81a2-eb60b4ebf1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-64ddc493-16a8-4b0c-80e9-a9c67df74b84,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-25159425-91f3-4e4e-b4ae-ba174080e5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-df720c50-2610-4985-8153-2326c6f2bcd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-a9435d06-fdab-452f-8674-afaa5de6b81d,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-ff1c4b64-cf39-43ca-a6a9-9151a8e62a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-6ff5d4a5-4802-42d7-9144-65ca93d47148,DISK], DatanodeInfoWithStorage[127.0.0.1:35000,DS-fff5275b-dc95-4fcd-a018-de345082d5e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-97674144-172.17.0.8-1595973705627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35097,DS-4826c8e3-75db-4be6-b352-4dfecc4d2c12,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-b8a10920-3e41-4af4-b2d1-d4dffa2fb656,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-16c5e0eb-2a62-45a7-98bd-87debe3bc8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-dd3a8212-f4d9-45a0-af54-6637188a6ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-8de4f278-d0ec-4d31-90d1-5545ce95493f,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-276b5d1e-226a-44ac-a376-3774dae28e25,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-b991c6b9-0959-4f09-91de-01a7f25ff5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35050,DS-90d9d548-d03c-4759-a7f4-9369f1b4f076,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-97674144-172.17.0.8-1595973705627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35097,DS-4826c8e3-75db-4be6-b352-4dfecc4d2c12,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-b8a10920-3e41-4af4-b2d1-d4dffa2fb656,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-16c5e0eb-2a62-45a7-98bd-87debe3bc8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-dd3a8212-f4d9-45a0-af54-6637188a6ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-8de4f278-d0ec-4d31-90d1-5545ce95493f,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-276b5d1e-226a-44ac-a376-3774dae28e25,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-b991c6b9-0959-4f09-91de-01a7f25ff5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35050,DS-90d9d548-d03c-4759-a7f4-9369f1b4f076,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2099367558-172.17.0.8-1595974137370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44040,DS-92afceb1-4f42-486e-b3d0-da22b1a795ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-dcadfc1d-c128-499b-8218-350d502ecf9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-a98ee76d-98db-48e6-90ab-109d284ccbea,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-88b21e53-b5ea-4f9e-8858-0b3459789408,DISK], DatanodeInfoWithStorage[127.0.0.1:34447,DS-f2916177-cf1d-4e58-a5e0-2ccfa8025316,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-c22b3403-e47d-4f66-a1a1-1d440c874892,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-03065c67-88b9-4b08-b672-80eb202a739f,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-4aee9171-cbd1-4b43-8fc7-a8aaf6c21502,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2099367558-172.17.0.8-1595974137370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44040,DS-92afceb1-4f42-486e-b3d0-da22b1a795ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-dcadfc1d-c128-499b-8218-350d502ecf9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-a98ee76d-98db-48e6-90ab-109d284ccbea,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-88b21e53-b5ea-4f9e-8858-0b3459789408,DISK], DatanodeInfoWithStorage[127.0.0.1:34447,DS-f2916177-cf1d-4e58-a5e0-2ccfa8025316,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-c22b3403-e47d-4f66-a1a1-1d440c874892,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-03065c67-88b9-4b08-b672-80eb202a739f,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-4aee9171-cbd1-4b43-8fc7-a8aaf6c21502,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-857272530-172.17.0.8-1595974216588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34814,DS-03344041-af35-4776-aa93-2ccc0a56ef85,DISK], DatanodeInfoWithStorage[127.0.0.1:45814,DS-49386ef4-f869-4cfb-8a5c-17ba5c77b876,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-23cace97-84cd-47da-85aa-1976c104c5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-61abfe63-aa2b-4ede-b52a-ea72ee1f9ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-f7cd0b6a-2cf5-4405-b088-81b7b3d9f798,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-7aaa99cb-2318-4f98-94f2-93d3c9dcd57c,DISK], DatanodeInfoWithStorage[127.0.0.1:41518,DS-800da2ee-79bc-4c67-b442-22159354c270,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-e94355d5-ed5f-43ad-90de-5f33fb8f602b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-857272530-172.17.0.8-1595974216588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34814,DS-03344041-af35-4776-aa93-2ccc0a56ef85,DISK], DatanodeInfoWithStorage[127.0.0.1:45814,DS-49386ef4-f869-4cfb-8a5c-17ba5c77b876,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-23cace97-84cd-47da-85aa-1976c104c5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-61abfe63-aa2b-4ede-b52a-ea72ee1f9ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-f7cd0b6a-2cf5-4405-b088-81b7b3d9f798,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-7aaa99cb-2318-4f98-94f2-93d3c9dcd57c,DISK], DatanodeInfoWithStorage[127.0.0.1:41518,DS-800da2ee-79bc-4c67-b442-22159354c270,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-e94355d5-ed5f-43ad-90de-5f33fb8f602b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1181417854-172.17.0.8-1595974429233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41892,DS-c2d85405-7479-44a7-ab8b-185369269a21,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-3205a41f-e8cd-464b-a32b-3e30fb254a35,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-07aa0966-d89f-42fe-bb5d-adfe78b3cb10,DISK], DatanodeInfoWithStorage[127.0.0.1:42483,DS-bc6f9e80-59f9-451a-9be5-98e135072c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-70f729ba-4106-4c4f-8505-85b22cd11b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-be8ad3cc-5316-4f38-aa40-eec5b60e8e19,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-51b7af4d-cf72-4e64-95f6-d1f2ac7a7710,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-7105f142-30c6-40d8-89a6-96bc3e46403a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1181417854-172.17.0.8-1595974429233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41892,DS-c2d85405-7479-44a7-ab8b-185369269a21,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-3205a41f-e8cd-464b-a32b-3e30fb254a35,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-07aa0966-d89f-42fe-bb5d-adfe78b3cb10,DISK], DatanodeInfoWithStorage[127.0.0.1:42483,DS-bc6f9e80-59f9-451a-9be5-98e135072c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-70f729ba-4106-4c4f-8505-85b22cd11b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-be8ad3cc-5316-4f38-aa40-eec5b60e8e19,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-51b7af4d-cf72-4e64-95f6-d1f2ac7a7710,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-7105f142-30c6-40d8-89a6-96bc3e46403a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-902633467-172.17.0.8-1595974469180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36502,DS-607edc66-27a1-42db-ac1b-329e607ad5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-0f48274f-aa7f-4a34-897a-af36a25616df,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-ffc7ff19-c2df-420f-9640-85b62f3dd953,DISK], DatanodeInfoWithStorage[127.0.0.1:32898,DS-80a025f4-1279-4d49-a766-7a4fa439a385,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-7138b0ce-1568-4cdb-b939-a6fe12a4e60b,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-5e8b2496-dda9-4c2d-b7e0-6953dc0aa8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-15e2a533-e01d-4434-a45e-8814e1379c31,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-0febeb14-3543-43a3-bda7-a8b79f440020,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-902633467-172.17.0.8-1595974469180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36502,DS-607edc66-27a1-42db-ac1b-329e607ad5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-0f48274f-aa7f-4a34-897a-af36a25616df,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-ffc7ff19-c2df-420f-9640-85b62f3dd953,DISK], DatanodeInfoWithStorage[127.0.0.1:32898,DS-80a025f4-1279-4d49-a766-7a4fa439a385,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-7138b0ce-1568-4cdb-b939-a6fe12a4e60b,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-5e8b2496-dda9-4c2d-b7e0-6953dc0aa8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-15e2a533-e01d-4434-a45e-8814e1379c31,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-0febeb14-3543-43a3-bda7-a8b79f440020,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5026
