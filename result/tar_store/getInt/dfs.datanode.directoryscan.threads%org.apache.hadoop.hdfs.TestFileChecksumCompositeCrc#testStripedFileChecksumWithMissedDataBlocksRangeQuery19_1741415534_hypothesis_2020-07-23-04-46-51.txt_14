reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1913087231-172.17.0.2-1595479808665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36437,DS-bd08fbca-699c-4eb9-828b-222b934a0752,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-83aff754-f973-4e7a-8de4-abdca85f2e33,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-b1d9a60e-3c99-4255-8098-a10bedfcabf5,DISK], DatanodeInfoWithStorage[127.0.0.1:35910,DS-f637a210-33e9-49c4-a21a-8f61098bf0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-bbb13414-a6f3-458b-8986-5bfcbc8de5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-d671e358-bc02-4ec1-a711-933487b702b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44042,DS-7ee0ac51-6756-433b-b174-fcdcce7ee003,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-d160bebe-3b8d-4ac8-8a87-1e951bb10227,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1913087231-172.17.0.2-1595479808665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36437,DS-bd08fbca-699c-4eb9-828b-222b934a0752,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-83aff754-f973-4e7a-8de4-abdca85f2e33,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-b1d9a60e-3c99-4255-8098-a10bedfcabf5,DISK], DatanodeInfoWithStorage[127.0.0.1:35910,DS-f637a210-33e9-49c4-a21a-8f61098bf0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-bbb13414-a6f3-458b-8986-5bfcbc8de5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-d671e358-bc02-4ec1-a711-933487b702b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44042,DS-7ee0ac51-6756-433b-b174-fcdcce7ee003,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-d160bebe-3b8d-4ac8-8a87-1e951bb10227,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-681791218-172.17.0.2-1595479997163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35022,DS-2b3870ca-51b8-44de-8373-ef188d9bf7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-7000a28f-7634-4805-8fbc-0939966e7b53,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-fefb6b43-84f0-4463-a3f4-71170ce4b65c,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-05194792-54fc-4176-beea-7e38f5b7189b,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-4b99b228-d4e5-4d49-852d-c14254a6559c,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-8ac9f3e7-a1e8-4fe8-bb65-75ccf72ee9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40405,DS-58809420-66eb-4d80-a809-e01b9b78d0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-06434685-5d0d-4d1f-b96b-93ca5bc193bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-681791218-172.17.0.2-1595479997163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35022,DS-2b3870ca-51b8-44de-8373-ef188d9bf7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-7000a28f-7634-4805-8fbc-0939966e7b53,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-fefb6b43-84f0-4463-a3f4-71170ce4b65c,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-05194792-54fc-4176-beea-7e38f5b7189b,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-4b99b228-d4e5-4d49-852d-c14254a6559c,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-8ac9f3e7-a1e8-4fe8-bb65-75ccf72ee9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40405,DS-58809420-66eb-4d80-a809-e01b9b78d0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-06434685-5d0d-4d1f-b96b-93ca5bc193bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2116984687-172.17.0.2-1595480028081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37626,DS-028508f7-9a3d-4b7d-ac6a-dab5858e46b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-f71f9c7d-3bc0-4b3c-bb35-2166fbbfb002,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-b72d2ec8-af76-4b19-9ff0-ad97b3985787,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-3bc6fdc1-5ba9-4f8a-96d8-97d876a082aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-16ea1c9f-8a17-42f9-8439-11d05145b01a,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-4e12b9b8-8d6e-4a6b-b6e5-7457b5accc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-f5443fde-c095-42d0-b671-0a84d4b4ae18,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-5f703372-844b-4472-a545-97cade56aac8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2116984687-172.17.0.2-1595480028081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37626,DS-028508f7-9a3d-4b7d-ac6a-dab5858e46b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-f71f9c7d-3bc0-4b3c-bb35-2166fbbfb002,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-b72d2ec8-af76-4b19-9ff0-ad97b3985787,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-3bc6fdc1-5ba9-4f8a-96d8-97d876a082aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-16ea1c9f-8a17-42f9-8439-11d05145b01a,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-4e12b9b8-8d6e-4a6b-b6e5-7457b5accc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-f5443fde-c095-42d0-b671-0a84d4b4ae18,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-5f703372-844b-4472-a545-97cade56aac8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-269197065-172.17.0.2-1595480444100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41563,DS-0a270ee0-3af3-496d-8376-fe272b774fef,DISK], DatanodeInfoWithStorage[127.0.0.1:46522,DS-e4c7eedb-b90d-460f-a7a1-bc7b4f27ff6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45610,DS-e7cd60bd-4f10-4b94-b753-bb99848234e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-d8cd0f69-271f-4374-9e7b-2cc78567f9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-9dc6f710-7813-42ac-862b-0b8e8fb7daf3,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-55cc323a-22f5-4b38-a51c-b95c3c135d52,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-9e6867f2-9498-4662-b136-a81de0fa1b14,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-ae0d799b-227c-49b6-9394-0d304e163bac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-269197065-172.17.0.2-1595480444100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41563,DS-0a270ee0-3af3-496d-8376-fe272b774fef,DISK], DatanodeInfoWithStorage[127.0.0.1:46522,DS-e4c7eedb-b90d-460f-a7a1-bc7b4f27ff6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45610,DS-e7cd60bd-4f10-4b94-b753-bb99848234e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-d8cd0f69-271f-4374-9e7b-2cc78567f9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-9dc6f710-7813-42ac-862b-0b8e8fb7daf3,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-55cc323a-22f5-4b38-a51c-b95c3c135d52,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-9e6867f2-9498-4662-b136-a81de0fa1b14,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-ae0d799b-227c-49b6-9394-0d304e163bac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-336367420-172.17.0.2-1595480472553:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41814,DS-6df2c3de-00b7-4797-bf4c-635d5e6e9413,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-0ae497be-097b-4e8a-85f3-29ec4e6d0ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-993fad0d-7308-4011-b881-a7b7ad4df633,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-53ca3e9f-68d4-4821-9b05-c07099e6433a,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-bf7cf2f9-81c4-4be6-aa38-c7084796ef39,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-894f46d6-bf6c-479a-947b-b42aa8d3c267,DISK], DatanodeInfoWithStorage[127.0.0.1:45030,DS-ead60e13-f9c2-4593-9f68-41218a53dcf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39960,DS-caac91ae-56fa-4742-9ffe-d41cbe637992,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-336367420-172.17.0.2-1595480472553:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41814,DS-6df2c3de-00b7-4797-bf4c-635d5e6e9413,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-0ae497be-097b-4e8a-85f3-29ec4e6d0ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-993fad0d-7308-4011-b881-a7b7ad4df633,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-53ca3e9f-68d4-4821-9b05-c07099e6433a,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-bf7cf2f9-81c4-4be6-aa38-c7084796ef39,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-894f46d6-bf6c-479a-947b-b42aa8d3c267,DISK], DatanodeInfoWithStorage[127.0.0.1:45030,DS-ead60e13-f9c2-4593-9f68-41218a53dcf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39960,DS-caac91ae-56fa-4742-9ffe-d41cbe637992,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1321508405-172.17.0.2-1595480701986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35074,DS-d951ab24-c337-4ef1-821a-b9592b4bbbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-30ee529b-3055-48e6-b87a-f05538409631,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-17517714-ac27-4aa1-a3c8-2909bd0c8930,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-7d339d69-01bb-40ac-89cf-d28fb849537a,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-4e91064f-1a62-4391-abcf-45bd9cf25efc,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-bafc1efd-1485-42f5-9e3d-cbf298c49e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-8cc38dc5-aeff-41b4-bed4-715bdf295b53,DISK], DatanodeInfoWithStorage[127.0.0.1:36496,DS-1ea6f9f9-14b7-41a2-8f35-e360be9363e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1321508405-172.17.0.2-1595480701986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35074,DS-d951ab24-c337-4ef1-821a-b9592b4bbbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-30ee529b-3055-48e6-b87a-f05538409631,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-17517714-ac27-4aa1-a3c8-2909bd0c8930,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-7d339d69-01bb-40ac-89cf-d28fb849537a,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-4e91064f-1a62-4391-abcf-45bd9cf25efc,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-bafc1efd-1485-42f5-9e3d-cbf298c49e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-8cc38dc5-aeff-41b4-bed4-715bdf295b53,DISK], DatanodeInfoWithStorage[127.0.0.1:36496,DS-1ea6f9f9-14b7-41a2-8f35-e360be9363e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-257863564-172.17.0.2-1595480912242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36355,DS-9a0ee020-288c-4105-abdc-760e36258fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-33d0a437-c685-43e2-bc43-78ab853a7fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-b89564d1-fe5e-4989-9aba-d1282be3cc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-c0ecf3a5-0498-4f30-bb29-516535adf722,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-2dea4c7b-24fe-40a1-bd99-0c0e8b4601b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-00c0349f-d740-4181-a072-d5db30cdb05b,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-f3bcbd39-b1cc-494a-8618-2a2862f406ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-8fe75305-e105-49af-bf2c-4df2bc324831,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-257863564-172.17.0.2-1595480912242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36355,DS-9a0ee020-288c-4105-abdc-760e36258fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-33d0a437-c685-43e2-bc43-78ab853a7fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-b89564d1-fe5e-4989-9aba-d1282be3cc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-c0ecf3a5-0498-4f30-bb29-516535adf722,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-2dea4c7b-24fe-40a1-bd99-0c0e8b4601b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-00c0349f-d740-4181-a072-d5db30cdb05b,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-f3bcbd39-b1cc-494a-8618-2a2862f406ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-8fe75305-e105-49af-bf2c-4df2bc324831,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1945770329-172.17.0.2-1595481112623:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34281,DS-b73adc4c-c587-4617-8d7d-05cd4d8c3fec,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-e3e2a1a8-07fc-424a-82f4-c385d0ca6690,DISK], DatanodeInfoWithStorage[127.0.0.1:36742,DS-5d695c31-bf93-4fb7-9d00-90d48c20becf,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-6ecda734-03ed-405f-b2eb-3685566f2f39,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-8f64d011-c736-4aeb-90d7-a231c7ee3957,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-687b9c83-5b8e-4076-86ca-530313f04666,DISK], DatanodeInfoWithStorage[127.0.0.1:37367,DS-9072825c-fd8a-4624-b139-6fd5e7e66cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43538,DS-175b07cc-6652-4b7c-acaa-2aad8054fd6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1945770329-172.17.0.2-1595481112623:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34281,DS-b73adc4c-c587-4617-8d7d-05cd4d8c3fec,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-e3e2a1a8-07fc-424a-82f4-c385d0ca6690,DISK], DatanodeInfoWithStorage[127.0.0.1:36742,DS-5d695c31-bf93-4fb7-9d00-90d48c20becf,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-6ecda734-03ed-405f-b2eb-3685566f2f39,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-8f64d011-c736-4aeb-90d7-a231c7ee3957,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-687b9c83-5b8e-4076-86ca-530313f04666,DISK], DatanodeInfoWithStorage[127.0.0.1:37367,DS-9072825c-fd8a-4624-b139-6fd5e7e66cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43538,DS-175b07cc-6652-4b7c-acaa-2aad8054fd6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1013301784-172.17.0.2-1595481475764:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41937,DS-6b84314d-1351-445a-a091-5f36d2bd2ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:43020,DS-967eaa56-095a-4c20-801a-09af0d33e575,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-4837ad39-407a-4032-a97a-4a85e857a494,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-6fc16e7e-cb71-4eef-b222-f59dd3630f30,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-36786fb2-b0fa-4f5d-9f5a-4ad62237a8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-9b695cc9-966a-425f-8184-4861309874d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-72580942-1d18-4b51-a1d2-56a938a1382f,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-b23b390d-921d-4418-802b-bb31fbcb7d86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1013301784-172.17.0.2-1595481475764:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41937,DS-6b84314d-1351-445a-a091-5f36d2bd2ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:43020,DS-967eaa56-095a-4c20-801a-09af0d33e575,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-4837ad39-407a-4032-a97a-4a85e857a494,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-6fc16e7e-cb71-4eef-b222-f59dd3630f30,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-36786fb2-b0fa-4f5d-9f5a-4ad62237a8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-9b695cc9-966a-425f-8184-4861309874d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-72580942-1d18-4b51-a1d2-56a938a1382f,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-b23b390d-921d-4418-802b-bb31fbcb7d86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1421712688-172.17.0.2-1595482003489:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46027,DS-0abb6528-cc78-4c15-a917-a92470ff6ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-62227540-9630-4efb-9dff-25df6fc80f56,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-dc837730-4fde-4ca4-b9e2-67d6dcab6e54,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-9949a53d-3b7e-40be-bb38-6f64fcf915d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-1ee876ca-f832-46d0-bcbc-bec024db8c63,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-1032b729-3745-4ce2-876b-0f692dc5fb00,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-2cd146b8-300f-4a34-ae74-9bb02068c129,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-60873577-46a5-41aa-8218-19860b30df2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1421712688-172.17.0.2-1595482003489:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46027,DS-0abb6528-cc78-4c15-a917-a92470ff6ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-62227540-9630-4efb-9dff-25df6fc80f56,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-dc837730-4fde-4ca4-b9e2-67d6dcab6e54,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-9949a53d-3b7e-40be-bb38-6f64fcf915d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-1ee876ca-f832-46d0-bcbc-bec024db8c63,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-1032b729-3745-4ce2-876b-0f692dc5fb00,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-2cd146b8-300f-4a34-ae74-9bb02068c129,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-60873577-46a5-41aa-8218-19860b30df2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-89541261-172.17.0.2-1595482373116:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33227,DS-67e361fb-846d-499d-91dc-80b9acdef487,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-5d6a3fa6-11d7-45e6-b328-05124c11ff3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-d0a5e4e2-b0ce-4084-ba74-887ec57d192f,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-b4d39c2b-74ae-4304-be92-168ee7994b74,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-f89354d8-a531-4cd5-8370-78e2d7bf5a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-5670fd45-94e5-4e26-92d8-3af6054147b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42556,DS-f9390b30-92b6-4faa-bac1-1ebe61934045,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-2efe5f59-0663-4c04-bee7-e75770bb1f44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-89541261-172.17.0.2-1595482373116:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33227,DS-67e361fb-846d-499d-91dc-80b9acdef487,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-5d6a3fa6-11d7-45e6-b328-05124c11ff3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-d0a5e4e2-b0ce-4084-ba74-887ec57d192f,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-b4d39c2b-74ae-4304-be92-168ee7994b74,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-f89354d8-a531-4cd5-8370-78e2d7bf5a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-5670fd45-94e5-4e26-92d8-3af6054147b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42556,DS-f9390b30-92b6-4faa-bac1-1ebe61934045,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-2efe5f59-0663-4c04-bee7-e75770bb1f44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2137624200-172.17.0.2-1595482480116:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38790,DS-bc8e3829-fb9e-409c-87b5-b43e54b5991a,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-bbb86905-fbad-4adc-8673-b9df208488f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-ff187b64-3e7c-4962-a796-6a508beaf5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-90351705-a048-40c7-9151-da2987cb397f,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-fda8e6d4-5341-4e95-915c-545cda0939a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-c4330bd1-ca85-4246-bedc-06219980ec65,DISK], DatanodeInfoWithStorage[127.0.0.1:43115,DS-5d28ea69-518e-41f8-918b-5b62e1510a42,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-8f7c54e9-fd28-4df9-9c1d-3e548acc70d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2137624200-172.17.0.2-1595482480116:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38790,DS-bc8e3829-fb9e-409c-87b5-b43e54b5991a,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-bbb86905-fbad-4adc-8673-b9df208488f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-ff187b64-3e7c-4962-a796-6a508beaf5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-90351705-a048-40c7-9151-da2987cb397f,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-fda8e6d4-5341-4e95-915c-545cda0939a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-c4330bd1-ca85-4246-bedc-06219980ec65,DISK], DatanodeInfoWithStorage[127.0.0.1:43115,DS-5d28ea69-518e-41f8-918b-5b62e1510a42,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-8f7c54e9-fd28-4df9-9c1d-3e548acc70d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-687502388-172.17.0.2-1595482552491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38636,DS-d4ea3825-cbd2-4e5a-a259-b1276f6b2d99,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-3474bc3f-e401-4361-a572-80471190eeb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-98c9930f-4203-4067-b218-9eb821d9770c,DISK], DatanodeInfoWithStorage[127.0.0.1:44061,DS-4f95c4b7-5944-4a52-be4c-3f245761c2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-3f4a7e4b-8a86-4ea8-86c5-34196fba74a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-4bddc5b9-d804-4f4b-aa01-4eca9a5a33c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-82ed0a86-5d8a-40dc-9aae-6497b4a6d931,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-2590e6fc-078f-4184-9963-581004d3d574,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-687502388-172.17.0.2-1595482552491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38636,DS-d4ea3825-cbd2-4e5a-a259-b1276f6b2d99,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-3474bc3f-e401-4361-a572-80471190eeb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-98c9930f-4203-4067-b218-9eb821d9770c,DISK], DatanodeInfoWithStorage[127.0.0.1:44061,DS-4f95c4b7-5944-4a52-be4c-3f245761c2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-3f4a7e4b-8a86-4ea8-86c5-34196fba74a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-4bddc5b9-d804-4f4b-aa01-4eca9a5a33c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-82ed0a86-5d8a-40dc-9aae-6497b4a6d931,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-2590e6fc-078f-4184-9963-581004d3d574,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1657947042-172.17.0.2-1595483279940:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42196,DS-ea4fbc06-b947-4f1e-b4e9-a63561fc2a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-56d51d83-2cd5-4774-a75a-a9233e7af34b,DISK], DatanodeInfoWithStorage[127.0.0.1:34928,DS-0e983a27-235f-445f-9dca-50072b5d809c,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-412b0d0b-e711-4e02-960b-02bfd338d3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-d5306b3c-6f3b-4c89-b075-48bd391f18b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-2c838e92-2f3d-4990-95b7-b4920591b45e,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-f41bfea2-d46d-4cbb-b6bd-02081ae14b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-71347093-f7b8-4888-b862-97b9d15e1904,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1657947042-172.17.0.2-1595483279940:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42196,DS-ea4fbc06-b947-4f1e-b4e9-a63561fc2a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-56d51d83-2cd5-4774-a75a-a9233e7af34b,DISK], DatanodeInfoWithStorage[127.0.0.1:34928,DS-0e983a27-235f-445f-9dca-50072b5d809c,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-412b0d0b-e711-4e02-960b-02bfd338d3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-d5306b3c-6f3b-4c89-b075-48bd391f18b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-2c838e92-2f3d-4990-95b7-b4920591b45e,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-f41bfea2-d46d-4cbb-b6bd-02081ae14b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-71347093-f7b8-4888-b862-97b9d15e1904,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-556867107-172.17.0.2-1595483730186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41869,DS-9d253da4-92b4-4f14-adc0-19391cf9a4de,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-62e601c1-db48-4a12-9c5e-bd71f6718983,DISK], DatanodeInfoWithStorage[127.0.0.1:33759,DS-df6fcb72-0906-4557-bb8f-a92d7545510a,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-7a962a52-7e70-4a04-8394-5706e8052246,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-3db9703f-54b4-4e95-bddd-2bdca1460ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-d25aa4b8-a97b-408a-b5b2-18232911b2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-0c67df26-beee-4846-9d36-822f91b6fc43,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-948992a0-6483-406e-93ee-8fbfcb4aa902,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-556867107-172.17.0.2-1595483730186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41869,DS-9d253da4-92b4-4f14-adc0-19391cf9a4de,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-62e601c1-db48-4a12-9c5e-bd71f6718983,DISK], DatanodeInfoWithStorage[127.0.0.1:33759,DS-df6fcb72-0906-4557-bb8f-a92d7545510a,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-7a962a52-7e70-4a04-8394-5706e8052246,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-3db9703f-54b4-4e95-bddd-2bdca1460ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-d25aa4b8-a97b-408a-b5b2-18232911b2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-0c67df26-beee-4846-9d36-822f91b6fc43,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-948992a0-6483-406e-93ee-8fbfcb4aa902,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-245775089-172.17.0.2-1595484072683:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36727,DS-2a9f0a24-daa1-4d04-9b23-b1a65c795c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-c655857a-f38a-4aac-9c47-188f0485959b,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-336ea80c-9752-4a1f-8585-a1eb5594b970,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-fb59abc1-4bd0-4b9f-93ca-87a4b7a9a7da,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-95647732-3af0-4858-a07a-7faa16140ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:37732,DS-40164c13-ea14-42f6-a993-e63d33fdd67e,DISK], DatanodeInfoWithStorage[127.0.0.1:41762,DS-2a1fbdcd-63df-4fed-ba89-6330e539da8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35724,DS-85a0e69c-bd0e-434d-aa52-80118f123309,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-245775089-172.17.0.2-1595484072683:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36727,DS-2a9f0a24-daa1-4d04-9b23-b1a65c795c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-c655857a-f38a-4aac-9c47-188f0485959b,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-336ea80c-9752-4a1f-8585-a1eb5594b970,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-fb59abc1-4bd0-4b9f-93ca-87a4b7a9a7da,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-95647732-3af0-4858-a07a-7faa16140ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:37732,DS-40164c13-ea14-42f6-a993-e63d33fdd67e,DISK], DatanodeInfoWithStorage[127.0.0.1:41762,DS-2a1fbdcd-63df-4fed-ba89-6330e539da8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35724,DS-85a0e69c-bd0e-434d-aa52-80118f123309,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-281103194-172.17.0.2-1595484317910:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33813,DS-a6625363-d5a4-4710-b017-c560cd7914fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-3f4e9597-4ed8-4ce1-8598-650e41464473,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-6118302e-d62f-4c07-8fb1-326a8d2ac751,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-a8be900b-74a9-4e80-9b12-ebb5f779974d,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-d96aeb68-ee59-445d-8433-190601c89ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:42670,DS-eca85c25-4aaa-4e42-b23d-96e82ffe1440,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-d1583af7-e1cb-4348-bd16-4e9d144a87b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-5f86f810-41f6-4f20-9d73-2ff23d224f63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-281103194-172.17.0.2-1595484317910:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33813,DS-a6625363-d5a4-4710-b017-c560cd7914fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-3f4e9597-4ed8-4ce1-8598-650e41464473,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-6118302e-d62f-4c07-8fb1-326a8d2ac751,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-a8be900b-74a9-4e80-9b12-ebb5f779974d,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-d96aeb68-ee59-445d-8433-190601c89ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:42670,DS-eca85c25-4aaa-4e42-b23d-96e82ffe1440,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-d1583af7-e1cb-4348-bd16-4e9d144a87b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-5f86f810-41f6-4f20-9d73-2ff23d224f63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1896724299-172.17.0.2-1595484421720:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36042,DS-c15f5b85-b8fe-4a09-8a30-19568af6ef33,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-9b4485d4-734a-4267-8c9f-2e3639cf11b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-6a180a6f-9d3d-4afd-8a27-567ca9b346d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-39cc6d23-2542-459a-85e8-0b8e8b751db9,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-4a519be6-87d0-443e-aed5-662ba528358d,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-21454c03-b9bd-4406-8f96-67873c59c116,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-02667a2b-8a26-4eab-9770-e45daf80aeaf,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-4bf736d2-f01b-427f-8fc4-c649eb32b4c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1896724299-172.17.0.2-1595484421720:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36042,DS-c15f5b85-b8fe-4a09-8a30-19568af6ef33,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-9b4485d4-734a-4267-8c9f-2e3639cf11b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-6a180a6f-9d3d-4afd-8a27-567ca9b346d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-39cc6d23-2542-459a-85e8-0b8e8b751db9,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-4a519be6-87d0-443e-aed5-662ba528358d,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-21454c03-b9bd-4406-8f96-67873c59c116,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-02667a2b-8a26-4eab-9770-e45daf80aeaf,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-4bf736d2-f01b-427f-8fc4-c649eb32b4c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1043958404-172.17.0.2-1595484575012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41968,DS-9dacd58d-f323-4e30-98f7-b8c3333b6f55,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-09ee668b-ac6c-46c9-b73f-309035444daf,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-68edb011-df6d-4d23-949a-894379ddab9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-996613e9-ce37-4f97-9039-ae36527388fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-0b337b35-696f-4352-b495-59adddf71c32,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-ddf41c1e-d55c-49c4-b250-b6bb4bee6b63,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-f1a9c892-0306-46cc-b993-c53c9884a3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-2ae90bc0-3909-4355-85e4-5a06190b7335,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1043958404-172.17.0.2-1595484575012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41968,DS-9dacd58d-f323-4e30-98f7-b8c3333b6f55,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-09ee668b-ac6c-46c9-b73f-309035444daf,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-68edb011-df6d-4d23-949a-894379ddab9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-996613e9-ce37-4f97-9039-ae36527388fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-0b337b35-696f-4352-b495-59adddf71c32,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-ddf41c1e-d55c-49c4-b250-b6bb4bee6b63,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-f1a9c892-0306-46cc-b993-c53c9884a3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-2ae90bc0-3909-4355-85e4-5a06190b7335,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5252
