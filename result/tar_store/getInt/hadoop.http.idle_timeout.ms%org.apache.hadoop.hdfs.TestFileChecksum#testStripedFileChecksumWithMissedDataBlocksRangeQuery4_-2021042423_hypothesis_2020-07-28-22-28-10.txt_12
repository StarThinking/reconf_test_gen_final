reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-106660751-172.17.0.11-1595976218114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44869,DS-221cfb86-aa68-496f-b203-e05f983e62e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-259dc5fc-029e-4d56-87fc-04e8a3747a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46816,DS-8a631d6b-20c8-474c-b7ea-7de5a38a6f71,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-4431b7fd-fa55-4721-a481-966bf571ab72,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-55d11a0f-9e24-40a9-9543-0ce743176475,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-feecdd36-5334-48c4-9e7a-491e28ef77a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-6a542662-ab26-4075-ae9b-4d83bb287523,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-546dba8e-1ee2-4598-b990-2214269a069e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-106660751-172.17.0.11-1595976218114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44869,DS-221cfb86-aa68-496f-b203-e05f983e62e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-259dc5fc-029e-4d56-87fc-04e8a3747a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46816,DS-8a631d6b-20c8-474c-b7ea-7de5a38a6f71,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-4431b7fd-fa55-4721-a481-966bf571ab72,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-55d11a0f-9e24-40a9-9543-0ce743176475,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-feecdd36-5334-48c4-9e7a-491e28ef77a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-6a542662-ab26-4075-ae9b-4d83bb287523,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-546dba8e-1ee2-4598-b990-2214269a069e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2093360028-172.17.0.11-1595976331421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38787,DS-22b5ade6-6783-4b1d-82d8-9874440e0590,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-aa496d30-4925-4679-9d66-505bc6f4174d,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-9a941e2f-507b-4895-b118-b52f33d778b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-11879d64-7817-40a3-aaad-ea6ef917bd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-5b555159-5153-4c89-ad5d-d9c3e54acbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-6b8fbb73-4bd1-4c29-8b5f-b73a33b96f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41818,DS-4072fbbb-2c53-45fb-8ee6-7a978630a6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-ae70b8bb-cdd1-445d-9d3d-9a730c1be3cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2093360028-172.17.0.11-1595976331421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38787,DS-22b5ade6-6783-4b1d-82d8-9874440e0590,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-aa496d30-4925-4679-9d66-505bc6f4174d,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-9a941e2f-507b-4895-b118-b52f33d778b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-11879d64-7817-40a3-aaad-ea6ef917bd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-5b555159-5153-4c89-ad5d-d9c3e54acbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-6b8fbb73-4bd1-4c29-8b5f-b73a33b96f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41818,DS-4072fbbb-2c53-45fb-8ee6-7a978630a6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-ae70b8bb-cdd1-445d-9d3d-9a730c1be3cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-159017162-172.17.0.11-1595976926702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45995,DS-f0274379-5329-4c83-b05d-ce16ee282b84,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-900dbfe2-1a53-4f7d-9976-57a88f755ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-690dab67-3808-4167-9143-22dac3d3c0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35185,DS-93c224ee-0aba-4f2a-b30b-5f1fe0d96669,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-1f0605c0-ef75-45e2-af3d-d3c04735869c,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-f6c3d5ce-ce35-43f3-a9c4-22cd0189fe17,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-13b947b8-5916-43c5-bcf8-d672d2c16e84,DISK], DatanodeInfoWithStorage[127.0.0.1:39853,DS-8b78a985-961d-4228-b2e5-c5388b60caab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-159017162-172.17.0.11-1595976926702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45995,DS-f0274379-5329-4c83-b05d-ce16ee282b84,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-900dbfe2-1a53-4f7d-9976-57a88f755ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-690dab67-3808-4167-9143-22dac3d3c0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35185,DS-93c224ee-0aba-4f2a-b30b-5f1fe0d96669,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-1f0605c0-ef75-45e2-af3d-d3c04735869c,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-f6c3d5ce-ce35-43f3-a9c4-22cd0189fe17,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-13b947b8-5916-43c5-bcf8-d672d2c16e84,DISK], DatanodeInfoWithStorage[127.0.0.1:39853,DS-8b78a985-961d-4228-b2e5-c5388b60caab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-376132758-172.17.0.11-1595977108928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40528,DS-30ea8860-a615-40e4-95b3-d90afcf8615f,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-75dacbff-2be1-417e-b6b9-d28ecaa91bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-96c86777-30ba-4269-94d5-7ee4f43139b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46118,DS-56d6a09b-8d27-4e87-acdf-8fac6352edc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-a6f6c7c0-c568-4ef1-90c0-c0e0a4b7ff02,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-6541e92e-c133-4aab-9831-3ae5e15d1d43,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-a60d54f4-d740-4b28-8033-b9af0e285160,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-1ca5a482-9fc9-4161-9f46-bfd037538e25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-376132758-172.17.0.11-1595977108928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40528,DS-30ea8860-a615-40e4-95b3-d90afcf8615f,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-75dacbff-2be1-417e-b6b9-d28ecaa91bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-96c86777-30ba-4269-94d5-7ee4f43139b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46118,DS-56d6a09b-8d27-4e87-acdf-8fac6352edc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-a6f6c7c0-c568-4ef1-90c0-c0e0a4b7ff02,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-6541e92e-c133-4aab-9831-3ae5e15d1d43,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-a60d54f4-d740-4b28-8033-b9af0e285160,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-1ca5a482-9fc9-4161-9f46-bfd037538e25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2035779841-172.17.0.11-1595977301777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43918,DS-8de098fc-7ce7-4e83-81cd-108323aa55d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-a9ca537c-0239-41c7-9319-bbcbe582436e,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-0319e674-c431-4c64-b158-74a40aa5c83f,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-407879dc-98fd-48d2-acf2-a076ffd3e94b,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-fe6cc54b-a38a-419d-9270-339c37d125c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46686,DS-1f6d3d97-5c8a-4179-a92c-0f751deea990,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-a7da90e5-509b-43df-b3ca-19db24c48cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-3b261fb0-f4c1-43d2-bd36-799feff6cd37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2035779841-172.17.0.11-1595977301777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43918,DS-8de098fc-7ce7-4e83-81cd-108323aa55d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-a9ca537c-0239-41c7-9319-bbcbe582436e,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-0319e674-c431-4c64-b158-74a40aa5c83f,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-407879dc-98fd-48d2-acf2-a076ffd3e94b,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-fe6cc54b-a38a-419d-9270-339c37d125c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46686,DS-1f6d3d97-5c8a-4179-a92c-0f751deea990,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-a7da90e5-509b-43df-b3ca-19db24c48cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-3b261fb0-f4c1-43d2-bd36-799feff6cd37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1454459728-172.17.0.11-1595977623551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46754,DS-f5a7469f-fcda-4d5f-8bae-c0a01accf0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-4ece5426-635c-4cb0-80ef-5a43c7492759,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-199a0fb2-e6c4-4b7e-93b4-903020ecb3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-5d0424ab-4b28-4ae1-a4ee-20024560b704,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-00819ab6-342b-4593-98bf-8373cf558c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-b453d34d-3697-4754-afc2-82e5e0465efb,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-fd1c0973-f63f-4938-b873-07d765ac22fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-cb9ad0dc-f5ce-4cac-beb7-d93ee748cd84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1454459728-172.17.0.11-1595977623551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46754,DS-f5a7469f-fcda-4d5f-8bae-c0a01accf0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-4ece5426-635c-4cb0-80ef-5a43c7492759,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-199a0fb2-e6c4-4b7e-93b4-903020ecb3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-5d0424ab-4b28-4ae1-a4ee-20024560b704,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-00819ab6-342b-4593-98bf-8373cf558c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-b453d34d-3697-4754-afc2-82e5e0465efb,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-fd1c0973-f63f-4938-b873-07d765ac22fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-cb9ad0dc-f5ce-4cac-beb7-d93ee748cd84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54448025-172.17.0.11-1595977653194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34475,DS-a9126d0a-e467-4810-a214-3ec26c0047f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-e7880bfd-00b7-4f89-aed7-c843afa99e41,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-8cb73565-d1f0-40e0-81a0-5eb940ea89ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-81e6d215-6774-4127-a3b4-ed15d21097fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34804,DS-2ddbcd0b-c754-4460-a09c-cfe5f8347d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-5dd0bd88-7c2a-489b-b168-b418bbd6af01,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-f4980a76-169a-4150-9ed0-88158b4ceefd,DISK], DatanodeInfoWithStorage[127.0.0.1:46789,DS-e05ae62d-44db-4dc2-8d36-756a41e08344,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54448025-172.17.0.11-1595977653194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34475,DS-a9126d0a-e467-4810-a214-3ec26c0047f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-e7880bfd-00b7-4f89-aed7-c843afa99e41,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-8cb73565-d1f0-40e0-81a0-5eb940ea89ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-81e6d215-6774-4127-a3b4-ed15d21097fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34804,DS-2ddbcd0b-c754-4460-a09c-cfe5f8347d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-5dd0bd88-7c2a-489b-b168-b418bbd6af01,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-f4980a76-169a-4150-9ed0-88158b4ceefd,DISK], DatanodeInfoWithStorage[127.0.0.1:46789,DS-e05ae62d-44db-4dc2-8d36-756a41e08344,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1737684214-172.17.0.11-1595977741386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44405,DS-57ca7698-2fe6-4c74-8e8d-32d62fc15fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-3f7c7402-d15a-457e-8d43-b21db65f9659,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-72a8fe80-94d6-4b8f-a8ae-ced381de2bed,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-b9b1e2f9-bbd2-4188-84b2-0349dda5dfb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-77c55611-7866-4a88-ac7e-c86ea5905dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-a877d94c-f73e-4f22-935c-ce77448f3988,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-bbeb0885-b473-4d42-8575-8c02e3ce314d,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-a8f94db0-eb9c-4d26-b400-cb39625b2358,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1737684214-172.17.0.11-1595977741386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44405,DS-57ca7698-2fe6-4c74-8e8d-32d62fc15fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-3f7c7402-d15a-457e-8d43-b21db65f9659,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-72a8fe80-94d6-4b8f-a8ae-ced381de2bed,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-b9b1e2f9-bbd2-4188-84b2-0349dda5dfb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-77c55611-7866-4a88-ac7e-c86ea5905dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-a877d94c-f73e-4f22-935c-ce77448f3988,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-bbeb0885-b473-4d42-8575-8c02e3ce314d,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-a8f94db0-eb9c-4d26-b400-cb39625b2358,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892679805-172.17.0.11-1595977770273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42310,DS-93eb07f5-a5a8-4dbc-b9c3-868a3fc1412a,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-8686b115-a8a0-4260-8ae7-45919c0a2c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-718ce50f-8de3-4a0c-8a1f-71a19b6b64a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-b2eda942-5f25-41b6-a73d-47065e011f88,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-611fdf14-e425-48eb-9384-c997593acb68,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-ac28f090-7191-4bd6-8a08-f61212e0ff36,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-0ec3d1ed-912c-4419-ab1b-92cff6478ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-5e5c7dc3-c960-413e-b049-123916e24db6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892679805-172.17.0.11-1595977770273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42310,DS-93eb07f5-a5a8-4dbc-b9c3-868a3fc1412a,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-8686b115-a8a0-4260-8ae7-45919c0a2c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-718ce50f-8de3-4a0c-8a1f-71a19b6b64a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-b2eda942-5f25-41b6-a73d-47065e011f88,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-611fdf14-e425-48eb-9384-c997593acb68,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-ac28f090-7191-4bd6-8a08-f61212e0ff36,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-0ec3d1ed-912c-4419-ab1b-92cff6478ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-5e5c7dc3-c960-413e-b049-123916e24db6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1917455404-172.17.0.11-1595978012953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39694,DS-3260fdaf-3a72-434e-afa7-b1ebed22087d,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-df13c3b0-7e9c-4876-a0f2-7861a49d83a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-d58607ab-5f75-4861-98ac-761a0d5e6dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-86693677-d319-4697-915b-1f3d1c657b58,DISK], DatanodeInfoWithStorage[127.0.0.1:44202,DS-c79002d8-50d2-4f66-8731-32bfdab8c552,DISK], DatanodeInfoWithStorage[127.0.0.1:42171,DS-78242713-00ef-48b0-b653-9898769075c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-903e02d4-e460-4f5d-ad1d-63a92b5b4e74,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-312aa296-2be9-4842-81f9-fe63ec01339f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1917455404-172.17.0.11-1595978012953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39694,DS-3260fdaf-3a72-434e-afa7-b1ebed22087d,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-df13c3b0-7e9c-4876-a0f2-7861a49d83a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-d58607ab-5f75-4861-98ac-761a0d5e6dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-86693677-d319-4697-915b-1f3d1c657b58,DISK], DatanodeInfoWithStorage[127.0.0.1:44202,DS-c79002d8-50d2-4f66-8731-32bfdab8c552,DISK], DatanodeInfoWithStorage[127.0.0.1:42171,DS-78242713-00ef-48b0-b653-9898769075c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-903e02d4-e460-4f5d-ad1d-63a92b5b4e74,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-312aa296-2be9-4842-81f9-fe63ec01339f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2130998134-172.17.0.11-1595978041408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38547,DS-8e4b5b67-809b-4163-9b28-cb7ef6020db0,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-ec86dd98-ba4e-45df-8f47-033fe8b0f4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-81226d73-1d2e-44ba-a682-4c313f37faa6,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-6dc6eafa-4eb4-4845-928c-9abee9b5dfb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-18e1a0e8-932d-4fbe-a49a-9c6c470aa9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-af5023ec-7e84-4b24-a5de-5220f920a764,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-18df6a71-6292-4915-9719-9ba3a71f76e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-cc0a2a82-5085-4e8f-a03b-ba6f2f50b7bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2130998134-172.17.0.11-1595978041408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38547,DS-8e4b5b67-809b-4163-9b28-cb7ef6020db0,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-ec86dd98-ba4e-45df-8f47-033fe8b0f4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-81226d73-1d2e-44ba-a682-4c313f37faa6,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-6dc6eafa-4eb4-4845-928c-9abee9b5dfb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-18e1a0e8-932d-4fbe-a49a-9c6c470aa9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-af5023ec-7e84-4b24-a5de-5220f920a764,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-18df6a71-6292-4915-9719-9ba3a71f76e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-cc0a2a82-5085-4e8f-a03b-ba6f2f50b7bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1810889013-172.17.0.11-1595978110348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44382,DS-73c2d5de-e646-4533-9428-e79cc2c47c61,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-54969af9-c11e-4038-952c-bddef941c66e,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-678b3ac0-c380-4ada-bd14-45f6d8d7e510,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-f1fd4261-1b0d-482c-a7ac-6c88ddc5213a,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-241b0807-41f0-4898-99fd-0a94e92e46b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-4044a05a-1916-4392-bcf9-3205ddb836f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-54d72046-9ba1-42d3-b43a-a8b93abf7862,DISK], DatanodeInfoWithStorage[127.0.0.1:32794,DS-1369aa0a-1c65-4ef3-82dc-d0fb755474f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1810889013-172.17.0.11-1595978110348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44382,DS-73c2d5de-e646-4533-9428-e79cc2c47c61,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-54969af9-c11e-4038-952c-bddef941c66e,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-678b3ac0-c380-4ada-bd14-45f6d8d7e510,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-f1fd4261-1b0d-482c-a7ac-6c88ddc5213a,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-241b0807-41f0-4898-99fd-0a94e92e46b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-4044a05a-1916-4392-bcf9-3205ddb836f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-54d72046-9ba1-42d3-b43a-a8b93abf7862,DISK], DatanodeInfoWithStorage[127.0.0.1:32794,DS-1369aa0a-1c65-4ef3-82dc-d0fb755474f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1678774241-172.17.0.11-1595978340234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35384,DS-09d6057e-11d2-4aff-9e0e-da7b239213c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-7f330bb4-c9cc-495a-8abe-68af2501bdc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-3b16053b-aff7-4aac-8607-6f2248034aab,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-51817fe3-cc6e-475f-ba68-ac7cc6ff9b90,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-f1826cfa-85b8-4e8b-822c-afa55193ffe3,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-cc7ad413-15fd-4e0f-a373-5539e2df05c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-30c9b4b5-e91d-44c4-ba03-da98d617eef8,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-134f830a-ce8f-4051-9c0c-1ebf4b75f079,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1678774241-172.17.0.11-1595978340234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35384,DS-09d6057e-11d2-4aff-9e0e-da7b239213c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-7f330bb4-c9cc-495a-8abe-68af2501bdc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-3b16053b-aff7-4aac-8607-6f2248034aab,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-51817fe3-cc6e-475f-ba68-ac7cc6ff9b90,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-f1826cfa-85b8-4e8b-822c-afa55193ffe3,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-cc7ad413-15fd-4e0f-a373-5539e2df05c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-30c9b4b5-e91d-44c4-ba03-da98d617eef8,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-134f830a-ce8f-4051-9c0c-1ebf4b75f079,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-338836153-172.17.0.11-1595978372020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43083,DS-6ef9b608-39e2-46b0-8161-181406f481b0,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-b47ee951-620f-4ee2-b600-9fc877829e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-f49f0891-d49f-4e98-b270-3789a61443ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-3629272c-ad45-4aca-ba1a-c11fbd7078ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-4c9851c4-d17a-41c6-b45b-18c1d3a20cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-44d9efdf-6308-4a11-99af-09d0f9652891,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-bf6cbd61-0d1e-4982-a90a-3ea3eb58346e,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-81d2a10f-4428-46bd-9067-7fefd7ab56f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-338836153-172.17.0.11-1595978372020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43083,DS-6ef9b608-39e2-46b0-8161-181406f481b0,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-b47ee951-620f-4ee2-b600-9fc877829e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-f49f0891-d49f-4e98-b270-3789a61443ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-3629272c-ad45-4aca-ba1a-c11fbd7078ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-4c9851c4-d17a-41c6-b45b-18c1d3a20cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-44d9efdf-6308-4a11-99af-09d0f9652891,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-bf6cbd61-0d1e-4982-a90a-3ea3eb58346e,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-81d2a10f-4428-46bd-9067-7fefd7ab56f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1808066152-172.17.0.11-1595978604781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41618,DS-9d0d76be-b3f7-4229-9fbc-f7a8425090ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-85640363-8a65-4f8f-bc0f-2410df69c52a,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-dda194a2-2485-48f3-b4e5-2575b112c48a,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-4ff43b1d-1f6b-42ca-907a-03a99c7ba9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33910,DS-7ae53316-bc20-4acc-aeb0-5eeb27285fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-47cfe2ee-60e9-4a97-a054-933fd4e4e8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-b5ab1611-2dbb-434a-900b-360836a13878,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-44fe1347-1cc8-4c71-87aa-e63821369a90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1808066152-172.17.0.11-1595978604781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41618,DS-9d0d76be-b3f7-4229-9fbc-f7a8425090ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-85640363-8a65-4f8f-bc0f-2410df69c52a,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-dda194a2-2485-48f3-b4e5-2575b112c48a,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-4ff43b1d-1f6b-42ca-907a-03a99c7ba9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33910,DS-7ae53316-bc20-4acc-aeb0-5eeb27285fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-47cfe2ee-60e9-4a97-a054-933fd4e4e8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-b5ab1611-2dbb-434a-900b-360836a13878,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-44fe1347-1cc8-4c71-87aa-e63821369a90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1030640876-172.17.0.11-1595978637803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45644,DS-52dacd00-7422-4d93-b776-19b8dc691d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36776,DS-cb6d5157-d681-41d4-a340-2f09a6d9c9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-cd49be8f-eb83-4d09-b494-d30a6272ee24,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-81a15768-bedf-45bc-b916-f2c0d7936cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-87ef9293-8f40-4636-b687-ecbba083e4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-286d052c-d219-4576-a35f-be8354113ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-48531356-7225-49e3-b79c-cb2da42641a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-180c6993-953d-4e4d-813c-340862ce6128,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1030640876-172.17.0.11-1595978637803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45644,DS-52dacd00-7422-4d93-b776-19b8dc691d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36776,DS-cb6d5157-d681-41d4-a340-2f09a6d9c9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-cd49be8f-eb83-4d09-b494-d30a6272ee24,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-81a15768-bedf-45bc-b916-f2c0d7936cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-87ef9293-8f40-4636-b687-ecbba083e4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-286d052c-d219-4576-a35f-be8354113ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-48531356-7225-49e3-b79c-cb2da42641a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-180c6993-953d-4e4d-813c-340862ce6128,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1758744485-172.17.0.11-1595978913447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35758,DS-69884ca7-7ea0-4966-9bf4-5f82d81e423a,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-1b23505a-cb99-4fb0-a781-923f9196ec9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-b8547511-cf58-41c7-997e-cbf4c2fb7d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-9fcddb7b-d4da-49ad-b89e-55ae6e777799,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-defb5f8c-b6b7-4a88-b7c5-aefa24757b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-952d1814-ade5-4f42-b041-897d36afffb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-8aa78807-28b0-46b9-81ed-4c3fd2fb36f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-8941de75-6583-459a-9eb1-c334c0473e40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1758744485-172.17.0.11-1595978913447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35758,DS-69884ca7-7ea0-4966-9bf4-5f82d81e423a,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-1b23505a-cb99-4fb0-a781-923f9196ec9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-b8547511-cf58-41c7-997e-cbf4c2fb7d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-9fcddb7b-d4da-49ad-b89e-55ae6e777799,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-defb5f8c-b6b7-4a88-b7c5-aefa24757b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-952d1814-ade5-4f42-b041-897d36afffb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-8aa78807-28b0-46b9-81ed-4c3fd2fb36f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-8941de75-6583-459a-9eb1-c334c0473e40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-564042173-172.17.0.11-1595979877613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45493,DS-f3153239-a7f7-4122-afa6-12d1d01a79f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-2aa59d5c-afd7-422c-8d4e-9659bd34bcc5,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-b437e876-11d3-45ff-8508-1b810d9f5c07,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-d099fa34-4202-4e50-b21a-f5e3e96ec5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33643,DS-54366f1a-c489-4ecb-b93f-11f3902e9954,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-e1da8ca8-09c0-48a6-af60-77835356b6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-0af00e70-3bce-482f-90f0-39175f5bc865,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-2c296e1d-a771-49c6-a8a3-43eee2434e61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-564042173-172.17.0.11-1595979877613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45493,DS-f3153239-a7f7-4122-afa6-12d1d01a79f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-2aa59d5c-afd7-422c-8d4e-9659bd34bcc5,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-b437e876-11d3-45ff-8508-1b810d9f5c07,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-d099fa34-4202-4e50-b21a-f5e3e96ec5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33643,DS-54366f1a-c489-4ecb-b93f-11f3902e9954,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-e1da8ca8-09c0-48a6-af60-77835356b6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-0af00e70-3bce-482f-90f0-39175f5bc865,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-2c296e1d-a771-49c6-a8a3-43eee2434e61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1671512954-172.17.0.11-1595979980306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37097,DS-8439f9e0-0b15-4b07-828f-bc230a575665,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-2164c5ea-408c-4c0a-8ed1-d08adede6497,DISK], DatanodeInfoWithStorage[127.0.0.1:45430,DS-56c34256-d9b7-4df4-b5ef-6e04a4cc66d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36745,DS-c4207f28-63b0-4e4b-b54b-54bca766a20d,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-d1db0be2-7709-490f-b053-9513c34e087a,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-e14fe996-27e7-4466-b858-3eb55b69439f,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-12d71517-02da-47ad-82c1-2dec5b14168b,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-2409e49a-2f8d-45b6-b836-8ac7d0e22927,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1671512954-172.17.0.11-1595979980306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37097,DS-8439f9e0-0b15-4b07-828f-bc230a575665,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-2164c5ea-408c-4c0a-8ed1-d08adede6497,DISK], DatanodeInfoWithStorage[127.0.0.1:45430,DS-56c34256-d9b7-4df4-b5ef-6e04a4cc66d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36745,DS-c4207f28-63b0-4e4b-b54b-54bca766a20d,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-d1db0be2-7709-490f-b053-9513c34e087a,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-e14fe996-27e7-4466-b858-3eb55b69439f,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-12d71517-02da-47ad-82c1-2dec5b14168b,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-2409e49a-2f8d-45b6-b836-8ac7d0e22927,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5093
