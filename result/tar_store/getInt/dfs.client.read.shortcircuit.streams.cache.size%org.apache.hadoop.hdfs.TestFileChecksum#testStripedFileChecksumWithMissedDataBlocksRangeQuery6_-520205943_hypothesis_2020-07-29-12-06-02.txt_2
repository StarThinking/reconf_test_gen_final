reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2063065599-172.17.0.12-1596024378577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33786,DS-504f175e-b813-4e68-8cd7-117920d1503b,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-73358d94-dc21-4aa5-a10a-1d13ea1c924b,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-0ba1a6b2-bf0e-4bb7-a96d-c307d9cc3e29,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-6ee251f5-920c-4d5b-95e2-041b6495f8af,DISK], DatanodeInfoWithStorage[127.0.0.1:43647,DS-e54b5491-5f3e-450b-8646-9a4062eb0143,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-47326874-fadc-4d62-a84b-f1fa952fc770,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-f25b514f-5eff-434d-89ae-e776a1f81101,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-503f24ec-6a15-45d1-85cb-b9e2af41e59d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2063065599-172.17.0.12-1596024378577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33786,DS-504f175e-b813-4e68-8cd7-117920d1503b,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-73358d94-dc21-4aa5-a10a-1d13ea1c924b,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-0ba1a6b2-bf0e-4bb7-a96d-c307d9cc3e29,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-6ee251f5-920c-4d5b-95e2-041b6495f8af,DISK], DatanodeInfoWithStorage[127.0.0.1:43647,DS-e54b5491-5f3e-450b-8646-9a4062eb0143,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-47326874-fadc-4d62-a84b-f1fa952fc770,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-f25b514f-5eff-434d-89ae-e776a1f81101,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-503f24ec-6a15-45d1-85cb-b9e2af41e59d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1480115759-172.17.0.12-1596024555402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46521,DS-0c966b69-e8ba-42da-bacd-693eca0120b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-0e5cfd41-69e5-43b6-a8ea-237adfb84293,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-138a2e12-2934-4b35-8ffa-3646bd39011e,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-cb8c2a32-7d37-44e1-bffd-dadc2e6208fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-a339914a-a22c-4d4f-8bed-812a91890812,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-ffb368eb-3c74-415e-9f81-1e7633e6167b,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-332318ce-ae9b-403a-814d-304433cd525c,DISK], DatanodeInfoWithStorage[127.0.0.1:40376,DS-cdca92de-2a21-4680-bff3-efc52c0fda82,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1480115759-172.17.0.12-1596024555402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46521,DS-0c966b69-e8ba-42da-bacd-693eca0120b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-0e5cfd41-69e5-43b6-a8ea-237adfb84293,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-138a2e12-2934-4b35-8ffa-3646bd39011e,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-cb8c2a32-7d37-44e1-bffd-dadc2e6208fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-a339914a-a22c-4d4f-8bed-812a91890812,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-ffb368eb-3c74-415e-9f81-1e7633e6167b,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-332318ce-ae9b-403a-814d-304433cd525c,DISK], DatanodeInfoWithStorage[127.0.0.1:40376,DS-cdca92de-2a21-4680-bff3-efc52c0fda82,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-405296432-172.17.0.12-1596024588757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46477,DS-5eb42004-6088-48b1-bc39-4f4c693afa82,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-fbf4de65-58fb-4859-ae26-686ed68cd9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-46d94a68-2cad-4a27-beee-9157471b19c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-dcba12c8-3333-4bc9-b994-56a2287567cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-8d2b1a41-c68b-4ca2-85a2-664866e59dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-5a58131f-0148-4336-9456-740f5fdaee65,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-a3fe52ae-2724-4154-887e-6d714dab704f,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-27327563-a756-41d4-b894-674a69ca3d83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-405296432-172.17.0.12-1596024588757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46477,DS-5eb42004-6088-48b1-bc39-4f4c693afa82,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-fbf4de65-58fb-4859-ae26-686ed68cd9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-46d94a68-2cad-4a27-beee-9157471b19c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-dcba12c8-3333-4bc9-b994-56a2287567cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-8d2b1a41-c68b-4ca2-85a2-664866e59dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-5a58131f-0148-4336-9456-740f5fdaee65,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-a3fe52ae-2724-4154-887e-6d714dab704f,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-27327563-a756-41d4-b894-674a69ca3d83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-667322326-172.17.0.12-1596024823143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37445,DS-b918dee7-20ca-438c-844e-fceea7e22b14,DISK], DatanodeInfoWithStorage[127.0.0.1:42742,DS-2590d04d-600d-4429-b674-768c1433f18d,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-c814fdda-6153-45e2-b812-68113ebfea62,DISK], DatanodeInfoWithStorage[127.0.0.1:40065,DS-ca0044a1-9a08-4fa3-97e5-5fee640b4c63,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-4167d01b-b519-4d3c-a1a1-bcc011c56a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-2569d738-2d0b-47be-b227-f4f34c61707f,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-8baa0ce0-6b4d-4e41-adaf-bc22326c58db,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-b435b19d-96df-4f9f-b8a4-86f8df968be0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-667322326-172.17.0.12-1596024823143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37445,DS-b918dee7-20ca-438c-844e-fceea7e22b14,DISK], DatanodeInfoWithStorage[127.0.0.1:42742,DS-2590d04d-600d-4429-b674-768c1433f18d,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-c814fdda-6153-45e2-b812-68113ebfea62,DISK], DatanodeInfoWithStorage[127.0.0.1:40065,DS-ca0044a1-9a08-4fa3-97e5-5fee640b4c63,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-4167d01b-b519-4d3c-a1a1-bcc011c56a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-2569d738-2d0b-47be-b227-f4f34c61707f,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-8baa0ce0-6b4d-4e41-adaf-bc22326c58db,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-b435b19d-96df-4f9f-b8a4-86f8df968be0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-692811531-172.17.0.12-1596025274303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38023,DS-00bfc6a4-10d9-474b-bc48-aedad5362a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-9b6c9aff-e56f-4199-ba4c-e7c23978ad74,DISK], DatanodeInfoWithStorage[127.0.0.1:34822,DS-a8fd24b8-c876-4828-a748-145d8d55e5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-61c0bd55-5a85-4bf1-a893-92bec8c2d9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37289,DS-449a5650-e558-49d5-9253-03c37ef8d7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-c759319f-a2e2-4468-9044-c396cf1c20b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-57bec326-1264-45ad-93a5-6b5ff8c244bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-f962cf97-3dc8-469f-85f6-08de2500cf9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-692811531-172.17.0.12-1596025274303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38023,DS-00bfc6a4-10d9-474b-bc48-aedad5362a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-9b6c9aff-e56f-4199-ba4c-e7c23978ad74,DISK], DatanodeInfoWithStorage[127.0.0.1:34822,DS-a8fd24b8-c876-4828-a748-145d8d55e5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-61c0bd55-5a85-4bf1-a893-92bec8c2d9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37289,DS-449a5650-e558-49d5-9253-03c37ef8d7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-c759319f-a2e2-4468-9044-c396cf1c20b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-57bec326-1264-45ad-93a5-6b5ff8c244bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-f962cf97-3dc8-469f-85f6-08de2500cf9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1172830753-172.17.0.12-1596025372423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41398,DS-4d6e4782-8ef3-4739-a827-3305818f2dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-3336d21a-1cd8-416c-b72f-9d19a406b6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-d857df8f-3c3a-4aac-8c44-4ed8913fa2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-1f936f45-47ae-47ad-b345-b01b04ab612a,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-c5eb6f21-7c7c-48a0-8e95-c9655b63ba8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40039,DS-eeace90b-397f-4d62-bc3c-34dd87b6dc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-6f27e2ec-13ba-42e0-b968-97bbd9d83a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-87186bc8-73e0-4fd2-8906-d8d3b3364a20,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1172830753-172.17.0.12-1596025372423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41398,DS-4d6e4782-8ef3-4739-a827-3305818f2dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-3336d21a-1cd8-416c-b72f-9d19a406b6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-d857df8f-3c3a-4aac-8c44-4ed8913fa2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-1f936f45-47ae-47ad-b345-b01b04ab612a,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-c5eb6f21-7c7c-48a0-8e95-c9655b63ba8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40039,DS-eeace90b-397f-4d62-bc3c-34dd87b6dc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-6f27e2ec-13ba-42e0-b968-97bbd9d83a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-87186bc8-73e0-4fd2-8906-d8d3b3364a20,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483740715-172.17.0.12-1596025547896:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39094,DS-aee5842c-af27-407b-9c00-5bd8ccee22ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-4dc9054a-ba83-4895-83a1-d0e719ba9775,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-c48c6547-f5c1-4240-b687-95bf255ccf46,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-339e5b0f-dc55-4d6c-9fbf-fc2cd53e19ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34467,DS-91f83e05-a8bb-4dd8-9104-f57c310b5efc,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-f6d73a7d-e4da-4b8d-975d-eeff3e3e04c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-dfaadd9a-176e-4bba-b363-0c49bc14324a,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-b9e8c905-9741-4f8e-8ef2-4dee7a5d1eb9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483740715-172.17.0.12-1596025547896:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39094,DS-aee5842c-af27-407b-9c00-5bd8ccee22ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-4dc9054a-ba83-4895-83a1-d0e719ba9775,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-c48c6547-f5c1-4240-b687-95bf255ccf46,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-339e5b0f-dc55-4d6c-9fbf-fc2cd53e19ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34467,DS-91f83e05-a8bb-4dd8-9104-f57c310b5efc,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-f6d73a7d-e4da-4b8d-975d-eeff3e3e04c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-dfaadd9a-176e-4bba-b363-0c49bc14324a,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-b9e8c905-9741-4f8e-8ef2-4dee7a5d1eb9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1322868417-172.17.0.12-1596025654119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38782,DS-d0aded31-75c5-4f45-a310-979b3b59ef0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46548,DS-143207b5-91b4-4652-82fb-cdae87d72205,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-280332c1-a7fd-4079-ba0c-d13216add510,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-2692c292-9d36-4d34-ac92-a1c7dcbafbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-1f1d403d-7e83-4d23-87dc-ebc5a1e8ce3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-cce25bdd-6930-4c28-8559-8b3f20da9108,DISK], DatanodeInfoWithStorage[127.0.0.1:37154,DS-f2baf112-e893-454e-8de0-70349c9db1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-eecb21ec-c3f0-44e3-891b-674f32235450,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1322868417-172.17.0.12-1596025654119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38782,DS-d0aded31-75c5-4f45-a310-979b3b59ef0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46548,DS-143207b5-91b4-4652-82fb-cdae87d72205,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-280332c1-a7fd-4079-ba0c-d13216add510,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-2692c292-9d36-4d34-ac92-a1c7dcbafbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-1f1d403d-7e83-4d23-87dc-ebc5a1e8ce3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-cce25bdd-6930-4c28-8559-8b3f20da9108,DISK], DatanodeInfoWithStorage[127.0.0.1:37154,DS-f2baf112-e893-454e-8de0-70349c9db1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-eecb21ec-c3f0-44e3-891b-674f32235450,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-356651774-172.17.0.12-1596025837587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33468,DS-f54a4d3e-4775-4c69-8429-1b1239b4e526,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-162cc08e-53e8-46e0-9fea-a26920e8da8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-ed7e5dd7-28ba-4b6b-8021-4764bb7245fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-1e99e293-6bdf-4af2-bc10-032019480c08,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-a3efa964-c461-4200-9417-49dcb3c8da0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-a1d87676-6019-44a5-98b7-a29c548bc3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40487,DS-930ff4c9-43dc-4cf9-a265-b1875e8f2b32,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-830575da-c521-4526-a82f-9c8ef2ae8491,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-356651774-172.17.0.12-1596025837587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33468,DS-f54a4d3e-4775-4c69-8429-1b1239b4e526,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-162cc08e-53e8-46e0-9fea-a26920e8da8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-ed7e5dd7-28ba-4b6b-8021-4764bb7245fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-1e99e293-6bdf-4af2-bc10-032019480c08,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-a3efa964-c461-4200-9417-49dcb3c8da0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-a1d87676-6019-44a5-98b7-a29c548bc3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40487,DS-930ff4c9-43dc-4cf9-a265-b1875e8f2b32,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-830575da-c521-4526-a82f-9c8ef2ae8491,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1190367243-172.17.0.12-1596026015946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41883,DS-1b87569c-16b0-450d-9cf0-6491b50f3d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-db1b842e-454f-4556-941f-a8bb18c9f2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40025,DS-9a81cedc-0b2c-412a-9900-ed987a0c0029,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-ec50e0c9-8ec9-4cc6-8b2f-2e012dcdc23c,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-64acdf5f-5b32-4b6a-8ab4-d337ead0d9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-eacccb11-6858-459d-b2a0-eb1be906095f,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-6aaeb50d-e11b-491f-bf57-747fc3b29d99,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-c557b041-36ac-4af1-95c3-8a73cb7f50d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1190367243-172.17.0.12-1596026015946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41883,DS-1b87569c-16b0-450d-9cf0-6491b50f3d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-db1b842e-454f-4556-941f-a8bb18c9f2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40025,DS-9a81cedc-0b2c-412a-9900-ed987a0c0029,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-ec50e0c9-8ec9-4cc6-8b2f-2e012dcdc23c,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-64acdf5f-5b32-4b6a-8ab4-d337ead0d9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-eacccb11-6858-459d-b2a0-eb1be906095f,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-6aaeb50d-e11b-491f-bf57-747fc3b29d99,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-c557b041-36ac-4af1-95c3-8a73cb7f50d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-219999481-172.17.0.12-1596026211942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35862,DS-df4d9af5-8c85-4019-b794-ea74ffb630d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-39d060a1-bc92-4ee1-b7c4-1b74e82f3b73,DISK], DatanodeInfoWithStorage[127.0.0.1:46594,DS-9042016c-f28b-40ad-855d-175a96ac60bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-7e281f7c-d9cb-4835-a14b-4c6f9dd002aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-655b9bcb-11bc-4fa4-9e3e-90e5de95428e,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-106ee1de-4123-459e-a6ad-c805d8491ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-5755a61a-5556-4c13-aaec-24b8372f4161,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-f2fa2453-2a42-41d9-bbe2-a2267c8e0d22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-219999481-172.17.0.12-1596026211942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35862,DS-df4d9af5-8c85-4019-b794-ea74ffb630d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-39d060a1-bc92-4ee1-b7c4-1b74e82f3b73,DISK], DatanodeInfoWithStorage[127.0.0.1:46594,DS-9042016c-f28b-40ad-855d-175a96ac60bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-7e281f7c-d9cb-4835-a14b-4c6f9dd002aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-655b9bcb-11bc-4fa4-9e3e-90e5de95428e,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-106ee1de-4123-459e-a6ad-c805d8491ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-5755a61a-5556-4c13-aaec-24b8372f4161,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-f2fa2453-2a42-41d9-bbe2-a2267c8e0d22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-699671728-172.17.0.12-1596026250141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46339,DS-f183c72a-fc47-4061-829f-970378c88a70,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-3db57f1f-61b6-44df-abc1-9dc1048ada41,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-6a1e27ec-7ac6-4b52-8ac6-abfe6c990a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40909,DS-9f433b7b-b644-4aa2-8984-93e4642ee98c,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-461818c4-cbe9-4a38-9878-fa4f594e6829,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-aa0a1579-accb-4464-90b1-a4035a03af90,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-b69cbe07-8d37-4b8f-9068-67d7fd567fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42960,DS-6263f601-1d7d-4a11-817d-5be2b78c7ed1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-699671728-172.17.0.12-1596026250141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46339,DS-f183c72a-fc47-4061-829f-970378c88a70,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-3db57f1f-61b6-44df-abc1-9dc1048ada41,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-6a1e27ec-7ac6-4b52-8ac6-abfe6c990a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40909,DS-9f433b7b-b644-4aa2-8984-93e4642ee98c,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-461818c4-cbe9-4a38-9878-fa4f594e6829,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-aa0a1579-accb-4464-90b1-a4035a03af90,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-b69cbe07-8d37-4b8f-9068-67d7fd567fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42960,DS-6263f601-1d7d-4a11-817d-5be2b78c7ed1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1753522262-172.17.0.12-1596026278045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35277,DS-3f3ff188-f2b8-43b9-b2ff-75b1b33c6090,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-a4bfd7c2-4f17-4e13-a709-9a7251e242af,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-38df9cdb-aeac-4157-954e-84fec401308f,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-9ee2e3e0-f668-45c4-bf4c-61b88f57490c,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-1fb0572e-db1a-499c-ae83-aaa94407ceb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35857,DS-5899a747-6aa9-4cf1-b5d3-8c034b71b8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-fd41999f-a21b-40a8-8957-a31ad55c9c31,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-f80e583e-eb93-4ee4-a74c-a4d9038f49a5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1753522262-172.17.0.12-1596026278045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35277,DS-3f3ff188-f2b8-43b9-b2ff-75b1b33c6090,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-a4bfd7c2-4f17-4e13-a709-9a7251e242af,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-38df9cdb-aeac-4157-954e-84fec401308f,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-9ee2e3e0-f668-45c4-bf4c-61b88f57490c,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-1fb0572e-db1a-499c-ae83-aaa94407ceb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35857,DS-5899a747-6aa9-4cf1-b5d3-8c034b71b8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-fd41999f-a21b-40a8-8957-a31ad55c9c31,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-f80e583e-eb93-4ee4-a74c-a4d9038f49a5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-268290847-172.17.0.12-1596026311808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37718,DS-16146458-d9f8-40f7-b7db-3032e7078890,DISK], DatanodeInfoWithStorage[127.0.0.1:43506,DS-137077bd-524d-4e1a-9649-0b54918b4602,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-50b16a16-d929-4fe1-9087-f3329257bd81,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-efb346e7-bf8f-4a7a-b08e-2493a23876f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-e37b5930-fd87-4fc8-80a1-abbd9279f4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-ba572b91-9e11-4dd0-ac4a-56b84d5b6345,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-fbc9ea24-5b50-4a39-b2b5-b67d79ba0cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-f002d49f-8390-49b3-81ff-9db3a996e00b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-268290847-172.17.0.12-1596026311808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37718,DS-16146458-d9f8-40f7-b7db-3032e7078890,DISK], DatanodeInfoWithStorage[127.0.0.1:43506,DS-137077bd-524d-4e1a-9649-0b54918b4602,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-50b16a16-d929-4fe1-9087-f3329257bd81,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-efb346e7-bf8f-4a7a-b08e-2493a23876f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-e37b5930-fd87-4fc8-80a1-abbd9279f4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-ba572b91-9e11-4dd0-ac4a-56b84d5b6345,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-fbc9ea24-5b50-4a39-b2b5-b67d79ba0cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-f002d49f-8390-49b3-81ff-9db3a996e00b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712698972-172.17.0.12-1596026506912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37184,DS-8b23da0c-5dcb-48b0-8a9f-5b57ff5d23f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-6052754e-9cfc-4395-a275-3f34baba2b33,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-77c88463-1309-474a-be9c-ca9a55a4896f,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-1d91b311-f90d-4db5-ba60-6f1ce87603a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-3bfe0545-abee-40bc-902d-53dd85ff340b,DISK], DatanodeInfoWithStorage[127.0.0.1:34804,DS-0c240e6d-2c84-47f7-9435-047711d18421,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-85093eff-2ed8-471f-aa77-065443f8317f,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-7a3b4c26-264f-4fb3-a012-a8f63762e3fc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712698972-172.17.0.12-1596026506912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37184,DS-8b23da0c-5dcb-48b0-8a9f-5b57ff5d23f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-6052754e-9cfc-4395-a275-3f34baba2b33,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-77c88463-1309-474a-be9c-ca9a55a4896f,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-1d91b311-f90d-4db5-ba60-6f1ce87603a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-3bfe0545-abee-40bc-902d-53dd85ff340b,DISK], DatanodeInfoWithStorage[127.0.0.1:34804,DS-0c240e6d-2c84-47f7-9435-047711d18421,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-85093eff-2ed8-471f-aa77-065443f8317f,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-7a3b4c26-264f-4fb3-a012-a8f63762e3fc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-536851396-172.17.0.12-1596027196586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46586,DS-b242f6fd-19a5-4e58-adfd-5f8a173ce126,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-f8d87161-8d76-494c-8f67-0c31b1c6efdb,DISK], DatanodeInfoWithStorage[127.0.0.1:33142,DS-4e7cff1e-afff-4ac4-bcd9-e4d80fcdd14d,DISK], DatanodeInfoWithStorage[127.0.0.1:38555,DS-fb984e64-d891-4d99-b0f8-3dc8e255f852,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-5f940883-e2cb-4607-bf37-77c2f99f9414,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-25ec87b5-59f6-40e6-8e68-1c18b702b435,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-359622c8-a765-459e-b068-cf6305ccd8df,DISK], DatanodeInfoWithStorage[127.0.0.1:44668,DS-e93a30a6-f470-4543-ba05-a800cb1796ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-536851396-172.17.0.12-1596027196586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46586,DS-b242f6fd-19a5-4e58-adfd-5f8a173ce126,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-f8d87161-8d76-494c-8f67-0c31b1c6efdb,DISK], DatanodeInfoWithStorage[127.0.0.1:33142,DS-4e7cff1e-afff-4ac4-bcd9-e4d80fcdd14d,DISK], DatanodeInfoWithStorage[127.0.0.1:38555,DS-fb984e64-d891-4d99-b0f8-3dc8e255f852,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-5f940883-e2cb-4607-bf37-77c2f99f9414,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-25ec87b5-59f6-40e6-8e68-1c18b702b435,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-359622c8-a765-459e-b068-cf6305ccd8df,DISK], DatanodeInfoWithStorage[127.0.0.1:44668,DS-e93a30a6-f470-4543-ba05-a800cb1796ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-496220694-172.17.0.12-1596027291790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34632,DS-8c9254eb-cf34-4c78-a456-b3bae01451bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-180e98c9-a7a3-415e-84ae-b8024e20c3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-99c0c578-ffe8-4de5-9c79-5b2d17dc547f,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-3b551235-d3a8-4991-9ee2-32cd0f0bd5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-6b421876-1219-434a-b6a1-ddc4ad17d60d,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-0ea404a6-d3a4-4036-ab69-2dd535b53f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-7009c8fa-15c8-4088-b898-308a998922b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-83ed229f-dc5f-4dda-be71-bdc85d3f3159,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-496220694-172.17.0.12-1596027291790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34632,DS-8c9254eb-cf34-4c78-a456-b3bae01451bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-180e98c9-a7a3-415e-84ae-b8024e20c3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-99c0c578-ffe8-4de5-9c79-5b2d17dc547f,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-3b551235-d3a8-4991-9ee2-32cd0f0bd5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-6b421876-1219-434a-b6a1-ddc4ad17d60d,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-0ea404a6-d3a4-4036-ab69-2dd535b53f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-7009c8fa-15c8-4088-b898-308a998922b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-83ed229f-dc5f-4dda-be71-bdc85d3f3159,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-925758989-172.17.0.12-1596027325301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42856,DS-8bccd4da-4bf5-43ab-be28-42507027edf6,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-06b1b8c2-8f87-45b3-8e44-9b95fea45703,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-a6fb895e-f432-4b38-807e-ad33779389a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36671,DS-05b5ad97-fb44-4a4e-8500-313daf13a38d,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-728c0546-20e6-4b12-823d-2e5e50ea5e51,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-1e96bf9a-6750-4b91-8429-2a7fdcd9666f,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-aa875561-120b-4ac2-bb21-e805e4e77828,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-6c2e220b-04f0-4f9b-ad6d-e259fb2ddb36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-925758989-172.17.0.12-1596027325301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42856,DS-8bccd4da-4bf5-43ab-be28-42507027edf6,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-06b1b8c2-8f87-45b3-8e44-9b95fea45703,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-a6fb895e-f432-4b38-807e-ad33779389a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36671,DS-05b5ad97-fb44-4a4e-8500-313daf13a38d,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-728c0546-20e6-4b12-823d-2e5e50ea5e51,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-1e96bf9a-6750-4b91-8429-2a7fdcd9666f,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-aa875561-120b-4ac2-bb21-e805e4e77828,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-6c2e220b-04f0-4f9b-ad6d-e259fb2ddb36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-933786946-172.17.0.12-1596027360411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33327,DS-f600aa12-b900-443a-a20e-f2b2579e1832,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-abfe3fa7-d74a-484e-9337-d3c371cfde88,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-de381de5-077c-4beb-a725-b730f5b08c34,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-3170a8f3-6812-4f5c-8096-7a65b93f3fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-df4af48c-5af2-4061-9140-97238886b982,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-15c90967-f6eb-4e87-803f-a6562beb1ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-7c0639f6-fd55-4aca-bca6-bd4903049ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-27a865de-2cbd-4e68-8a81-48c5722b5196,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-933786946-172.17.0.12-1596027360411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33327,DS-f600aa12-b900-443a-a20e-f2b2579e1832,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-abfe3fa7-d74a-484e-9337-d3c371cfde88,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-de381de5-077c-4beb-a725-b730f5b08c34,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-3170a8f3-6812-4f5c-8096-7a65b93f3fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-df4af48c-5af2-4061-9140-97238886b982,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-15c90967-f6eb-4e87-803f-a6562beb1ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-7c0639f6-fd55-4aca-bca6-bd4903049ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-27a865de-2cbd-4e68-8a81-48c5722b5196,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1357146230-172.17.0.12-1596027498905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43424,DS-ec783649-c917-4c38-887d-1d15da873fac,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-b0f847f5-32fe-4c34-93d6-a4f5e48b1a69,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-c27a1fbf-64d2-4c6d-912c-8ae7eefef3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-53ad799f-b53c-42ca-88ba-053c0d073c64,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-2cfffbd8-b375-4f33-9df1-31271e9636ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38555,DS-042d3077-2291-46e1-8877-27a9ce7cca69,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-d075a80c-2c9e-48f0-98c0-27a02e892cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-77225dc7-e30d-4d41-9b4a-7c443ee74b13,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1357146230-172.17.0.12-1596027498905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43424,DS-ec783649-c917-4c38-887d-1d15da873fac,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-b0f847f5-32fe-4c34-93d6-a4f5e48b1a69,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-c27a1fbf-64d2-4c6d-912c-8ae7eefef3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-53ad799f-b53c-42ca-88ba-053c0d073c64,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-2cfffbd8-b375-4f33-9df1-31271e9636ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38555,DS-042d3077-2291-46e1-8877-27a9ce7cca69,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-d075a80c-2c9e-48f0-98c0-27a02e892cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-77225dc7-e30d-4d41-9b4a-7c443ee74b13,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1197645137-172.17.0.12-1596027535468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34416,DS-2cde288f-b9d0-4039-8ae4-7bb7dd7dd4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-6fafc56a-46ac-4e75-b2f5-6126c84f13c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-7c47129d-418f-4865-afe0-739c80714348,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-9c1d393b-2f8e-492f-ba58-b37ae36d64fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-e371a2d6-ea75-4888-9726-70d5608db655,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-4e00dc46-ee0c-401f-aa2f-5ab41ed950b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-7760870a-958d-4ccf-bf21-fc24d45ed2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38925,DS-06ef54f6-fa08-4087-a574-643599a7e268,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1197645137-172.17.0.12-1596027535468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34416,DS-2cde288f-b9d0-4039-8ae4-7bb7dd7dd4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-6fafc56a-46ac-4e75-b2f5-6126c84f13c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-7c47129d-418f-4865-afe0-739c80714348,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-9c1d393b-2f8e-492f-ba58-b37ae36d64fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-e371a2d6-ea75-4888-9726-70d5608db655,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-4e00dc46-ee0c-401f-aa2f-5ab41ed950b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-7760870a-958d-4ccf-bf21-fc24d45ed2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38925,DS-06ef54f6-fa08-4087-a574-643599a7e268,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1455621478-172.17.0.12-1596027569724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44869,DS-f607f9aa-7dd8-499b-be9a-f10fc6e62459,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-a09df1fb-8a6c-4971-ba3f-ae51387c41ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41508,DS-3f27f51b-c26d-46c2-acb3-95ea82047a45,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-8b0d73b3-da81-4a7d-990c-9a219b4bbc18,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-a9f6f566-3947-4554-8641-556c5cc7c20b,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-93efb532-9374-49d9-b6c8-4e0ea6a74da1,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-83d809d0-8684-4a8b-bc90-8fb56b6305c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-74046001-0938-47dc-832a-a7ff839b50af,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1455621478-172.17.0.12-1596027569724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44869,DS-f607f9aa-7dd8-499b-be9a-f10fc6e62459,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-a09df1fb-8a6c-4971-ba3f-ae51387c41ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41508,DS-3f27f51b-c26d-46c2-acb3-95ea82047a45,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-8b0d73b3-da81-4a7d-990c-9a219b4bbc18,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-a9f6f566-3947-4554-8641-556c5cc7c20b,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-93efb532-9374-49d9-b6c8-4e0ea6a74da1,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-83d809d0-8684-4a8b-bc90-8fb56b6305c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-74046001-0938-47dc-832a-a7ff839b50af,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1672444845-172.17.0.12-1596027957669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37246,DS-ee281dd3-541e-4daa-8697-03b3d13bf4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-f935b138-7957-4477-ad9d-a0b53cb75ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:33210,DS-c6d75fa0-cd60-4657-9ce1-58692030c8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37732,DS-a5c03792-d29e-48b1-9cdf-0dc4a8c2e412,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-6dc9af38-5f1e-4819-9385-5360f10afc92,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-599a81f4-f3cf-4a5f-80d8-579b37cc5d35,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-2a676583-01f2-44b5-a107-4cd1690aca79,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-025ca70c-fdfc-46d2-81bc-a87bd49392ad,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1672444845-172.17.0.12-1596027957669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37246,DS-ee281dd3-541e-4daa-8697-03b3d13bf4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-f935b138-7957-4477-ad9d-a0b53cb75ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:33210,DS-c6d75fa0-cd60-4657-9ce1-58692030c8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37732,DS-a5c03792-d29e-48b1-9cdf-0dc4a8c2e412,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-6dc9af38-5f1e-4819-9385-5360f10afc92,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-599a81f4-f3cf-4a5f-80d8-579b37cc5d35,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-2a676583-01f2-44b5-a107-4cd1690aca79,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-025ca70c-fdfc-46d2-81bc-a87bd49392ad,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-811050032-172.17.0.12-1596028065129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34486,DS-d4d03d7c-ea6a-4e68-b531-ce10b37fba8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-79afe248-ac51-42e7-9398-b3db1f38784e,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-74d8e275-bd45-44bc-bce5-5509dbffa74e,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-ceb2f3a0-f10e-447b-9159-3640913ec493,DISK], DatanodeInfoWithStorage[127.0.0.1:41694,DS-979fc35d-54e9-4bb9-a2f7-613dbbbba7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-671e8dc4-18e3-49e6-a411-427f3567de0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-d62af094-1e3a-42fc-87d9-c10ab87ed21b,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-a8aaa492-2505-4061-9f64-010fc5545170,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-811050032-172.17.0.12-1596028065129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34486,DS-d4d03d7c-ea6a-4e68-b531-ce10b37fba8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-79afe248-ac51-42e7-9398-b3db1f38784e,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-74d8e275-bd45-44bc-bce5-5509dbffa74e,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-ceb2f3a0-f10e-447b-9159-3640913ec493,DISK], DatanodeInfoWithStorage[127.0.0.1:41694,DS-979fc35d-54e9-4bb9-a2f7-613dbbbba7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-671e8dc4-18e3-49e6-a411-427f3567de0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-d62af094-1e3a-42fc-87d9-c10ab87ed21b,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-a8aaa492-2505-4061-9f64-010fc5545170,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1990586819-172.17.0.12-1596028098142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38237,DS-da4ee44c-ca69-4c93-9ae7-cffc008c835a,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-587b77b5-cc2e-47a1-a40c-6e4bfcbb2195,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-b11d8f9b-3bce-41ec-9ece-54b8c17dfb0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-9f33b5e8-db50-4dd5-bb6f-c6d27c7cbd19,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-cc393824-63a6-44d8-a704-1152a8b3552c,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-2875b528-93ac-4555-a914-c5f449170228,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-5bc98eaa-7c42-4389-b947-1dd526c358e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-30732522-3555-4dd6-a7da-ec641e600c07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1990586819-172.17.0.12-1596028098142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38237,DS-da4ee44c-ca69-4c93-9ae7-cffc008c835a,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-587b77b5-cc2e-47a1-a40c-6e4bfcbb2195,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-b11d8f9b-3bce-41ec-9ece-54b8c17dfb0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-9f33b5e8-db50-4dd5-bb6f-c6d27c7cbd19,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-cc393824-63a6-44d8-a704-1152a8b3552c,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-2875b528-93ac-4555-a914-c5f449170228,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-5bc98eaa-7c42-4389-b947-1dd526c358e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-30732522-3555-4dd6-a7da-ec641e600c07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2133352861-172.17.0.12-1596028437839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43813,DS-fbe34a5f-b8d7-471c-9c4c-9131a584652f,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-07701033-1fd6-4acb-9949-a9f635b88454,DISK], DatanodeInfoWithStorage[127.0.0.1:45830,DS-c91d3b74-32c9-4511-90b6-0808752531a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37480,DS-13d9dfec-f759-4204-9a02-c25ffa9a7667,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-550b2f0e-1aa1-408a-9902-304b3effe700,DISK], DatanodeInfoWithStorage[127.0.0.1:41606,DS-672e8464-5362-458e-93bd-6986f236d133,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-adcff70c-fc7d-4a54-9ff1-d4e5dac48ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-704292b2-a955-4606-aee2-f25e7becbed6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2133352861-172.17.0.12-1596028437839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43813,DS-fbe34a5f-b8d7-471c-9c4c-9131a584652f,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-07701033-1fd6-4acb-9949-a9f635b88454,DISK], DatanodeInfoWithStorage[127.0.0.1:45830,DS-c91d3b74-32c9-4511-90b6-0808752531a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37480,DS-13d9dfec-f759-4204-9a02-c25ffa9a7667,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-550b2f0e-1aa1-408a-9902-304b3effe700,DISK], DatanodeInfoWithStorage[127.0.0.1:41606,DS-672e8464-5362-458e-93bd-6986f236d133,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-adcff70c-fc7d-4a54-9ff1-d4e5dac48ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-704292b2-a955-4606-aee2-f25e7becbed6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2032682045-172.17.0.12-1596028502780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45004,DS-624ada10-cf75-4be3-8b59-e99beb186f94,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-7a8f826c-6c30-4d52-b9fd-716a5d815f14,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-737a9ec5-bf70-4335-b0f2-9fcd544858bb,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-f1cdac99-78fe-4394-a399-d909653df54a,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-3d0a4c0e-4250-44b0-84cd-e1bd74191bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-562936b7-3e6b-4d1c-b66e-2eeb0613754f,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-9d777e59-7fb4-4b94-9c46-6679230771f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43598,DS-eae1fa5b-45a7-4905-b1d9-514baa13c3e4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2032682045-172.17.0.12-1596028502780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45004,DS-624ada10-cf75-4be3-8b59-e99beb186f94,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-7a8f826c-6c30-4d52-b9fd-716a5d815f14,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-737a9ec5-bf70-4335-b0f2-9fcd544858bb,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-f1cdac99-78fe-4394-a399-d909653df54a,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-3d0a4c0e-4250-44b0-84cd-e1bd74191bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-562936b7-3e6b-4d1c-b66e-2eeb0613754f,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-9d777e59-7fb4-4b94-9c46-6679230771f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43598,DS-eae1fa5b-45a7-4905-b1d9-514baa13c3e4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-744049708-172.17.0.12-1596028642464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40830,DS-d8ebf0a2-cda4-4e05-a9b9-02e92b55ad32,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-1c2ccedc-d2f1-4806-9918-f0bccb12c247,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-38dc4f8d-27d1-487d-8e29-874216439dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-9b60ea1c-8981-4f73-827a-c46ec450b316,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-bf09ecc8-dd06-401f-b161-c53e4cad92e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-ad928847-2223-4f20-a01c-95dea35f743d,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-1b6e14ee-ea9a-447e-8c67-0a57a4060702,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-549de405-c3e7-4951-a0f6-a16b80d06662,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-744049708-172.17.0.12-1596028642464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40830,DS-d8ebf0a2-cda4-4e05-a9b9-02e92b55ad32,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-1c2ccedc-d2f1-4806-9918-f0bccb12c247,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-38dc4f8d-27d1-487d-8e29-874216439dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-9b60ea1c-8981-4f73-827a-c46ec450b316,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-bf09ecc8-dd06-401f-b161-c53e4cad92e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-ad928847-2223-4f20-a01c-95dea35f743d,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-1b6e14ee-ea9a-447e-8c67-0a57a4060702,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-549de405-c3e7-4951-a0f6-a16b80d06662,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1334213980-172.17.0.12-1596028658858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45444,DS-03052e39-3034-4929-883d-37b753293c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-e18253f3-83cf-4252-b9d6-2f489703a497,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-fba372f7-fe97-47c5-9c38-30d44ab04d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-23c42378-24ac-4400-8b76-769ed9e6e381,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-dc88c85b-3b88-4318-ba62-d78068133f00,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-5c5c93d5-b04d-49f1-a592-a12d1b761e89,DISK], DatanodeInfoWithStorage[127.0.0.1:33339,DS-b0001a9f-d036-488e-b77c-833a7f5ce8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46529,DS-9cccab34-b67d-4ff8-af2e-f5e2c745d4bd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1334213980-172.17.0.12-1596028658858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45444,DS-03052e39-3034-4929-883d-37b753293c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-e18253f3-83cf-4252-b9d6-2f489703a497,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-fba372f7-fe97-47c5-9c38-30d44ab04d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-23c42378-24ac-4400-8b76-769ed9e6e381,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-dc88c85b-3b88-4318-ba62-d78068133f00,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-5c5c93d5-b04d-49f1-a592-a12d1b761e89,DISK], DatanodeInfoWithStorage[127.0.0.1:33339,DS-b0001a9f-d036-488e-b77c-833a7f5ce8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46529,DS-9cccab34-b67d-4ff8-af2e-f5e2c745d4bd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-302096385-172.17.0.12-1596028787916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36697,DS-6ea8e9a1-2ed8-4da6-9326-28194ff66b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-9551ea0e-e276-44eb-b20e-7fedcfedc2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-79e01b95-4ef8-41e1-9a90-e813cab015a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-9730ba17-a4c0-4e37-b895-fe9587e1ce4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-82ee4751-4d77-424f-bdae-9d48285d94b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-c7209d86-f74a-4f0d-ba3d-5d0ed6a0d579,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-c0e575f1-dcce-4735-9be8-57c119c023cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-dc97436c-f500-44c4-ae19-c6c0863fb965,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-302096385-172.17.0.12-1596028787916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36697,DS-6ea8e9a1-2ed8-4da6-9326-28194ff66b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-9551ea0e-e276-44eb-b20e-7fedcfedc2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-79e01b95-4ef8-41e1-9a90-e813cab015a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-9730ba17-a4c0-4e37-b895-fe9587e1ce4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-82ee4751-4d77-424f-bdae-9d48285d94b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-c7209d86-f74a-4f0d-ba3d-5d0ed6a0d579,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-c0e575f1-dcce-4735-9be8-57c119c023cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-dc97436c-f500-44c4-ae19-c6c0863fb965,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1864357001-172.17.0.12-1596028803426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46530,DS-a511514b-243d-40da-be9d-5204ba886088,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-9ebf65a7-cf93-466f-ac15-12934b5cba99,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-c129d16c-22fa-41da-a0a1-c6ec4ab04e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42168,DS-77d14add-b37f-454d-9719-de22d17e30f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-f2198804-3467-4f0c-b784-97586e075cac,DISK], DatanodeInfoWithStorage[127.0.0.1:40251,DS-c8f08650-02c1-48e6-8262-76143984778a,DISK], DatanodeInfoWithStorage[127.0.0.1:33394,DS-3558749e-15c9-4343-9676-79dbd7acdf15,DISK], DatanodeInfoWithStorage[127.0.0.1:34692,DS-c8e4ba51-bd11-4bdb-bd24-c2372a2aa318,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1864357001-172.17.0.12-1596028803426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46530,DS-a511514b-243d-40da-be9d-5204ba886088,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-9ebf65a7-cf93-466f-ac15-12934b5cba99,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-c129d16c-22fa-41da-a0a1-c6ec4ab04e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42168,DS-77d14add-b37f-454d-9719-de22d17e30f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-f2198804-3467-4f0c-b784-97586e075cac,DISK], DatanodeInfoWithStorage[127.0.0.1:40251,DS-c8f08650-02c1-48e6-8262-76143984778a,DISK], DatanodeInfoWithStorage[127.0.0.1:33394,DS-3558749e-15c9-4343-9676-79dbd7acdf15,DISK], DatanodeInfoWithStorage[127.0.0.1:34692,DS-c8e4ba51-bd11-4bdb-bd24-c2372a2aa318,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-527862177-172.17.0.12-1596028851543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37181,DS-53aa419d-73aa-415c-a52f-cc66d73c0a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-4dcbc629-4b01-4925-9c74-aa74663e2eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-1f5c8140-115b-4bcf-9ced-97c2ca086576,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-9f3c3d55-0d76-420e-a03c-83d993033a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-3c45dd81-8fed-4902-820d-2a8f52ed6bff,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-12d87f04-209d-4616-ab7f-9c7093fe96e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-35fd2d4c-4a55-4246-8f45-c798972f3ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-a92e562a-420b-442c-ad79-1d6f0105c0f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-527862177-172.17.0.12-1596028851543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37181,DS-53aa419d-73aa-415c-a52f-cc66d73c0a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-4dcbc629-4b01-4925-9c74-aa74663e2eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-1f5c8140-115b-4bcf-9ced-97c2ca086576,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-9f3c3d55-0d76-420e-a03c-83d993033a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-3c45dd81-8fed-4902-820d-2a8f52ed6bff,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-12d87f04-209d-4616-ab7f-9c7093fe96e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-35fd2d4c-4a55-4246-8f45-c798972f3ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-a92e562a-420b-442c-ad79-1d6f0105c0f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 18 out of 50
result: false positive !!!
Total execution time in seconds : 4672
