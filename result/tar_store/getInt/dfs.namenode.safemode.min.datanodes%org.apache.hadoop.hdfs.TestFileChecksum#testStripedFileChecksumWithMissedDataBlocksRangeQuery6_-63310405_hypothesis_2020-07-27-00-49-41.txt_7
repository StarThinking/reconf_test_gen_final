reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1179706353-172.17.0.9-1595811030267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34003,DS-8d943f9b-02c4-4dfd-a337-c3beaae55603,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-3535d155-312a-43bb-83a2-61c45f8f00bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-068440c1-407c-48b8-8d2b-371aaa3a8a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-468849aa-f69e-40b0-8a39-d004cdfe7254,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-3a73b10f-8303-4124-8258-b21c923f7806,DISK], DatanodeInfoWithStorage[127.0.0.1:41952,DS-36d539ef-07d9-455d-97c2-21a8ff8638f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-9d8b752e-3f8b-4b41-aeee-b6405889fb52,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-68cd0ce9-fdbf-44a9-aaef-164dc56a0b0e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1179706353-172.17.0.9-1595811030267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34003,DS-8d943f9b-02c4-4dfd-a337-c3beaae55603,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-3535d155-312a-43bb-83a2-61c45f8f00bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-068440c1-407c-48b8-8d2b-371aaa3a8a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-468849aa-f69e-40b0-8a39-d004cdfe7254,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-3a73b10f-8303-4124-8258-b21c923f7806,DISK], DatanodeInfoWithStorage[127.0.0.1:41952,DS-36d539ef-07d9-455d-97c2-21a8ff8638f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-9d8b752e-3f8b-4b41-aeee-b6405889fb52,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-68cd0ce9-fdbf-44a9-aaef-164dc56a0b0e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-197519088-172.17.0.9-1595811240717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36379,DS-e4d51194-84fe-48bb-9ee3-473d03a3bcf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45199,DS-9fe0fe25-0d01-4123-88a2-5ca3c8eda49b,DISK], DatanodeInfoWithStorage[127.0.0.1:39204,DS-0d4885f4-7a4a-4e31-b07d-86d97fcbef5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-c50c2018-1627-49e2-81e9-6c4161e7c5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38851,DS-2b2d51b2-af38-418c-aa8f-cf6ff996b93e,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-6726e01e-76e8-404d-9992-8308d93a69d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-ed4122ba-ef21-4751-8bba-cf50c3ac9653,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-4e5a376e-0504-44fb-8415-f6b8b7501cf8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-197519088-172.17.0.9-1595811240717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36379,DS-e4d51194-84fe-48bb-9ee3-473d03a3bcf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45199,DS-9fe0fe25-0d01-4123-88a2-5ca3c8eda49b,DISK], DatanodeInfoWithStorage[127.0.0.1:39204,DS-0d4885f4-7a4a-4e31-b07d-86d97fcbef5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-c50c2018-1627-49e2-81e9-6c4161e7c5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38851,DS-2b2d51b2-af38-418c-aa8f-cf6ff996b93e,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-6726e01e-76e8-404d-9992-8308d93a69d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-ed4122ba-ef21-4751-8bba-cf50c3ac9653,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-4e5a376e-0504-44fb-8415-f6b8b7501cf8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1627750848-172.17.0.9-1595811493076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46111,DS-e83c9ee0-5b76-47cd-9e40-b4602f133b41,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-3d44badc-77a5-418c-b709-61b7a8e98c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-a159cee3-fb3b-4fdb-a30a-0db726f05365,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-631b3ae3-12a4-4ba1-9ba0-a9fb4c3e7037,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-1f6bc299-0dc2-470b-a0bd-822d32e42fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-3d7312b0-5b86-4619-92e5-6bef2df19b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-fd33983d-bfcc-4869-88e7-418584d43b86,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-370a2859-644e-492e-891f-35b0b8cd2baa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1627750848-172.17.0.9-1595811493076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46111,DS-e83c9ee0-5b76-47cd-9e40-b4602f133b41,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-3d44badc-77a5-418c-b709-61b7a8e98c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-a159cee3-fb3b-4fdb-a30a-0db726f05365,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-631b3ae3-12a4-4ba1-9ba0-a9fb4c3e7037,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-1f6bc299-0dc2-470b-a0bd-822d32e42fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-3d7312b0-5b86-4619-92e5-6bef2df19b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-fd33983d-bfcc-4869-88e7-418584d43b86,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-370a2859-644e-492e-891f-35b0b8cd2baa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1669981649-172.17.0.9-1595811600192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38944,DS-2fec0daa-90b3-4f7d-8131-0281f264eacd,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-156d8a3d-acf3-4d15-8eb6-9c6fdb161880,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-3cf27199-ed45-4a26-bb53-1d059c2008f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40884,DS-dfbb3d37-0264-4297-bbb5-01364322bf54,DISK], DatanodeInfoWithStorage[127.0.0.1:44243,DS-61ad720c-6250-40f4-b6d6-d490da66c457,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-d567188c-fe9e-4d85-b144-1db4157f0121,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-2c29040b-6533-4a4b-acf4-f0e72d9519ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-952ba0f8-2bd7-4d40-a9d5-d0e348a3a799,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1669981649-172.17.0.9-1595811600192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38944,DS-2fec0daa-90b3-4f7d-8131-0281f264eacd,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-156d8a3d-acf3-4d15-8eb6-9c6fdb161880,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-3cf27199-ed45-4a26-bb53-1d059c2008f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40884,DS-dfbb3d37-0264-4297-bbb5-01364322bf54,DISK], DatanodeInfoWithStorage[127.0.0.1:44243,DS-61ad720c-6250-40f4-b6d6-d490da66c457,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-d567188c-fe9e-4d85-b144-1db4157f0121,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-2c29040b-6533-4a4b-acf4-f0e72d9519ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-952ba0f8-2bd7-4d40-a9d5-d0e348a3a799,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1504020805-172.17.0.9-1595811699777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35020,DS-d1014912-d3a3-4836-8679-c9991a9bee87,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-c9b022ba-8fa1-48b8-90c6-0498b3d6b09f,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-7e0e4faf-e153-4ec4-be86-0a9014eb4b16,DISK], DatanodeInfoWithStorage[127.0.0.1:45831,DS-3011a0e9-3f3d-400e-aa09-b51efceb980b,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-c704fc74-61f5-4312-a9e1-28383bab00aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-215d3fb3-50bc-4712-b6a1-53d250dc4451,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-18d190fe-ad0e-4ecc-bb60-30c982341e52,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-13704750-2c52-4f8d-9b44-82b2ba158ac3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1504020805-172.17.0.9-1595811699777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35020,DS-d1014912-d3a3-4836-8679-c9991a9bee87,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-c9b022ba-8fa1-48b8-90c6-0498b3d6b09f,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-7e0e4faf-e153-4ec4-be86-0a9014eb4b16,DISK], DatanodeInfoWithStorage[127.0.0.1:45831,DS-3011a0e9-3f3d-400e-aa09-b51efceb980b,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-c704fc74-61f5-4312-a9e1-28383bab00aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-215d3fb3-50bc-4712-b6a1-53d250dc4451,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-18d190fe-ad0e-4ecc-bb60-30c982341e52,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-13704750-2c52-4f8d-9b44-82b2ba158ac3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1929074998-172.17.0.9-1595811924550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39916,DS-274ef457-117e-4b75-a39b-627591b7112f,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-78190d4d-6434-49ec-af5e-377c3629111f,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-96eb273d-a40c-420c-93a2-8e41f92f3040,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-d139111a-1a0a-473d-807f-d316ccd4c1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-9559be1b-0e80-4e31-be9e-609ffd2165a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-3be81fcb-0357-4d57-bbaa-0df2df29704f,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-4ee814be-4f96-48ec-a2f2-2a52e7b47c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-3c586239-cbc7-4cb1-8aed-5cd494431159,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1929074998-172.17.0.9-1595811924550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39916,DS-274ef457-117e-4b75-a39b-627591b7112f,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-78190d4d-6434-49ec-af5e-377c3629111f,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-96eb273d-a40c-420c-93a2-8e41f92f3040,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-d139111a-1a0a-473d-807f-d316ccd4c1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-9559be1b-0e80-4e31-be9e-609ffd2165a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-3be81fcb-0357-4d57-bbaa-0df2df29704f,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-4ee814be-4f96-48ec-a2f2-2a52e7b47c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-3c586239-cbc7-4cb1-8aed-5cd494431159,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1934956442-172.17.0.9-1595811986591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42049,DS-53da03b9-77bc-479b-ac3c-9320d6270b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-1ff25180-6dd0-4525-ac61-451a037bea4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-8128d8a8-4ef7-4bd4-ba50-c8c7e5a8baab,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-78703f28-d710-42b3-9d65-9b2f82bb7530,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-2ea4e5fd-d236-47e4-bdbc-ab71cee5bb2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38243,DS-b71f55e6-9c71-4e06-9fc8-5017634e222c,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-d9dd51e7-7918-4be6-a35c-9980c3a9fca2,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-df84c773-3a35-4e43-97e0-64d1bd41be73,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1934956442-172.17.0.9-1595811986591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42049,DS-53da03b9-77bc-479b-ac3c-9320d6270b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-1ff25180-6dd0-4525-ac61-451a037bea4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-8128d8a8-4ef7-4bd4-ba50-c8c7e5a8baab,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-78703f28-d710-42b3-9d65-9b2f82bb7530,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-2ea4e5fd-d236-47e4-bdbc-ab71cee5bb2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38243,DS-b71f55e6-9c71-4e06-9fc8-5017634e222c,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-d9dd51e7-7918-4be6-a35c-9980c3a9fca2,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-df84c773-3a35-4e43-97e0-64d1bd41be73,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800423863-172.17.0.9-1595812390573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41432,DS-b24ecc7d-0221-43d0-b9c5-5459256c1d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-746cf526-9933-433b-a65f-d44f745840aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-2b70e2ca-e342-4559-a87c-d7ac0424703f,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-72eecf0b-1ec1-42fd-b633-cd3ec9f53f25,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-d051df85-aabf-4176-90b2-caf02db15fca,DISK], DatanodeInfoWithStorage[127.0.0.1:38794,DS-9122d042-3e77-4851-8d14-e0e85a56b542,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-4db39621-b2d1-4284-bdbd-cef1cc56946a,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-bf0aa1c1-39d7-478b-a138-197cdc47f0f9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800423863-172.17.0.9-1595812390573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41432,DS-b24ecc7d-0221-43d0-b9c5-5459256c1d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-746cf526-9933-433b-a65f-d44f745840aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-2b70e2ca-e342-4559-a87c-d7ac0424703f,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-72eecf0b-1ec1-42fd-b633-cd3ec9f53f25,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-d051df85-aabf-4176-90b2-caf02db15fca,DISK], DatanodeInfoWithStorage[127.0.0.1:38794,DS-9122d042-3e77-4851-8d14-e0e85a56b542,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-4db39621-b2d1-4284-bdbd-cef1cc56946a,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-bf0aa1c1-39d7-478b-a138-197cdc47f0f9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-417672540-172.17.0.9-1595812691296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44613,DS-be9bc0f4-70a3-4558-953f-ac4b958eaaed,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-2620e274-7f1d-4dbf-9dae-5a9f58223b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-c86faed7-18ec-4038-9c66-d82e5b800a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-12905061-d43b-425f-8e3e-47e34da62836,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-c54c5626-a926-4f16-a67f-d0e3e4fc3084,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-1fe31a5c-b381-4893-9e46-79bdf6ef4c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-bba8a9bd-98d1-43c3-947b-fa266cb84a39,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-0e0940f5-20dd-445d-976c-73cd366e7dc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-417672540-172.17.0.9-1595812691296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44613,DS-be9bc0f4-70a3-4558-953f-ac4b958eaaed,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-2620e274-7f1d-4dbf-9dae-5a9f58223b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-c86faed7-18ec-4038-9c66-d82e5b800a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-12905061-d43b-425f-8e3e-47e34da62836,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-c54c5626-a926-4f16-a67f-d0e3e4fc3084,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-1fe31a5c-b381-4893-9e46-79bdf6ef4c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-bba8a9bd-98d1-43c3-947b-fa266cb84a39,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-0e0940f5-20dd-445d-976c-73cd366e7dc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-497684616-172.17.0.9-1595812755333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37776,DS-e8bc18bc-4d62-4c24-b27e-64b05bc516c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-97089d86-5086-4a69-aebf-01ea178b69d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-f2f4781b-d6e1-4ad4-9191-c5fcc1c95be9,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-3e15312e-2b66-4334-9654-4b0d77f0575b,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-7ba8b99c-6e3b-4ce8-9d55-ff0c26405421,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-c9e8c0df-ed9b-42c5-ae06-e2e05424edd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41905,DS-0ecebe09-041e-4b91-a11b-17d3ffb93366,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-b9b0bb14-214d-4c53-86e1-534a03ad336b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-497684616-172.17.0.9-1595812755333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37776,DS-e8bc18bc-4d62-4c24-b27e-64b05bc516c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-97089d86-5086-4a69-aebf-01ea178b69d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-f2f4781b-d6e1-4ad4-9191-c5fcc1c95be9,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-3e15312e-2b66-4334-9654-4b0d77f0575b,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-7ba8b99c-6e3b-4ce8-9d55-ff0c26405421,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-c9e8c0df-ed9b-42c5-ae06-e2e05424edd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41905,DS-0ecebe09-041e-4b91-a11b-17d3ffb93366,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-b9b0bb14-214d-4c53-86e1-534a03ad336b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1013843298-172.17.0.9-1595812981832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40118,DS-f8e0290f-8135-4bb2-b4c6-7cbd83ef3624,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-96bbc1cc-4e84-4752-8188-715f73826a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34811,DS-69fd2630-4065-49b7-a155-3217793c49bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-62b3d986-6405-4df9-a2be-6dca9885e73e,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-3a5415b4-369c-4374-bb8e-a33756aae7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44233,DS-880b605c-9eb3-4755-b545-2a3e84e2b29c,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-f800f9f7-eab0-4e77-b829-239633cea2db,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-c204794a-ce55-4770-8399-27f7fc3ca6fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1013843298-172.17.0.9-1595812981832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40118,DS-f8e0290f-8135-4bb2-b4c6-7cbd83ef3624,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-96bbc1cc-4e84-4752-8188-715f73826a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34811,DS-69fd2630-4065-49b7-a155-3217793c49bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-62b3d986-6405-4df9-a2be-6dca9885e73e,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-3a5415b4-369c-4374-bb8e-a33756aae7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44233,DS-880b605c-9eb3-4755-b545-2a3e84e2b29c,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-f800f9f7-eab0-4e77-b829-239633cea2db,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-c204794a-ce55-4770-8399-27f7fc3ca6fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-336686013-172.17.0.9-1595813079278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33545,DS-9b184b1c-a6df-4f67-a09c-437454323501,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-0e4f9732-638a-4710-91ec-af61c73f4f36,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-0ed4f60b-18c8-4590-b788-dcad5bbce5da,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-41bcee63-1b3c-44ea-96f3-b615a5174c54,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-c60deea5-c31e-400a-b702-e0967281b8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-bdc0adea-b0eb-4969-82e8-15d3ff9dd36a,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-373742d3-8e41-42c3-9aef-ce916e9570c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-3eba69ec-5c21-40fd-af10-89bde8a352ac,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-336686013-172.17.0.9-1595813079278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33545,DS-9b184b1c-a6df-4f67-a09c-437454323501,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-0e4f9732-638a-4710-91ec-af61c73f4f36,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-0ed4f60b-18c8-4590-b788-dcad5bbce5da,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-41bcee63-1b3c-44ea-96f3-b615a5174c54,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-c60deea5-c31e-400a-b702-e0967281b8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-bdc0adea-b0eb-4969-82e8-15d3ff9dd36a,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-373742d3-8e41-42c3-9aef-ce916e9570c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-3eba69ec-5c21-40fd-af10-89bde8a352ac,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-49480678-172.17.0.9-1595813182202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42292,DS-3b6d03c6-1693-4fdc-9305-adc0e30dc6be,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-58ce5150-711e-42e1-bc4b-28c250c28d15,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-27292f1e-fdcb-4ccd-b916-8cd3a9ab5d64,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-7de67609-53d3-41d5-971b-406080aafc95,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-000f1bfc-da2a-4a36-9856-828e17b93d16,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-5a48f16a-8e36-4716-9bb6-1b61ff25010c,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-b19cfe54-55c8-499c-9cca-fd76e1f12d77,DISK], DatanodeInfoWithStorage[127.0.0.1:33751,DS-92a46fd6-4254-4482-8169-b9dc4dbe8420,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-49480678-172.17.0.9-1595813182202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42292,DS-3b6d03c6-1693-4fdc-9305-adc0e30dc6be,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-58ce5150-711e-42e1-bc4b-28c250c28d15,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-27292f1e-fdcb-4ccd-b916-8cd3a9ab5d64,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-7de67609-53d3-41d5-971b-406080aafc95,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-000f1bfc-da2a-4a36-9856-828e17b93d16,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-5a48f16a-8e36-4716-9bb6-1b61ff25010c,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-b19cfe54-55c8-499c-9cca-fd76e1f12d77,DISK], DatanodeInfoWithStorage[127.0.0.1:33751,DS-92a46fd6-4254-4482-8169-b9dc4dbe8420,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-980244669-172.17.0.9-1595813304770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41148,DS-5a0f06cc-bba6-4424-b946-e29748b5a285,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-500c5e79-43eb-45aa-91f9-c5900647448a,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-fa6709cc-6003-4c12-8f28-7fbe9b8dd79b,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-449f85e3-ba7a-410d-863f-8dbb187d5dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40072,DS-5525b6df-04eb-4069-a82c-fdd504fe06a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37132,DS-5f2b0ecf-4f31-49b2-b02b-ae1684279046,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-4be41c5f-bd0b-4eab-991a-057d063ef81f,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-77d33270-d005-42b1-9b8d-99872033aece,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-980244669-172.17.0.9-1595813304770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41148,DS-5a0f06cc-bba6-4424-b946-e29748b5a285,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-500c5e79-43eb-45aa-91f9-c5900647448a,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-fa6709cc-6003-4c12-8f28-7fbe9b8dd79b,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-449f85e3-ba7a-410d-863f-8dbb187d5dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40072,DS-5525b6df-04eb-4069-a82c-fdd504fe06a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37132,DS-5f2b0ecf-4f31-49b2-b02b-ae1684279046,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-4be41c5f-bd0b-4eab-991a-057d063ef81f,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-77d33270-d005-42b1-9b8d-99872033aece,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2048497120-172.17.0.9-1595813491401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45165,DS-a76a8bde-56c6-4783-a6b8-a5ecd8a09e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-8136890e-468f-431e-83fe-9881de47ab4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-2aaf5b7b-0bab-4bba-acd7-a943a560312a,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-9ef6f891-1089-43c4-a45d-7b9d65a69dda,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-0208ca69-89ee-4417-b353-a4a75cf9f75d,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-b1ea5f41-d429-4d6e-bd97-8b8cc1ae188b,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-70f67f44-134e-42d9-9cd7-b9d7d37a3566,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-caa70721-e938-4811-b94e-b00602d20eea,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2048497120-172.17.0.9-1595813491401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45165,DS-a76a8bde-56c6-4783-a6b8-a5ecd8a09e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-8136890e-468f-431e-83fe-9881de47ab4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-2aaf5b7b-0bab-4bba-acd7-a943a560312a,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-9ef6f891-1089-43c4-a45d-7b9d65a69dda,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-0208ca69-89ee-4417-b353-a4a75cf9f75d,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-b1ea5f41-d429-4d6e-bd97-8b8cc1ae188b,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-70f67f44-134e-42d9-9cd7-b9d7d37a3566,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-caa70721-e938-4811-b94e-b00602d20eea,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-412890538-172.17.0.9-1595813588456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46830,DS-ce711dec-c55a-4b26-993c-a07d58694e65,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-25f23bef-ce38-4a06-802e-42db5ae4f150,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-326fe4e3-c2d7-407e-a6d6-642e0b39ac46,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-93ea2d3c-2a3d-4783-8988-0c0ad96f24c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-5d232782-02b8-400f-ab92-e1735a82653f,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-fc4e9353-5848-4930-8b34-8f2615092d68,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-2fb5bf48-98a4-4178-b2a5-96551d89cbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-ea886a06-a430-40d0-aa71-53d373d0c09b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-412890538-172.17.0.9-1595813588456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46830,DS-ce711dec-c55a-4b26-993c-a07d58694e65,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-25f23bef-ce38-4a06-802e-42db5ae4f150,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-326fe4e3-c2d7-407e-a6d6-642e0b39ac46,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-93ea2d3c-2a3d-4783-8988-0c0ad96f24c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-5d232782-02b8-400f-ab92-e1735a82653f,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-fc4e9353-5848-4930-8b34-8f2615092d68,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-2fb5bf48-98a4-4178-b2a5-96551d89cbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-ea886a06-a430-40d0-aa71-53d373d0c09b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-348871057-172.17.0.9-1595814017324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37841,DS-09968b6a-3170-42d9-b9e8-aae5272d81e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-39c54b2f-f7f6-457a-87be-f307f30354cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-a9ed523a-fad7-48b9-a225-9db5051617af,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-aaf47f2e-ef82-4757-9cca-6566689352ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-79d3f542-d3c1-4bbc-9837-7f0bcb008332,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-277b2404-df36-446b-ae94-b3b14f5a36ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37796,DS-b026dba8-9863-41fa-8c0a-f93436ae62e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-215c3fb0-9a68-49cf-b25d-3d61629076d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-348871057-172.17.0.9-1595814017324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37841,DS-09968b6a-3170-42d9-b9e8-aae5272d81e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-39c54b2f-f7f6-457a-87be-f307f30354cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-a9ed523a-fad7-48b9-a225-9db5051617af,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-aaf47f2e-ef82-4757-9cca-6566689352ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-79d3f542-d3c1-4bbc-9837-7f0bcb008332,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-277b2404-df36-446b-ae94-b3b14f5a36ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37796,DS-b026dba8-9863-41fa-8c0a-f93436ae62e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-215c3fb0-9a68-49cf-b25d-3d61629076d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-198243283-172.17.0.9-1595814368797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44334,DS-8e8303fa-c84b-42bf-b32a-80a5d37babc7,DISK], DatanodeInfoWithStorage[127.0.0.1:46514,DS-fb44da66-50d2-45b5-8645-dc7d5c0fe5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41012,DS-bc8d9b97-f895-4dee-b52d-9abaa6031241,DISK], DatanodeInfoWithStorage[127.0.0.1:36623,DS-53f24438-4a0f-4a42-86ae-4e57f9dc97ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-47169c50-2ff6-40f4-816e-23f213a9e07e,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-183c5c93-1e0f-41ce-b327-2694f1804db4,DISK], DatanodeInfoWithStorage[127.0.0.1:36910,DS-0b48ab5c-6b4e-430c-8412-fc46c0804c54,DISK], DatanodeInfoWithStorage[127.0.0.1:41467,DS-7db8ca4c-e467-4b09-a4e8-439791685879,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-198243283-172.17.0.9-1595814368797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44334,DS-8e8303fa-c84b-42bf-b32a-80a5d37babc7,DISK], DatanodeInfoWithStorage[127.0.0.1:46514,DS-fb44da66-50d2-45b5-8645-dc7d5c0fe5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41012,DS-bc8d9b97-f895-4dee-b52d-9abaa6031241,DISK], DatanodeInfoWithStorage[127.0.0.1:36623,DS-53f24438-4a0f-4a42-86ae-4e57f9dc97ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-47169c50-2ff6-40f4-816e-23f213a9e07e,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-183c5c93-1e0f-41ce-b327-2694f1804db4,DISK], DatanodeInfoWithStorage[127.0.0.1:36910,DS-0b48ab5c-6b4e-430c-8412-fc46c0804c54,DISK], DatanodeInfoWithStorage[127.0.0.1:41467,DS-7db8ca4c-e467-4b09-a4e8-439791685879,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2080316841-172.17.0.9-1595814439486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40171,DS-67f57520-bc6e-46d6-af77-a43215d2224c,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-d19213e3-6f5a-48de-aaa2-66c997f59990,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-8c960257-cb0d-4736-b355-2d13c4186293,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-aa00bc9b-a90c-4f34-9c74-6586e5dd27da,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-cd3c02c9-40ca-411e-a365-8bcb60b8c060,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-397900e0-d268-42a6-bf03-15563feeeb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-f7dbd9d3-6e28-4de0-81c5-c88c97396df2,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-6808b1b6-bf54-4274-86c5-2d83f56ea585,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2080316841-172.17.0.9-1595814439486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40171,DS-67f57520-bc6e-46d6-af77-a43215d2224c,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-d19213e3-6f5a-48de-aaa2-66c997f59990,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-8c960257-cb0d-4736-b355-2d13c4186293,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-aa00bc9b-a90c-4f34-9c74-6586e5dd27da,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-cd3c02c9-40ca-411e-a365-8bcb60b8c060,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-397900e0-d268-42a6-bf03-15563feeeb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-f7dbd9d3-6e28-4de0-81c5-c88c97396df2,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-6808b1b6-bf54-4274-86c5-2d83f56ea585,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1390194726-172.17.0.9-1595814586895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38990,DS-bf07b162-6737-43c7-b8dd-615d8aa14f43,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-bf7748e9-6559-4c2f-975c-6e4cacb12342,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-c5623dc4-5370-453c-9d3e-e21bbf5035d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33278,DS-53c9f4bd-d5d6-455a-a255-232988d470e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-4cff0e5a-404b-449a-8652-ca0c5942f01f,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-4072e240-987a-4a91-9099-4073186d9f10,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-0d4c4e7f-032e-4295-b107-d7bf668cce73,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-adf40d7e-a992-4ec9-b746-32a32ef657d2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1390194726-172.17.0.9-1595814586895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38990,DS-bf07b162-6737-43c7-b8dd-615d8aa14f43,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-bf7748e9-6559-4c2f-975c-6e4cacb12342,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-c5623dc4-5370-453c-9d3e-e21bbf5035d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33278,DS-53c9f4bd-d5d6-455a-a255-232988d470e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-4cff0e5a-404b-449a-8652-ca0c5942f01f,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-4072e240-987a-4a91-9099-4073186d9f10,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-0d4c4e7f-032e-4295-b107-d7bf668cce73,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-adf40d7e-a992-4ec9-b746-32a32ef657d2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-549832709-172.17.0.9-1595814860262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37392,DS-93760be5-b5ed-47fb-90ec-e04b76f9ab73,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-a384638b-710d-4055-90fc-90bce0731c75,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-c374585e-d618-4930-86b2-f0b139a31ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-3e4c8251-622f-4f5b-b4f5-27522b0be9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45613,DS-6a0ccdbc-142f-4484-bdf0-933ba49c6367,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-7f5880f7-9d2f-4106-b672-e9ebb652fa5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-71f9101f-7577-44c3-9e29-af184d25467a,DISK], DatanodeInfoWithStorage[127.0.0.1:44988,DS-0a6a6901-82cf-47f4-a4f6-7edeb66534cc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-549832709-172.17.0.9-1595814860262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37392,DS-93760be5-b5ed-47fb-90ec-e04b76f9ab73,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-a384638b-710d-4055-90fc-90bce0731c75,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-c374585e-d618-4930-86b2-f0b139a31ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-3e4c8251-622f-4f5b-b4f5-27522b0be9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45613,DS-6a0ccdbc-142f-4484-bdf0-933ba49c6367,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-7f5880f7-9d2f-4106-b672-e9ebb652fa5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-71f9101f-7577-44c3-9e29-af184d25467a,DISK], DatanodeInfoWithStorage[127.0.0.1:44988,DS-0a6a6901-82cf-47f4-a4f6-7edeb66534cc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-37430247-172.17.0.9-1595814898155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40488,DS-ae500cdf-76e1-4530-bc80-cbca0bf8faa5,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-4b2d05c6-24b7-4a3a-b028-78a28b77d419,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-2f614430-652b-4485-8013-4f6ec67c0038,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-45ac1c05-1227-46a0-9abb-257098143c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-c8b4e305-933d-405a-93ef-f4b883d443c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-8b2dfde5-9420-45ec-b5e1-25a477240ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-d65a1f8a-21e2-4bda-83c5-56ea48cfd033,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-144e8aa7-5872-4a39-a441-0f1e6beaa49a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-37430247-172.17.0.9-1595814898155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40488,DS-ae500cdf-76e1-4530-bc80-cbca0bf8faa5,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-4b2d05c6-24b7-4a3a-b028-78a28b77d419,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-2f614430-652b-4485-8013-4f6ec67c0038,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-45ac1c05-1227-46a0-9abb-257098143c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-c8b4e305-933d-405a-93ef-f4b883d443c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-8b2dfde5-9420-45ec-b5e1-25a477240ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-d65a1f8a-21e2-4bda-83c5-56ea48cfd033,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-144e8aa7-5872-4a39-a441-0f1e6beaa49a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056006100-172.17.0.9-1595814984063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32774,DS-98f6784f-767e-4113-8740-a4fd066e34e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-506530e2-c8dc-4508-9035-1246e4f72590,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-9070f64b-2690-4c0e-8f0d-ab16627ac68f,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-96cd4808-e483-428f-ac09-4d300207043f,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-5bfc9cce-f501-471b-bd1d-9823f3f1c63f,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-3cee0f36-6214-4f69-ac7c-0d2221ddf431,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-e8d99674-013b-4abd-b88e-383083bb72b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-97dd2383-5da8-4f36-a24a-0a1154c399aa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056006100-172.17.0.9-1595814984063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32774,DS-98f6784f-767e-4113-8740-a4fd066e34e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-506530e2-c8dc-4508-9035-1246e4f72590,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-9070f64b-2690-4c0e-8f0d-ab16627ac68f,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-96cd4808-e483-428f-ac09-4d300207043f,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-5bfc9cce-f501-471b-bd1d-9823f3f1c63f,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-3cee0f36-6214-4f69-ac7c-0d2221ddf431,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-e8d99674-013b-4abd-b88e-383083bb72b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-97dd2383-5da8-4f36-a24a-0a1154c399aa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1563918818-172.17.0.9-1595815088456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38673,DS-034f470a-5b37-414b-b3b6-1ec0d8eabf7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-e703fb0d-01ba-4075-a75c-001834eee5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38044,DS-26e3fc5f-eadf-4dfc-aacd-0f5bd9b7f31d,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-57208bf6-bc41-4f98-a635-d989207d9b88,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-d1b982f0-733f-40de-9780-3aeb235979bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-da30b691-f988-4064-90f2-73b9537cd6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-f9496396-8276-4a81-928b-55bdc473add2,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-aea4a29a-db5a-4255-a79f-98dca681e4dd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1563918818-172.17.0.9-1595815088456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38673,DS-034f470a-5b37-414b-b3b6-1ec0d8eabf7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-e703fb0d-01ba-4075-a75c-001834eee5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38044,DS-26e3fc5f-eadf-4dfc-aacd-0f5bd9b7f31d,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-57208bf6-bc41-4f98-a635-d989207d9b88,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-d1b982f0-733f-40de-9780-3aeb235979bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-da30b691-f988-4064-90f2-73b9537cd6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-f9496396-8276-4a81-928b-55bdc473add2,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-aea4a29a-db5a-4255-a79f-98dca681e4dd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1862849725-172.17.0.9-1595815242895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44920,DS-4fef0046-81ce-48db-9364-dbe24167796b,DISK], DatanodeInfoWithStorage[127.0.0.1:32900,DS-4e3801c4-fba8-4270-9a0f-770c32681ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:33906,DS-c8bbd9bb-29ec-4a02-b19f-5a66a434c4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-6e202098-c949-4eba-8488-9377a4fc1db1,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-b81ec826-2d63-4df8-b83d-8150e06ff56b,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-ff911028-be32-4ac4-997e-2ffe28cd02c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36333,DS-8ea3a862-8638-4a37-983b-2d8d0cc89924,DISK], DatanodeInfoWithStorage[127.0.0.1:36631,DS-2426460c-747b-415f-8e56-079a76c48058,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1862849725-172.17.0.9-1595815242895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44920,DS-4fef0046-81ce-48db-9364-dbe24167796b,DISK], DatanodeInfoWithStorage[127.0.0.1:32900,DS-4e3801c4-fba8-4270-9a0f-770c32681ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:33906,DS-c8bbd9bb-29ec-4a02-b19f-5a66a434c4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-6e202098-c949-4eba-8488-9377a4fc1db1,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-b81ec826-2d63-4df8-b83d-8150e06ff56b,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-ff911028-be32-4ac4-997e-2ffe28cd02c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36333,DS-8ea3a862-8638-4a37-983b-2d8d0cc89924,DISK], DatanodeInfoWithStorage[127.0.0.1:36631,DS-2426460c-747b-415f-8e56-079a76c48058,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1839840633-172.17.0.9-1595815427415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43957,DS-135465d9-9f50-4e7c-8593-5e4ac5a5491b,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-b7231c6e-8169-480f-a3c0-e554134bb200,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-53b5f140-e67a-4fdf-b229-78cd3ccc2682,DISK], DatanodeInfoWithStorage[127.0.0.1:35612,DS-47c97e9e-d9cf-48d9-b620-868a17ede2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-ee9326a4-b77f-4714-8511-f6b263145d11,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-3add22c5-8557-4c57-b091-097935769e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-7beb6058-51e4-4ba2-b31a-829547387d11,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-d960c450-a3f7-41cb-ba4f-4ecdede6cf4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1839840633-172.17.0.9-1595815427415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43957,DS-135465d9-9f50-4e7c-8593-5e4ac5a5491b,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-b7231c6e-8169-480f-a3c0-e554134bb200,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-53b5f140-e67a-4fdf-b229-78cd3ccc2682,DISK], DatanodeInfoWithStorage[127.0.0.1:35612,DS-47c97e9e-d9cf-48d9-b620-868a17ede2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-ee9326a4-b77f-4714-8511-f6b263145d11,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-3add22c5-8557-4c57-b091-097935769e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-7beb6058-51e4-4ba2-b31a-829547387d11,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-d960c450-a3f7-41cb-ba4f-4ecdede6cf4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2096121099-172.17.0.9-1595815649124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36460,DS-5049c611-5f63-4fb7-a902-889837c2ad26,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-a0ec8270-a4dd-43cb-adb1-438c0436d836,DISK], DatanodeInfoWithStorage[127.0.0.1:45969,DS-12ca4ba5-b9a9-48fb-b2b0-ebb41bae3b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44013,DS-ee25c1ce-5b68-4365-a201-9648db83ac3c,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-813adb8c-09b8-444b-9e05-5f4c79e8e3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-02aea4c7-6b8f-4347-b488-10c5f4cf5a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-83add98a-0af3-461c-af0e-0837d1509eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-44ba81db-2f19-40c5-8d84-7b2b45184232,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2096121099-172.17.0.9-1595815649124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36460,DS-5049c611-5f63-4fb7-a902-889837c2ad26,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-a0ec8270-a4dd-43cb-adb1-438c0436d836,DISK], DatanodeInfoWithStorage[127.0.0.1:45969,DS-12ca4ba5-b9a9-48fb-b2b0-ebb41bae3b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44013,DS-ee25c1ce-5b68-4365-a201-9648db83ac3c,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-813adb8c-09b8-444b-9e05-5f4c79e8e3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-02aea4c7-6b8f-4347-b488-10c5f4cf5a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-83add98a-0af3-461c-af0e-0837d1509eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-44ba81db-2f19-40c5-8d84-7b2b45184232,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1772220826-172.17.0.9-1595815978561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37947,DS-e7679b3c-a736-4475-882a-253970186e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-ff899b69-8f52-44db-970b-78d05b44f165,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-51110dc9-46a0-4125-b3f5-d3c333922f08,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-59ed7759-cb28-4dba-bfa6-63b4c7461ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-92dd4a32-a7ec-42ef-9de9-eec34fe055d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-17f40968-5498-424c-9494-5e8e0bcefe97,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-8b1f3322-fd2e-417a-a041-264def2bf53c,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-9fc1e4c9-0627-4eb2-a441-6eb27392a5ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1772220826-172.17.0.9-1595815978561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37947,DS-e7679b3c-a736-4475-882a-253970186e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-ff899b69-8f52-44db-970b-78d05b44f165,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-51110dc9-46a0-4125-b3f5-d3c333922f08,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-59ed7759-cb28-4dba-bfa6-63b4c7461ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-92dd4a32-a7ec-42ef-9de9-eec34fe055d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-17f40968-5498-424c-9494-5e8e0bcefe97,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-8b1f3322-fd2e-417a-a041-264def2bf53c,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-9fc1e4c9-0627-4eb2-a441-6eb27392a5ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-300098060-172.17.0.9-1595816077407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35670,DS-fe2cd41f-8284-4684-b54b-41828a1fe804,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-e752332b-f69f-4cb5-969a-a285710364d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-81f39c64-7696-43c1-a707-11f8e1cea655,DISK], DatanodeInfoWithStorage[127.0.0.1:44771,DS-8e0a2d4b-0839-4817-94c4-9b3dbdfa3e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-ba40a32c-8415-4920-a7bb-60ba8d0b8998,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-ba71f7a7-21ac-4e6f-96d4-bd174c77b692,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-23899d34-ce48-4ff6-9d55-980c9d055afe,DISK], DatanodeInfoWithStorage[127.0.0.1:46042,DS-6bac4add-2ffa-49d3-8380-d04d3fcdffb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-300098060-172.17.0.9-1595816077407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35670,DS-fe2cd41f-8284-4684-b54b-41828a1fe804,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-e752332b-f69f-4cb5-969a-a285710364d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-81f39c64-7696-43c1-a707-11f8e1cea655,DISK], DatanodeInfoWithStorage[127.0.0.1:44771,DS-8e0a2d4b-0839-4817-94c4-9b3dbdfa3e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-ba40a32c-8415-4920-a7bb-60ba8d0b8998,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-ba71f7a7-21ac-4e6f-96d4-bd174c77b692,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-23899d34-ce48-4ff6-9d55-980c9d055afe,DISK], DatanodeInfoWithStorage[127.0.0.1:46042,DS-6bac4add-2ffa-49d3-8380-d04d3fcdffb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1129518836-172.17.0.9-1595816186382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36144,DS-f9a93c50-68b8-4f3e-9ae0-616005cf79e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-d9669286-200a-49ed-bd89-5b37e165385c,DISK], DatanodeInfoWithStorage[127.0.0.1:38851,DS-63e2a0ab-55b5-4974-9dde-c57e5dea0c76,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-9c57455a-e8f4-4ef0-9740-97c759f24c57,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-84cb924f-8316-49e8-96ab-37e7559ce9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38267,DS-2930ba78-9844-41ed-9f2f-9cc34c4bbcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-7ffa50b6-b058-49de-afc5-bbb6df85e3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-00fe1884-eb7a-4574-9c17-9c966214ed40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1129518836-172.17.0.9-1595816186382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36144,DS-f9a93c50-68b8-4f3e-9ae0-616005cf79e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-d9669286-200a-49ed-bd89-5b37e165385c,DISK], DatanodeInfoWithStorage[127.0.0.1:38851,DS-63e2a0ab-55b5-4974-9dde-c57e5dea0c76,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-9c57455a-e8f4-4ef0-9740-97c759f24c57,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-84cb924f-8316-49e8-96ab-37e7559ce9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38267,DS-2930ba78-9844-41ed-9f2f-9cc34c4bbcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-7ffa50b6-b058-49de-afc5-bbb6df85e3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-00fe1884-eb7a-4574-9c17-9c966214ed40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 21 out of 50
result: false positive !!!
Total execution time in seconds : 5301
