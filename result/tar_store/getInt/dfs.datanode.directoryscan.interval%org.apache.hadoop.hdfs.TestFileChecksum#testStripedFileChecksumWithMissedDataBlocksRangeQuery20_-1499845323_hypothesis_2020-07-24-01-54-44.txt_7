reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1884507602-172.17.0.19-1595556245462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40183,DS-1484b1e6-d832-4af2-b28a-480e4dc93ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-37dec580-f4d3-4b78-95d8-e5df756de65c,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-01f972d3-4899-4d22-b52a-80b91213dc84,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-5dd28a29-ea37-4e1c-a41b-306a65044b20,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-0be032ac-add4-45a8-a925-266a95c49b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-7db7c897-2d83-49d4-8947-4cab9c9724ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-3b62a038-08a6-4115-97ee-2da96a907f95,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-1ea70607-7cc9-492b-a14c-b86162595887,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1884507602-172.17.0.19-1595556245462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40183,DS-1484b1e6-d832-4af2-b28a-480e4dc93ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-37dec580-f4d3-4b78-95d8-e5df756de65c,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-01f972d3-4899-4d22-b52a-80b91213dc84,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-5dd28a29-ea37-4e1c-a41b-306a65044b20,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-0be032ac-add4-45a8-a925-266a95c49b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-7db7c897-2d83-49d4-8947-4cab9c9724ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-3b62a038-08a6-4115-97ee-2da96a907f95,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-1ea70607-7cc9-492b-a14c-b86162595887,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-480120488-172.17.0.19-1595556282019:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42439,DS-108e43fb-cea2-4932-9294-a588b494aff5,DISK], DatanodeInfoWithStorage[127.0.0.1:45072,DS-a20fdab4-9b34-48c2-9f69-f6d0d45d1cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-4dfa73d9-e4e2-4386-9990-f6892f12a6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-016110d4-35fc-4120-ad62-5f784ce01290,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-fabd79ee-5b5d-411a-bf76-0067a3f46d12,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-e7fb1d31-31ce-4f38-bfe6-d7c049886818,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-86f800a5-1c99-4b1f-970c-2838f35cd9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-15e8123e-4847-45ae-afc6-04d689c48ad4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-480120488-172.17.0.19-1595556282019:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42439,DS-108e43fb-cea2-4932-9294-a588b494aff5,DISK], DatanodeInfoWithStorage[127.0.0.1:45072,DS-a20fdab4-9b34-48c2-9f69-f6d0d45d1cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-4dfa73d9-e4e2-4386-9990-f6892f12a6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-016110d4-35fc-4120-ad62-5f784ce01290,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-fabd79ee-5b5d-411a-bf76-0067a3f46d12,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-e7fb1d31-31ce-4f38-bfe6-d7c049886818,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-86f800a5-1c99-4b1f-970c-2838f35cd9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-15e8123e-4847-45ae-afc6-04d689c48ad4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1582407428-172.17.0.19-1595557016222:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43279,DS-1bfceb01-359e-4fd3-8017-6ebc454e4a52,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-3848e92f-b561-41f5-97b3-c1346dc52ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-ef2d15ee-73d8-4694-955d-8b814e24fe04,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-108e1919-f99f-4a65-a5cf-f894975c0510,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-f72ba492-3f41-4af4-ada2-f6365e837493,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-dc9c993e-7ec2-4e46-910f-e6ad74d9229e,DISK], DatanodeInfoWithStorage[127.0.0.1:37411,DS-58f26928-2b42-454f-b26c-e66cc3dcb1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-9a20df7f-e6d3-4365-82c2-7c362e7ddff1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1582407428-172.17.0.19-1595557016222:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43279,DS-1bfceb01-359e-4fd3-8017-6ebc454e4a52,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-3848e92f-b561-41f5-97b3-c1346dc52ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-ef2d15ee-73d8-4694-955d-8b814e24fe04,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-108e1919-f99f-4a65-a5cf-f894975c0510,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-f72ba492-3f41-4af4-ada2-f6365e837493,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-dc9c993e-7ec2-4e46-910f-e6ad74d9229e,DISK], DatanodeInfoWithStorage[127.0.0.1:37411,DS-58f26928-2b42-454f-b26c-e66cc3dcb1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-9a20df7f-e6d3-4365-82c2-7c362e7ddff1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2091980829-172.17.0.19-1595557048292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36390,DS-16a7b2b6-b08c-424e-8c44-0bd7d5092357,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-bcad8bd2-8bb6-4287-b81f-bb22d653e830,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-91b7c4b2-e9cd-4f6c-aea0-1ccfa1feaf35,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-1a0ff694-a5af-4035-8b5b-a0d0b7844ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-c6d27f21-2968-457e-a022-1b4685508370,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-85c22d90-52c9-472d-abf0-24789f0d5f51,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-4498d9c1-81d3-44f3-93cd-13a7de3a1f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-b4a4d831-5daa-4d83-9998-0ee8bcad5d74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2091980829-172.17.0.19-1595557048292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36390,DS-16a7b2b6-b08c-424e-8c44-0bd7d5092357,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-bcad8bd2-8bb6-4287-b81f-bb22d653e830,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-91b7c4b2-e9cd-4f6c-aea0-1ccfa1feaf35,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-1a0ff694-a5af-4035-8b5b-a0d0b7844ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-c6d27f21-2968-457e-a022-1b4685508370,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-85c22d90-52c9-472d-abf0-24789f0d5f51,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-4498d9c1-81d3-44f3-93cd-13a7de3a1f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-b4a4d831-5daa-4d83-9998-0ee8bcad5d74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-828826138-172.17.0.19-1595557154460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40350,DS-852e6c2a-3df5-4c4b-b3a8-aa7e6b7762ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36006,DS-56ac9e5e-7ab1-4c5e-b5d4-bb8badb322d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-23508e20-b5d8-4598-9e12-f9eea5c04ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-8e6f46b3-ce0d-4c6d-a8ec-bea561b61377,DISK], DatanodeInfoWithStorage[127.0.0.1:36694,DS-3d10b07e-cf23-4a0d-9e90-269241819984,DISK], DatanodeInfoWithStorage[127.0.0.1:42638,DS-68e8d7d3-514c-4251-8e8a-98b7cebe4999,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-7679b020-5ad5-4659-9c3d-aa449d540a56,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-b021c01a-171e-4873-a5b5-16e78ab2d278,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-828826138-172.17.0.19-1595557154460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40350,DS-852e6c2a-3df5-4c4b-b3a8-aa7e6b7762ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36006,DS-56ac9e5e-7ab1-4c5e-b5d4-bb8badb322d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-23508e20-b5d8-4598-9e12-f9eea5c04ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-8e6f46b3-ce0d-4c6d-a8ec-bea561b61377,DISK], DatanodeInfoWithStorage[127.0.0.1:36694,DS-3d10b07e-cf23-4a0d-9e90-269241819984,DISK], DatanodeInfoWithStorage[127.0.0.1:42638,DS-68e8d7d3-514c-4251-8e8a-98b7cebe4999,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-7679b020-5ad5-4659-9c3d-aa449d540a56,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-b021c01a-171e-4873-a5b5-16e78ab2d278,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1474993416-172.17.0.19-1595557815253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32906,DS-1ba2bfa7-b42f-45f5-b0eb-039d25a5902e,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-70686469-a12f-4e49-ba88-09ffb95d0d14,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-2fd6e6cb-f1b3-477f-9a2d-c6e4a1e7aede,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-46b2f2e6-a3fb-42de-b758-86e4c8d06da2,DISK], DatanodeInfoWithStorage[127.0.0.1:34076,DS-6b3b60ab-22c6-423d-89e1-9b6761cf5265,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-77ccf6be-cd0b-4efc-8929-182d2c610a44,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-fdb44b48-9805-46b4-8b71-d9fbae519ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-fa301a6d-1742-49b3-99f6-439e3f2704db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1474993416-172.17.0.19-1595557815253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32906,DS-1ba2bfa7-b42f-45f5-b0eb-039d25a5902e,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-70686469-a12f-4e49-ba88-09ffb95d0d14,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-2fd6e6cb-f1b3-477f-9a2d-c6e4a1e7aede,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-46b2f2e6-a3fb-42de-b758-86e4c8d06da2,DISK], DatanodeInfoWithStorage[127.0.0.1:34076,DS-6b3b60ab-22c6-423d-89e1-9b6761cf5265,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-77ccf6be-cd0b-4efc-8929-182d2c610a44,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-fdb44b48-9805-46b4-8b71-d9fbae519ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-fa301a6d-1742-49b3-99f6-439e3f2704db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-196899611-172.17.0.19-1595557957760:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43996,DS-71839d3c-d6c7-4390-bde4-38f09e04a43c,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-0f7c1a0b-b602-4f7d-92bc-905c398ce9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-fd9201d6-8769-4976-a7b7-e19b8cafb36e,DISK], DatanodeInfoWithStorage[127.0.0.1:46817,DS-16a66c7b-cde1-4f81-8abd-e71818ee3cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-e39081ec-7cbc-488b-84e3-56f41f717258,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-3372d9f4-7427-4d15-8849-be86b5bd4a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-25f1fe44-dbe8-4893-97a4-ced49e61313b,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-385d1947-c4bf-466c-bd18-2e893d66f517,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-196899611-172.17.0.19-1595557957760:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43996,DS-71839d3c-d6c7-4390-bde4-38f09e04a43c,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-0f7c1a0b-b602-4f7d-92bc-905c398ce9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-fd9201d6-8769-4976-a7b7-e19b8cafb36e,DISK], DatanodeInfoWithStorage[127.0.0.1:46817,DS-16a66c7b-cde1-4f81-8abd-e71818ee3cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-e39081ec-7cbc-488b-84e3-56f41f717258,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-3372d9f4-7427-4d15-8849-be86b5bd4a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-25f1fe44-dbe8-4893-97a4-ced49e61313b,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-385d1947-c4bf-466c-bd18-2e893d66f517,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1147936494-172.17.0.19-1595558520017:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39541,DS-315ad0fb-35dc-4d00-baf7-7bbb310fff55,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-35f2502c-5bc6-4130-9ba1-bba6224e9f12,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-9c62156f-bca6-40d0-addf-4dde9b730a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-76ec49e2-b68b-4398-9ed3-4563de19afc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-5c1e7b0f-3748-460f-87bc-1925fd152ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-bde4525c-6f76-43e3-9485-b1facfb6aabb,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-ddd6f5ea-f411-4559-8e73-730354991a90,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-754cfa1c-303f-4959-993c-cdef37e7836d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1147936494-172.17.0.19-1595558520017:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39541,DS-315ad0fb-35dc-4d00-baf7-7bbb310fff55,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-35f2502c-5bc6-4130-9ba1-bba6224e9f12,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-9c62156f-bca6-40d0-addf-4dde9b730a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-76ec49e2-b68b-4398-9ed3-4563de19afc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-5c1e7b0f-3748-460f-87bc-1925fd152ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-bde4525c-6f76-43e3-9485-b1facfb6aabb,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-ddd6f5ea-f411-4559-8e73-730354991a90,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-754cfa1c-303f-4959-993c-cdef37e7836d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1970741013-172.17.0.19-1595558907126:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43787,DS-44a4efa7-fca9-43c4-88ef-f36595bde9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-c393ea31-82f4-416c-ab10-55f4bb7e38a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-a43238f6-545e-4674-aa4d-edd2214c12db,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-63472236-a318-44c0-9324-550c7c93f36b,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-198087ac-1ce9-4dde-95d0-e6f853cc622d,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-1c37d7a3-5faa-4932-b786-e7e1f893ffb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-1355b591-73cf-4229-94b9-2ba14f6c36f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-a246f5ce-282e-46d1-93af-a06be2285262,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1970741013-172.17.0.19-1595558907126:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43787,DS-44a4efa7-fca9-43c4-88ef-f36595bde9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-c393ea31-82f4-416c-ab10-55f4bb7e38a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-a43238f6-545e-4674-aa4d-edd2214c12db,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-63472236-a318-44c0-9324-550c7c93f36b,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-198087ac-1ce9-4dde-95d0-e6f853cc622d,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-1c37d7a3-5faa-4932-b786-e7e1f893ffb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-1355b591-73cf-4229-94b9-2ba14f6c36f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-a246f5ce-282e-46d1-93af-a06be2285262,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-308420467-172.17.0.19-1595559013449:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43551,DS-abb1f874-1597-4801-884f-c406a9cdf8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43840,DS-ac88bdff-a21a-4f6e-8c7f-b957628a8f14,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-3e9d6133-63d3-4a3d-8c56-317672059e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-72b2842c-45d2-43e2-9beb-7e0974bc907c,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-ac16e18f-46b8-4c75-8cbe-4e89cd354262,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-32b19e39-0ea1-48d1-bcaf-0575e4de1fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-00ee7dc4-4501-40dd-9769-be97f418c560,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-7f04c651-589f-43a1-8224-c362f8b08144,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-308420467-172.17.0.19-1595559013449:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43551,DS-abb1f874-1597-4801-884f-c406a9cdf8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43840,DS-ac88bdff-a21a-4f6e-8c7f-b957628a8f14,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-3e9d6133-63d3-4a3d-8c56-317672059e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-72b2842c-45d2-43e2-9beb-7e0974bc907c,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-ac16e18f-46b8-4c75-8cbe-4e89cd354262,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-32b19e39-0ea1-48d1-bcaf-0575e4de1fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-00ee7dc4-4501-40dd-9769-be97f418c560,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-7f04c651-589f-43a1-8224-c362f8b08144,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-969292758-172.17.0.19-1595559075227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39831,DS-24ac41c2-189e-4a1c-bbb9-a3a26ce453d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-9d73900d-173e-4849-b423-8db2c8886c65,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-5f76ef4c-47d7-4927-83a7-fba49aa350da,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-3d0b8752-c352-44be-acf8-968e13a438f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-93a4c738-60ab-4472-892c-8f090e54a24e,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-a69ed5ea-f16e-4f63-a34f-72f0cd816e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-3e7bc723-3717-4842-9b47-6438451c5ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-bb6cb068-9c93-4083-988c-50eaa7ac9444,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-969292758-172.17.0.19-1595559075227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39831,DS-24ac41c2-189e-4a1c-bbb9-a3a26ce453d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-9d73900d-173e-4849-b423-8db2c8886c65,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-5f76ef4c-47d7-4927-83a7-fba49aa350da,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-3d0b8752-c352-44be-acf8-968e13a438f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-93a4c738-60ab-4472-892c-8f090e54a24e,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-a69ed5ea-f16e-4f63-a34f-72f0cd816e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-3e7bc723-3717-4842-9b47-6438451c5ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-bb6cb068-9c93-4083-988c-50eaa7ac9444,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-379291283-172.17.0.19-1595559227294:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39563,DS-569f5597-521c-4865-931c-a856de4e00c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-a81d77d6-6c12-441c-bb08-c7bb22edd11f,DISK], DatanodeInfoWithStorage[127.0.0.1:42953,DS-7f0b884a-e82e-4da6-8566-594587fbb78c,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-66cc38eb-c801-47b0-91db-8ebc6ad53675,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-521bd607-f88e-4208-8179-82eeaad82953,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-edd159fb-3982-4d5f-a00d-9ac489999456,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-2e9ab52b-d818-4d51-b770-91bfb791b448,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-bfeb380c-4429-4878-8931-967f5419e419,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-379291283-172.17.0.19-1595559227294:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39563,DS-569f5597-521c-4865-931c-a856de4e00c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-a81d77d6-6c12-441c-bb08-c7bb22edd11f,DISK], DatanodeInfoWithStorage[127.0.0.1:42953,DS-7f0b884a-e82e-4da6-8566-594587fbb78c,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-66cc38eb-c801-47b0-91db-8ebc6ad53675,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-521bd607-f88e-4208-8179-82eeaad82953,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-edd159fb-3982-4d5f-a00d-9ac489999456,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-2e9ab52b-d818-4d51-b770-91bfb791b448,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-bfeb380c-4429-4878-8931-967f5419e419,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2024995452-172.17.0.19-1595559265370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46238,DS-f26d7163-42c6-494c-9b91-b362390bbecb,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-6efc8bde-c0f9-4e50-8a7e-be3a0db818a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-c2c04ec0-0697-42f9-89f9-90f4563b6b96,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-7bfa630b-4079-47ae-bcb0-24475cf9c124,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-1303cbfb-efd7-4b6f-a21c-22737df179e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-a51f2cdc-9b7b-481b-9334-05a3f89211ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-ca8bc40a-6b5a-40c3-a0a2-85109d97b932,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-7f518d2a-e435-468f-bca4-abc598d835bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2024995452-172.17.0.19-1595559265370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46238,DS-f26d7163-42c6-494c-9b91-b362390bbecb,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-6efc8bde-c0f9-4e50-8a7e-be3a0db818a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-c2c04ec0-0697-42f9-89f9-90f4563b6b96,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-7bfa630b-4079-47ae-bcb0-24475cf9c124,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-1303cbfb-efd7-4b6f-a21c-22737df179e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-a51f2cdc-9b7b-481b-9334-05a3f89211ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-ca8bc40a-6b5a-40c3-a0a2-85109d97b932,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-7f518d2a-e435-468f-bca4-abc598d835bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1281041377-172.17.0.19-1595560176257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34762,DS-db9b1cef-79bc-4835-bbf3-103e5e2b3598,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-adc98032-6f75-4d2f-a34f-a7adc832e4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-ac3fdb31-8d9b-43dd-8d02-20ac754e7903,DISK], DatanodeInfoWithStorage[127.0.0.1:43647,DS-7234f829-3fdc-46e8-bb54-3e087e5f9cca,DISK], DatanodeInfoWithStorage[127.0.0.1:42903,DS-bb2f1f1e-d46d-461e-884e-7f8165a5f3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-53bd2a9e-3f77-44e0-b243-33035c1bb8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-5f692911-2e1b-4450-a912-06b565c3ee27,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-88115698-7221-4ef6-b9ff-e93da6e7c98c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1281041377-172.17.0.19-1595560176257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34762,DS-db9b1cef-79bc-4835-bbf3-103e5e2b3598,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-adc98032-6f75-4d2f-a34f-a7adc832e4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-ac3fdb31-8d9b-43dd-8d02-20ac754e7903,DISK], DatanodeInfoWithStorage[127.0.0.1:43647,DS-7234f829-3fdc-46e8-bb54-3e087e5f9cca,DISK], DatanodeInfoWithStorage[127.0.0.1:42903,DS-bb2f1f1e-d46d-461e-884e-7f8165a5f3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-53bd2a9e-3f77-44e0-b243-33035c1bb8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-5f692911-2e1b-4450-a912-06b565c3ee27,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-88115698-7221-4ef6-b9ff-e93da6e7c98c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-581675770-172.17.0.19-1595560870775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38773,DS-2b0d51a4-345d-4341-acb8-cc3691d6095d,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-9dda5c9a-1616-463d-b3c3-01e63998886f,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-2d716c22-399e-43df-8a16-258ddb4e0704,DISK], DatanodeInfoWithStorage[127.0.0.1:43636,DS-ec011337-3cd6-42d8-a40c-10c98181614a,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-43f8d7f2-7bdc-4381-a5be-3536ff86a64e,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-c1b5093d-d34b-4fd4-8c20-5e247fefed1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-7f5bde5e-a653-4215-9fdd-1caccbd21ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-f3e00438-bf91-4a0c-bbaa-b30457d4ee78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-581675770-172.17.0.19-1595560870775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38773,DS-2b0d51a4-345d-4341-acb8-cc3691d6095d,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-9dda5c9a-1616-463d-b3c3-01e63998886f,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-2d716c22-399e-43df-8a16-258ddb4e0704,DISK], DatanodeInfoWithStorage[127.0.0.1:43636,DS-ec011337-3cd6-42d8-a40c-10c98181614a,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-43f8d7f2-7bdc-4381-a5be-3536ff86a64e,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-c1b5093d-d34b-4fd4-8c20-5e247fefed1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-7f5bde5e-a653-4215-9fdd-1caccbd21ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-f3e00438-bf91-4a0c-bbaa-b30457d4ee78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5334
