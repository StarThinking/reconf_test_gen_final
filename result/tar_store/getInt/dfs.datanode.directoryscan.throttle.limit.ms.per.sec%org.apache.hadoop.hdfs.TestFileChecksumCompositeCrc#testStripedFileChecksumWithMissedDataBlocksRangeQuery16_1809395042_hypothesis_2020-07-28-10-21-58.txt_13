reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-42016323-172.17.0.11-1595931811997:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42687,DS-58e31fba-26af-46e4-81af-d1107cae0f31,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-cecad93e-c281-4437-9500-0a9be89a5c65,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-b43b092f-0f84-4498-b317-d2aaebdab4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-50853e1a-dd97-4b32-8d19-e128263d2af6,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-24c1a048-295d-4209-9b1c-0c3868c2470a,DISK], DatanodeInfoWithStorage[127.0.0.1:44551,DS-e59b5de2-bb8c-4096-ad2f-63ccf848b3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38875,DS-675e54bb-04dc-411d-9ed8-8f333c483b99,DISK], DatanodeInfoWithStorage[127.0.0.1:44041,DS-ff09883e-ac30-4bc6-826b-c700c9d24d51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-42016323-172.17.0.11-1595931811997:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42687,DS-58e31fba-26af-46e4-81af-d1107cae0f31,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-cecad93e-c281-4437-9500-0a9be89a5c65,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-b43b092f-0f84-4498-b317-d2aaebdab4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-50853e1a-dd97-4b32-8d19-e128263d2af6,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-24c1a048-295d-4209-9b1c-0c3868c2470a,DISK], DatanodeInfoWithStorage[127.0.0.1:44551,DS-e59b5de2-bb8c-4096-ad2f-63ccf848b3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38875,DS-675e54bb-04dc-411d-9ed8-8f333c483b99,DISK], DatanodeInfoWithStorage[127.0.0.1:44041,DS-ff09883e-ac30-4bc6-826b-c700c9d24d51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-634601520-172.17.0.11-1595932153335:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44214,DS-a7e353d4-6c5b-467a-bc47-d7b519b65e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43448,DS-3ff67a0c-3fa2-4915-a587-484c6c4f7197,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-d5cb944a-0cc0-4fc0-9a4d-e71e6a98558e,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-a950e910-4ace-47ad-bac5-179f328d5e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-a47796ca-cddf-41ca-bcfa-c12cd0baec4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-3a4c1d6a-70f7-4443-a94a-23fcb965ac97,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-8ea8a61b-779b-45c8-a1c2-ba3894db0524,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-1497fc1a-d5ad-4dae-955c-671acad6fae9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-634601520-172.17.0.11-1595932153335:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44214,DS-a7e353d4-6c5b-467a-bc47-d7b519b65e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43448,DS-3ff67a0c-3fa2-4915-a587-484c6c4f7197,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-d5cb944a-0cc0-4fc0-9a4d-e71e6a98558e,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-a950e910-4ace-47ad-bac5-179f328d5e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-a47796ca-cddf-41ca-bcfa-c12cd0baec4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-3a4c1d6a-70f7-4443-a94a-23fcb965ac97,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-8ea8a61b-779b-45c8-a1c2-ba3894db0524,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-1497fc1a-d5ad-4dae-955c-671acad6fae9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-584585772-172.17.0.11-1595932366123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35255,DS-7e5a708c-d3a0-4b97-a3da-2e91acf2518c,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-6ab458bc-783e-42e6-b30e-d42f5a07f86b,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-cf96aafc-78b4-4963-ac73-8c2a2eaa2626,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-5cc78017-0cf3-4765-bf9b-c13569456e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-d14bacf8-5be4-4a43-b400-9ed29c2e631b,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-41a046e8-16ff-4947-b8e0-7bb171e78c98,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-359d79b1-d12d-4bf7-b0ae-7aebb19f9df0,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-61f61ee8-393b-42eb-ada4-598e0c2f20ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-584585772-172.17.0.11-1595932366123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35255,DS-7e5a708c-d3a0-4b97-a3da-2e91acf2518c,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-6ab458bc-783e-42e6-b30e-d42f5a07f86b,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-cf96aafc-78b4-4963-ac73-8c2a2eaa2626,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-5cc78017-0cf3-4765-bf9b-c13569456e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-d14bacf8-5be4-4a43-b400-9ed29c2e631b,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-41a046e8-16ff-4947-b8e0-7bb171e78c98,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-359d79b1-d12d-4bf7-b0ae-7aebb19f9df0,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-61f61ee8-393b-42eb-ada4-598e0c2f20ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1494740135-172.17.0.11-1595933159798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42472,DS-4dd37b22-6994-47ef-b93c-560f95e01e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-1af633ae-d176-4c76-b61d-4b410db2b49a,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-f12a11b9-0a48-4194-a95d-b757fc127de7,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-ecae45d7-e79f-4f84-a184-25e539da6239,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-11ec3416-b363-4823-8e7d-941e3e979c00,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-54f2c1ab-00ac-4231-8e2a-517d649acb47,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-d30bd3a9-a896-4d10-9e73-78179b2c73a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-32eda90c-0d0e-475b-852b-a588901419c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1494740135-172.17.0.11-1595933159798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42472,DS-4dd37b22-6994-47ef-b93c-560f95e01e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-1af633ae-d176-4c76-b61d-4b410db2b49a,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-f12a11b9-0a48-4194-a95d-b757fc127de7,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-ecae45d7-e79f-4f84-a184-25e539da6239,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-11ec3416-b363-4823-8e7d-941e3e979c00,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-54f2c1ab-00ac-4231-8e2a-517d649acb47,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-d30bd3a9-a896-4d10-9e73-78179b2c73a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-32eda90c-0d0e-475b-852b-a588901419c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-92162047-172.17.0.11-1595933197758:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36128,DS-663c505c-cc4f-4bbc-a4d2-b0a4355e59ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-ca761721-255e-4ed3-a88c-70247b9fddbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-85c83127-6eb7-4f58-a32e-c119ea79b0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42953,DS-adc9a379-be72-40e8-b308-9121125ae7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-c7cfe814-d328-49b0-8783-1786cc288568,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-b5aea852-0f18-4ed3-b906-8ed34df74ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-f226c2cd-908a-4dad-9bf1-7ae6059d7b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-2b579d2c-a742-4af0-b00a-9b11e58feb04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-92162047-172.17.0.11-1595933197758:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36128,DS-663c505c-cc4f-4bbc-a4d2-b0a4355e59ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-ca761721-255e-4ed3-a88c-70247b9fddbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-85c83127-6eb7-4f58-a32e-c119ea79b0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42953,DS-adc9a379-be72-40e8-b308-9121125ae7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-c7cfe814-d328-49b0-8783-1786cc288568,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-b5aea852-0f18-4ed3-b906-8ed34df74ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-f226c2cd-908a-4dad-9bf1-7ae6059d7b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-2b579d2c-a742-4af0-b00a-9b11e58feb04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-630684792-172.17.0.11-1595933704155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41099,DS-e40164c4-2dc1-4cc1-a7bb-b7dae3ff8c63,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-2cf22a65-4812-4881-8ca3-0a350fa0a8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40927,DS-77474044-4cce-4c21-895c-b2c46fb9bfff,DISK], DatanodeInfoWithStorage[127.0.0.1:41658,DS-5f90a062-5889-4e5c-9b0e-b8b99ea3c45f,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-c3306560-7d5d-45e2-a854-c1f6b7c016f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-9676a762-2805-4d2b-9366-e6be6c625d64,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-f21ac263-2bc6-4c23-adb6-8bfe5484bd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-47a2bff0-f5e5-49fc-b224-8dee14b88e17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-630684792-172.17.0.11-1595933704155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41099,DS-e40164c4-2dc1-4cc1-a7bb-b7dae3ff8c63,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-2cf22a65-4812-4881-8ca3-0a350fa0a8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40927,DS-77474044-4cce-4c21-895c-b2c46fb9bfff,DISK], DatanodeInfoWithStorage[127.0.0.1:41658,DS-5f90a062-5889-4e5c-9b0e-b8b99ea3c45f,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-c3306560-7d5d-45e2-a854-c1f6b7c016f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-9676a762-2805-4d2b-9366-e6be6c625d64,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-f21ac263-2bc6-4c23-adb6-8bfe5484bd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-47a2bff0-f5e5-49fc-b224-8dee14b88e17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-298840603-172.17.0.11-1595934143273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35156,DS-0ae0214a-29d3-4fae-a8cc-7d53b387a4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-80dc59f5-cea8-47c5-9cf1-51541c92751a,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-dedc1c56-8d11-4983-876a-1fe4c3f5a8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-9ec7d8bf-12f0-4abd-96a9-4d015d87c88e,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-d5a79fd7-92d9-42ee-961b-ba52a652154e,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-91884df2-b088-43bd-b044-4f42e2e116cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-28e5b17a-a042-4a3e-a774-8c9560ca841a,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-f02a3b84-7b4e-490f-a113-fee7d178f9db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-298840603-172.17.0.11-1595934143273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35156,DS-0ae0214a-29d3-4fae-a8cc-7d53b387a4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-80dc59f5-cea8-47c5-9cf1-51541c92751a,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-dedc1c56-8d11-4983-876a-1fe4c3f5a8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-9ec7d8bf-12f0-4abd-96a9-4d015d87c88e,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-d5a79fd7-92d9-42ee-961b-ba52a652154e,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-91884df2-b088-43bd-b044-4f42e2e116cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-28e5b17a-a042-4a3e-a774-8c9560ca841a,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-f02a3b84-7b4e-490f-a113-fee7d178f9db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1301151004-172.17.0.11-1595934272328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36807,DS-d10772c8-ee78-45ec-9c49-32917901debe,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-b28a6805-1305-4500-830f-ae8070b22f81,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-02d543ec-4aed-4d87-a472-d0684fdc4131,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-69012113-90f5-4018-a95d-d8441b88b5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-ed700011-ac65-4011-8f87-877b4bf99110,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-b4a7d65c-3605-42aa-bc44-251c48841f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-004834dd-ea66-4678-a221-8689df15cf36,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-ed81dd72-0310-4f6b-a2a6-5d2da058bf57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1301151004-172.17.0.11-1595934272328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36807,DS-d10772c8-ee78-45ec-9c49-32917901debe,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-b28a6805-1305-4500-830f-ae8070b22f81,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-02d543ec-4aed-4d87-a472-d0684fdc4131,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-69012113-90f5-4018-a95d-d8441b88b5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-ed700011-ac65-4011-8f87-877b4bf99110,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-b4a7d65c-3605-42aa-bc44-251c48841f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-004834dd-ea66-4678-a221-8689df15cf36,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-ed81dd72-0310-4f6b-a2a6-5d2da058bf57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-642061373-172.17.0.11-1595934742032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39493,DS-dadec2e9-aa92-4544-b27f-bfe4e800417a,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-2773bfdf-cb37-441e-af44-cfe411617c05,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-448455bf-8c52-48b3-a302-784adf3e642a,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-e41bdc10-250b-4881-bd14-b2bf1e7bc575,DISK], DatanodeInfoWithStorage[127.0.0.1:42464,DS-4d4c6377-5b2b-4535-b498-e445de9e4162,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-52928329-36e5-402d-8105-6a0f830b92e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-de73fe1f-3495-40c3-9adf-b5adb15b6137,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-3a00d380-58f8-4a1f-b56f-0d74e63e1e9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-642061373-172.17.0.11-1595934742032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39493,DS-dadec2e9-aa92-4544-b27f-bfe4e800417a,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-2773bfdf-cb37-441e-af44-cfe411617c05,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-448455bf-8c52-48b3-a302-784adf3e642a,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-e41bdc10-250b-4881-bd14-b2bf1e7bc575,DISK], DatanodeInfoWithStorage[127.0.0.1:42464,DS-4d4c6377-5b2b-4535-b498-e445de9e4162,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-52928329-36e5-402d-8105-6a0f830b92e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-de73fe1f-3495-40c3-9adf-b5adb15b6137,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-3a00d380-58f8-4a1f-b56f-0d74e63e1e9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1942966703-172.17.0.11-1595935451174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44150,DS-16299980-1943-481c-a421-d7fc70a174bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-d7ce2ce8-865f-45d2-a48a-ecffb25e2896,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-5b702257-8397-457a-bb95-2ad5eca64ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-bd7320cf-3aef-4066-92c3-db99f0bb5849,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-12088917-cc1e-4528-9ee4-4aa33a4fcd43,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-4ab9362d-749a-4e06-a7b9-50d36afc0ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-921261d9-45f7-4906-b186-3baac73d5f58,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-b92d0bf1-f081-44a6-9330-16d0e4ffbf66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1942966703-172.17.0.11-1595935451174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44150,DS-16299980-1943-481c-a421-d7fc70a174bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-d7ce2ce8-865f-45d2-a48a-ecffb25e2896,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-5b702257-8397-457a-bb95-2ad5eca64ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-bd7320cf-3aef-4066-92c3-db99f0bb5849,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-12088917-cc1e-4528-9ee4-4aa33a4fcd43,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-4ab9362d-749a-4e06-a7b9-50d36afc0ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-921261d9-45f7-4906-b186-3baac73d5f58,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-b92d0bf1-f081-44a6-9330-16d0e4ffbf66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1433297962-172.17.0.11-1595935494656:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44314,DS-b787153d-c9ae-44de-a522-a11236fae5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-6ad611c3-ca5c-4d79-9ad8-c0d7c9914549,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-329d2599-9252-4a71-a47c-9cdd0b6e0706,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-bdee3474-1ee5-48ec-ab0e-c6de934b1ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-6ab436f0-2973-4238-908f-0401b68b230a,DISK], DatanodeInfoWithStorage[127.0.0.1:33135,DS-79cdd5a1-e721-4ab3-8a69-508181dd0913,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-fcd08153-a122-4345-abdb-2e8de20d0145,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-56d784f1-ff0d-4403-8750-428200b03178,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1433297962-172.17.0.11-1595935494656:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44314,DS-b787153d-c9ae-44de-a522-a11236fae5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-6ad611c3-ca5c-4d79-9ad8-c0d7c9914549,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-329d2599-9252-4a71-a47c-9cdd0b6e0706,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-bdee3474-1ee5-48ec-ab0e-c6de934b1ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-6ab436f0-2973-4238-908f-0401b68b230a,DISK], DatanodeInfoWithStorage[127.0.0.1:33135,DS-79cdd5a1-e721-4ab3-8a69-508181dd0913,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-fcd08153-a122-4345-abdb-2e8de20d0145,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-56d784f1-ff0d-4403-8750-428200b03178,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1281121853-172.17.0.11-1595936092874:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35768,DS-1c64fe6a-fa14-4271-89a9-4569228c2f13,DISK], DatanodeInfoWithStorage[127.0.0.1:39807,DS-8afdc143-598d-4954-a0ef-f3c7753c2068,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-7e412aa3-70e5-4b00-bebf-b8e9556a1f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37933,DS-59048c55-35d3-48f5-a2af-a722da56b8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-f5b4ac18-81d6-4671-9b65-4dd002fd00f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-0bd43a6a-a66e-4ce7-9f99-cc970972de91,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-5c5654d2-3d4b-410b-803e-4e397ff40977,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-06dca50c-fec1-4ef3-a34b-422bb7a3b088,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1281121853-172.17.0.11-1595936092874:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35768,DS-1c64fe6a-fa14-4271-89a9-4569228c2f13,DISK], DatanodeInfoWithStorage[127.0.0.1:39807,DS-8afdc143-598d-4954-a0ef-f3c7753c2068,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-7e412aa3-70e5-4b00-bebf-b8e9556a1f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37933,DS-59048c55-35d3-48f5-a2af-a722da56b8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-f5b4ac18-81d6-4671-9b65-4dd002fd00f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-0bd43a6a-a66e-4ce7-9f99-cc970972de91,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-5c5654d2-3d4b-410b-803e-4e397ff40977,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-06dca50c-fec1-4ef3-a34b-422bb7a3b088,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1394743464-172.17.0.11-1595936359198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41756,DS-1eab16fd-9cbb-4853-845a-ab1b1ffb56fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-db4fce42-7104-4e3e-b0c9-385c758bcc23,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-4ba07ca5-790e-4a32-962c-16518e8efb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-81a1d425-8af8-41d0-b2ee-560d9f5fb91b,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-adce222b-a29e-4497-af6c-2d3fca82e83b,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-36583a34-3065-4cac-af88-4e1aa73692f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-4176c16a-1153-4ad1-a3fe-c3fa70ed7b34,DISK], DatanodeInfoWithStorage[127.0.0.1:46613,DS-ce6a03d5-7c86-492c-8dcb-dfdcc2ef309a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1394743464-172.17.0.11-1595936359198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41756,DS-1eab16fd-9cbb-4853-845a-ab1b1ffb56fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-db4fce42-7104-4e3e-b0c9-385c758bcc23,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-4ba07ca5-790e-4a32-962c-16518e8efb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-81a1d425-8af8-41d0-b2ee-560d9f5fb91b,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-adce222b-a29e-4497-af6c-2d3fca82e83b,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-36583a34-3065-4cac-af88-4e1aa73692f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-4176c16a-1153-4ad1-a3fe-c3fa70ed7b34,DISK], DatanodeInfoWithStorage[127.0.0.1:46613,DS-ce6a03d5-7c86-492c-8dcb-dfdcc2ef309a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1019261048-172.17.0.11-1595936593615:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44467,DS-98bd443e-b0c7-425a-a815-47a0beb9e760,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-078c272f-9e91-4dde-acf3-a25e525093b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-c36bf938-0534-4f88-9601-6d26e5463dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:45823,DS-0a505f74-0c06-4f9d-b37e-2c5f280c9a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-15b16db6-a364-46fb-852d-f5cbcca8300a,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-a8647187-d644-4f4a-b2ff-6a8d0ab212a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-291c2b20-d8b9-439a-8a1f-7fe6fee97987,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-71b612ee-dc87-4ea3-b654-96309e33c1d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1019261048-172.17.0.11-1595936593615:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44467,DS-98bd443e-b0c7-425a-a815-47a0beb9e760,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-078c272f-9e91-4dde-acf3-a25e525093b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-c36bf938-0534-4f88-9601-6d26e5463dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:45823,DS-0a505f74-0c06-4f9d-b37e-2c5f280c9a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-15b16db6-a364-46fb-852d-f5cbcca8300a,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-a8647187-d644-4f4a-b2ff-6a8d0ab212a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-291c2b20-d8b9-439a-8a1f-7fe6fee97987,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-71b612ee-dc87-4ea3-b654-96309e33c1d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1313222651-172.17.0.11-1595937310192:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35342,DS-2490bd55-5c89-402f-b358-1bd9ad2de834,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-a5047aee-686f-4d64-8a09-e9e6104ec683,DISK], DatanodeInfoWithStorage[127.0.0.1:37784,DS-5432af2f-4943-439d-b55b-ee33f658b422,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-5a2670c1-3e11-4fd2-af3a-47df8e0b47f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-0bbcff20-cb26-42de-9b5d-2f19110551d2,DISK], DatanodeInfoWithStorage[127.0.0.1:32774,DS-2eefc18a-d18f-4c2a-beb7-38c88c4deea1,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-a4691513-b1c8-4b68-9c7e-9ebdbe225ede,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-084f82a0-80b1-48c4-be5f-c520ee669660,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1313222651-172.17.0.11-1595937310192:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35342,DS-2490bd55-5c89-402f-b358-1bd9ad2de834,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-a5047aee-686f-4d64-8a09-e9e6104ec683,DISK], DatanodeInfoWithStorage[127.0.0.1:37784,DS-5432af2f-4943-439d-b55b-ee33f658b422,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-5a2670c1-3e11-4fd2-af3a-47df8e0b47f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-0bbcff20-cb26-42de-9b5d-2f19110551d2,DISK], DatanodeInfoWithStorage[127.0.0.1:32774,DS-2eefc18a-d18f-4c2a-beb7-38c88c4deea1,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-a4691513-b1c8-4b68-9c7e-9ebdbe225ede,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-084f82a0-80b1-48c4-be5f-c520ee669660,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-183654598-172.17.0.11-1595937447769:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42582,DS-cd3c479a-193c-4348-af50-06338f64480a,DISK], DatanodeInfoWithStorage[127.0.0.1:46731,DS-bc337178-7fa6-4716-91e1-05a7d4626096,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-e1ef4d2f-f72a-4b4d-b6bb-66e3ab6911d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-4dd08914-3c6e-40cb-b769-278f05ff8285,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-8e737426-c294-48c6-8b65-79e4b803eecf,DISK], DatanodeInfoWithStorage[127.0.0.1:34046,DS-65f1db06-f40b-4566-828a-ef3b57d59c75,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-11331274-1632-49ec-ba1f-9a0026d83776,DISK], DatanodeInfoWithStorage[127.0.0.1:37024,DS-5346802c-5528-4e85-9ec6-eaa354dd3560,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-183654598-172.17.0.11-1595937447769:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42582,DS-cd3c479a-193c-4348-af50-06338f64480a,DISK], DatanodeInfoWithStorage[127.0.0.1:46731,DS-bc337178-7fa6-4716-91e1-05a7d4626096,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-e1ef4d2f-f72a-4b4d-b6bb-66e3ab6911d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-4dd08914-3c6e-40cb-b769-278f05ff8285,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-8e737426-c294-48c6-8b65-79e4b803eecf,DISK], DatanodeInfoWithStorage[127.0.0.1:34046,DS-65f1db06-f40b-4566-828a-ef3b57d59c75,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-11331274-1632-49ec-ba1f-9a0026d83776,DISK], DatanodeInfoWithStorage[127.0.0.1:37024,DS-5346802c-5528-4e85-9ec6-eaa354dd3560,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1120232815-172.17.0.11-1595937524254:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39554,DS-7320d13e-df17-40f1-a005-cc510764b664,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-1f07f5cd-56fb-41a1-8d1c-5077573f5df3,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-3a342197-a53d-4cf9-9d8f-4d2daf5d0bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-66ee5d8e-d93f-4656-9b6e-ae513f4c248e,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-d60f22f3-a0a1-4292-9363-9c2a23c9da0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-ee8e0347-877f-4bb8-bcf9-808808f833ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-825d97aa-ddb3-4a79-b806-0f2eb52b2c30,DISK], DatanodeInfoWithStorage[127.0.0.1:42905,DS-aba887f0-0e2a-4e78-beec-8054973ec2f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1120232815-172.17.0.11-1595937524254:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39554,DS-7320d13e-df17-40f1-a005-cc510764b664,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-1f07f5cd-56fb-41a1-8d1c-5077573f5df3,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-3a342197-a53d-4cf9-9d8f-4d2daf5d0bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-66ee5d8e-d93f-4656-9b6e-ae513f4c248e,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-d60f22f3-a0a1-4292-9363-9c2a23c9da0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-ee8e0347-877f-4bb8-bcf9-808808f833ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-825d97aa-ddb3-4a79-b806-0f2eb52b2c30,DISK], DatanodeInfoWithStorage[127.0.0.1:42905,DS-aba887f0-0e2a-4e78-beec-8054973ec2f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1026062441-172.17.0.11-1595937621089:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33897,DS-2dc3ffde-6ba3-4e3c-b161-6b01778d0c23,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-01212fd2-d985-48f4-9820-9ad97d0840cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-d107bf9b-3c90-4348-815e-42ac2f15e1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-dbdaee76-d512-4ce0-babd-fad8318c9b12,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-1ed4cd78-ced7-4e32-ba29-145817a19641,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-7f8347b8-0bb7-4325-8bc7-a1988eccfb65,DISK], DatanodeInfoWithStorage[127.0.0.1:42358,DS-00ad907b-3675-4872-9a11-f12c05f93a96,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-34d34c5d-5f2a-4c8b-985d-4328a45e9fc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1026062441-172.17.0.11-1595937621089:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33897,DS-2dc3ffde-6ba3-4e3c-b161-6b01778d0c23,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-01212fd2-d985-48f4-9820-9ad97d0840cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-d107bf9b-3c90-4348-815e-42ac2f15e1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-dbdaee76-d512-4ce0-babd-fad8318c9b12,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-1ed4cd78-ced7-4e32-ba29-145817a19641,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-7f8347b8-0bb7-4325-8bc7-a1988eccfb65,DISK], DatanodeInfoWithStorage[127.0.0.1:42358,DS-00ad907b-3675-4872-9a11-f12c05f93a96,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-34d34c5d-5f2a-4c8b-985d-4328a45e9fc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-200675982-172.17.0.11-1595938248603:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44250,DS-b8a5352f-a869-4645-8501-f2a188dae440,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-bf374929-9f0b-46d7-96f8-a589fbda21d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-ab9cf543-0975-435a-b407-6eaa1cd4671d,DISK], DatanodeInfoWithStorage[127.0.0.1:39877,DS-673adb84-1ee3-4d96-8e27-0ac596683d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45276,DS-7afbdcaf-7973-4627-b0c8-2ec7cb1a1cba,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-5c61ba93-1142-4639-a10b-977eaec850d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-db4d0617-e5f0-4675-8238-57cfe7132d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34924,DS-e960c47b-9f28-40f6-8b41-5994657f05bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-200675982-172.17.0.11-1595938248603:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44250,DS-b8a5352f-a869-4645-8501-f2a188dae440,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-bf374929-9f0b-46d7-96f8-a589fbda21d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-ab9cf543-0975-435a-b407-6eaa1cd4671d,DISK], DatanodeInfoWithStorage[127.0.0.1:39877,DS-673adb84-1ee3-4d96-8e27-0ac596683d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45276,DS-7afbdcaf-7973-4627-b0c8-2ec7cb1a1cba,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-5c61ba93-1142-4639-a10b-977eaec850d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-db4d0617-e5f0-4675-8238-57cfe7132d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34924,DS-e960c47b-9f28-40f6-8b41-5994657f05bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6639
