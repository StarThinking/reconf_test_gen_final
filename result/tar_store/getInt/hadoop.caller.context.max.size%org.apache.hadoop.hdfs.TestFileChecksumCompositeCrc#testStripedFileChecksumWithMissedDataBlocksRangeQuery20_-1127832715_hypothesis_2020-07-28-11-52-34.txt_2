reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-402043335-172.17.0.5-1595937823813:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41555,DS-37d4e188-1cb5-4f07-b241-fba016748b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-524072d7-e075-476a-9592-66e8009c9dea,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-1b42200e-3522-4891-af39-c46dd5f56024,DISK], DatanodeInfoWithStorage[127.0.0.1:39829,DS-0cead6fb-782a-4ddb-8080-7c4585d2f5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-283a865f-ffe2-4961-b077-adf177b5e94a,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-a6b30e78-e769-41d7-aed5-9ca25c2f486e,DISK], DatanodeInfoWithStorage[127.0.0.1:34974,DS-5101ab5b-313e-406c-bd94-b1e3a9334c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-51bdcf9b-c785-4773-9dc5-05ffa1148a16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-402043335-172.17.0.5-1595937823813:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41555,DS-37d4e188-1cb5-4f07-b241-fba016748b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-524072d7-e075-476a-9592-66e8009c9dea,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-1b42200e-3522-4891-af39-c46dd5f56024,DISK], DatanodeInfoWithStorage[127.0.0.1:39829,DS-0cead6fb-782a-4ddb-8080-7c4585d2f5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-283a865f-ffe2-4961-b077-adf177b5e94a,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-a6b30e78-e769-41d7-aed5-9ca25c2f486e,DISK], DatanodeInfoWithStorage[127.0.0.1:34974,DS-5101ab5b-313e-406c-bd94-b1e3a9334c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-51bdcf9b-c785-4773-9dc5-05ffa1148a16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1507056819-172.17.0.5-1595937902699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35118,DS-f6be855b-06d3-41a3-95df-5fa7e5badebd,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-f74ee852-69f0-4eaa-8c92-d03e14257d23,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-d711a684-dd53-41fa-b424-4d3072bce3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43213,DS-87fbd89e-9f11-48a1-b026-dbc4ed6cd6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-31f41bad-7773-4bb7-a3c5-2b786a908b84,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-e33ae5ea-dcaf-4978-98e3-d9ddacb7261f,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-41382fac-7ef8-43d5-b404-840886134795,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-5539566d-8d25-46c4-a83b-f87e18c23554,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1507056819-172.17.0.5-1595937902699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35118,DS-f6be855b-06d3-41a3-95df-5fa7e5badebd,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-f74ee852-69f0-4eaa-8c92-d03e14257d23,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-d711a684-dd53-41fa-b424-4d3072bce3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43213,DS-87fbd89e-9f11-48a1-b026-dbc4ed6cd6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-31f41bad-7773-4bb7-a3c5-2b786a908b84,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-e33ae5ea-dcaf-4978-98e3-d9ddacb7261f,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-41382fac-7ef8-43d5-b404-840886134795,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-5539566d-8d25-46c4-a83b-f87e18c23554,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-316116404-172.17.0.5-1595938010375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42247,DS-43d06b92-464e-4c4b-9304-ed1db40dd8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-a1376efe-ca8f-4986-a7a9-c6bb4253b880,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-7f0035ad-bbcb-4323-adb3-165b9023d669,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-1afc6a83-2d70-4e45-b749-71524d8c963f,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-ba4588f0-2274-41fb-a063-329a1bdbb91a,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-1d9d70d9-d341-4f93-81fe-346cbb9e255b,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-6e182c8e-bbfd-4671-9a45-dec5abcfb53c,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-0a5a981a-1b8d-471e-925e-ed4f4ee6f240,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-316116404-172.17.0.5-1595938010375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42247,DS-43d06b92-464e-4c4b-9304-ed1db40dd8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-a1376efe-ca8f-4986-a7a9-c6bb4253b880,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-7f0035ad-bbcb-4323-adb3-165b9023d669,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-1afc6a83-2d70-4e45-b749-71524d8c963f,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-ba4588f0-2274-41fb-a063-329a1bdbb91a,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-1d9d70d9-d341-4f93-81fe-346cbb9e255b,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-6e182c8e-bbfd-4671-9a45-dec5abcfb53c,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-0a5a981a-1b8d-471e-925e-ed4f4ee6f240,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-191124259-172.17.0.5-1595938659088:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43086,DS-7c83c723-77bc-4bfc-92ac-97fb14a7e3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-8234d8ec-b47f-44b2-b823-4d8910f31856,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-eac7648c-6d2e-40be-b1c6-0fa9c75fdf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-5a9960b3-510c-4675-a4d7-70e526930fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-71fc7f97-5f44-4db0-909d-57681877d874,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-9fbab18a-0ae3-438b-bf8b-3b1404db47ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-7047961b-8940-416e-b28a-bb07b5414b83,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-3d4d3515-f312-4948-bc9b-a24717d9f0e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-191124259-172.17.0.5-1595938659088:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43086,DS-7c83c723-77bc-4bfc-92ac-97fb14a7e3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-8234d8ec-b47f-44b2-b823-4d8910f31856,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-eac7648c-6d2e-40be-b1c6-0fa9c75fdf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-5a9960b3-510c-4675-a4d7-70e526930fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-71fc7f97-5f44-4db0-909d-57681877d874,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-9fbab18a-0ae3-438b-bf8b-3b1404db47ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-7047961b-8940-416e-b28a-bb07b5414b83,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-3d4d3515-f312-4948-bc9b-a24717d9f0e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-302595197-172.17.0.5-1595938904680:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41369,DS-feb389ff-ee18-443b-a02b-56944c1c2355,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-d8f380ee-cc0c-4fe9-8b67-8dbd9358fce3,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-33e1a3f9-bd5b-47b2-b564-42aecf1ec3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-b2a23101-2123-4c4b-8c31-1e5b73f9a86a,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-cf0c4c91-07e3-4cd8-8118-f92fa503744b,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-879919eb-037e-4022-9a47-8317de963a61,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-66373291-6a91-4d22-abe9-4cb950b971d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-1c4c5c3a-be1a-4324-ab96-7b76bdc32e6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-302595197-172.17.0.5-1595938904680:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41369,DS-feb389ff-ee18-443b-a02b-56944c1c2355,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-d8f380ee-cc0c-4fe9-8b67-8dbd9358fce3,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-33e1a3f9-bd5b-47b2-b564-42aecf1ec3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-b2a23101-2123-4c4b-8c31-1e5b73f9a86a,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-cf0c4c91-07e3-4cd8-8118-f92fa503744b,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-879919eb-037e-4022-9a47-8317de963a61,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-66373291-6a91-4d22-abe9-4cb950b971d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-1c4c5c3a-be1a-4324-ab96-7b76bdc32e6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-761385884-172.17.0.5-1595939142361:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45884,DS-b79cd6e4-2042-40e5-8b98-545ac79a46b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-1a767ce8-9525-4ec7-85ed-e6dde51f1e91,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-189c2548-f422-4881-a3c6-8d17de14a08f,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-9a2a422c-0387-40d5-a79a-23e705a6d9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-5c99f07a-2cf1-4e87-a5d8-1881149f4556,DISK], DatanodeInfoWithStorage[127.0.0.1:41244,DS-78472589-1fe4-4177-a1cb-5f8f167c5096,DISK], DatanodeInfoWithStorage[127.0.0.1:41380,DS-8d9e1f5c-8cf6-4712-9339-5c54a2742f62,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-c951d1f3-f5af-41e5-952b-009376aea0bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-761385884-172.17.0.5-1595939142361:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45884,DS-b79cd6e4-2042-40e5-8b98-545ac79a46b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-1a767ce8-9525-4ec7-85ed-e6dde51f1e91,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-189c2548-f422-4881-a3c6-8d17de14a08f,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-9a2a422c-0387-40d5-a79a-23e705a6d9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-5c99f07a-2cf1-4e87-a5d8-1881149f4556,DISK], DatanodeInfoWithStorage[127.0.0.1:41244,DS-78472589-1fe4-4177-a1cb-5f8f167c5096,DISK], DatanodeInfoWithStorage[127.0.0.1:41380,DS-8d9e1f5c-8cf6-4712-9339-5c54a2742f62,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-c951d1f3-f5af-41e5-952b-009376aea0bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1651598569-172.17.0.5-1595939175163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36212,DS-8e950155-40ab-4f89-a8aa-c8d008c09c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38399,DS-f84d89a7-b5c3-4005-b449-ebb4b54f7cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37930,DS-892f48e6-0b8f-4487-96b6-8a9d5a7e894d,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-a055e7eb-2af0-4d76-8a89-0c22ca99f315,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-370cdd7a-8d7f-4327-8822-96b463da06a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-ca8721e9-eacf-4583-9227-8822ac788263,DISK], DatanodeInfoWithStorage[127.0.0.1:34434,DS-a415d894-d336-417f-817e-2829803e0be0,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-7e56f0e4-5ccc-4d09-88f0-a1bf47f79c30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1651598569-172.17.0.5-1595939175163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36212,DS-8e950155-40ab-4f89-a8aa-c8d008c09c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38399,DS-f84d89a7-b5c3-4005-b449-ebb4b54f7cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37930,DS-892f48e6-0b8f-4487-96b6-8a9d5a7e894d,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-a055e7eb-2af0-4d76-8a89-0c22ca99f315,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-370cdd7a-8d7f-4327-8822-96b463da06a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-ca8721e9-eacf-4583-9227-8822ac788263,DISK], DatanodeInfoWithStorage[127.0.0.1:34434,DS-a415d894-d336-417f-817e-2829803e0be0,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-7e56f0e4-5ccc-4d09-88f0-a1bf47f79c30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1942293129-172.17.0.5-1595940809427:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46227,DS-89d91024-bd98-4e7b-830a-7b71affc4b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-1635163e-4e8e-4a90-ab05-717b97a6c539,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-33194f09-cab0-4ea2-ab35-6a63212030cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45646,DS-002e6c02-5e81-4b21-a361-fdf7439b0f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-b32da029-1a4e-4f3c-b1b0-ecdc072a767f,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-090c7c63-9a2f-4184-a484-1d87ebc5526d,DISK], DatanodeInfoWithStorage[127.0.0.1:44283,DS-d6c0c936-42f2-4e60-a5b6-b84b962d1810,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-3ef62e0f-bc76-452d-9502-43b3dc2d7050,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1942293129-172.17.0.5-1595940809427:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46227,DS-89d91024-bd98-4e7b-830a-7b71affc4b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-1635163e-4e8e-4a90-ab05-717b97a6c539,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-33194f09-cab0-4ea2-ab35-6a63212030cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45646,DS-002e6c02-5e81-4b21-a361-fdf7439b0f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-b32da029-1a4e-4f3c-b1b0-ecdc072a767f,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-090c7c63-9a2f-4184-a484-1d87ebc5526d,DISK], DatanodeInfoWithStorage[127.0.0.1:44283,DS-d6c0c936-42f2-4e60-a5b6-b84b962d1810,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-3ef62e0f-bc76-452d-9502-43b3dc2d7050,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1611098288-172.17.0.5-1595940870198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33708,DS-e27024cd-8ea2-4d3d-a579-a0a12dd90a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-0ae6086c-0355-43da-ad48-0cef91f73262,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-13a60824-0f9d-438f-b51c-173dd4780ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-2df85783-1edc-4f43-9111-4cb33df52a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-ca988d51-30cb-423d-9643-28024c855f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-3ef3d8e3-9101-4bc1-a083-e98580a41615,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-d4806cb7-133a-4db9-aaed-a57711626f79,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-7c97632c-481f-408f-82c4-d3347a19c3e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1611098288-172.17.0.5-1595940870198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33708,DS-e27024cd-8ea2-4d3d-a579-a0a12dd90a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-0ae6086c-0355-43da-ad48-0cef91f73262,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-13a60824-0f9d-438f-b51c-173dd4780ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-2df85783-1edc-4f43-9111-4cb33df52a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-ca988d51-30cb-423d-9643-28024c855f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-3ef3d8e3-9101-4bc1-a083-e98580a41615,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-d4806cb7-133a-4db9-aaed-a57711626f79,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-7c97632c-481f-408f-82c4-d3347a19c3e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-230945695-172.17.0.5-1595940910658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40729,DS-19abd26b-07fe-4ad1-94fa-ca37c6632bce,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-9c4ad0b6-89e5-4f06-bec6-46314f0b0555,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-f5db215a-72c4-493f-957b-7d86b614c8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42191,DS-a065ef94-1338-481f-bf82-337a1e7929d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-964c6007-c1d6-48cd-9b88-1115a63a9e56,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-5ad1110a-ff07-46a1-8b29-c05a94fde52c,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-210cb59f-8558-47a7-9cd5-046a54cfa6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-7ecab1d2-4062-4235-b05d-7913b3eb5a2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-230945695-172.17.0.5-1595940910658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40729,DS-19abd26b-07fe-4ad1-94fa-ca37c6632bce,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-9c4ad0b6-89e5-4f06-bec6-46314f0b0555,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-f5db215a-72c4-493f-957b-7d86b614c8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42191,DS-a065ef94-1338-481f-bf82-337a1e7929d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-964c6007-c1d6-48cd-9b88-1115a63a9e56,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-5ad1110a-ff07-46a1-8b29-c05a94fde52c,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-210cb59f-8558-47a7-9cd5-046a54cfa6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-7ecab1d2-4062-4235-b05d-7913b3eb5a2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-713957442-172.17.0.5-1595941589679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44515,DS-61217cdb-76b6-465c-84ce-5dc738198936,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-a3896047-2715-43c1-a6f5-dbb427e1e55a,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-48246e80-0d61-4903-a114-b88a9250a44e,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-e304f115-5c07-4b76-b59d-5956a11361e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-7ab9cd5c-081b-4e04-bf56-3e544193bd5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-39575a4b-1c8c-4bee-a927-921570793f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-ede52e98-a78b-4e22-b948-5ae9b6c5cc2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-05526586-43c2-4279-b69e-9d2f556c2200,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-713957442-172.17.0.5-1595941589679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44515,DS-61217cdb-76b6-465c-84ce-5dc738198936,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-a3896047-2715-43c1-a6f5-dbb427e1e55a,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-48246e80-0d61-4903-a114-b88a9250a44e,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-e304f115-5c07-4b76-b59d-5956a11361e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-7ab9cd5c-081b-4e04-bf56-3e544193bd5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-39575a4b-1c8c-4bee-a927-921570793f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-ede52e98-a78b-4e22-b948-5ae9b6c5cc2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-05526586-43c2-4279-b69e-9d2f556c2200,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1704823161-172.17.0.5-1595941619332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40786,DS-53639323-f33a-4fc6-bb98-f28fba45a295,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-d7e792ed-0c78-4e00-be0e-b47175b4def7,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-6e19cf38-3b82-491b-84a2-97d399b23cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-57ec4954-17f6-478c-b358-4bc5216946a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-bef24135-6a8f-4165-8530-b7f8eafdcbf3,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-01e6ff34-c1a5-46b8-89eb-93d5e4113eef,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-5028dcbe-c75b-4e9e-9b5f-704f0daa5b73,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-7c86183d-903b-4897-9f15-4076f207fa21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1704823161-172.17.0.5-1595941619332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40786,DS-53639323-f33a-4fc6-bb98-f28fba45a295,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-d7e792ed-0c78-4e00-be0e-b47175b4def7,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-6e19cf38-3b82-491b-84a2-97d399b23cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-57ec4954-17f6-478c-b358-4bc5216946a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-bef24135-6a8f-4165-8530-b7f8eafdcbf3,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-01e6ff34-c1a5-46b8-89eb-93d5e4113eef,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-5028dcbe-c75b-4e9e-9b5f-704f0daa5b73,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-7c86183d-903b-4897-9f15-4076f207fa21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-670784555-172.17.0.5-1595942219698:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35577,DS-4e86ec4c-de2a-4223-95b9-224c47c54e86,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-ae4378f9-5f5b-4f26-af3c-48411b5ad3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-4b372139-d1c9-42ad-bac7-f1248f1d89c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-ce2bfe4f-b7ff-47b9-ad9a-129f3a85b7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-ae5eee48-293b-4fd5-b1da-d65cc06deca5,DISK], DatanodeInfoWithStorage[127.0.0.1:46042,DS-354062b7-ba8a-4379-b3de-b4089c0c0cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-73b57f9f-2e46-419c-b7eb-a48c21fa8711,DISK], DatanodeInfoWithStorage[127.0.0.1:37249,DS-78c8ebf1-ede9-4f70-ae7f-e0ecb57a7c41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-670784555-172.17.0.5-1595942219698:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35577,DS-4e86ec4c-de2a-4223-95b9-224c47c54e86,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-ae4378f9-5f5b-4f26-af3c-48411b5ad3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-4b372139-d1c9-42ad-bac7-f1248f1d89c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-ce2bfe4f-b7ff-47b9-ad9a-129f3a85b7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-ae5eee48-293b-4fd5-b1da-d65cc06deca5,DISK], DatanodeInfoWithStorage[127.0.0.1:46042,DS-354062b7-ba8a-4379-b3de-b4089c0c0cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-73b57f9f-2e46-419c-b7eb-a48c21fa8711,DISK], DatanodeInfoWithStorage[127.0.0.1:37249,DS-78c8ebf1-ede9-4f70-ae7f-e0ecb57a7c41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5214
