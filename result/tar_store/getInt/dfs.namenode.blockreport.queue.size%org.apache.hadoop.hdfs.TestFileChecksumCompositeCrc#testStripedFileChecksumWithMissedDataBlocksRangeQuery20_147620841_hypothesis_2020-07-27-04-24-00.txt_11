reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 2048
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 2048
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1070435155-172.17.0.10-1595823858149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39196,DS-35804dd2-ae90-4aa0-8098-616b8a045f45,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-ed187e83-c05d-498e-bc66-76208f3e56ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-d2ef6957-4b91-4d09-865c-1d4a2d865300,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-e1831242-91a6-4d4c-8baf-231f379d0fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-f2e494ab-dcf2-40c2-b9f4-49f2044d23e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-2272c27b-0324-472c-bc5d-51fcbd44c3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-18a28d06-4dda-475c-8151-ed0ebb89e4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-444b2938-5d34-4b7a-832d-bb6e0ed8bb90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1070435155-172.17.0.10-1595823858149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39196,DS-35804dd2-ae90-4aa0-8098-616b8a045f45,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-ed187e83-c05d-498e-bc66-76208f3e56ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-d2ef6957-4b91-4d09-865c-1d4a2d865300,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-e1831242-91a6-4d4c-8baf-231f379d0fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-f2e494ab-dcf2-40c2-b9f4-49f2044d23e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-2272c27b-0324-472c-bc5d-51fcbd44c3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-18a28d06-4dda-475c-8151-ed0ebb89e4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-444b2938-5d34-4b7a-832d-bb6e0ed8bb90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 2048
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1674382880-172.17.0.10-1595824308882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43513,DS-76c99bb1-83e9-4a5f-abae-a417522c5ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-7ff5456a-e3d8-4c8f-8a82-849556ae5e01,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-f15e6646-6859-4e93-b812-9440b18e8541,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-b0363e5c-c51e-4a9e-82b1-9aaec0e57d88,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-d22a1bb2-7c90-4206-9fed-7168e203b115,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-37e12946-5cce-4dbe-9d9e-dd5e660827e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-eee0f3dc-5238-41f5-b23e-f022ecabc2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-983b8b83-96c8-4760-9c0f-2564f8063afe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1674382880-172.17.0.10-1595824308882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43513,DS-76c99bb1-83e9-4a5f-abae-a417522c5ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-7ff5456a-e3d8-4c8f-8a82-849556ae5e01,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-f15e6646-6859-4e93-b812-9440b18e8541,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-b0363e5c-c51e-4a9e-82b1-9aaec0e57d88,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-d22a1bb2-7c90-4206-9fed-7168e203b115,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-37e12946-5cce-4dbe-9d9e-dd5e660827e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-eee0f3dc-5238-41f5-b23e-f022ecabc2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-983b8b83-96c8-4760-9c0f-2564f8063afe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 2048
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1128328696-172.17.0.10-1595824687076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37475,DS-dd3cee64-f467-44cd-a2a0-f0234e83434e,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-18424f0e-e12b-46a9-af8f-99b72b0bd35c,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-971c5bb4-c6a9-4063-a74c-70bccf93940e,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-1e498c12-b7ac-438b-b082-35295610a061,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-2cf5e8a5-6650-4d3d-8a09-11b9dc0006ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-5c7de8cd-e768-4d78-bcd7-b0e37af897e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-057d4a98-77aa-49f7-9e32-f8625d42cd24,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-ba34a8bf-92ae-4e7c-957f-61052dc58cb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1128328696-172.17.0.10-1595824687076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37475,DS-dd3cee64-f467-44cd-a2a0-f0234e83434e,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-18424f0e-e12b-46a9-af8f-99b72b0bd35c,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-971c5bb4-c6a9-4063-a74c-70bccf93940e,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-1e498c12-b7ac-438b-b082-35295610a061,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-2cf5e8a5-6650-4d3d-8a09-11b9dc0006ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-5c7de8cd-e768-4d78-bcd7-b0e37af897e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-057d4a98-77aa-49f7-9e32-f8625d42cd24,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-ba34a8bf-92ae-4e7c-957f-61052dc58cb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 2048
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1839309883-172.17.0.10-1595825326210:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44550,DS-71f09614-7e7a-4f2d-87ca-88cf8c0f1804,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-bb111974-d7fe-4f2f-9dff-bfaebad8c6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-3597e7b4-abe2-4bcb-83fd-79b7b823be32,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-ec17e951-6659-4314-9a8d-eb4582e29709,DISK], DatanodeInfoWithStorage[127.0.0.1:46416,DS-c7118c63-ce16-463f-9fb1-d135c2bd2555,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-3f4563ae-a27a-4e12-959a-e198eed50208,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-0ee933fe-5171-441c-8c44-00072e9b6487,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-b8a5f7a1-521f-4f18-89c9-e9a84c35f033,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1839309883-172.17.0.10-1595825326210:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44550,DS-71f09614-7e7a-4f2d-87ca-88cf8c0f1804,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-bb111974-d7fe-4f2f-9dff-bfaebad8c6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-3597e7b4-abe2-4bcb-83fd-79b7b823be32,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-ec17e951-6659-4314-9a8d-eb4582e29709,DISK], DatanodeInfoWithStorage[127.0.0.1:46416,DS-c7118c63-ce16-463f-9fb1-d135c2bd2555,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-3f4563ae-a27a-4e12-959a-e198eed50208,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-0ee933fe-5171-441c-8c44-00072e9b6487,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-b8a5f7a1-521f-4f18-89c9-e9a84c35f033,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 2048
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-899272523-172.17.0.10-1595825488257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46179,DS-7929d545-219d-46f4-9558-65216927311c,DISK], DatanodeInfoWithStorage[127.0.0.1:40909,DS-8d67ecdc-e03f-4578-80dd-671ed99e9a79,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-a7c4164e-a98f-4000-a68f-68d5fd75552d,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-73250a03-01b9-4050-89a9-e185016f31d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-07a9a29d-3763-49e9-b597-b54a9dee3877,DISK], DatanodeInfoWithStorage[127.0.0.1:38838,DS-1d8a57bc-3413-4c4e-9e3a-c766fcbfa71f,DISK], DatanodeInfoWithStorage[127.0.0.1:39085,DS-dac40a36-2a45-442f-bc95-869168d396be,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-88315a41-55d1-4985-a3a1-ce8e8434eca9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-899272523-172.17.0.10-1595825488257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46179,DS-7929d545-219d-46f4-9558-65216927311c,DISK], DatanodeInfoWithStorage[127.0.0.1:40909,DS-8d67ecdc-e03f-4578-80dd-671ed99e9a79,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-a7c4164e-a98f-4000-a68f-68d5fd75552d,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-73250a03-01b9-4050-89a9-e185016f31d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-07a9a29d-3763-49e9-b597-b54a9dee3877,DISK], DatanodeInfoWithStorage[127.0.0.1:38838,DS-1d8a57bc-3413-4c4e-9e3a-c766fcbfa71f,DISK], DatanodeInfoWithStorage[127.0.0.1:39085,DS-dac40a36-2a45-442f-bc95-869168d396be,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-88315a41-55d1-4985-a3a1-ce8e8434eca9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 2048
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-774161527-172.17.0.10-1595826183517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34378,DS-96ee6a8b-9f56-4d2c-9f44-e276d2b60c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-5d40d972-bbe0-4b05-8f9a-ca4452a2245e,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-14c78f4b-e014-477c-8a7c-07ade75b244b,DISK], DatanodeInfoWithStorage[127.0.0.1:36693,DS-a96931a3-d290-42b0-845a-e05b828d253c,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-da0d1326-30c6-4e33-a37e-2231df29fe76,DISK], DatanodeInfoWithStorage[127.0.0.1:46529,DS-f3e5c997-a7b3-4e11-ba2b-047f8ed9f333,DISK], DatanodeInfoWithStorage[127.0.0.1:40321,DS-78bff9b1-7d9d-482b-9a39-e06ced092897,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-2951ebe5-8387-47b1-a509-8fcfe43c8264,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-774161527-172.17.0.10-1595826183517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34378,DS-96ee6a8b-9f56-4d2c-9f44-e276d2b60c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-5d40d972-bbe0-4b05-8f9a-ca4452a2245e,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-14c78f4b-e014-477c-8a7c-07ade75b244b,DISK], DatanodeInfoWithStorage[127.0.0.1:36693,DS-a96931a3-d290-42b0-845a-e05b828d253c,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-da0d1326-30c6-4e33-a37e-2231df29fe76,DISK], DatanodeInfoWithStorage[127.0.0.1:46529,DS-f3e5c997-a7b3-4e11-ba2b-047f8ed9f333,DISK], DatanodeInfoWithStorage[127.0.0.1:40321,DS-78bff9b1-7d9d-482b-9a39-e06ced092897,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-2951ebe5-8387-47b1-a509-8fcfe43c8264,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 2048
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1695347511-172.17.0.10-1595826230152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37627,DS-986d6a22-a6ab-4fdb-8ca6-d7304ec6943c,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-b9d25fbb-5376-406f-8f21-f2577854016e,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-3921a1d2-9214-4b22-898e-086166013b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-770a06d0-640a-4220-858b-acdc9f36b10f,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-e54b67f8-118f-4841-b511-5e677be9f142,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-53712383-eee4-4a4c-9f9c-a40fafed5780,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-85d92e47-9d9d-4e36-b579-0cebaa241c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-e06ad3dd-ad48-41ea-9189-2ad7346bbc36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1695347511-172.17.0.10-1595826230152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37627,DS-986d6a22-a6ab-4fdb-8ca6-d7304ec6943c,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-b9d25fbb-5376-406f-8f21-f2577854016e,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-3921a1d2-9214-4b22-898e-086166013b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-770a06d0-640a-4220-858b-acdc9f36b10f,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-e54b67f8-118f-4841-b511-5e677be9f142,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-53712383-eee4-4a4c-9f9c-a40fafed5780,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-85d92e47-9d9d-4e36-b579-0cebaa241c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-e06ad3dd-ad48-41ea-9189-2ad7346bbc36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 2048
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2140854400-172.17.0.10-1595826355812:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41260,DS-d01c1d6a-2dd3-4071-a270-de8b6e843fba,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-b4e36792-1a5a-4bdb-89fc-24be80bb7bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-2daf049f-2bc2-466c-8784-0b9a2a6f36d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-c249da0c-80a5-467c-9354-dfc76452ece0,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-0307aa25-51de-4001-9ee1-bafe296fbd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-d5e23a92-7e5c-47a9-9295-e90cbf5e7155,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-1e938f10-c2f0-4832-99dc-d5c485f8fc49,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-3a5b47dc-bc98-4d2c-8a26-5c4be8db44a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2140854400-172.17.0.10-1595826355812:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41260,DS-d01c1d6a-2dd3-4071-a270-de8b6e843fba,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-b4e36792-1a5a-4bdb-89fc-24be80bb7bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-2daf049f-2bc2-466c-8784-0b9a2a6f36d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-c249da0c-80a5-467c-9354-dfc76452ece0,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-0307aa25-51de-4001-9ee1-bafe296fbd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-d5e23a92-7e5c-47a9-9295-e90cbf5e7155,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-1e938f10-c2f0-4832-99dc-d5c485f8fc49,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-3a5b47dc-bc98-4d2c-8a26-5c4be8db44a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 2048
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1979514153-172.17.0.10-1595826548549:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42995,DS-d7b82a73-c65c-476b-9202-d036c2c0cf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-d6457e0f-6fe6-42fd-b912-52c6a6ba1f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-1ef78d33-0e24-40d6-9380-1a7adda28caf,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-01b5a0cd-e559-4d82-837a-4babc50e731c,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-7fd6f5da-1edb-4ada-9bd7-e09ce121c8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-501dc6c7-6a83-4429-b7f8-b2a2512a7db9,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-d6f8b10f-c1ca-42dd-bcd9-76367a0bde45,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-c97f7931-31cd-4f57-bc75-aca070483bc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1979514153-172.17.0.10-1595826548549:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42995,DS-d7b82a73-c65c-476b-9202-d036c2c0cf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-d6457e0f-6fe6-42fd-b912-52c6a6ba1f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-1ef78d33-0e24-40d6-9380-1a7adda28caf,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-01b5a0cd-e559-4d82-837a-4babc50e731c,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-7fd6f5da-1edb-4ada-9bd7-e09ce121c8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-501dc6c7-6a83-4429-b7f8-b2a2512a7db9,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-d6f8b10f-c1ca-42dd-bcd9-76367a0bde45,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-c97f7931-31cd-4f57-bc75-aca070483bc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 2048
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2006186563-172.17.0.10-1595827048519:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45169,DS-c5cafd95-e206-4064-a14f-db61808487c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-09296a37-eae3-43c1-a108-56ea1dd77cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-bf8d4369-f8c5-48b7-97dc-883db67ac6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46010,DS-336ddf1e-6da8-49de-ad92-6795447ce9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37403,DS-9eac66b5-b984-4a9c-acc0-633ab2a4a038,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-56b8b640-6e9f-4f88-95aa-c813593dc819,DISK], DatanodeInfoWithStorage[127.0.0.1:41208,DS-76e552b6-99ea-403d-b8e7-7a48ecf96867,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-2af5403c-181a-48c3-9813-4eb88a24ff5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2006186563-172.17.0.10-1595827048519:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45169,DS-c5cafd95-e206-4064-a14f-db61808487c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-09296a37-eae3-43c1-a108-56ea1dd77cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-bf8d4369-f8c5-48b7-97dc-883db67ac6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46010,DS-336ddf1e-6da8-49de-ad92-6795447ce9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37403,DS-9eac66b5-b984-4a9c-acc0-633ab2a4a038,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-56b8b640-6e9f-4f88-95aa-c813593dc819,DISK], DatanodeInfoWithStorage[127.0.0.1:41208,DS-76e552b6-99ea-403d-b8e7-7a48ecf96867,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-2af5403c-181a-48c3-9813-4eb88a24ff5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 2048
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2091495497-172.17.0.10-1595827177702:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43984,DS-dea201c4-32ac-4698-aa66-e32228fac78b,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-4917b5c8-2bf9-43dc-91ba-c8875efbfbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-7b2726a1-91ef-42a0-9d39-d935b388304a,DISK], DatanodeInfoWithStorage[127.0.0.1:36233,DS-f8ffaaea-c151-4221-a92b-cfdc422ef5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-ddca4ed1-afc6-4b84-bd14-8b4bd26ab000,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-2f5c509b-5d4e-42e0-81c6-c6ea1281abd9,DISK], DatanodeInfoWithStorage[127.0.0.1:44392,DS-3d1a800c-2fb8-423e-81c7-6b11d41d2f22,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-c5cc55c7-5986-41e1-82f7-a6c9bbb362df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2091495497-172.17.0.10-1595827177702:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43984,DS-dea201c4-32ac-4698-aa66-e32228fac78b,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-4917b5c8-2bf9-43dc-91ba-c8875efbfbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-7b2726a1-91ef-42a0-9d39-d935b388304a,DISK], DatanodeInfoWithStorage[127.0.0.1:36233,DS-f8ffaaea-c151-4221-a92b-cfdc422ef5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-ddca4ed1-afc6-4b84-bd14-8b4bd26ab000,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-2f5c509b-5d4e-42e0-81c6-c6ea1281abd9,DISK], DatanodeInfoWithStorage[127.0.0.1:44392,DS-3d1a800c-2fb8-423e-81c7-6b11d41d2f22,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-c5cc55c7-5986-41e1-82f7-a6c9bbb362df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 2048
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1174493818-172.17.0.10-1595827257844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41283,DS-9cdeb5e2-b799-491d-b077-120d706dd061,DISK], DatanodeInfoWithStorage[127.0.0.1:34491,DS-483a1f14-240e-4bf9-8089-587c5da5600a,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-a26333ee-3f8b-4242-9c4f-6a1ab12bc52a,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-49a08e45-cf04-4d4e-8c9a-3047010df76a,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-038787ea-3d0f-4e72-972f-23d0f643e6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-e3f45072-e622-4bc9-8d82-49850eca4534,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-85b844ce-1b75-4522-ba4e-6c04db4dc90a,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-0130dea5-fc25-4440-a4d1-9dfce8bbce6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1174493818-172.17.0.10-1595827257844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41283,DS-9cdeb5e2-b799-491d-b077-120d706dd061,DISK], DatanodeInfoWithStorage[127.0.0.1:34491,DS-483a1f14-240e-4bf9-8089-587c5da5600a,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-a26333ee-3f8b-4242-9c4f-6a1ab12bc52a,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-49a08e45-cf04-4d4e-8c9a-3047010df76a,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-038787ea-3d0f-4e72-972f-23d0f643e6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-e3f45072-e622-4bc9-8d82-49850eca4534,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-85b844ce-1b75-4522-ba4e-6c04db4dc90a,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-0130dea5-fc25-4440-a4d1-9dfce8bbce6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 2048
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1638541324-172.17.0.10-1595827944292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33221,DS-a26e0352-6383-4425-b654-27a098312162,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-51996785-5065-4818-9a5a-8c34d617b265,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-f751d6ab-3dd5-41e5-886c-11c9a240ac1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-fefe43ba-ef1c-456d-8996-c01b20c9b8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-c0c8880f-0fa1-4dd2-b66f-39e8e65d8720,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-16ffaf1c-c2e4-48df-bc7e-85745818c5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-7e7943b1-3025-435d-93ca-bcc6cf017bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-33eecacb-1ecd-443b-bf0f-a9d545f3b698,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1638541324-172.17.0.10-1595827944292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33221,DS-a26e0352-6383-4425-b654-27a098312162,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-51996785-5065-4818-9a5a-8c34d617b265,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-f751d6ab-3dd5-41e5-886c-11c9a240ac1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-fefe43ba-ef1c-456d-8996-c01b20c9b8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-c0c8880f-0fa1-4dd2-b66f-39e8e65d8720,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-16ffaf1c-c2e4-48df-bc7e-85745818c5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-7e7943b1-3025-435d-93ca-bcc6cf017bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-33eecacb-1ecd-443b-bf0f-a9d545f3b698,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 2048
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-458928483-172.17.0.10-1595828025551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38091,DS-483f0c2d-24c0-4da8-924d-5321937eb4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-391eae9c-48c4-4a47-ab32-aedc7f7c166b,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-b6a91222-32fd-4b70-9ead-c5b6780cf798,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-ce9a9623-e206-4737-bae7-0123692643c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42279,DS-ef673b29-948b-4a10-b548-36a4606dad35,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-aef42307-0d01-4b39-b918-bbb36eab28dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-87d1516b-a8f7-42be-8b6b-136fb7ae2b51,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-51c9c450-7a19-46f4-90d1-67f5075ea3da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-458928483-172.17.0.10-1595828025551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38091,DS-483f0c2d-24c0-4da8-924d-5321937eb4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-391eae9c-48c4-4a47-ab32-aedc7f7c166b,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-b6a91222-32fd-4b70-9ead-c5b6780cf798,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-ce9a9623-e206-4737-bae7-0123692643c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42279,DS-ef673b29-948b-4a10-b548-36a4606dad35,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-aef42307-0d01-4b39-b918-bbb36eab28dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-87d1516b-a8f7-42be-8b6b-136fb7ae2b51,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-51c9c450-7a19-46f4-90d1-67f5075ea3da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 2048
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1718286114-172.17.0.10-1595828277397:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43257,DS-45aaf56e-04f9-4ea7-8b1a-774ac49fe981,DISK], DatanodeInfoWithStorage[127.0.0.1:34949,DS-2dcc13e4-818a-4ec7-a49e-a53a5dead174,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-9e092a8e-e5c2-496e-92a7-69d7aedd1e29,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-f4e76d49-950f-4899-ac8e-699240bc0007,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-29e22dc5-655f-447e-aac3-1b44020f2705,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-41ba7f1e-a2bc-4d3b-ad83-87d1a98a0fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-8f228e2b-f711-49aa-9a01-1ca67db9c450,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-43f6fcfb-b10a-467d-af8d-7aad39e131a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1718286114-172.17.0.10-1595828277397:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43257,DS-45aaf56e-04f9-4ea7-8b1a-774ac49fe981,DISK], DatanodeInfoWithStorage[127.0.0.1:34949,DS-2dcc13e4-818a-4ec7-a49e-a53a5dead174,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-9e092a8e-e5c2-496e-92a7-69d7aedd1e29,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-f4e76d49-950f-4899-ac8e-699240bc0007,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-29e22dc5-655f-447e-aac3-1b44020f2705,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-41ba7f1e-a2bc-4d3b-ad83-87d1a98a0fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-8f228e2b-f711-49aa-9a01-1ca67db9c450,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-43f6fcfb-b10a-467d-af8d-7aad39e131a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 2048
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-569485070-172.17.0.10-1595828743354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42088,DS-199eeea6-fc41-498d-920d-27f18b14f879,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-1719e46c-66ba-40f0-b5b0-28b658938d65,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-1419eabd-4ab0-404f-b9ce-da045377a598,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-e7356450-fe64-43a3-86dc-221643a64c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-30d0447e-48e1-4835-bbbd-02c6a43ea013,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-c39662fe-0a34-47dc-b897-15447852a1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-20a04791-8bbb-43a6-bc99-a789ec7ff2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-4442bf49-8130-4dcb-ae10-4cd7db46f9bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-569485070-172.17.0.10-1595828743354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42088,DS-199eeea6-fc41-498d-920d-27f18b14f879,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-1719e46c-66ba-40f0-b5b0-28b658938d65,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-1419eabd-4ab0-404f-b9ce-da045377a598,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-e7356450-fe64-43a3-86dc-221643a64c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-30d0447e-48e1-4835-bbbd-02c6a43ea013,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-c39662fe-0a34-47dc-b897-15447852a1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-20a04791-8bbb-43a6-bc99-a789ec7ff2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-4442bf49-8130-4dcb-ae10-4cd7db46f9bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 2048
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-55394993-172.17.0.10-1595829200293:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35800,DS-09dc2fb2-020b-40b6-9c48-683182317ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-f9b99c2d-f19e-4074-babe-62bbdc07e859,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-a42c1972-2927-4dcf-bd8a-088414f76855,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-0ef044b0-7148-42e9-9cae-abdf8bcb2768,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-15be0abe-82eb-42f4-b31e-1d6b3ec8f3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-e2fb43bb-6097-4bae-b210-27215e9e339e,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-3fd02afa-4dc4-4ec7-9e0d-21ed266810e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-53905a45-39a6-4f2d-acd3-a0ad257cb2a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-55394993-172.17.0.10-1595829200293:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35800,DS-09dc2fb2-020b-40b6-9c48-683182317ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-f9b99c2d-f19e-4074-babe-62bbdc07e859,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-a42c1972-2927-4dcf-bd8a-088414f76855,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-0ef044b0-7148-42e9-9cae-abdf8bcb2768,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-15be0abe-82eb-42f4-b31e-1d6b3ec8f3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-e2fb43bb-6097-4bae-b210-27215e9e339e,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-3fd02afa-4dc4-4ec7-9e0d-21ed266810e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-53905a45-39a6-4f2d-acd3-a0ad257cb2a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 2048
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1267870464-172.17.0.10-1595829359203:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41041,DS-1ba0e645-f86c-4fda-8ea1-3dd508b46f15,DISK], DatanodeInfoWithStorage[127.0.0.1:39001,DS-d2e65137-980c-490f-bcf4-8d0f61a694b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-284422dc-4eb6-4862-bfd1-af9345a51163,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-761865c2-d5a2-4b4d-a1dc-feb071ddeff2,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-efa9e653-48a5-46b6-89c0-f76890948e54,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-f16ff8b6-c8d0-4bad-8811-58e6f977c374,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-2ebd45b1-6317-49de-83fb-aedca8b0c12c,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-d29b4f54-f6bc-459e-ab39-abf83ec4556d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1267870464-172.17.0.10-1595829359203:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41041,DS-1ba0e645-f86c-4fda-8ea1-3dd508b46f15,DISK], DatanodeInfoWithStorage[127.0.0.1:39001,DS-d2e65137-980c-490f-bcf4-8d0f61a694b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-284422dc-4eb6-4862-bfd1-af9345a51163,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-761865c2-d5a2-4b4d-a1dc-feb071ddeff2,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-efa9e653-48a5-46b6-89c0-f76890948e54,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-f16ff8b6-c8d0-4bad-8811-58e6f977c374,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-2ebd45b1-6317-49de-83fb-aedca8b0c12c,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-d29b4f54-f6bc-459e-ab39-abf83ec4556d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 2048
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-459292464-172.17.0.10-1595829568088:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35525,DS-c7e15f1f-f8f0-4a81-93c6-49d63c86bf41,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-ae1f3033-170f-477e-9a39-3cbf25451b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-00899d54-ba73-4ca0-80bd-eea34c563f67,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-42a28bdc-63f9-4220-b5bd-d2d335a14f41,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-79804ace-d2ea-4e66-bd76-96ef27c9f909,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-a49a1f15-64b2-453d-b2bf-9c93a46401db,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-d51d5660-bb3d-49b9-9868-dfe9f88529f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-912cf514-eef2-41ca-8c31-a596d01cf2a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-459292464-172.17.0.10-1595829568088:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35525,DS-c7e15f1f-f8f0-4a81-93c6-49d63c86bf41,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-ae1f3033-170f-477e-9a39-3cbf25451b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-00899d54-ba73-4ca0-80bd-eea34c563f67,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-42a28bdc-63f9-4220-b5bd-d2d335a14f41,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-79804ace-d2ea-4e66-bd76-96ef27c9f909,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-a49a1f15-64b2-453d-b2bf-9c93a46401db,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-d51d5660-bb3d-49b9-9868-dfe9f88529f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-912cf514-eef2-41ca-8c31-a596d01cf2a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 2048
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1510008804-172.17.0.10-1595830091200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42016,DS-a8502378-042c-4b4e-ada0-474e888e1a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-75bbc228-4132-482d-a97c-5e1e16183b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-50c3ad4c-4024-40cd-85d4-cdf9db1ca36d,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-4af45df6-47d5-4519-82d5-78ffbd855427,DISK], DatanodeInfoWithStorage[127.0.0.1:34994,DS-e006fcef-725a-4e9d-a084-6ab2e4c1ab60,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-f0bf2930-a2c7-4224-ad01-0e2038cacea6,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-fa37f6ad-9709-4269-a078-49bb9aefa2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-7f2a9658-7abd-4aa7-8d2d-88b6abb9b0ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1510008804-172.17.0.10-1595830091200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42016,DS-a8502378-042c-4b4e-ada0-474e888e1a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-75bbc228-4132-482d-a97c-5e1e16183b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-50c3ad4c-4024-40cd-85d4-cdf9db1ca36d,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-4af45df6-47d5-4519-82d5-78ffbd855427,DISK], DatanodeInfoWithStorage[127.0.0.1:34994,DS-e006fcef-725a-4e9d-a084-6ab2e4c1ab60,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-f0bf2930-a2c7-4224-ad01-0e2038cacea6,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-fa37f6ad-9709-4269-a078-49bb9aefa2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-7f2a9658-7abd-4aa7-8d2d-88b6abb9b0ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 6272
