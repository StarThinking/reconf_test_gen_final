reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1066881116-172.17.0.2-1595817865280:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45612,DS-7c00770b-d5f5-4da5-ab85-d492657c9711,DISK], DatanodeInfoWithStorage[127.0.0.1:43508,DS-4d4904c0-7bc5-48cd-8ed2-75646fe30f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-4ebc648c-6298-4308-88b4-a8b3bfad3e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36832,DS-d99217c6-28a2-4a2d-b5e7-2868b92a34b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-06b0e4ab-7dd9-4319-91cf-b41157db32a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-86496670-3d80-47cb-aa20-62400935abbb,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-7fe3535b-7c84-4030-9183-f0d3872f5397,DISK], DatanodeInfoWithStorage[127.0.0.1:38350,DS-1441b69a-4387-450a-9875-e9dcfc9d3cda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1066881116-172.17.0.2-1595817865280:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45612,DS-7c00770b-d5f5-4da5-ab85-d492657c9711,DISK], DatanodeInfoWithStorage[127.0.0.1:43508,DS-4d4904c0-7bc5-48cd-8ed2-75646fe30f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-4ebc648c-6298-4308-88b4-a8b3bfad3e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36832,DS-d99217c6-28a2-4a2d-b5e7-2868b92a34b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-06b0e4ab-7dd9-4319-91cf-b41157db32a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-86496670-3d80-47cb-aa20-62400935abbb,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-7fe3535b-7c84-4030-9183-f0d3872f5397,DISK], DatanodeInfoWithStorage[127.0.0.1:38350,DS-1441b69a-4387-450a-9875-e9dcfc9d3cda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-863444027-172.17.0.2-1595818862160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42218,DS-9a8af721-e02e-44c4-9327-faec04bc35ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-13cbf978-784a-4a7c-9929-308e07f8f82c,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-122e7a75-817f-4eea-84e6-f06734fd36e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-f5c9edbc-f7a9-49fa-938d-0abceb3543d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-94115e28-c3d0-47f0-8662-ee866d331281,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-14ae8592-16d5-413e-b5a7-d7f90713afff,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-58f382b4-f61c-4a72-81d4-bf881e9ec595,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-b0eba28c-8222-485b-bd4f-61086ecbf166,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-863444027-172.17.0.2-1595818862160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42218,DS-9a8af721-e02e-44c4-9327-faec04bc35ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-13cbf978-784a-4a7c-9929-308e07f8f82c,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-122e7a75-817f-4eea-84e6-f06734fd36e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-f5c9edbc-f7a9-49fa-938d-0abceb3543d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-94115e28-c3d0-47f0-8662-ee866d331281,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-14ae8592-16d5-413e-b5a7-d7f90713afff,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-58f382b4-f61c-4a72-81d4-bf881e9ec595,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-b0eba28c-8222-485b-bd4f-61086ecbf166,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-199265300-172.17.0.2-1595818903341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40593,DS-34008ef2-2310-4ea9-8d18-e38c4dedeaab,DISK], DatanodeInfoWithStorage[127.0.0.1:42858,DS-7ba4eb07-76b5-467a-8f41-2253596e3bad,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-cd52bb51-3e9d-4a5b-bcc6-ae9385daff82,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-2298cd92-e675-4523-91af-aa5099e4b4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-4f8d2ad2-fa8c-4d2d-8ea7-863034c50bab,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-e159a3f9-354a-4dec-a19c-6ddc1ad31a66,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-a98a0b5a-6944-4f91-a839-b1a1d36e4930,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-b3b18aa4-0ce9-4311-a734-cb8775a42510,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-199265300-172.17.0.2-1595818903341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40593,DS-34008ef2-2310-4ea9-8d18-e38c4dedeaab,DISK], DatanodeInfoWithStorage[127.0.0.1:42858,DS-7ba4eb07-76b5-467a-8f41-2253596e3bad,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-cd52bb51-3e9d-4a5b-bcc6-ae9385daff82,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-2298cd92-e675-4523-91af-aa5099e4b4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-4f8d2ad2-fa8c-4d2d-8ea7-863034c50bab,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-e159a3f9-354a-4dec-a19c-6ddc1ad31a66,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-a98a0b5a-6944-4f91-a839-b1a1d36e4930,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-b3b18aa4-0ce9-4311-a734-cb8775a42510,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1048985657-172.17.0.2-1595819025963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38202,DS-4658e09a-b84f-4b1e-b28e-57f7135a78e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-f88fd424-94ed-4313-98c7-7dc6acd8e530,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-95b89036-5be3-441e-b455-82202df40773,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-1825b2ac-a20d-4599-a21b-a5929173fb3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-3a773685-7569-4201-8b67-db3051d553e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34438,DS-10dc766e-5e23-42bc-8a69-01ca2e46606f,DISK], DatanodeInfoWithStorage[127.0.0.1:36830,DS-bb09a507-2c7a-4908-84c3-5a9f33f07d80,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-bb6f8355-b226-4c14-9fc4-44faf3de1878,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1048985657-172.17.0.2-1595819025963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38202,DS-4658e09a-b84f-4b1e-b28e-57f7135a78e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-f88fd424-94ed-4313-98c7-7dc6acd8e530,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-95b89036-5be3-441e-b455-82202df40773,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-1825b2ac-a20d-4599-a21b-a5929173fb3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-3a773685-7569-4201-8b67-db3051d553e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34438,DS-10dc766e-5e23-42bc-8a69-01ca2e46606f,DISK], DatanodeInfoWithStorage[127.0.0.1:36830,DS-bb09a507-2c7a-4908-84c3-5a9f33f07d80,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-bb6f8355-b226-4c14-9fc4-44faf3de1878,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-398759267-172.17.0.2-1595819195094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36244,DS-fddbee87-4286-4ea2-ab46-7c37b3d42f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42123,DS-2939527c-4b20-4a6d-b85f-0f17f62b554f,DISK], DatanodeInfoWithStorage[127.0.0.1:46050,DS-b0d86c27-bd7d-45af-bbf7-eaacac9bc84f,DISK], DatanodeInfoWithStorage[127.0.0.1:40370,DS-33bc640a-5cd5-4b5c-9a51-757b8770d1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-54d5bbb2-6942-4215-85d9-8226313eaaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-b676951e-63c6-467a-81c6-8b93078d28ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-766325bd-7bd1-4eaa-b823-df76fad3e5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-42ec34e0-0a11-48a5-a118-ce8776d8169a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-398759267-172.17.0.2-1595819195094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36244,DS-fddbee87-4286-4ea2-ab46-7c37b3d42f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42123,DS-2939527c-4b20-4a6d-b85f-0f17f62b554f,DISK], DatanodeInfoWithStorage[127.0.0.1:46050,DS-b0d86c27-bd7d-45af-bbf7-eaacac9bc84f,DISK], DatanodeInfoWithStorage[127.0.0.1:40370,DS-33bc640a-5cd5-4b5c-9a51-757b8770d1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-54d5bbb2-6942-4215-85d9-8226313eaaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-b676951e-63c6-467a-81c6-8b93078d28ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-766325bd-7bd1-4eaa-b823-df76fad3e5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-42ec34e0-0a11-48a5-a118-ce8776d8169a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1657438422-172.17.0.2-1595819637451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34995,DS-ca1f4594-6bf9-4a11-bfb6-50c2d6e31e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-74097444-3278-481e-8e54-24cfbfd8d4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-d01c9f6d-f841-4bea-bebd-8f604b9431a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-99b32ead-7e81-46e0-82da-b64b2d805424,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-2428a9cd-2e77-4515-ba61-a09f2a753761,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-2ab3c10d-cb0a-4b4d-a91e-46ea06c0ed56,DISK], DatanodeInfoWithStorage[127.0.0.1:36005,DS-d622874c-16bf-4f72-b5fe-b726d2a94a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-760ffe2f-41f9-42b0-9eca-72f709296e1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1657438422-172.17.0.2-1595819637451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34995,DS-ca1f4594-6bf9-4a11-bfb6-50c2d6e31e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-74097444-3278-481e-8e54-24cfbfd8d4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-d01c9f6d-f841-4bea-bebd-8f604b9431a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-99b32ead-7e81-46e0-82da-b64b2d805424,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-2428a9cd-2e77-4515-ba61-a09f2a753761,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-2ab3c10d-cb0a-4b4d-a91e-46ea06c0ed56,DISK], DatanodeInfoWithStorage[127.0.0.1:36005,DS-d622874c-16bf-4f72-b5fe-b726d2a94a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-760ffe2f-41f9-42b0-9eca-72f709296e1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1156628099-172.17.0.2-1595820263462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40148,DS-97ebc162-3d39-4e64-aec7-50650a5246a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-78bb073e-def5-45c8-afa0-c17cba04f6be,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-b31ae486-946d-4440-bb3f-8bc1da7b3e91,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-3c8530dc-7d7b-4726-8f4e-54c038e467bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-c40d6988-ccec-46c0-9846-6ef32353a603,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-a2221811-daeb-4643-9a38-9f07edd494cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-1d5c575b-faea-4efd-8fcc-74f9559f0cec,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-135d1dd7-dfc9-4ccf-9895-bb0a4390770a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1156628099-172.17.0.2-1595820263462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40148,DS-97ebc162-3d39-4e64-aec7-50650a5246a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-78bb073e-def5-45c8-afa0-c17cba04f6be,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-b31ae486-946d-4440-bb3f-8bc1da7b3e91,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-3c8530dc-7d7b-4726-8f4e-54c038e467bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-c40d6988-ccec-46c0-9846-6ef32353a603,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-a2221811-daeb-4643-9a38-9f07edd494cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-1d5c575b-faea-4efd-8fcc-74f9559f0cec,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-135d1dd7-dfc9-4ccf-9895-bb0a4390770a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1377211024-172.17.0.2-1595820396976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36155,DS-6e43d440-24ff-4f73-ac4e-80e69b85236f,DISK], DatanodeInfoWithStorage[127.0.0.1:34437,DS-b572920f-a160-44cf-9533-d80d7492bb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-0bc95497-3fe7-45fa-856d-9b2d06905cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-ccd634d1-725d-4b16-8658-3ace9642022d,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-748de2a9-e07e-4df0-a573-622b287af357,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-b2df73f1-33e6-4115-9bb3-f00349861f90,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-e6c7987d-0697-4511-b04c-f22f86d2a501,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-f9f97f0c-d5b5-4d89-88cd-14a880481f87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1377211024-172.17.0.2-1595820396976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36155,DS-6e43d440-24ff-4f73-ac4e-80e69b85236f,DISK], DatanodeInfoWithStorage[127.0.0.1:34437,DS-b572920f-a160-44cf-9533-d80d7492bb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-0bc95497-3fe7-45fa-856d-9b2d06905cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-ccd634d1-725d-4b16-8658-3ace9642022d,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-748de2a9-e07e-4df0-a573-622b287af357,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-b2df73f1-33e6-4115-9bb3-f00349861f90,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-e6c7987d-0697-4511-b04c-f22f86d2a501,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-f9f97f0c-d5b5-4d89-88cd-14a880481f87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-282303943-172.17.0.2-1595820903112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42713,DS-c429f640-6e46-4cb4-8ade-cd02576ff194,DISK], DatanodeInfoWithStorage[127.0.0.1:45428,DS-2631aa42-33a7-45f2-abc4-9e3c7b90e7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-ac0f7280-7c35-4349-a94a-935ab3ab9d31,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-162e516a-38ad-456b-adfb-cf1ce8ee5e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41958,DS-35692853-20e6-46c6-a943-dc9e89c1d11e,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-ac8413d8-8a6d-4bd9-866b-9de8b5420aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-dfe3b539-13b5-4010-a8bd-e80185e3b212,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-3290b89f-610c-4f2c-87c8-80688a2fe342,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-282303943-172.17.0.2-1595820903112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42713,DS-c429f640-6e46-4cb4-8ade-cd02576ff194,DISK], DatanodeInfoWithStorage[127.0.0.1:45428,DS-2631aa42-33a7-45f2-abc4-9e3c7b90e7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-ac0f7280-7c35-4349-a94a-935ab3ab9d31,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-162e516a-38ad-456b-adfb-cf1ce8ee5e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41958,DS-35692853-20e6-46c6-a943-dc9e89c1d11e,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-ac8413d8-8a6d-4bd9-866b-9de8b5420aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-dfe3b539-13b5-4010-a8bd-e80185e3b212,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-3290b89f-610c-4f2c-87c8-80688a2fe342,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-949839494-172.17.0.2-1595820981753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42859,DS-4c1165b7-9e33-42b8-884d-1acdba069197,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-f3afe03d-18ce-4a55-8ebe-96bdaf0c964f,DISK], DatanodeInfoWithStorage[127.0.0.1:36521,DS-e3eb1bb9-1e3c-4193-8a9a-13bce0f677e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-0203558c-6e6e-4f64-b24c-ae6d91b964ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-9bed6072-3fa7-4da5-8e41-1337036e2ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-fafa035a-d526-4928-9f76-278798a7293f,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-b8359608-2f87-4ff7-99d1-313899ad7cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-a981b7e5-2e78-4087-bc8c-daf9d1a4d12c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-949839494-172.17.0.2-1595820981753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42859,DS-4c1165b7-9e33-42b8-884d-1acdba069197,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-f3afe03d-18ce-4a55-8ebe-96bdaf0c964f,DISK], DatanodeInfoWithStorage[127.0.0.1:36521,DS-e3eb1bb9-1e3c-4193-8a9a-13bce0f677e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-0203558c-6e6e-4f64-b24c-ae6d91b964ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-9bed6072-3fa7-4da5-8e41-1337036e2ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-fafa035a-d526-4928-9f76-278798a7293f,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-b8359608-2f87-4ff7-99d1-313899ad7cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-a981b7e5-2e78-4087-bc8c-daf9d1a4d12c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1365525682-172.17.0.2-1595821160675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32983,DS-edb033f5-69f7-4e35-8497-a7783114ee9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-51625482-30d6-4e3b-9ffe-07b61ae9bc53,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-f8ae8e60-22dd-4fc9-9441-344ac94bd1e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-5c95ff3f-3b15-4b28-96de-f2f456f2eb10,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-8af0fc69-c93e-43ad-8417-660b5d4a66e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-d85d4269-fa59-4304-b957-5578d9831a01,DISK], DatanodeInfoWithStorage[127.0.0.1:39504,DS-60a4cef8-2357-4d9a-9a8f-2f99e6b0ae0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-1f787989-4d0b-4f54-a29b-0e525969428b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1365525682-172.17.0.2-1595821160675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32983,DS-edb033f5-69f7-4e35-8497-a7783114ee9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-51625482-30d6-4e3b-9ffe-07b61ae9bc53,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-f8ae8e60-22dd-4fc9-9441-344ac94bd1e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-5c95ff3f-3b15-4b28-96de-f2f456f2eb10,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-8af0fc69-c93e-43ad-8417-660b5d4a66e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-d85d4269-fa59-4304-b957-5578d9831a01,DISK], DatanodeInfoWithStorage[127.0.0.1:39504,DS-60a4cef8-2357-4d9a-9a8f-2f99e6b0ae0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-1f787989-4d0b-4f54-a29b-0e525969428b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1992794676-172.17.0.2-1595821811481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43018,DS-793473ae-685e-4078-ab76-0c1ebcd67f23,DISK], DatanodeInfoWithStorage[127.0.0.1:33567,DS-5d040475-9ee4-405e-a263-08f5a1d6f6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-12da60e4-e19c-49c7-bacb-ea9e4667d19e,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-dd7e6e1a-3326-4436-bfe5-6459d6c848cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-980f9b75-e141-40c3-b596-3d8f4771ca50,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-f9cc4684-825d-49bc-9447-2c5c12dacd4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-28e9bb9b-7d44-4f30-af84-42859855198a,DISK], DatanodeInfoWithStorage[127.0.0.1:34094,DS-2ebf456a-91d5-403b-9333-3f754c0b8b6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1992794676-172.17.0.2-1595821811481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43018,DS-793473ae-685e-4078-ab76-0c1ebcd67f23,DISK], DatanodeInfoWithStorage[127.0.0.1:33567,DS-5d040475-9ee4-405e-a263-08f5a1d6f6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-12da60e4-e19c-49c7-bacb-ea9e4667d19e,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-dd7e6e1a-3326-4436-bfe5-6459d6c848cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-980f9b75-e141-40c3-b596-3d8f4771ca50,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-f9cc4684-825d-49bc-9447-2c5c12dacd4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-28e9bb9b-7d44-4f30-af84-42859855198a,DISK], DatanodeInfoWithStorage[127.0.0.1:34094,DS-2ebf456a-91d5-403b-9333-3f754c0b8b6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-810534393-172.17.0.2-1595822369940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36068,DS-23c79579-49f1-4ea6-a51c-68ad62789b18,DISK], DatanodeInfoWithStorage[127.0.0.1:36748,DS-cf333e5e-7313-4c42-8a99-b327881e0004,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-c32c038c-367f-4c0e-a80f-58a8129e15e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-0c36f05b-6a95-483c-8c7f-7946d9154976,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-574a8e0e-0148-47ca-a599-efa0b5340d62,DISK], DatanodeInfoWithStorage[127.0.0.1:45140,DS-7431c413-81ca-463f-8fb4-6e0106d31ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-135acb00-904b-4ba4-a6eb-f440cd3626f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-a91b1350-4e2c-4902-a84c-da614ad357ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-810534393-172.17.0.2-1595822369940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36068,DS-23c79579-49f1-4ea6-a51c-68ad62789b18,DISK], DatanodeInfoWithStorage[127.0.0.1:36748,DS-cf333e5e-7313-4c42-8a99-b327881e0004,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-c32c038c-367f-4c0e-a80f-58a8129e15e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-0c36f05b-6a95-483c-8c7f-7946d9154976,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-574a8e0e-0148-47ca-a599-efa0b5340d62,DISK], DatanodeInfoWithStorage[127.0.0.1:45140,DS-7431c413-81ca-463f-8fb4-6e0106d31ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-135acb00-904b-4ba4-a6eb-f440cd3626f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-a91b1350-4e2c-4902-a84c-da614ad357ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1217606391-172.17.0.2-1595822709372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35400,DS-03759291-5202-4c3f-903b-3ea435fb904f,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-a001ea85-c0dd-4b23-8c2e-dbb3b213913a,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-e4b8e371-f9c4-47d8-80da-fcdfb1f7180e,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-ac185fac-c86f-4136-b0db-985f0191f23c,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-131bf135-ace8-408f-8650-16fccf1c075f,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-8e58d0f1-ffb7-49a8-8803-eda0eece0e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-357dde25-d4bd-412c-90ce-0c9460d1a9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-65b11dd0-3371-47d6-8520-753f3c4c2573,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1217606391-172.17.0.2-1595822709372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35400,DS-03759291-5202-4c3f-903b-3ea435fb904f,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-a001ea85-c0dd-4b23-8c2e-dbb3b213913a,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-e4b8e371-f9c4-47d8-80da-fcdfb1f7180e,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-ac185fac-c86f-4136-b0db-985f0191f23c,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-131bf135-ace8-408f-8650-16fccf1c075f,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-8e58d0f1-ffb7-49a8-8803-eda0eece0e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-357dde25-d4bd-412c-90ce-0c9460d1a9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-65b11dd0-3371-47d6-8520-753f3c4c2573,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1339846657-172.17.0.2-1595822925223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38271,DS-9d4d1821-8674-45dd-bcfa-2ee3e6c644cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-7b711008-8ebb-4cc6-813b-62d524e0a604,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-66694143-e7fe-4c93-a3e2-6360e39f2328,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-998c6e23-d942-4b68-9f6a-bd0d6eb03dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-32cb602e-786d-4089-b982-4d2e3ea4b3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-51f5a15d-87f4-4d3c-96d4-80cb272a4743,DISK], DatanodeInfoWithStorage[127.0.0.1:37173,DS-57156af0-ba37-48c1-9bda-9f6a015349c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-292ff9da-c0db-4223-9bcb-cd17c83ca45a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1339846657-172.17.0.2-1595822925223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38271,DS-9d4d1821-8674-45dd-bcfa-2ee3e6c644cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-7b711008-8ebb-4cc6-813b-62d524e0a604,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-66694143-e7fe-4c93-a3e2-6360e39f2328,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-998c6e23-d942-4b68-9f6a-bd0d6eb03dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-32cb602e-786d-4089-b982-4d2e3ea4b3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-51f5a15d-87f4-4d3c-96d4-80cb272a4743,DISK], DatanodeInfoWithStorage[127.0.0.1:37173,DS-57156af0-ba37-48c1-9bda-9f6a015349c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-292ff9da-c0db-4223-9bcb-cd17c83ca45a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-309391694-172.17.0.2-1595823016929:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45945,DS-36fa6b18-063c-4f3f-8303-1e79346aa999,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-4eab2b51-4530-4260-bf0e-fefb13959dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-2d4b41cb-581b-4699-a971-d277563ae52c,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-453388b8-05ec-45b2-a324-fcdd77723258,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-e53f3d67-5dda-4a34-85a1-3ea0ed1c4ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-c1cba67f-5436-4cd1-a1bc-d46ef44f77fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-c8589c7a-2f7a-4b7e-b6da-d21a2cf445a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-315d4f8e-ebd0-4afd-b118-a6985e6695b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-309391694-172.17.0.2-1595823016929:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45945,DS-36fa6b18-063c-4f3f-8303-1e79346aa999,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-4eab2b51-4530-4260-bf0e-fefb13959dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-2d4b41cb-581b-4699-a971-d277563ae52c,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-453388b8-05ec-45b2-a324-fcdd77723258,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-e53f3d67-5dda-4a34-85a1-3ea0ed1c4ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-c1cba67f-5436-4cd1-a1bc-d46ef44f77fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-c8589c7a-2f7a-4b7e-b6da-d21a2cf445a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-315d4f8e-ebd0-4afd-b118-a6985e6695b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1611632799-172.17.0.2-1595823100110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40027,DS-2178ac54-7be6-4cac-b4d3-66cfb6a09c72,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-55450597-e9c0-4f7e-b9fa-385837a10db2,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-393ecb88-7994-4aaa-9e84-0aa37c0db2fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-4ef7ea5d-34a9-413c-ae61-a58c30e793c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-5a83fb7c-2f0d-42d3-b706-7db16c29d756,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-4c2c56b9-9545-4946-8689-83a5e2fa8116,DISK], DatanodeInfoWithStorage[127.0.0.1:42541,DS-09e3b03a-8763-42b8-b535-3a0ce6fbafa0,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-8099195c-cca7-495d-9981-adbe3f89750e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1611632799-172.17.0.2-1595823100110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40027,DS-2178ac54-7be6-4cac-b4d3-66cfb6a09c72,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-55450597-e9c0-4f7e-b9fa-385837a10db2,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-393ecb88-7994-4aaa-9e84-0aa37c0db2fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-4ef7ea5d-34a9-413c-ae61-a58c30e793c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-5a83fb7c-2f0d-42d3-b706-7db16c29d756,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-4c2c56b9-9545-4946-8689-83a5e2fa8116,DISK], DatanodeInfoWithStorage[127.0.0.1:42541,DS-09e3b03a-8763-42b8-b535-3a0ce6fbafa0,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-8099195c-cca7-495d-9981-adbe3f89750e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1844074892-172.17.0.2-1595823464905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33241,DS-db6cb770-4dbb-4761-9ec9-79e518f8c4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-47dc05fa-12d6-4203-8afd-abbebebdb218,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-2506ad7a-dff4-49e1-af3d-4a0b2d41a655,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-6d6890de-b659-471d-8e1a-27eb07ceccf4,DISK], DatanodeInfoWithStorage[127.0.0.1:34278,DS-88a764a1-8da3-4c4e-acea-0a8ed6fed38c,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-76c03693-a996-4313-9e3e-7e8cd73e1abd,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-4ac53335-7bc2-468f-b565-36862688f76f,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-538ca221-c434-4fa7-8272-f9f86f6e0d8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1844074892-172.17.0.2-1595823464905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33241,DS-db6cb770-4dbb-4761-9ec9-79e518f8c4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-47dc05fa-12d6-4203-8afd-abbebebdb218,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-2506ad7a-dff4-49e1-af3d-4a0b2d41a655,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-6d6890de-b659-471d-8e1a-27eb07ceccf4,DISK], DatanodeInfoWithStorage[127.0.0.1:34278,DS-88a764a1-8da3-4c4e-acea-0a8ed6fed38c,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-76c03693-a996-4313-9e3e-7e8cd73e1abd,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-4ac53335-7bc2-468f-b565-36862688f76f,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-538ca221-c434-4fa7-8272-f9f86f6e0d8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1275087384-172.17.0.2-1595824167700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37198,DS-9bd25189-98f6-4c48-9f35-ed6215ee1f85,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-d00a24b3-9d4d-4489-a03b-ea18342d2c67,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-fd425a56-768f-4d1b-97c4-cd2692b7742f,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-dca3fc16-bfe3-4ed0-8e65-6881b0503a80,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-7fb5418b-1098-48e7-a77a-8dc0497146e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-094b6eaa-294a-487a-ac04-d2560160b0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-7eab154b-2a6b-41e5-9851-e34e747810a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-3289ce73-0ebb-4084-bdcf-a07bd61ee34e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1275087384-172.17.0.2-1595824167700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37198,DS-9bd25189-98f6-4c48-9f35-ed6215ee1f85,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-d00a24b3-9d4d-4489-a03b-ea18342d2c67,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-fd425a56-768f-4d1b-97c4-cd2692b7742f,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-dca3fc16-bfe3-4ed0-8e65-6881b0503a80,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-7fb5418b-1098-48e7-a77a-8dc0497146e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-094b6eaa-294a-487a-ac04-d2560160b0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-7eab154b-2a6b-41e5-9851-e34e747810a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-3289ce73-0ebb-4084-bdcf-a07bd61ee34e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 6432
