reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1967850429-172.17.0.2-1595490719325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42337,DS-df9c79b0-e4a9-4dfb-8061-4073d056d2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-6d2fe818-efd4-4113-aa5a-1e8bae08dfd3,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-d5125a1a-5fad-4dc9-8108-db488b3cc9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-49b0dcd1-17c0-4147-8dde-b9f6cd61ce48,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-b6ceda58-2e83-4869-a504-6224033e1239,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-4e14ed23-cd01-4e8d-9153-8ab61188e829,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-35f6df35-cf94-42fe-bfc4-3ab018331d22,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-965df4d3-369c-471e-b2c6-64d244137f78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1967850429-172.17.0.2-1595490719325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42337,DS-df9c79b0-e4a9-4dfb-8061-4073d056d2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-6d2fe818-efd4-4113-aa5a-1e8bae08dfd3,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-d5125a1a-5fad-4dc9-8108-db488b3cc9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-49b0dcd1-17c0-4147-8dde-b9f6cd61ce48,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-b6ceda58-2e83-4869-a504-6224033e1239,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-4e14ed23-cd01-4e8d-9153-8ab61188e829,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-35f6df35-cf94-42fe-bfc4-3ab018331d22,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-965df4d3-369c-471e-b2c6-64d244137f78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-47112890-172.17.0.2-1595492107269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33720,DS-648a699c-fe6b-44d3-888b-3896b5b0fc43,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-cea0a03d-cf5f-488c-a5c2-8516d32d610d,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-ee184e81-f118-491a-8560-175643ff9b66,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-5e7befe3-d517-4cb3-9d60-1dca4e6cae63,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-e82e2e0a-bf63-488a-9601-0ecac2a25b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-8109ab68-f642-48c6-be30-f59841aa559d,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-71c3223f-a13b-4bf0-87f1-cdcf9c9d922b,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-c8864851-9d5f-43e4-bc79-e67a4808444e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-47112890-172.17.0.2-1595492107269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33720,DS-648a699c-fe6b-44d3-888b-3896b5b0fc43,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-cea0a03d-cf5f-488c-a5c2-8516d32d610d,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-ee184e81-f118-491a-8560-175643ff9b66,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-5e7befe3-d517-4cb3-9d60-1dca4e6cae63,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-e82e2e0a-bf63-488a-9601-0ecac2a25b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-8109ab68-f642-48c6-be30-f59841aa559d,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-71c3223f-a13b-4bf0-87f1-cdcf9c9d922b,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-c8864851-9d5f-43e4-bc79-e67a4808444e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1444790058-172.17.0.2-1595493635982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43706,DS-928b5f02-5190-4173-b34c-437ac8723f80,DISK], DatanodeInfoWithStorage[127.0.0.1:35555,DS-a02c27de-f182-4296-8d61-f9c96759ba88,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-d0cba9ab-8ee0-4cb6-b871-33975e91d9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-b3c7787c-d6fc-43a6-b1ce-2e477155c4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-1180019a-59de-4bf7-87d0-9467f08b70cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-1ef91e0c-de69-45a2-ab51-9b182928b0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-5add0bd6-ea9e-410a-a363-214f24454a39,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-a2018763-ecbe-4062-b916-d86e88c4af4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1444790058-172.17.0.2-1595493635982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43706,DS-928b5f02-5190-4173-b34c-437ac8723f80,DISK], DatanodeInfoWithStorage[127.0.0.1:35555,DS-a02c27de-f182-4296-8d61-f9c96759ba88,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-d0cba9ab-8ee0-4cb6-b871-33975e91d9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-b3c7787c-d6fc-43a6-b1ce-2e477155c4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-1180019a-59de-4bf7-87d0-9467f08b70cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-1ef91e0c-de69-45a2-ab51-9b182928b0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-5add0bd6-ea9e-410a-a363-214f24454a39,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-a2018763-ecbe-4062-b916-d86e88c4af4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-442914399-172.17.0.2-1595493774834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45055,DS-61b4e6fd-3004-4a7d-9fdd-1a2c26c73826,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-71e56ed6-44a3-40cc-b4d4-00d538e690cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-a789db60-54b4-4383-a763-de5e738c54a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-e1497812-a7a8-46fc-bb8f-dd1eae16a489,DISK], DatanodeInfoWithStorage[127.0.0.1:34728,DS-eb85c63b-f8ca-49de-a9ad-497684cee274,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-d189461e-8b9c-4be5-ba5b-4213cf0712b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-82cbc2ee-ee9e-4be5-9844-f32dd1421fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44628,DS-56bffdf4-48e1-4efa-a958-f52f2c56432f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-442914399-172.17.0.2-1595493774834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45055,DS-61b4e6fd-3004-4a7d-9fdd-1a2c26c73826,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-71e56ed6-44a3-40cc-b4d4-00d538e690cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-a789db60-54b4-4383-a763-de5e738c54a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-e1497812-a7a8-46fc-bb8f-dd1eae16a489,DISK], DatanodeInfoWithStorage[127.0.0.1:34728,DS-eb85c63b-f8ca-49de-a9ad-497684cee274,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-d189461e-8b9c-4be5-ba5b-4213cf0712b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-82cbc2ee-ee9e-4be5-9844-f32dd1421fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44628,DS-56bffdf4-48e1-4efa-a958-f52f2c56432f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-354849993-172.17.0.2-1595494501764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40009,DS-b73a2965-a67a-4b31-9ca8-2b91ac591835,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-22c8efe3-bd61-457f-9fe0-4a11e4406d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-194cbcf7-2809-486b-af9b-f7faeded81bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34562,DS-f9018e7a-8413-4ba5-beba-9d262405e17f,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-9e9c3ada-0ea6-486a-b93f-a3854edd69e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-caea32f7-6cfe-47b3-b872-7355666c8a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-bcc2a4ad-c9cd-4141-be22-6bcf827f405d,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-2d347f8a-1900-4370-b8ff-696bd0c2f384,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-354849993-172.17.0.2-1595494501764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40009,DS-b73a2965-a67a-4b31-9ca8-2b91ac591835,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-22c8efe3-bd61-457f-9fe0-4a11e4406d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-194cbcf7-2809-486b-af9b-f7faeded81bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34562,DS-f9018e7a-8413-4ba5-beba-9d262405e17f,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-9e9c3ada-0ea6-486a-b93f-a3854edd69e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-caea32f7-6cfe-47b3-b872-7355666c8a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-bcc2a4ad-c9cd-4141-be22-6bcf827f405d,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-2d347f8a-1900-4370-b8ff-696bd0c2f384,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1725623130-172.17.0.2-1595494736160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40426,DS-c5521919-03bb-4afd-a7a0-ec4d139c9ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-b4ea7f8a-fb09-4361-8a8c-6ae82329b3db,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-6e961379-b7e3-4e57-875d-1e979f1d4f92,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-a8600e9b-50b0-4c1b-b007-9ffb988037dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-14aa4d2d-293b-44df-b636-3a0f68acb637,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-3e5cfd32-0866-4dc2-94b1-7eae1a4eb467,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-cddce57f-6234-49e3-b58d-5eab1ed8f98c,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-7d19cae3-cbbe-4d96-bef2-81c2a9c85366,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1725623130-172.17.0.2-1595494736160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40426,DS-c5521919-03bb-4afd-a7a0-ec4d139c9ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-b4ea7f8a-fb09-4361-8a8c-6ae82329b3db,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-6e961379-b7e3-4e57-875d-1e979f1d4f92,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-a8600e9b-50b0-4c1b-b007-9ffb988037dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-14aa4d2d-293b-44df-b636-3a0f68acb637,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-3e5cfd32-0866-4dc2-94b1-7eae1a4eb467,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-cddce57f-6234-49e3-b58d-5eab1ed8f98c,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-7d19cae3-cbbe-4d96-bef2-81c2a9c85366,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-940617215-172.17.0.2-1595494782951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36293,DS-f9d38360-6b24-4f59-bcb1-93dfd5914519,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-3f92d406-bacd-4d22-8ad1-8b6fe72b4bea,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-3b0c4536-d438-4217-bb7f-87a8346ef260,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-a6e462c9-5228-4436-bff7-92f056186ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:39143,DS-4d6a1010-1e25-463d-a962-5874bc961e77,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-8079e545-83d9-41c6-9d48-3258c15e47c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-d24984c3-83b5-4405-a19b-9e556a6be354,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-d5cc01ef-b2c4-4fbc-ab99-5b57fabc550a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-940617215-172.17.0.2-1595494782951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36293,DS-f9d38360-6b24-4f59-bcb1-93dfd5914519,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-3f92d406-bacd-4d22-8ad1-8b6fe72b4bea,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-3b0c4536-d438-4217-bb7f-87a8346ef260,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-a6e462c9-5228-4436-bff7-92f056186ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:39143,DS-4d6a1010-1e25-463d-a962-5874bc961e77,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-8079e545-83d9-41c6-9d48-3258c15e47c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-d24984c3-83b5-4405-a19b-9e556a6be354,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-d5cc01ef-b2c4-4fbc-ab99-5b57fabc550a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-540665262-172.17.0.2-1595495023204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44742,DS-b4618e7a-6e12-4174-ae20-63ca99fdf74a,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-963799f1-743a-46f6-81b5-d30bf21cbcea,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-76762ddd-c5fe-48cc-b941-25ce3dbfa50e,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-ad8fb5a2-0d40-4550-af3f-2fc772720c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-00053b38-7eca-4d53-bdb8-80e458e1cd84,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-8cdfb5e8-27bf-4a35-aa6b-aa2e96bf6b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-12f2aaf9-0cef-49d9-872d-d0e586f31ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-406b37e6-1aa7-4804-9cc2-7fb1e4795b91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-540665262-172.17.0.2-1595495023204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44742,DS-b4618e7a-6e12-4174-ae20-63ca99fdf74a,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-963799f1-743a-46f6-81b5-d30bf21cbcea,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-76762ddd-c5fe-48cc-b941-25ce3dbfa50e,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-ad8fb5a2-0d40-4550-af3f-2fc772720c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-00053b38-7eca-4d53-bdb8-80e458e1cd84,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-8cdfb5e8-27bf-4a35-aa6b-aa2e96bf6b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-12f2aaf9-0cef-49d9-872d-d0e586f31ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-406b37e6-1aa7-4804-9cc2-7fb1e4795b91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-202302332-172.17.0.2-1595495262565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43068,DS-43d4c04a-e7f8-4426-8699-973a48619de3,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-707dd350-21bb-43f1-915b-5edfc0c8acf5,DISK], DatanodeInfoWithStorage[127.0.0.1:38541,DS-2e82bb10-2da3-4579-9ce9-b8bcf7244120,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-ecd6dcce-2b50-429d-bc3f-65f94d490442,DISK], DatanodeInfoWithStorage[127.0.0.1:34496,DS-1d424c45-0c48-4189-a018-c905b0414345,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-18f40d29-1f53-4fff-a73d-a456f3ad4b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-29a71c6d-ea6e-4a23-bfe1-575dd53ee518,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-7b502f9e-a58e-454a-a733-e43b4dd0f324,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-202302332-172.17.0.2-1595495262565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43068,DS-43d4c04a-e7f8-4426-8699-973a48619de3,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-707dd350-21bb-43f1-915b-5edfc0c8acf5,DISK], DatanodeInfoWithStorage[127.0.0.1:38541,DS-2e82bb10-2da3-4579-9ce9-b8bcf7244120,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-ecd6dcce-2b50-429d-bc3f-65f94d490442,DISK], DatanodeInfoWithStorage[127.0.0.1:34496,DS-1d424c45-0c48-4189-a018-c905b0414345,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-18f40d29-1f53-4fff-a73d-a456f3ad4b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-29a71c6d-ea6e-4a23-bfe1-575dd53ee518,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-7b502f9e-a58e-454a-a733-e43b4dd0f324,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-765310270-172.17.0.2-1595495842230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37160,DS-a11f2687-598a-4a9e-8220-b23678e6fdf3,DISK], DatanodeInfoWithStorage[127.0.0.1:45830,DS-b89d6064-f245-45a1-9a72-ddf726bf5c62,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-b1aac473-b0b9-492d-9fdc-24cd149f2b68,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-2094bf71-74d7-4e39-b736-befc53036af0,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-6ef03da4-9d1b-4e59-835f-47c703934b59,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-5e5916a1-6110-43d7-bb7d-def97d414ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-5a6f8b65-4d73-4ebe-85a7-26041c67acff,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-bdc3aed0-95d3-4c45-9414-64ec50dde1b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-765310270-172.17.0.2-1595495842230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37160,DS-a11f2687-598a-4a9e-8220-b23678e6fdf3,DISK], DatanodeInfoWithStorage[127.0.0.1:45830,DS-b89d6064-f245-45a1-9a72-ddf726bf5c62,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-b1aac473-b0b9-492d-9fdc-24cd149f2b68,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-2094bf71-74d7-4e39-b736-befc53036af0,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-6ef03da4-9d1b-4e59-835f-47c703934b59,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-5e5916a1-6110-43d7-bb7d-def97d414ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-5a6f8b65-4d73-4ebe-85a7-26041c67acff,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-bdc3aed0-95d3-4c45-9414-64ec50dde1b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061733739-172.17.0.2-1595496915237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37583,DS-45afd367-a2cb-4088-a01d-f6f9d02d5bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-35ee8057-c6c8-44b9-a93a-e0da2dd82acf,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-44c7f2cd-1972-48b5-b8d6-e136dec9bf86,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-2c1c0f1e-0edd-43ca-89c0-a362c09fa09a,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-e84c1c61-45eb-4e86-844e-3f214e884fda,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-1d48d153-2f7d-417e-b186-5d8218463cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-601dd35e-92dc-42ef-aa90-f19563be4a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44692,DS-7f18986b-4dd3-450c-aad8-10b17551ed51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061733739-172.17.0.2-1595496915237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37583,DS-45afd367-a2cb-4088-a01d-f6f9d02d5bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-35ee8057-c6c8-44b9-a93a-e0da2dd82acf,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-44c7f2cd-1972-48b5-b8d6-e136dec9bf86,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-2c1c0f1e-0edd-43ca-89c0-a362c09fa09a,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-e84c1c61-45eb-4e86-844e-3f214e884fda,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-1d48d153-2f7d-417e-b186-5d8218463cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-601dd35e-92dc-42ef-aa90-f19563be4a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44692,DS-7f18986b-4dd3-450c-aad8-10b17551ed51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1398121806-172.17.0.2-1595497286168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34096,DS-e06ee0f2-d371-41a8-a3fe-c4d1390e8a52,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-fe4d5802-6f83-458c-b146-c8c1c82a77af,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-71a00341-c4fc-42af-8c49-72d3bd97b65b,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-1985d0da-7057-4fa6-b2aa-ec77cb6915fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-5743d75f-e5bc-4935-9981-63c0f14074c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44201,DS-cc09d136-9d5a-4ed5-9bbb-9f6dcebf03c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-e3ad5bdb-4afe-49c7-b174-def3ed3dad2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-17b604a9-725c-47cb-9507-29a330d25d29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1398121806-172.17.0.2-1595497286168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34096,DS-e06ee0f2-d371-41a8-a3fe-c4d1390e8a52,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-fe4d5802-6f83-458c-b146-c8c1c82a77af,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-71a00341-c4fc-42af-8c49-72d3bd97b65b,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-1985d0da-7057-4fa6-b2aa-ec77cb6915fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-5743d75f-e5bc-4935-9981-63c0f14074c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44201,DS-cc09d136-9d5a-4ed5-9bbb-9f6dcebf03c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-e3ad5bdb-4afe-49c7-b174-def3ed3dad2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-17b604a9-725c-47cb-9507-29a330d25d29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 6799
