reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-608282979-172.17.0.19-1595570174974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39810,DS-ba981426-25ed-4631-b08c-a3f2c27b9bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-8c3b7767-a3a7-4ef9-89b9-20cec2e5bc07,DISK], DatanodeInfoWithStorage[127.0.0.1:37480,DS-4dbd09b9-bc28-4277-b7d0-265ac543c94a,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-ca169c5e-589f-4f78-be83-98e064ff99a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-95ea0a32-72e9-48ac-9e2f-806085537a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-c75cf6db-faa0-447b-8096-92e7214d4d59,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-66813309-0ecb-497d-8453-2792a7c05f93,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-7aeb18e6-3fd9-4851-a76a-10d871335949,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-608282979-172.17.0.19-1595570174974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39810,DS-ba981426-25ed-4631-b08c-a3f2c27b9bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-8c3b7767-a3a7-4ef9-89b9-20cec2e5bc07,DISK], DatanodeInfoWithStorage[127.0.0.1:37480,DS-4dbd09b9-bc28-4277-b7d0-265ac543c94a,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-ca169c5e-589f-4f78-be83-98e064ff99a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-95ea0a32-72e9-48ac-9e2f-806085537a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-c75cf6db-faa0-447b-8096-92e7214d4d59,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-66813309-0ecb-497d-8453-2792a7c05f93,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-7aeb18e6-3fd9-4851-a76a-10d871335949,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1396686898-172.17.0.19-1595570275719:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39738,DS-1c3502b2-2011-414f-b7e4-f05eea74aad1,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-6270c494-c9ec-4978-bf79-977c976d9f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-37301fb9-2b5b-421f-94a1-f67ec3b758e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-0f60b138-4d93-4de1-869d-47f568f4881a,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-31adddbc-34c9-4faf-a2f3-23fefa61b740,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-7252baae-be5e-4a59-9181-049cec458754,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-9688e456-cbbb-407f-8ed9-1cbb732ccac2,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-dbb08ae4-dcbe-46b6-a04e-7fa7fbd88867,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1396686898-172.17.0.19-1595570275719:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39738,DS-1c3502b2-2011-414f-b7e4-f05eea74aad1,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-6270c494-c9ec-4978-bf79-977c976d9f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-37301fb9-2b5b-421f-94a1-f67ec3b758e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-0f60b138-4d93-4de1-869d-47f568f4881a,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-31adddbc-34c9-4faf-a2f3-23fefa61b740,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-7252baae-be5e-4a59-9181-049cec458754,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-9688e456-cbbb-407f-8ed9-1cbb732ccac2,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-dbb08ae4-dcbe-46b6-a04e-7fa7fbd88867,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-576579051-172.17.0.19-1595570482028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36933,DS-e25b31b0-5e19-4782-a244-eb02f0796ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-ef62c24b-2a41-4535-99ea-820437254c00,DISK], DatanodeInfoWithStorage[127.0.0.1:38302,DS-b692279a-7d66-48d9-86e8-baeac461a675,DISK], DatanodeInfoWithStorage[127.0.0.1:45319,DS-22e000ef-247e-4881-856e-816f7a3cc12e,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-e5e8f845-f495-4a12-a0a0-c49365f6f068,DISK], DatanodeInfoWithStorage[127.0.0.1:33514,DS-03ddcdcf-5a8a-433d-92bf-40e2e4ff4965,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-d1181cab-5e9c-4316-98c3-361148fcf96a,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-c4bf1de4-7f0c-4b0a-a5db-f30b63559b2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-576579051-172.17.0.19-1595570482028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36933,DS-e25b31b0-5e19-4782-a244-eb02f0796ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-ef62c24b-2a41-4535-99ea-820437254c00,DISK], DatanodeInfoWithStorage[127.0.0.1:38302,DS-b692279a-7d66-48d9-86e8-baeac461a675,DISK], DatanodeInfoWithStorage[127.0.0.1:45319,DS-22e000ef-247e-4881-856e-816f7a3cc12e,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-e5e8f845-f495-4a12-a0a0-c49365f6f068,DISK], DatanodeInfoWithStorage[127.0.0.1:33514,DS-03ddcdcf-5a8a-433d-92bf-40e2e4ff4965,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-d1181cab-5e9c-4316-98c3-361148fcf96a,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-c4bf1de4-7f0c-4b0a-a5db-f30b63559b2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-469337935-172.17.0.19-1595570514896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34640,DS-1090e5ad-dbcd-4fae-bb34-5d0abe4a20e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-489dca03-2c72-4b25-9654-3cee27a7b39b,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-08b4a47f-a8a0-48d1-83d0-6fb1049b2314,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-e5974b71-1529-473a-82a5-99037ef8b367,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-621bce17-6735-48fd-9605-eba8fa5efaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-f50553aa-2f23-43ab-948f-83bb5637df5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-6b0e9f0b-14a7-4d7e-b356-568992887bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-eb32f3ec-9303-4f96-9580-30046c230d35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-469337935-172.17.0.19-1595570514896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34640,DS-1090e5ad-dbcd-4fae-bb34-5d0abe4a20e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-489dca03-2c72-4b25-9654-3cee27a7b39b,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-08b4a47f-a8a0-48d1-83d0-6fb1049b2314,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-e5974b71-1529-473a-82a5-99037ef8b367,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-621bce17-6735-48fd-9605-eba8fa5efaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-f50553aa-2f23-43ab-948f-83bb5637df5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-6b0e9f0b-14a7-4d7e-b356-568992887bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-eb32f3ec-9303-4f96-9580-30046c230d35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1216410449-172.17.0.19-1595570785312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45234,DS-a113829b-166e-4962-a3a1-c3180d30a582,DISK], DatanodeInfoWithStorage[127.0.0.1:42358,DS-64d4a92d-29b7-48bd-ba07-ce64cdf88339,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-c17c3e61-ba44-4c2f-b8ef-5f1413639096,DISK], DatanodeInfoWithStorage[127.0.0.1:43677,DS-088c0a20-c5d9-497c-b4d2-fd69457c7266,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-23a5e4d6-cc50-4a9c-8dad-30e00e7582bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-8884f991-3b48-4bd4-982d-880c57262c70,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-fa4c3639-a033-4068-95a5-1ea0fb8489e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37703,DS-fb0f41f9-c76d-4079-85e8-dabc5de7eca0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1216410449-172.17.0.19-1595570785312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45234,DS-a113829b-166e-4962-a3a1-c3180d30a582,DISK], DatanodeInfoWithStorage[127.0.0.1:42358,DS-64d4a92d-29b7-48bd-ba07-ce64cdf88339,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-c17c3e61-ba44-4c2f-b8ef-5f1413639096,DISK], DatanodeInfoWithStorage[127.0.0.1:43677,DS-088c0a20-c5d9-497c-b4d2-fd69457c7266,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-23a5e4d6-cc50-4a9c-8dad-30e00e7582bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-8884f991-3b48-4bd4-982d-880c57262c70,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-fa4c3639-a033-4068-95a5-1ea0fb8489e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37703,DS-fb0f41f9-c76d-4079-85e8-dabc5de7eca0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1454788711-172.17.0.19-1595570847755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37026,DS-dfbee14f-d544-4b40-b8d3-121495716a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-ad52f3dd-f9a4-43be-a777-c9ecca8dd0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-d8b685cd-f2c0-4176-a06a-d007028a7116,DISK], DatanodeInfoWithStorage[127.0.0.1:43636,DS-01d97759-f181-447f-bcde-59a45e125817,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-b4c2e544-60ee-4cd7-a332-35a9b0b7c8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-8e269d3d-7d68-49ec-89e8-fa6ade85a6da,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-6aa4b9e7-d91d-441b-9b78-d4cbf64ccc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-1038a9f9-3bce-433c-8d6a-0d81c42b1932,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1454788711-172.17.0.19-1595570847755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37026,DS-dfbee14f-d544-4b40-b8d3-121495716a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-ad52f3dd-f9a4-43be-a777-c9ecca8dd0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-d8b685cd-f2c0-4176-a06a-d007028a7116,DISK], DatanodeInfoWithStorage[127.0.0.1:43636,DS-01d97759-f181-447f-bcde-59a45e125817,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-b4c2e544-60ee-4cd7-a332-35a9b0b7c8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-8e269d3d-7d68-49ec-89e8-fa6ade85a6da,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-6aa4b9e7-d91d-441b-9b78-d4cbf64ccc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-1038a9f9-3bce-433c-8d6a-0d81c42b1932,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1574524976-172.17.0.19-1595570999305:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35940,DS-c8ff950a-59c1-49aa-bda0-d6cc5fec181b,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-1c074209-7d91-4e1a-bcdc-57b04055b27b,DISK], DatanodeInfoWithStorage[127.0.0.1:38963,DS-37838c27-c80b-4e38-9295-152dca534789,DISK], DatanodeInfoWithStorage[127.0.0.1:34841,DS-f44761fa-0b7f-4744-aa5f-b88c91f4d38d,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-058dcc31-57e3-4163-8e8f-5be481d33342,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-01c93493-3a32-4f3a-9169-11bdbec7594f,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-7a1fcedd-d1ee-4cb0-80b9-c4407e49077d,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-924779a7-7530-4aba-b1f2-80e8b2111692,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1574524976-172.17.0.19-1595570999305:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35940,DS-c8ff950a-59c1-49aa-bda0-d6cc5fec181b,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-1c074209-7d91-4e1a-bcdc-57b04055b27b,DISK], DatanodeInfoWithStorage[127.0.0.1:38963,DS-37838c27-c80b-4e38-9295-152dca534789,DISK], DatanodeInfoWithStorage[127.0.0.1:34841,DS-f44761fa-0b7f-4744-aa5f-b88c91f4d38d,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-058dcc31-57e3-4163-8e8f-5be481d33342,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-01c93493-3a32-4f3a-9169-11bdbec7594f,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-7a1fcedd-d1ee-4cb0-80b9-c4407e49077d,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-924779a7-7530-4aba-b1f2-80e8b2111692,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-818111312-172.17.0.19-1595571030611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34198,DS-589e4a91-9409-4d9c-ad02-af6b7669a164,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-cb1a0b26-7c2c-4c1d-bd19-68a447f984bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37214,DS-01eabf47-b13e-4a52-ba3d-2aac9f6f2872,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-63692b2d-829b-4119-8bc4-4baa9d1da009,DISK], DatanodeInfoWithStorage[127.0.0.1:44984,DS-03b50acf-e085-4d58-8a5b-71c7fda77e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-f6e232e8-57d2-4f30-8f0a-bb165def4521,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-fd518e5d-57a0-4f11-b1d5-78f8cce8e1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-a9fd4499-c027-40cd-abea-9d5364e2917d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-818111312-172.17.0.19-1595571030611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34198,DS-589e4a91-9409-4d9c-ad02-af6b7669a164,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-cb1a0b26-7c2c-4c1d-bd19-68a447f984bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37214,DS-01eabf47-b13e-4a52-ba3d-2aac9f6f2872,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-63692b2d-829b-4119-8bc4-4baa9d1da009,DISK], DatanodeInfoWithStorage[127.0.0.1:44984,DS-03b50acf-e085-4d58-8a5b-71c7fda77e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-f6e232e8-57d2-4f30-8f0a-bb165def4521,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-fd518e5d-57a0-4f11-b1d5-78f8cce8e1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-a9fd4499-c027-40cd-abea-9d5364e2917d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1742650092-172.17.0.19-1595571286995:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45032,DS-7d8fb604-cdef-47b3-ad72-ba8097916fed,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-eca80dae-445d-4726-aa2a-bb4d3dee028d,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-69e701a9-0a18-4625-b3ff-4714d28d722e,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-51695487-eb79-4f2d-871d-40542bbea12b,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-bd80c9e0-8c8a-4b2a-b560-0f14c123596e,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-380e8785-449d-4339-bef5-4df2c4788022,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-06e27323-7be1-4e43-88ba-5acf7d7704dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-75981461-d455-4668-a56a-e4959532816f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1742650092-172.17.0.19-1595571286995:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45032,DS-7d8fb604-cdef-47b3-ad72-ba8097916fed,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-eca80dae-445d-4726-aa2a-bb4d3dee028d,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-69e701a9-0a18-4625-b3ff-4714d28d722e,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-51695487-eb79-4f2d-871d-40542bbea12b,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-bd80c9e0-8c8a-4b2a-b560-0f14c123596e,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-380e8785-449d-4339-bef5-4df2c4788022,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-06e27323-7be1-4e43-88ba-5acf7d7704dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-75981461-d455-4668-a56a-e4959532816f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2144235404-172.17.0.19-1595571836417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39888,DS-59303cdd-0813-4612-97f7-a13baf96c930,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-954883d1-0c4d-44f5-ae25-2178a7797a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-10446fd6-7d63-4b5f-9094-0998ab96db9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-2bf853c2-4221-4adf-99c7-e9f40febce45,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-1bd92bb0-1fad-4582-b5f1-88c4df98f236,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-14d18a79-5130-46f1-85cf-a253278ba27f,DISK], DatanodeInfoWithStorage[127.0.0.1:42693,DS-a3277a90-b8f5-4ffd-a9d9-a25dac331d40,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-8b8b923f-87d7-45a6-a4a1-b571f0d00afc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2144235404-172.17.0.19-1595571836417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39888,DS-59303cdd-0813-4612-97f7-a13baf96c930,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-954883d1-0c4d-44f5-ae25-2178a7797a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-10446fd6-7d63-4b5f-9094-0998ab96db9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-2bf853c2-4221-4adf-99c7-e9f40febce45,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-1bd92bb0-1fad-4582-b5f1-88c4df98f236,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-14d18a79-5130-46f1-85cf-a253278ba27f,DISK], DatanodeInfoWithStorage[127.0.0.1:42693,DS-a3277a90-b8f5-4ffd-a9d9-a25dac331d40,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-8b8b923f-87d7-45a6-a4a1-b571f0d00afc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-868518094-172.17.0.19-1595572405388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34371,DS-c2f255e1-8df3-4886-bb69-bfa8e8524b48,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-60ee6de6-7fab-4897-9165-d0248f6e431f,DISK], DatanodeInfoWithStorage[127.0.0.1:42395,DS-d2602750-d6d3-4f16-8134-5ddcc3d633e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-c096820e-8179-41a6-b282-2e2acb3c8eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-d4f815a2-31ea-4a1d-b160-e54ed00a159c,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-af371d48-6cb1-41d8-937c-5f8730009562,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-b545f6bf-5b10-4c33-99af-48d5b651ea57,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-20fad8ef-0222-45f4-86f9-876454782532,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-868518094-172.17.0.19-1595572405388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34371,DS-c2f255e1-8df3-4886-bb69-bfa8e8524b48,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-60ee6de6-7fab-4897-9165-d0248f6e431f,DISK], DatanodeInfoWithStorage[127.0.0.1:42395,DS-d2602750-d6d3-4f16-8134-5ddcc3d633e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-c096820e-8179-41a6-b282-2e2acb3c8eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-d4f815a2-31ea-4a1d-b160-e54ed00a159c,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-af371d48-6cb1-41d8-937c-5f8730009562,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-b545f6bf-5b10-4c33-99af-48d5b651ea57,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-20fad8ef-0222-45f4-86f9-876454782532,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-433366041-172.17.0.19-1595573933890:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42563,DS-2f02a378-b8e7-4d54-bd2b-4db8833e33f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-c809ba8d-3586-494c-8886-228a72576724,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-e7e31957-d495-4397-936a-8651b683cad9,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-b67e1353-12b7-46d2-9ea5-c3af8eb78ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-3521b5f3-a743-46e1-8f33-bd228119cbc1,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-811d98b7-f845-43c2-8ffd-1e4ee627919c,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-a4370814-01c1-47c4-a911-9435edaaf65f,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-c7be55ec-ac42-46f1-a2da-efcb31ca2f5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-433366041-172.17.0.19-1595573933890:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42563,DS-2f02a378-b8e7-4d54-bd2b-4db8833e33f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-c809ba8d-3586-494c-8886-228a72576724,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-e7e31957-d495-4397-936a-8651b683cad9,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-b67e1353-12b7-46d2-9ea5-c3af8eb78ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-3521b5f3-a743-46e1-8f33-bd228119cbc1,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-811d98b7-f845-43c2-8ffd-1e4ee627919c,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-a4370814-01c1-47c4-a911-9435edaaf65f,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-c7be55ec-ac42-46f1-a2da-efcb31ca2f5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-198744512-172.17.0.19-1595574180458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43550,DS-b47e17fc-2304-4e01-b61e-f5f6f7a690dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-d1db95cf-7593-4be5-b3a8-a376e5a691fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-876ef96e-d923-4c0d-b3f3-5f71fae88703,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-89f710ca-3ee9-48a0-a371-79c9fb8bd849,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-30bc61cc-758d-41b7-82e6-9b032d361a34,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-0fa980b0-23de-4c46-866f-405f9b0b87f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-d7d49f1c-a59b-49eb-aeda-d73699b512a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-947c5805-010c-4cc1-890a-fa410bc52172,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-198744512-172.17.0.19-1595574180458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43550,DS-b47e17fc-2304-4e01-b61e-f5f6f7a690dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-d1db95cf-7593-4be5-b3a8-a376e5a691fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-876ef96e-d923-4c0d-b3f3-5f71fae88703,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-89f710ca-3ee9-48a0-a371-79c9fb8bd849,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-30bc61cc-758d-41b7-82e6-9b032d361a34,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-0fa980b0-23de-4c46-866f-405f9b0b87f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-d7d49f1c-a59b-49eb-aeda-d73699b512a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-947c5805-010c-4cc1-890a-fa410bc52172,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-804474003-172.17.0.19-1595574258016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33520,DS-f143d584-5320-47e3-8cd9-f42137d38d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-7ad33e6e-d4c4-4b51-a8f6-dff79992de2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36200,DS-76bb51cb-91b8-402b-b6df-618ac8dbfbe2,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-9b1b7628-e436-44d5-a3f3-ccd8ef2a5df3,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-316c0813-0d9b-4926-9cd6-d8a2f8e51c01,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-bb5031cf-ddde-4a71-bf90-e9a90acd7a53,DISK], DatanodeInfoWithStorage[127.0.0.1:44343,DS-27a10742-de43-466d-b76f-be3982f75146,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-f82de885-ae0b-4dd0-9051-34c9f79f681a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-804474003-172.17.0.19-1595574258016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33520,DS-f143d584-5320-47e3-8cd9-f42137d38d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-7ad33e6e-d4c4-4b51-a8f6-dff79992de2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36200,DS-76bb51cb-91b8-402b-b6df-618ac8dbfbe2,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-9b1b7628-e436-44d5-a3f3-ccd8ef2a5df3,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-316c0813-0d9b-4926-9cd6-d8a2f8e51c01,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-bb5031cf-ddde-4a71-bf90-e9a90acd7a53,DISK], DatanodeInfoWithStorage[127.0.0.1:44343,DS-27a10742-de43-466d-b76f-be3982f75146,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-f82de885-ae0b-4dd0-9051-34c9f79f681a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1413944391-172.17.0.19-1595574331955:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40116,DS-5c14a756-8c99-40fe-a18b-555fbfd13552,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-46ad0253-6f36-490e-8346-a96ccd133d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-5244d729-eb26-4880-b8bf-8f993a637c10,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-7fcbac13-767d-49f5-a1a1-ffda802dacf0,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-da4e9a93-d6f5-4734-85d3-4a57bcadd09b,DISK], DatanodeInfoWithStorage[127.0.0.1:37146,DS-bc9c735c-0e67-4263-b8c8-30a25a3fc2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-7659138e-579e-459b-bac2-0e2b6ee6a95f,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-5fb09ab5-0b46-40dc-ade3-fe105f03ad92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1413944391-172.17.0.19-1595574331955:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40116,DS-5c14a756-8c99-40fe-a18b-555fbfd13552,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-46ad0253-6f36-490e-8346-a96ccd133d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-5244d729-eb26-4880-b8bf-8f993a637c10,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-7fcbac13-767d-49f5-a1a1-ffda802dacf0,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-da4e9a93-d6f5-4734-85d3-4a57bcadd09b,DISK], DatanodeInfoWithStorage[127.0.0.1:37146,DS-bc9c735c-0e67-4263-b8c8-30a25a3fc2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-7659138e-579e-459b-bac2-0e2b6ee6a95f,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-5fb09ab5-0b46-40dc-ade3-fe105f03ad92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5252
