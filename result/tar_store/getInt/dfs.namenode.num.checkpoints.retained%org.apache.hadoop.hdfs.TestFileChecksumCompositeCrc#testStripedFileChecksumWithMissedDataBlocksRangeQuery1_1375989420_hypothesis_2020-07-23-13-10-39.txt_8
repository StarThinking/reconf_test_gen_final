reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-882905438-172.17.0.4-1595510229300:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35159,DS-5191a7ee-756a-4f37-8585-5c7ca6d90bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-f9ab9316-c425-45a0-a37f-5aaeab296425,DISK], DatanodeInfoWithStorage[127.0.0.1:37759,DS-1dde7f3f-e3ac-4a3c-bd58-28e618f8023b,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-f9e9e9de-d79a-4e5c-8054-f20d73885e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-2ebdfedd-a3d0-4acc-b37a-bc3b83a41eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:46010,DS-94dc6bbc-667f-466d-8c7e-57a525bede10,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-56d8e697-9164-4cf3-a0cf-439b87e1a20d,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-dae9ec5f-6865-4a94-a90e-4f97ce26d0d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-882905438-172.17.0.4-1595510229300:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35159,DS-5191a7ee-756a-4f37-8585-5c7ca6d90bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-f9ab9316-c425-45a0-a37f-5aaeab296425,DISK], DatanodeInfoWithStorage[127.0.0.1:37759,DS-1dde7f3f-e3ac-4a3c-bd58-28e618f8023b,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-f9e9e9de-d79a-4e5c-8054-f20d73885e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-2ebdfedd-a3d0-4acc-b37a-bc3b83a41eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:46010,DS-94dc6bbc-667f-466d-8c7e-57a525bede10,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-56d8e697-9164-4cf3-a0cf-439b87e1a20d,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-dae9ec5f-6865-4a94-a90e-4f97ce26d0d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1838311891-172.17.0.4-1595510805702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34277,DS-48be9893-47de-41cf-ba53-2436ba91ec22,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-379339b8-13c9-479f-962c-9ed7c1046d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-9d804639-c512-47cb-983a-82d219a5d3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-822c6e49-0369-4237-ac26-edecba753ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-8fd81e66-f7c4-4346-b737-284bd2f94ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-5d5c3f29-6f07-4da0-8ae8-aebad085147c,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-d75d7909-cf76-4d5b-a0eb-3af884b491e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-1aadddb0-d29c-4374-b213-e737777d9c7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1838311891-172.17.0.4-1595510805702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34277,DS-48be9893-47de-41cf-ba53-2436ba91ec22,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-379339b8-13c9-479f-962c-9ed7c1046d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-9d804639-c512-47cb-983a-82d219a5d3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-822c6e49-0369-4237-ac26-edecba753ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-8fd81e66-f7c4-4346-b737-284bd2f94ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-5d5c3f29-6f07-4da0-8ae8-aebad085147c,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-d75d7909-cf76-4d5b-a0eb-3af884b491e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-1aadddb0-d29c-4374-b213-e737777d9c7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-558187133-172.17.0.4-1595510900477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39461,DS-ac62b216-a02b-47ef-b98c-bc0933afa1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-84d7db72-3448-4dce-80d5-c48e347992ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-5a55cf64-c516-4d10-bda8-c1403af28b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-c36d976a-8ee9-45ed-ac98-a405a66909b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-295eb5d0-c05e-4b8c-ba8a-b43ff7047a50,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-be0f128e-3375-4363-8f11-5d08f9b0d482,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-652e9762-b59a-43bf-b9ca-f6fcfc49396e,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-1314d853-ea20-43b8-a21c-23e77b50adb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-558187133-172.17.0.4-1595510900477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39461,DS-ac62b216-a02b-47ef-b98c-bc0933afa1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-84d7db72-3448-4dce-80d5-c48e347992ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-5a55cf64-c516-4d10-bda8-c1403af28b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-c36d976a-8ee9-45ed-ac98-a405a66909b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-295eb5d0-c05e-4b8c-ba8a-b43ff7047a50,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-be0f128e-3375-4363-8f11-5d08f9b0d482,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-652e9762-b59a-43bf-b9ca-f6fcfc49396e,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-1314d853-ea20-43b8-a21c-23e77b50adb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-707200738-172.17.0.4-1595511577976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46375,DS-6ccc8dee-1f58-45e6-87bd-043b2ddd8b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-c42b57aa-dc79-4301-b359-221eb762938f,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-2f0089e6-8428-49af-bdd1-557217c87839,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-13b27bb6-3616-443f-89e8-df6d7ae9a3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-48d4d7ab-7983-4853-8648-37d4507433f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-7231ac71-0df7-4b01-aa40-bcc53ce5bef8,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-72d9100e-860e-45d0-97ae-77baafdaec43,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-a6b1aef7-8d35-43ef-9171-90062e43e474,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-707200738-172.17.0.4-1595511577976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46375,DS-6ccc8dee-1f58-45e6-87bd-043b2ddd8b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-c42b57aa-dc79-4301-b359-221eb762938f,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-2f0089e6-8428-49af-bdd1-557217c87839,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-13b27bb6-3616-443f-89e8-df6d7ae9a3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-48d4d7ab-7983-4853-8648-37d4507433f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-7231ac71-0df7-4b01-aa40-bcc53ce5bef8,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-72d9100e-860e-45d0-97ae-77baafdaec43,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-a6b1aef7-8d35-43ef-9171-90062e43e474,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2041014099-172.17.0.4-1595511999043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46712,DS-4fe95d20-2c20-46f9-b3b0-e1e8e2cc0695,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-92cc18fa-ef0c-4fab-9440-926dfa8981c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-b4b111f6-f0a9-464a-9606-34848f1fc819,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-c3b5670e-f8c2-40b5-9b91-90d94718492e,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-cb520c43-ba61-450b-adfa-e33f9c19d972,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-1bf50941-f2e9-4b66-9fea-f58d4382309c,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-3bf473f2-c9db-4fd7-bbd5-5f932e05f3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-e0e7f703-ab1e-44ac-91f2-0761859f005d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2041014099-172.17.0.4-1595511999043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46712,DS-4fe95d20-2c20-46f9-b3b0-e1e8e2cc0695,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-92cc18fa-ef0c-4fab-9440-926dfa8981c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-b4b111f6-f0a9-464a-9606-34848f1fc819,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-c3b5670e-f8c2-40b5-9b91-90d94718492e,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-cb520c43-ba61-450b-adfa-e33f9c19d972,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-1bf50941-f2e9-4b66-9fea-f58d4382309c,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-3bf473f2-c9db-4fd7-bbd5-5f932e05f3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-e0e7f703-ab1e-44ac-91f2-0761859f005d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1822503234-172.17.0.4-1595512508698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38794,DS-4cf38a39-840f-42a8-919e-7ef8e3afba14,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-3f5b2705-07bb-4b6a-b959-c9e8bc622ede,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-44d534e2-42c6-4db1-a78c-e974683fa7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-cec35bec-a55f-4f64-8ab4-ae78b26c0b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-5df30812-0273-4341-b0cd-e9771998244b,DISK], DatanodeInfoWithStorage[127.0.0.1:33374,DS-5431a6fe-3301-4119-a4f1-7e72310578ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-30e8bc06-8eba-41a1-bf9f-e363c0b68132,DISK], DatanodeInfoWithStorage[127.0.0.1:42716,DS-e4fe3aef-be31-4d09-af7c-b8421f8ea60c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1822503234-172.17.0.4-1595512508698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38794,DS-4cf38a39-840f-42a8-919e-7ef8e3afba14,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-3f5b2705-07bb-4b6a-b959-c9e8bc622ede,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-44d534e2-42c6-4db1-a78c-e974683fa7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-cec35bec-a55f-4f64-8ab4-ae78b26c0b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-5df30812-0273-4341-b0cd-e9771998244b,DISK], DatanodeInfoWithStorage[127.0.0.1:33374,DS-5431a6fe-3301-4119-a4f1-7e72310578ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-30e8bc06-8eba-41a1-bf9f-e363c0b68132,DISK], DatanodeInfoWithStorage[127.0.0.1:42716,DS-e4fe3aef-be31-4d09-af7c-b8421f8ea60c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-273052542-172.17.0.4-1595513372259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39997,DS-0d5a6ce4-48f5-4d34-ba15-f062d3fa81d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-3ba6bebf-f0b6-4232-8c33-46ba6182cbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-55218ffc-3d26-4cb9-a42b-0367330f51c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-f989c928-7802-4487-b8d5-b0d4a6ca592b,DISK], DatanodeInfoWithStorage[127.0.0.1:43636,DS-64357440-5c7a-43e9-8efe-ceaf340cfc52,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-3dec8829-2010-47f4-a93e-d461eb3c99be,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-8093f057-5fdf-43bd-9223-9c41dd4108d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-864e93ac-d38f-416c-829e-46cc97d98f5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-273052542-172.17.0.4-1595513372259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39997,DS-0d5a6ce4-48f5-4d34-ba15-f062d3fa81d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-3ba6bebf-f0b6-4232-8c33-46ba6182cbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-55218ffc-3d26-4cb9-a42b-0367330f51c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-f989c928-7802-4487-b8d5-b0d4a6ca592b,DISK], DatanodeInfoWithStorage[127.0.0.1:43636,DS-64357440-5c7a-43e9-8efe-ceaf340cfc52,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-3dec8829-2010-47f4-a93e-d461eb3c99be,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-8093f057-5fdf-43bd-9223-9c41dd4108d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-864e93ac-d38f-416c-829e-46cc97d98f5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-607507680-172.17.0.4-1595513423416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45372,DS-d1f6900c-7442-49b9-85d9-ce8b9fd55fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-67f7cb34-3ca5-4f63-a097-fafcb2874179,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-48491c9a-703e-4356-a89a-ea589d578d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-c61ed50e-174a-402e-ab12-ea62e8f36965,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-6333c806-ca72-4ffb-b94a-8ab83bcbf682,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-47a83be3-cab2-4b8f-8e73-45dfb46ad97c,DISK], DatanodeInfoWithStorage[127.0.0.1:41995,DS-4e4bb691-e99a-4e47-865e-e2f646910bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-f65265b7-7799-4d75-ac83-c691c93fbfc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-607507680-172.17.0.4-1595513423416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45372,DS-d1f6900c-7442-49b9-85d9-ce8b9fd55fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-67f7cb34-3ca5-4f63-a097-fafcb2874179,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-48491c9a-703e-4356-a89a-ea589d578d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-c61ed50e-174a-402e-ab12-ea62e8f36965,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-6333c806-ca72-4ffb-b94a-8ab83bcbf682,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-47a83be3-cab2-4b8f-8e73-45dfb46ad97c,DISK], DatanodeInfoWithStorage[127.0.0.1:41995,DS-4e4bb691-e99a-4e47-865e-e2f646910bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-f65265b7-7799-4d75-ac83-c691c93fbfc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-346796879-172.17.0.4-1595513691316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37895,DS-fc5669d0-a595-45b1-9923-ae1914c8e5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-24ac6e5a-2ae8-4e9d-af54-8f28c4309ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-027b18d0-2c4f-4d39-90f4-cdf1e1f67bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-1c10acb1-1a8c-4e8e-83f2-805ef6c2e9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-55dcfe3f-6947-4113-9707-5733687d7972,DISK], DatanodeInfoWithStorage[127.0.0.1:34994,DS-d8cd9784-5931-4d4b-8ac7-79a299951012,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-10d5f957-c45b-453d-a2cb-879c34ab47d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-0f06db1e-83f8-446a-b119-535a32baf541,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-346796879-172.17.0.4-1595513691316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37895,DS-fc5669d0-a595-45b1-9923-ae1914c8e5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-24ac6e5a-2ae8-4e9d-af54-8f28c4309ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-027b18d0-2c4f-4d39-90f4-cdf1e1f67bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-1c10acb1-1a8c-4e8e-83f2-805ef6c2e9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-55dcfe3f-6947-4113-9707-5733687d7972,DISK], DatanodeInfoWithStorage[127.0.0.1:34994,DS-d8cd9784-5931-4d4b-8ac7-79a299951012,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-10d5f957-c45b-453d-a2cb-879c34ab47d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-0f06db1e-83f8-446a-b119-535a32baf541,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-76066872-172.17.0.4-1595514068681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46019,DS-a5c2028d-e67b-4b96-baf7-06a728d13faf,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-77225acd-73b4-4fec-8f43-1e72586eb39f,DISK], DatanodeInfoWithStorage[127.0.0.1:46070,DS-40c7dbbd-76e7-4c24-a048-a460450112f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-153ac2fc-4c43-412a-a4ad-a5e186695c92,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-830dcf75-a334-45a8-ba64-58250316b306,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-14c51def-5349-4031-a45d-7deded754557,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-402bb010-7e0f-4978-827f-888504d0935d,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-64a343d5-c720-4359-a684-e18dcba038cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-76066872-172.17.0.4-1595514068681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46019,DS-a5c2028d-e67b-4b96-baf7-06a728d13faf,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-77225acd-73b4-4fec-8f43-1e72586eb39f,DISK], DatanodeInfoWithStorage[127.0.0.1:46070,DS-40c7dbbd-76e7-4c24-a048-a460450112f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-153ac2fc-4c43-412a-a4ad-a5e186695c92,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-830dcf75-a334-45a8-ba64-58250316b306,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-14c51def-5349-4031-a45d-7deded754557,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-402bb010-7e0f-4978-827f-888504d0935d,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-64a343d5-c720-4359-a684-e18dcba038cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1729054882-172.17.0.4-1595514112603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33049,DS-22b83c7b-4377-407f-93d5-85d42f00debf,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-c0d9cf2b-d30b-4fc8-b9eb-308bc2b88e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-82e11b15-3f45-4c38-950d-028207a95c04,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-8b71f83c-38ac-40e5-a944-bcc5d6877af6,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-81562b00-d8bf-46d8-8bc0-cc26436129a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-e6288b75-8b93-4d45-bc87-496f15d2c2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-d95cf35f-f04c-4a47-af86-f3a16fec515f,DISK], DatanodeInfoWithStorage[127.0.0.1:33114,DS-800163ab-a613-4f0e-a243-79b4af21e8ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1729054882-172.17.0.4-1595514112603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33049,DS-22b83c7b-4377-407f-93d5-85d42f00debf,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-c0d9cf2b-d30b-4fc8-b9eb-308bc2b88e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-82e11b15-3f45-4c38-950d-028207a95c04,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-8b71f83c-38ac-40e5-a944-bcc5d6877af6,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-81562b00-d8bf-46d8-8bc0-cc26436129a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-e6288b75-8b93-4d45-bc87-496f15d2c2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-d95cf35f-f04c-4a47-af86-f3a16fec515f,DISK], DatanodeInfoWithStorage[127.0.0.1:33114,DS-800163ab-a613-4f0e-a243-79b4af21e8ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-152299636-172.17.0.4-1595515259455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36836,DS-d6e54904-b2d8-4bfd-ac6f-f31a629fce85,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-3970171c-d8db-44c1-b077-76b53f3e376f,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-0b74ee1a-1dc6-49c8-b9c1-1d0488d2304c,DISK], DatanodeInfoWithStorage[127.0.0.1:40968,DS-d109c5d2-19c8-4017-b02d-4c312ba0bbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-4be186f7-9b0d-4323-ada1-b72245fa42e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-3fd30615-3e31-4e06-8bde-806cf37fbb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-d9610e0f-8b49-476d-8d3f-12f23f9bfc01,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-173198fd-1020-489d-9969-383ba2af6607,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-152299636-172.17.0.4-1595515259455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36836,DS-d6e54904-b2d8-4bfd-ac6f-f31a629fce85,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-3970171c-d8db-44c1-b077-76b53f3e376f,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-0b74ee1a-1dc6-49c8-b9c1-1d0488d2304c,DISK], DatanodeInfoWithStorage[127.0.0.1:40968,DS-d109c5d2-19c8-4017-b02d-4c312ba0bbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-4be186f7-9b0d-4323-ada1-b72245fa42e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-3fd30615-3e31-4e06-8bde-806cf37fbb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-d9610e0f-8b49-476d-8d3f-12f23f9bfc01,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-173198fd-1020-489d-9969-383ba2af6607,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1839949823-172.17.0.4-1595515774524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36482,DS-12eb9559-e594-4d7f-b5dd-cf23a075d68b,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-a4e51868-b482-4552-83a8-30560189b956,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-8021a093-1824-4635-b7d8-dc883a7f2997,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-996225ed-575f-4305-940f-da572764c6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-7d8adf96-661f-41b2-89d6-d8ebdc92cf65,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-8961c21f-33b9-4598-8d60-8b5175360272,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-72dfb21f-5038-42e2-9e19-ee83e69ba382,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-e5cb453f-7192-4986-9209-6e1d5ba5a560,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1839949823-172.17.0.4-1595515774524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36482,DS-12eb9559-e594-4d7f-b5dd-cf23a075d68b,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-a4e51868-b482-4552-83a8-30560189b956,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-8021a093-1824-4635-b7d8-dc883a7f2997,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-996225ed-575f-4305-940f-da572764c6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-7d8adf96-661f-41b2-89d6-d8ebdc92cf65,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-8961c21f-33b9-4598-8d60-8b5175360272,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-72dfb21f-5038-42e2-9e19-ee83e69ba382,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-e5cb453f-7192-4986-9209-6e1d5ba5a560,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1024943084-172.17.0.4-1595515817343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38037,DS-e74d8fba-4b53-4880-bb96-30ef2c756807,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-8fff9fc3-416b-4d57-9ac9-db29ace7f78c,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-11492e71-e3a9-4e0b-90a4-5cdc87c03e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-c1ba2f98-c4f0-422f-828d-76a0bae85ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-0590a1cc-57db-40ad-a8cc-777bff529d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46817,DS-1d521ad7-401e-41b7-90dd-c50970286c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-915e0131-33ac-46e8-a9f0-74755f27e266,DISK], DatanodeInfoWithStorage[127.0.0.1:34235,DS-b9781d38-8623-4efb-8063-dab7c16796da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1024943084-172.17.0.4-1595515817343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38037,DS-e74d8fba-4b53-4880-bb96-30ef2c756807,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-8fff9fc3-416b-4d57-9ac9-db29ace7f78c,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-11492e71-e3a9-4e0b-90a4-5cdc87c03e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-c1ba2f98-c4f0-422f-828d-76a0bae85ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-0590a1cc-57db-40ad-a8cc-777bff529d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46817,DS-1d521ad7-401e-41b7-90dd-c50970286c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-915e0131-33ac-46e8-a9f0-74755f27e266,DISK], DatanodeInfoWithStorage[127.0.0.1:34235,DS-b9781d38-8623-4efb-8063-dab7c16796da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1793926111-172.17.0.4-1595516049908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46490,DS-d616e095-5a94-4877-8252-3798d1ffb6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-73d22b43-6ddc-41d7-9d3e-33e3e7af5f26,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-63c31c13-2e78-407f-acb9-ae141e8a77b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-b25c2f01-2b32-40c6-9237-85bc703865c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-5d7714f0-2c73-4610-918d-023bebc2d801,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-e0f78a72-a905-40b3-8ba0-979e53890be0,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-7d217cc0-e901-4e90-95b7-e4acd068b084,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-319e2cbc-416b-4993-b8a7-34dddcc44092,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1793926111-172.17.0.4-1595516049908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46490,DS-d616e095-5a94-4877-8252-3798d1ffb6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-73d22b43-6ddc-41d7-9d3e-33e3e7af5f26,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-63c31c13-2e78-407f-acb9-ae141e8a77b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-b25c2f01-2b32-40c6-9237-85bc703865c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-5d7714f0-2c73-4610-918d-023bebc2d801,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-e0f78a72-a905-40b3-8ba0-979e53890be0,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-7d217cc0-e901-4e90-95b7-e4acd068b084,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-319e2cbc-416b-4993-b8a7-34dddcc44092,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-484744842-172.17.0.4-1595516889797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39793,DS-618f5aca-a207-4c30-b94c-d49f94721ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-883a7541-b5cd-4c0b-8cb0-3ac27e27c8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-7c7df925-5db0-4893-9b36-0f8f9ca8672e,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-c8fb67d6-620a-4338-89fc-250b59279477,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-511d975c-3ba0-469f-9cb3-13b0f925629b,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-c7fc994c-1650-47a0-9e10-70c743a2d41c,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-e6b3b152-c8ef-4aea-ade2-b442c882861e,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-80be5858-d2a9-4374-8557-247fbccca1fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-484744842-172.17.0.4-1595516889797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39793,DS-618f5aca-a207-4c30-b94c-d49f94721ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-883a7541-b5cd-4c0b-8cb0-3ac27e27c8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-7c7df925-5db0-4893-9b36-0f8f9ca8672e,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-c8fb67d6-620a-4338-89fc-250b59279477,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-511d975c-3ba0-469f-9cb3-13b0f925629b,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-c7fc994c-1650-47a0-9e10-70c743a2d41c,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-e6b3b152-c8ef-4aea-ade2-b442c882861e,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-80be5858-d2a9-4374-8557-247fbccca1fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 7078
