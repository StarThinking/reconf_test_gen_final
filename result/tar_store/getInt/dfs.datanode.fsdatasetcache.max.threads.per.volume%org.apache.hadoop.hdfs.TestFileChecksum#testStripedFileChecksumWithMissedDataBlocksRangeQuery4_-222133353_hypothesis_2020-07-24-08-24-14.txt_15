reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-630691240-172.17.0.10-1595579137800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39930,DS-2ad25fab-ff19-4099-9e98-d69e2f547093,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-bf7193d4-bea3-4ae1-8826-159417ddca0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-3d159adb-7f1d-46bb-adc7-9929f753624b,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-c4695750-e2d4-4344-a498-5151297643d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-ec3a18fb-d415-458f-bd41-bae6d7ec12c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-047c43b6-0a67-4559-8b00-faccd112e799,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-863a0698-64a8-4ec6-b27b-a57e54a31664,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-fe6754bb-e1b1-4855-9aee-5b52099e88d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-630691240-172.17.0.10-1595579137800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39930,DS-2ad25fab-ff19-4099-9e98-d69e2f547093,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-bf7193d4-bea3-4ae1-8826-159417ddca0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-3d159adb-7f1d-46bb-adc7-9929f753624b,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-c4695750-e2d4-4344-a498-5151297643d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-ec3a18fb-d415-458f-bd41-bae6d7ec12c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-047c43b6-0a67-4559-8b00-faccd112e799,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-863a0698-64a8-4ec6-b27b-a57e54a31664,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-fe6754bb-e1b1-4855-9aee-5b52099e88d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2057125924-172.17.0.10-1595579551387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44098,DS-140646a9-97bf-407c-b0f0-7c96091cb2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-e8ec4631-7339-4327-9427-04373c811057,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-475fff0b-b2e2-4bc5-b047-308e2b607452,DISK], DatanodeInfoWithStorage[127.0.0.1:43229,DS-e9b9d612-4fb1-4bd8-b091-3f5c7e8c99f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-5adf19c8-f162-41d6-afbd-d098cb5b3755,DISK], DatanodeInfoWithStorage[127.0.0.1:41769,DS-31e7a2c8-5f6b-4dfb-b444-a1fa4d1cc57f,DISK], DatanodeInfoWithStorage[127.0.0.1:43901,DS-ba3f05f0-230c-407d-ae51-b2268fbf336d,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-709314b5-da53-4fce-9457-10a1badabdca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2057125924-172.17.0.10-1595579551387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44098,DS-140646a9-97bf-407c-b0f0-7c96091cb2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-e8ec4631-7339-4327-9427-04373c811057,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-475fff0b-b2e2-4bc5-b047-308e2b607452,DISK], DatanodeInfoWithStorage[127.0.0.1:43229,DS-e9b9d612-4fb1-4bd8-b091-3f5c7e8c99f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-5adf19c8-f162-41d6-afbd-d098cb5b3755,DISK], DatanodeInfoWithStorage[127.0.0.1:41769,DS-31e7a2c8-5f6b-4dfb-b444-a1fa4d1cc57f,DISK], DatanodeInfoWithStorage[127.0.0.1:43901,DS-ba3f05f0-230c-407d-ae51-b2268fbf336d,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-709314b5-da53-4fce-9457-10a1badabdca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-903565415-172.17.0.10-1595579584206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46318,DS-aa85b913-1f13-4e09-b6a6-14c42f30d9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-ef15e086-2a73-4ecf-9a56-bc5bb9eb44c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-ba31993c-1045-4b78-990a-b68c57e72354,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-f6371c99-2fff-43c7-b467-672e957ad00d,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-27d84d56-bbe7-4338-be78-b5bb2e2a4669,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-bc7d4805-64b4-40e0-bfc8-a73e1677a291,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-81f173f5-34f5-44c6-8f6e-d2ddb3da7349,DISK], DatanodeInfoWithStorage[127.0.0.1:32859,DS-766631c4-1bca-436f-ae13-96ca9a3f565d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-903565415-172.17.0.10-1595579584206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46318,DS-aa85b913-1f13-4e09-b6a6-14c42f30d9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-ef15e086-2a73-4ecf-9a56-bc5bb9eb44c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-ba31993c-1045-4b78-990a-b68c57e72354,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-f6371c99-2fff-43c7-b467-672e957ad00d,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-27d84d56-bbe7-4338-be78-b5bb2e2a4669,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-bc7d4805-64b4-40e0-bfc8-a73e1677a291,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-81f173f5-34f5-44c6-8f6e-d2ddb3da7349,DISK], DatanodeInfoWithStorage[127.0.0.1:32859,DS-766631c4-1bca-436f-ae13-96ca9a3f565d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-159973799-172.17.0.10-1595579618368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33658,DS-9449ee26-d279-4840-9675-e095ac6ad140,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-13a46115-a5eb-47cf-88f4-ed9b4d138286,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-26de5636-29f5-4347-bd86-3696fa94b624,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-8cb94e95-92ad-4e11-b39a-dc57bf9bc4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-13d24754-4cce-4fc7-887d-c0aa9daac98d,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-9c744b0b-5090-4a97-94d0-5b8359a1b305,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-70714106-09d9-410d-8381-89daddf370a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-652fda25-96cf-45a4-82ba-81f5cd7999f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-159973799-172.17.0.10-1595579618368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33658,DS-9449ee26-d279-4840-9675-e095ac6ad140,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-13a46115-a5eb-47cf-88f4-ed9b4d138286,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-26de5636-29f5-4347-bd86-3696fa94b624,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-8cb94e95-92ad-4e11-b39a-dc57bf9bc4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-13d24754-4cce-4fc7-887d-c0aa9daac98d,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-9c744b0b-5090-4a97-94d0-5b8359a1b305,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-70714106-09d9-410d-8381-89daddf370a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-652fda25-96cf-45a4-82ba-81f5cd7999f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-160853709-172.17.0.10-1595579710299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36217,DS-9b444989-d4b6-47d5-b668-3d94c0877c43,DISK], DatanodeInfoWithStorage[127.0.0.1:44654,DS-73e1c8b4-7c51-4dbd-9e10-6d41ef63e7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-fd66b9af-a93f-4b37-b52b-ee12907fe337,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-5cac57f9-fa16-4fe2-90cc-3f487de611a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-6a7e93f8-3c57-4b5c-997a-c6e636c1e13a,DISK], DatanodeInfoWithStorage[127.0.0.1:39224,DS-0be6d538-feb6-4df9-8f7d-16d6aff28adc,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-ad9829ba-6c79-4cc8-9b3a-130b4d9d37c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34266,DS-d23b0d8a-878c-48fa-9372-98580124ec49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-160853709-172.17.0.10-1595579710299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36217,DS-9b444989-d4b6-47d5-b668-3d94c0877c43,DISK], DatanodeInfoWithStorage[127.0.0.1:44654,DS-73e1c8b4-7c51-4dbd-9e10-6d41ef63e7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-fd66b9af-a93f-4b37-b52b-ee12907fe337,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-5cac57f9-fa16-4fe2-90cc-3f487de611a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-6a7e93f8-3c57-4b5c-997a-c6e636c1e13a,DISK], DatanodeInfoWithStorage[127.0.0.1:39224,DS-0be6d538-feb6-4df9-8f7d-16d6aff28adc,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-ad9829ba-6c79-4cc8-9b3a-130b4d9d37c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34266,DS-d23b0d8a-878c-48fa-9372-98580124ec49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-376918151-172.17.0.10-1595579828037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38698,DS-77650412-2916-4978-9275-f50699b6dc84,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-313d8e49-bfac-4cb2-8d76-77254962b034,DISK], DatanodeInfoWithStorage[127.0.0.1:34989,DS-8abf7b35-8f9c-4086-821a-591c2459d97a,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-fea70c52-ab4b-4812-b4cb-bf3be0b726f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-b2888367-95bc-4882-8bd3-39e9f31d0e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-f5529670-0cba-4749-ad66-9b75fcd159da,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-68a8fb30-7f10-496a-8adf-9f282070deee,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-0ae6a2f4-5125-4d4b-93c4-5bae7fd441f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-376918151-172.17.0.10-1595579828037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38698,DS-77650412-2916-4978-9275-f50699b6dc84,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-313d8e49-bfac-4cb2-8d76-77254962b034,DISK], DatanodeInfoWithStorage[127.0.0.1:34989,DS-8abf7b35-8f9c-4086-821a-591c2459d97a,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-fea70c52-ab4b-4812-b4cb-bf3be0b726f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-b2888367-95bc-4882-8bd3-39e9f31d0e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-f5529670-0cba-4749-ad66-9b75fcd159da,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-68a8fb30-7f10-496a-8adf-9f282070deee,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-0ae6a2f4-5125-4d4b-93c4-5bae7fd441f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1812143778-172.17.0.10-1595580153398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40421,DS-19cf4251-c60b-42f6-8e3b-8cc42b8cbe15,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-5be73247-be74-4148-bc9d-1f28286972ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-eec26489-0616-4408-86b6-3d39e4bc1973,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-29b8ea07-e570-4678-88e9-85724496a7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-dc97b1d7-aec0-4301-aac7-e65baa332016,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-d34ee581-96b3-44dd-a179-cdff78946ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-2f34ed11-fb16-45cd-9ebd-e743313b939f,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-a61ba89a-9b59-4434-a2a4-eb008a540eef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1812143778-172.17.0.10-1595580153398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40421,DS-19cf4251-c60b-42f6-8e3b-8cc42b8cbe15,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-5be73247-be74-4148-bc9d-1f28286972ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-eec26489-0616-4408-86b6-3d39e4bc1973,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-29b8ea07-e570-4678-88e9-85724496a7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-dc97b1d7-aec0-4301-aac7-e65baa332016,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-d34ee581-96b3-44dd-a179-cdff78946ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-2f34ed11-fb16-45cd-9ebd-e743313b939f,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-a61ba89a-9b59-4434-a2a4-eb008a540eef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2039864776-172.17.0.10-1595580404953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39425,DS-00f8e95e-e6cc-4dbd-8519-f34ac82bf4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44045,DS-e208906a-df71-4cb2-b24a-137002f4c263,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-07e1b9b5-11ad-401e-8954-b961e83a8eef,DISK], DatanodeInfoWithStorage[127.0.0.1:38832,DS-79d0c1b1-db55-4d2b-84c4-65df6cc80b34,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-4390a7dc-d059-4b6e-ab94-889d956b4785,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-bb9d7aaf-6a94-42d5-93ea-e6052b627d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-6b46db2a-72e8-43d5-906f-44e5c52c98e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-5d430f17-33a4-46b2-adb4-e8000a7780a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2039864776-172.17.0.10-1595580404953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39425,DS-00f8e95e-e6cc-4dbd-8519-f34ac82bf4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44045,DS-e208906a-df71-4cb2-b24a-137002f4c263,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-07e1b9b5-11ad-401e-8954-b961e83a8eef,DISK], DatanodeInfoWithStorage[127.0.0.1:38832,DS-79d0c1b1-db55-4d2b-84c4-65df6cc80b34,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-4390a7dc-d059-4b6e-ab94-889d956b4785,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-bb9d7aaf-6a94-42d5-93ea-e6052b627d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-6b46db2a-72e8-43d5-906f-44e5c52c98e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-5d430f17-33a4-46b2-adb4-e8000a7780a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1917510457-172.17.0.10-1595580807366:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46231,DS-90cdfef6-99bf-454c-96a0-a52fbbe2157b,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-01200520-3bea-49f3-8a88-e2dec385235d,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-c9403857-7dd6-4ab1-8a99-305095ad6272,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-09e6310d-b39f-4258-95f6-5c604243517e,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-f3490025-334d-4ccc-8b52-52bced0dff1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-819fed23-8f66-4ef5-80ab-d4f1488b6ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-e683525d-f880-40aa-bd2f-b9da76f38925,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-b1c48b53-232f-49f0-85f9-0e2f28a71a59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1917510457-172.17.0.10-1595580807366:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46231,DS-90cdfef6-99bf-454c-96a0-a52fbbe2157b,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-01200520-3bea-49f3-8a88-e2dec385235d,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-c9403857-7dd6-4ab1-8a99-305095ad6272,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-09e6310d-b39f-4258-95f6-5c604243517e,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-f3490025-334d-4ccc-8b52-52bced0dff1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-819fed23-8f66-4ef5-80ab-d4f1488b6ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-e683525d-f880-40aa-bd2f-b9da76f38925,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-b1c48b53-232f-49f0-85f9-0e2f28a71a59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2126697375-172.17.0.10-1595580937547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38295,DS-409c7009-8908-4ff7-a8eb-74456af9525d,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-a22fdd00-957d-4da9-95c6-275641755bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-ae3e99cf-1676-44a8-9712-2fa3157b29d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33531,DS-2960f2a1-00f4-4e5d-9224-e5e649d38012,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-ed8a4c0e-16b8-417f-8ae2-c4f4265dffd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36951,DS-484b1bae-d66f-45cb-b98a-3936e8d09537,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-cb281993-dc7e-4e68-8c93-1650f8497f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-910bf063-8786-45e1-aeed-ca3e97ce4034,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2126697375-172.17.0.10-1595580937547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38295,DS-409c7009-8908-4ff7-a8eb-74456af9525d,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-a22fdd00-957d-4da9-95c6-275641755bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-ae3e99cf-1676-44a8-9712-2fa3157b29d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33531,DS-2960f2a1-00f4-4e5d-9224-e5e649d38012,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-ed8a4c0e-16b8-417f-8ae2-c4f4265dffd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36951,DS-484b1bae-d66f-45cb-b98a-3936e8d09537,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-cb281993-dc7e-4e68-8c93-1650f8497f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-910bf063-8786-45e1-aeed-ca3e97ce4034,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1973338329-172.17.0.10-1595580971925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38160,DS-d30d1f70-4057-4cb5-960d-e855ae650c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-794e5724-7a9d-4723-8006-16b90e8b89d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44364,DS-9450d3f7-330c-4588-9a51-576d36f06dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-465dc0a3-dffc-48d0-835b-d20549ec163a,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-1ebeaf08-c597-4a41-878b-9fa2dedea91d,DISK], DatanodeInfoWithStorage[127.0.0.1:42163,DS-a1a6459c-23ea-47bc-be95-a776375451bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-b07815b3-620d-4d4c-9750-33df73cd40f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-22fac892-5686-4d28-ac9a-438c2a9db177,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1973338329-172.17.0.10-1595580971925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38160,DS-d30d1f70-4057-4cb5-960d-e855ae650c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-794e5724-7a9d-4723-8006-16b90e8b89d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44364,DS-9450d3f7-330c-4588-9a51-576d36f06dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-465dc0a3-dffc-48d0-835b-d20549ec163a,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-1ebeaf08-c597-4a41-878b-9fa2dedea91d,DISK], DatanodeInfoWithStorage[127.0.0.1:42163,DS-a1a6459c-23ea-47bc-be95-a776375451bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-b07815b3-620d-4d4c-9750-33df73cd40f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-22fac892-5686-4d28-ac9a-438c2a9db177,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1725070065-172.17.0.10-1595581004797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38697,DS-5a9a619f-88b7-4b20-9d3b-571e4b09e94b,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-67b12da7-ca12-4713-8f68-4a9925965e15,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-f9889010-3bc4-405e-871b-f56e8554cf6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37612,DS-46b35f58-d842-4057-bc91-4b6fd981d1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-dd7dea79-4071-407d-8f75-2b6d0f6810d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-31fc0618-ccd8-4f54-9278-adc4ee9d9db7,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-cea45885-1b20-45cf-95bf-b641e30addee,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-8c5f90a7-1bd4-4284-a97e-b7d4e3757d29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1725070065-172.17.0.10-1595581004797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38697,DS-5a9a619f-88b7-4b20-9d3b-571e4b09e94b,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-67b12da7-ca12-4713-8f68-4a9925965e15,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-f9889010-3bc4-405e-871b-f56e8554cf6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37612,DS-46b35f58-d842-4057-bc91-4b6fd981d1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-dd7dea79-4071-407d-8f75-2b6d0f6810d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-31fc0618-ccd8-4f54-9278-adc4ee9d9db7,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-cea45885-1b20-45cf-95bf-b641e30addee,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-8c5f90a7-1bd4-4284-a97e-b7d4e3757d29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1608600939-172.17.0.10-1595581939218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44235,DS-e290ba74-b7bf-41f4-af23-e701745d9382,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-1ce2735c-9bc8-41d0-bd7e-fecd6df205b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-a93cefff-6f57-4a7c-a7a8-c92cd83d4fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-e4cf0810-14f5-4db4-92b4-13069a09fd35,DISK], DatanodeInfoWithStorage[127.0.0.1:38806,DS-b269b164-5ddd-4218-9cda-0867819a1f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-7b570aec-91f5-436b-b497-5e77df976be2,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-f164bea2-f173-47cf-a52a-45d01d73c027,DISK], DatanodeInfoWithStorage[127.0.0.1:34210,DS-6029e014-f438-474d-9f3b-7250c149c48c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1608600939-172.17.0.10-1595581939218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44235,DS-e290ba74-b7bf-41f4-af23-e701745d9382,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-1ce2735c-9bc8-41d0-bd7e-fecd6df205b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-a93cefff-6f57-4a7c-a7a8-c92cd83d4fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-e4cf0810-14f5-4db4-92b4-13069a09fd35,DISK], DatanodeInfoWithStorage[127.0.0.1:38806,DS-b269b164-5ddd-4218-9cda-0867819a1f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-7b570aec-91f5-436b-b497-5e77df976be2,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-f164bea2-f173-47cf-a52a-45d01d73c027,DISK], DatanodeInfoWithStorage[127.0.0.1:34210,DS-6029e014-f438-474d-9f3b-7250c149c48c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1944894615-172.17.0.10-1595582078770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40053,DS-546bf409-17b1-4f30-99a9-eca5cc31fa3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-07e7758c-0c0f-488c-a65f-7cb767cc99aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-03211628-3228-43be-9af2-083ca19f5c35,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-5ea920cc-3fa6-475b-8b38-88e1b00a02fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-75eea6a6-d76d-45b7-a87d-fc701cf7fa68,DISK], DatanodeInfoWithStorage[127.0.0.1:37952,DS-24c58b69-f386-41b2-9796-b4a8ff914b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-769f8cc5-fff3-4b09-a3e4-be7c62f8462a,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-9a402118-b1f3-4ab5-be10-de25a85a3849,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1944894615-172.17.0.10-1595582078770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40053,DS-546bf409-17b1-4f30-99a9-eca5cc31fa3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-07e7758c-0c0f-488c-a65f-7cb767cc99aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-03211628-3228-43be-9af2-083ca19f5c35,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-5ea920cc-3fa6-475b-8b38-88e1b00a02fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-75eea6a6-d76d-45b7-a87d-fc701cf7fa68,DISK], DatanodeInfoWithStorage[127.0.0.1:37952,DS-24c58b69-f386-41b2-9796-b4a8ff914b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-769f8cc5-fff3-4b09-a3e4-be7c62f8462a,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-9a402118-b1f3-4ab5-be10-de25a85a3849,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1000286581-172.17.0.10-1595582627512:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34282,DS-743e5a41-21d6-4333-ae04-6cf85275654c,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-440da265-491e-4cb7-b9a1-9ae1687fb848,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-bcbcaeaf-3bdd-4b55-badd-b9003dbc604f,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-64ebc749-f302-42eb-b837-16c9058f36e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-9ad6c812-3acf-4de3-b60f-83a02aa205c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-2f1a0a5b-71fc-4894-80bc-9b3e2c8d1e97,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-e5e160aa-7fc0-4250-8dbe-1091ccb131f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-a506a45f-f456-4658-8b75-c166ca999853,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1000286581-172.17.0.10-1595582627512:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34282,DS-743e5a41-21d6-4333-ae04-6cf85275654c,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-440da265-491e-4cb7-b9a1-9ae1687fb848,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-bcbcaeaf-3bdd-4b55-badd-b9003dbc604f,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-64ebc749-f302-42eb-b837-16c9058f36e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-9ad6c812-3acf-4de3-b60f-83a02aa205c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-2f1a0a5b-71fc-4894-80bc-9b3e2c8d1e97,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-e5e160aa-7fc0-4250-8dbe-1091ccb131f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-a506a45f-f456-4658-8b75-c166ca999853,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1399838772-172.17.0.10-1595583303495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37374,DS-e269385b-0393-49ea-8e6d-b881b2cbb602,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-1d4f16fc-1db8-43ae-a179-b9c539bd1796,DISK], DatanodeInfoWithStorage[127.0.0.1:36303,DS-6ca8e127-b811-444f-8093-d53fcb3bf950,DISK], DatanodeInfoWithStorage[127.0.0.1:45290,DS-33dc00c4-179d-414c-aad1-05e100818f25,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-04c027f3-c4cb-455c-9291-26e57fb464fe,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-72360dc6-ab34-4cbb-b3f9-ac85f7f2ace6,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-6e0aba6e-c982-42f7-acc1-e2f7e72610b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-b14b5a56-75fb-4540-b7d4-e72eb5428994,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1399838772-172.17.0.10-1595583303495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37374,DS-e269385b-0393-49ea-8e6d-b881b2cbb602,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-1d4f16fc-1db8-43ae-a179-b9c539bd1796,DISK], DatanodeInfoWithStorage[127.0.0.1:36303,DS-6ca8e127-b811-444f-8093-d53fcb3bf950,DISK], DatanodeInfoWithStorage[127.0.0.1:45290,DS-33dc00c4-179d-414c-aad1-05e100818f25,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-04c027f3-c4cb-455c-9291-26e57fb464fe,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-72360dc6-ab34-4cbb-b3f9-ac85f7f2ace6,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-6e0aba6e-c982-42f7-acc1-e2f7e72610b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-b14b5a56-75fb-4540-b7d4-e72eb5428994,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-945757069-172.17.0.10-1595583424880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45638,DS-104ba0b8-700e-4153-8dfc-5dad79214681,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-ad33fd65-5ab0-4047-b8d8-20b8de5fee6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-1a338579-0517-4e3d-8207-b80331fb1cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34928,DS-62c10313-0d6d-4fb2-b2be-b57dd9d18215,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-966e2a01-4887-4907-b88a-5c4f697532a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-932a8028-14a5-4080-a336-1fdcc886be76,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-d05f0134-c1d3-4e25-ae06-84ca5457eeb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-4db8543f-8cc1-4c02-a3f2-1e74be844af1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-945757069-172.17.0.10-1595583424880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45638,DS-104ba0b8-700e-4153-8dfc-5dad79214681,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-ad33fd65-5ab0-4047-b8d8-20b8de5fee6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-1a338579-0517-4e3d-8207-b80331fb1cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34928,DS-62c10313-0d6d-4fb2-b2be-b57dd9d18215,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-966e2a01-4887-4907-b88a-5c4f697532a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-932a8028-14a5-4080-a336-1fdcc886be76,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-d05f0134-c1d3-4e25-ae06-84ca5457eeb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-4db8543f-8cc1-4c02-a3f2-1e74be844af1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-640773614-172.17.0.10-1595583792217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46027,DS-dcc4b6cc-ac5c-465d-a61e-fc9ca7cdc639,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-32fd2f76-e8b1-413c-b9fd-2b124311fff8,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-ecece3b0-987a-447e-88d0-861544151a37,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-15e39361-3cab-4e93-97bb-faab3ac63ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:37673,DS-fc6c4319-6026-4a47-bf4f-eebb3df1108e,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-d97899ee-a0a4-422b-aa28-12fc5ebc0716,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-61d7b69c-8d5b-46a0-9596-a67f514a5676,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-141645f5-a7da-4fa7-b74f-b55557503542,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-640773614-172.17.0.10-1595583792217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46027,DS-dcc4b6cc-ac5c-465d-a61e-fc9ca7cdc639,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-32fd2f76-e8b1-413c-b9fd-2b124311fff8,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-ecece3b0-987a-447e-88d0-861544151a37,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-15e39361-3cab-4e93-97bb-faab3ac63ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:37673,DS-fc6c4319-6026-4a47-bf4f-eebb3df1108e,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-d97899ee-a0a4-422b-aa28-12fc5ebc0716,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-61d7b69c-8d5b-46a0-9596-a67f514a5676,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-141645f5-a7da-4fa7-b74f-b55557503542,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-841892844-172.17.0.10-1595583885420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41788,DS-6d472a61-73de-49fb-b595-a4d0bfb08221,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-c80818eb-5145-4ff7-b781-c796065ad730,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-24f64c3b-7899-4ebd-a327-b16565f97daa,DISK], DatanodeInfoWithStorage[127.0.0.1:44721,DS-fadec851-7682-406d-99ab-eed00ba55976,DISK], DatanodeInfoWithStorage[127.0.0.1:46012,DS-a4f2b51e-db8c-4054-9a18-d1dd60d3c6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-ee4806ae-e29f-4e67-9eb5-c1c10ebc09e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-d3dd0876-2964-4333-abf0-0cf6beb393d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39432,DS-6ac0d425-c038-4bd7-aae6-5249b15b615e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-841892844-172.17.0.10-1595583885420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41788,DS-6d472a61-73de-49fb-b595-a4d0bfb08221,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-c80818eb-5145-4ff7-b781-c796065ad730,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-24f64c3b-7899-4ebd-a327-b16565f97daa,DISK], DatanodeInfoWithStorage[127.0.0.1:44721,DS-fadec851-7682-406d-99ab-eed00ba55976,DISK], DatanodeInfoWithStorage[127.0.0.1:46012,DS-a4f2b51e-db8c-4054-9a18-d1dd60d3c6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-ee4806ae-e29f-4e67-9eb5-c1c10ebc09e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-d3dd0876-2964-4333-abf0-0cf6beb393d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39432,DS-6ac0d425-c038-4bd7-aae6-5249b15b615e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: might be true error
Total execution time in seconds : 4906
