reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-502738972-172.17.0.21-1595844978999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35484,DS-3ba0ff21-3914-4f6e-84aa-ea1e9fbc9ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-c4212038-713f-4f9b-aa52-e5823b3f7c91,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-955725b1-77b9-4b1f-b4d0-cf702ef0e193,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-cec3f4e4-f13f-45ec-96aa-dda3556198ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39072,DS-105ad01e-6f91-4f46-b221-cb11fdc27908,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-2ea9fd59-5648-4345-b344-29f959b90cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-8e7e90f7-24b1-45ae-bc84-27e4bff4d100,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-c4710b69-fe88-4932-9f57-129fee4ad84b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-502738972-172.17.0.21-1595844978999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35484,DS-3ba0ff21-3914-4f6e-84aa-ea1e9fbc9ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-c4212038-713f-4f9b-aa52-e5823b3f7c91,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-955725b1-77b9-4b1f-b4d0-cf702ef0e193,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-cec3f4e4-f13f-45ec-96aa-dda3556198ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39072,DS-105ad01e-6f91-4f46-b221-cb11fdc27908,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-2ea9fd59-5648-4345-b344-29f959b90cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-8e7e90f7-24b1-45ae-bc84-27e4bff4d100,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-c4710b69-fe88-4932-9f57-129fee4ad84b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-693829927-172.17.0.21-1595845301942:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42034,DS-cf97894e-a2d4-41e1-86a6-7cbc4e0d3b84,DISK], DatanodeInfoWithStorage[127.0.0.1:40031,DS-463a2de6-c678-4c75-af60-307489f6b417,DISK], DatanodeInfoWithStorage[127.0.0.1:33526,DS-1f4de8a9-d3d3-4475-b44d-a9c84d7dab66,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-3e0ddf7a-06ad-472b-a07b-d16a1e4eb621,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-b24e7cee-ba06-479a-b5b9-d54947c9a7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-613f00ff-5116-4b89-afda-a972afd83019,DISK], DatanodeInfoWithStorage[127.0.0.1:45704,DS-32f03fc7-a9df-45aa-9d18-eabaef648660,DISK], DatanodeInfoWithStorage[127.0.0.1:45080,DS-e29fdb1a-c04a-4690-81cc-af022fa80ca9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-693829927-172.17.0.21-1595845301942:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42034,DS-cf97894e-a2d4-41e1-86a6-7cbc4e0d3b84,DISK], DatanodeInfoWithStorage[127.0.0.1:40031,DS-463a2de6-c678-4c75-af60-307489f6b417,DISK], DatanodeInfoWithStorage[127.0.0.1:33526,DS-1f4de8a9-d3d3-4475-b44d-a9c84d7dab66,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-3e0ddf7a-06ad-472b-a07b-d16a1e4eb621,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-b24e7cee-ba06-479a-b5b9-d54947c9a7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-613f00ff-5116-4b89-afda-a972afd83019,DISK], DatanodeInfoWithStorage[127.0.0.1:45704,DS-32f03fc7-a9df-45aa-9d18-eabaef648660,DISK], DatanodeInfoWithStorage[127.0.0.1:45080,DS-e29fdb1a-c04a-4690-81cc-af022fa80ca9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1161516650-172.17.0.21-1595845455308:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46662,DS-5ea892ed-b735-49c2-9833-935a61122046,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-c2f4e224-8f4d-4f94-b14e-20d9c1529539,DISK], DatanodeInfoWithStorage[127.0.0.1:44673,DS-3b873636-14df-46ea-95a2-12d70ca41565,DISK], DatanodeInfoWithStorage[127.0.0.1:38806,DS-41b5bcd2-635e-4864-8f51-e195e3d4bfc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-424f9581-7e20-493c-a31b-1dc1d6f088c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38367,DS-166ef9e7-6a58-4b33-8155-d4f6f6c5d9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-f85b94ed-b760-4874-b8de-b68daadf3a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-b893393e-efeb-4b4b-aae0-91b7f0d7bf8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1161516650-172.17.0.21-1595845455308:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46662,DS-5ea892ed-b735-49c2-9833-935a61122046,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-c2f4e224-8f4d-4f94-b14e-20d9c1529539,DISK], DatanodeInfoWithStorage[127.0.0.1:44673,DS-3b873636-14df-46ea-95a2-12d70ca41565,DISK], DatanodeInfoWithStorage[127.0.0.1:38806,DS-41b5bcd2-635e-4864-8f51-e195e3d4bfc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-424f9581-7e20-493c-a31b-1dc1d6f088c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38367,DS-166ef9e7-6a58-4b33-8155-d4f6f6c5d9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-f85b94ed-b760-4874-b8de-b68daadf3a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-b893393e-efeb-4b4b-aae0-91b7f0d7bf8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1203147027-172.17.0.21-1595845948111:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33494,DS-6b642e08-6843-4108-8d8b-d87c3f6d041a,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-9a256675-e680-4242-b49d-399f4e873b21,DISK], DatanodeInfoWithStorage[127.0.0.1:41473,DS-244f4fb4-b648-4ebb-9602-e4c1e47fab81,DISK], DatanodeInfoWithStorage[127.0.0.1:39423,DS-74ca7fdb-bbe8-4d66-9e8a-9dc1d742cd73,DISK], DatanodeInfoWithStorage[127.0.0.1:37294,DS-0adb8e18-1469-492c-a1ef-f9e1f59d1ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-e90bbf54-1ade-440c-a868-4222da6ef3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-50f57ccd-6085-4af5-adb0-e4f1e00bc1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-6710ab43-a50d-46e5-a16c-9542884346ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1203147027-172.17.0.21-1595845948111:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33494,DS-6b642e08-6843-4108-8d8b-d87c3f6d041a,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-9a256675-e680-4242-b49d-399f4e873b21,DISK], DatanodeInfoWithStorage[127.0.0.1:41473,DS-244f4fb4-b648-4ebb-9602-e4c1e47fab81,DISK], DatanodeInfoWithStorage[127.0.0.1:39423,DS-74ca7fdb-bbe8-4d66-9e8a-9dc1d742cd73,DISK], DatanodeInfoWithStorage[127.0.0.1:37294,DS-0adb8e18-1469-492c-a1ef-f9e1f59d1ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-e90bbf54-1ade-440c-a868-4222da6ef3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-50f57ccd-6085-4af5-adb0-e4f1e00bc1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-6710ab43-a50d-46e5-a16c-9542884346ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-460682933-172.17.0.21-1595846121771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41691,DS-727a4481-b7d1-450a-b357-af201cef0144,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-14c39797-5a18-4672-9e22-234203e8e2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-414a6d55-000a-4f14-90ff-30608588d378,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-6b8bb8b4-2a2c-453a-ac4f-409a83a60fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-adc1f279-0db5-47db-bfaf-3b77dfe69f20,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-64695346-258b-4ec7-acef-9f393b9dc57b,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-1a41cf76-10c1-419d-a0a6-3c5d2c23b4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37869,DS-66f744eb-3be3-48e5-9364-d6bf1565e033,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-460682933-172.17.0.21-1595846121771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41691,DS-727a4481-b7d1-450a-b357-af201cef0144,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-14c39797-5a18-4672-9e22-234203e8e2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-414a6d55-000a-4f14-90ff-30608588d378,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-6b8bb8b4-2a2c-453a-ac4f-409a83a60fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-adc1f279-0db5-47db-bfaf-3b77dfe69f20,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-64695346-258b-4ec7-acef-9f393b9dc57b,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-1a41cf76-10c1-419d-a0a6-3c5d2c23b4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37869,DS-66f744eb-3be3-48e5-9364-d6bf1565e033,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1146989948-172.17.0.21-1595847300133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46400,DS-eedb3133-46dd-4206-9eb8-2d7d259fa190,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-d8664d17-3953-4693-b79d-0235532e5348,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-49d9daff-b343-4ae6-b1e9-591f6eb8d475,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-26d66f94-bf3f-4095-b74d-cb5cff4d2bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-b9443026-b56a-41bf-9957-b817026ccadd,DISK], DatanodeInfoWithStorage[127.0.0.1:33243,DS-b23a29e0-35ac-41db-bd24-74f148e5d021,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-27482fd4-5511-4007-8327-85dfd6757312,DISK], DatanodeInfoWithStorage[127.0.0.1:34126,DS-1644e323-1d87-490f-9a8d-b3ea13542d90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1146989948-172.17.0.21-1595847300133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46400,DS-eedb3133-46dd-4206-9eb8-2d7d259fa190,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-d8664d17-3953-4693-b79d-0235532e5348,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-49d9daff-b343-4ae6-b1e9-591f6eb8d475,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-26d66f94-bf3f-4095-b74d-cb5cff4d2bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-b9443026-b56a-41bf-9957-b817026ccadd,DISK], DatanodeInfoWithStorage[127.0.0.1:33243,DS-b23a29e0-35ac-41db-bd24-74f148e5d021,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-27482fd4-5511-4007-8327-85dfd6757312,DISK], DatanodeInfoWithStorage[127.0.0.1:34126,DS-1644e323-1d87-490f-9a8d-b3ea13542d90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1610204237-172.17.0.21-1595847639560:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35273,DS-db0fb192-d166-4cd3-bb20-fa17a5172ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-ddb31963-551d-4eef-8e1f-67a3d2869c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-e99906a5-6dd8-4f9e-b795-dc34b699f3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-3719a728-5b2e-4ab1-82d0-415e8530196a,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-7db7aaa3-8f48-44c8-8115-494226e74643,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-56d05a19-985c-4e1b-a151-048c2df511e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35156,DS-418e462a-b96e-4307-8762-302e434d1488,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-bace3dc3-ab2c-419a-b609-05662a04396c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1610204237-172.17.0.21-1595847639560:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35273,DS-db0fb192-d166-4cd3-bb20-fa17a5172ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-ddb31963-551d-4eef-8e1f-67a3d2869c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-e99906a5-6dd8-4f9e-b795-dc34b699f3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-3719a728-5b2e-4ab1-82d0-415e8530196a,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-7db7aaa3-8f48-44c8-8115-494226e74643,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-56d05a19-985c-4e1b-a151-048c2df511e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35156,DS-418e462a-b96e-4307-8762-302e434d1488,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-bace3dc3-ab2c-419a-b609-05662a04396c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1022465859-172.17.0.21-1595847672675:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44479,DS-1977ccf3-ab5c-4784-aa2b-7b903679932f,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-65e9574e-0877-488a-8394-7245e18dc074,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-f28d8eef-54fa-4686-a3d2-34b0e34fe41a,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-e01802ac-9246-49f9-aaf8-0aa3a3777651,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-83d77c4d-b885-446f-a5e2-f61d7676deed,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-18e36f41-f829-4a94-94d4-cc37f885f306,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-9b176062-62ca-444c-820e-baa876d5cf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-cea6ad3f-8072-437b-a637-b11a80ab3d3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1022465859-172.17.0.21-1595847672675:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44479,DS-1977ccf3-ab5c-4784-aa2b-7b903679932f,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-65e9574e-0877-488a-8394-7245e18dc074,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-f28d8eef-54fa-4686-a3d2-34b0e34fe41a,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-e01802ac-9246-49f9-aaf8-0aa3a3777651,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-83d77c4d-b885-446f-a5e2-f61d7676deed,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-18e36f41-f829-4a94-94d4-cc37f885f306,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-9b176062-62ca-444c-820e-baa876d5cf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-cea6ad3f-8072-437b-a637-b11a80ab3d3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1774509446-172.17.0.21-1595848127896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34866,DS-2b1d9fbe-bea9-475a-9c88-dfc4b089cd5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-221a66b4-f7b8-4051-83ed-9e5428befd93,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-23f30417-e9d5-4316-9689-7dd3aeae183b,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-635b698b-a240-4840-8c73-d034ca8d4107,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-0153dc78-ae8e-408a-a785-c4326c3004c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33751,DS-8c7ac2e9-9680-4eee-907c-561932dcb082,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-979635b0-da3e-412f-b7af-4b64a22889c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-f105c44e-6350-40d2-bdec-285f89871d45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1774509446-172.17.0.21-1595848127896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34866,DS-2b1d9fbe-bea9-475a-9c88-dfc4b089cd5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-221a66b4-f7b8-4051-83ed-9e5428befd93,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-23f30417-e9d5-4316-9689-7dd3aeae183b,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-635b698b-a240-4840-8c73-d034ca8d4107,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-0153dc78-ae8e-408a-a785-c4326c3004c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33751,DS-8c7ac2e9-9680-4eee-907c-561932dcb082,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-979635b0-da3e-412f-b7af-4b64a22889c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-f105c44e-6350-40d2-bdec-285f89871d45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-294402688-172.17.0.21-1595848440282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35685,DS-9dc8ed7c-aa65-42f8-a58d-237a227749d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-1a4ee7ef-6995-4b82-afab-11f50319a0be,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-090e461e-3982-4851-9360-69a478ae315b,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-3c3ced0c-f05a-47c5-9549-be389ef9eb01,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-6cd6a6c2-b56d-4104-8586-c91598b61b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-b15916af-81be-4573-a50d-965e3d56ee6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45532,DS-e6c51e7f-d42b-4784-b398-96a1da911f10,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-f7bd98dd-c533-40e7-9bba-0ef7ceec9f66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-294402688-172.17.0.21-1595848440282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35685,DS-9dc8ed7c-aa65-42f8-a58d-237a227749d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-1a4ee7ef-6995-4b82-afab-11f50319a0be,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-090e461e-3982-4851-9360-69a478ae315b,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-3c3ced0c-f05a-47c5-9549-be389ef9eb01,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-6cd6a6c2-b56d-4104-8586-c91598b61b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-b15916af-81be-4573-a50d-965e3d56ee6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45532,DS-e6c51e7f-d42b-4784-b398-96a1da911f10,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-f7bd98dd-c533-40e7-9bba-0ef7ceec9f66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-323609774-172.17.0.21-1595849240443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33001,DS-ab4d95ad-2ba5-4434-9865-6d02305c48e8,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-9f14846f-d474-4f55-ab78-b70c15c63794,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-172171d4-be53-4394-a65f-0a23542ff7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-90d5cf32-736e-4842-b007-8abfa5f9ec2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-22363f07-7194-49b1-b88b-c861cd5495de,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-f8aa9749-be24-482e-b3ee-b0ea97bb0b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-118f91c5-e390-4fb7-a1c7-5120a1ffd350,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-547bc661-085b-4259-a3f0-8644aafb8409,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-323609774-172.17.0.21-1595849240443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33001,DS-ab4d95ad-2ba5-4434-9865-6d02305c48e8,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-9f14846f-d474-4f55-ab78-b70c15c63794,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-172171d4-be53-4394-a65f-0a23542ff7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-90d5cf32-736e-4842-b007-8abfa5f9ec2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-22363f07-7194-49b1-b88b-c861cd5495de,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-f8aa9749-be24-482e-b3ee-b0ea97bb0b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-118f91c5-e390-4fb7-a1c7-5120a1ffd350,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-547bc661-085b-4259-a3f0-8644aafb8409,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-982227373-172.17.0.21-1595849605714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39796,DS-a40a401a-3d2e-4b82-865c-298e9114add7,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-1934ccda-d7ab-4937-8a04-f4ffb491e869,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-f282ad0a-a347-4a73-95b0-5104d8415964,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-5b2c8c03-2d78-4ff6-a45d-0feac5691c71,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-c45191a8-400c-4f56-ae8c-dd00e5ea7143,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-08c07276-6f58-431f-892c-fdc5220a9495,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-3aecd7c4-7dce-4049-ba55-97db8ebb35ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-f3c00dfb-28b6-4662-ac88-829589f0c601,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-982227373-172.17.0.21-1595849605714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39796,DS-a40a401a-3d2e-4b82-865c-298e9114add7,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-1934ccda-d7ab-4937-8a04-f4ffb491e869,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-f282ad0a-a347-4a73-95b0-5104d8415964,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-5b2c8c03-2d78-4ff6-a45d-0feac5691c71,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-c45191a8-400c-4f56-ae8c-dd00e5ea7143,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-08c07276-6f58-431f-892c-fdc5220a9495,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-3aecd7c4-7dce-4049-ba55-97db8ebb35ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-f3c00dfb-28b6-4662-ac88-829589f0c601,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5404
