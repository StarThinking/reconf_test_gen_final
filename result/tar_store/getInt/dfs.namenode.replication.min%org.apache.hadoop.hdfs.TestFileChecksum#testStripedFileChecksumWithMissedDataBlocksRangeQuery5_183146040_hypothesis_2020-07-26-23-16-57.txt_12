reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-918654727-172.17.0.17-1595805676868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43499,DS-73f80106-5e00-4d88-bd9e-a5565594f9be,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-c546d433-0c06-456e-8a7b-ab03961e050c,DISK], DatanodeInfoWithStorage[127.0.0.1:41975,DS-bbb13ecc-b8ea-4708-92d1-2705756c478e,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-9db6375d-fd90-4bcb-8b84-d7620da73520,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-f19310ad-8004-4588-8f35-ea250493e78a,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-d2279de9-ad12-4033-b8fc-097238ce8611,DISK], DatanodeInfoWithStorage[127.0.0.1:45217,DS-f2f536de-dc27-4614-b2b8-faf5bd4096e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-7e9dc0e1-33cc-4f35-9744-7112cbf43f53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-918654727-172.17.0.17-1595805676868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43499,DS-73f80106-5e00-4d88-bd9e-a5565594f9be,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-c546d433-0c06-456e-8a7b-ab03961e050c,DISK], DatanodeInfoWithStorage[127.0.0.1:41975,DS-bbb13ecc-b8ea-4708-92d1-2705756c478e,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-9db6375d-fd90-4bcb-8b84-d7620da73520,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-f19310ad-8004-4588-8f35-ea250493e78a,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-d2279de9-ad12-4033-b8fc-097238ce8611,DISK], DatanodeInfoWithStorage[127.0.0.1:45217,DS-f2f536de-dc27-4614-b2b8-faf5bd4096e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-7e9dc0e1-33cc-4f35-9744-7112cbf43f53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1156740475-172.17.0.17-1595805887134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41885,DS-99a170e8-b247-43af-af21-c429c40b84ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34538,DS-9db33841-aade-4f7a-a39a-72dd9bd54163,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-fcc6a28a-5bca-4b20-bc38-8f907294df97,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-75b46754-2d9e-40bb-b877-443c545b72eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-1aabc01f-1bbd-4df3-b638-f7f8847ac18a,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-548f3b9d-01aa-4c29-b62e-05501c0f4a15,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-1d36739a-d859-43a5-be78-afce89e4389b,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-db8ceb0d-c5e1-4471-9a63-5787765379c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1156740475-172.17.0.17-1595805887134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41885,DS-99a170e8-b247-43af-af21-c429c40b84ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34538,DS-9db33841-aade-4f7a-a39a-72dd9bd54163,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-fcc6a28a-5bca-4b20-bc38-8f907294df97,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-75b46754-2d9e-40bb-b877-443c545b72eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-1aabc01f-1bbd-4df3-b638-f7f8847ac18a,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-548f3b9d-01aa-4c29-b62e-05501c0f4a15,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-1d36739a-d859-43a5-be78-afce89e4389b,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-db8ceb0d-c5e1-4471-9a63-5787765379c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1593082491-172.17.0.17-1595805951212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35837,DS-6c879b6d-1cdf-434b-8943-f7aea71cae88,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-15b7ad7d-30f2-4abb-945b-ce642ed0d884,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-b31374ec-1a10-41f5-ac65-9ea52fd6e67e,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-1bcc278d-b29b-4d51-aa5c-0a2fe2acdcb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34971,DS-cbc07dee-b447-4c3a-b5fb-69070c9bce35,DISK], DatanodeInfoWithStorage[127.0.0.1:37912,DS-4c346067-987a-440d-a589-421edc1d64d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-5d5421bd-3bc4-44d8-9355-ea8f5be233df,DISK], DatanodeInfoWithStorage[127.0.0.1:33196,DS-b5f2669d-7838-4cd7-a767-fec591adf9bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1593082491-172.17.0.17-1595805951212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35837,DS-6c879b6d-1cdf-434b-8943-f7aea71cae88,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-15b7ad7d-30f2-4abb-945b-ce642ed0d884,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-b31374ec-1a10-41f5-ac65-9ea52fd6e67e,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-1bcc278d-b29b-4d51-aa5c-0a2fe2acdcb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34971,DS-cbc07dee-b447-4c3a-b5fb-69070c9bce35,DISK], DatanodeInfoWithStorage[127.0.0.1:37912,DS-4c346067-987a-440d-a589-421edc1d64d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-5d5421bd-3bc4-44d8-9355-ea8f5be233df,DISK], DatanodeInfoWithStorage[127.0.0.1:33196,DS-b5f2669d-7838-4cd7-a767-fec591adf9bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1415887244-172.17.0.17-1595806181677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41429,DS-184a7cd9-8fdd-4ac0-ba1b-6f52faa4c2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-54f73938-d075-4df5-a681-ebd5437737be,DISK], DatanodeInfoWithStorage[127.0.0.1:33624,DS-da81c8bc-69d6-47c1-b735-2aa5a97228a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-1ffd51c9-0c63-44cc-bd7e-27242f55010d,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-d4f0e8e5-e16d-4bbb-bcd3-94e51c8674ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-00e3c37f-ffc0-4284-a09f-30de4e489d35,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-bc4f8143-314a-443d-bb46-53f3447246c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-8b27d131-e6a4-499d-b16d-21f50b0e3472,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1415887244-172.17.0.17-1595806181677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41429,DS-184a7cd9-8fdd-4ac0-ba1b-6f52faa4c2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-54f73938-d075-4df5-a681-ebd5437737be,DISK], DatanodeInfoWithStorage[127.0.0.1:33624,DS-da81c8bc-69d6-47c1-b735-2aa5a97228a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-1ffd51c9-0c63-44cc-bd7e-27242f55010d,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-d4f0e8e5-e16d-4bbb-bcd3-94e51c8674ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-00e3c37f-ffc0-4284-a09f-30de4e489d35,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-bc4f8143-314a-443d-bb46-53f3447246c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-8b27d131-e6a4-499d-b16d-21f50b0e3472,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-919774247-172.17.0.17-1595806640887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33157,DS-7f3ab23d-f886-463f-b6ee-ead5e908410a,DISK], DatanodeInfoWithStorage[127.0.0.1:42824,DS-b4f2b184-bc05-48d2-ace8-b99ffb98e895,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-200edf44-bd29-4afa-9107-306607ac2b73,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-bd370cc2-fb86-425a-abf0-ccc24ebeb12e,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-365dddb9-b3b9-4cea-914c-bbc7f1f971da,DISK], DatanodeInfoWithStorage[127.0.0.1:41053,DS-1cc449c7-ad8a-42de-b82c-27ba8445c026,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-42abaa88-91e8-4075-94b5-f13d045e8cec,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-37cca942-cdc9-45dc-a69c-7a458596e6a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-919774247-172.17.0.17-1595806640887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33157,DS-7f3ab23d-f886-463f-b6ee-ead5e908410a,DISK], DatanodeInfoWithStorage[127.0.0.1:42824,DS-b4f2b184-bc05-48d2-ace8-b99ffb98e895,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-200edf44-bd29-4afa-9107-306607ac2b73,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-bd370cc2-fb86-425a-abf0-ccc24ebeb12e,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-365dddb9-b3b9-4cea-914c-bbc7f1f971da,DISK], DatanodeInfoWithStorage[127.0.0.1:41053,DS-1cc449c7-ad8a-42de-b82c-27ba8445c026,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-42abaa88-91e8-4075-94b5-f13d045e8cec,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-37cca942-cdc9-45dc-a69c-7a458596e6a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-385003706-172.17.0.17-1595806996432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40992,DS-13830546-3ae4-42a8-abed-ccc50078cf6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-05914c0c-dcbf-42ab-899e-a8516a51991c,DISK], DatanodeInfoWithStorage[127.0.0.1:46233,DS-78b5f900-e387-4865-8ebc-6bccfe4c83bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34781,DS-3ff8fd58-8c50-4433-83ad-dbceb0786790,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-0904463c-548f-47cc-9ad0-1199d1d99219,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-0c37a267-beb6-4fc7-8197-b3eea5af85d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-8a71df3d-d8c9-4f3c-9302-fa4071c18999,DISK], DatanodeInfoWithStorage[127.0.0.1:43621,DS-0722a5be-cb91-4aa0-ab41-1ccd077c8154,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-385003706-172.17.0.17-1595806996432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40992,DS-13830546-3ae4-42a8-abed-ccc50078cf6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-05914c0c-dcbf-42ab-899e-a8516a51991c,DISK], DatanodeInfoWithStorage[127.0.0.1:46233,DS-78b5f900-e387-4865-8ebc-6bccfe4c83bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34781,DS-3ff8fd58-8c50-4433-83ad-dbceb0786790,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-0904463c-548f-47cc-9ad0-1199d1d99219,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-0c37a267-beb6-4fc7-8197-b3eea5af85d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-8a71df3d-d8c9-4f3c-9302-fa4071c18999,DISK], DatanodeInfoWithStorage[127.0.0.1:43621,DS-0722a5be-cb91-4aa0-ab41-1ccd077c8154,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2097940773-172.17.0.17-1595807198152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37642,DS-6a4954c6-d210-4c2b-af73-4c8609d555f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38061,DS-9693c76b-14bc-4776-bd1c-752e662bec2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-f887e5de-30e7-44f2-99fd-42e995553508,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-9ab6224b-9e74-4dfb-bfcf-d2bc17f5e439,DISK], DatanodeInfoWithStorage[127.0.0.1:34811,DS-51bd5707-07c5-43f7-a8c8-6a82d84acc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-b46bb52a-8ffd-4c07-afa7-b5c659f83710,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-f80b5270-8937-4ba4-b634-e21620dc5e23,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-035c0103-81d0-4787-9768-5dfabc9a9344,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2097940773-172.17.0.17-1595807198152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37642,DS-6a4954c6-d210-4c2b-af73-4c8609d555f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38061,DS-9693c76b-14bc-4776-bd1c-752e662bec2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-f887e5de-30e7-44f2-99fd-42e995553508,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-9ab6224b-9e74-4dfb-bfcf-d2bc17f5e439,DISK], DatanodeInfoWithStorage[127.0.0.1:34811,DS-51bd5707-07c5-43f7-a8c8-6a82d84acc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-b46bb52a-8ffd-4c07-afa7-b5c659f83710,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-f80b5270-8937-4ba4-b634-e21620dc5e23,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-035c0103-81d0-4787-9768-5dfabc9a9344,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-104620300-172.17.0.17-1595807235678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33105,DS-bd9eed34-1e51-4fa5-b7b9-1af564e25169,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-b20469b0-b2e6-440e-8bd3-137281d6c38b,DISK], DatanodeInfoWithStorage[127.0.0.1:45483,DS-47a64b84-5cb6-42a1-b2e7-f5ae90598b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38619,DS-3b0520fb-a668-41d5-adfd-ad3e813c39d3,DISK], DatanodeInfoWithStorage[127.0.0.1:32836,DS-73ed6ec3-2ab9-4878-b156-4ff0392baabc,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-993fb45e-1fa1-49e5-aebb-c9ae261263bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-f2f9471e-627c-4e2c-903c-395dc41bd063,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-977f8c89-431d-4a86-b09c-d71f34d50589,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-104620300-172.17.0.17-1595807235678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33105,DS-bd9eed34-1e51-4fa5-b7b9-1af564e25169,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-b20469b0-b2e6-440e-8bd3-137281d6c38b,DISK], DatanodeInfoWithStorage[127.0.0.1:45483,DS-47a64b84-5cb6-42a1-b2e7-f5ae90598b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38619,DS-3b0520fb-a668-41d5-adfd-ad3e813c39d3,DISK], DatanodeInfoWithStorage[127.0.0.1:32836,DS-73ed6ec3-2ab9-4878-b156-4ff0392baabc,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-993fb45e-1fa1-49e5-aebb-c9ae261263bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-f2f9471e-627c-4e2c-903c-395dc41bd063,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-977f8c89-431d-4a86-b09c-d71f34d50589,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-694748158-172.17.0.17-1595808017965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45218,DS-47d982f0-7f8e-4747-97bb-15f71ece75c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36674,DS-0b2afb20-86e4-492b-9a8f-9ff77e81c0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-056e3970-3c3f-4be6-8336-7cdc4464554b,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-e6fa5357-c06a-472b-915e-b718bd398aef,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-d407f752-0484-4a2c-af64-ce379f901c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-e2ddeaa7-14de-479c-b684-57a60fb41147,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-93868afa-3a69-4e82-90f0-22bafad01e72,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-f928f566-0688-42d4-8c5b-f2b98ce9ba42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-694748158-172.17.0.17-1595808017965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45218,DS-47d982f0-7f8e-4747-97bb-15f71ece75c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36674,DS-0b2afb20-86e4-492b-9a8f-9ff77e81c0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-056e3970-3c3f-4be6-8336-7cdc4464554b,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-e6fa5357-c06a-472b-915e-b718bd398aef,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-d407f752-0484-4a2c-af64-ce379f901c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-e2ddeaa7-14de-479c-b684-57a60fb41147,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-93868afa-3a69-4e82-90f0-22bafad01e72,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-f928f566-0688-42d4-8c5b-f2b98ce9ba42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1794482744-172.17.0.17-1595808149429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44169,DS-04182b59-716e-4e3a-b150-fe053602762b,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-7f95ca46-6c25-4bef-9a14-cd6f2cf51227,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-cbefa021-d5dd-4d9d-afb0-0551878a22e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-e306f795-d7a9-4e75-b742-a60d0bbfd6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-d623e76d-adb6-42d4-99c3-bb5845ef525b,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-5ca602f6-57c0-4b67-8867-ce678efc9b09,DISK], DatanodeInfoWithStorage[127.0.0.1:46807,DS-f9e17cf9-b90a-4332-9836-25404ec7ff69,DISK], DatanodeInfoWithStorage[127.0.0.1:38722,DS-ba311295-ebf7-4adc-aacb-4412d40abe82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1794482744-172.17.0.17-1595808149429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44169,DS-04182b59-716e-4e3a-b150-fe053602762b,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-7f95ca46-6c25-4bef-9a14-cd6f2cf51227,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-cbefa021-d5dd-4d9d-afb0-0551878a22e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-e306f795-d7a9-4e75-b742-a60d0bbfd6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-d623e76d-adb6-42d4-99c3-bb5845ef525b,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-5ca602f6-57c0-4b67-8867-ce678efc9b09,DISK], DatanodeInfoWithStorage[127.0.0.1:46807,DS-f9e17cf9-b90a-4332-9836-25404ec7ff69,DISK], DatanodeInfoWithStorage[127.0.0.1:38722,DS-ba311295-ebf7-4adc-aacb-4412d40abe82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553677052-172.17.0.17-1595808289932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33888,DS-074aaab0-4b0b-4738-bb0a-8e8c22fc4da1,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-966fd61e-2281-4c16-a1c8-792993f35d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-cb38f944-fb04-4fd1-b321-7f8c9fa1130c,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-b455a219-f444-4aa3-b610-dec44808f20b,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-a1ace6c0-4426-4c6e-8769-8050255728aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-bef06160-bf9a-4fda-8b79-2af2fad300d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-675882b8-ec8e-4e56-bb23-c42bf9266c78,DISK], DatanodeInfoWithStorage[127.0.0.1:46770,DS-ddcfb4b5-3e44-4fc7-bcf4-9184c5588d19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553677052-172.17.0.17-1595808289932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33888,DS-074aaab0-4b0b-4738-bb0a-8e8c22fc4da1,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-966fd61e-2281-4c16-a1c8-792993f35d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-cb38f944-fb04-4fd1-b321-7f8c9fa1130c,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-b455a219-f444-4aa3-b610-dec44808f20b,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-a1ace6c0-4426-4c6e-8769-8050255728aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-bef06160-bf9a-4fda-8b79-2af2fad300d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-675882b8-ec8e-4e56-bb23-c42bf9266c78,DISK], DatanodeInfoWithStorage[127.0.0.1:46770,DS-ddcfb4b5-3e44-4fc7-bcf4-9184c5588d19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-522374977-172.17.0.17-1595808331249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43708,DS-63fd2736-98c9-485d-b108-1f9a36bc8591,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-0d344599-ce10-4227-bfec-09598e785df8,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-8411e694-e67f-4f82-be49-9ca931538697,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-d503cb11-1707-4a7d-8c66-433478a5be34,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-d74fa242-63fa-41a0-b4ee-c2b35eafff49,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-47ab0f5a-f188-40bf-a899-6f1aa13195de,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-893c3645-d64d-40b7-9ab2-50c38cd25bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-744c5ac9-2949-46b0-91c8-80831e05c0b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-522374977-172.17.0.17-1595808331249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43708,DS-63fd2736-98c9-485d-b108-1f9a36bc8591,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-0d344599-ce10-4227-bfec-09598e785df8,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-8411e694-e67f-4f82-be49-9ca931538697,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-d503cb11-1707-4a7d-8c66-433478a5be34,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-d74fa242-63fa-41a0-b4ee-c2b35eafff49,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-47ab0f5a-f188-40bf-a899-6f1aa13195de,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-893c3645-d64d-40b7-9ab2-50c38cd25bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-744c5ac9-2949-46b0-91c8-80831e05c0b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184574059-172.17.0.17-1595808775636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43009,DS-a64a4507-dcf2-4f15-96ec-7c77ba18c04b,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-1030f92c-9c4f-46a9-87a9-8734ef5c8cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-a9b64472-3db9-422e-9393-2b60485fc489,DISK], DatanodeInfoWithStorage[127.0.0.1:40318,DS-2483af76-2160-4835-9975-27244dcbba70,DISK], DatanodeInfoWithStorage[127.0.0.1:38726,DS-f57f9a01-54d8-4f29-b484-7a4155f2036b,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-32c32825-e380-4b8c-a720-621dd18f7e57,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-53b2ede0-e66d-4c99-a15d-d71be1479e22,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-e154328a-b357-48ce-a34d-d84518058f54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184574059-172.17.0.17-1595808775636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43009,DS-a64a4507-dcf2-4f15-96ec-7c77ba18c04b,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-1030f92c-9c4f-46a9-87a9-8734ef5c8cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-a9b64472-3db9-422e-9393-2b60485fc489,DISK], DatanodeInfoWithStorage[127.0.0.1:40318,DS-2483af76-2160-4835-9975-27244dcbba70,DISK], DatanodeInfoWithStorage[127.0.0.1:38726,DS-f57f9a01-54d8-4f29-b484-7a4155f2036b,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-32c32825-e380-4b8c-a720-621dd18f7e57,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-53b2ede0-e66d-4c99-a15d-d71be1479e22,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-e154328a-b357-48ce-a34d-d84518058f54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1289436458-172.17.0.17-1595809220636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43258,DS-82081deb-7140-4ce4-b3e7-65e0b452e5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38843,DS-a34db9f5-82dc-41b3-b9f4-c569bab869e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33816,DS-2bd94027-0c45-4c6d-9382-dab3eb03f73f,DISK], DatanodeInfoWithStorage[127.0.0.1:36813,DS-488b782e-e35e-4f6c-9ba2-94699fc30c33,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-aae98937-151e-48d7-b072-6a232f3cceeb,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-2f99747a-3d69-4594-a808-a36e5ff44bef,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-0bb0c903-1077-497e-ac5d-fd914107a4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-bd6d1adb-dd39-47f3-ad26-3d2512069c9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1289436458-172.17.0.17-1595809220636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43258,DS-82081deb-7140-4ce4-b3e7-65e0b452e5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38843,DS-a34db9f5-82dc-41b3-b9f4-c569bab869e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33816,DS-2bd94027-0c45-4c6d-9382-dab3eb03f73f,DISK], DatanodeInfoWithStorage[127.0.0.1:36813,DS-488b782e-e35e-4f6c-9ba2-94699fc30c33,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-aae98937-151e-48d7-b072-6a232f3cceeb,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-2f99747a-3d69-4594-a808-a36e5ff44bef,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-0bb0c903-1077-497e-ac5d-fd914107a4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-bd6d1adb-dd39-47f3-ad26-3d2512069c9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1566184649-172.17.0.17-1595809334676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44014,DS-d4277df5-98fc-41cc-b793-bd449e8d2e04,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-91e331b4-56fa-49b5-8687-d310932d8199,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-33e95a3a-3605-440e-8d4c-afed8ed92124,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-6b4772c7-8522-4395-b899-9aba5bcafbff,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-e3a80e0b-20e2-447a-ae77-7ff6565612d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-7a747ca1-98c5-4569-9408-fcee22976914,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-9bd6b022-689c-475f-a72c-404934a84fab,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-3b6c03e7-a81b-409a-8837-31b7f00ae542,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1566184649-172.17.0.17-1595809334676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44014,DS-d4277df5-98fc-41cc-b793-bd449e8d2e04,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-91e331b4-56fa-49b5-8687-d310932d8199,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-33e95a3a-3605-440e-8d4c-afed8ed92124,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-6b4772c7-8522-4395-b899-9aba5bcafbff,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-e3a80e0b-20e2-447a-ae77-7ff6565612d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-7a747ca1-98c5-4569-9408-fcee22976914,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-9bd6b022-689c-475f-a72c-404934a84fab,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-3b6c03e7-a81b-409a-8837-31b7f00ae542,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1167969098-172.17.0.17-1595809448042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40458,DS-7d91365c-13b2-43d3-abbb-9c03afd93a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-27645970-3855-4433-80cb-5392659c8f77,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-4719c9c2-78ff-4870-b965-2df3b21d9d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-7908ccab-986b-4182-b3bd-2d68a1e9cdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-0e9b0c7a-0993-45cc-8a0d-516552b26ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:37625,DS-ed49f546-a89b-43d9-9943-2227dd6d872a,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-3db2d749-f1c3-49a2-8fa2-e97a63bf8a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-1dd1bd0a-1510-4f91-a868-c8872e3656fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1167969098-172.17.0.17-1595809448042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40458,DS-7d91365c-13b2-43d3-abbb-9c03afd93a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-27645970-3855-4433-80cb-5392659c8f77,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-4719c9c2-78ff-4870-b965-2df3b21d9d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-7908ccab-986b-4182-b3bd-2d68a1e9cdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-0e9b0c7a-0993-45cc-8a0d-516552b26ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:37625,DS-ed49f546-a89b-43d9-9943-2227dd6d872a,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-3db2d749-f1c3-49a2-8fa2-e97a63bf8a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-1dd1bd0a-1510-4f91-a868-c8872e3656fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1140335046-172.17.0.17-1595809550407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40561,DS-5d0fd0ad-cc94-4072-a734-de54fcf9ad4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-c27979b7-7e7e-45c3-85b2-556dc619a937,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-4e089cdc-5730-4098-85a9-0de7bcff9f18,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-27ac284d-85c5-4faf-b303-0d10b4e22bac,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-1958784f-55d4-485a-ae84-ad6a47898ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-6e03dd32-9ca8-4202-a4be-fe794c301d64,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-c20194f5-353f-44df-87ab-3de3ec6aeafe,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-84d5a3b9-1063-4712-aabf-427d74079287,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1140335046-172.17.0.17-1595809550407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40561,DS-5d0fd0ad-cc94-4072-a734-de54fcf9ad4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-c27979b7-7e7e-45c3-85b2-556dc619a937,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-4e089cdc-5730-4098-85a9-0de7bcff9f18,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-27ac284d-85c5-4faf-b303-0d10b4e22bac,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-1958784f-55d4-485a-ae84-ad6a47898ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-6e03dd32-9ca8-4202-a4be-fe794c301d64,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-c20194f5-353f-44df-87ab-3de3ec6aeafe,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-84d5a3b9-1063-4712-aabf-427d74079287,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1804939159-172.17.0.17-1595809806564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39957,DS-e395e99d-196c-4064-bc7f-17a2a36b285d,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-24c64993-5454-41f9-9bce-8d84e263a38f,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-3c893273-73b5-4e86-9520-9444b41a7aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-acedf7e6-3f3c-45b1-914f-4895b7647b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-478a3dda-8c3a-463e-ac23-452f152d4bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37229,DS-d1afd37b-fb05-4565-9d9f-d655a6027cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-a704f4ae-835b-41fe-a102-ed913d431193,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-6874621f-6d2d-4fa2-a54c-9775252014c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1804939159-172.17.0.17-1595809806564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39957,DS-e395e99d-196c-4064-bc7f-17a2a36b285d,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-24c64993-5454-41f9-9bce-8d84e263a38f,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-3c893273-73b5-4e86-9520-9444b41a7aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-acedf7e6-3f3c-45b1-914f-4895b7647b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-478a3dda-8c3a-463e-ac23-452f152d4bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37229,DS-d1afd37b-fb05-4565-9d9f-d655a6027cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-a704f4ae-835b-41fe-a102-ed913d431193,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-6874621f-6d2d-4fa2-a54c-9775252014c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1354347689-172.17.0.17-1595810099745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33212,DS-b2916b25-9ce9-4a74-8c8c-5a892dd972ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-86ef2317-4387-4c15-a972-695838d35cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-e122c212-823c-44ee-b0e7-d127c76d0c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46424,DS-87e71f66-4d85-4e39-b39a-6253c85af2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-b1202d30-4101-4a0d-9186-c41fde183f57,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-39a4bcfc-abb1-4ebc-9705-04b7a067a43e,DISK], DatanodeInfoWithStorage[127.0.0.1:45109,DS-45ab61f5-732a-42d4-a47e-a884c9b192de,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-b24954a0-7002-46ee-bd52-e660255a8624,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1354347689-172.17.0.17-1595810099745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33212,DS-b2916b25-9ce9-4a74-8c8c-5a892dd972ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-86ef2317-4387-4c15-a972-695838d35cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-e122c212-823c-44ee-b0e7-d127c76d0c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46424,DS-87e71f66-4d85-4e39-b39a-6253c85af2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-b1202d30-4101-4a0d-9186-c41fde183f57,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-39a4bcfc-abb1-4ebc-9705-04b7a067a43e,DISK], DatanodeInfoWithStorage[127.0.0.1:45109,DS-45ab61f5-732a-42d4-a47e-a884c9b192de,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-b24954a0-7002-46ee-bd52-e660255a8624,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-744101963-172.17.0.17-1595810218213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37791,DS-8e1bf87b-518b-4242-ac30-10fe53e8b16e,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-bd82d509-366e-4676-a851-5730889d2ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-95d4df30-e84e-4508-a428-b0bda4c85c80,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-c8cfa96c-9e68-4616-86b6-cebd9d4c16bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-d693a647-4855-49d9-a6ff-81e4740b7e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34941,DS-f0b8a76d-9cb6-43a5-ae90-dfd667b7480e,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-7e408756-faf0-4273-a836-63462908a2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-da4e35f3-410b-40ff-bb9e-049fae233fc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-744101963-172.17.0.17-1595810218213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37791,DS-8e1bf87b-518b-4242-ac30-10fe53e8b16e,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-bd82d509-366e-4676-a851-5730889d2ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-95d4df30-e84e-4508-a428-b0bda4c85c80,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-c8cfa96c-9e68-4616-86b6-cebd9d4c16bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-d693a647-4855-49d9-a6ff-81e4740b7e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34941,DS-f0b8a76d-9cb6-43a5-ae90-dfd667b7480e,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-7e408756-faf0-4273-a836-63462908a2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-da4e35f3-410b-40ff-bb9e-049fae233fc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1479393708-172.17.0.17-1595810252329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34174,DS-eaded516-a50c-4823-8f37-8fab284dc38e,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-dffb4b47-83ca-4ea3-8d4c-99c844c2986c,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-0701d0ef-d5dc-42bc-84d9-0255b086a7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41513,DS-9cc6ec8b-588d-4afe-a372-32f7fd57ea5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-4e75ec69-8fb0-47f7-82b0-4537f2a7e54f,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-76987d17-d6e4-40cc-a366-9cca03327d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-1ef976ea-84bd-42b2-a61d-5d4f8fe7ef31,DISK], DatanodeInfoWithStorage[127.0.0.1:39397,DS-cbc2e1d6-1c08-48b2-9235-a36aba8f2347,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1479393708-172.17.0.17-1595810252329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34174,DS-eaded516-a50c-4823-8f37-8fab284dc38e,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-dffb4b47-83ca-4ea3-8d4c-99c844c2986c,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-0701d0ef-d5dc-42bc-84d9-0255b086a7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41513,DS-9cc6ec8b-588d-4afe-a372-32f7fd57ea5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-4e75ec69-8fb0-47f7-82b0-4537f2a7e54f,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-76987d17-d6e4-40cc-a366-9cca03327d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-1ef976ea-84bd-42b2-a61d-5d4f8fe7ef31,DISK], DatanodeInfoWithStorage[127.0.0.1:39397,DS-cbc2e1d6-1c08-48b2-9235-a36aba8f2347,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1140689199-172.17.0.17-1595810387867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36422,DS-c6d5c993-1a01-4914-b92f-6e1821e0497f,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-059402a2-bd31-433a-9c62-37efb2ba0c37,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-16240247-c354-46f2-9651-a7f9d0c4a1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-3fee0b14-e995-440c-a400-d87e26e07110,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-5e4f431b-13f9-4211-898e-acf9b4395c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-f6bdd01c-7690-456b-83be-9ca4ac07a02c,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-65522e41-6ef7-482f-9a05-469ebd5a4dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-1bfd2137-d8a8-491c-a84c-86cabedb56e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1140689199-172.17.0.17-1595810387867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36422,DS-c6d5c993-1a01-4914-b92f-6e1821e0497f,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-059402a2-bd31-433a-9c62-37efb2ba0c37,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-16240247-c354-46f2-9651-a7f9d0c4a1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-3fee0b14-e995-440c-a400-d87e26e07110,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-5e4f431b-13f9-4211-898e-acf9b4395c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-f6bdd01c-7690-456b-83be-9ca4ac07a02c,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-65522e41-6ef7-482f-9a05-469ebd5a4dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-1bfd2137-d8a8-491c-a84c-86cabedb56e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-75298709-172.17.0.17-1595810735445:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40643,DS-a3299c78-301a-4280-9594-8f1a506d556c,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-491c2378-ad3f-40c8-9f22-dd507f881004,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-cf174e72-7e56-42de-964e-7f4e98a0b2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-ea2fde57-1b42-4480-b831-46542ca9d08c,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-fa23090b-83a3-46f8-aacd-be1de8f9d583,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-eaa433ee-577c-47c2-9942-4fdeb8080f61,DISK], DatanodeInfoWithStorage[127.0.0.1:33768,DS-88c6b726-2b27-45f6-a005-ebd879d8918d,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-fe17e82f-6dcb-43e6-9d7e-26d2c66c21dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-75298709-172.17.0.17-1595810735445:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40643,DS-a3299c78-301a-4280-9594-8f1a506d556c,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-491c2378-ad3f-40c8-9f22-dd507f881004,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-cf174e72-7e56-42de-964e-7f4e98a0b2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-ea2fde57-1b42-4480-b831-46542ca9d08c,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-fa23090b-83a3-46f8-aacd-be1de8f9d583,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-eaa433ee-577c-47c2-9942-4fdeb8080f61,DISK], DatanodeInfoWithStorage[127.0.0.1:33768,DS-88c6b726-2b27-45f6-a005-ebd879d8918d,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-fe17e82f-6dcb-43e6-9d7e-26d2c66c21dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-548699942-172.17.0.17-1595810810568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46289,DS-01749681-05ec-4bac-ae11-2913ae29b3be,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-a6797def-5f81-461f-a0ab-785a809f4bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-adc7948e-176b-468c-9688-3cdebfc82a13,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-6555bfb8-df4b-4c69-a1c6-739ace808ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-715f1976-d913-4b79-98a9-d9e697adb8be,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-2c2c6e04-31b0-48b3-b977-4d32f5a684f5,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-79e6aed8-41aa-48dd-8b06-30304f8a3ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-5788fb4c-65d6-4271-8e59-81f766b8764d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-548699942-172.17.0.17-1595810810568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46289,DS-01749681-05ec-4bac-ae11-2913ae29b3be,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-a6797def-5f81-461f-a0ab-785a809f4bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-adc7948e-176b-468c-9688-3cdebfc82a13,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-6555bfb8-df4b-4c69-a1c6-739ace808ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-715f1976-d913-4b79-98a9-d9e697adb8be,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-2c2c6e04-31b0-48b3-b977-4d32f5a684f5,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-79e6aed8-41aa-48dd-8b06-30304f8a3ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-5788fb4c-65d6-4271-8e59-81f766b8764d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1172462426-172.17.0.17-1595811070163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41645,DS-2dc0dbcb-a6c6-4cd4-9d58-af766f58fc33,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-d6c5f5cf-b72b-4eda-90a9-08f0515b3bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-f3f3b393-2639-4f55-8a14-66759e5ddd8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-401221cd-11d7-483b-a163-9976e2d487f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-d12b2d98-3b1d-44f5-95ef-1a98c1e80eac,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-11a49705-15dd-443a-aee2-864aef3614bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-b2f05bef-1dff-4cee-8342-d1e29077ba2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33487,DS-f2698b3b-da30-4ba9-86d9-fa91ccfbbce5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1172462426-172.17.0.17-1595811070163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41645,DS-2dc0dbcb-a6c6-4cd4-9d58-af766f58fc33,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-d6c5f5cf-b72b-4eda-90a9-08f0515b3bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-f3f3b393-2639-4f55-8a14-66759e5ddd8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-401221cd-11d7-483b-a163-9976e2d487f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-d12b2d98-3b1d-44f5-95ef-1a98c1e80eac,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-11a49705-15dd-443a-aee2-864aef3614bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-b2f05bef-1dff-4cee-8342-d1e29077ba2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33487,DS-f2698b3b-da30-4ba9-86d9-fa91ccfbbce5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1797527608-172.17.0.17-1595811173424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35318,DS-d542d3c5-66e9-4fd1-b327-80f24ac83595,DISK], DatanodeInfoWithStorage[127.0.0.1:38542,DS-f6784f34-d6ad-4024-b3ac-cea37cb46842,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-8b0e8e5e-a959-4b8b-9bd5-7f4e04925474,DISK], DatanodeInfoWithStorage[127.0.0.1:39463,DS-525ad1cf-8e70-45c5-81d1-afb5b687d13a,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-78c6f65b-c05a-45d8-9883-52e10fd11d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-758c511c-9594-411d-a6c0-a177bfb137a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45057,DS-35927606-081c-4626-b441-b7795372b014,DISK], DatanodeInfoWithStorage[127.0.0.1:40566,DS-4a7fc6a5-db9c-447a-b383-b1138b4e6cf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1797527608-172.17.0.17-1595811173424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35318,DS-d542d3c5-66e9-4fd1-b327-80f24ac83595,DISK], DatanodeInfoWithStorage[127.0.0.1:38542,DS-f6784f34-d6ad-4024-b3ac-cea37cb46842,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-8b0e8e5e-a959-4b8b-9bd5-7f4e04925474,DISK], DatanodeInfoWithStorage[127.0.0.1:39463,DS-525ad1cf-8e70-45c5-81d1-afb5b687d13a,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-78c6f65b-c05a-45d8-9883-52e10fd11d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-758c511c-9594-411d-a6c0-a177bfb137a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45057,DS-35927606-081c-4626-b441-b7795372b014,DISK], DatanodeInfoWithStorage[127.0.0.1:40566,DS-4a7fc6a5-db9c-447a-b383-b1138b4e6cf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 18 out of 50
result: false positive !!!
Total execution time in seconds : 5772
