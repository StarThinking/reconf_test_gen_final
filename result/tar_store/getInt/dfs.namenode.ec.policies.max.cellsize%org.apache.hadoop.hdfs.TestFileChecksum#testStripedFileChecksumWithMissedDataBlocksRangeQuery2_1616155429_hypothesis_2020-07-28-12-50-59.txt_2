reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 4194304
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 4194304
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-768266585-172.17.0.14-1595940720872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36937,DS-5e38f3dc-cda2-4e9e-82ed-4b17c6d8ba1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-ae7fb299-2731-4660-98ab-2ec11fa57009,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-c3f6032b-4adb-480f-b2d3-4580a2513f48,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-3827d93e-b651-435c-a328-93fcbc919b82,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-a5e96f02-0ece-4bde-bd76-349c4c0e3da9,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-dddb54eb-eed3-42dc-8b60-abd5ea7933f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-6eb5adfb-1306-4548-bd89-35f1d6ee1ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-5b40e246-dd62-43e5-8590-f8c5b99ad70a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-768266585-172.17.0.14-1595940720872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36937,DS-5e38f3dc-cda2-4e9e-82ed-4b17c6d8ba1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-ae7fb299-2731-4660-98ab-2ec11fa57009,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-c3f6032b-4adb-480f-b2d3-4580a2513f48,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-3827d93e-b651-435c-a328-93fcbc919b82,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-a5e96f02-0ece-4bde-bd76-349c4c0e3da9,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-dddb54eb-eed3-42dc-8b60-abd5ea7933f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-6eb5adfb-1306-4548-bd89-35f1d6ee1ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-5b40e246-dd62-43e5-8590-f8c5b99ad70a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 4194304
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-680962921-172.17.0.14-1595940755575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34819,DS-408ffbd6-b3b3-481f-9c5e-08179ca707a8,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-806ec3a4-0202-471a-baeb-5f50b8ed3a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34823,DS-ada16933-b0cc-4cdb-ad25-56ef53caf119,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-d990f7b7-0ec3-4152-82b3-2be33622bbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-8c023b3c-a5b7-4cf8-aa8e-838859f85042,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-009e823f-2f3b-4117-ad75-60c6b99434b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-24011a97-a50c-49e2-becd-d31a52389ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-a91336a9-c2ea-4a88-ade8-1cc1e87c0c0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-680962921-172.17.0.14-1595940755575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34819,DS-408ffbd6-b3b3-481f-9c5e-08179ca707a8,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-806ec3a4-0202-471a-baeb-5f50b8ed3a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34823,DS-ada16933-b0cc-4cdb-ad25-56ef53caf119,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-d990f7b7-0ec3-4152-82b3-2be33622bbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-8c023b3c-a5b7-4cf8-aa8e-838859f85042,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-009e823f-2f3b-4117-ad75-60c6b99434b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-24011a97-a50c-49e2-becd-d31a52389ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-a91336a9-c2ea-4a88-ade8-1cc1e87c0c0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 4194304
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1448635413-172.17.0.14-1595941460457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40925,DS-5d58ba07-309f-4d77-a8f3-45d6e4a4373b,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-a0c7dfa0-c8d5-4832-9ef4-7c6b3d19f375,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-6eb7ba00-eede-4a99-95c4-16a008944e15,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-765a4960-a3c5-49ba-898c-5ba5276b2ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:42505,DS-49053fdd-909f-4cb1-8f80-69c37b6a7215,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-aa2ec168-ba39-47b9-973a-4d2ea2032811,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-bc29a9b3-dfeb-47ac-81c5-ad6187285af6,DISK], DatanodeInfoWithStorage[127.0.0.1:44643,DS-3c33569b-4f00-469b-a482-4fbe72723734,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1448635413-172.17.0.14-1595941460457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40925,DS-5d58ba07-309f-4d77-a8f3-45d6e4a4373b,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-a0c7dfa0-c8d5-4832-9ef4-7c6b3d19f375,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-6eb7ba00-eede-4a99-95c4-16a008944e15,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-765a4960-a3c5-49ba-898c-5ba5276b2ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:42505,DS-49053fdd-909f-4cb1-8f80-69c37b6a7215,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-aa2ec168-ba39-47b9-973a-4d2ea2032811,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-bc29a9b3-dfeb-47ac-81c5-ad6187285af6,DISK], DatanodeInfoWithStorage[127.0.0.1:44643,DS-3c33569b-4f00-469b-a482-4fbe72723734,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 4194304
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-694882903-172.17.0.14-1595941824219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39163,DS-bcda7905-891a-4139-9c3a-d23285bd8c98,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-11840c8c-bb14-43e3-b9ae-d6a3b1293df5,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-61a65641-04cb-4a63-aba4-119bf9356192,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-5712ea9a-c8e5-4922-ba1c-c3dc27f08cff,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-90a5182c-8a5f-4186-accd-768f44683270,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-ee9aead8-422b-4ff5-b2c6-d617547a4a39,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-442a0917-e8bb-4289-8198-94bc23943727,DISK], DatanodeInfoWithStorage[127.0.0.1:37108,DS-dc106ecd-b7ac-40e7-97d7-aab3fd608924,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-694882903-172.17.0.14-1595941824219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39163,DS-bcda7905-891a-4139-9c3a-d23285bd8c98,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-11840c8c-bb14-43e3-b9ae-d6a3b1293df5,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-61a65641-04cb-4a63-aba4-119bf9356192,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-5712ea9a-c8e5-4922-ba1c-c3dc27f08cff,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-90a5182c-8a5f-4186-accd-768f44683270,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-ee9aead8-422b-4ff5-b2c6-d617547a4a39,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-442a0917-e8bb-4289-8198-94bc23943727,DISK], DatanodeInfoWithStorage[127.0.0.1:37108,DS-dc106ecd-b7ac-40e7-97d7-aab3fd608924,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 4194304
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2117312197-172.17.0.14-1595942758681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37280,DS-098abda3-4676-451c-9d67-30e84edf86bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-973a0603-4e09-484e-9886-c4b86b250975,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-d8567ee1-608d-43ff-a93a-745dee762ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-60537451-7a60-46c3-8eb5-ad88b24d1299,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-87d5441c-4b10-4f13-ad83-ebee58f21d40,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-3b578dfa-a56b-4a4f-abb7-1b78008ba256,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-73eb2604-9696-4790-a74e-731109d2e461,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-9bb149bf-7426-4608-82b8-04c194168f1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2117312197-172.17.0.14-1595942758681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37280,DS-098abda3-4676-451c-9d67-30e84edf86bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-973a0603-4e09-484e-9886-c4b86b250975,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-d8567ee1-608d-43ff-a93a-745dee762ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-60537451-7a60-46c3-8eb5-ad88b24d1299,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-87d5441c-4b10-4f13-ad83-ebee58f21d40,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-3b578dfa-a56b-4a4f-abb7-1b78008ba256,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-73eb2604-9696-4790-a74e-731109d2e461,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-9bb149bf-7426-4608-82b8-04c194168f1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 4194304
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2078933797-172.17.0.14-1595942900105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38441,DS-213e9f1d-f942-47d2-82f2-1eae1420d3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-7c6c3e24-c340-43f0-bc7e-2bf16791504c,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-37c0a771-ff63-4fcb-bb4c-9cd5bcae63e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-d8353647-88b1-49b8-b468-b0f0ffbeddd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-62db1800-3f04-4023-a88c-840739c303ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-11482530-3d5b-4e62-bb4b-dd20b4f67d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-ea536c16-2e19-4758-b7e2-c218fa98551c,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-9c65a39c-e23c-4425-b348-1d1e0f727138,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2078933797-172.17.0.14-1595942900105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38441,DS-213e9f1d-f942-47d2-82f2-1eae1420d3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-7c6c3e24-c340-43f0-bc7e-2bf16791504c,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-37c0a771-ff63-4fcb-bb4c-9cd5bcae63e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-d8353647-88b1-49b8-b468-b0f0ffbeddd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-62db1800-3f04-4023-a88c-840739c303ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-11482530-3d5b-4e62-bb4b-dd20b4f67d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-ea536c16-2e19-4758-b7e2-c218fa98551c,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-9c65a39c-e23c-4425-b348-1d1e0f727138,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 4194304
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-565846569-172.17.0.14-1595942934983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40658,DS-af518660-87bb-48ea-aa4a-e607ad746107,DISK], DatanodeInfoWithStorage[127.0.0.1:39473,DS-8c563330-8cf8-41d8-96e8-a77fce1ffaaa,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-ef318294-87d4-4ccb-b771-957925998ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:41184,DS-21fd13fa-775f-4581-ae93-93ceff74f42a,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-44007d7b-aa98-4cae-9fa1-75cec5eb0023,DISK], DatanodeInfoWithStorage[127.0.0.1:43840,DS-544bff11-76f6-482c-8ffb-3f24e886051e,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-08f76b98-71fd-4601-8e74-f182e308720c,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-41daa8da-1d20-4557-a8ba-2940a8d78a0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-565846569-172.17.0.14-1595942934983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40658,DS-af518660-87bb-48ea-aa4a-e607ad746107,DISK], DatanodeInfoWithStorage[127.0.0.1:39473,DS-8c563330-8cf8-41d8-96e8-a77fce1ffaaa,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-ef318294-87d4-4ccb-b771-957925998ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:41184,DS-21fd13fa-775f-4581-ae93-93ceff74f42a,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-44007d7b-aa98-4cae-9fa1-75cec5eb0023,DISK], DatanodeInfoWithStorage[127.0.0.1:43840,DS-544bff11-76f6-482c-8ffb-3f24e886051e,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-08f76b98-71fd-4601-8e74-f182e308720c,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-41daa8da-1d20-4557-a8ba-2940a8d78a0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 4194304
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1202627743-172.17.0.14-1595943293731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41796,DS-44b6e765-ded0-4b96-bdb2-b8eb41b65da1,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-596491c9-8504-4526-b918-11f8ac8090ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-a5eb259f-b8b9-40d3-befe-589a88f46869,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-97b42a5a-0e50-408c-a44e-23d9da81616f,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-4ee20f37-7f0a-4893-a5f4-c9ec7ce43d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-a8f6d87f-c4e4-47b4-8876-c73875d894f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-72a0ea56-b437-4d4f-9692-28a706fb83b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-8287ef1c-14a7-4ec5-bd4d-29f23094eccc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1202627743-172.17.0.14-1595943293731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41796,DS-44b6e765-ded0-4b96-bdb2-b8eb41b65da1,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-596491c9-8504-4526-b918-11f8ac8090ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-a5eb259f-b8b9-40d3-befe-589a88f46869,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-97b42a5a-0e50-408c-a44e-23d9da81616f,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-4ee20f37-7f0a-4893-a5f4-c9ec7ce43d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-a8f6d87f-c4e4-47b4-8876-c73875d894f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-72a0ea56-b437-4d4f-9692-28a706fb83b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-8287ef1c-14a7-4ec5-bd4d-29f23094eccc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 4194304
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-234199930-172.17.0.14-1595944405035:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35816,DS-bf93445b-0f44-4019-93ae-fbf275eccd1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-33671cfb-046e-47e4-b3ab-8f363e70a436,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-99aa8394-627b-4015-a709-9997e10c8e62,DISK], DatanodeInfoWithStorage[127.0.0.1:44853,DS-2cba7f89-f490-4654-a44a-f68944bf3705,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-87d5dd61-1cd0-4f35-82bd-cade2ae6611c,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-b36adde3-5309-41b5-b583-dbd7000142bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-43ee1506-9f76-43c8-9628-b0829d57c651,DISK], DatanodeInfoWithStorage[127.0.0.1:43505,DS-55b713fd-fd57-4458-b55a-33520121b592,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-234199930-172.17.0.14-1595944405035:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35816,DS-bf93445b-0f44-4019-93ae-fbf275eccd1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-33671cfb-046e-47e4-b3ab-8f363e70a436,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-99aa8394-627b-4015-a709-9997e10c8e62,DISK], DatanodeInfoWithStorage[127.0.0.1:44853,DS-2cba7f89-f490-4654-a44a-f68944bf3705,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-87d5dd61-1cd0-4f35-82bd-cade2ae6611c,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-b36adde3-5309-41b5-b583-dbd7000142bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-43ee1506-9f76-43c8-9628-b0829d57c651,DISK], DatanodeInfoWithStorage[127.0.0.1:43505,DS-55b713fd-fd57-4458-b55a-33520121b592,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 4194304
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-955011491-172.17.0.14-1595944767350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39004,DS-2d713dff-520b-4ba2-8e82-416a5fbcef44,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-d807ff04-572a-431c-a1ff-1618eaf9f0be,DISK], DatanodeInfoWithStorage[127.0.0.1:35427,DS-13b07fcf-1db3-462c-a2d9-23f9d83e2cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-2995d486-4597-4257-a1a8-83dc4f5545c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33605,DS-99a52125-0ca8-4cb0-99f7-aef6471a8920,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-f7ac81a3-f439-4fc9-b3c7-953fd2595500,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-d1780257-d263-4726-b281-4de974bf8ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-02de60ea-72e4-4fc5-8d22-2b0667cb2d51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-955011491-172.17.0.14-1595944767350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39004,DS-2d713dff-520b-4ba2-8e82-416a5fbcef44,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-d807ff04-572a-431c-a1ff-1618eaf9f0be,DISK], DatanodeInfoWithStorage[127.0.0.1:35427,DS-13b07fcf-1db3-462c-a2d9-23f9d83e2cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-2995d486-4597-4257-a1a8-83dc4f5545c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33605,DS-99a52125-0ca8-4cb0-99f7-aef6471a8920,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-f7ac81a3-f439-4fc9-b3c7-953fd2595500,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-d1780257-d263-4726-b281-4de974bf8ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-02de60ea-72e4-4fc5-8d22-2b0667cb2d51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 4194304
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-424466631-172.17.0.14-1595944850481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38182,DS-214b7f27-446b-4e3b-bde5-39304f0a59bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-ccda91c7-f4c6-4dc0-b643-6d9a02a13212,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-673520ab-a071-45a9-99fe-4094f153c86a,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-16fcfa84-6968-4db8-8bf4-875a6ac4f571,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-6bd63d1a-cd6e-484c-96ac-68a70c30cc06,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-4a8f723e-dce4-4717-8852-33db5644d8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39307,DS-5cb04223-8657-405f-bcf8-6c527d89a941,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-6a2ff4af-bd3f-4662-8e33-8f6a1aafb5f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-424466631-172.17.0.14-1595944850481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38182,DS-214b7f27-446b-4e3b-bde5-39304f0a59bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-ccda91c7-f4c6-4dc0-b643-6d9a02a13212,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-673520ab-a071-45a9-99fe-4094f153c86a,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-16fcfa84-6968-4db8-8bf4-875a6ac4f571,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-6bd63d1a-cd6e-484c-96ac-68a70c30cc06,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-4a8f723e-dce4-4717-8852-33db5644d8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39307,DS-5cb04223-8657-405f-bcf8-6c527d89a941,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-6a2ff4af-bd3f-4662-8e33-8f6a1aafb5f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 4194304
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1376852277-172.17.0.14-1595945345948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34773,DS-33e5112d-e6b3-43db-b905-dd147a3dc5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-27ed8de5-578a-487d-9239-de0f4edb8f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-19a35bf6-14e4-438e-aba9-761e933e48e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-23bebe35-7bc0-494b-905a-4606426ecb50,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-a1bed8de-8009-4580-a284-e40fe541da1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-6917f5bc-6afc-46bd-9b58-6a8c0b08b111,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-a36a7e66-77e3-4537-8a4e-d0fda05c01a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-4ce1ca64-9b5e-4b7c-abd6-bf4b5373fd58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1376852277-172.17.0.14-1595945345948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34773,DS-33e5112d-e6b3-43db-b905-dd147a3dc5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-27ed8de5-578a-487d-9239-de0f4edb8f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-19a35bf6-14e4-438e-aba9-761e933e48e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-23bebe35-7bc0-494b-905a-4606426ecb50,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-a1bed8de-8009-4580-a284-e40fe541da1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-6917f5bc-6afc-46bd-9b58-6a8c0b08b111,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-a36a7e66-77e3-4537-8a4e-d0fda05c01a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-4ce1ca64-9b5e-4b7c-abd6-bf4b5373fd58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 4194304
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1757677590-172.17.0.14-1595946391867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35780,DS-2918b580-073b-4bf9-9aa8-e0218ed4e352,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-b7cbdcb2-552c-40d6-885d-966839040592,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-c358c4a8-9a08-402c-a674-80ad64a948f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-e0f75d05-3919-4e1b-b3e9-ef415691bce0,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-3df52726-f6c0-4eff-86e0-9d9dba55b3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33229,DS-070a8d50-069e-4562-b0d5-da4871d79239,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-50b07f94-fef8-4ca6-8402-8621fe6c53da,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-3dd6edba-fd30-49d3-b716-21dc2105f2e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1757677590-172.17.0.14-1595946391867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35780,DS-2918b580-073b-4bf9-9aa8-e0218ed4e352,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-b7cbdcb2-552c-40d6-885d-966839040592,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-c358c4a8-9a08-402c-a674-80ad64a948f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-e0f75d05-3919-4e1b-b3e9-ef415691bce0,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-3df52726-f6c0-4eff-86e0-9d9dba55b3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33229,DS-070a8d50-069e-4562-b0d5-da4871d79239,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-50b07f94-fef8-4ca6-8402-8621fe6c53da,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-3dd6edba-fd30-49d3-b716-21dc2105f2e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 4194304
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1352690724-172.17.0.14-1595946774158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43991,DS-14e517a2-ba6c-4d5f-9996-ee3203682425,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-cfd4bff2-7942-474c-846b-d12d41aa53ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-d5b87a7c-0d5b-4a57-9c0a-463a51c7aca7,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-c9b8c86f-511a-4a10-917e-8789895ba15c,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-9baa4644-c21f-4dd9-b991-d9e824d66981,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-069e89c6-d163-4525-97f7-ca86d652cdf0,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-06f98692-96ae-4745-8993-615b0fef7244,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-2122014d-7f85-46c7-ab37-2982c66cb2dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1352690724-172.17.0.14-1595946774158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43991,DS-14e517a2-ba6c-4d5f-9996-ee3203682425,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-cfd4bff2-7942-474c-846b-d12d41aa53ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-d5b87a7c-0d5b-4a57-9c0a-463a51c7aca7,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-c9b8c86f-511a-4a10-917e-8789895ba15c,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-9baa4644-c21f-4dd9-b991-d9e824d66981,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-069e89c6-d163-4525-97f7-ca86d652cdf0,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-06f98692-96ae-4745-8993-615b0fef7244,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-2122014d-7f85-46c7-ab37-2982c66cb2dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6786
