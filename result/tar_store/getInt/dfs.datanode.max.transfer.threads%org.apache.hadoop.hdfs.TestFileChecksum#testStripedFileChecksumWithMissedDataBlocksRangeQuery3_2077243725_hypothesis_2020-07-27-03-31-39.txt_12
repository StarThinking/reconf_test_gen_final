reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1513911580-172.17.0.5-1595820826438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43370,DS-af1b0b78-d55d-4089-bc81-6c11ffb99055,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-e8896e78-28f9-4e6f-afd0-ccf63b2b9ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-88ee46d7-c20f-41d5-8536-2c17891ca310,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-7c056e3e-3032-4017-96a8-0b9a69b04f79,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-0a2aefaf-f946-49ed-a1f3-b9719986ca99,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-d187b872-5270-459b-ab9a-9c4c64310fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-4c52decc-41b8-4317-a325-05f7140aa930,DISK], DatanodeInfoWithStorage[127.0.0.1:40346,DS-6cebe0dc-b639-4e0f-8239-708f2fbdc5e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1513911580-172.17.0.5-1595820826438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43370,DS-af1b0b78-d55d-4089-bc81-6c11ffb99055,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-e8896e78-28f9-4e6f-afd0-ccf63b2b9ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-88ee46d7-c20f-41d5-8536-2c17891ca310,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-7c056e3e-3032-4017-96a8-0b9a69b04f79,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-0a2aefaf-f946-49ed-a1f3-b9719986ca99,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-d187b872-5270-459b-ab9a-9c4c64310fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-4c52decc-41b8-4317-a325-05f7140aa930,DISK], DatanodeInfoWithStorage[127.0.0.1:40346,DS-6cebe0dc-b639-4e0f-8239-708f2fbdc5e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-601058990-172.17.0.5-1595820869394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34835,DS-823b9142-2bd6-4269-ac9a-3481746f77b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40438,DS-510e3624-d05a-48ff-a136-dd94ce2b187d,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-e676cf20-666f-4def-813a-ab3eb4b8f3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34208,DS-d9b0cf9a-bfe3-4815-b03b-f306acacf33a,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-5253c45c-bab2-4200-84ac-93e160a2ff77,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-9646f029-9239-4736-8977-e8d50e0ec6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-4b90f6aa-630d-4356-83df-88bfba26e70b,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-f3a3c23e-0ab3-4c38-bf83-1a353cc2d303,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-601058990-172.17.0.5-1595820869394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34835,DS-823b9142-2bd6-4269-ac9a-3481746f77b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40438,DS-510e3624-d05a-48ff-a136-dd94ce2b187d,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-e676cf20-666f-4def-813a-ab3eb4b8f3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34208,DS-d9b0cf9a-bfe3-4815-b03b-f306acacf33a,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-5253c45c-bab2-4200-84ac-93e160a2ff77,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-9646f029-9239-4736-8977-e8d50e0ec6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-4b90f6aa-630d-4356-83df-88bfba26e70b,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-f3a3c23e-0ab3-4c38-bf83-1a353cc2d303,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-437228928-172.17.0.5-1595820946218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37573,DS-8bb910ed-f9c0-41f6-85f9-ea2999395483,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-a368b019-d651-46f5-ba68-3abd90b47851,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-45de0e52-e849-4e95-8d46-e85e059017f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46205,DS-31074bfc-e852-4ab3-b740-eab58d163e34,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-b2a453bf-00f9-46f7-bc3c-6b6ad599625e,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-4a2b0ea2-3cd6-4c53-8333-f0cb912af581,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-5817a163-b910-4fb2-8173-2d8cfa3bb025,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-39fb3d29-171b-4a4b-99bb-2cdb4dda120a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-437228928-172.17.0.5-1595820946218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37573,DS-8bb910ed-f9c0-41f6-85f9-ea2999395483,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-a368b019-d651-46f5-ba68-3abd90b47851,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-45de0e52-e849-4e95-8d46-e85e059017f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46205,DS-31074bfc-e852-4ab3-b740-eab58d163e34,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-b2a453bf-00f9-46f7-bc3c-6b6ad599625e,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-4a2b0ea2-3cd6-4c53-8333-f0cb912af581,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-5817a163-b910-4fb2-8173-2d8cfa3bb025,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-39fb3d29-171b-4a4b-99bb-2cdb4dda120a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1247719212-172.17.0.5-1595821290161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40560,DS-e9e20061-2822-4960-be27-5df603091e33,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-e5c66004-293b-4395-a602-6a08a0eee6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-fedb1666-3d4d-4b61-b413-58f14cd50503,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-ad81aea6-05bf-475f-b8f0-f63009039629,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-6927b3fc-02c5-4f50-9c23-4106a064e71c,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-25f4b5bd-5126-4ee0-a095-6cd65aa49fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41780,DS-b41d0b69-0966-4dd6-96e4-2c402ec81f36,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-80508233-2b84-41b2-9f7e-ad24e48ce868,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1247719212-172.17.0.5-1595821290161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40560,DS-e9e20061-2822-4960-be27-5df603091e33,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-e5c66004-293b-4395-a602-6a08a0eee6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-fedb1666-3d4d-4b61-b413-58f14cd50503,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-ad81aea6-05bf-475f-b8f0-f63009039629,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-6927b3fc-02c5-4f50-9c23-4106a064e71c,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-25f4b5bd-5126-4ee0-a095-6cd65aa49fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41780,DS-b41d0b69-0966-4dd6-96e4-2c402ec81f36,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-80508233-2b84-41b2-9f7e-ad24e48ce868,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1498022535-172.17.0.5-1595821611842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34961,DS-ef2a05b3-99eb-4702-9d41-a5f28f20a4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40526,DS-e3242427-623d-401d-8680-cb24924416af,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-3377547f-aed8-4983-94c3-f917aabe1bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-596bcf2d-6c79-4d06-82c1-300dcdb35d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41164,DS-2e4c25ff-49d3-442d-b626-251b81f7c46c,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-4d95b44a-64e9-4f1a-b28f-f1d969b582f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-0ea92726-d324-4c3d-b365-8cd60a27f3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-5b28846b-1da1-40a6-906d-99996f8c39b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1498022535-172.17.0.5-1595821611842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34961,DS-ef2a05b3-99eb-4702-9d41-a5f28f20a4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40526,DS-e3242427-623d-401d-8680-cb24924416af,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-3377547f-aed8-4983-94c3-f917aabe1bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-596bcf2d-6c79-4d06-82c1-300dcdb35d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41164,DS-2e4c25ff-49d3-442d-b626-251b81f7c46c,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-4d95b44a-64e9-4f1a-b28f-f1d969b582f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-0ea92726-d324-4c3d-b365-8cd60a27f3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-5b28846b-1da1-40a6-906d-99996f8c39b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1027851664-172.17.0.5-1595821788574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43519,DS-df2eb164-a346-4101-8487-1d01693d2345,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-103ce006-8775-4523-9176-95be24490d21,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-42ed43a7-51ad-4a14-bf7e-4435ef6f0027,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-efe151e7-85d7-4ddf-b02c-882195f43c00,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-e2b028d4-01f0-4180-b78f-c54518f01717,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-1b810a1b-77c6-456c-96f3-32dc8b68ebb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-db9d214d-fb2b-4660-bcae-a0becc05582d,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-4c8acea4-ea97-4811-ace4-93ed23b463b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1027851664-172.17.0.5-1595821788574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43519,DS-df2eb164-a346-4101-8487-1d01693d2345,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-103ce006-8775-4523-9176-95be24490d21,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-42ed43a7-51ad-4a14-bf7e-4435ef6f0027,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-efe151e7-85d7-4ddf-b02c-882195f43c00,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-e2b028d4-01f0-4180-b78f-c54518f01717,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-1b810a1b-77c6-456c-96f3-32dc8b68ebb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-db9d214d-fb2b-4660-bcae-a0becc05582d,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-4c8acea4-ea97-4811-ace4-93ed23b463b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-486362206-172.17.0.5-1595822492759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35039,DS-a34bb444-11bc-4d6f-9c28-e28a444579b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-6e7cf0cc-f666-4e19-af9f-d45796a22fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-628660e5-df92-46fc-9477-2962ce8490b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-46e9aba9-4a3e-4521-87bc-42fe8dd8c121,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-3281ad1c-37bb-4bd2-9f3b-5ef01d6dc484,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-0f0a0779-aa02-4799-afdb-1f412199200d,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-2ecf0363-fec2-45bf-9b99-9c575bb36527,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-9336b560-278b-4228-9599-60f43b0292fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-486362206-172.17.0.5-1595822492759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35039,DS-a34bb444-11bc-4d6f-9c28-e28a444579b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-6e7cf0cc-f666-4e19-af9f-d45796a22fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-628660e5-df92-46fc-9477-2962ce8490b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-46e9aba9-4a3e-4521-87bc-42fe8dd8c121,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-3281ad1c-37bb-4bd2-9f3b-5ef01d6dc484,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-0f0a0779-aa02-4799-afdb-1f412199200d,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-2ecf0363-fec2-45bf-9b99-9c575bb36527,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-9336b560-278b-4228-9599-60f43b0292fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-777888221-172.17.0.5-1595822858096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42836,DS-ef3fed3a-4b77-43f4-9d69-f610145c1e81,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-7b5447c3-6cdd-4d6a-a4ad-33611f95673f,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-bf58670a-38f0-4f92-9f15-d54dc019c570,DISK], DatanodeInfoWithStorage[127.0.0.1:34434,DS-eb2589d3-2b62-4d1d-ad1a-5d3d45863598,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-7962231c-35bc-4552-94ba-026dcb37bb5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-419f5da7-c56e-402e-a7dc-7577d5a37ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-dbb8c9f4-826a-4147-abfc-17878c937085,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-3be98466-8c3e-499b-84da-bfd7866f45d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-777888221-172.17.0.5-1595822858096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42836,DS-ef3fed3a-4b77-43f4-9d69-f610145c1e81,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-7b5447c3-6cdd-4d6a-a4ad-33611f95673f,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-bf58670a-38f0-4f92-9f15-d54dc019c570,DISK], DatanodeInfoWithStorage[127.0.0.1:34434,DS-eb2589d3-2b62-4d1d-ad1a-5d3d45863598,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-7962231c-35bc-4552-94ba-026dcb37bb5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-419f5da7-c56e-402e-a7dc-7577d5a37ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-dbb8c9f4-826a-4147-abfc-17878c937085,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-3be98466-8c3e-499b-84da-bfd7866f45d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-849260353-172.17.0.5-1595823736767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39768,DS-08d2a308-65e8-4b35-ac8f-3fff01496017,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-f22c3f60-cb5c-495a-b33c-cab197af05a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-bd13af89-e52b-412e-9946-d344847b3638,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-673359f5-afa8-40c0-b1f0-c9c881552f25,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-158c441b-eaaf-46ce-81c6-6e757367c32d,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-e9a18ab8-8f3c-40fb-922a-44eb829f468c,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-81a83c35-0b1e-49e3-b676-2b407f7e6ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-e3ebf1b8-8239-4cae-950d-588f30cb916e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-849260353-172.17.0.5-1595823736767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39768,DS-08d2a308-65e8-4b35-ac8f-3fff01496017,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-f22c3f60-cb5c-495a-b33c-cab197af05a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-bd13af89-e52b-412e-9946-d344847b3638,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-673359f5-afa8-40c0-b1f0-c9c881552f25,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-158c441b-eaaf-46ce-81c6-6e757367c32d,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-e9a18ab8-8f3c-40fb-922a-44eb829f468c,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-81a83c35-0b1e-49e3-b676-2b407f7e6ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-e3ebf1b8-8239-4cae-950d-588f30cb916e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-394663953-172.17.0.5-1595823839366:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46532,DS-6a66a6d5-667f-4076-b2b8-0dfaec14cdc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-26a4585c-99ca-4e21-8fa9-c8aee1819ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:34535,DS-43c1ce08-1514-428c-842f-6d2ba26d32fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-a8c0a5fb-aa9c-4768-8237-0573ddff24fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-66fd1407-3268-431b-8f12-28efee717022,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-2045afd8-8919-4f54-a6e4-dfe50f9c973b,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-793708aa-d69e-401c-a243-eb9ccf0d9e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-0d40013f-95b5-454b-ad6b-08df86e1cf61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-394663953-172.17.0.5-1595823839366:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46532,DS-6a66a6d5-667f-4076-b2b8-0dfaec14cdc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-26a4585c-99ca-4e21-8fa9-c8aee1819ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:34535,DS-43c1ce08-1514-428c-842f-6d2ba26d32fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-a8c0a5fb-aa9c-4768-8237-0573ddff24fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-66fd1407-3268-431b-8f12-28efee717022,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-2045afd8-8919-4f54-a6e4-dfe50f9c973b,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-793708aa-d69e-401c-a243-eb9ccf0d9e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-0d40013f-95b5-454b-ad6b-08df86e1cf61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-133028221-172.17.0.5-1595824306777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39921,DS-65635ea0-0a5b-4689-a184-880e9259bf95,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-8158e71b-e2af-46d5-ae54-2add15c3fced,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-680bf288-0295-4ab6-bfdd-fec5dd2eaa0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-a59557b1-8934-4f4a-b51a-8ef4f9d593cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-fca160dd-87c7-4ba1-a0df-de529b3f9eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44265,DS-dadfa78e-0734-48d0-a42f-1da31b9f2366,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-934637d0-9c59-462e-870a-fdabf3d56eca,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-6b3bc238-dacc-4d52-acbf-9db70e5eab3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-133028221-172.17.0.5-1595824306777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39921,DS-65635ea0-0a5b-4689-a184-880e9259bf95,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-8158e71b-e2af-46d5-ae54-2add15c3fced,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-680bf288-0295-4ab6-bfdd-fec5dd2eaa0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-a59557b1-8934-4f4a-b51a-8ef4f9d593cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-fca160dd-87c7-4ba1-a0df-de529b3f9eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44265,DS-dadfa78e-0734-48d0-a42f-1da31b9f2366,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-934637d0-9c59-462e-870a-fdabf3d56eca,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-6b3bc238-dacc-4d52-acbf-9db70e5eab3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1934005414-172.17.0.5-1595824414093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38655,DS-18e284ae-6a7f-475f-8bb9-0c10a0aefaf1,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-4eee7838-162f-422b-83d7-6a817215c0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-3441cced-1beb-41df-8a7c-24ef383d5e29,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-0d74c70e-ed75-4751-867e-6251e5b78ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-d0a560f2-46c2-4aa5-a463-0d08156d574f,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-9ec7dc49-8a6b-49c5-bf3b-104dd29bccd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-0c3a0ed7-b073-40ac-8bbc-8314769e50d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-8f04645a-e7b9-48f5-baa7-0753c4ac19e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1934005414-172.17.0.5-1595824414093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38655,DS-18e284ae-6a7f-475f-8bb9-0c10a0aefaf1,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-4eee7838-162f-422b-83d7-6a817215c0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-3441cced-1beb-41df-8a7c-24ef383d5e29,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-0d74c70e-ed75-4751-867e-6251e5b78ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-d0a560f2-46c2-4aa5-a463-0d08156d574f,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-9ec7dc49-8a6b-49c5-bf3b-104dd29bccd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-0c3a0ed7-b073-40ac-8bbc-8314769e50d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-8f04645a-e7b9-48f5-baa7-0753c4ac19e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1838671931-172.17.0.5-1595824585263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36899,DS-08029f20-25d8-488f-9093-98517165ae11,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-7310192a-0a83-4320-b09b-3b73458a01b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-ae03a7a2-655f-40cf-a00f-8e79ae420aed,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-bf86d2c2-c511-4628-a628-6267997e70c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-b8e470c7-4f7c-42b1-af54-49d3653e7f92,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-4b4f6a82-899e-4b2e-b1ee-0243afb8e214,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-701188f6-861d-4895-b245-cfa8ca1dfac6,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-db066b35-5e2d-430c-9a74-7ea5a73b573a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1838671931-172.17.0.5-1595824585263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36899,DS-08029f20-25d8-488f-9093-98517165ae11,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-7310192a-0a83-4320-b09b-3b73458a01b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-ae03a7a2-655f-40cf-a00f-8e79ae420aed,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-bf86d2c2-c511-4628-a628-6267997e70c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-b8e470c7-4f7c-42b1-af54-49d3653e7f92,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-4b4f6a82-899e-4b2e-b1ee-0243afb8e214,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-701188f6-861d-4895-b245-cfa8ca1dfac6,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-db066b35-5e2d-430c-9a74-7ea5a73b573a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1914638498-172.17.0.5-1595825056719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45195,DS-1a4394e6-8085-4f83-b5be-8bfb195d1db3,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-d5453f08-f923-4724-969a-70376b2f799c,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-47d11b04-3b7e-4766-b73e-1c506754d2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-a804fe0b-5b4d-4013-8a23-6796c8f9bebc,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-16db4874-39ee-4c17-b763-68a892627aae,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-3ec3336b-a97d-4ce2-b29d-cdf94a9969bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-90a52983-77fe-441d-a465-2ff657633b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-93bdc9f1-a882-4f56-8c63-34fb0cffe427,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1914638498-172.17.0.5-1595825056719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45195,DS-1a4394e6-8085-4f83-b5be-8bfb195d1db3,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-d5453f08-f923-4724-969a-70376b2f799c,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-47d11b04-3b7e-4766-b73e-1c506754d2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-a804fe0b-5b4d-4013-8a23-6796c8f9bebc,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-16db4874-39ee-4c17-b763-68a892627aae,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-3ec3336b-a97d-4ce2-b29d-cdf94a9969bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-90a52983-77fe-441d-a465-2ff657633b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-93bdc9f1-a882-4f56-8c63-34fb0cffe427,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-154494544-172.17.0.5-1595825282224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38180,DS-e6e86c89-73e8-4bd3-b2db-bf1faf69fd40,DISK], DatanodeInfoWithStorage[127.0.0.1:43290,DS-86f56138-b423-49ea-9a5f-6cc451a3fdfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-2540178e-9457-430c-975e-27cf09741f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-6807e526-48d9-42fa-a702-df19a786ec84,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-c25b6f7d-c886-48a4-8313-df83bc8a19ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-8276f7eb-5565-41d5-90e7-84de18b3644d,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-1f0bffeb-0491-494b-8108-3d3610f0a959,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-3245a512-b585-4979-9bd0-e51260201384,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-154494544-172.17.0.5-1595825282224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38180,DS-e6e86c89-73e8-4bd3-b2db-bf1faf69fd40,DISK], DatanodeInfoWithStorage[127.0.0.1:43290,DS-86f56138-b423-49ea-9a5f-6cc451a3fdfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-2540178e-9457-430c-975e-27cf09741f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-6807e526-48d9-42fa-a702-df19a786ec84,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-c25b6f7d-c886-48a4-8313-df83bc8a19ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-8276f7eb-5565-41d5-90e7-84de18b3644d,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-1f0bffeb-0491-494b-8108-3d3610f0a959,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-3245a512-b585-4979-9bd0-e51260201384,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5323
