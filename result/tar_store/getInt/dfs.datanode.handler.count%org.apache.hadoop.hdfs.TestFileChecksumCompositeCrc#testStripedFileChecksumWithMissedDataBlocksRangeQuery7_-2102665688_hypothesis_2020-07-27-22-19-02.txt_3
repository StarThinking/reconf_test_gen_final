reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1078108817-172.17.0.10-1595888487746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34080,DS-1e6b8ba0-8904-481d-93ea-d52fdb4d57b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-7b2cb980-0734-4697-b9dc-dcf0fc0f1f31,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-1ebae98c-eea5-4583-9d2a-12ba3a2f37ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-6d1baa15-b8ad-4e57-b127-76d705eb719b,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-13fb4da6-2a0b-467d-88fd-4b728583640e,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-aa7e9143-4a79-4b32-8f4e-9eaf33cb24f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-a0d1d2eb-8cf7-46ec-a14f-accba2118382,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-42392c04-1b12-432a-88a0-f62430dae887,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1078108817-172.17.0.10-1595888487746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34080,DS-1e6b8ba0-8904-481d-93ea-d52fdb4d57b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-7b2cb980-0734-4697-b9dc-dcf0fc0f1f31,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-1ebae98c-eea5-4583-9d2a-12ba3a2f37ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-6d1baa15-b8ad-4e57-b127-76d705eb719b,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-13fb4da6-2a0b-467d-88fd-4b728583640e,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-aa7e9143-4a79-4b32-8f4e-9eaf33cb24f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-a0d1d2eb-8cf7-46ec-a14f-accba2118382,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-42392c04-1b12-432a-88a0-f62430dae887,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1667554389-172.17.0.10-1595888522706:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36970,DS-440b5b3c-d971-40b8-ad2f-83e0da52427b,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-b825199a-6905-4e50-b3f4-3a456acd76eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-9eaa55f6-f3a5-45f9-917f-652074ec9438,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-34ca12c8-a632-44e5-bb2d-706c73d42d48,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-5c571829-482e-47e9-ad83-12aa954f61f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-3ef62755-1852-4846-bf16-33543ff985fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-713fba2e-6310-4a4a-b3c5-d6a78852d158,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-5c305268-6fee-493c-b6cc-cf5a0a5fc054,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1667554389-172.17.0.10-1595888522706:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36970,DS-440b5b3c-d971-40b8-ad2f-83e0da52427b,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-b825199a-6905-4e50-b3f4-3a456acd76eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-9eaa55f6-f3a5-45f9-917f-652074ec9438,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-34ca12c8-a632-44e5-bb2d-706c73d42d48,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-5c571829-482e-47e9-ad83-12aa954f61f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-3ef62755-1852-4846-bf16-33543ff985fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-713fba2e-6310-4a4a-b3c5-d6a78852d158,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-5c305268-6fee-493c-b6cc-cf5a0a5fc054,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-91777374-172.17.0.10-1595888698855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45036,DS-4d763617-ff13-4951-b39e-012db02c8374,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-02093808-7fae-49f6-9ee8-aff3a9c46ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-76a27972-1398-4d58-9eec-c4bfd0dfc303,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-f9ec3755-8149-4639-b93e-2674ea50e3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-4c579864-fd3f-4e41-987a-b67dc2c4e8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-aeaa759f-38b5-4043-8a33-175c0a4f0606,DISK], DatanodeInfoWithStorage[127.0.0.1:36099,DS-391a7ec9-de2d-4a55-b7af-d17233f45b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42703,DS-d4bb9a69-70d6-4d47-9469-a000b284abb6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-91777374-172.17.0.10-1595888698855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45036,DS-4d763617-ff13-4951-b39e-012db02c8374,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-02093808-7fae-49f6-9ee8-aff3a9c46ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-76a27972-1398-4d58-9eec-c4bfd0dfc303,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-f9ec3755-8149-4639-b93e-2674ea50e3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-4c579864-fd3f-4e41-987a-b67dc2c4e8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-aeaa759f-38b5-4043-8a33-175c0a4f0606,DISK], DatanodeInfoWithStorage[127.0.0.1:36099,DS-391a7ec9-de2d-4a55-b7af-d17233f45b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42703,DS-d4bb9a69-70d6-4d47-9469-a000b284abb6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-542448665-172.17.0.10-1595888896755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37074,DS-301c36e7-d188-4962-882e-2fe818fd5640,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-06ca4352-1756-4b4e-a964-d909f1a73db6,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-02f171a6-a07f-45bc-9d28-e0087574ff27,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-70a73464-fb36-4f6b-819b-78e3535a6c40,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-8014379e-0b44-4aff-9bb8-7077f6ba8b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-20ddbd5a-fb17-455d-939d-51f99e7e9a07,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-fcda94e1-1a9d-4c5e-84fc-d4357c5c193d,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-5c1c14ad-8093-47ef-ab32-20a40ab5f017,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-542448665-172.17.0.10-1595888896755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37074,DS-301c36e7-d188-4962-882e-2fe818fd5640,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-06ca4352-1756-4b4e-a964-d909f1a73db6,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-02f171a6-a07f-45bc-9d28-e0087574ff27,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-70a73464-fb36-4f6b-819b-78e3535a6c40,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-8014379e-0b44-4aff-9bb8-7077f6ba8b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-20ddbd5a-fb17-455d-939d-51f99e7e9a07,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-fcda94e1-1a9d-4c5e-84fc-d4357c5c193d,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-5c1c14ad-8093-47ef-ab32-20a40ab5f017,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-394140850-172.17.0.10-1595889042531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33383,DS-f71d3ab9-90c0-4061-b30d-f99e8c31e75c,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-dc4305df-9dfc-4b18-9f8c-4e42fe665b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-e37efff6-639b-43ed-ba7c-841d02105951,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-863c61b8-d033-4cb8-bd4b-b93221090b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-c2445faf-af14-4d18-92e7-6ee0fc299efc,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-623f3bc0-cc68-401b-92da-bfc756935e82,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-4988bd08-9c7c-4f05-a483-dcb10a3381a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-5d91a94b-25eb-43d1-8d86-fdb8f612ed25,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-394140850-172.17.0.10-1595889042531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33383,DS-f71d3ab9-90c0-4061-b30d-f99e8c31e75c,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-dc4305df-9dfc-4b18-9f8c-4e42fe665b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-e37efff6-639b-43ed-ba7c-841d02105951,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-863c61b8-d033-4cb8-bd4b-b93221090b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-c2445faf-af14-4d18-92e7-6ee0fc299efc,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-623f3bc0-cc68-401b-92da-bfc756935e82,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-4988bd08-9c7c-4f05-a483-dcb10a3381a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-5d91a94b-25eb-43d1-8d86-fdb8f612ed25,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-388832165-172.17.0.10-1595889271822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41542,DS-26e19310-17cc-43b0-83ac-312be50e0d41,DISK], DatanodeInfoWithStorage[127.0.0.1:38318,DS-5aa43166-1483-4966-b7d9-a51d3c415b97,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-65ae2668-b667-4736-a2ce-63bc63eb6d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45072,DS-13ba56df-5092-412e-a95b-6b839c88ab55,DISK], DatanodeInfoWithStorage[127.0.0.1:33573,DS-a27d39ac-5a4a-422f-bf16-0f8c0e272fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-5c22381d-d899-40d4-840d-7cc27d3bf6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-5dc113d0-335d-43c8-a2f2-eebdc394664d,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-06df53e8-d49c-4e37-8ec5-351d048272e4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-388832165-172.17.0.10-1595889271822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41542,DS-26e19310-17cc-43b0-83ac-312be50e0d41,DISK], DatanodeInfoWithStorage[127.0.0.1:38318,DS-5aa43166-1483-4966-b7d9-a51d3c415b97,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-65ae2668-b667-4736-a2ce-63bc63eb6d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45072,DS-13ba56df-5092-412e-a95b-6b839c88ab55,DISK], DatanodeInfoWithStorage[127.0.0.1:33573,DS-a27d39ac-5a4a-422f-bf16-0f8c0e272fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-5c22381d-d899-40d4-840d-7cc27d3bf6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-5dc113d0-335d-43c8-a2f2-eebdc394664d,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-06df53e8-d49c-4e37-8ec5-351d048272e4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1484515463-172.17.0.10-1595889327359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45881,DS-197f1fe1-3908-41c7-90ae-f81822da7ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-bdc1a8e4-c1df-41ef-b6e1-99f136856eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-c07098ee-3acb-4db1-9b49-c503b1239e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-14bd2844-d8ef-4be3-8916-df9900688593,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-f3404ab5-8639-4954-ab8b-223f92da2a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-eed36d9a-456c-468c-9f0a-73cd3e1560e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-ea729ddd-574c-4792-9838-624e8b8289d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-16b35f08-1893-48eb-a5e8-9f0a8c517cad,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1484515463-172.17.0.10-1595889327359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45881,DS-197f1fe1-3908-41c7-90ae-f81822da7ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-bdc1a8e4-c1df-41ef-b6e1-99f136856eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-c07098ee-3acb-4db1-9b49-c503b1239e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-14bd2844-d8ef-4be3-8916-df9900688593,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-f3404ab5-8639-4954-ab8b-223f92da2a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-eed36d9a-456c-468c-9f0a-73cd3e1560e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-ea729ddd-574c-4792-9838-624e8b8289d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-16b35f08-1893-48eb-a5e8-9f0a8c517cad,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1416181466-172.17.0.10-1595889356129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37688,DS-72a1cea8-90d6-4e5f-9b5c-cf96de56adfd,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-8217c610-02f8-4b48-8e8b-bc2678b370e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-9cf7973d-4dd4-477b-9db0-7173799cea56,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-deb671aa-ac83-48e4-a5b4-a61db2b28ace,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-eadc248d-2864-45eb-9d32-d2943b1763ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-b2ec527c-46f2-49e9-b26a-741886ac488d,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-3d374335-77d0-45d4-b0bc-a7f18a9ee797,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-65c02a0b-3fcd-4468-a453-4ac2e495c734,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1416181466-172.17.0.10-1595889356129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37688,DS-72a1cea8-90d6-4e5f-9b5c-cf96de56adfd,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-8217c610-02f8-4b48-8e8b-bc2678b370e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-9cf7973d-4dd4-477b-9db0-7173799cea56,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-deb671aa-ac83-48e4-a5b4-a61db2b28ace,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-eadc248d-2864-45eb-9d32-d2943b1763ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-b2ec527c-46f2-49e9-b26a-741886ac488d,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-3d374335-77d0-45d4-b0bc-a7f18a9ee797,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-65c02a0b-3fcd-4468-a453-4ac2e495c734,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1471035435-172.17.0.10-1595889443774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34108,DS-9626fd50-3169-48fb-9829-a58db2c8560c,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-e025013f-1d8f-43a1-95be-2ca0a718af5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-7b8e5a5d-acc1-4965-b276-9a11844fca7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-7e5f55eb-e61b-4393-b454-7c7d5b276443,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-6c63afb5-a28a-476a-8b86-5ec12626dc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-048f40ac-e7d0-487a-88b5-319d14c2d9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-73671355-6859-4811-8b40-e2e0c50febb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-0b6af59d-474d-4c8f-b061-4bccd5ab32b0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1471035435-172.17.0.10-1595889443774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34108,DS-9626fd50-3169-48fb-9829-a58db2c8560c,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-e025013f-1d8f-43a1-95be-2ca0a718af5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-7b8e5a5d-acc1-4965-b276-9a11844fca7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-7e5f55eb-e61b-4393-b454-7c7d5b276443,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-6c63afb5-a28a-476a-8b86-5ec12626dc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-048f40ac-e7d0-487a-88b5-319d14c2d9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-73671355-6859-4811-8b40-e2e0c50febb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-0b6af59d-474d-4c8f-b061-4bccd5ab32b0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-605043486-172.17.0.10-1595889513333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43247,DS-88da2edb-904f-4b44-a2eb-e87feff99b11,DISK], DatanodeInfoWithStorage[127.0.0.1:41473,DS-2631587e-88d2-42dd-b861-3eab29e6b2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-3e5c2f1a-9bb1-44ed-b81c-18a55768fb84,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-373ea0c3-5ac2-4502-a6af-804b9a2c1fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-6482ae3c-4240-4a5e-917f-c1b39c0af651,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-5c89f3a5-2d3b-4fb7-a68b-dae494bbdf85,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-cb24b828-cc50-465a-8e3f-4e4896511150,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-f0eaee0f-7841-455b-9a75-7929fe65c588,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-605043486-172.17.0.10-1595889513333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43247,DS-88da2edb-904f-4b44-a2eb-e87feff99b11,DISK], DatanodeInfoWithStorage[127.0.0.1:41473,DS-2631587e-88d2-42dd-b861-3eab29e6b2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-3e5c2f1a-9bb1-44ed-b81c-18a55768fb84,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-373ea0c3-5ac2-4502-a6af-804b9a2c1fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-6482ae3c-4240-4a5e-917f-c1b39c0af651,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-5c89f3a5-2d3b-4fb7-a68b-dae494bbdf85,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-cb24b828-cc50-465a-8e3f-4e4896511150,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-f0eaee0f-7841-455b-9a75-7929fe65c588,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-374301939-172.17.0.10-1595889691970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35160,DS-03aaa9c0-7241-4419-ba72-cf15f4ab4ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:41139,DS-f3350748-1511-4385-bb9d-6adf3339ad2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-dbce88b7-f2e8-4d94-8540-c8f6bfd6bdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-1ec5af59-2598-48b9-bbcc-19425fdb0f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-84dfa731-a8a7-46e0-8a35-d95e4117897f,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-c9a6fb11-b511-4828-aa66-3db1e5aef340,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-f851a58d-2bab-4ecc-b185-488906173f65,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-6068114e-42ec-4a88-b8ee-85f00a4d65ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-374301939-172.17.0.10-1595889691970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35160,DS-03aaa9c0-7241-4419-ba72-cf15f4ab4ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:41139,DS-f3350748-1511-4385-bb9d-6adf3339ad2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-dbce88b7-f2e8-4d94-8540-c8f6bfd6bdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-1ec5af59-2598-48b9-bbcc-19425fdb0f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-84dfa731-a8a7-46e0-8a35-d95e4117897f,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-c9a6fb11-b511-4828-aa66-3db1e5aef340,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-f851a58d-2bab-4ecc-b185-488906173f65,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-6068114e-42ec-4a88-b8ee-85f00a4d65ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-157443873-172.17.0.10-1595889770746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38864,DS-b1d4073d-c9ec-450e-8e8e-7bc35e8c75f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-43f2e4bd-28dc-44bc-92d3-80f210a562e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-f1b0ed6c-601e-4c09-abae-eefdfe04fb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-2d4ff750-56cd-47a2-818a-521b9085bc34,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-43eb6927-7b1c-4342-ac0e-8b0dbce88164,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-24b82da2-6d08-4223-8ba2-74798a9f12ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-a2cbfb85-5773-4be3-8c7e-5868034e13de,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-ec07d87f-19e6-4819-aa70-d24f9b9072ee,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-157443873-172.17.0.10-1595889770746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38864,DS-b1d4073d-c9ec-450e-8e8e-7bc35e8c75f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-43f2e4bd-28dc-44bc-92d3-80f210a562e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-f1b0ed6c-601e-4c09-abae-eefdfe04fb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-2d4ff750-56cd-47a2-818a-521b9085bc34,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-43eb6927-7b1c-4342-ac0e-8b0dbce88164,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-24b82da2-6d08-4223-8ba2-74798a9f12ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-a2cbfb85-5773-4be3-8c7e-5868034e13de,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-ec07d87f-19e6-4819-aa70-d24f9b9072ee,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1059956695-172.17.0.10-1595889799831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33579,DS-beb7903f-fea1-4059-9ffb-5fe1e8529db4,DISK], DatanodeInfoWithStorage[127.0.0.1:38044,DS-42a7a55a-de49-431e-bf78-48ccedb0d4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41416,DS-60e7f5dc-b445-42c5-a035-cb6a1159bea1,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-df029390-b11a-4a7a-b76f-971f04c61e46,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-c17dd520-1c7e-46d0-96ea-5303a41184b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-3bfb6060-5e1d-4312-afed-25795117ea5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-b271c0d8-a241-40fa-8400-5f38bc21c1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-d9ff8fe4-d3a8-4874-8758-2fc8a173407d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1059956695-172.17.0.10-1595889799831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33579,DS-beb7903f-fea1-4059-9ffb-5fe1e8529db4,DISK], DatanodeInfoWithStorage[127.0.0.1:38044,DS-42a7a55a-de49-431e-bf78-48ccedb0d4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41416,DS-60e7f5dc-b445-42c5-a035-cb6a1159bea1,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-df029390-b11a-4a7a-b76f-971f04c61e46,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-c17dd520-1c7e-46d0-96ea-5303a41184b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-3bfb6060-5e1d-4312-afed-25795117ea5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-b271c0d8-a241-40fa-8400-5f38bc21c1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-d9ff8fe4-d3a8-4874-8758-2fc8a173407d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1978705976-172.17.0.10-1595890127711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38711,DS-c1a26ab5-a812-444b-8f48-dceef2d21f48,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-714b294c-8d3f-4d91-be61-34ea5e3183c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-7eeb466e-f6ae-4264-a956-19a8356191f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-a7ffb5c3-f388-40bb-aa0a-de3acf5a95fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33243,DS-7edd8101-2dde-4b76-98ec-357177b2252e,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-806b68c8-79a7-4660-90f2-fad8cf730b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-3740b066-aa82-4452-ae3e-bd4b1954dc7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-b2d06127-2b19-4a90-9ae6-e54c806a4dd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1978705976-172.17.0.10-1595890127711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38711,DS-c1a26ab5-a812-444b-8f48-dceef2d21f48,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-714b294c-8d3f-4d91-be61-34ea5e3183c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-7eeb466e-f6ae-4264-a956-19a8356191f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-a7ffb5c3-f388-40bb-aa0a-de3acf5a95fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33243,DS-7edd8101-2dde-4b76-98ec-357177b2252e,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-806b68c8-79a7-4660-90f2-fad8cf730b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-3740b066-aa82-4452-ae3e-bd4b1954dc7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-b2d06127-2b19-4a90-9ae6-e54c806a4dd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2141120830-172.17.0.10-1595890258741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46453,DS-2e6b3800-0a06-4c4e-8e0f-21c2f3ac247a,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-5d40df2d-edac-452b-97fb-be0c894f7954,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-6868cb0d-571c-4f84-93a4-d199f644aca6,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-58ce2fee-717e-4ae8-90bb-35511656a7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-ad87e64a-42ed-4925-8121-db3bd39c2b19,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-61e0a4d8-2a2a-4a7a-9be1-b6a0b8375171,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-47b4962c-7301-4f4b-b5d5-2bed038d456f,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-82a2ae94-6139-4976-832b-06a56985bdb4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2141120830-172.17.0.10-1595890258741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46453,DS-2e6b3800-0a06-4c4e-8e0f-21c2f3ac247a,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-5d40df2d-edac-452b-97fb-be0c894f7954,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-6868cb0d-571c-4f84-93a4-d199f644aca6,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-58ce2fee-717e-4ae8-90bb-35511656a7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-ad87e64a-42ed-4925-8121-db3bd39c2b19,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-61e0a4d8-2a2a-4a7a-9be1-b6a0b8375171,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-47b4962c-7301-4f4b-b5d5-2bed038d456f,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-82a2ae94-6139-4976-832b-06a56985bdb4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1289194585-172.17.0.10-1595890333148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41722,DS-41584c31-b747-4390-a8e6-2c6d74fec89c,DISK], DatanodeInfoWithStorage[127.0.0.1:40884,DS-b561f041-0e9d-4bd2-a6a9-9007e3be5076,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-44ff828e-a406-48ce-bcb0-c3f368136b13,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-e10fc638-046b-4599-a660-57dac68adff4,DISK], DatanodeInfoWithStorage[127.0.0.1:42283,DS-3558853c-963c-438c-ab82-0128ef90252c,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-d987be05-f71a-47a7-9aee-4f50cc152ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-005a397c-0c40-4cbc-8bc5-c1a3b2ea1c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-0b4e50ab-1bc0-4fcd-89e7-0a520a3812c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1289194585-172.17.0.10-1595890333148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41722,DS-41584c31-b747-4390-a8e6-2c6d74fec89c,DISK], DatanodeInfoWithStorage[127.0.0.1:40884,DS-b561f041-0e9d-4bd2-a6a9-9007e3be5076,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-44ff828e-a406-48ce-bcb0-c3f368136b13,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-e10fc638-046b-4599-a660-57dac68adff4,DISK], DatanodeInfoWithStorage[127.0.0.1:42283,DS-3558853c-963c-438c-ab82-0128ef90252c,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-d987be05-f71a-47a7-9aee-4f50cc152ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-005a397c-0c40-4cbc-8bc5-c1a3b2ea1c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-0b4e50ab-1bc0-4fcd-89e7-0a520a3812c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2023308575-172.17.0.10-1595890501540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38804,DS-78461b97-8cca-43d8-a074-38a473ea8270,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-fdca4213-0e8a-4cbc-8c80-d39f35a139a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38659,DS-9bec6dd8-5bf6-4922-803f-9d11be1a4d92,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-d41d9a0e-2c08-463c-b5b4-135c9d4aa2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-45fb161b-d261-495d-b901-e2b848192537,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-6d7dec74-7898-44e7-a1ce-bc9272f0ea36,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-94fd77cb-4ff1-466f-b560-40f3757ea18f,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-994ce842-4a78-4e10-a131-e1db1ffb9d48,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2023308575-172.17.0.10-1595890501540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38804,DS-78461b97-8cca-43d8-a074-38a473ea8270,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-fdca4213-0e8a-4cbc-8c80-d39f35a139a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38659,DS-9bec6dd8-5bf6-4922-803f-9d11be1a4d92,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-d41d9a0e-2c08-463c-b5b4-135c9d4aa2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-45fb161b-d261-495d-b901-e2b848192537,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-6d7dec74-7898-44e7-a1ce-bc9272f0ea36,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-94fd77cb-4ff1-466f-b560-40f3757ea18f,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-994ce842-4a78-4e10-a131-e1db1ffb9d48,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-67492731-172.17.0.10-1595890603314:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35788,DS-3db70b2a-96bc-4191-b503-8f51910bce83,DISK], DatanodeInfoWithStorage[127.0.0.1:42903,DS-2506c7d6-b72b-45f2-a084-15adc5c56486,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-56b690a9-f6b8-4813-a69f-fece5f35fd44,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-87b36e58-c8fe-4142-acf4-c0b7935ee8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-b48721ab-4e0c-4a8f-aa81-55ee100486cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36527,DS-55124db7-930c-4a75-b3b3-6d6496176634,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-ef03ff7f-9a4f-4a71-97e4-e2f6adfafc13,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-24fac2c6-8de7-42a2-afc1-a3a4f236f958,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-67492731-172.17.0.10-1595890603314:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35788,DS-3db70b2a-96bc-4191-b503-8f51910bce83,DISK], DatanodeInfoWithStorage[127.0.0.1:42903,DS-2506c7d6-b72b-45f2-a084-15adc5c56486,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-56b690a9-f6b8-4813-a69f-fece5f35fd44,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-87b36e58-c8fe-4142-acf4-c0b7935ee8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-b48721ab-4e0c-4a8f-aa81-55ee100486cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36527,DS-55124db7-930c-4a75-b3b3-6d6496176634,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-ef03ff7f-9a4f-4a71-97e4-e2f6adfafc13,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-24fac2c6-8de7-42a2-afc1-a3a4f236f958,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-604270307-172.17.0.10-1595891032808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44478,DS-0e76296d-213e-4a17-a3b8-e39eb6352752,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-890b139b-8c02-4dd4-a570-323197f428b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-7e94ed1e-564f-4c09-b013-d0f159328a66,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-e63c5e7f-81cb-4ef4-a84e-4b0945b756a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43370,DS-8f86b617-b3cb-479f-b870-6d1ea4c2e704,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-53d8485a-e763-4e76-8be1-66bd8b42a11a,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-27deba36-4c90-4ac7-9c03-fb6b6bae6b77,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-de9b8fb1-7992-47dc-9ad1-98b5fd79a2ba,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-604270307-172.17.0.10-1595891032808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44478,DS-0e76296d-213e-4a17-a3b8-e39eb6352752,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-890b139b-8c02-4dd4-a570-323197f428b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-7e94ed1e-564f-4c09-b013-d0f159328a66,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-e63c5e7f-81cb-4ef4-a84e-4b0945b756a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43370,DS-8f86b617-b3cb-479f-b870-6d1ea4c2e704,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-53d8485a-e763-4e76-8be1-66bd8b42a11a,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-27deba36-4c90-4ac7-9c03-fb6b6bae6b77,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-de9b8fb1-7992-47dc-9ad1-98b5fd79a2ba,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1456028428-172.17.0.10-1595891133984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37236,DS-b2dfdef6-6d43-451f-8636-5913abd75b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-f2000848-839c-4226-bdcd-5b862cea62ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-5b04cf3c-d17b-4954-8234-d7beb5da7144,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-b627a09d-8264-4386-bce3-ff1b3e0ce5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37350,DS-0e88ae87-b10a-4b66-8550-329fd4588e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45643,DS-acf269e2-f257-4d12-8396-e05d6ebe49cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-2eda0f74-ab47-4136-b74f-24cd9fa0feef,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-f68b152e-f3ad-4769-beb7-1e7cc8eeca3d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1456028428-172.17.0.10-1595891133984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37236,DS-b2dfdef6-6d43-451f-8636-5913abd75b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-f2000848-839c-4226-bdcd-5b862cea62ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-5b04cf3c-d17b-4954-8234-d7beb5da7144,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-b627a09d-8264-4386-bce3-ff1b3e0ce5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37350,DS-0e88ae87-b10a-4b66-8550-329fd4588e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45643,DS-acf269e2-f257-4d12-8396-e05d6ebe49cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-2eda0f74-ab47-4136-b74f-24cd9fa0feef,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-f68b152e-f3ad-4769-beb7-1e7cc8eeca3d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1056807944-172.17.0.10-1595891272371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34165,DS-ab0bd200-16c1-49d5-94c1-011d4767c6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-20b700ce-b91e-47c1-8bed-67b3cc1abf94,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-aa174d67-c98e-4365-bc23-f44dccb6363a,DISK], DatanodeInfoWithStorage[127.0.0.1:43213,DS-aecc05f0-36d4-4878-a9b4-a8d231b35294,DISK], DatanodeInfoWithStorage[127.0.0.1:44419,DS-c21eeb01-417b-421f-b78e-04e8dec5b3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-b63c18e0-7a30-4d24-9681-fb222ab0f717,DISK], DatanodeInfoWithStorage[127.0.0.1:40405,DS-57e819bd-cd21-4797-9fd1-3d777ce18335,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-056c9f22-39ea-447a-a5b6-a5a44f4831bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1056807944-172.17.0.10-1595891272371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34165,DS-ab0bd200-16c1-49d5-94c1-011d4767c6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-20b700ce-b91e-47c1-8bed-67b3cc1abf94,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-aa174d67-c98e-4365-bc23-f44dccb6363a,DISK], DatanodeInfoWithStorage[127.0.0.1:43213,DS-aecc05f0-36d4-4878-a9b4-a8d231b35294,DISK], DatanodeInfoWithStorage[127.0.0.1:44419,DS-c21eeb01-417b-421f-b78e-04e8dec5b3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-b63c18e0-7a30-4d24-9681-fb222ab0f717,DISK], DatanodeInfoWithStorage[127.0.0.1:40405,DS-57e819bd-cd21-4797-9fd1-3d777ce18335,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-056c9f22-39ea-447a-a5b6-a5a44f4831bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-34423335-172.17.0.10-1595891372206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42162,DS-8e2e41b3-1fb6-4b39-a9a4-594542c2dd9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-1e2f8e74-1b02-423a-87d8-8527f484db15,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-84de1d49-21c7-416e-8180-c6588d21773a,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-4828f169-583b-44e7-9671-75828dea1a97,DISK], DatanodeInfoWithStorage[127.0.0.1:41862,DS-6fcd7897-aec7-4d9c-bfcb-9139784d3c29,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-613d55a2-6f3e-47c8-8027-afa30e5422fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-5880d7e4-9ada-4a11-aaf2-ac23fe4ddcc0,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-6d7e2424-93b5-4d41-975b-e970add05751,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-34423335-172.17.0.10-1595891372206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42162,DS-8e2e41b3-1fb6-4b39-a9a4-594542c2dd9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-1e2f8e74-1b02-423a-87d8-8527f484db15,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-84de1d49-21c7-416e-8180-c6588d21773a,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-4828f169-583b-44e7-9671-75828dea1a97,DISK], DatanodeInfoWithStorage[127.0.0.1:41862,DS-6fcd7897-aec7-4d9c-bfcb-9139784d3c29,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-613d55a2-6f3e-47c8-8027-afa30e5422fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-5880d7e4-9ada-4a11-aaf2-ac23fe4ddcc0,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-6d7e2424-93b5-4d41-975b-e970add05751,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2136891009-172.17.0.10-1595891403063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45264,DS-84e51259-7061-440d-9e3b-f0652ead2565,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-0493b8a6-a730-4edc-a9ed-8ac21e086d10,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-1c7b2bdb-5acc-4685-a80a-009fd2f77380,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-c9c64907-1c7a-4f3b-abea-773c31ee8938,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-1d196f8e-db24-4831-9679-ae4207b07cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38677,DS-c4d33478-4ed8-4f25-ad48-4fb3aae29b50,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-efa41c52-1131-4ae8-b23f-d4fef4f0d344,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-77bb608c-740f-46a7-b9d0-ee920a1a19ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2136891009-172.17.0.10-1595891403063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45264,DS-84e51259-7061-440d-9e3b-f0652ead2565,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-0493b8a6-a730-4edc-a9ed-8ac21e086d10,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-1c7b2bdb-5acc-4685-a80a-009fd2f77380,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-c9c64907-1c7a-4f3b-abea-773c31ee8938,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-1d196f8e-db24-4831-9679-ae4207b07cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38677,DS-c4d33478-4ed8-4f25-ad48-4fb3aae29b50,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-efa41c52-1131-4ae8-b23f-d4fef4f0d344,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-77bb608c-740f-46a7-b9d0-ee920a1a19ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2075555086-172.17.0.10-1595891466267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44479,DS-28b533b2-50a6-4924-a1b7-3d4901ae251f,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-62621df1-3228-48f6-92e5-89816a956b89,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-bba2939b-015e-4706-8a2c-0df5ade95393,DISK], DatanodeInfoWithStorage[127.0.0.1:38041,DS-40d50cec-1d96-4b18-9084-875c4b98dfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38456,DS-12eefc1e-d780-424b-8b30-a13c845e1f68,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-50fe87fb-d480-40b7-9e97-b53e2816c85b,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-c719c0b0-c875-4776-a53e-345cef0c24e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-9d51fa53-22e5-4b53-acdc-770b4b941129,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2075555086-172.17.0.10-1595891466267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44479,DS-28b533b2-50a6-4924-a1b7-3d4901ae251f,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-62621df1-3228-48f6-92e5-89816a956b89,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-bba2939b-015e-4706-8a2c-0df5ade95393,DISK], DatanodeInfoWithStorage[127.0.0.1:38041,DS-40d50cec-1d96-4b18-9084-875c4b98dfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38456,DS-12eefc1e-d780-424b-8b30-a13c845e1f68,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-50fe87fb-d480-40b7-9e97-b53e2816c85b,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-c719c0b0-c875-4776-a53e-345cef0c24e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-9d51fa53-22e5-4b53-acdc-770b4b941129,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1805370281-172.17.0.10-1595891680632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43123,DS-bf523e3f-d3df-4fcb-a752-c30228935f66,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-2a6c6484-e893-42b4-b3bc-68b191b9aed7,DISK], DatanodeInfoWithStorage[127.0.0.1:39818,DS-206d4450-afdb-4c87-8e62-75dc4cb30524,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-a926f226-ae4d-4535-be20-6bed0fdb5023,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-5c2f3c80-eb37-455e-bb93-eefe5c7a130d,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-bd8efa94-5ac0-4b35-8551-6387339fb087,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-bc8d2dda-8663-4c11-83fc-6335f42df456,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-a9f0b907-b0f8-4e50-9d82-0399567c73de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1805370281-172.17.0.10-1595891680632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43123,DS-bf523e3f-d3df-4fcb-a752-c30228935f66,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-2a6c6484-e893-42b4-b3bc-68b191b9aed7,DISK], DatanodeInfoWithStorage[127.0.0.1:39818,DS-206d4450-afdb-4c87-8e62-75dc4cb30524,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-a926f226-ae4d-4535-be20-6bed0fdb5023,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-5c2f3c80-eb37-455e-bb93-eefe5c7a130d,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-bd8efa94-5ac0-4b35-8551-6387339fb087,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-bc8d2dda-8663-4c11-83fc-6335f42df456,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-a9f0b907-b0f8-4e50-9d82-0399567c73de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-754522430-172.17.0.10-1595891714615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45666,DS-b2467477-ca72-482a-98f1-62fdc96f3fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35714,DS-5badb911-5d37-4cc6-8e86-52c22f30439c,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-d4e120de-48fb-4dd3-a6d4-9d0e2bb118ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-5cf268f7-1efd-4db9-bf67-f2b0a34fd28e,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-50704b04-2a7e-44cd-9122-39a3310b3995,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-2dbef1dc-94c7-4606-bf6a-60e27c2f969b,DISK], DatanodeInfoWithStorage[127.0.0.1:46870,DS-59684a25-bfc2-4b27-acff-935d2ee4c7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-ab6c5d89-57d4-4f03-82fa-54072a7c8875,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-754522430-172.17.0.10-1595891714615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45666,DS-b2467477-ca72-482a-98f1-62fdc96f3fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35714,DS-5badb911-5d37-4cc6-8e86-52c22f30439c,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-d4e120de-48fb-4dd3-a6d4-9d0e2bb118ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-5cf268f7-1efd-4db9-bf67-f2b0a34fd28e,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-50704b04-2a7e-44cd-9122-39a3310b3995,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-2dbef1dc-94c7-4606-bf6a-60e27c2f969b,DISK], DatanodeInfoWithStorage[127.0.0.1:46870,DS-59684a25-bfc2-4b27-acff-935d2ee4c7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-ab6c5d89-57d4-4f03-82fa-54072a7c8875,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267457232-172.17.0.10-1595891757199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45342,DS-59d931e5-7afc-42ba-a13a-4d9da012c556,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-f98c3406-e255-42ce-9df6-e667352d8433,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-dcebd5ad-5814-4780-b7b8-2583402ffa2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-ded9eda6-fa3c-4ae8-8dbb-b7b139f98d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-1c178d68-e48d-48b1-b5cd-05d6e32636a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38983,DS-e3ccffe2-7661-4680-91d8-8113d230aa31,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-270a3515-99ca-4f5a-aeec-dd26e2c10188,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-7afb01e2-219c-4596-9343-d15741619d77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267457232-172.17.0.10-1595891757199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45342,DS-59d931e5-7afc-42ba-a13a-4d9da012c556,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-f98c3406-e255-42ce-9df6-e667352d8433,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-dcebd5ad-5814-4780-b7b8-2583402ffa2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-ded9eda6-fa3c-4ae8-8dbb-b7b139f98d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-1c178d68-e48d-48b1-b5cd-05d6e32636a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38983,DS-e3ccffe2-7661-4680-91d8-8113d230aa31,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-270a3515-99ca-4f5a-aeec-dd26e2c10188,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-7afb01e2-219c-4596-9343-d15741619d77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-634757857-172.17.0.10-1595891961382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40813,DS-c6528307-a78d-4526-9efa-d4cb7183ea78,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-4bb0f25d-eedf-4705-a672-72be4730ec3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-5ae09cb2-6196-4da1-9707-86d4434404b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-77235751-34c6-4017-90cd-d69290f2d451,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-f0883327-0903-49af-ac3b-26a2c9f4c147,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-b9642fb1-71da-4d8a-bf4d-8cb6ef33be77,DISK], DatanodeInfoWithStorage[127.0.0.1:40841,DS-b53fcc73-893c-4534-b462-b7d60fe1de50,DISK], DatanodeInfoWithStorage[127.0.0.1:37901,DS-c70e3ce7-0065-4345-94dd-d75499a1deec,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-634757857-172.17.0.10-1595891961382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40813,DS-c6528307-a78d-4526-9efa-d4cb7183ea78,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-4bb0f25d-eedf-4705-a672-72be4730ec3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-5ae09cb2-6196-4da1-9707-86d4434404b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-77235751-34c6-4017-90cd-d69290f2d451,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-f0883327-0903-49af-ac3b-26a2c9f4c147,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-b9642fb1-71da-4d8a-bf4d-8cb6ef33be77,DISK], DatanodeInfoWithStorage[127.0.0.1:40841,DS-b53fcc73-893c-4534-b462-b7d60fe1de50,DISK], DatanodeInfoWithStorage[127.0.0.1:37901,DS-c70e3ce7-0065-4345-94dd-d75499a1deec,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-398803943-172.17.0.10-1595892028594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43694,DS-42547179-2883-4126-a501-3fede20c6e29,DISK], DatanodeInfoWithStorage[127.0.0.1:43020,DS-d3bb2856-16a9-4714-9bfc-a0ff4ed99271,DISK], DatanodeInfoWithStorage[127.0.0.1:44227,DS-640ab6f5-e0b0-4c9e-a189-d56a5659f91b,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-a38072af-05ae-49fe-ae7e-f3469711387d,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-0dd4478c-94b0-4d9f-bae2-f63c30128725,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-e4d252b8-4d5d-4790-abac-52af415410a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38862,DS-44fa0c58-c052-4f5f-b3a0-a07889f96a60,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-9c840dd5-b23a-4fd9-9134-6a73de023002,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-398803943-172.17.0.10-1595892028594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43694,DS-42547179-2883-4126-a501-3fede20c6e29,DISK], DatanodeInfoWithStorage[127.0.0.1:43020,DS-d3bb2856-16a9-4714-9bfc-a0ff4ed99271,DISK], DatanodeInfoWithStorage[127.0.0.1:44227,DS-640ab6f5-e0b0-4c9e-a189-d56a5659f91b,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-a38072af-05ae-49fe-ae7e-f3469711387d,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-0dd4478c-94b0-4d9f-bae2-f63c30128725,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-e4d252b8-4d5d-4790-abac-52af415410a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38862,DS-44fa0c58-c052-4f5f-b3a0-a07889f96a60,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-9c840dd5-b23a-4fd9-9134-6a73de023002,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2039223333-172.17.0.10-1595892099088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37223,DS-9444a5e5-99b9-45e8-8d80-11dcf7a09404,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-b8ecfe62-4aa3-4055-8cd8-e4d428893de0,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-b720229b-6555-445f-a824-c3ec53380887,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-ce1f8d72-43b4-42d2-bcc7-8ea44111ee5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38180,DS-3f9bee9f-5e01-47e0-a080-559299bbeaff,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-70cfc299-2127-4a88-95b9-6d9f6bef204c,DISK], DatanodeInfoWithStorage[127.0.0.1:45837,DS-0f856b99-7f29-442c-9503-53ea17732cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-bd24a5f7-707a-4684-990e-933d569b489c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2039223333-172.17.0.10-1595892099088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37223,DS-9444a5e5-99b9-45e8-8d80-11dcf7a09404,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-b8ecfe62-4aa3-4055-8cd8-e4d428893de0,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-b720229b-6555-445f-a824-c3ec53380887,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-ce1f8d72-43b4-42d2-bcc7-8ea44111ee5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38180,DS-3f9bee9f-5e01-47e0-a080-559299bbeaff,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-70cfc299-2127-4a88-95b9-6d9f6bef204c,DISK], DatanodeInfoWithStorage[127.0.0.1:45837,DS-0f856b99-7f29-442c-9503-53ea17732cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-bd24a5f7-707a-4684-990e-933d569b489c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2113991799-172.17.0.10-1595892124653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46827,DS-11a783a1-c9dc-42a1-972a-80371e626320,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-5a6104d0-935b-47aa-8d4f-7faef245af42,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-c433a785-38a4-4659-ba8a-9ad650eeacbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-b577b5db-d08a-4654-8ae6-26fd9fd09a90,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-3a331cd3-75eb-4a6f-a1e1-7198cbcd3a37,DISK], DatanodeInfoWithStorage[127.0.0.1:44956,DS-1b6c484b-a972-40fb-a536-1d343504e597,DISK], DatanodeInfoWithStorage[127.0.0.1:41033,DS-62fa1d80-36ab-42be-aea4-412558977dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-4ec911c1-7a55-4e06-8440-9cb0603fd6f2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2113991799-172.17.0.10-1595892124653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46827,DS-11a783a1-c9dc-42a1-972a-80371e626320,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-5a6104d0-935b-47aa-8d4f-7faef245af42,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-c433a785-38a4-4659-ba8a-9ad650eeacbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-b577b5db-d08a-4654-8ae6-26fd9fd09a90,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-3a331cd3-75eb-4a6f-a1e1-7198cbcd3a37,DISK], DatanodeInfoWithStorage[127.0.0.1:44956,DS-1b6c484b-a972-40fb-a536-1d343504e597,DISK], DatanodeInfoWithStorage[127.0.0.1:41033,DS-62fa1d80-36ab-42be-aea4-412558977dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-4ec911c1-7a55-4e06-8440-9cb0603fd6f2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1318958774-172.17.0.10-1595892638488:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44942,DS-388357f0-bca5-4d57-9614-e713701d5dad,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-52046b8c-88e8-47a8-b0c2-fb1751116cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-827a591f-dcdf-49ef-9a31-6559033546f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-6d98814d-2e8a-4041-bc8d-764af0ebbc41,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-f9846082-ea3d-4475-ae8f-ddbab131c2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-e4ea33ae-9922-47e7-9928-bd5f16a4615c,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-8603d3c7-31bb-4208-abb5-06d91c2f585f,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-3f186611-6555-4bd4-a84d-a25ffb059c05,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1318958774-172.17.0.10-1595892638488:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44942,DS-388357f0-bca5-4d57-9614-e713701d5dad,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-52046b8c-88e8-47a8-b0c2-fb1751116cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-827a591f-dcdf-49ef-9a31-6559033546f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-6d98814d-2e8a-4041-bc8d-764af0ebbc41,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-f9846082-ea3d-4475-ae8f-ddbab131c2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-e4ea33ae-9922-47e7-9928-bd5f16a4615c,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-8603d3c7-31bb-4208-abb5-06d91c2f585f,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-3f186611-6555-4bd4-a84d-a25ffb059c05,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1037427024-172.17.0.10-1595892846586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41280,DS-61310c6c-7b56-4865-8cdf-4737df2d5efb,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-38acadd7-54c2-4ad7-b9ec-81f9cffffacf,DISK], DatanodeInfoWithStorage[127.0.0.1:33725,DS-6eb04030-2955-40b1-9964-028c58337e68,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-b03d5df5-db3b-4298-a302-607a56d8b590,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-bc100f8d-b508-4cb2-9fc8-425a2cc26c30,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-d7922bee-3ebd-45d7-bc96-99a06ec55b10,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-5422b358-5435-41f2-b8b1-ee135c666f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-e223ea8a-7cdb-4e43-94a3-5d4a72d2501a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1037427024-172.17.0.10-1595892846586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41280,DS-61310c6c-7b56-4865-8cdf-4737df2d5efb,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-38acadd7-54c2-4ad7-b9ec-81f9cffffacf,DISK], DatanodeInfoWithStorage[127.0.0.1:33725,DS-6eb04030-2955-40b1-9964-028c58337e68,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-b03d5df5-db3b-4298-a302-607a56d8b590,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-bc100f8d-b508-4cb2-9fc8-425a2cc26c30,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-d7922bee-3ebd-45d7-bc96-99a06ec55b10,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-5422b358-5435-41f2-b8b1-ee135c666f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-e223ea8a-7cdb-4e43-94a3-5d4a72d2501a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 21 out of 50
result: false positive !!!
Total execution time in seconds : 4799
