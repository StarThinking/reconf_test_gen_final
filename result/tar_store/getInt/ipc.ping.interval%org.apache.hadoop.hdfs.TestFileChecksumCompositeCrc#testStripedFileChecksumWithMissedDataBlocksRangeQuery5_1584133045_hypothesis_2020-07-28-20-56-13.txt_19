reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1519652340-172.17.0.10-1595970231717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39304,DS-ec7006d4-94fc-4238-aafc-899f3097b4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-ffcd4902-5b0b-4855-be0e-49f1a57ced30,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-f67d5d00-6ebf-4205-bf17-c701fccf7b88,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-1bf9fccb-9944-4522-a463-6acb0e7fa325,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-1d637ef8-ec20-4602-b473-3f69d028977c,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-46411697-c1c8-4a58-abad-d74b217e3e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-1300eb51-8572-4f2a-aea5-fc74c1a84863,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-3f1f976c-84a1-451b-a436-bee93aaa50e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1519652340-172.17.0.10-1595970231717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39304,DS-ec7006d4-94fc-4238-aafc-899f3097b4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-ffcd4902-5b0b-4855-be0e-49f1a57ced30,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-f67d5d00-6ebf-4205-bf17-c701fccf7b88,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-1bf9fccb-9944-4522-a463-6acb0e7fa325,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-1d637ef8-ec20-4602-b473-3f69d028977c,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-46411697-c1c8-4a58-abad-d74b217e3e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-1300eb51-8572-4f2a-aea5-fc74c1a84863,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-3f1f976c-84a1-451b-a436-bee93aaa50e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1318731354-172.17.0.10-1595970403934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39778,DS-2296d302-60d7-4cc5-9b94-b506827fc2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-0d409c47-d837-412d-9a1b-6a5cd402cc93,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-c2743853-f3c5-452a-bd62-c00093a6e037,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-cf9a674f-49ae-4829-a09f-2a514d970787,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-a8dabacd-e0c9-42d9-a3ab-2202b54742d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-569d6696-8d11-40d1-918c-7ca5dfbd4b89,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-0ac7cc34-0740-4f2d-856e-5b0d3b43749f,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-52addd58-c7b4-4dea-b116-dd5b8c6b353c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1318731354-172.17.0.10-1595970403934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39778,DS-2296d302-60d7-4cc5-9b94-b506827fc2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-0d409c47-d837-412d-9a1b-6a5cd402cc93,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-c2743853-f3c5-452a-bd62-c00093a6e037,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-cf9a674f-49ae-4829-a09f-2a514d970787,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-a8dabacd-e0c9-42d9-a3ab-2202b54742d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-569d6696-8d11-40d1-918c-7ca5dfbd4b89,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-0ac7cc34-0740-4f2d-856e-5b0d3b43749f,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-52addd58-c7b4-4dea-b116-dd5b8c6b353c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-976139246-172.17.0.10-1595970451359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39602,DS-81d3ff90-9140-4860-8b81-989c67c437fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-f2a7be9c-df26-4e0d-864f-f34bf11f65af,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-84a57b2e-c1e5-46d4-8daa-bda036f8220f,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-a1bf037f-9e5b-4760-b820-2f9906a0e38b,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-be25ee7e-ffa7-4929-ab11-7b38088effaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-1873ac4a-1f88-4ff3-8b9e-c6f4f9b9ea14,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-1131c81a-1d6a-4f43-9845-fde64a4b731f,DISK], DatanodeInfoWithStorage[127.0.0.1:33648,DS-2c02af81-2bfd-45b2-9260-0dba51402f7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-976139246-172.17.0.10-1595970451359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39602,DS-81d3ff90-9140-4860-8b81-989c67c437fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-f2a7be9c-df26-4e0d-864f-f34bf11f65af,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-84a57b2e-c1e5-46d4-8daa-bda036f8220f,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-a1bf037f-9e5b-4760-b820-2f9906a0e38b,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-be25ee7e-ffa7-4929-ab11-7b38088effaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-1873ac4a-1f88-4ff3-8b9e-c6f4f9b9ea14,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-1131c81a-1d6a-4f43-9845-fde64a4b731f,DISK], DatanodeInfoWithStorage[127.0.0.1:33648,DS-2c02af81-2bfd-45b2-9260-0dba51402f7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-669638374-172.17.0.10-1595970880364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43912,DS-5848151e-e4fe-4d13-accb-d46e0090c60d,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-b71b1252-e7c8-4f76-997e-2754c5c07320,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-a2a2c907-c913-4150-9527-2f6b6ee2a061,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-c50f95d7-d260-47eb-8177-f547be110b75,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-47b8e881-0a84-49d0-a2a2-16e15c006ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-b937e0f9-6019-4ab1-926e-138b6a7a1cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-fcf67926-626f-4c9e-82ed-63e6d47255d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-dd39a274-5c86-4a94-a6e3-916cd93c853a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-669638374-172.17.0.10-1595970880364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43912,DS-5848151e-e4fe-4d13-accb-d46e0090c60d,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-b71b1252-e7c8-4f76-997e-2754c5c07320,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-a2a2c907-c913-4150-9527-2f6b6ee2a061,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-c50f95d7-d260-47eb-8177-f547be110b75,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-47b8e881-0a84-49d0-a2a2-16e15c006ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-b937e0f9-6019-4ab1-926e-138b6a7a1cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-fcf67926-626f-4c9e-82ed-63e6d47255d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-dd39a274-5c86-4a94-a6e3-916cd93c853a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-716940389-172.17.0.10-1595971519294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35056,DS-b0c52ac5-7e3d-4e4e-b79b-a41bb6f6fd17,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-fbc0eee5-28cc-4d53-8728-da558158a5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-f341f869-1ed5-4b8e-a353-b48c5304cde7,DISK], DatanodeInfoWithStorage[127.0.0.1:44440,DS-6313bc0d-c051-4f24-92c0-fc9a2013efa2,DISK], DatanodeInfoWithStorage[127.0.0.1:38824,DS-913b3ef7-dd99-479b-bc83-5716c24e503b,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-5306e8d5-3cb2-472f-b781-5d0709075950,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-9bc5e748-8dbd-4521-ae9f-b5d6e063efac,DISK], DatanodeInfoWithStorage[127.0.0.1:41868,DS-160045f9-594e-4067-a322-f78eda8abeb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-716940389-172.17.0.10-1595971519294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35056,DS-b0c52ac5-7e3d-4e4e-b79b-a41bb6f6fd17,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-fbc0eee5-28cc-4d53-8728-da558158a5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-f341f869-1ed5-4b8e-a353-b48c5304cde7,DISK], DatanodeInfoWithStorage[127.0.0.1:44440,DS-6313bc0d-c051-4f24-92c0-fc9a2013efa2,DISK], DatanodeInfoWithStorage[127.0.0.1:38824,DS-913b3ef7-dd99-479b-bc83-5716c24e503b,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-5306e8d5-3cb2-472f-b781-5d0709075950,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-9bc5e748-8dbd-4521-ae9f-b5d6e063efac,DISK], DatanodeInfoWithStorage[127.0.0.1:41868,DS-160045f9-594e-4067-a322-f78eda8abeb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2142006154-172.17.0.10-1595971559227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38638,DS-6db1952c-a6a6-4ccb-8dec-97fda8d6644e,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-189626f3-b7b4-4ff6-8cac-d6099e2cec3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46449,DS-65304fd8-0d92-4987-bb10-08bf8b9f9efb,DISK], DatanodeInfoWithStorage[127.0.0.1:41410,DS-a638dfc7-b34f-4645-8b46-43681addef09,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-16ba9ce5-649d-4b17-85fd-990315ffb1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46623,DS-af801bb9-ce85-40cf-b810-ed4137488300,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-cd7feac2-2853-4ad1-96a7-f9c302fa0fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-1f240aa9-9c6d-41ee-8573-96ec70bb3585,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2142006154-172.17.0.10-1595971559227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38638,DS-6db1952c-a6a6-4ccb-8dec-97fda8d6644e,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-189626f3-b7b4-4ff6-8cac-d6099e2cec3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46449,DS-65304fd8-0d92-4987-bb10-08bf8b9f9efb,DISK], DatanodeInfoWithStorage[127.0.0.1:41410,DS-a638dfc7-b34f-4645-8b46-43681addef09,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-16ba9ce5-649d-4b17-85fd-990315ffb1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46623,DS-af801bb9-ce85-40cf-b810-ed4137488300,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-cd7feac2-2853-4ad1-96a7-f9c302fa0fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-1f240aa9-9c6d-41ee-8573-96ec70bb3585,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2088035633-172.17.0.10-1595971956340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44967,DS-2eaa8798-4e57-4c2a-855f-eeda7dad16cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-5e02a749-f4d5-4bbc-bdec-4af3c3a4ec72,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-5f64d5fe-20c2-4aee-98f9-2ae6ca94aca0,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-84fbdbd7-52ee-4f64-85c8-8adb5c4bc97e,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-62e4d69e-9260-443a-bbc6-917ea83ad83d,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-fc7bfd93-0b32-490e-9466-97662dd10d80,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-0b7566e4-4593-4f8e-a882-32881f4c6ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-a2afe494-b656-46f6-85ac-45112696fb76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2088035633-172.17.0.10-1595971956340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44967,DS-2eaa8798-4e57-4c2a-855f-eeda7dad16cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-5e02a749-f4d5-4bbc-bdec-4af3c3a4ec72,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-5f64d5fe-20c2-4aee-98f9-2ae6ca94aca0,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-84fbdbd7-52ee-4f64-85c8-8adb5c4bc97e,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-62e4d69e-9260-443a-bbc6-917ea83ad83d,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-fc7bfd93-0b32-490e-9466-97662dd10d80,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-0b7566e4-4593-4f8e-a882-32881f4c6ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-a2afe494-b656-46f6-85ac-45112696fb76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2055386829-172.17.0.10-1595972566892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34631,DS-6a4dbb02-1e19-4371-b1d8-db35eeb064ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-bf2f7d06-1749-4430-ba4e-0e993f12a88e,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-49d3b55e-692a-4aa7-96c2-81fc34881e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-ab2c9455-d45d-4aea-a47f-926fb4ffd8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-cd81884f-223b-46fc-b695-1ef871d220c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-bb1fe27f-8443-4509-b79c-d8545d863a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-fa1b666e-575c-480e-8158-0c419b2b046c,DISK], DatanodeInfoWithStorage[127.0.0.1:44704,DS-3c0cbe95-c206-4c6d-9303-41e6e0b9387d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2055386829-172.17.0.10-1595972566892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34631,DS-6a4dbb02-1e19-4371-b1d8-db35eeb064ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-bf2f7d06-1749-4430-ba4e-0e993f12a88e,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-49d3b55e-692a-4aa7-96c2-81fc34881e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-ab2c9455-d45d-4aea-a47f-926fb4ffd8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-cd81884f-223b-46fc-b695-1ef871d220c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-bb1fe27f-8443-4509-b79c-d8545d863a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-fa1b666e-575c-480e-8158-0c419b2b046c,DISK], DatanodeInfoWithStorage[127.0.0.1:44704,DS-3c0cbe95-c206-4c6d-9303-41e6e0b9387d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1739617424-172.17.0.10-1595972962165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40410,DS-5535f488-10a1-49f8-b311-94079bb1003a,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-0f58e9a5-de7d-4fad-b460-0cff30b794c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-1bc023d4-3b73-4a3e-980f-cc452783a4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-04b26424-a698-47a6-baad-2dacd5cb6f18,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-6787bbdc-eb37-4b69-8d51-100629fee82c,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-4c2bba09-d5f3-4433-80ec-545ba025fd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-84391485-9966-440b-b995-718779625501,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-a4f1b5b0-12cd-41a5-9c57-5433ab8b4423,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1739617424-172.17.0.10-1595972962165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40410,DS-5535f488-10a1-49f8-b311-94079bb1003a,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-0f58e9a5-de7d-4fad-b460-0cff30b794c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-1bc023d4-3b73-4a3e-980f-cc452783a4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-04b26424-a698-47a6-baad-2dacd5cb6f18,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-6787bbdc-eb37-4b69-8d51-100629fee82c,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-4c2bba09-d5f3-4433-80ec-545ba025fd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-84391485-9966-440b-b995-718779625501,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-a4f1b5b0-12cd-41a5-9c57-5433ab8b4423,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-488788003-172.17.0.10-1595973655578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36715,DS-68c404de-62fe-4ff2-8720-b9144015d564,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-d8e92bbf-6868-461f-a12e-d30a678042a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-47267e64-3d42-4454-86af-ee1134d2d70b,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-6320bc0c-cb72-4f41-92ec-7e5cb1bc2872,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-b1c2c462-2297-4fcd-97d8-f47e8b37bfc0,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-fdca60dc-aa86-4e45-b046-1688fed983b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-39ae5807-add9-4bb5-b4fa-26eb1293b928,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-322a9b7c-6250-4486-bbc3-cfb9ffb94f80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-488788003-172.17.0.10-1595973655578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36715,DS-68c404de-62fe-4ff2-8720-b9144015d564,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-d8e92bbf-6868-461f-a12e-d30a678042a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-47267e64-3d42-4454-86af-ee1134d2d70b,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-6320bc0c-cb72-4f41-92ec-7e5cb1bc2872,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-b1c2c462-2297-4fcd-97d8-f47e8b37bfc0,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-fdca60dc-aa86-4e45-b046-1688fed983b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-39ae5807-add9-4bb5-b4fa-26eb1293b928,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-322a9b7c-6250-4486-bbc3-cfb9ffb94f80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-708902823-172.17.0.10-1595973947785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35856,DS-25b4c643-0940-4463-a398-514b61759df0,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-bca4a097-7c22-4500-b3ea-8c14727ad57b,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-edcb8d96-9402-4d97-b209-80f65729e8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-7ebec3b1-cbae-4d24-b4a4-e55208a84901,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-4de7a622-6177-40f3-b80d-5f7a56c9f7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-906691a1-d093-4664-8401-d1ff53e6e338,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-6252a576-b7c4-42c2-9b7e-c9c11c1e81c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-cf91bb67-5a0e-4254-843b-1846893a014a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-708902823-172.17.0.10-1595973947785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35856,DS-25b4c643-0940-4463-a398-514b61759df0,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-bca4a097-7c22-4500-b3ea-8c14727ad57b,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-edcb8d96-9402-4d97-b209-80f65729e8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-7ebec3b1-cbae-4d24-b4a4-e55208a84901,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-4de7a622-6177-40f3-b80d-5f7a56c9f7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-906691a1-d093-4664-8401-d1ff53e6e338,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-6252a576-b7c4-42c2-9b7e-c9c11c1e81c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-cf91bb67-5a0e-4254-843b-1846893a014a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-821667947-172.17.0.10-1595973988930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39582,DS-6b73ab77-f889-44de-aa9e-f9ebb6c59501,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-a1e49f8a-fe08-4b33-a652-b675f7fe52b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-352ba1ef-64ba-472e-a47c-b5e498c2d6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-a3ddc771-75f1-46f1-bd05-a32253f9e18e,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-cccce8b9-fa28-4615-84c6-5da163c63183,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-2d8eec93-c67a-4db9-a945-21d6645aefd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42679,DS-5ec6eea6-7a3c-418e-aac7-d682ebd4b430,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-d3259c73-2f38-4bc8-a4e9-ad51118e55de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-821667947-172.17.0.10-1595973988930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39582,DS-6b73ab77-f889-44de-aa9e-f9ebb6c59501,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-a1e49f8a-fe08-4b33-a652-b675f7fe52b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-352ba1ef-64ba-472e-a47c-b5e498c2d6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-a3ddc771-75f1-46f1-bd05-a32253f9e18e,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-cccce8b9-fa28-4615-84c6-5da163c63183,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-2d8eec93-c67a-4db9-a945-21d6645aefd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42679,DS-5ec6eea6-7a3c-418e-aac7-d682ebd4b430,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-d3259c73-2f38-4bc8-a4e9-ad51118e55de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1952457333-172.17.0.10-1595974033624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33315,DS-56ff8e8b-c0a1-4bf3-bfa6-59361d12ac77,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-86a40a17-547f-4074-aeb6-be5aa50d4776,DISK], DatanodeInfoWithStorage[127.0.0.1:43179,DS-9e17e437-c7a9-43a4-b12e-d50142162f42,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-513abf54-5207-48a9-913a-d2559194712b,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-ebc8223e-bf62-4c10-8704-6b7da2f840bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-b1544718-f9e5-45d6-a3e4-e817cedb1ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-42827cc9-5115-466e-acea-53d8a919d629,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-238a5ad3-e75f-4dd7-8314-398a0afa818a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1952457333-172.17.0.10-1595974033624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33315,DS-56ff8e8b-c0a1-4bf3-bfa6-59361d12ac77,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-86a40a17-547f-4074-aeb6-be5aa50d4776,DISK], DatanodeInfoWithStorage[127.0.0.1:43179,DS-9e17e437-c7a9-43a4-b12e-d50142162f42,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-513abf54-5207-48a9-913a-d2559194712b,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-ebc8223e-bf62-4c10-8704-6b7da2f840bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-b1544718-f9e5-45d6-a3e4-e817cedb1ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-42827cc9-5115-466e-acea-53d8a919d629,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-238a5ad3-e75f-4dd7-8314-398a0afa818a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2100867916-172.17.0.10-1595975339713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40617,DS-8f837b9c-81f5-44e1-a733-dc1fd87f5a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-4f1c3472-0dbc-49b0-a589-3b860119e02e,DISK], DatanodeInfoWithStorage[127.0.0.1:33998,DS-26debc8d-c7f9-4f50-aae2-4290f849d0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-feb7a60a-aadd-4986-b284-6875716f67b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-b947694d-1151-4b5b-9b5a-f3784d9333a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-fee70087-bf64-4331-9383-a6d592e36d31,DISK], DatanodeInfoWithStorage[127.0.0.1:45903,DS-e9519482-a0aa-46f5-ac63-89659a495bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-079be58b-1b11-4b2e-8e5d-995ee59fcdd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2100867916-172.17.0.10-1595975339713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40617,DS-8f837b9c-81f5-44e1-a733-dc1fd87f5a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-4f1c3472-0dbc-49b0-a589-3b860119e02e,DISK], DatanodeInfoWithStorage[127.0.0.1:33998,DS-26debc8d-c7f9-4f50-aae2-4290f849d0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-feb7a60a-aadd-4986-b284-6875716f67b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-b947694d-1151-4b5b-9b5a-f3784d9333a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-fee70087-bf64-4331-9383-a6d592e36d31,DISK], DatanodeInfoWithStorage[127.0.0.1:45903,DS-e9519482-a0aa-46f5-ac63-89659a495bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-079be58b-1b11-4b2e-8e5d-995ee59fcdd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1595369349-172.17.0.10-1595976128754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43150,DS-1237566d-f0f5-401e-9c2a-b168366ca3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-63e1f654-0d24-4ec9-9aa8-6d7dd9ad134b,DISK], DatanodeInfoWithStorage[127.0.0.1:36926,DS-7b08aaca-922b-4452-97fe-8ce7fc5ab57c,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-51182f7b-4753-41d7-9c07-e9c8b3945a16,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-97d1fbb4-fa2a-44e5-a3ff-2abd43c3c684,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-d93e5f32-5a08-4b85-951e-ac4232322a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-931c4d30-150b-4a95-8733-4d852fd6bc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-29b3f5f5-40e0-45ca-b42f-47c89842da6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1595369349-172.17.0.10-1595976128754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43150,DS-1237566d-f0f5-401e-9c2a-b168366ca3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-63e1f654-0d24-4ec9-9aa8-6d7dd9ad134b,DISK], DatanodeInfoWithStorage[127.0.0.1:36926,DS-7b08aaca-922b-4452-97fe-8ce7fc5ab57c,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-51182f7b-4753-41d7-9c07-e9c8b3945a16,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-97d1fbb4-fa2a-44e5-a3ff-2abd43c3c684,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-d93e5f32-5a08-4b85-951e-ac4232322a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-931c4d30-150b-4a95-8733-4d852fd6bc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-29b3f5f5-40e0-45ca-b42f-47c89842da6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1336470190-172.17.0.10-1595976181315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34280,DS-b6bed372-a016-431f-bc00-c811808107d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-bbf2ab59-ec8d-4b63-9b96-80c6858864c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41766,DS-0143898a-ffb9-448f-9649-815d325b9e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-32cd2ccc-2587-43a5-9d72-a2f5e0493ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:36527,DS-d7385de7-896a-466f-a54b-a9de3176c22e,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-e35decfe-d8a7-42d3-a0ef-4339bf033162,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-c1710aa3-93ce-4105-ae06-cddd1b684e88,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-8d3f51b2-aa09-40f6-a2ed-38a7f4ff9cc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1336470190-172.17.0.10-1595976181315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34280,DS-b6bed372-a016-431f-bc00-c811808107d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-bbf2ab59-ec8d-4b63-9b96-80c6858864c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41766,DS-0143898a-ffb9-448f-9649-815d325b9e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-32cd2ccc-2587-43a5-9d72-a2f5e0493ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:36527,DS-d7385de7-896a-466f-a54b-a9de3176c22e,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-e35decfe-d8a7-42d3-a0ef-4339bf033162,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-c1710aa3-93ce-4105-ae06-cddd1b684e88,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-8d3f51b2-aa09-40f6-a2ed-38a7f4ff9cc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1047892419-172.17.0.10-1595976529071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44962,DS-a55c0641-feff-4838-82b6-58e3ff42fa0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-ef0c4a19-7999-46e9-a67e-fbb7684c8732,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-976627d3-baab-4204-a1f9-fee65e88cc34,DISK], DatanodeInfoWithStorage[127.0.0.1:43369,DS-e49b05de-2483-4bfa-a143-494f1396357a,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-483d16ef-4a46-45f1-86ca-7f2748d3aea7,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-58a6f4da-4386-43d9-a429-3720f61da3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-53a0c34d-dff2-4a5e-ba74-538aa4521321,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-00c71c11-0005-48d7-98d6-88f7b1f0b168,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1047892419-172.17.0.10-1595976529071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44962,DS-a55c0641-feff-4838-82b6-58e3ff42fa0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-ef0c4a19-7999-46e9-a67e-fbb7684c8732,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-976627d3-baab-4204-a1f9-fee65e88cc34,DISK], DatanodeInfoWithStorage[127.0.0.1:43369,DS-e49b05de-2483-4bfa-a143-494f1396357a,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-483d16ef-4a46-45f1-86ca-7f2748d3aea7,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-58a6f4da-4386-43d9-a429-3720f61da3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-53a0c34d-dff2-4a5e-ba74-538aa4521321,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-00c71c11-0005-48d7-98d6-88f7b1f0b168,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6793
