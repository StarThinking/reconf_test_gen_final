reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 64
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 64
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-843340863-172.17.0.21-1595696468561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46045,DS-7b4bf687-cdcc-4c9a-a58e-77d9f70f42b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-e72adab9-39a7-405c-a2a0-41ecb99f189e,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-ee1dea43-7822-4ef8-b629-877c9fc015bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38099,DS-7624f204-fc98-4a75-bec8-bd4f4c546540,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-52ec8f6d-201e-4cfe-a54d-e5e9261f5ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-d1bb0af4-8c68-457f-9e92-ad423eda12cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-fa0379b1-b53b-4b2b-b129-ad3cf324baf5,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-5b77a0ae-6e04-4305-b6e7-6d07b71b23a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-843340863-172.17.0.21-1595696468561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46045,DS-7b4bf687-cdcc-4c9a-a58e-77d9f70f42b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-e72adab9-39a7-405c-a2a0-41ecb99f189e,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-ee1dea43-7822-4ef8-b629-877c9fc015bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38099,DS-7624f204-fc98-4a75-bec8-bd4f4c546540,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-52ec8f6d-201e-4cfe-a54d-e5e9261f5ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-d1bb0af4-8c68-457f-9e92-ad423eda12cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-fa0379b1-b53b-4b2b-b129-ad3cf324baf5,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-5b77a0ae-6e04-4305-b6e7-6d07b71b23a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 64
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-305949665-172.17.0.21-1595696662164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43185,DS-f0e00994-da2e-4770-8301-7c9d5818ccde,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-6dd3ff75-70ad-45df-af3c-a0014fc78d13,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-5e151e97-15e2-411e-95ee-a55afb059ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-8f7c18bc-4f1c-446a-8e48-7a8c31013614,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-61357c9f-5fd9-4025-aeac-9f8d67050bac,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-4d657cd0-7c17-4397-9bf2-c1f7ca48b153,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-8db2206c-e05c-492d-830f-2111ea577004,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-1f0c55a3-9e16-49e7-913c-21d49ed39840,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-305949665-172.17.0.21-1595696662164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43185,DS-f0e00994-da2e-4770-8301-7c9d5818ccde,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-6dd3ff75-70ad-45df-af3c-a0014fc78d13,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-5e151e97-15e2-411e-95ee-a55afb059ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-8f7c18bc-4f1c-446a-8e48-7a8c31013614,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-61357c9f-5fd9-4025-aeac-9f8d67050bac,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-4d657cd0-7c17-4397-9bf2-c1f7ca48b153,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-8db2206c-e05c-492d-830f-2111ea577004,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-1f0c55a3-9e16-49e7-913c-21d49ed39840,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 64
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-330102048-172.17.0.21-1595696984889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34773,DS-1e34c9be-e649-49c1-be45-a4265ccc2f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-f23807ef-1350-4023-bc6f-428c2a7beca0,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-9c32b561-466f-4136-a27a-d82974d050fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-27455bc8-6a68-4cca-82c5-dcd60e4a8b48,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-e4b59b0d-1aaa-4231-b0aa-f14e8adadde4,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-4c6b4d6c-2f05-41b7-8db3-30062588e09a,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-5e318158-d7ce-45ef-b2f8-76271bce434e,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-b5b446b2-5d03-427d-b924-e172aa116472,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-330102048-172.17.0.21-1595696984889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34773,DS-1e34c9be-e649-49c1-be45-a4265ccc2f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-f23807ef-1350-4023-bc6f-428c2a7beca0,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-9c32b561-466f-4136-a27a-d82974d050fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-27455bc8-6a68-4cca-82c5-dcd60e4a8b48,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-e4b59b0d-1aaa-4231-b0aa-f14e8adadde4,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-4c6b4d6c-2f05-41b7-8db3-30062588e09a,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-5e318158-d7ce-45ef-b2f8-76271bce434e,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-b5b446b2-5d03-427d-b924-e172aa116472,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 64
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-669848235-172.17.0.21-1595697057178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39263,DS-d14655d6-849b-4b51-8818-fad1b9fff361,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-7b8b0330-7144-4ad7-9127-3a641badc67b,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-eb23f1bd-4e68-4645-9fac-bbdf430d11c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-92624a39-2571-4388-be29-8a1166f4fc36,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-ccd3b30a-eedb-4be1-a09d-0fb1a607f307,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-314fae4f-2419-48bc-b032-123b4ce4df02,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-7a6d2b91-a219-45c1-b739-a71e5a099868,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-1c57eeb6-979e-4098-9e1d-540bdf310b52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-669848235-172.17.0.21-1595697057178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39263,DS-d14655d6-849b-4b51-8818-fad1b9fff361,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-7b8b0330-7144-4ad7-9127-3a641badc67b,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-eb23f1bd-4e68-4645-9fac-bbdf430d11c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-92624a39-2571-4388-be29-8a1166f4fc36,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-ccd3b30a-eedb-4be1-a09d-0fb1a607f307,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-314fae4f-2419-48bc-b032-123b4ce4df02,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-7a6d2b91-a219-45c1-b739-a71e5a099868,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-1c57eeb6-979e-4098-9e1d-540bdf310b52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 64
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-156523156-172.17.0.21-1595697131691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43825,DS-3b27d700-14d3-4b12-a4a5-0572921250d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-f368276d-b05b-4507-9c7d-f813af6c2c92,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-60eeb534-1260-4207-8e4b-c1e723e33452,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-34171b92-c599-4bcb-acc1-b2d08544b3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-a9bed2e8-ec23-4604-b06c-90da0b9c2df8,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-3a42e81d-7d0a-44c3-8657-0b36b1ca0a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-c10deeb5-4b8e-4f40-890c-f5150c9539cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-823ddc93-8ce1-4f6e-91c2-90b1593743ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-156523156-172.17.0.21-1595697131691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43825,DS-3b27d700-14d3-4b12-a4a5-0572921250d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-f368276d-b05b-4507-9c7d-f813af6c2c92,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-60eeb534-1260-4207-8e4b-c1e723e33452,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-34171b92-c599-4bcb-acc1-b2d08544b3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-a9bed2e8-ec23-4604-b06c-90da0b9c2df8,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-3a42e81d-7d0a-44c3-8657-0b36b1ca0a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-c10deeb5-4b8e-4f40-890c-f5150c9539cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-823ddc93-8ce1-4f6e-91c2-90b1593743ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 64
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2015815706-172.17.0.21-1595697832438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44401,DS-c4aed3a5-9481-44cb-b9a5-0cac674b0f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-a3ee5e58-4186-4ebd-8ab3-f26d5ffd328b,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-74e7746a-b8bc-40c5-873b-4c5c1401d081,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-d05420d9-331c-4461-86cf-985db0720b40,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-7b18ea4a-f535-42d2-bf54-654571816689,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-7092b773-93d7-4114-92b3-2a2aa2544000,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-257b71ec-ea3a-48fd-a303-871665367e73,DISK], DatanodeInfoWithStorage[127.0.0.1:36554,DS-e64ae4b0-1a17-44b3-9936-c343ef0a53db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2015815706-172.17.0.21-1595697832438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44401,DS-c4aed3a5-9481-44cb-b9a5-0cac674b0f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-a3ee5e58-4186-4ebd-8ab3-f26d5ffd328b,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-74e7746a-b8bc-40c5-873b-4c5c1401d081,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-d05420d9-331c-4461-86cf-985db0720b40,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-7b18ea4a-f535-42d2-bf54-654571816689,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-7092b773-93d7-4114-92b3-2a2aa2544000,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-257b71ec-ea3a-48fd-a303-871665367e73,DISK], DatanodeInfoWithStorage[127.0.0.1:36554,DS-e64ae4b0-1a17-44b3-9936-c343ef0a53db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 64
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-80525938-172.17.0.21-1595698164467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33970,DS-36342d21-86fc-4020-a742-bc7f7b1df6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-10416810-fb26-43d1-a346-3931a28f73ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-2e14904e-9399-4c09-a0e6-7787cb1984eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37747,DS-c7c0635b-dc0f-49d1-a1b7-44799d29f705,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-b404c07e-18fc-4bdc-8596-17d1014dde39,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-7e56fa2e-3692-43c8-9c5f-abe8aa43de39,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-e29a2ceb-abc4-4d1e-978a-1ce046c80eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-e936c723-f5f1-48d6-9552-6f59f4d0adbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-80525938-172.17.0.21-1595698164467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33970,DS-36342d21-86fc-4020-a742-bc7f7b1df6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-10416810-fb26-43d1-a346-3931a28f73ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-2e14904e-9399-4c09-a0e6-7787cb1984eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37747,DS-c7c0635b-dc0f-49d1-a1b7-44799d29f705,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-b404c07e-18fc-4bdc-8596-17d1014dde39,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-7e56fa2e-3692-43c8-9c5f-abe8aa43de39,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-e29a2ceb-abc4-4d1e-978a-1ce046c80eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-e936c723-f5f1-48d6-9552-6f59f4d0adbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 64
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1213750046-172.17.0.21-1595699014021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37912,DS-e85cb3c6-0fdb-461f-b97a-f8bda1cbbab7,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-05555419-c67a-491d-927a-122142104a92,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-27504cb1-6cf5-4390-8fc1-986816faae93,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-470fc227-9d3c-4efe-a646-f1caf9023e07,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-afafc887-3b56-4306-a66a-6288b99cba6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-3ff3e32d-5e1f-4ba0-8684-ab392e730c67,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-43849fcc-0c6d-47a4-ba96-b37d4295b5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-0967b860-3348-4a23-b45c-000c523f34cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1213750046-172.17.0.21-1595699014021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37912,DS-e85cb3c6-0fdb-461f-b97a-f8bda1cbbab7,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-05555419-c67a-491d-927a-122142104a92,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-27504cb1-6cf5-4390-8fc1-986816faae93,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-470fc227-9d3c-4efe-a646-f1caf9023e07,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-afafc887-3b56-4306-a66a-6288b99cba6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-3ff3e32d-5e1f-4ba0-8684-ab392e730c67,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-43849fcc-0c6d-47a4-ba96-b37d4295b5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-0967b860-3348-4a23-b45c-000c523f34cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 64
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1374475210-172.17.0.21-1595699303746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39868,DS-56522c87-1383-4049-b13c-ba4fa8227ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-2088bb70-24d6-4be8-843a-4a62e4e48409,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-ffd1e4f9-c887-40d1-a73b-3af7a3994222,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-7afcdcd2-aa7b-493b-acf8-a676c02a6228,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-1a275e00-555d-4fa3-9e9c-b62d95e13bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39392,DS-ec49a981-b724-4576-9e8a-068b0bb3eb47,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-1fe80d3b-5e15-48fe-844e-ec0f4e5aaef1,DISK], DatanodeInfoWithStorage[127.0.0.1:38206,DS-da0b3148-3e37-4973-b184-07a9b9587364,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1374475210-172.17.0.21-1595699303746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39868,DS-56522c87-1383-4049-b13c-ba4fa8227ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-2088bb70-24d6-4be8-843a-4a62e4e48409,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-ffd1e4f9-c887-40d1-a73b-3af7a3994222,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-7afcdcd2-aa7b-493b-acf8-a676c02a6228,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-1a275e00-555d-4fa3-9e9c-b62d95e13bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39392,DS-ec49a981-b724-4576-9e8a-068b0bb3eb47,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-1fe80d3b-5e15-48fe-844e-ec0f4e5aaef1,DISK], DatanodeInfoWithStorage[127.0.0.1:38206,DS-da0b3148-3e37-4973-b184-07a9b9587364,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 64
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1409639441-172.17.0.21-1595699382247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44899,DS-cf48f686-437f-4fa3-8437-755579c73da3,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-72843bf4-66e4-4672-afe9-8a762fd4fb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-e604aa2f-f8fb-4b02-af19-ce58b4de2dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-ef0eb3f4-af9f-4bf3-b9e3-f7b71f4c9db1,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-252f2dae-1473-4af7-94ad-25b11ef961a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-10b1766a-6b37-4f8d-a182-b9fe7741193f,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-f9466180-83b9-4f4e-a101-ec88bc351fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-6ac8a5ef-b056-4c1c-b7d2-981bcf0e13cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1409639441-172.17.0.21-1595699382247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44899,DS-cf48f686-437f-4fa3-8437-755579c73da3,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-72843bf4-66e4-4672-afe9-8a762fd4fb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-e604aa2f-f8fb-4b02-af19-ce58b4de2dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-ef0eb3f4-af9f-4bf3-b9e3-f7b71f4c9db1,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-252f2dae-1473-4af7-94ad-25b11ef961a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-10b1766a-6b37-4f8d-a182-b9fe7741193f,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-f9466180-83b9-4f4e-a101-ec88bc351fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-6ac8a5ef-b056-4c1c-b7d2-981bcf0e13cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 64
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1244828266-172.17.0.21-1595699722973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44612,DS-8db77f10-fa16-4bd9-9454-06389e52a792,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-24a6af8e-584b-43dc-8f86-184c1c80bd42,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-c05c0dcf-9617-47b2-9c63-cad50ec9f4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-55b9e44b-37ce-4528-b843-7126d06f4f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-d7b56897-be20-447d-ae75-120aa8df11e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-f45905d4-4a51-4ed3-be94-75c7675e3e20,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-b951109d-2215-4cc9-bfbe-6ff7c7540306,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-2e8edfbf-1acd-44a7-aefb-d7042b20a729,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1244828266-172.17.0.21-1595699722973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44612,DS-8db77f10-fa16-4bd9-9454-06389e52a792,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-24a6af8e-584b-43dc-8f86-184c1c80bd42,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-c05c0dcf-9617-47b2-9c63-cad50ec9f4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-55b9e44b-37ce-4528-b843-7126d06f4f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-d7b56897-be20-447d-ae75-120aa8df11e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-f45905d4-4a51-4ed3-be94-75c7675e3e20,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-b951109d-2215-4cc9-bfbe-6ff7c7540306,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-2e8edfbf-1acd-44a7-aefb-d7042b20a729,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 64
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-794131856-172.17.0.21-1595699910673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37705,DS-f98febf3-5f2a-4d91-9f6f-707ded37a585,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-3ccf4aff-6deb-47c1-80e7-a3ad57a22812,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-30657e09-9c7d-4c12-aaa2-7784ec5c4e55,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-dca5b30a-e7b2-4a9d-ab5f-9c9e938f33ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-336e0806-7178-4fbf-bdbf-53575425ecae,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-835b2af4-346c-40e9-9c9c-a44ca8138363,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-978043a8-83c5-4a7b-a3fb-9788346c0a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-e00b0c58-e308-4dc5-822b-d622fbdd42fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-794131856-172.17.0.21-1595699910673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37705,DS-f98febf3-5f2a-4d91-9f6f-707ded37a585,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-3ccf4aff-6deb-47c1-80e7-a3ad57a22812,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-30657e09-9c7d-4c12-aaa2-7784ec5c4e55,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-dca5b30a-e7b2-4a9d-ab5f-9c9e938f33ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-336e0806-7178-4fbf-bdbf-53575425ecae,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-835b2af4-346c-40e9-9c9c-a44ca8138363,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-978043a8-83c5-4a7b-a3fb-9788346c0a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-e00b0c58-e308-4dc5-822b-d622fbdd42fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 64
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1909184303-172.17.0.21-1595700152907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42552,DS-d54df298-5e70-4325-9c00-0d594709a334,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-a6bf6a86-e80c-4bce-a778-1dcc6b617e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-7b5357db-35e2-436b-bdcd-443f5c13ab53,DISK], DatanodeInfoWithStorage[127.0.0.1:46731,DS-ae3ee1fd-fe82-4f5e-8e26-e4710026245d,DISK], DatanodeInfoWithStorage[127.0.0.1:37654,DS-812777ba-5344-4a97-916e-be4aec114db9,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-47e5303f-5ccc-4237-a73e-057cf1aebfa5,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-10cf8bdd-cad7-4b86-a2a5-1e7d041ff04d,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-078961a6-864a-49f8-ba88-c6d0f3ccb204,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1909184303-172.17.0.21-1595700152907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42552,DS-d54df298-5e70-4325-9c00-0d594709a334,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-a6bf6a86-e80c-4bce-a778-1dcc6b617e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-7b5357db-35e2-436b-bdcd-443f5c13ab53,DISK], DatanodeInfoWithStorage[127.0.0.1:46731,DS-ae3ee1fd-fe82-4f5e-8e26-e4710026245d,DISK], DatanodeInfoWithStorage[127.0.0.1:37654,DS-812777ba-5344-4a97-916e-be4aec114db9,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-47e5303f-5ccc-4237-a73e-057cf1aebfa5,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-10cf8bdd-cad7-4b86-a2a5-1e7d041ff04d,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-078961a6-864a-49f8-ba88-c6d0f3ccb204,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 64
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1256639717-172.17.0.21-1595700864731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43416,DS-9acf544e-58f5-41ba-a7e6-cb882f226c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42000,DS-ebb4a956-d82b-4614-a624-b9de1a63935e,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-61039e84-8538-4273-94e3-752dbb328c25,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-c4d8d365-b5fe-4da9-9a49-b7c828cebb78,DISK], DatanodeInfoWithStorage[127.0.0.1:44045,DS-5ad06b7e-632f-455f-9436-bb8ca962c9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-891db44e-0457-44fd-89a6-d1eb59d41a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-4f084093-245d-447b-a912-70d93473be91,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-6827c6e2-d256-4ba2-bb1f-41dbbd553ed6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1256639717-172.17.0.21-1595700864731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43416,DS-9acf544e-58f5-41ba-a7e6-cb882f226c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42000,DS-ebb4a956-d82b-4614-a624-b9de1a63935e,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-61039e84-8538-4273-94e3-752dbb328c25,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-c4d8d365-b5fe-4da9-9a49-b7c828cebb78,DISK], DatanodeInfoWithStorage[127.0.0.1:44045,DS-5ad06b7e-632f-455f-9436-bb8ca962c9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-891db44e-0457-44fd-89a6-d1eb59d41a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-4f084093-245d-447b-a912-70d93473be91,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-6827c6e2-d256-4ba2-bb1f-41dbbd553ed6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 64
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-297197702-172.17.0.21-1595700927504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35341,DS-a09613b7-4cb6-4675-993b-cc048fc75160,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-77e0bb44-b6ee-4f89-9c62-faf4b2b0c1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-aecf040a-d395-4ead-8341-ac648ff4fc99,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-19c22aa6-488c-4077-8f09-6276a990b880,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-ae9496f6-bd34-4107-be77-ff61c37ee6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-e20d5933-fd6d-40a5-859d-810bb50d39f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-40ac9b7f-555d-459f-af20-feefde88179e,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-06db5d1b-3840-4eb9-aef0-a5b99857d2d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-297197702-172.17.0.21-1595700927504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35341,DS-a09613b7-4cb6-4675-993b-cc048fc75160,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-77e0bb44-b6ee-4f89-9c62-faf4b2b0c1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-aecf040a-d395-4ead-8341-ac648ff4fc99,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-19c22aa6-488c-4077-8f09-6276a990b880,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-ae9496f6-bd34-4107-be77-ff61c37ee6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-e20d5933-fd6d-40a5-859d-810bb50d39f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-40ac9b7f-555d-459f-af20-feefde88179e,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-06db5d1b-3840-4eb9-aef0-a5b99857d2d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 64
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1032394445-172.17.0.21-1595701071439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39982,DS-29e3cb1a-42e7-4fe2-91ba-f9e07ecbb276,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-683c038f-49aa-46f6-9b35-dd2724955f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33025,DS-a9ba4864-0d99-4528-b4f9-fe3233c20ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-d459df87-7730-4709-a627-10a57e31dec3,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-e846deb1-97c4-4c77-b961-ac1c82c781ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-2f5c35c6-f272-4546-a3ee-f775bd1ac3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-2b4ded19-3716-48bb-8d27-f5e0767c9c10,DISK], DatanodeInfoWithStorage[127.0.0.1:43593,DS-9d783ed6-fada-4f8e-9790-5df7bb7a9bfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1032394445-172.17.0.21-1595701071439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39982,DS-29e3cb1a-42e7-4fe2-91ba-f9e07ecbb276,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-683c038f-49aa-46f6-9b35-dd2724955f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33025,DS-a9ba4864-0d99-4528-b4f9-fe3233c20ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-d459df87-7730-4709-a627-10a57e31dec3,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-e846deb1-97c4-4c77-b961-ac1c82c781ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-2f5c35c6-f272-4546-a3ee-f775bd1ac3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-2b4ded19-3716-48bb-8d27-f5e0767c9c10,DISK], DatanodeInfoWithStorage[127.0.0.1:43593,DS-9d783ed6-fada-4f8e-9790-5df7bb7a9bfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 64
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-152802085-172.17.0.21-1595701104935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38744,DS-ff477672-839c-4708-a6d6-301d8a866f86,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-c7750a97-7fef-4eb7-ba63-cd7e22a560cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39541,DS-af4803cb-08a1-4455-92ff-ba8ce5043cab,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-9551323f-8ffd-4b2a-9279-24702c07d167,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-26509a1f-32ab-459a-bb54-2d364dbb9024,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-8b667883-4d0b-4bb2-91cd-754cc3bf7a94,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-f8a52865-26a8-4534-abec-05b1aa3cc8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-411d8346-01a3-4fca-b326-0f0ef3357330,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-152802085-172.17.0.21-1595701104935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38744,DS-ff477672-839c-4708-a6d6-301d8a866f86,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-c7750a97-7fef-4eb7-ba63-cd7e22a560cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39541,DS-af4803cb-08a1-4455-92ff-ba8ce5043cab,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-9551323f-8ffd-4b2a-9279-24702c07d167,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-26509a1f-32ab-459a-bb54-2d364dbb9024,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-8b667883-4d0b-4bb2-91cd-754cc3bf7a94,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-f8a52865-26a8-4534-abec-05b1aa3cc8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-411d8346-01a3-4fca-b326-0f0ef3357330,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 64
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-594281264-172.17.0.21-1595701498033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45972,DS-f05faaae-acd3-4101-8b6a-2e1b2917db38,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-d8793ab1-f22a-4544-83aa-f692971a69a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-3eaac768-d542-4766-ab01-000db9e61a76,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-17fe731a-4e6c-4376-99b2-24109b80da77,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-934580e5-8920-47e8-b4cf-e2a9414e30f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-c2a65021-fdc5-43d2-92e2-67dd736bf626,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-90e46dc1-2adb-428e-ad51-064c11e7ab14,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-384a0205-a665-47a1-b0fa-e45a380f8823,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-594281264-172.17.0.21-1595701498033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45972,DS-f05faaae-acd3-4101-8b6a-2e1b2917db38,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-d8793ab1-f22a-4544-83aa-f692971a69a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-3eaac768-d542-4766-ab01-000db9e61a76,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-17fe731a-4e6c-4376-99b2-24109b80da77,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-934580e5-8920-47e8-b4cf-e2a9414e30f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-c2a65021-fdc5-43d2-92e2-67dd736bf626,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-90e46dc1-2adb-428e-ad51-064c11e7ab14,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-384a0205-a665-47a1-b0fa-e45a380f8823,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 64
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-815849607-172.17.0.21-1595701719343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43685,DS-6117523b-2846-4ccd-aa94-b9a0a6675ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-d9eca304-93af-41fc-847c-4e057f54b50e,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-f1a3099d-aae8-4714-b358-af6df3668760,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-c8edb0b5-9b1a-49b9-8b82-58a74fb932c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-384a3154-1fe1-41b0-bc24-ba98829ec738,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-91e878c4-048e-428b-a571-34c14e1c3b87,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-69462b2e-d5c5-4344-97e9-f628eac89817,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-8772d5a1-5786-4ed5-ae7a-c219017590d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-815849607-172.17.0.21-1595701719343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43685,DS-6117523b-2846-4ccd-aa94-b9a0a6675ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-d9eca304-93af-41fc-847c-4e057f54b50e,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-f1a3099d-aae8-4714-b358-af6df3668760,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-c8edb0b5-9b1a-49b9-8b82-58a74fb932c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-384a3154-1fe1-41b0-bc24-ba98829ec738,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-91e878c4-048e-428b-a571-34c14e1c3b87,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-69462b2e-d5c5-4344-97e9-f628eac89817,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-8772d5a1-5786-4ed5-ae7a-c219017590d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5393
