reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1153564114-172.17.0.8-1595995767912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41004,DS-1e538a69-ec28-4df6-a6a2-5afe2958388f,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-a88a7d56-aae5-4878-8804-4cda9713aee3,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-7b17cd25-7d11-4faa-a95a-e4c85d906daa,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-c0908d96-2dee-498c-af10-952f5769927f,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-1a2f04a7-e304-47ca-bcdd-13f548714b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-8420f592-2afc-45c5-9b6d-c8811cc5863a,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-6088a737-2230-4bbe-a001-3451af74ea4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-3a32c035-7bff-41d2-86c7-5e7024be20da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1153564114-172.17.0.8-1595995767912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41004,DS-1e538a69-ec28-4df6-a6a2-5afe2958388f,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-a88a7d56-aae5-4878-8804-4cda9713aee3,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-7b17cd25-7d11-4faa-a95a-e4c85d906daa,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-c0908d96-2dee-498c-af10-952f5769927f,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-1a2f04a7-e304-47ca-bcdd-13f548714b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-8420f592-2afc-45c5-9b6d-c8811cc5863a,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-6088a737-2230-4bbe-a001-3451af74ea4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-3a32c035-7bff-41d2-86c7-5e7024be20da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-459509712-172.17.0.8-1595996261618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43016,DS-b8bed416-77d2-4569-a043-528c6863b826,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-a301b1b4-5d3d-42ad-ad03-7d76c79a7fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40863,DS-fdf3b572-455e-4fc2-90b6-0692974f4441,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-4e8ee3f2-38e7-4174-9e50-f2f0e24f929d,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-0c212ed3-d81f-412f-840f-bdc1a8725f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35015,DS-6037dbce-cf7c-4314-bfb4-84b66064a810,DISK], DatanodeInfoWithStorage[127.0.0.1:38963,DS-33e5c0e9-2939-4497-875a-ef3ab8afb2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-cd775010-0c42-4ad2-af61-868c302d1243,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-459509712-172.17.0.8-1595996261618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43016,DS-b8bed416-77d2-4569-a043-528c6863b826,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-a301b1b4-5d3d-42ad-ad03-7d76c79a7fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40863,DS-fdf3b572-455e-4fc2-90b6-0692974f4441,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-4e8ee3f2-38e7-4174-9e50-f2f0e24f929d,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-0c212ed3-d81f-412f-840f-bdc1a8725f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35015,DS-6037dbce-cf7c-4314-bfb4-84b66064a810,DISK], DatanodeInfoWithStorage[127.0.0.1:38963,DS-33e5c0e9-2939-4497-875a-ef3ab8afb2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-cd775010-0c42-4ad2-af61-868c302d1243,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2025576052-172.17.0.8-1595996585913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42115,DS-95870d9d-16cf-45d9-ba64-7d53d080a03c,DISK], DatanodeInfoWithStorage[127.0.0.1:33135,DS-b20d670c-5087-4f6e-bb12-b4e154d4dbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-cda0accc-ef7d-4eba-9b0f-1a87ffae8cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-5e87eb9a-d885-4867-90f2-5c9a50d7dab3,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-69dfacfa-f128-4924-957e-c715c744c311,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-e0e40940-1f72-4b53-9721-6bdd48800134,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-8ebf6498-f921-4fe1-bf96-94fddfc0a255,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-231f668c-f618-4b76-8e14-343b4ddb023e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2025576052-172.17.0.8-1595996585913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42115,DS-95870d9d-16cf-45d9-ba64-7d53d080a03c,DISK], DatanodeInfoWithStorage[127.0.0.1:33135,DS-b20d670c-5087-4f6e-bb12-b4e154d4dbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-cda0accc-ef7d-4eba-9b0f-1a87ffae8cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-5e87eb9a-d885-4867-90f2-5c9a50d7dab3,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-69dfacfa-f128-4924-957e-c715c744c311,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-e0e40940-1f72-4b53-9721-6bdd48800134,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-8ebf6498-f921-4fe1-bf96-94fddfc0a255,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-231f668c-f618-4b76-8e14-343b4ddb023e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1554368195-172.17.0.8-1595996756165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39648,DS-384ca092-5b56-4e01-925a-4a24351952d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-59be204d-0c62-484e-b008-f9c9379e7d92,DISK], DatanodeInfoWithStorage[127.0.0.1:42927,DS-86f17dec-957e-4def-89df-22e91fc68503,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-db5c71ea-bf23-46d8-965e-2fb4705a3852,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-9823737f-479d-4311-b7ac-cdec2e4ff32f,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-da50720e-370d-4758-8c42-5e7f3f0c442b,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-c13e4d01-b155-4062-b81d-1386e8490faf,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-0d357f7f-20de-46f3-85e2-36c6577cb367,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1554368195-172.17.0.8-1595996756165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39648,DS-384ca092-5b56-4e01-925a-4a24351952d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-59be204d-0c62-484e-b008-f9c9379e7d92,DISK], DatanodeInfoWithStorage[127.0.0.1:42927,DS-86f17dec-957e-4def-89df-22e91fc68503,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-db5c71ea-bf23-46d8-965e-2fb4705a3852,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-9823737f-479d-4311-b7ac-cdec2e4ff32f,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-da50720e-370d-4758-8c42-5e7f3f0c442b,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-c13e4d01-b155-4062-b81d-1386e8490faf,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-0d357f7f-20de-46f3-85e2-36c6577cb367,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-46909449-172.17.0.8-1595997346499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34687,DS-959f7392-2b8e-467c-b831-23634badfeb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-323f78d1-ab87-4355-8a71-aefcf1952ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-d875d042-c8db-4030-9a7b-fbca38bdcb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-155ac771-b303-4a7e-ac9e-214b203a35d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-b71a7d23-94fa-4e3b-80be-d3c35d635919,DISK], DatanodeInfoWithStorage[127.0.0.1:43051,DS-34bbd70d-811e-494f-baef-f0709c87b330,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-9b443ba3-e305-4339-a972-acf81f541211,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-0833d1b7-64c0-4f42-beaa-3563b3c24409,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-46909449-172.17.0.8-1595997346499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34687,DS-959f7392-2b8e-467c-b831-23634badfeb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-323f78d1-ab87-4355-8a71-aefcf1952ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-d875d042-c8db-4030-9a7b-fbca38bdcb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-155ac771-b303-4a7e-ac9e-214b203a35d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-b71a7d23-94fa-4e3b-80be-d3c35d635919,DISK], DatanodeInfoWithStorage[127.0.0.1:43051,DS-34bbd70d-811e-494f-baef-f0709c87b330,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-9b443ba3-e305-4339-a972-acf81f541211,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-0833d1b7-64c0-4f42-beaa-3563b3c24409,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-475850305-172.17.0.8-1595997442845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33702,DS-231e78aa-6768-46ca-93b0-48ed651be8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-6682f99d-b44b-4a6b-bcf9-9f4f4add472e,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-344b45a8-6c26-4482-aa63-ea61ca432f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42610,DS-dbdce23a-04b0-4ac7-88fb-5bd0da0183f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-49daa814-11b3-4cf7-80ea-3145e6fb7a98,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-e5d8819f-ad2f-4392-b952-f1d3c4e4c9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-004f89e9-264e-40f7-b2fa-08173fc24fea,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-a78b9109-c211-4a73-bf4c-f04e11606934,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-475850305-172.17.0.8-1595997442845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33702,DS-231e78aa-6768-46ca-93b0-48ed651be8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-6682f99d-b44b-4a6b-bcf9-9f4f4add472e,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-344b45a8-6c26-4482-aa63-ea61ca432f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42610,DS-dbdce23a-04b0-4ac7-88fb-5bd0da0183f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-49daa814-11b3-4cf7-80ea-3145e6fb7a98,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-e5d8819f-ad2f-4392-b952-f1d3c4e4c9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-004f89e9-264e-40f7-b2fa-08173fc24fea,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-a78b9109-c211-4a73-bf4c-f04e11606934,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1358769764-172.17.0.8-1595997511389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36250,DS-6e43ce4f-d8c8-47b2-9886-ad9da29bd022,DISK], DatanodeInfoWithStorage[127.0.0.1:43685,DS-8d58dfaf-c57d-4125-84c2-d20e6612307b,DISK], DatanodeInfoWithStorage[127.0.0.1:40475,DS-dba411f5-c6d7-486f-9547-568ecc2b49b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-71b917e0-488c-4355-b929-6fe7945965fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-e29dbfd6-27c6-4775-b260-57026a2ce5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-80c658b8-c4e5-4899-bb8e-4a15c378cf12,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-43d3b5a4-b0ee-4c1c-84b2-d2b26e2ebd94,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-e18caab5-6c42-4c22-aa67-a27fb1d8b795,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1358769764-172.17.0.8-1595997511389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36250,DS-6e43ce4f-d8c8-47b2-9886-ad9da29bd022,DISK], DatanodeInfoWithStorage[127.0.0.1:43685,DS-8d58dfaf-c57d-4125-84c2-d20e6612307b,DISK], DatanodeInfoWithStorage[127.0.0.1:40475,DS-dba411f5-c6d7-486f-9547-568ecc2b49b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-71b917e0-488c-4355-b929-6fe7945965fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-e29dbfd6-27c6-4775-b260-57026a2ce5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-80c658b8-c4e5-4899-bb8e-4a15c378cf12,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-43d3b5a4-b0ee-4c1c-84b2-d2b26e2ebd94,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-e18caab5-6c42-4c22-aa67-a27fb1d8b795,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-639327918-172.17.0.8-1595998795797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43014,DS-7d17d973-4e08-4a5b-8540-06efad89cac2,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-4cb41430-ac7c-4e65-a069-0b13cc97e8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-a32b88b7-720c-4e0a-8ce6-05c1c88b44c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-1e5aae3d-71e8-4fa7-9fab-a1fda4892f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-7b949e82-db95-4554-9b0b-fab338b3ffcb,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-311da311-cfef-4c74-81b4-c0ca646c0fad,DISK], DatanodeInfoWithStorage[127.0.0.1:40459,DS-10edde27-ae80-4f5f-95e6-022b7cab2b88,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-e953e6bb-6db6-456c-a827-8ffac3275525,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-639327918-172.17.0.8-1595998795797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43014,DS-7d17d973-4e08-4a5b-8540-06efad89cac2,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-4cb41430-ac7c-4e65-a069-0b13cc97e8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-a32b88b7-720c-4e0a-8ce6-05c1c88b44c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-1e5aae3d-71e8-4fa7-9fab-a1fda4892f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-7b949e82-db95-4554-9b0b-fab338b3ffcb,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-311da311-cfef-4c74-81b4-c0ca646c0fad,DISK], DatanodeInfoWithStorage[127.0.0.1:40459,DS-10edde27-ae80-4f5f-95e6-022b7cab2b88,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-e953e6bb-6db6-456c-a827-8ffac3275525,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2078031687-172.17.0.8-1595999332977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34161,DS-e21c8951-21b7-4c72-9cc0-e915b1dec413,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-64fd0d93-fbc6-42b5-9eb9-ff3cd3964451,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-f01c4038-6b16-4abe-b402-5c0949ee04dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-d415b578-dd2e-4dcc-8a42-366b101a6ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:41148,DS-ebcd4d5a-a121-4282-83cc-c19f46870fae,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-57d12c27-f348-405c-835d-7692cfc757f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-5c11d93f-0dc8-4c65-aae0-bf38cdee8819,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-ba198356-e108-44ef-957d-f397e2ffde03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2078031687-172.17.0.8-1595999332977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34161,DS-e21c8951-21b7-4c72-9cc0-e915b1dec413,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-64fd0d93-fbc6-42b5-9eb9-ff3cd3964451,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-f01c4038-6b16-4abe-b402-5c0949ee04dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-d415b578-dd2e-4dcc-8a42-366b101a6ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:41148,DS-ebcd4d5a-a121-4282-83cc-c19f46870fae,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-57d12c27-f348-405c-835d-7692cfc757f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-5c11d93f-0dc8-4c65-aae0-bf38cdee8819,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-ba198356-e108-44ef-957d-f397e2ffde03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-730954285-172.17.0.8-1595999364368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44671,DS-3b9a74fd-4c2d-448b-a174-2b147c4cf2c8,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-b322ec2d-f003-4b61-b98e-c508c04cd241,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-6eec775f-7566-497e-9291-a3992a02f62f,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-49e76a42-9b3c-4a83-82f1-f46f0d072679,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-b228eb16-293a-4695-9e11-76aaaa87ee1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-6ce7230c-1882-47ba-8518-2f4f9e2d18c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-fd5a5d83-3aaa-44c8-9111-838a8b9987bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-18329e2c-8591-4057-bc0b-f6b8ddd3c7c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-730954285-172.17.0.8-1595999364368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44671,DS-3b9a74fd-4c2d-448b-a174-2b147c4cf2c8,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-b322ec2d-f003-4b61-b98e-c508c04cd241,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-6eec775f-7566-497e-9291-a3992a02f62f,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-49e76a42-9b3c-4a83-82f1-f46f0d072679,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-b228eb16-293a-4695-9e11-76aaaa87ee1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-6ce7230c-1882-47ba-8518-2f4f9e2d18c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-fd5a5d83-3aaa-44c8-9111-838a8b9987bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-18329e2c-8591-4057-bc0b-f6b8ddd3c7c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-709911881-172.17.0.8-1595999771290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38548,DS-d3171685-940b-4cbd-9504-cbce4c061e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-20110b25-41fc-40d5-9954-834c1477900f,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-44d4a146-351b-4ce5-a582-6e85458d3ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:41326,DS-83605e5a-82b0-4c5c-8fed-63da7b661b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-225a300c-0f38-4baf-8655-702c402104c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-e545c132-af3b-4dfc-a375-3c26e6293331,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-e3299856-bbaa-4ce9-bf1e-68be68e7987c,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-93df8e77-1794-46ee-8f70-24756519d115,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-709911881-172.17.0.8-1595999771290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38548,DS-d3171685-940b-4cbd-9504-cbce4c061e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-20110b25-41fc-40d5-9954-834c1477900f,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-44d4a146-351b-4ce5-a582-6e85458d3ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:41326,DS-83605e5a-82b0-4c5c-8fed-63da7b661b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-225a300c-0f38-4baf-8655-702c402104c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-e545c132-af3b-4dfc-a375-3c26e6293331,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-e3299856-bbaa-4ce9-bf1e-68be68e7987c,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-93df8e77-1794-46ee-8f70-24756519d115,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1932013927-172.17.0.8-1595999964164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36101,DS-df101427-3f1f-4b3f-a025-9c7a6940d8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-54ebd9b9-17c9-45ba-9c70-93856521df61,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-730428b7-5ded-4a87-8aad-fd25d2ac9252,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-2d52593d-9888-43bc-9f53-a2357910b6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-67b4853b-60fd-45e9-a0c2-27b04c17a55e,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-23397849-fa3e-4c70-b1bc-e7310346e3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-89122bb5-a246-43b2-95f6-ad88533a92f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-19f4a98f-ead4-4768-9cf7-f6519cd91f66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1932013927-172.17.0.8-1595999964164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36101,DS-df101427-3f1f-4b3f-a025-9c7a6940d8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-54ebd9b9-17c9-45ba-9c70-93856521df61,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-730428b7-5ded-4a87-8aad-fd25d2ac9252,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-2d52593d-9888-43bc-9f53-a2357910b6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-67b4853b-60fd-45e9-a0c2-27b04c17a55e,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-23397849-fa3e-4c70-b1bc-e7310346e3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-89122bb5-a246-43b2-95f6-ad88533a92f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-19f4a98f-ead4-4768-9cf7-f6519cd91f66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-5392756-172.17.0.8-1596000359793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43438,DS-b99b6b17-a421-4979-b8b7-0cbb9cb3c654,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-6ca4c721-04e6-4c3a-a39f-760eb68c88cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40702,DS-cc50af81-2e17-43a9-899f-1b086b79a46d,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-124c3b91-b3dd-470c-a89e-29813b283316,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-cf6bcbc0-5f3a-40fe-ada8-8347661f3fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:41336,DS-f89ecd3f-dafa-42ec-8caa-025899b979a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-0a3995a1-7063-4955-9e9e-751e5adc2b05,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-559f77e3-b8a8-48a8-b46b-298583741085,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-5392756-172.17.0.8-1596000359793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43438,DS-b99b6b17-a421-4979-b8b7-0cbb9cb3c654,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-6ca4c721-04e6-4c3a-a39f-760eb68c88cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40702,DS-cc50af81-2e17-43a9-899f-1b086b79a46d,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-124c3b91-b3dd-470c-a89e-29813b283316,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-cf6bcbc0-5f3a-40fe-ada8-8347661f3fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:41336,DS-f89ecd3f-dafa-42ec-8caa-025899b979a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-0a3995a1-7063-4955-9e9e-751e5adc2b05,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-559f77e3-b8a8-48a8-b46b-298583741085,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 4951
