reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-864485551-172.17.0.4-1596022577845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43306,DS-f65df13a-5aa6-4e03-9fe7-d435490b72b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-f0da38b7-1cb3-4bee-8d22-f309593c6f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-10a420ea-4998-404c-a307-89413cb35ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:42601,DS-b1584110-f270-4873-b219-9d35f8784327,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-1c655713-6911-4d15-85c9-7523d93f7271,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-10a9a698-0abc-485e-b8c0-6d9a03f219d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-080b2532-58af-41a2-8218-88ec619ac751,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-1fba28ca-59f6-429d-a797-4a69f05c7b03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-864485551-172.17.0.4-1596022577845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43306,DS-f65df13a-5aa6-4e03-9fe7-d435490b72b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-f0da38b7-1cb3-4bee-8d22-f309593c6f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-10a420ea-4998-404c-a307-89413cb35ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:42601,DS-b1584110-f270-4873-b219-9d35f8784327,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-1c655713-6911-4d15-85c9-7523d93f7271,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-10a9a698-0abc-485e-b8c0-6d9a03f219d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-080b2532-58af-41a2-8218-88ec619ac751,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-1fba28ca-59f6-429d-a797-4a69f05c7b03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-542051854-172.17.0.4-1596022767740:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43201,DS-85116ac6-4cf2-4e5f-a015-d91e4abef103,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-7ce1ab40-ebe1-44cc-bce2-7264146bfd4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-fc0a4ae5-0080-4a52-a94b-211a96fff48a,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-59da0cb6-0121-4109-8ce8-66c0dd33b3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-706e7eeb-0421-495f-8905-4990812547b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-83358e21-85b5-4528-b6e0-19449f94b75b,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-aabe3f9c-89d2-4214-b981-4c7c57311a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-38e462b5-732b-4f3b-a611-10bef72520bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-542051854-172.17.0.4-1596022767740:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43201,DS-85116ac6-4cf2-4e5f-a015-d91e4abef103,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-7ce1ab40-ebe1-44cc-bce2-7264146bfd4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-fc0a4ae5-0080-4a52-a94b-211a96fff48a,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-59da0cb6-0121-4109-8ce8-66c0dd33b3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-706e7eeb-0421-495f-8905-4990812547b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-83358e21-85b5-4528-b6e0-19449f94b75b,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-aabe3f9c-89d2-4214-b981-4c7c57311a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-38e462b5-732b-4f3b-a611-10bef72520bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-186775135-172.17.0.4-1596023359658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40056,DS-5711e0f5-4c4d-494c-82b0-c53c4f3f7307,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-ff84e19e-7938-425d-9403-84aefdf0ae91,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-7e05b0df-2628-43e6-bac8-513b0116d503,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-19ef9bc9-4397-4582-b2e2-f1d6f0312fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-6e002134-0d32-449d-86bc-c1d74fa9f69a,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-bcd09aa0-bf30-4eb2-9608-fd6dce1d3026,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-74698868-1068-48c3-b5b0-8b18c5d22d16,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-15061f07-ef76-4907-82ce-20e5f0577a1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-186775135-172.17.0.4-1596023359658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40056,DS-5711e0f5-4c4d-494c-82b0-c53c4f3f7307,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-ff84e19e-7938-425d-9403-84aefdf0ae91,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-7e05b0df-2628-43e6-bac8-513b0116d503,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-19ef9bc9-4397-4582-b2e2-f1d6f0312fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-6e002134-0d32-449d-86bc-c1d74fa9f69a,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-bcd09aa0-bf30-4eb2-9608-fd6dce1d3026,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-74698868-1068-48c3-b5b0-8b18c5d22d16,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-15061f07-ef76-4907-82ce-20e5f0577a1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-973528568-172.17.0.4-1596023620981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34541,DS-924a55b9-1803-40ea-bf04-7b1b2e660921,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-ef737976-85f1-4c15-aa52-29eab4435577,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-4665dc68-3255-498a-9238-25e9af8a25a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45544,DS-ad65ebb0-65b8-44ce-af46-2ab2a8952c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-e03ff450-e733-4940-9378-57c34682a711,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-fe91258e-675f-46c2-9ba7-4ec417357993,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-3133009d-e983-4b67-9bcd-8ee8d9e3d870,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-05abed54-bca4-42d6-9d05-6d24c4451b04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-973528568-172.17.0.4-1596023620981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34541,DS-924a55b9-1803-40ea-bf04-7b1b2e660921,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-ef737976-85f1-4c15-aa52-29eab4435577,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-4665dc68-3255-498a-9238-25e9af8a25a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45544,DS-ad65ebb0-65b8-44ce-af46-2ab2a8952c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-e03ff450-e733-4940-9378-57c34682a711,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-fe91258e-675f-46c2-9ba7-4ec417357993,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-3133009d-e983-4b67-9bcd-8ee8d9e3d870,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-05abed54-bca4-42d6-9d05-6d24c4451b04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1960538388-172.17.0.4-1596023660722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33877,DS-2216ca7d-b979-4a6d-82d5-eb2ee1cea0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-2d791fe2-1c29-4a81-9b0a-11da0aeb2004,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-49035a0a-6290-4f4c-9cf3-09c71112ba1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33822,DS-0b892cea-bf67-480c-adf0-2e137d51e432,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-24c0537d-ace8-49f7-b32f-eb40de6e93ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-87932bb4-449f-4e57-a56a-c3bcb27fe25b,DISK], DatanodeInfoWithStorage[127.0.0.1:33200,DS-ed76d37d-a58d-4dae-8324-88c60c8f3357,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-74810396-dc6e-49af-85e8-15532a9f6940,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1960538388-172.17.0.4-1596023660722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33877,DS-2216ca7d-b979-4a6d-82d5-eb2ee1cea0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-2d791fe2-1c29-4a81-9b0a-11da0aeb2004,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-49035a0a-6290-4f4c-9cf3-09c71112ba1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33822,DS-0b892cea-bf67-480c-adf0-2e137d51e432,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-24c0537d-ace8-49f7-b32f-eb40de6e93ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-87932bb4-449f-4e57-a56a-c3bcb27fe25b,DISK], DatanodeInfoWithStorage[127.0.0.1:33200,DS-ed76d37d-a58d-4dae-8324-88c60c8f3357,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-74810396-dc6e-49af-85e8-15532a9f6940,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-13856156-172.17.0.4-1596023962076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42533,DS-1a42866e-a97b-4684-b983-946fb3c3d66b,DISK], DatanodeInfoWithStorage[127.0.0.1:41766,DS-8962aef8-50c6-4fc0-9813-d92a584efbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-760845c7-c9a4-4ccd-9345-1f51379e1bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-54f04715-c444-4dbc-9894-2fd130175cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-8139b9df-27e7-4738-bcd2-688135ef6d29,DISK], DatanodeInfoWithStorage[127.0.0.1:38862,DS-96aeb55b-7fc2-4345-9dc7-52e8d3f17344,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-35ec3527-502c-4536-a8b4-6ef6af727a36,DISK], DatanodeInfoWithStorage[127.0.0.1:33301,DS-b55ea2a6-f8cf-4493-a18b-4886f41b70ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-13856156-172.17.0.4-1596023962076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42533,DS-1a42866e-a97b-4684-b983-946fb3c3d66b,DISK], DatanodeInfoWithStorage[127.0.0.1:41766,DS-8962aef8-50c6-4fc0-9813-d92a584efbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-760845c7-c9a4-4ccd-9345-1f51379e1bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-54f04715-c444-4dbc-9894-2fd130175cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-8139b9df-27e7-4738-bcd2-688135ef6d29,DISK], DatanodeInfoWithStorage[127.0.0.1:38862,DS-96aeb55b-7fc2-4345-9dc7-52e8d3f17344,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-35ec3527-502c-4536-a8b4-6ef6af727a36,DISK], DatanodeInfoWithStorage[127.0.0.1:33301,DS-b55ea2a6-f8cf-4493-a18b-4886f41b70ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2055348079-172.17.0.4-1596024955025:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44695,DS-620e0f92-8283-4129-a78f-461e60c73d03,DISK], DatanodeInfoWithStorage[127.0.0.1:41101,DS-6cee5523-767e-43eb-b7cf-1102c6e76990,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-3b95cfc3-9203-4d4f-8480-4cc25f596c52,DISK], DatanodeInfoWithStorage[127.0.0.1:40438,DS-088a1153-eaaf-4196-b979-96e55cb7eda4,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-c64c7bf7-01be-4d7d-bfe8-6c156d801b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38261,DS-7890579b-b369-4cb7-b0f9-eba3bdc41e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-18db1389-ef6a-497c-8a9e-ada3844b7615,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-726d68a2-37f7-4b41-b3b7-7548651e8ccf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2055348079-172.17.0.4-1596024955025:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44695,DS-620e0f92-8283-4129-a78f-461e60c73d03,DISK], DatanodeInfoWithStorage[127.0.0.1:41101,DS-6cee5523-767e-43eb-b7cf-1102c6e76990,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-3b95cfc3-9203-4d4f-8480-4cc25f596c52,DISK], DatanodeInfoWithStorage[127.0.0.1:40438,DS-088a1153-eaaf-4196-b979-96e55cb7eda4,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-c64c7bf7-01be-4d7d-bfe8-6c156d801b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38261,DS-7890579b-b369-4cb7-b0f9-eba3bdc41e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-18db1389-ef6a-497c-8a9e-ada3844b7615,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-726d68a2-37f7-4b41-b3b7-7548651e8ccf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-89616983-172.17.0.4-1596025169284:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36983,DS-0e13c3f6-5157-4a45-a958-2953570ecb27,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-53c75d03-a51a-4db5-8ed9-f4adac185c90,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-9bd80724-f082-44e2-bc05-e9dec3f95166,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-94d2a1d1-e07b-46d2-bb47-954e577dfe1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-488ef1f4-f6ab-4b3c-9a5b-295069e1d982,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-f6a7d34b-ca45-4819-8229-7075ab637185,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-d132ad6e-bb3e-4fb2-b8f8-81b8942ea14e,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-5c6c41cf-68e4-469c-bd9b-9bf0fa66d674,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-89616983-172.17.0.4-1596025169284:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36983,DS-0e13c3f6-5157-4a45-a958-2953570ecb27,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-53c75d03-a51a-4db5-8ed9-f4adac185c90,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-9bd80724-f082-44e2-bc05-e9dec3f95166,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-94d2a1d1-e07b-46d2-bb47-954e577dfe1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-488ef1f4-f6ab-4b3c-9a5b-295069e1d982,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-f6a7d34b-ca45-4819-8229-7075ab637185,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-d132ad6e-bb3e-4fb2-b8f8-81b8942ea14e,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-5c6c41cf-68e4-469c-bd9b-9bf0fa66d674,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1541333429-172.17.0.4-1596025395087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43997,DS-db37cf68-969f-437b-81ba-c322336bd0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42216,DS-db75d6de-6886-4c29-ac44-286a5e2d7fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-704c092a-1402-4f36-a7fa-30db07f7eba4,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-9d8992a5-7d74-44c6-a4fd-84b977ab3a46,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-83e22e7a-5e56-45bf-8498-6cc9e4634a99,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-e314e87c-92a8-4328-836f-59492782c6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-a953fa72-f9f6-4089-b314-b2777503ca12,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-e658ca59-464b-4784-bc88-4e33d5a1e099,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1541333429-172.17.0.4-1596025395087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43997,DS-db37cf68-969f-437b-81ba-c322336bd0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42216,DS-db75d6de-6886-4c29-ac44-286a5e2d7fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-704c092a-1402-4f36-a7fa-30db07f7eba4,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-9d8992a5-7d74-44c6-a4fd-84b977ab3a46,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-83e22e7a-5e56-45bf-8498-6cc9e4634a99,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-e314e87c-92a8-4328-836f-59492782c6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-a953fa72-f9f6-4089-b314-b2777503ca12,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-e658ca59-464b-4784-bc88-4e33d5a1e099,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1366951301-172.17.0.4-1596026432711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34300,DS-0ced3912-3b67-41b8-8ebd-9dc9f8a6fd02,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-fc2023db-fd87-4cbe-b92f-c1243d34d532,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-200a4235-effc-47e6-a76a-430fd350bc3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-48e69e4b-279b-4b7f-a993-e132135ab881,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-95c74514-b436-4c63-a7d9-c7895acdd176,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-defff042-50b6-4a15-bcf2-2336187d410a,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-0d9773d6-a13b-41d5-9498-c871c09bd541,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-a67b2e27-12e8-4bf5-8072-5372f04de9ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1366951301-172.17.0.4-1596026432711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34300,DS-0ced3912-3b67-41b8-8ebd-9dc9f8a6fd02,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-fc2023db-fd87-4cbe-b92f-c1243d34d532,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-200a4235-effc-47e6-a76a-430fd350bc3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-48e69e4b-279b-4b7f-a993-e132135ab881,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-95c74514-b436-4c63-a7d9-c7895acdd176,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-defff042-50b6-4a15-bcf2-2336187d410a,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-0d9773d6-a13b-41d5-9498-c871c09bd541,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-a67b2e27-12e8-4bf5-8072-5372f04de9ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1121971235-172.17.0.4-1596026683003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39444,DS-23c7291c-50c5-4d3d-9524-612674172498,DISK], DatanodeInfoWithStorage[127.0.0.1:40034,DS-a5460dde-7f57-44d6-b60d-6ae27cce5523,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-110972fa-5c9a-45d4-9894-5dcef9fc3069,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-d7edd299-7cf1-4cd4-afeb-eab2e3070ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-8e6c9ede-c7e4-4e88-b0d1-6023cc80aa81,DISK], DatanodeInfoWithStorage[127.0.0.1:36400,DS-bd27a045-9ae3-4f55-b8c9-eb813dcbcbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-c3efb97d-146b-49c9-a310-885276b504a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-f856fcf2-0015-4531-abec-6ae2fba756a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1121971235-172.17.0.4-1596026683003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39444,DS-23c7291c-50c5-4d3d-9524-612674172498,DISK], DatanodeInfoWithStorage[127.0.0.1:40034,DS-a5460dde-7f57-44d6-b60d-6ae27cce5523,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-110972fa-5c9a-45d4-9894-5dcef9fc3069,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-d7edd299-7cf1-4cd4-afeb-eab2e3070ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-8e6c9ede-c7e4-4e88-b0d1-6023cc80aa81,DISK], DatanodeInfoWithStorage[127.0.0.1:36400,DS-bd27a045-9ae3-4f55-b8c9-eb813dcbcbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-c3efb97d-146b-49c9-a310-885276b504a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-f856fcf2-0015-4531-abec-6ae2fba756a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1560801774-172.17.0.4-1596027142192:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39311,DS-c2e5a9fa-7dbd-4af4-b3b0-d67e144acbba,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-da8cca53-4358-488f-a2de-cf36fa76fdf8,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-742531e2-d8b5-4bd6-8fe0-6e21713b4ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-925b9cb6-973a-4b69-8c25-30dc53bb07ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34280,DS-c6bdc4c5-4507-408a-a2e0-80ca86525a82,DISK], DatanodeInfoWithStorage[127.0.0.1:41440,DS-b7a785f5-527f-43ff-b705-4017de635f69,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-e596e9b8-33b4-4407-bf3e-19710e7d3d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-985f524c-7168-492a-b71c-ca5c2c775bed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1560801774-172.17.0.4-1596027142192:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39311,DS-c2e5a9fa-7dbd-4af4-b3b0-d67e144acbba,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-da8cca53-4358-488f-a2de-cf36fa76fdf8,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-742531e2-d8b5-4bd6-8fe0-6e21713b4ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-925b9cb6-973a-4b69-8c25-30dc53bb07ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34280,DS-c6bdc4c5-4507-408a-a2e0-80ca86525a82,DISK], DatanodeInfoWithStorage[127.0.0.1:41440,DS-b7a785f5-527f-43ff-b705-4017de635f69,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-e596e9b8-33b4-4407-bf3e-19710e7d3d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-985f524c-7168-492a-b71c-ca5c2c775bed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5395
