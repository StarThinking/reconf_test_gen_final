reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-248614814-172.17.0.21-1595916089578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36320,DS-b3bf84b8-48b4-4323-b238-13210459a36d,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-556521ad-4327-424e-817b-7968fe5ef6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-4c1e6e34-7894-447e-a7f8-fbc5746a90b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39623,DS-0490675d-b17f-420a-a2d8-15dec0c1c26d,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-acb8dd95-85cd-4462-a5c7-1af06ccd5e38,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-69fa7229-7575-4a22-a6c0-0dd1d208676f,DISK], DatanodeInfoWithStorage[127.0.0.1:46069,DS-c9cfcc9b-d8cf-47a4-999f-48ef38721138,DISK], DatanodeInfoWithStorage[127.0.0.1:44148,DS-0bb5545c-7699-4dff-b6ef-28f76382f783,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-248614814-172.17.0.21-1595916089578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36320,DS-b3bf84b8-48b4-4323-b238-13210459a36d,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-556521ad-4327-424e-817b-7968fe5ef6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-4c1e6e34-7894-447e-a7f8-fbc5746a90b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39623,DS-0490675d-b17f-420a-a2d8-15dec0c1c26d,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-acb8dd95-85cd-4462-a5c7-1af06ccd5e38,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-69fa7229-7575-4a22-a6c0-0dd1d208676f,DISK], DatanodeInfoWithStorage[127.0.0.1:46069,DS-c9cfcc9b-d8cf-47a4-999f-48ef38721138,DISK], DatanodeInfoWithStorage[127.0.0.1:44148,DS-0bb5545c-7699-4dff-b6ef-28f76382f783,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-772049094-172.17.0.21-1595916161356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35393,DS-bcc413e4-b3d3-404f-8767-5d74132d98cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-b82c36bb-d513-41e2-a900-08c7c83ea63b,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-0616454c-2846-47ae-9457-c3b14fde8792,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-3eb26f7a-b345-4019-8491-db382750ac14,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-acff0302-6bc0-499a-b63b-6d83675ba3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44952,DS-a29143fa-d34e-483c-9fbb-e4aaed61b9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-a551eb6b-a607-405f-8ce0-66b587e3cbba,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-e668e0b9-1f23-40be-a16e-ca9326030e06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-772049094-172.17.0.21-1595916161356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35393,DS-bcc413e4-b3d3-404f-8767-5d74132d98cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-b82c36bb-d513-41e2-a900-08c7c83ea63b,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-0616454c-2846-47ae-9457-c3b14fde8792,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-3eb26f7a-b345-4019-8491-db382750ac14,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-acff0302-6bc0-499a-b63b-6d83675ba3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44952,DS-a29143fa-d34e-483c-9fbb-e4aaed61b9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-a551eb6b-a607-405f-8ce0-66b587e3cbba,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-e668e0b9-1f23-40be-a16e-ca9326030e06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1202212649-172.17.0.21-1595916722427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35329,DS-5d1da80e-2233-4565-9ff6-b91106d76870,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-493bd06e-2321-4557-aaaf-77f3a323c8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-6fdcbaa1-d3a9-4c8b-a12d-89f6375e23f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-1e07020e-0365-4152-8ce1-33dcac6f3b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-28c1b34a-b6af-49b4-a822-af16799a07e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-a5400a19-c243-439e-9bc6-3a14208ede05,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-f4773300-a361-40a1-9486-6488e440a8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-50acd6a7-3480-4e84-bb57-f166a08a30ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1202212649-172.17.0.21-1595916722427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35329,DS-5d1da80e-2233-4565-9ff6-b91106d76870,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-493bd06e-2321-4557-aaaf-77f3a323c8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-6fdcbaa1-d3a9-4c8b-a12d-89f6375e23f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-1e07020e-0365-4152-8ce1-33dcac6f3b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-28c1b34a-b6af-49b4-a822-af16799a07e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-a5400a19-c243-439e-9bc6-3a14208ede05,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-f4773300-a361-40a1-9486-6488e440a8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-50acd6a7-3480-4e84-bb57-f166a08a30ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-749461040-172.17.0.21-1595916803596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40215,DS-c67e5cde-04f7-48fb-9c33-d145095bb5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-a9f9a3bc-4325-410e-93e2-50155e57475e,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-302ba4aa-22d6-4ffd-8ba6-82310a2ec0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-09d4c911-ab7f-496f-8468-c3f6b2c1eed9,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-6383e3d1-2ede-40b2-b56b-45429f3b97cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43304,DS-f5e722f9-00f8-4fbc-a081-84705969a5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-0e725e27-8965-4271-9cc4-f09c842060cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-a2444b67-fe71-46f4-ba69-f723fdbf5ff8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-749461040-172.17.0.21-1595916803596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40215,DS-c67e5cde-04f7-48fb-9c33-d145095bb5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-a9f9a3bc-4325-410e-93e2-50155e57475e,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-302ba4aa-22d6-4ffd-8ba6-82310a2ec0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-09d4c911-ab7f-496f-8468-c3f6b2c1eed9,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-6383e3d1-2ede-40b2-b56b-45429f3b97cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43304,DS-f5e722f9-00f8-4fbc-a081-84705969a5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-0e725e27-8965-4271-9cc4-f09c842060cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-a2444b67-fe71-46f4-ba69-f723fdbf5ff8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-681192927-172.17.0.21-1595917362033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44150,DS-c0c1a071-b072-4ed9-9df9-16a387174ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-5a09fe71-536c-4137-9b34-5623dbb8f8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-87217797-68d8-4861-b972-a905e200b69e,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-7491b916-3948-4596-8301-1a077dc7b3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-44d5987b-e1e6-4899-9d9e-151e1c277511,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-11edda66-f7de-4206-8cb3-a9273113968b,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-841d75e9-5a69-448f-881e-fab0ecdbc296,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-7979e643-345d-4cf7-9f36-06eb2bff8805,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-681192927-172.17.0.21-1595917362033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44150,DS-c0c1a071-b072-4ed9-9df9-16a387174ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-5a09fe71-536c-4137-9b34-5623dbb8f8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-87217797-68d8-4861-b972-a905e200b69e,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-7491b916-3948-4596-8301-1a077dc7b3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-44d5987b-e1e6-4899-9d9e-151e1c277511,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-11edda66-f7de-4206-8cb3-a9273113968b,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-841d75e9-5a69-448f-881e-fab0ecdbc296,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-7979e643-345d-4cf7-9f36-06eb2bff8805,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1735374221-172.17.0.21-1595917994401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41968,DS-bea8e2cf-8445-43dc-8487-19037e5586d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-6fe983b6-3b0b-43bf-82a8-69e91ecf078e,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-69c55145-ed66-4add-b247-72cbaf029134,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-cc605e09-530f-4617-b2a6-8bbecdcb5a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46358,DS-b9731194-cf81-495d-9c5a-49126a63fcc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-b815a1ab-0487-4373-92fb-239190881036,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-607bff44-5184-42da-b81a-b48dd1e5a494,DISK], DatanodeInfoWithStorage[127.0.0.1:39513,DS-8204ca20-9d67-45d2-bacb-e40dac5ad301,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1735374221-172.17.0.21-1595917994401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41968,DS-bea8e2cf-8445-43dc-8487-19037e5586d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-6fe983b6-3b0b-43bf-82a8-69e91ecf078e,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-69c55145-ed66-4add-b247-72cbaf029134,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-cc605e09-530f-4617-b2a6-8bbecdcb5a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46358,DS-b9731194-cf81-495d-9c5a-49126a63fcc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-b815a1ab-0487-4373-92fb-239190881036,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-607bff44-5184-42da-b81a-b48dd1e5a494,DISK], DatanodeInfoWithStorage[127.0.0.1:39513,DS-8204ca20-9d67-45d2-bacb-e40dac5ad301,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-692158838-172.17.0.21-1595918306326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39214,DS-4d7f530d-a088-4e85-ba80-aac4a4dd7b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-a29ebcb0-d5d1-4291-9d00-e0a348f6b68a,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-8bb917fc-336b-4a3d-9177-dc5d4a406b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-2bd8553a-30f3-4183-ae68-1963539d9a64,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-66e7b975-5311-47cf-afa7-adb3ffde87ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-c1fc48aa-00c8-4cd4-8c2f-18b503db0f42,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-fe881079-95c4-49cf-aba1-cc6d75b14408,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-339e5ed5-8e16-4ed6-9e17-15eaca491675,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-692158838-172.17.0.21-1595918306326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39214,DS-4d7f530d-a088-4e85-ba80-aac4a4dd7b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-a29ebcb0-d5d1-4291-9d00-e0a348f6b68a,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-8bb917fc-336b-4a3d-9177-dc5d4a406b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-2bd8553a-30f3-4183-ae68-1963539d9a64,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-66e7b975-5311-47cf-afa7-adb3ffde87ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-c1fc48aa-00c8-4cd4-8c2f-18b503db0f42,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-fe881079-95c4-49cf-aba1-cc6d75b14408,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-339e5ed5-8e16-4ed6-9e17-15eaca491675,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1370681761-172.17.0.21-1595918670068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46283,DS-9449b504-3f5f-4ee9-9256-27835382c831,DISK], DatanodeInfoWithStorage[127.0.0.1:38694,DS-cdbe71ad-34b8-4a07-bc33-0cc1a444f5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-bef1e6bb-8db0-44cb-9e90-0c83facd250b,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-6055c887-ea76-4186-beb5-b844481f3d10,DISK], DatanodeInfoWithStorage[127.0.0.1:45617,DS-142b9cd2-d212-4296-847d-6e73ac0fb9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-2569c84f-3d69-4efa-8888-9c7861efe835,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-8db44225-2dd5-4004-82b5-286330ee5e56,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-e6107b42-579e-4475-8ccb-1a804a9f802e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1370681761-172.17.0.21-1595918670068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46283,DS-9449b504-3f5f-4ee9-9256-27835382c831,DISK], DatanodeInfoWithStorage[127.0.0.1:38694,DS-cdbe71ad-34b8-4a07-bc33-0cc1a444f5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-bef1e6bb-8db0-44cb-9e90-0c83facd250b,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-6055c887-ea76-4186-beb5-b844481f3d10,DISK], DatanodeInfoWithStorage[127.0.0.1:45617,DS-142b9cd2-d212-4296-847d-6e73ac0fb9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-2569c84f-3d69-4efa-8888-9c7861efe835,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-8db44225-2dd5-4004-82b5-286330ee5e56,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-e6107b42-579e-4475-8ccb-1a804a9f802e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1100103748-172.17.0.21-1595918708768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42121,DS-0e23008e-36d5-4197-8295-abbb070b54b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40913,DS-9920bda1-35f5-4682-ba32-f8a2c6bcb891,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-c91c92db-9f30-4827-b4d5-36d3c8f85e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-3b51cc14-0719-49a9-805d-d410920b165b,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-d00448f4-798d-4e93-b7f0-20960d5fb1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34486,DS-9c0260c0-57f7-4bf0-acd4-16ad5c1f6771,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-34d4f3fd-18d5-47fb-9a7f-cd738cd7ac76,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-69a308ba-040f-4b0b-8122-0b08f6455139,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1100103748-172.17.0.21-1595918708768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42121,DS-0e23008e-36d5-4197-8295-abbb070b54b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40913,DS-9920bda1-35f5-4682-ba32-f8a2c6bcb891,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-c91c92db-9f30-4827-b4d5-36d3c8f85e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-3b51cc14-0719-49a9-805d-d410920b165b,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-d00448f4-798d-4e93-b7f0-20960d5fb1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34486,DS-9c0260c0-57f7-4bf0-acd4-16ad5c1f6771,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-34d4f3fd-18d5-47fb-9a7f-cd738cd7ac76,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-69a308ba-040f-4b0b-8122-0b08f6455139,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1670432058-172.17.0.21-1595918888571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38009,DS-9edae1b6-7db5-4569-85ed-67d898d28196,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-743e2b4c-b8a7-449a-9c97-be13330c6a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-27c03972-0abb-4a22-b157-ee162865cdf0,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-1a7a0ac3-850c-45ed-85af-014f0282f6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-18daed2e-f11e-4e39-9f5e-62fc7e49a21d,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-27cfb307-2ec2-41a0-b86b-9ee3ca514ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-0a7e7815-2368-4ffd-bb6c-32fb0f10e6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-e98e3671-41c4-4da5-b68b-5378cac2d1bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1670432058-172.17.0.21-1595918888571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38009,DS-9edae1b6-7db5-4569-85ed-67d898d28196,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-743e2b4c-b8a7-449a-9c97-be13330c6a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-27c03972-0abb-4a22-b157-ee162865cdf0,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-1a7a0ac3-850c-45ed-85af-014f0282f6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-18daed2e-f11e-4e39-9f5e-62fc7e49a21d,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-27cfb307-2ec2-41a0-b86b-9ee3ca514ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-0a7e7815-2368-4ffd-bb6c-32fb0f10e6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-e98e3671-41c4-4da5-b68b-5378cac2d1bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1310312745-172.17.0.21-1595919316086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43898,DS-0ee7a22a-a4cc-4e55-b509-1335497612b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-54132190-3cba-4b0d-8472-ed9bc7e458a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-3e8188d9-7d26-4fcb-9212-dd1f44751b89,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-b99e1265-7a35-4d99-b13c-29515719bda8,DISK], DatanodeInfoWithStorage[127.0.0.1:34921,DS-036430d8-ba62-4201-8c26-a2fe4577f094,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-9f29a833-e84c-4cf3-a383-89c34b6214a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38859,DS-cb0c22c7-cd3b-4a03-8dd1-71da1e65b2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-bf1f94f5-7bcd-4cb5-a91e-8f6d518f4d12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1310312745-172.17.0.21-1595919316086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43898,DS-0ee7a22a-a4cc-4e55-b509-1335497612b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-54132190-3cba-4b0d-8472-ed9bc7e458a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-3e8188d9-7d26-4fcb-9212-dd1f44751b89,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-b99e1265-7a35-4d99-b13c-29515719bda8,DISK], DatanodeInfoWithStorage[127.0.0.1:34921,DS-036430d8-ba62-4201-8c26-a2fe4577f094,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-9f29a833-e84c-4cf3-a383-89c34b6214a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38859,DS-cb0c22c7-cd3b-4a03-8dd1-71da1e65b2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-bf1f94f5-7bcd-4cb5-a91e-8f6d518f4d12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-129971193-172.17.0.21-1595919353547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37210,DS-de03a474-236a-4f92-a1dc-7b6e19eacdae,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-c8a4d42c-4e51-47c2-b0cb-fa28f80baf0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-670f7169-70bb-4195-8093-1d928527af88,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-f0af2c4e-b44f-42c3-ba3a-4fe73c60a81b,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-b95d27f5-f7e5-45a2-99b2-416fb541d1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-55f9afb8-8900-4229-9835-a6909c2e0608,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-8f41b7b8-a1b9-41d7-80cc-766fdaf5747e,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-10e364ca-ee8c-4932-af99-2ddf7089ecf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-129971193-172.17.0.21-1595919353547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37210,DS-de03a474-236a-4f92-a1dc-7b6e19eacdae,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-c8a4d42c-4e51-47c2-b0cb-fa28f80baf0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-670f7169-70bb-4195-8093-1d928527af88,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-f0af2c4e-b44f-42c3-ba3a-4fe73c60a81b,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-b95d27f5-f7e5-45a2-99b2-416fb541d1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-55f9afb8-8900-4229-9835-a6909c2e0608,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-8f41b7b8-a1b9-41d7-80cc-766fdaf5747e,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-10e364ca-ee8c-4932-af99-2ddf7089ecf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-272121905-172.17.0.21-1595919631850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34418,DS-c4a6207f-a945-436a-9995-9f08adcbdd57,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-b0df1a29-6c60-4318-b1f4-f8170b0db5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36229,DS-b0569040-ef02-4128-a726-51cd4539af5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42612,DS-a666bf1c-1c0f-4bc4-ad2d-f3e58ced1bed,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-cf70fb3d-91cd-41b2-b67f-c951e5d1bdbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-a8cc915f-6d0e-4acf-8676-59841ea675e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-9ab3f7b2-60d3-4cf8-b567-93c115cb838e,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-2b851d4e-ecc8-4a3d-82f8-ecedc8bd22d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-272121905-172.17.0.21-1595919631850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34418,DS-c4a6207f-a945-436a-9995-9f08adcbdd57,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-b0df1a29-6c60-4318-b1f4-f8170b0db5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36229,DS-b0569040-ef02-4128-a726-51cd4539af5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42612,DS-a666bf1c-1c0f-4bc4-ad2d-f3e58ced1bed,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-cf70fb3d-91cd-41b2-b67f-c951e5d1bdbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-a8cc915f-6d0e-4acf-8676-59841ea675e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-9ab3f7b2-60d3-4cf8-b567-93c115cb838e,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-2b851d4e-ecc8-4a3d-82f8-ecedc8bd22d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214811005-172.17.0.21-1595919732131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35582,DS-d5557efa-f63f-4cce-a327-0164424ceaef,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-d407c76e-ba46-4581-afd5-37471ec6fedf,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-4671c41b-5701-40de-8412-d639b438c478,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-abb6e172-21a7-4bb9-86b2-61f44a476efb,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-38bc02a2-1d18-44a6-a06b-2b96e1c51c87,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-8bb49931-427c-4a2a-bd91-57586de955cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-ac72b438-9201-4059-b8d6-23f3ef94c1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-8b300ad6-d8ff-442f-9936-bd0f8e042743,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214811005-172.17.0.21-1595919732131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35582,DS-d5557efa-f63f-4cce-a327-0164424ceaef,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-d407c76e-ba46-4581-afd5-37471ec6fedf,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-4671c41b-5701-40de-8412-d639b438c478,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-abb6e172-21a7-4bb9-86b2-61f44a476efb,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-38bc02a2-1d18-44a6-a06b-2b96e1c51c87,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-8bb49931-427c-4a2a-bd91-57586de955cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-ac72b438-9201-4059-b8d6-23f3ef94c1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-8b300ad6-d8ff-442f-9936-bd0f8e042743,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1468016597-172.17.0.21-1595919981043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44700,DS-44586f13-4585-49e6-b25f-a80db28739a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46424,DS-ee148cbd-62a9-4654-8557-742f639e6cff,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-69bb744b-2351-4b6a-91b0-b7a32609984b,DISK], DatanodeInfoWithStorage[127.0.0.1:39691,DS-cb4e4f70-6c29-45ed-bea6-6ac17d5f0b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-f5a4f929-2f5c-4a28-81d1-12354160a474,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-ccbc59de-ec66-4231-bc46-11983e5dcf39,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-e60a49cc-c477-4c65-acab-2da060cf1f17,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-69aa46ff-26ba-4625-a14d-b78a5f1620f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1468016597-172.17.0.21-1595919981043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44700,DS-44586f13-4585-49e6-b25f-a80db28739a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46424,DS-ee148cbd-62a9-4654-8557-742f639e6cff,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-69bb744b-2351-4b6a-91b0-b7a32609984b,DISK], DatanodeInfoWithStorage[127.0.0.1:39691,DS-cb4e4f70-6c29-45ed-bea6-6ac17d5f0b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-f5a4f929-2f5c-4a28-81d1-12354160a474,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-ccbc59de-ec66-4231-bc46-11983e5dcf39,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-e60a49cc-c477-4c65-acab-2da060cf1f17,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-69aa46ff-26ba-4625-a14d-b78a5f1620f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1216421053-172.17.0.21-1595920046777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46136,DS-67cd60fa-17b9-4e71-bf24-8b313993d4de,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-b6111398-9203-4899-8892-a1340bf82e49,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-8122861a-74e7-4d73-9ac5-3baf6abbe473,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-240fd1f5-511d-490a-b101-2b0bf60f0cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37547,DS-99561635-90ab-4d47-a47d-2fca30fe941b,DISK], DatanodeInfoWithStorage[127.0.0.1:45140,DS-a2185910-c74e-476d-9c8e-85870b0d1430,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-bd7b49cb-633b-40ae-ba13-874e6eab4ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-0866d5a1-9278-4c7d-aaea-b7e2e0452a3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1216421053-172.17.0.21-1595920046777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46136,DS-67cd60fa-17b9-4e71-bf24-8b313993d4de,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-b6111398-9203-4899-8892-a1340bf82e49,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-8122861a-74e7-4d73-9ac5-3baf6abbe473,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-240fd1f5-511d-490a-b101-2b0bf60f0cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37547,DS-99561635-90ab-4d47-a47d-2fca30fe941b,DISK], DatanodeInfoWithStorage[127.0.0.1:45140,DS-a2185910-c74e-476d-9c8e-85870b0d1430,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-bd7b49cb-633b-40ae-ba13-874e6eab4ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-0866d5a1-9278-4c7d-aaea-b7e2e0452a3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-754911721-172.17.0.21-1595920076970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46636,DS-0b2e30fa-925a-4527-9529-a8d433ef7667,DISK], DatanodeInfoWithStorage[127.0.0.1:44856,DS-5fdc54fe-6268-4d2d-9f27-4a5e0fdd858a,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-1f9ac09b-15d9-433c-b4c9-64e958cf2772,DISK], DatanodeInfoWithStorage[127.0.0.1:46323,DS-c1538107-5c56-47a8-9615-d2973b273d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-2349d3c8-a710-442e-9968-c845a19af85d,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-540b1656-92ea-451b-95a5-ad27c8a4c3af,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-d5cedd1e-7317-48c6-bfad-93d491646bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-4f372464-ae3d-4821-a132-e14ba1273ad5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-754911721-172.17.0.21-1595920076970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46636,DS-0b2e30fa-925a-4527-9529-a8d433ef7667,DISK], DatanodeInfoWithStorage[127.0.0.1:44856,DS-5fdc54fe-6268-4d2d-9f27-4a5e0fdd858a,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-1f9ac09b-15d9-433c-b4c9-64e958cf2772,DISK], DatanodeInfoWithStorage[127.0.0.1:46323,DS-c1538107-5c56-47a8-9615-d2973b273d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-2349d3c8-a710-442e-9968-c845a19af85d,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-540b1656-92ea-451b-95a5-ad27c8a4c3af,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-d5cedd1e-7317-48c6-bfad-93d491646bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-4f372464-ae3d-4821-a132-e14ba1273ad5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1445688332-172.17.0.21-1595920104726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43884,DS-dda4e9b1-ae01-474f-9631-5367c68f4087,DISK], DatanodeInfoWithStorage[127.0.0.1:45617,DS-21a08c87-fc0e-4327-aad6-58d505b30f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-fccd03d5-6e76-4146-a271-ebd13e7acc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-dad5884c-c8ac-41ce-bcee-e8ca37881f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-53466023-5dbe-4074-8925-b624c0a89592,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-a8853250-6493-479b-8874-fc92c68884fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41842,DS-84f03ac7-3389-40fa-96be-3081545d6535,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-cb64ad03-47f1-47bb-8c80-dd8d4e2f993e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1445688332-172.17.0.21-1595920104726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43884,DS-dda4e9b1-ae01-474f-9631-5367c68f4087,DISK], DatanodeInfoWithStorage[127.0.0.1:45617,DS-21a08c87-fc0e-4327-aad6-58d505b30f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-fccd03d5-6e76-4146-a271-ebd13e7acc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-dad5884c-c8ac-41ce-bcee-e8ca37881f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-53466023-5dbe-4074-8925-b624c0a89592,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-a8853250-6493-479b-8874-fc92c68884fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41842,DS-84f03ac7-3389-40fa-96be-3081545d6535,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-cb64ad03-47f1-47bb-8c80-dd8d4e2f993e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1914776497-172.17.0.21-1595920199753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35159,DS-0bb06d9f-b1a5-4f47-a95f-bcc74fc4af06,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-24363cac-d0a1-491a-be9e-25b5d1df1641,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-274bb242-11ed-474a-aab5-b7b34ade9405,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-87c6c8ef-a842-4d86-8a73-e823cd81b025,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-aad02b9d-3c9c-4595-a145-72df1999164a,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-68f9494f-9252-4d89-8526-3049679f2419,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-816b4c75-7bce-4909-a99a-8ee22db3ab74,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-caa4932b-4b16-4a06-8c3f-213a0a79cee3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1914776497-172.17.0.21-1595920199753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35159,DS-0bb06d9f-b1a5-4f47-a95f-bcc74fc4af06,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-24363cac-d0a1-491a-be9e-25b5d1df1641,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-274bb242-11ed-474a-aab5-b7b34ade9405,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-87c6c8ef-a842-4d86-8a73-e823cd81b025,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-aad02b9d-3c9c-4595-a145-72df1999164a,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-68f9494f-9252-4d89-8526-3049679f2419,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-816b4c75-7bce-4909-a99a-8ee22db3ab74,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-caa4932b-4b16-4a06-8c3f-213a0a79cee3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1339331161-172.17.0.21-1595920768757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43211,DS-a483e2b0-5bbf-4e0c-8b3c-3bfcf6392383,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-f3876dbc-e017-4310-b9c6-de90dc7885ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-485ea851-31a8-40cd-9f73-b90cceb2c9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-a9ffe409-66ec-4dc6-ad1f-6e0a9337aab9,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-e27972c2-e087-400d-b4ae-a66b643bfa1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-cab65281-ffcc-48dc-a54f-d7ed6e3ffba2,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-46d92ab0-c1e8-4007-969c-2a2488a00ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-16480bd8-dc3e-41d5-b6b8-cfec78a3edc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1339331161-172.17.0.21-1595920768757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43211,DS-a483e2b0-5bbf-4e0c-8b3c-3bfcf6392383,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-f3876dbc-e017-4310-b9c6-de90dc7885ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-485ea851-31a8-40cd-9f73-b90cceb2c9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-a9ffe409-66ec-4dc6-ad1f-6e0a9337aab9,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-e27972c2-e087-400d-b4ae-a66b643bfa1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-cab65281-ffcc-48dc-a54f-d7ed6e3ffba2,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-46d92ab0-c1e8-4007-969c-2a2488a00ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-16480bd8-dc3e-41d5-b6b8-cfec78a3edc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-243249566-172.17.0.21-1595920800223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39447,DS-b29546a2-df43-4c48-a579-404bff1a8013,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-bc8a667e-e8cd-4cc4-8078-87bc9b28ec24,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-4be08fa2-be45-4b8e-ad0c-01916aca43e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-2e641674-e371-4310-800a-549863d48e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-e6cb0e5f-bcea-4038-8b1b-5c130193d05b,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-cccbff1f-b7d8-49e1-a79a-bc3e34127ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-0ad0b36b-01ed-4cd0-8e83-77eada2acb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-f7a10bd8-7f89-42d3-bb90-8c4fb7307d6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-243249566-172.17.0.21-1595920800223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39447,DS-b29546a2-df43-4c48-a579-404bff1a8013,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-bc8a667e-e8cd-4cc4-8078-87bc9b28ec24,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-4be08fa2-be45-4b8e-ad0c-01916aca43e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-2e641674-e371-4310-800a-549863d48e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-e6cb0e5f-bcea-4038-8b1b-5c130193d05b,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-cccbff1f-b7d8-49e1-a79a-bc3e34127ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-0ad0b36b-01ed-4cd0-8e83-77eada2acb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-f7a10bd8-7f89-42d3-bb90-8c4fb7307d6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5140
