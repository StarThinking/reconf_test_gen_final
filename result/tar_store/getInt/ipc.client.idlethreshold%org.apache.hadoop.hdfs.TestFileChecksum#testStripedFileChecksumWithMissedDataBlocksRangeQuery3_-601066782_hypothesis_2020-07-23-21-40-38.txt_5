reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-242284227-172.17.0.16-1595541370622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33589,DS-37350e19-be4d-4eec-906f-d4ce03358183,DISK], DatanodeInfoWithStorage[127.0.0.1:38063,DS-03eaf60e-8e6c-44a2-b823-99a40428c566,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-ef0c6eb0-5b7e-4890-b0b3-7d8d180013e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-1e3c1d56-a4fc-4539-be6f-3da4f6749f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-16e07e80-0e4c-4fe2-b54f-720d03332e37,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-7d23bc29-3523-4540-87d3-a4a0657f307f,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-795c63d7-4606-449c-9a84-6d96dcae6dab,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-2003de45-e5d9-41f2-9bb9-1722b1cc97fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-242284227-172.17.0.16-1595541370622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33589,DS-37350e19-be4d-4eec-906f-d4ce03358183,DISK], DatanodeInfoWithStorage[127.0.0.1:38063,DS-03eaf60e-8e6c-44a2-b823-99a40428c566,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-ef0c6eb0-5b7e-4890-b0b3-7d8d180013e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-1e3c1d56-a4fc-4539-be6f-3da4f6749f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-16e07e80-0e4c-4fe2-b54f-720d03332e37,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-7d23bc29-3523-4540-87d3-a4a0657f307f,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-795c63d7-4606-449c-9a84-6d96dcae6dab,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-2003de45-e5d9-41f2-9bb9-1722b1cc97fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688247252-172.17.0.16-1595542185104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40773,DS-d6fc8637-4f54-4118-ab19-421f982bb722,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-84e7a18c-4452-4377-b223-32bff117d863,DISK], DatanodeInfoWithStorage[127.0.0.1:42427,DS-05ebb1aa-de70-4923-8434-c06b5d7157f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-647b31db-9443-4f71-8d8c-b6e228e947de,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-dfbbf1ed-9e00-45d8-b7c6-f07e8e212437,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-edd4f5eb-dced-49cd-9c27-90a724507e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-3fc60a07-7963-471a-afb9-5313ef51be92,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-28ec571b-869c-4100-83e2-6382482f9ca0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688247252-172.17.0.16-1595542185104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40773,DS-d6fc8637-4f54-4118-ab19-421f982bb722,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-84e7a18c-4452-4377-b223-32bff117d863,DISK], DatanodeInfoWithStorage[127.0.0.1:42427,DS-05ebb1aa-de70-4923-8434-c06b5d7157f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-647b31db-9443-4f71-8d8c-b6e228e947de,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-dfbbf1ed-9e00-45d8-b7c6-f07e8e212437,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-edd4f5eb-dced-49cd-9c27-90a724507e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-3fc60a07-7963-471a-afb9-5313ef51be92,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-28ec571b-869c-4100-83e2-6382482f9ca0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1056982896-172.17.0.16-1595542475469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44912,DS-4e51a381-5190-4296-8753-e5b687ef507a,DISK], DatanodeInfoWithStorage[127.0.0.1:44793,DS-13cdc0f0-0232-464e-bdae-c2530f99bc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-85bf17f9-ca0b-47e7-a6f3-4855c7c4aa42,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-2931f0b0-e2f8-46a9-ad12-39c1cbf5b187,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-d44b712c-e5a7-4813-9837-9ea4a74676c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-593e359c-3b35-486a-820b-a97cf782b821,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-1b01656a-ff81-480e-aa24-58f521fe73d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-00309131-8971-4ef6-adca-6e52e4364d03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1056982896-172.17.0.16-1595542475469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44912,DS-4e51a381-5190-4296-8753-e5b687ef507a,DISK], DatanodeInfoWithStorage[127.0.0.1:44793,DS-13cdc0f0-0232-464e-bdae-c2530f99bc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-85bf17f9-ca0b-47e7-a6f3-4855c7c4aa42,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-2931f0b0-e2f8-46a9-ad12-39c1cbf5b187,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-d44b712c-e5a7-4813-9837-9ea4a74676c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-593e359c-3b35-486a-820b-a97cf782b821,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-1b01656a-ff81-480e-aa24-58f521fe73d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-00309131-8971-4ef6-adca-6e52e4364d03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-789537355-172.17.0.16-1595542914573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44279,DS-6f0824aa-d6f3-4c08-99f2-56d4ab6dc638,DISK], DatanodeInfoWithStorage[127.0.0.1:34687,DS-3666c71d-6e73-41e0-afef-349f0f11f006,DISK], DatanodeInfoWithStorage[127.0.0.1:39712,DS-df547122-5528-4c7a-872a-7478a085f871,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-a1cd6e1b-413a-4502-b5bf-7884ba7124f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-1c059329-d8be-48b2-a32e-6a89cb32db0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-f64487d7-e0d9-4ccc-955b-9ea3c0b65f74,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-21a526b6-c2e8-4762-bda8-cf96b88e7cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-371f406d-5b0e-4dca-9e72-73ead6c8f5b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-789537355-172.17.0.16-1595542914573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44279,DS-6f0824aa-d6f3-4c08-99f2-56d4ab6dc638,DISK], DatanodeInfoWithStorage[127.0.0.1:34687,DS-3666c71d-6e73-41e0-afef-349f0f11f006,DISK], DatanodeInfoWithStorage[127.0.0.1:39712,DS-df547122-5528-4c7a-872a-7478a085f871,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-a1cd6e1b-413a-4502-b5bf-7884ba7124f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-1c059329-d8be-48b2-a32e-6a89cb32db0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-f64487d7-e0d9-4ccc-955b-9ea3c0b65f74,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-21a526b6-c2e8-4762-bda8-cf96b88e7cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-371f406d-5b0e-4dca-9e72-73ead6c8f5b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1263306968-172.17.0.16-1595543099084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37291,DS-4fbe8915-68c5-4185-b13b-9a69173dedc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-25585c8b-02e1-46ba-9865-ee86a6a35c70,DISK], DatanodeInfoWithStorage[127.0.0.1:42622,DS-03df7745-c20b-48c3-9e77-35b7f5706455,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-68518bf6-d38f-43bd-82c1-821b99b385b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-c03d187b-1ce1-4421-a2bd-40c5842e2902,DISK], DatanodeInfoWithStorage[127.0.0.1:44776,DS-c229ed22-3994-4fa2-b166-c66976db3265,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-47aafb93-b011-4edc-b581-62f700457ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:42154,DS-cf48e5ab-fa32-4f6f-adc9-789b79f52802,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1263306968-172.17.0.16-1595543099084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37291,DS-4fbe8915-68c5-4185-b13b-9a69173dedc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-25585c8b-02e1-46ba-9865-ee86a6a35c70,DISK], DatanodeInfoWithStorage[127.0.0.1:42622,DS-03df7745-c20b-48c3-9e77-35b7f5706455,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-68518bf6-d38f-43bd-82c1-821b99b385b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-c03d187b-1ce1-4421-a2bd-40c5842e2902,DISK], DatanodeInfoWithStorage[127.0.0.1:44776,DS-c229ed22-3994-4fa2-b166-c66976db3265,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-47aafb93-b011-4edc-b581-62f700457ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:42154,DS-cf48e5ab-fa32-4f6f-adc9-789b79f52802,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-7508368-172.17.0.16-1595543250664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34988,DS-262eafcc-b47b-4e25-8279-81e72a09758a,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-9e9f262b-9a4e-4948-9573-7737ce7ac43b,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-37282dc9-73c0-4e25-9610-542ad103d095,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-1d018715-6bd5-48e0-9112-a6dcdebe4b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-36a3335b-30d7-4cf2-b94e-e0c9258a77db,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-cb61285c-af1b-4d6a-bd8f-9f8c066aeaef,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-a09f56df-3e99-4c22-afae-5e0adfcd6c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-3966baa1-12af-4f0d-8934-ddd760dab4cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-7508368-172.17.0.16-1595543250664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34988,DS-262eafcc-b47b-4e25-8279-81e72a09758a,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-9e9f262b-9a4e-4948-9573-7737ce7ac43b,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-37282dc9-73c0-4e25-9610-542ad103d095,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-1d018715-6bd5-48e0-9112-a6dcdebe4b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-36a3335b-30d7-4cf2-b94e-e0c9258a77db,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-cb61285c-af1b-4d6a-bd8f-9f8c066aeaef,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-a09f56df-3e99-4c22-afae-5e0adfcd6c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-3966baa1-12af-4f0d-8934-ddd760dab4cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178911238-172.17.0.16-1595543439071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43961,DS-3920046d-3e47-4262-8a0c-a7e7f087fd6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41370,DS-162d00f1-aab0-429b-be07-1964362a6cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:34949,DS-dfb2ce4b-f0f4-4e4b-97c1-0122ba029deb,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-2677622d-b6b9-408e-ab4f-29013de7aa01,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-18ebd1c8-8cb2-4a8d-91a8-cbbb83eaf509,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-67efbb3f-cb4e-4411-805d-a60c3dc2f92d,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-b8207f33-4689-4ffe-bcac-93fbbd9ef25a,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-9233b1a5-ec99-4ad2-b1bf-a6bff3a363ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178911238-172.17.0.16-1595543439071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43961,DS-3920046d-3e47-4262-8a0c-a7e7f087fd6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41370,DS-162d00f1-aab0-429b-be07-1964362a6cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:34949,DS-dfb2ce4b-f0f4-4e4b-97c1-0122ba029deb,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-2677622d-b6b9-408e-ab4f-29013de7aa01,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-18ebd1c8-8cb2-4a8d-91a8-cbbb83eaf509,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-67efbb3f-cb4e-4411-805d-a60c3dc2f92d,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-b8207f33-4689-4ffe-bcac-93fbbd9ef25a,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-9233b1a5-ec99-4ad2-b1bf-a6bff3a363ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-465502204-172.17.0.16-1595543514324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37826,DS-cf1bed0a-af3c-4f0c-8c71-5d01096be989,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-3ae2fdf5-4cf2-4595-8406-c5d89273761f,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-471962f7-9b09-4b07-8bb9-43d71a3a095b,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-1df63aa7-28ea-44d9-9fbe-974745f5552c,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-ac2ee9ab-d321-472c-ad96-63210105f703,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-be4b920e-f4da-4f66-a3d5-acded3055b20,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-b8c382c6-df41-4ee1-9f1c-a53665bbdba4,DISK], DatanodeInfoWithStorage[127.0.0.1:38951,DS-0524f4c0-cec0-416f-9829-6e959417981e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-465502204-172.17.0.16-1595543514324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37826,DS-cf1bed0a-af3c-4f0c-8c71-5d01096be989,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-3ae2fdf5-4cf2-4595-8406-c5d89273761f,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-471962f7-9b09-4b07-8bb9-43d71a3a095b,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-1df63aa7-28ea-44d9-9fbe-974745f5552c,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-ac2ee9ab-d321-472c-ad96-63210105f703,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-be4b920e-f4da-4f66-a3d5-acded3055b20,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-b8c382c6-df41-4ee1-9f1c-a53665bbdba4,DISK], DatanodeInfoWithStorage[127.0.0.1:38951,DS-0524f4c0-cec0-416f-9829-6e959417981e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2144934430-172.17.0.16-1595544261158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32824,DS-5a015b1e-fb90-41fe-8de3-c5aad355d56f,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-6493a69a-3025-4625-b2ec-b4862e09f2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-145c534f-6608-40b1-b339-0509cac81630,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-d0800b5b-90ab-42a1-be91-5454cfe57a72,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-28a88ab6-5539-4804-9952-999a1cd01b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-52317cc0-706e-4805-b938-62ff1a44a318,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-bdeb97b0-f2e9-4f2f-b12b-a930c75c40d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-c83dd7fa-a6bc-4a6c-94aa-b098f042722e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2144934430-172.17.0.16-1595544261158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32824,DS-5a015b1e-fb90-41fe-8de3-c5aad355d56f,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-6493a69a-3025-4625-b2ec-b4862e09f2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-145c534f-6608-40b1-b339-0509cac81630,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-d0800b5b-90ab-42a1-be91-5454cfe57a72,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-28a88ab6-5539-4804-9952-999a1cd01b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-52317cc0-706e-4805-b938-62ff1a44a318,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-bdeb97b0-f2e9-4f2f-b12b-a930c75c40d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-c83dd7fa-a6bc-4a6c-94aa-b098f042722e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-145540906-172.17.0.16-1595544521392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35663,DS-d23f0d4e-3dd5-4eb7-bca8-6ed5e3050625,DISK], DatanodeInfoWithStorage[127.0.0.1:40313,DS-458ab64d-4902-4675-8ea0-a547dfa61e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-9d1315c7-79c6-4218-bb89-8af146b2adf5,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-ded2dae3-8696-49d1-9d6b-17be38a74753,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-5aefd119-3f92-4548-9423-a627ba55c1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45905,DS-4edd009a-4250-4161-a1b2-7ed3e71421f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44564,DS-98bf9765-5c62-4d72-88ad-accb5c9a00ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-41a6f116-000f-4b97-84a7-d092b95cc260,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-145540906-172.17.0.16-1595544521392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35663,DS-d23f0d4e-3dd5-4eb7-bca8-6ed5e3050625,DISK], DatanodeInfoWithStorage[127.0.0.1:40313,DS-458ab64d-4902-4675-8ea0-a547dfa61e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-9d1315c7-79c6-4218-bb89-8af146b2adf5,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-ded2dae3-8696-49d1-9d6b-17be38a74753,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-5aefd119-3f92-4548-9423-a627ba55c1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45905,DS-4edd009a-4250-4161-a1b2-7ed3e71421f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44564,DS-98bf9765-5c62-4d72-88ad-accb5c9a00ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-41a6f116-000f-4b97-84a7-d092b95cc260,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2138835901-172.17.0.16-1595544817417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37463,DS-762dfd78-d427-4211-8bae-b013e6af0016,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-6bad66b3-dfd8-438e-861e-f91ccbd35ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:44809,DS-0465fd16-f706-40ac-bff0-e77ffcdabc29,DISK], DatanodeInfoWithStorage[127.0.0.1:42810,DS-f2d5caa8-8270-402e-b234-f320a40b33c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-576b2b77-2f92-453f-9566-d5c10c7ceb61,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-d92dc190-e529-4e88-b852-651127895c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45870,DS-3e2fd4a7-a770-4f53-8314-c2ba6968a445,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-4295ec39-a0cf-4b06-8183-7a657989bdf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2138835901-172.17.0.16-1595544817417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37463,DS-762dfd78-d427-4211-8bae-b013e6af0016,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-6bad66b3-dfd8-438e-861e-f91ccbd35ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:44809,DS-0465fd16-f706-40ac-bff0-e77ffcdabc29,DISK], DatanodeInfoWithStorage[127.0.0.1:42810,DS-f2d5caa8-8270-402e-b234-f320a40b33c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-576b2b77-2f92-453f-9566-d5c10c7ceb61,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-d92dc190-e529-4e88-b852-651127895c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45870,DS-3e2fd4a7-a770-4f53-8314-c2ba6968a445,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-4295ec39-a0cf-4b06-8183-7a657989bdf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1037481678-172.17.0.16-1595544859840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44652,DS-0f220f25-27ef-40b0-abfd-82b25b4da6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-d4ca3290-bba9-4342-a354-999a4fd9b341,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-a517f97a-3b8e-4e3e-bdb0-0fdc532c0b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-92684aea-5a33-46a9-b312-203f9c5f9775,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-2f31ff85-d705-46b6-8af8-cc4ff606c342,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-49e93d78-d22e-42d0-8779-7305336865b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-6298d7a5-b465-4baa-be2a-40efd80b2c60,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-1d4d7e39-af19-4249-81d2-4c392f3a89c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1037481678-172.17.0.16-1595544859840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44652,DS-0f220f25-27ef-40b0-abfd-82b25b4da6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-d4ca3290-bba9-4342-a354-999a4fd9b341,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-a517f97a-3b8e-4e3e-bdb0-0fdc532c0b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-92684aea-5a33-46a9-b312-203f9c5f9775,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-2f31ff85-d705-46b6-8af8-cc4ff606c342,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-49e93d78-d22e-42d0-8779-7305336865b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-6298d7a5-b465-4baa-be2a-40efd80b2c60,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-1d4d7e39-af19-4249-81d2-4c392f3a89c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-694403181-172.17.0.16-1595545351058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33739,DS-2abef0df-2292-4453-bae1-002612277a19,DISK], DatanodeInfoWithStorage[127.0.0.1:41963,DS-ab51fe73-0272-4681-8cc7-85d09224cd54,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-07613329-9de9-4736-b08a-774ab4c2736f,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-1591699d-c42c-467e-9fe5-a3b622229169,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-c6b53054-2bbe-4918-a9ad-6bc6c23c7fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:35156,DS-dfaf7484-6d46-4c17-a4b6-918508c2db07,DISK], DatanodeInfoWithStorage[127.0.0.1:38947,DS-8df94f52-6565-474e-ad47-672dce0e2601,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-4efc6f15-49df-4541-a136-eb077fbc4339,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-694403181-172.17.0.16-1595545351058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33739,DS-2abef0df-2292-4453-bae1-002612277a19,DISK], DatanodeInfoWithStorage[127.0.0.1:41963,DS-ab51fe73-0272-4681-8cc7-85d09224cd54,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-07613329-9de9-4736-b08a-774ab4c2736f,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-1591699d-c42c-467e-9fe5-a3b622229169,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-c6b53054-2bbe-4918-a9ad-6bc6c23c7fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:35156,DS-dfaf7484-6d46-4c17-a4b6-918508c2db07,DISK], DatanodeInfoWithStorage[127.0.0.1:38947,DS-8df94f52-6565-474e-ad47-672dce0e2601,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-4efc6f15-49df-4541-a136-eb077fbc4339,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-824140782-172.17.0.16-1595545466802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43416,DS-26a3400b-cef5-4660-b753-3c4a82956992,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-4d237854-95dc-4bd6-9b9b-f1a90664528e,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-e128b4f2-05ba-4695-a628-f393bdfc856d,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-d714356f-c874-4500-8ba1-6a242a35f5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-e0668795-e747-41b6-9cda-7a18606db8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37411,DS-8d38a6d2-61e2-4f6a-9cfd-8801534a4409,DISK], DatanodeInfoWithStorage[127.0.0.1:39011,DS-76ec7b44-7280-465d-b868-df14de4a4390,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-12762808-da0a-48ef-a3e5-a60bb1ac730b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-824140782-172.17.0.16-1595545466802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43416,DS-26a3400b-cef5-4660-b753-3c4a82956992,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-4d237854-95dc-4bd6-9b9b-f1a90664528e,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-e128b4f2-05ba-4695-a628-f393bdfc856d,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-d714356f-c874-4500-8ba1-6a242a35f5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-e0668795-e747-41b6-9cda-7a18606db8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37411,DS-8d38a6d2-61e2-4f6a-9cfd-8801534a4409,DISK], DatanodeInfoWithStorage[127.0.0.1:39011,DS-76ec7b44-7280-465d-b868-df14de4a4390,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-12762808-da0a-48ef-a3e5-a60bb1ac730b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5534
