reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2036832439-172.17.0.2-1596028272745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40208,DS-7c839f5d-363c-40d0-b443-330afc48f2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-2d411744-42fe-4674-8356-35dd97cc604c,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-17cd6cd9-c60d-45be-a83d-66578022fc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-ca21d364-c029-4654-878c-62e430a3aac2,DISK], DatanodeInfoWithStorage[127.0.0.1:37807,DS-76f70fd2-ce26-47a2-b825-2a61199e7b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-ec261f41-a4b2-41d9-a0d5-71733ac12fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-1094147c-e2c3-430a-97f6-8cd477aca3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-eb2cfd6a-c607-456a-8468-09b4bc833f57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2036832439-172.17.0.2-1596028272745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40208,DS-7c839f5d-363c-40d0-b443-330afc48f2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-2d411744-42fe-4674-8356-35dd97cc604c,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-17cd6cd9-c60d-45be-a83d-66578022fc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-ca21d364-c029-4654-878c-62e430a3aac2,DISK], DatanodeInfoWithStorage[127.0.0.1:37807,DS-76f70fd2-ce26-47a2-b825-2a61199e7b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-ec261f41-a4b2-41d9-a0d5-71733ac12fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-1094147c-e2c3-430a-97f6-8cd477aca3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-eb2cfd6a-c607-456a-8468-09b4bc833f57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-538836647-172.17.0.2-1596028446265:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40511,DS-f19314c0-bcd3-4215-831a-dd3626c23979,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-148a507e-4a5f-43b1-9f48-682901362fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-34620936-5d97-4ebf-894b-7d92f4a3cf24,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-72381e75-642a-49ce-81a2-32b03aa0119b,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-301f2235-bd54-4a0b-9b06-c880fc5fb2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-3eb23e15-4840-4e46-b3b3-1d548eef7598,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-feb7c478-9ce2-4793-a2c6-c0afc1fca801,DISK], DatanodeInfoWithStorage[127.0.0.1:44600,DS-98e44b32-3b46-457d-871a-04d63c645136,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-538836647-172.17.0.2-1596028446265:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40511,DS-f19314c0-bcd3-4215-831a-dd3626c23979,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-148a507e-4a5f-43b1-9f48-682901362fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-34620936-5d97-4ebf-894b-7d92f4a3cf24,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-72381e75-642a-49ce-81a2-32b03aa0119b,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-301f2235-bd54-4a0b-9b06-c880fc5fb2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-3eb23e15-4840-4e46-b3b3-1d548eef7598,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-feb7c478-9ce2-4793-a2c6-c0afc1fca801,DISK], DatanodeInfoWithStorage[127.0.0.1:44600,DS-98e44b32-3b46-457d-871a-04d63c645136,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-967109759-172.17.0.2-1596029035421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36903,DS-9443616e-45b2-46f9-b9a8-3fb75703ad2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-587a4678-4f72-418c-9517-cbd3a616150b,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-4a38dcde-0367-4f15-adb4-2996f7721a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37207,DS-d90e1556-e290-400c-9657-5486a9ddb1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-fed72695-5d11-4234-90cc-458fb9186e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-bf58b77d-c5a4-4a9f-a5c9-b0640ce2b90d,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-ffc5ea66-e83f-41a0-b15f-92a952c73dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-85ea4ac3-ef81-485b-908a-bac0d734fc6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-967109759-172.17.0.2-1596029035421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36903,DS-9443616e-45b2-46f9-b9a8-3fb75703ad2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-587a4678-4f72-418c-9517-cbd3a616150b,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-4a38dcde-0367-4f15-adb4-2996f7721a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37207,DS-d90e1556-e290-400c-9657-5486a9ddb1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-fed72695-5d11-4234-90cc-458fb9186e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-bf58b77d-c5a4-4a9f-a5c9-b0640ce2b90d,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-ffc5ea66-e83f-41a0-b15f-92a952c73dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-85ea4ac3-ef81-485b-908a-bac0d734fc6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1910341004-172.17.0.2-1596029172570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46780,DS-23627494-892a-4af3-b7ca-6a968fb3ea9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-d0643a75-6d05-4344-b94e-62e701554b82,DISK], DatanodeInfoWithStorage[127.0.0.1:38047,DS-0121811c-1ee7-450b-a71d-fd74e50e6a94,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-32fb4382-3686-4a9b-b2a6-841fccd3d406,DISK], DatanodeInfoWithStorage[127.0.0.1:46844,DS-0b1b9b3d-8e8c-438b-8bde-2daaca8365c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-edcdd83a-d25d-46c0-a24b-585861d926bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-c7a736e6-e4e0-443b-a83d-517ba42dbd32,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-f209c246-b3f7-483c-a035-c6f6a4235c43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1910341004-172.17.0.2-1596029172570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46780,DS-23627494-892a-4af3-b7ca-6a968fb3ea9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-d0643a75-6d05-4344-b94e-62e701554b82,DISK], DatanodeInfoWithStorage[127.0.0.1:38047,DS-0121811c-1ee7-450b-a71d-fd74e50e6a94,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-32fb4382-3686-4a9b-b2a6-841fccd3d406,DISK], DatanodeInfoWithStorage[127.0.0.1:46844,DS-0b1b9b3d-8e8c-438b-8bde-2daaca8365c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-edcdd83a-d25d-46c0-a24b-585861d926bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-c7a736e6-e4e0-443b-a83d-517ba42dbd32,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-f209c246-b3f7-483c-a035-c6f6a4235c43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-8501485-172.17.0.2-1596029223044:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45338,DS-88329b70-92e5-4448-997f-9fdf4bfd018e,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-0bd74993-6678-414b-9f59-6cfd982b6116,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-d2287033-b549-40e0-ba19-cc0144231be2,DISK], DatanodeInfoWithStorage[127.0.0.1:46750,DS-7dd7c279-1ef8-4520-9961-91ffa0aad4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-03a2799a-7b2a-4da1-91db-ecebbde1e6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-634ebda4-a875-44c9-9c7a-037c6294e463,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-dedd46c7-159e-4e24-b09c-d37c6646a05b,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-a4af26a8-f6d1-42c5-9d71-840fdfb7cbcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-8501485-172.17.0.2-1596029223044:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45338,DS-88329b70-92e5-4448-997f-9fdf4bfd018e,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-0bd74993-6678-414b-9f59-6cfd982b6116,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-d2287033-b549-40e0-ba19-cc0144231be2,DISK], DatanodeInfoWithStorage[127.0.0.1:46750,DS-7dd7c279-1ef8-4520-9961-91ffa0aad4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-03a2799a-7b2a-4da1-91db-ecebbde1e6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-634ebda4-a875-44c9-9c7a-037c6294e463,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-dedd46c7-159e-4e24-b09c-d37c6646a05b,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-a4af26a8-f6d1-42c5-9d71-840fdfb7cbcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-25454434-172.17.0.2-1596029358579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33223,DS-e1513dee-0ea5-4cb6-9cee-736d87efc497,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-b7579470-66f4-48db-b8e3-ea29036804a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38900,DS-4afe9104-c20c-4950-9c13-af88f6f9bf02,DISK], DatanodeInfoWithStorage[127.0.0.1:41910,DS-841428b9-1bae-47d3-b313-efbffd197d68,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-4d9548f0-e92d-4fd7-b253-b44ba21717f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-9712b5bf-f7f4-42a1-aa82-9f3bed26bc02,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-1e4c9fa1-a6d9-470f-a391-1c4e3d80e02e,DISK], DatanodeInfoWithStorage[127.0.0.1:40906,DS-d37e7303-d7d6-493a-acea-141b4f77a7f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-25454434-172.17.0.2-1596029358579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33223,DS-e1513dee-0ea5-4cb6-9cee-736d87efc497,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-b7579470-66f4-48db-b8e3-ea29036804a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38900,DS-4afe9104-c20c-4950-9c13-af88f6f9bf02,DISK], DatanodeInfoWithStorage[127.0.0.1:41910,DS-841428b9-1bae-47d3-b313-efbffd197d68,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-4d9548f0-e92d-4fd7-b253-b44ba21717f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-9712b5bf-f7f4-42a1-aa82-9f3bed26bc02,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-1e4c9fa1-a6d9-470f-a391-1c4e3d80e02e,DISK], DatanodeInfoWithStorage[127.0.0.1:40906,DS-d37e7303-d7d6-493a-acea-141b4f77a7f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-635792030-172.17.0.2-1596029497754:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38970,DS-8047f3d0-d1db-4b5a-9d66-aed5736b442e,DISK], DatanodeInfoWithStorage[127.0.0.1:42340,DS-c2e9d875-7373-4083-a0d1-430d11f37575,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-99bb463f-b67a-4d6e-a853-6b7c16cd7ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-603f989d-b4cd-46f1-a80f-02650372639b,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-435ead75-475f-4a45-9908-7461713a56b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-12dac8c0-aa43-4eeb-a1e4-ad093130f58b,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-b50ce6ed-51ba-40cf-9ba5-6a18e7610f05,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-9f0c42b3-a9eb-4bd6-aa3c-b2667a0db886,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-635792030-172.17.0.2-1596029497754:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38970,DS-8047f3d0-d1db-4b5a-9d66-aed5736b442e,DISK], DatanodeInfoWithStorage[127.0.0.1:42340,DS-c2e9d875-7373-4083-a0d1-430d11f37575,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-99bb463f-b67a-4d6e-a853-6b7c16cd7ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-603f989d-b4cd-46f1-a80f-02650372639b,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-435ead75-475f-4a45-9908-7461713a56b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-12dac8c0-aa43-4eeb-a1e4-ad093130f58b,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-b50ce6ed-51ba-40cf-9ba5-6a18e7610f05,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-9f0c42b3-a9eb-4bd6-aa3c-b2667a0db886,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1144318675-172.17.0.2-1596029807884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40457,DS-af4eef6f-451b-4a3f-a987-3fcf5475e1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-ec303259-b4ea-44ab-9f4f-d950a0eaf688,DISK], DatanodeInfoWithStorage[127.0.0.1:41344,DS-74b22384-35ef-4743-af3c-b2eb159c5d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-f6d8aa8b-3f0d-4f72-ac4e-fe4996d0c2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42937,DS-4920cbae-8c0f-4fb5-9a05-89d4e00fc2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-c51b094c-b106-4f14-9275-b2db466b42e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-b801649a-5bcf-40db-9a4a-2cca31792fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-067bf9a3-7290-430e-bd32-3ad40f1389ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1144318675-172.17.0.2-1596029807884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40457,DS-af4eef6f-451b-4a3f-a987-3fcf5475e1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-ec303259-b4ea-44ab-9f4f-d950a0eaf688,DISK], DatanodeInfoWithStorage[127.0.0.1:41344,DS-74b22384-35ef-4743-af3c-b2eb159c5d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-f6d8aa8b-3f0d-4f72-ac4e-fe4996d0c2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42937,DS-4920cbae-8c0f-4fb5-9a05-89d4e00fc2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-c51b094c-b106-4f14-9275-b2db466b42e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-b801649a-5bcf-40db-9a4a-2cca31792fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-067bf9a3-7290-430e-bd32-3ad40f1389ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2078769255-172.17.0.2-1596030783418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33187,DS-07542a57-7ed2-4daf-92f3-4bb9f689fae9,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-58f2695c-4abb-4400-8c4f-28c0df9fe546,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-6a600e53-6732-4ea9-9b14-46a369071373,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-a11d7d87-1967-4db7-8030-4854d3443f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-013f2cd0-46ee-473d-831f-8e66c49bf2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-23a2ace6-901b-4923-b97d-06a840646f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-a58a3b47-f336-448b-8127-6f08fb27ae45,DISK], DatanodeInfoWithStorage[127.0.0.1:37876,DS-88f5c61e-0c27-446f-bbb8-5851424baad6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2078769255-172.17.0.2-1596030783418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33187,DS-07542a57-7ed2-4daf-92f3-4bb9f689fae9,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-58f2695c-4abb-4400-8c4f-28c0df9fe546,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-6a600e53-6732-4ea9-9b14-46a369071373,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-a11d7d87-1967-4db7-8030-4854d3443f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-013f2cd0-46ee-473d-831f-8e66c49bf2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-23a2ace6-901b-4923-b97d-06a840646f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-a58a3b47-f336-448b-8127-6f08fb27ae45,DISK], DatanodeInfoWithStorage[127.0.0.1:37876,DS-88f5c61e-0c27-446f-bbb8-5851424baad6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-165596264-172.17.0.2-1596031196523:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33932,DS-1780b7eb-fce4-4ccb-b3da-fac1628510ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-c31398f2-66ea-40b7-964c-5ecc481e4289,DISK], DatanodeInfoWithStorage[127.0.0.1:36796,DS-e12b2d2f-14b6-4a7b-b186-2ec59f322ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:38126,DS-40aa9940-89fa-4c9c-9629-eed17646f1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40940,DS-1ca9a9a2-214c-4451-a5f3-8dc347d1c62a,DISK], DatanodeInfoWithStorage[127.0.0.1:41610,DS-c80824e6-0640-42cf-9fb5-c012864f8d30,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-58f955c3-67e8-4076-b2ac-e6f4af0a249e,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-a28fc422-723a-49b0-8f63-4ec09904c896,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-165596264-172.17.0.2-1596031196523:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33932,DS-1780b7eb-fce4-4ccb-b3da-fac1628510ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-c31398f2-66ea-40b7-964c-5ecc481e4289,DISK], DatanodeInfoWithStorage[127.0.0.1:36796,DS-e12b2d2f-14b6-4a7b-b186-2ec59f322ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:38126,DS-40aa9940-89fa-4c9c-9629-eed17646f1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40940,DS-1ca9a9a2-214c-4451-a5f3-8dc347d1c62a,DISK], DatanodeInfoWithStorage[127.0.0.1:41610,DS-c80824e6-0640-42cf-9fb5-c012864f8d30,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-58f955c3-67e8-4076-b2ac-e6f4af0a249e,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-a28fc422-723a-49b0-8f63-4ec09904c896,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-303828796-172.17.0.2-1596031329499:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44422,DS-2104c605-4a49-4e16-b977-ede1cdcac580,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-bcf4297a-d0ed-428a-b81a-68390d8d646e,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-0d6273ab-3958-42fa-b373-fe21e99a6109,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-6df30249-7c28-4af5-bf74-037e5cca99aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-3240b9a1-008d-46f9-bd96-54a6c957a02d,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-413a32fb-4fbe-4d62-9fe7-eda345853c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-a2b18114-2e4a-40ac-aeeb-5cd725dced00,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-ae26c5f2-d9a0-45a4-a523-84c6be02d205,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-303828796-172.17.0.2-1596031329499:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44422,DS-2104c605-4a49-4e16-b977-ede1cdcac580,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-bcf4297a-d0ed-428a-b81a-68390d8d646e,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-0d6273ab-3958-42fa-b373-fe21e99a6109,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-6df30249-7c28-4af5-bf74-037e5cca99aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-3240b9a1-008d-46f9-bd96-54a6c957a02d,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-413a32fb-4fbe-4d62-9fe7-eda345853c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-a2b18114-2e4a-40ac-aeeb-5cd725dced00,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-ae26c5f2-d9a0-45a4-a523-84c6be02d205,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1212957379-172.17.0.2-1596032501020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44646,DS-df1075ab-dd12-4df7-9f19-ddfda4c9728d,DISK], DatanodeInfoWithStorage[127.0.0.1:39102,DS-52abc9b1-83b0-4aa8-8380-9c429db0a679,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-df624a34-b0f2-44ef-84e5-0643df07dbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-e9a938b5-88eb-4a92-a159-209e87ddc42f,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-9fc9dd86-355f-4b8c-8da4-2395c6abc7af,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-bbe247a6-5be3-4a1d-97e8-d429af81c167,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-f7d62d82-b018-4b40-8559-dd23c69c5210,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-5a3f7cdb-0623-4c80-abe1-b8531f8ee750,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1212957379-172.17.0.2-1596032501020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44646,DS-df1075ab-dd12-4df7-9f19-ddfda4c9728d,DISK], DatanodeInfoWithStorage[127.0.0.1:39102,DS-52abc9b1-83b0-4aa8-8380-9c429db0a679,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-df624a34-b0f2-44ef-84e5-0643df07dbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-e9a938b5-88eb-4a92-a159-209e87ddc42f,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-9fc9dd86-355f-4b8c-8da4-2395c6abc7af,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-bbe247a6-5be3-4a1d-97e8-d429af81c167,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-f7d62d82-b018-4b40-8559-dd23c69c5210,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-5a3f7cdb-0623-4c80-abe1-b8531f8ee750,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-26960506-172.17.0.2-1596033213767:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36478,DS-9ec27eef-0fbb-4490-ba69-6f7fda687dec,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-a5934101-b11f-4dbe-809e-ae29e58e70b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-83a4fcfd-bf0f-4474-a47f-e18ff58cc34b,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-ecf59473-b002-46dc-9187-a6272e8c030f,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-edb9331d-34e9-4ae2-bcc6-61f2f9a82ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-2f1df7dc-700e-48a5-972a-a94f733a072c,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-3a4de5e2-d47e-43a6-912d-bc6ed763da6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-46834cdc-001a-44ae-932d-0cbe42de2211,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-26960506-172.17.0.2-1596033213767:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36478,DS-9ec27eef-0fbb-4490-ba69-6f7fda687dec,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-a5934101-b11f-4dbe-809e-ae29e58e70b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-83a4fcfd-bf0f-4474-a47f-e18ff58cc34b,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-ecf59473-b002-46dc-9187-a6272e8c030f,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-edb9331d-34e9-4ae2-bcc6-61f2f9a82ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-2f1df7dc-700e-48a5-972a-a94f733a072c,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-3a4de5e2-d47e-43a6-912d-bc6ed763da6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-46834cdc-001a-44ae-932d-0cbe42de2211,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-60490097-172.17.0.2-1596033636690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36702,DS-ca207b73-1d99-41af-b9b2-e7d5061b00c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-ff6bbd66-60c7-447b-9b2e-deb03502997e,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-68356b42-52ec-4041-a56f-af59b1762c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-146588de-68f4-4f1c-8d5c-01f434aa3b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-b434e701-7f08-46a1-99ea-4b59deaee82e,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-0b8b46e8-2c25-4be2-ad88-c2fd9543cde9,DISK], DatanodeInfoWithStorage[127.0.0.1:32954,DS-a45ea826-1380-4e21-9b13-1a7c5d085e62,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-306a96a5-4d26-4473-8230-c3d643094cd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-60490097-172.17.0.2-1596033636690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36702,DS-ca207b73-1d99-41af-b9b2-e7d5061b00c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-ff6bbd66-60c7-447b-9b2e-deb03502997e,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-68356b42-52ec-4041-a56f-af59b1762c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-146588de-68f4-4f1c-8d5c-01f434aa3b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-b434e701-7f08-46a1-99ea-4b59deaee82e,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-0b8b46e8-2c25-4be2-ad88-c2fd9543cde9,DISK], DatanodeInfoWithStorage[127.0.0.1:32954,DS-a45ea826-1380-4e21-9b13-1a7c5d085e62,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-306a96a5-4d26-4473-8230-c3d643094cd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-743595863-172.17.0.2-1596034092902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38889,DS-ae4ebb8a-d8a8-4398-9332-21f95043b328,DISK], DatanodeInfoWithStorage[127.0.0.1:41033,DS-d4a8b318-2ccb-4621-9302-937f93bbf8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45532,DS-1db57971-e4e6-47bc-86c5-4e89d2e4943c,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-d0daf625-055e-4e08-b9f1-74ac729a05dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-8bc15461-8c28-4285-92ea-ede7a9907c89,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-fcaff8e8-65ca-45f3-b2e2-8c4eb4649695,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-20d57425-1e4c-4ce5-b9d9-a895140976cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-61ef53cb-e6f2-4a59-ab95-34fb1e6893f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-743595863-172.17.0.2-1596034092902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38889,DS-ae4ebb8a-d8a8-4398-9332-21f95043b328,DISK], DatanodeInfoWithStorage[127.0.0.1:41033,DS-d4a8b318-2ccb-4621-9302-937f93bbf8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45532,DS-1db57971-e4e6-47bc-86c5-4e89d2e4943c,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-d0daf625-055e-4e08-b9f1-74ac729a05dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-8bc15461-8c28-4285-92ea-ede7a9907c89,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-fcaff8e8-65ca-45f3-b2e2-8c4eb4649695,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-20d57425-1e4c-4ce5-b9d9-a895140976cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-61ef53cb-e6f2-4a59-ab95-34fb1e6893f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1585983055-172.17.0.2-1596034825991:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34406,DS-d3e72a7e-af7d-41a2-b6b3-20614fe4395f,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-73fdac09-1ef5-4054-adcf-933e598dbf48,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-4e475f75-7909-4eae-b054-bcee0b174864,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-025eb5ba-2c65-4c33-8dce-ab0daedf22ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-8375ca85-8a44-4f50-80ed-28586cbee764,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-86ff43e1-6da7-4fa5-8201-9fcfb656985f,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-6a7b179c-c413-439f-99e3-e07322c069cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-f7eeebbb-e07f-47e6-87e9-8172c1ba0a1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1585983055-172.17.0.2-1596034825991:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34406,DS-d3e72a7e-af7d-41a2-b6b3-20614fe4395f,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-73fdac09-1ef5-4054-adcf-933e598dbf48,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-4e475f75-7909-4eae-b054-bcee0b174864,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-025eb5ba-2c65-4c33-8dce-ab0daedf22ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-8375ca85-8a44-4f50-80ed-28586cbee764,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-86ff43e1-6da7-4fa5-8201-9fcfb656985f,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-6a7b179c-c413-439f-99e3-e07322c069cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-f7eeebbb-e07f-47e6-87e9-8172c1ba0a1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6836
