reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-737326738-172.17.0.14-1595832534899:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36309,DS-e2c72b56-a82b-4396-83b5-fbd872442d14,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-b9fb8bae-84e2-4f96-84f0-7df33b6f3f62,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-2240cde5-c58e-4640-b3ad-0822feea0db7,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-10cbd9bb-3647-4180-b566-d80f1f1e458c,DISK], DatanodeInfoWithStorage[127.0.0.1:42923,DS-fd31e135-2a4d-42e6-af3f-91072c8410f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-4eda3221-22e9-4920-9f3b-23369e2bf9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-6ebe5487-8074-44a7-9fc9-2484664f286c,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-52a3f4ca-665a-405d-b59b-9bf29b18e1e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-737326738-172.17.0.14-1595832534899:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36309,DS-e2c72b56-a82b-4396-83b5-fbd872442d14,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-b9fb8bae-84e2-4f96-84f0-7df33b6f3f62,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-2240cde5-c58e-4640-b3ad-0822feea0db7,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-10cbd9bb-3647-4180-b566-d80f1f1e458c,DISK], DatanodeInfoWithStorage[127.0.0.1:42923,DS-fd31e135-2a4d-42e6-af3f-91072c8410f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-4eda3221-22e9-4920-9f3b-23369e2bf9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-6ebe5487-8074-44a7-9fc9-2484664f286c,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-52a3f4ca-665a-405d-b59b-9bf29b18e1e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-675254065-172.17.0.14-1595833136133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46128,DS-e57ab58c-ca13-4413-8e5c-98ade490b657,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-e0520ef4-1266-458d-b092-d7ce819e7ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-1e4176cc-30d7-4982-9967-f8f13bdfa1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-5f159690-32f0-4577-a709-6f72b5ca5daa,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-da79d6ee-e0f8-40e1-8cd5-9cd600d6b46b,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-ce669ed6-75b9-44ea-acf3-24fe7b2f2a39,DISK], DatanodeInfoWithStorage[127.0.0.1:40434,DS-569cade2-d67c-4756-9a50-682e5c46c0da,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-597a2fad-df8e-40ab-9e43-55475ce443cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-675254065-172.17.0.14-1595833136133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46128,DS-e57ab58c-ca13-4413-8e5c-98ade490b657,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-e0520ef4-1266-458d-b092-d7ce819e7ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-1e4176cc-30d7-4982-9967-f8f13bdfa1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-5f159690-32f0-4577-a709-6f72b5ca5daa,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-da79d6ee-e0f8-40e1-8cd5-9cd600d6b46b,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-ce669ed6-75b9-44ea-acf3-24fe7b2f2a39,DISK], DatanodeInfoWithStorage[127.0.0.1:40434,DS-569cade2-d67c-4756-9a50-682e5c46c0da,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-597a2fad-df8e-40ab-9e43-55475ce443cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1735495480-172.17.0.14-1595833515522:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40435,DS-8de81d72-ba90-44b0-bab9-dcfefc08c8be,DISK], DatanodeInfoWithStorage[127.0.0.1:42312,DS-99ff07ca-4122-4e5c-bed7-8959cda60158,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-b34038b6-03ac-4b00-8088-14842566d57d,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-a622916b-d9a3-4b11-a65b-1f84c45c11e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-f0ede84c-3a45-4d16-8e0d-47e1acc12fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-b3147c50-8b0e-438e-8be5-af1f502f62ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-51d84c6e-737a-4857-bf73-99af1d3f8a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-bbd71605-ff1c-401f-8019-1575f7b0cfad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1735495480-172.17.0.14-1595833515522:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40435,DS-8de81d72-ba90-44b0-bab9-dcfefc08c8be,DISK], DatanodeInfoWithStorage[127.0.0.1:42312,DS-99ff07ca-4122-4e5c-bed7-8959cda60158,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-b34038b6-03ac-4b00-8088-14842566d57d,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-a622916b-d9a3-4b11-a65b-1f84c45c11e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-f0ede84c-3a45-4d16-8e0d-47e1acc12fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-b3147c50-8b0e-438e-8be5-af1f502f62ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-51d84c6e-737a-4857-bf73-99af1d3f8a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-bbd71605-ff1c-401f-8019-1575f7b0cfad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-132982582-172.17.0.14-1595833637236:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40054,DS-fb3985c8-8084-4a67-bde7-bda13c7f8863,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-225d41d0-fc22-4004-8e94-a9dce8b285d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-89876495-3030-43fa-81f9-94cb4f49602d,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-7b950e3e-0f73-4771-a214-826e5078509a,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-f3c2f324-4600-4382-863a-b64b010319a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-d5a9a4c3-f7d2-494b-8f70-711b4d395d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-d24e8f90-d278-4401-8f4a-82deb40bae04,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-cc6aee89-2f57-4678-a598-970385f35b27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-132982582-172.17.0.14-1595833637236:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40054,DS-fb3985c8-8084-4a67-bde7-bda13c7f8863,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-225d41d0-fc22-4004-8e94-a9dce8b285d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-89876495-3030-43fa-81f9-94cb4f49602d,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-7b950e3e-0f73-4771-a214-826e5078509a,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-f3c2f324-4600-4382-863a-b64b010319a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-d5a9a4c3-f7d2-494b-8f70-711b4d395d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-d24e8f90-d278-4401-8f4a-82deb40bae04,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-cc6aee89-2f57-4678-a598-970385f35b27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1027489458-172.17.0.14-1595833945868:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46505,DS-214f98da-77d4-4c1c-b628-ce3e15f15851,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-f353d82a-21b9-467e-8a7e-65a980c46851,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-79a8ebbf-2673-455b-ab7f-b6093efc4b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-51021083-be0b-4647-b5d1-1b8b9b8ba07b,DISK], DatanodeInfoWithStorage[127.0.0.1:38907,DS-a3f4e26b-c6da-475d-8117-0e66b7ed849c,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-38ae929c-a9c5-4f82-b575-61d35e20ba77,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-f0d7ed18-03a2-458f-949c-b9a99678fa3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-6a2f038e-18c4-4574-b3d7-6f9eb1e99fa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1027489458-172.17.0.14-1595833945868:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46505,DS-214f98da-77d4-4c1c-b628-ce3e15f15851,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-f353d82a-21b9-467e-8a7e-65a980c46851,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-79a8ebbf-2673-455b-ab7f-b6093efc4b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-51021083-be0b-4647-b5d1-1b8b9b8ba07b,DISK], DatanodeInfoWithStorage[127.0.0.1:38907,DS-a3f4e26b-c6da-475d-8117-0e66b7ed849c,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-38ae929c-a9c5-4f82-b575-61d35e20ba77,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-f0d7ed18-03a2-458f-949c-b9a99678fa3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-6a2f038e-18c4-4574-b3d7-6f9eb1e99fa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-215391192-172.17.0.14-1595834547126:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35997,DS-decc8ec1-2d34-4c84-abfd-4390d086f374,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-4f0a4ae6-08d1-4882-bf1d-3feb53911789,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-a91b4a9d-6b3e-4820-867a-d72ed2e084a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-a1148cd9-e447-4f70-a648-44e714194c72,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-33119fda-b581-446b-90c7-4ef19bffd06f,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-af1e3bdf-9ddc-48a3-98cb-2f4fe30f21f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-3c497c93-7e50-4898-9bbe-481365e15125,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-ab5203a7-10cc-4e30-8fec-3d0ead2009ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-215391192-172.17.0.14-1595834547126:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35997,DS-decc8ec1-2d34-4c84-abfd-4390d086f374,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-4f0a4ae6-08d1-4882-bf1d-3feb53911789,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-a91b4a9d-6b3e-4820-867a-d72ed2e084a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-a1148cd9-e447-4f70-a648-44e714194c72,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-33119fda-b581-446b-90c7-4ef19bffd06f,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-af1e3bdf-9ddc-48a3-98cb-2f4fe30f21f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-3c497c93-7e50-4898-9bbe-481365e15125,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-ab5203a7-10cc-4e30-8fec-3d0ead2009ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-893819542-172.17.0.14-1595834587569:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40439,DS-33799a94-d858-4063-a03d-d57037d5dbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-13b6017f-20f0-42df-80bb-f4f6093fddbc,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-5e8dd335-273e-4d32-9650-d2098a043d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41455,DS-a620c6eb-2d5a-4e24-a89b-e4f172a3bfe5,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-fe432bae-e7b3-4e25-b0f0-d2418f1b9832,DISK], DatanodeInfoWithStorage[127.0.0.1:39710,DS-720904e3-111f-4c27-8ff2-af4bd574ac95,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-019b6bbd-32ad-4f2c-b1b2-31e04f9559da,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-c0d734c0-5ddb-4b35-a04e-21e72fa29aaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-893819542-172.17.0.14-1595834587569:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40439,DS-33799a94-d858-4063-a03d-d57037d5dbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-13b6017f-20f0-42df-80bb-f4f6093fddbc,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-5e8dd335-273e-4d32-9650-d2098a043d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41455,DS-a620c6eb-2d5a-4e24-a89b-e4f172a3bfe5,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-fe432bae-e7b3-4e25-b0f0-d2418f1b9832,DISK], DatanodeInfoWithStorage[127.0.0.1:39710,DS-720904e3-111f-4c27-8ff2-af4bd574ac95,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-019b6bbd-32ad-4f2c-b1b2-31e04f9559da,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-c0d734c0-5ddb-4b35-a04e-21e72fa29aaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-784735400-172.17.0.14-1595835229032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40746,DS-55d07edd-0070-42d2-bee8-5e1238b3141d,DISK], DatanodeInfoWithStorage[127.0.0.1:33358,DS-5cb9c198-e35f-432c-b8f7-5438cb8e4556,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-00c60744-97b2-4582-af7a-e217843e5de8,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-5ed73f55-8b76-439e-86b9-71443fc89200,DISK], DatanodeInfoWithStorage[127.0.0.1:33555,DS-255f6e4b-f1d3-4487-b147-468f4a954006,DISK], DatanodeInfoWithStorage[127.0.0.1:43678,DS-e37e092d-9111-4432-9f10-df3bab406198,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-b8123b3a-f08e-4691-afa3-df6f812225e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-bcdce999-749e-4b17-8920-f4e0fb05bc0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-784735400-172.17.0.14-1595835229032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40746,DS-55d07edd-0070-42d2-bee8-5e1238b3141d,DISK], DatanodeInfoWithStorage[127.0.0.1:33358,DS-5cb9c198-e35f-432c-b8f7-5438cb8e4556,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-00c60744-97b2-4582-af7a-e217843e5de8,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-5ed73f55-8b76-439e-86b9-71443fc89200,DISK], DatanodeInfoWithStorage[127.0.0.1:33555,DS-255f6e4b-f1d3-4487-b147-468f4a954006,DISK], DatanodeInfoWithStorage[127.0.0.1:43678,DS-e37e092d-9111-4432-9f10-df3bab406198,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-b8123b3a-f08e-4691-afa3-df6f812225e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-bcdce999-749e-4b17-8920-f4e0fb05bc0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1009991615-172.17.0.14-1595835871016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40493,DS-c9f2b069-b8e5-411b-9518-7d5b1219ba59,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-58619417-11da-4dc0-b10d-8f4d9027c1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44730,DS-2bc2efa6-245f-4bf5-9292-1d7d0783dad5,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-54ce3e99-122f-4ec5-96d6-c4e15089f2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-e41a946f-a3c2-4274-a9c7-30eeccd5a773,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-fd8e9d9c-c3fa-43e1-bb53-7bdc65457d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-1e2afb72-2000-4feb-9ad5-f6ce1e5cb53b,DISK], DatanodeInfoWithStorage[127.0.0.1:45996,DS-14b4a7f0-1f2a-461e-9973-285245790152,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1009991615-172.17.0.14-1595835871016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40493,DS-c9f2b069-b8e5-411b-9518-7d5b1219ba59,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-58619417-11da-4dc0-b10d-8f4d9027c1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44730,DS-2bc2efa6-245f-4bf5-9292-1d7d0783dad5,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-54ce3e99-122f-4ec5-96d6-c4e15089f2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-e41a946f-a3c2-4274-a9c7-30eeccd5a773,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-fd8e9d9c-c3fa-43e1-bb53-7bdc65457d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-1e2afb72-2000-4feb-9ad5-f6ce1e5cb53b,DISK], DatanodeInfoWithStorage[127.0.0.1:45996,DS-14b4a7f0-1f2a-461e-9973-285245790152,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1071845393-172.17.0.14-1595836097621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36683,DS-5d71caa3-9f52-4579-acad-75312d6f254d,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-318ea782-0969-4029-a48e-92f8a987b396,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-308efa0d-bbac-4d93-ab6a-d2793a00db56,DISK], DatanodeInfoWithStorage[127.0.0.1:41248,DS-7def53d5-f48e-4545-bf62-db929e7044f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-f485f206-f61b-4f98-b6c5-7447230a6008,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-054cbf3c-59af-4f5d-a2bd-88447d8f9498,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-b7d5d1a5-136a-4c91-b345-0ab724a5bcb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-b8fb5e41-8bb1-4636-a4cc-f33af8816e18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1071845393-172.17.0.14-1595836097621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36683,DS-5d71caa3-9f52-4579-acad-75312d6f254d,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-318ea782-0969-4029-a48e-92f8a987b396,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-308efa0d-bbac-4d93-ab6a-d2793a00db56,DISK], DatanodeInfoWithStorage[127.0.0.1:41248,DS-7def53d5-f48e-4545-bf62-db929e7044f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-f485f206-f61b-4f98-b6c5-7447230a6008,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-054cbf3c-59af-4f5d-a2bd-88447d8f9498,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-b7d5d1a5-136a-4c91-b345-0ab724a5bcb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-b8fb5e41-8bb1-4636-a4cc-f33af8816e18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1116688958-172.17.0.14-1595836459010:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39098,DS-573ba554-7b93-4c02-ac5e-ffad4856d204,DISK], DatanodeInfoWithStorage[127.0.0.1:42612,DS-b9b8e02d-d176-41b5-9fbd-2d077a05f616,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-e59a47d0-9849-41be-a802-acacdfe09518,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-db8ecb85-1be7-44d2-9d03-bfba96360c78,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-e20ee1a6-c5eb-45b9-a9a0-2ab551a56f64,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-a2faaf1c-7a04-4c15-b5bf-f1dbf9436e51,DISK], DatanodeInfoWithStorage[127.0.0.1:40075,DS-43839977-798e-4f7a-b987-14d79139a27e,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-9a5070d6-3f97-43d9-8707-6d8958c08b7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1116688958-172.17.0.14-1595836459010:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39098,DS-573ba554-7b93-4c02-ac5e-ffad4856d204,DISK], DatanodeInfoWithStorage[127.0.0.1:42612,DS-b9b8e02d-d176-41b5-9fbd-2d077a05f616,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-e59a47d0-9849-41be-a802-acacdfe09518,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-db8ecb85-1be7-44d2-9d03-bfba96360c78,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-e20ee1a6-c5eb-45b9-a9a0-2ab551a56f64,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-a2faaf1c-7a04-4c15-b5bf-f1dbf9436e51,DISK], DatanodeInfoWithStorage[127.0.0.1:40075,DS-43839977-798e-4f7a-b987-14d79139a27e,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-9a5070d6-3f97-43d9-8707-6d8958c08b7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1609504776-172.17.0.14-1595837046650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37065,DS-17dbdb21-9d60-4501-86ea-c3347f217892,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-e2f78743-34b2-4af2-81d0-cecbd373802a,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-a08a6fac-8467-41b3-9e9c-119a9b20df72,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-17f0f2ce-3e8d-4a5f-b93d-8ad8908c2817,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-a730f1fd-9e07-45dd-b6bd-a2f8c8e4cc47,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-a8359fbf-3256-45f3-b140-661ec47d5a48,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-b5d641f9-8fc1-4881-b35a-8a1af6b81bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-97a3ec7c-2094-472a-b045-615b2eaa71c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1609504776-172.17.0.14-1595837046650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37065,DS-17dbdb21-9d60-4501-86ea-c3347f217892,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-e2f78743-34b2-4af2-81d0-cecbd373802a,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-a08a6fac-8467-41b3-9e9c-119a9b20df72,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-17f0f2ce-3e8d-4a5f-b93d-8ad8908c2817,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-a730f1fd-9e07-45dd-b6bd-a2f8c8e4cc47,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-a8359fbf-3256-45f3-b140-661ec47d5a48,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-b5d641f9-8fc1-4881-b35a-8a1af6b81bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-97a3ec7c-2094-472a-b045-615b2eaa71c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1930271962-172.17.0.14-1595837224191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43864,DS-cbdb35eb-63f6-4698-97ff-8795155413ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-38290017-d230-47bb-a874-1c868e276d64,DISK], DatanodeInfoWithStorage[127.0.0.1:38478,DS-5668469a-7af9-437b-9cce-d5bbe76764fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-7ee5f700-da55-44f8-a45a-a2025ecbcff8,DISK], DatanodeInfoWithStorage[127.0.0.1:46675,DS-8555f10b-18a6-4ea1-acf7-608af36f5d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-f6f46886-3147-4465-9cd6-020ce8a84554,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-0779b9ea-dc7e-4b53-9f12-c2389a0f983b,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-a005cd3e-c789-4a51-a453-e57f212ea61f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1930271962-172.17.0.14-1595837224191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43864,DS-cbdb35eb-63f6-4698-97ff-8795155413ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-38290017-d230-47bb-a874-1c868e276d64,DISK], DatanodeInfoWithStorage[127.0.0.1:38478,DS-5668469a-7af9-437b-9cce-d5bbe76764fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-7ee5f700-da55-44f8-a45a-a2025ecbcff8,DISK], DatanodeInfoWithStorage[127.0.0.1:46675,DS-8555f10b-18a6-4ea1-acf7-608af36f5d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-f6f46886-3147-4465-9cd6-020ce8a84554,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-0779b9ea-dc7e-4b53-9f12-c2389a0f983b,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-a005cd3e-c789-4a51-a453-e57f212ea61f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2020904378-172.17.0.14-1595838080150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38423,DS-416edcb9-98e0-489f-b134-ebcb4ba47d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-52979867-7d56-41ee-a7c2-f8fa3a7a6e57,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-890b50b0-1fb4-4ef4-a06c-3bff25bd03b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-3957c330-e8fc-4611-b200-70f83b9b0fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-762a2afd-676f-457b-ab0b-343116e058a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-3876ad1e-32f5-4025-9cf6-cf57ff024ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-e549b699-4aea-47e1-969b-15a1d3968a50,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-3020e586-946b-413f-b37c-df639b1db70b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2020904378-172.17.0.14-1595838080150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38423,DS-416edcb9-98e0-489f-b134-ebcb4ba47d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-52979867-7d56-41ee-a7c2-f8fa3a7a6e57,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-890b50b0-1fb4-4ef4-a06c-3bff25bd03b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-3957c330-e8fc-4611-b200-70f83b9b0fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-762a2afd-676f-457b-ab0b-343116e058a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-3876ad1e-32f5-4025-9cf6-cf57ff024ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-e549b699-4aea-47e1-969b-15a1d3968a50,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-3020e586-946b-413f-b37c-df639b1db70b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-851672240-172.17.0.14-1595838158020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41254,DS-aed6a8fb-0003-4fb2-bd86-65fe467b9607,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-80654dc2-76ac-414f-abcd-f66dca760822,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-028ef147-fba5-4c12-966f-5ddc405cc879,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-8ae9ae4b-bfa5-4a25-a81a-1282545c9e41,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-e0f72454-3b1d-497e-b28b-9c3b1277f9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-66eac026-b98d-41df-b723-e7775617947a,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-53f10a4f-7a6f-4e66-ad4e-fb85cb77772a,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-737cea4a-e17e-4a5a-9c73-073a33c3c0d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-851672240-172.17.0.14-1595838158020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41254,DS-aed6a8fb-0003-4fb2-bd86-65fe467b9607,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-80654dc2-76ac-414f-abcd-f66dca760822,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-028ef147-fba5-4c12-966f-5ddc405cc879,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-8ae9ae4b-bfa5-4a25-a81a-1282545c9e41,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-e0f72454-3b1d-497e-b28b-9c3b1277f9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-66eac026-b98d-41df-b723-e7775617947a,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-53f10a4f-7a6f-4e66-ad4e-fb85cb77772a,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-737cea4a-e17e-4a5a-9c73-073a33c3c0d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-800408188-172.17.0.14-1595838484793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35969,DS-7d8e6fec-95ca-43aa-9a92-c6a04f15251c,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-d95119f1-7275-4ec9-ade7-5d2c54abf6db,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-066faf0f-53ff-4097-ae10-0f63d86b2f81,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-c0e8f2ea-d81f-4518-b39f-f692adc378cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-bf47d9dc-5fc9-4267-a620-3aa40fbc9dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-5f2357bf-efbf-4b72-a2d6-c7e63f517792,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-6ec06123-9dc3-40c5-a586-15d021c30d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42990,DS-cb67e130-2108-479f-a71d-5336d8d17adb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-800408188-172.17.0.14-1595838484793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35969,DS-7d8e6fec-95ca-43aa-9a92-c6a04f15251c,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-d95119f1-7275-4ec9-ade7-5d2c54abf6db,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-066faf0f-53ff-4097-ae10-0f63d86b2f81,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-c0e8f2ea-d81f-4518-b39f-f692adc378cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-bf47d9dc-5fc9-4267-a620-3aa40fbc9dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-5f2357bf-efbf-4b72-a2d6-c7e63f517792,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-6ec06123-9dc3-40c5-a586-15d021c30d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42990,DS-cb67e130-2108-479f-a71d-5336d8d17adb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6332
