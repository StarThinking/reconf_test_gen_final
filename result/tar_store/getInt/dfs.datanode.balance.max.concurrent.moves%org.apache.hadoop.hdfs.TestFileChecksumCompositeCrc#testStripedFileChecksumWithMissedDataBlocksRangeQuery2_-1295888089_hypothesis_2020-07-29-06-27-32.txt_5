reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1696159267-172.17.0.13-1596004196595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39898,DS-ee79c6d6-40a5-462e-9a3c-c7d4d7340f65,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-b0edfbf8-c84a-4127-be5c-03660a8413f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-b4206c28-27a4-4858-acfe-da45e8b352a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45259,DS-8721c99e-fe7e-4bdf-be99-31cb74ac55a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-b3c401c8-a89a-4f51-bee5-07086699801d,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-d71226b7-9d2c-487f-972c-5a8e4803b776,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-fc0f5007-6a01-4c20-8697-0674264fd5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-3cd58215-96fd-4e82-bdb6-c6ddf55ef6a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1696159267-172.17.0.13-1596004196595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39898,DS-ee79c6d6-40a5-462e-9a3c-c7d4d7340f65,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-b0edfbf8-c84a-4127-be5c-03660a8413f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-b4206c28-27a4-4858-acfe-da45e8b352a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45259,DS-8721c99e-fe7e-4bdf-be99-31cb74ac55a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-b3c401c8-a89a-4f51-bee5-07086699801d,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-d71226b7-9d2c-487f-972c-5a8e4803b776,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-fc0f5007-6a01-4c20-8697-0674264fd5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-3cd58215-96fd-4e82-bdb6-c6ddf55ef6a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-670607076-172.17.0.13-1596004349864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42390,DS-43cf9d70-b059-4c46-88f6-37b4fb165aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-2277e903-038e-4f3d-8a9e-ec155edafe86,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-ea240725-8350-4663-8c1a-1ed32ef676a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-c3101c65-db6f-44bc-9977-b9bb129a36c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-f372c767-f00c-481c-a622-a35d1bc07ace,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-1c51e97c-12d7-4a15-aa80-55e222edcdf4,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-ea0af436-6a11-41fa-9cf3-a059834c0b92,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-3a3d65ff-2782-455a-bb4c-ce3f0a9f9632,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-670607076-172.17.0.13-1596004349864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42390,DS-43cf9d70-b059-4c46-88f6-37b4fb165aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-2277e903-038e-4f3d-8a9e-ec155edafe86,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-ea240725-8350-4663-8c1a-1ed32ef676a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-c3101c65-db6f-44bc-9977-b9bb129a36c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-f372c767-f00c-481c-a622-a35d1bc07ace,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-1c51e97c-12d7-4a15-aa80-55e222edcdf4,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-ea0af436-6a11-41fa-9cf3-a059834c0b92,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-3a3d65ff-2782-455a-bb4c-ce3f0a9f9632,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218468388-172.17.0.13-1596005307104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44538,DS-450e2509-0edc-4bbc-95e1-113acc80c839,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-6365233d-b438-4e7d-9290-a4121d36d567,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-65182e90-3361-4b20-a534-3670f4ab4fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-4e9a7489-15e3-4ebd-9a8c-452a8cc87f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-b017411a-c536-4c68-b3ab-aed240a646e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-c4b0a049-16e1-48a9-9a35-7b8500d6a595,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-2a326326-5104-4262-84c0-d14c0850c841,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-668e33b3-33aa-4625-8f7a-86230472f183,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218468388-172.17.0.13-1596005307104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44538,DS-450e2509-0edc-4bbc-95e1-113acc80c839,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-6365233d-b438-4e7d-9290-a4121d36d567,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-65182e90-3361-4b20-a534-3670f4ab4fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-4e9a7489-15e3-4ebd-9a8c-452a8cc87f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-b017411a-c536-4c68-b3ab-aed240a646e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-c4b0a049-16e1-48a9-9a35-7b8500d6a595,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-2a326326-5104-4262-84c0-d14c0850c841,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-668e33b3-33aa-4625-8f7a-86230472f183,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1299746365-172.17.0.13-1596005342231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44591,DS-cfb76cb9-2152-428f-8814-3e90594f8644,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-38b8fc25-b22d-494d-a7e0-0cc79e71a2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-9358de6c-f359-494f-8d78-3353c4ba0b32,DISK], DatanodeInfoWithStorage[127.0.0.1:36357,DS-a1ba56fb-63b3-4da8-bb20-cd456271a615,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-49e2a267-485f-4440-831c-b6ba2c71b795,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-98d0d6b1-4584-44c1-a387-dd29187eea2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-37c10432-8bb6-4668-bca9-75989f508cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-c5523a84-3479-4b57-b775-02d5b6fd5c80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1299746365-172.17.0.13-1596005342231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44591,DS-cfb76cb9-2152-428f-8814-3e90594f8644,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-38b8fc25-b22d-494d-a7e0-0cc79e71a2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-9358de6c-f359-494f-8d78-3353c4ba0b32,DISK], DatanodeInfoWithStorage[127.0.0.1:36357,DS-a1ba56fb-63b3-4da8-bb20-cd456271a615,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-49e2a267-485f-4440-831c-b6ba2c71b795,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-98d0d6b1-4584-44c1-a387-dd29187eea2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-37c10432-8bb6-4668-bca9-75989f508cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-c5523a84-3479-4b57-b775-02d5b6fd5c80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1474900350-172.17.0.13-1596005645408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45570,DS-0ef18b44-f05a-407d-9dbb-cd3ca8dfac7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-e7d7049e-f11e-4781-9321-7eb9c9b2343c,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-bb06dea0-b7d9-4a0f-8542-f806a43e7d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-fb466f6b-cc16-44e7-9550-5f8980f5602b,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-d8d2ff50-7fd0-4654-b069-fa30a39eb17b,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-36b644bd-edd0-4332-afe3-f45543d1de99,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-fd03e0d8-0ee7-4582-95b2-e08e82b5b594,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-0a223eda-0005-40b3-a56e-6420c0cf7819,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1474900350-172.17.0.13-1596005645408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45570,DS-0ef18b44-f05a-407d-9dbb-cd3ca8dfac7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-e7d7049e-f11e-4781-9321-7eb9c9b2343c,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-bb06dea0-b7d9-4a0f-8542-f806a43e7d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-fb466f6b-cc16-44e7-9550-5f8980f5602b,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-d8d2ff50-7fd0-4654-b069-fa30a39eb17b,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-36b644bd-edd0-4332-afe3-f45543d1de99,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-fd03e0d8-0ee7-4582-95b2-e08e82b5b594,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-0a223eda-0005-40b3-a56e-6420c0cf7819,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1854650088-172.17.0.13-1596006669043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33505,DS-747132d4-d4bd-4546-9222-1a1b2cd3d771,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-68310cb6-409b-47f3-b56e-327d4bf548c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-d9a4110f-6aad-4e6e-b3e4-0cb1786f6e24,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-29871fb0-5311-440a-ae47-002caf846527,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-8930c1f7-d16a-45c6-949b-2069b4551d01,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-1a039933-c4b3-451e-b5f0-8586d469e055,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-d65bfd3d-758f-4371-9ef9-cbea26cca09b,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-2aa99c75-a5b9-4662-bc23-f8246a7b6139,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1854650088-172.17.0.13-1596006669043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33505,DS-747132d4-d4bd-4546-9222-1a1b2cd3d771,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-68310cb6-409b-47f3-b56e-327d4bf548c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-d9a4110f-6aad-4e6e-b3e4-0cb1786f6e24,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-29871fb0-5311-440a-ae47-002caf846527,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-8930c1f7-d16a-45c6-949b-2069b4551d01,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-1a039933-c4b3-451e-b5f0-8586d469e055,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-d65bfd3d-758f-4371-9ef9-cbea26cca09b,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-2aa99c75-a5b9-4662-bc23-f8246a7b6139,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-783079423-172.17.0.13-1596006940925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35863,DS-9fbce708-2717-4a81-8d79-cd296e8ab1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-ead13bfb-06d7-48bd-94e7-c4dd754b2bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-db0978e0-a87a-43c2-80bd-2cd58ec5c237,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-3823cbe9-cf21-4cd6-9a43-411df88702ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-5cb04b06-493e-491e-80ad-8fd933935e65,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-ca0e3666-a710-47bc-bf3e-90868e0e95b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-09ba78a4-0963-44f1-92a2-2581af1cb86f,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-52bd1f7b-a5a4-4995-b4b1-4fcba5da6c99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-783079423-172.17.0.13-1596006940925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35863,DS-9fbce708-2717-4a81-8d79-cd296e8ab1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-ead13bfb-06d7-48bd-94e7-c4dd754b2bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-db0978e0-a87a-43c2-80bd-2cd58ec5c237,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-3823cbe9-cf21-4cd6-9a43-411df88702ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-5cb04b06-493e-491e-80ad-8fd933935e65,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-ca0e3666-a710-47bc-bf3e-90868e0e95b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-09ba78a4-0963-44f1-92a2-2581af1cb86f,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-52bd1f7b-a5a4-4995-b4b1-4fcba5da6c99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1984641266-172.17.0.13-1596007183041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32866,DS-f1926d5c-17df-435e-b108-38e6d6d2ebb9,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-6f112c4f-866c-4c34-ac68-216c1b2a9cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-fc5e1af7-009c-460d-986a-857ab746ea7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-be3d549e-e3f6-4cbd-9cc9-f6cb3f55a149,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-5ba40f0d-e21d-49d7-bab2-7bc876f9d5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-4bc04031-4530-430c-9a73-c6eeca4d1c44,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-866acf87-0a7d-473a-a72b-b3f0df972ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-6850b024-851e-43bd-9198-27b9c2690fa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1984641266-172.17.0.13-1596007183041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32866,DS-f1926d5c-17df-435e-b108-38e6d6d2ebb9,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-6f112c4f-866c-4c34-ac68-216c1b2a9cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-fc5e1af7-009c-460d-986a-857ab746ea7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-be3d549e-e3f6-4cbd-9cc9-f6cb3f55a149,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-5ba40f0d-e21d-49d7-bab2-7bc876f9d5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-4bc04031-4530-430c-9a73-c6eeca4d1c44,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-866acf87-0a7d-473a-a72b-b3f0df972ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-6850b024-851e-43bd-9198-27b9c2690fa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1501657882-172.17.0.13-1596007598503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46306,DS-0d470458-489a-445c-b17f-7c60d49fb873,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-ce13197c-a926-43a8-af1f-9319f3af6699,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-301aac06-56cc-412f-9d26-07ebea05ca4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35422,DS-610e90b7-b6b1-4580-b658-0411785ae3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-831eb1e2-c3cf-4003-bcaf-df58a20b68d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-c510c4ca-b5a0-4b24-bdfc-8c574d3ca74f,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-cbe9a089-6a6e-4124-bc01-2b306976a9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35106,DS-e7568b4e-6cc3-48f2-952a-3b58766fa593,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1501657882-172.17.0.13-1596007598503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46306,DS-0d470458-489a-445c-b17f-7c60d49fb873,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-ce13197c-a926-43a8-af1f-9319f3af6699,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-301aac06-56cc-412f-9d26-07ebea05ca4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35422,DS-610e90b7-b6b1-4580-b658-0411785ae3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-831eb1e2-c3cf-4003-bcaf-df58a20b68d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-c510c4ca-b5a0-4b24-bdfc-8c574d3ca74f,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-cbe9a089-6a6e-4124-bc01-2b306976a9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35106,DS-e7568b4e-6cc3-48f2-952a-3b58766fa593,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1427182279-172.17.0.13-1596007666479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42848,DS-29134fc8-9aa1-4f15-b9a0-c2d6a6c6365f,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-ac2aa078-1e8b-4885-8637-fd6e6d3eed05,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-0904de71-d95f-4b5b-ad0a-7443b9ebc0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-8f749b85-3e75-4d8d-bec9-06259eb0830d,DISK], DatanodeInfoWithStorage[127.0.0.1:44467,DS-2b2bf3fa-bba0-44d9-9b03-58eed57601ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43223,DS-902ab656-2337-40b3-9794-31f720707601,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-db9a9275-5548-4e33-ac9a-82bf246c4c46,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-b3c77389-e830-4b79-a75a-04fac60a23a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1427182279-172.17.0.13-1596007666479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42848,DS-29134fc8-9aa1-4f15-b9a0-c2d6a6c6365f,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-ac2aa078-1e8b-4885-8637-fd6e6d3eed05,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-0904de71-d95f-4b5b-ad0a-7443b9ebc0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-8f749b85-3e75-4d8d-bec9-06259eb0830d,DISK], DatanodeInfoWithStorage[127.0.0.1:44467,DS-2b2bf3fa-bba0-44d9-9b03-58eed57601ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43223,DS-902ab656-2337-40b3-9794-31f720707601,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-db9a9275-5548-4e33-ac9a-82bf246c4c46,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-b3c77389-e830-4b79-a75a-04fac60a23a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1027344181-172.17.0.13-1596007700537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42080,DS-5753625c-9861-4d24-b29a-6f1739b66609,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-5acd0606-98e0-4253-80e9-a56d4bcd7a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-6668c4ac-3316-4983-bfa9-6ed88554e927,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-dd559260-8092-4db0-b771-ba720e2a1fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-c648777f-c95e-40a8-83c3-fa17dad726d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-2ac56ce4-b682-47fd-adb0-4216c5df28d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-4567e0e7-a817-453b-b4fa-6a6fd88a7cde,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-14c87c5f-783d-4d8a-84fd-0415c1015d8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1027344181-172.17.0.13-1596007700537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42080,DS-5753625c-9861-4d24-b29a-6f1739b66609,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-5acd0606-98e0-4253-80e9-a56d4bcd7a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-6668c4ac-3316-4983-bfa9-6ed88554e927,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-dd559260-8092-4db0-b771-ba720e2a1fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-c648777f-c95e-40a8-83c3-fa17dad726d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-2ac56ce4-b682-47fd-adb0-4216c5df28d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-4567e0e7-a817-453b-b4fa-6a6fd88a7cde,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-14c87c5f-783d-4d8a-84fd-0415c1015d8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-860598652-172.17.0.13-1596007736244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34600,DS-e4358d6e-a42b-46f6-b631-2302739fdacf,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-6a53ef07-2c18-4b7f-b174-cd33179bbcb2,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-08b58784-d2f1-44d0-a563-2c81c4d8cd2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-94f3d561-9cb3-40d5-a589-65f228bed327,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-976896aa-beaf-4f61-b476-232682bcabbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-73ea5294-b981-4f98-bafb-4933c9d69427,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-46c56080-6d57-4229-a9ca-dd2ff3a4e585,DISK], DatanodeInfoWithStorage[127.0.0.1:46001,DS-5b2144cb-e5a9-410c-b251-a225b797a822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-860598652-172.17.0.13-1596007736244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34600,DS-e4358d6e-a42b-46f6-b631-2302739fdacf,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-6a53ef07-2c18-4b7f-b174-cd33179bbcb2,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-08b58784-d2f1-44d0-a563-2c81c4d8cd2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-94f3d561-9cb3-40d5-a589-65f228bed327,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-976896aa-beaf-4f61-b476-232682bcabbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-73ea5294-b981-4f98-bafb-4933c9d69427,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-46c56080-6d57-4229-a9ca-dd2ff3a4e585,DISK], DatanodeInfoWithStorage[127.0.0.1:46001,DS-5b2144cb-e5a9-410c-b251-a225b797a822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-58561118-172.17.0.13-1596008155013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40190,DS-c3571546-51fa-4ca8-b742-1b7b6b7990d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-fe8586c2-8280-43a2-845b-bdb343fc4944,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-fc6deffe-e25e-430e-9518-328d57e12e22,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-cceca5bc-40cd-4935-b980-950df692f1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-7265ede3-228b-479a-ab49-841bd73c0a90,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-a57374dd-99dd-44d6-bfd0-3185c190c3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-02916f5e-cc7f-4a1e-ae18-f75ca3d6ffa2,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-09f80f5b-710c-48ec-ab2a-6e29c515596f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-58561118-172.17.0.13-1596008155013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40190,DS-c3571546-51fa-4ca8-b742-1b7b6b7990d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-fe8586c2-8280-43a2-845b-bdb343fc4944,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-fc6deffe-e25e-430e-9518-328d57e12e22,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-cceca5bc-40cd-4935-b980-950df692f1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-7265ede3-228b-479a-ab49-841bd73c0a90,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-a57374dd-99dd-44d6-bfd0-3185c190c3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-02916f5e-cc7f-4a1e-ae18-f75ca3d6ffa2,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-09f80f5b-710c-48ec-ab2a-6e29c515596f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5499
