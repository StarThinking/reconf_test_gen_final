reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 20000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 20000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1107578012-172.17.0.18-1595949234110:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41253,DS-e21602d4-a959-4b57-939c-2de464c1ede2,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-58cebbc8-86eb-46e5-966c-07ef3162d5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-4fa1c227-62a9-4744-a03f-def0b06dab69,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-361164ed-6dde-4886-9bd6-21d554b8f3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42396,DS-e3ca842a-e558-404b-8cf6-0de02a4cec12,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-0da3de06-94e4-4045-a8dc-4e480ccaf94c,DISK], DatanodeInfoWithStorage[127.0.0.1:33696,DS-fb2d58a5-d457-4004-9b07-4acb33982ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-8ffb0c00-a081-4bec-997b-676691d4c456,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1107578012-172.17.0.18-1595949234110:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41253,DS-e21602d4-a959-4b57-939c-2de464c1ede2,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-58cebbc8-86eb-46e5-966c-07ef3162d5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-4fa1c227-62a9-4744-a03f-def0b06dab69,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-361164ed-6dde-4886-9bd6-21d554b8f3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42396,DS-e3ca842a-e558-404b-8cf6-0de02a4cec12,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-0da3de06-94e4-4045-a8dc-4e480ccaf94c,DISK], DatanodeInfoWithStorage[127.0.0.1:33696,DS-fb2d58a5-d457-4004-9b07-4acb33982ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-8ffb0c00-a081-4bec-997b-676691d4c456,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 20000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1392411545-172.17.0.18-1595949862630:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34708,DS-5bb9e9c9-39d2-411b-ac04-40a2df8fb8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-cfc35cc3-688f-4644-a93d-2858bb066442,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-27cd1357-11a7-4e18-8e9e-135aabe4d42c,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-779aa24c-10c7-476a-b581-3665808d987a,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-012af3eb-2083-472a-aa54-2fc909f49fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-aca4680d-44de-494f-9c20-237d7c83ba63,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-d6ae64b9-8394-48ef-ac84-822a28118f57,DISK], DatanodeInfoWithStorage[127.0.0.1:35799,DS-25154e5f-e8cc-43bf-90d4-15b7076ef9b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1392411545-172.17.0.18-1595949862630:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34708,DS-5bb9e9c9-39d2-411b-ac04-40a2df8fb8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-cfc35cc3-688f-4644-a93d-2858bb066442,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-27cd1357-11a7-4e18-8e9e-135aabe4d42c,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-779aa24c-10c7-476a-b581-3665808d987a,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-012af3eb-2083-472a-aa54-2fc909f49fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-aca4680d-44de-494f-9c20-237d7c83ba63,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-d6ae64b9-8394-48ef-ac84-822a28118f57,DISK], DatanodeInfoWithStorage[127.0.0.1:35799,DS-25154e5f-e8cc-43bf-90d4-15b7076ef9b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 20000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-227811071-172.17.0.18-1595950566490:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39699,DS-65823235-86cd-41d8-b161-b7e5d747c6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-3d4d92bd-660c-42a2-95b8-284ba599e031,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-e870fee8-3cbc-49c5-88bf-22d2b283db90,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-bbea608d-27b7-4854-bbbe-2ec717c1dd16,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-dd7216c9-154b-4c66-ad00-45553105a0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-52c10f5b-810f-4330-9e2e-d4548df175cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-aa1f3aec-04f0-4658-be4d-1586000b6577,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-5e0412a0-0a37-485e-ba9b-70652a4fde83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-227811071-172.17.0.18-1595950566490:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39699,DS-65823235-86cd-41d8-b161-b7e5d747c6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-3d4d92bd-660c-42a2-95b8-284ba599e031,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-e870fee8-3cbc-49c5-88bf-22d2b283db90,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-bbea608d-27b7-4854-bbbe-2ec717c1dd16,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-dd7216c9-154b-4c66-ad00-45553105a0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-52c10f5b-810f-4330-9e2e-d4548df175cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-aa1f3aec-04f0-4658-be4d-1586000b6577,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-5e0412a0-0a37-485e-ba9b-70652a4fde83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 20000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1188908043-172.17.0.18-1595950665513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44225,DS-7b8e290f-695a-4ed1-ba49-64718bc4d8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-bef58562-2249-4994-8b81-30e50455612f,DISK], DatanodeInfoWithStorage[127.0.0.1:44809,DS-0060249d-0351-4e3c-a647-73046f909ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-69ba925a-10af-4a15-8e17-e211df88f60d,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-11f791ef-0391-4926-b18c-3b695f846ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-c5a91809-da3e-4721-81b7-dfced79ae311,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-91cf3716-c248-4615-8d11-c7e47d19f93b,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-aaa5f4e5-ecb3-476b-ae75-ed633728e39a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1188908043-172.17.0.18-1595950665513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44225,DS-7b8e290f-695a-4ed1-ba49-64718bc4d8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-bef58562-2249-4994-8b81-30e50455612f,DISK], DatanodeInfoWithStorage[127.0.0.1:44809,DS-0060249d-0351-4e3c-a647-73046f909ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-69ba925a-10af-4a15-8e17-e211df88f60d,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-11f791ef-0391-4926-b18c-3b695f846ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-c5a91809-da3e-4721-81b7-dfced79ae311,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-91cf3716-c248-4615-8d11-c7e47d19f93b,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-aaa5f4e5-ecb3-476b-ae75-ed633728e39a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 20000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1691068612-172.17.0.18-1595951431090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46580,DS-af38df1e-2de6-40dc-a5f9-6393fd8886de,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-7ad93320-850e-495a-9d17-db2c2451aa8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39955,DS-3ab6b3a1-2419-4dc6-8813-a9e67a2b3205,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-e0c5a9f5-0fff-4665-95d2-6e79972f5c70,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-7d52b55c-5f39-4e3e-af62-ff83019625d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-1e3d292e-263a-41da-934d-05b673d691e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-1486a767-433f-47b6-bc81-019f77e2d88e,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-77e700fe-ec4f-4d06-bf32-55ee78475501,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1691068612-172.17.0.18-1595951431090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46580,DS-af38df1e-2de6-40dc-a5f9-6393fd8886de,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-7ad93320-850e-495a-9d17-db2c2451aa8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39955,DS-3ab6b3a1-2419-4dc6-8813-a9e67a2b3205,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-e0c5a9f5-0fff-4665-95d2-6e79972f5c70,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-7d52b55c-5f39-4e3e-af62-ff83019625d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-1e3d292e-263a-41da-934d-05b673d691e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-1486a767-433f-47b6-bc81-019f77e2d88e,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-77e700fe-ec4f-4d06-bf32-55ee78475501,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 20000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2113461111-172.17.0.18-1595951753914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43179,DS-210bfe8d-d236-439b-b9e0-638f9270919a,DISK], DatanodeInfoWithStorage[127.0.0.1:34404,DS-33e474ca-51dd-4c72-9a38-995748095f15,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-b57a100e-0f7e-4d09-94c1-be38583ca4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-b2ced7e7-cac5-4703-a261-302f83f295fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-5cec014d-8946-4865-a86a-e909668fbffc,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-44ef3d4a-f7f3-48ed-8080-693f2f49d1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-9eb06d67-6f18-49a8-82e7-23e1d8de3ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:36843,DS-9c11d3d0-7a60-4446-82ac-c72ed07f431b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2113461111-172.17.0.18-1595951753914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43179,DS-210bfe8d-d236-439b-b9e0-638f9270919a,DISK], DatanodeInfoWithStorage[127.0.0.1:34404,DS-33e474ca-51dd-4c72-9a38-995748095f15,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-b57a100e-0f7e-4d09-94c1-be38583ca4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-b2ced7e7-cac5-4703-a261-302f83f295fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-5cec014d-8946-4865-a86a-e909668fbffc,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-44ef3d4a-f7f3-48ed-8080-693f2f49d1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-9eb06d67-6f18-49a8-82e7-23e1d8de3ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:36843,DS-9c11d3d0-7a60-4446-82ac-c72ed07f431b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 20000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1859644052-172.17.0.18-1595953402113:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45818,DS-026ba658-f242-4386-bcac-a68f59d27c44,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-d12543c5-5593-43be-8b2d-548a6be4d9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-0ffcd3fa-b7bc-48fa-a5d5-b57c59cedd10,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-40f8c738-82e8-4ae9-96fc-5d7a26af62f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-8b7f4897-00f7-4ad7-9d0d-801835235b07,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-c0d97f53-fc43-448a-a557-441bc63b554d,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-afda02fe-d9d9-49b5-9ba7-a743c31318af,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-c4c7fb72-adfe-4dce-8c26-38177c5cd16f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1859644052-172.17.0.18-1595953402113:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45818,DS-026ba658-f242-4386-bcac-a68f59d27c44,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-d12543c5-5593-43be-8b2d-548a6be4d9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-0ffcd3fa-b7bc-48fa-a5d5-b57c59cedd10,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-40f8c738-82e8-4ae9-96fc-5d7a26af62f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-8b7f4897-00f7-4ad7-9d0d-801835235b07,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-c0d97f53-fc43-448a-a557-441bc63b554d,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-afda02fe-d9d9-49b5-9ba7-a743c31318af,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-c4c7fb72-adfe-4dce-8c26-38177c5cd16f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 2 out of 50
result: might be true error
Total execution time in seconds : 5297
