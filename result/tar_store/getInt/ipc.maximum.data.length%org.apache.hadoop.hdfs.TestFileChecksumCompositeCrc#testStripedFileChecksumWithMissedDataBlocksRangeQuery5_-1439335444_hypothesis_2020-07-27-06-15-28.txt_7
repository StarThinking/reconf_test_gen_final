reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1524355379-172.17.0.10-1595830611241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37219,DS-22d46020-b761-422c-9de9-8e1d7f99bf36,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-aae4d424-5e6a-4142-90c9-88366564fb08,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-b4a395a6-6b8c-4661-b035-13d804d67ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:35035,DS-4cfb5ce7-8c7c-4808-8b27-cfc4b63feeb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-32dacd6a-225f-4d04-bf24-982a5c33d954,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-d0cf0a54-ec0b-48fc-b897-bd08eea6a9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-96673bbb-87ec-46eb-a344-5e49bab3ec78,DISK], DatanodeInfoWithStorage[127.0.0.1:42201,DS-3639ab2c-5bc9-4be2-a439-1fe204844a0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1524355379-172.17.0.10-1595830611241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37219,DS-22d46020-b761-422c-9de9-8e1d7f99bf36,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-aae4d424-5e6a-4142-90c9-88366564fb08,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-b4a395a6-6b8c-4661-b035-13d804d67ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:35035,DS-4cfb5ce7-8c7c-4808-8b27-cfc4b63feeb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-32dacd6a-225f-4d04-bf24-982a5c33d954,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-d0cf0a54-ec0b-48fc-b897-bd08eea6a9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-96673bbb-87ec-46eb-a344-5e49bab3ec78,DISK], DatanodeInfoWithStorage[127.0.0.1:42201,DS-3639ab2c-5bc9-4be2-a439-1fe204844a0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-554013675-172.17.0.10-1595830833857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33364,DS-423129be-0637-4b8a-9ce9-6f860441825c,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-fa371565-49fb-4fd3-a952-23431ca277d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-274f6994-2dad-4e58-bdba-5e3a41a08eab,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-805afc85-05df-4631-9146-696e09a11873,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-cc981456-793b-4e46-8768-4d884b3f39a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-d44c7083-4f4c-4aaa-bb69-82664f5e7d90,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-b33e7b21-9243-40af-9c8e-a8777a906a93,DISK], DatanodeInfoWithStorage[127.0.0.1:37067,DS-ae46b1b7-a145-4b60-827c-2e81fd57e630,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-554013675-172.17.0.10-1595830833857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33364,DS-423129be-0637-4b8a-9ce9-6f860441825c,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-fa371565-49fb-4fd3-a952-23431ca277d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-274f6994-2dad-4e58-bdba-5e3a41a08eab,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-805afc85-05df-4631-9146-696e09a11873,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-cc981456-793b-4e46-8768-4d884b3f39a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-d44c7083-4f4c-4aaa-bb69-82664f5e7d90,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-b33e7b21-9243-40af-9c8e-a8777a906a93,DISK], DatanodeInfoWithStorage[127.0.0.1:37067,DS-ae46b1b7-a145-4b60-827c-2e81fd57e630,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-40535133-172.17.0.10-1595830864461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33410,DS-4242faff-2d7f-4699-8585-e0c3f6d56a36,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-1f49acae-f227-42b8-ae78-e43018d862cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-94a66495-813c-4738-83f1-b8f5e3512765,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-8aaddb95-e87e-497e-b6f0-ed3f9448f263,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-9a88eae7-b46d-4cfb-8ad4-b24377f53ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-e40ced13-07f9-4f29-ad2e-e7e4aa740aef,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-a7ed6eb2-ed5c-482c-bd68-13db9b3b783a,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-c683863c-237b-4361-9efd-89b3cfc2f2ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-40535133-172.17.0.10-1595830864461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33410,DS-4242faff-2d7f-4699-8585-e0c3f6d56a36,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-1f49acae-f227-42b8-ae78-e43018d862cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-94a66495-813c-4738-83f1-b8f5e3512765,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-8aaddb95-e87e-497e-b6f0-ed3f9448f263,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-9a88eae7-b46d-4cfb-8ad4-b24377f53ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-e40ced13-07f9-4f29-ad2e-e7e4aa740aef,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-a7ed6eb2-ed5c-482c-bd68-13db9b3b783a,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-c683863c-237b-4361-9efd-89b3cfc2f2ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-897414316-172.17.0.10-1595831432034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43535,DS-955133c9-e5d2-45ef-9770-fc2709254ada,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-5bb9d591-7db8-40e1-8193-76240879c192,DISK], DatanodeInfoWithStorage[127.0.0.1:38632,DS-675a93eb-1b6c-4a3f-a7b6-3d445abee9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-bc9dbb71-3fc2-426f-b77e-0d2cd63f9e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-c3f86bb7-f669-4ada-9d2d-b1e25aad91ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-444f12ca-4e21-453f-b614-92bab7d97569,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-602652c1-be5a-4411-a1db-f44de3a39e96,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-5a462e75-cca2-4a27-85f1-4b29db3b1b57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-897414316-172.17.0.10-1595831432034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43535,DS-955133c9-e5d2-45ef-9770-fc2709254ada,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-5bb9d591-7db8-40e1-8193-76240879c192,DISK], DatanodeInfoWithStorage[127.0.0.1:38632,DS-675a93eb-1b6c-4a3f-a7b6-3d445abee9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-bc9dbb71-3fc2-426f-b77e-0d2cd63f9e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-c3f86bb7-f669-4ada-9d2d-b1e25aad91ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-444f12ca-4e21-453f-b614-92bab7d97569,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-602652c1-be5a-4411-a1db-f44de3a39e96,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-5a462e75-cca2-4a27-85f1-4b29db3b1b57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1016840462-172.17.0.10-1595831716243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35348,DS-7886e836-2b3d-4593-8703-fb0e99886531,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-cd3ea655-21c2-41ab-ae3c-ab94e7b04979,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-31134a7c-b399-4163-822d-20cb44cfa2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-979aff48-24d2-4981-a777-a14126b4bb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-4fbf6f2d-6ad6-45d7-9b3f-e8bd6fdf2bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-e044a987-2e2b-4d1c-acf2-b4ccda4ead5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-48d4cc56-f0e1-4bed-a836-4b470ca51f44,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-e8245a4a-dd0f-4593-87c4-a6874bc31342,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1016840462-172.17.0.10-1595831716243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35348,DS-7886e836-2b3d-4593-8703-fb0e99886531,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-cd3ea655-21c2-41ab-ae3c-ab94e7b04979,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-31134a7c-b399-4163-822d-20cb44cfa2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-979aff48-24d2-4981-a777-a14126b4bb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-4fbf6f2d-6ad6-45d7-9b3f-e8bd6fdf2bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-e044a987-2e2b-4d1c-acf2-b4ccda4ead5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-48d4cc56-f0e1-4bed-a836-4b470ca51f44,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-e8245a4a-dd0f-4593-87c4-a6874bc31342,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144189115-172.17.0.10-1595831881092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40541,DS-9848373c-1dbb-475e-b0b1-4114e88696fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-8ced5e41-b5dc-4b49-ba58-34fb33dd9286,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-eccaf27f-6a26-47bf-9081-ee91ceb9dd4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-2d408209-71e5-41b1-81a9-ddb92179dac1,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-284821e7-2b80-4c72-9eb2-94c56ce1b84c,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-5625d891-b6b5-43c2-b6ba-6bf0d409c1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-e1d7638d-add4-449f-a423-b7ad8ed0895b,DISK], DatanodeInfoWithStorage[127.0.0.1:35793,DS-720a629c-e413-4389-b9b5-c4b4b387874b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144189115-172.17.0.10-1595831881092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40541,DS-9848373c-1dbb-475e-b0b1-4114e88696fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-8ced5e41-b5dc-4b49-ba58-34fb33dd9286,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-eccaf27f-6a26-47bf-9081-ee91ceb9dd4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-2d408209-71e5-41b1-81a9-ddb92179dac1,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-284821e7-2b80-4c72-9eb2-94c56ce1b84c,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-5625d891-b6b5-43c2-b6ba-6bf0d409c1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-e1d7638d-add4-449f-a423-b7ad8ed0895b,DISK], DatanodeInfoWithStorage[127.0.0.1:35793,DS-720a629c-e413-4389-b9b5-c4b4b387874b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1925825853-172.17.0.10-1595832354075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41702,DS-8d7ef011-0bea-44cb-9bf4-69b7b0143e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39162,DS-375cd2aa-b3c1-489d-8667-192069370ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-a3abb4d0-c744-476a-b67a-a933e804bf0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-9809e116-3c6d-4413-a0ac-e070a5485342,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-f099a60f-fe8c-4636-b8d0-0d08e2e03e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-0373858b-df97-4544-a11e-50c72f22a89d,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-6c952935-2821-40eb-87f3-f7f3402b0277,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-68b422e0-1e14-4ab5-8ab2-1da09a1286dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1925825853-172.17.0.10-1595832354075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41702,DS-8d7ef011-0bea-44cb-9bf4-69b7b0143e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39162,DS-375cd2aa-b3c1-489d-8667-192069370ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-a3abb4d0-c744-476a-b67a-a933e804bf0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-9809e116-3c6d-4413-a0ac-e070a5485342,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-f099a60f-fe8c-4636-b8d0-0d08e2e03e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-0373858b-df97-4544-a11e-50c72f22a89d,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-6c952935-2821-40eb-87f3-f7f3402b0277,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-68b422e0-1e14-4ab5-8ab2-1da09a1286dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1682370872-172.17.0.10-1595832763062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45836,DS-4fe24b2c-f838-4bc4-b411-9ce254d02f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-723a4899-1037-44da-b150-6e59373bf793,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-3035791e-cb0a-4cec-a171-d6398ffe6984,DISK], DatanodeInfoWithStorage[127.0.0.1:36934,DS-6592c5a9-21fe-4df6-86e3-9bb6af72b1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-b8784f78-af56-4e49-ad28-27f84d25c440,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-2fa3a87e-337e-4f01-b794-8086221601e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-32d393fa-72e6-48f9-9a97-c634ecd0a964,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-48d185a1-d733-48a6-95f5-179dea236322,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1682370872-172.17.0.10-1595832763062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45836,DS-4fe24b2c-f838-4bc4-b411-9ce254d02f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-723a4899-1037-44da-b150-6e59373bf793,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-3035791e-cb0a-4cec-a171-d6398ffe6984,DISK], DatanodeInfoWithStorage[127.0.0.1:36934,DS-6592c5a9-21fe-4df6-86e3-9bb6af72b1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-b8784f78-af56-4e49-ad28-27f84d25c440,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-2fa3a87e-337e-4f01-b794-8086221601e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-32d393fa-72e6-48f9-9a97-c634ecd0a964,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-48d185a1-d733-48a6-95f5-179dea236322,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-386971003-172.17.0.10-1595833341754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40692,DS-30face8b-dc59-41a1-a3c5-bc8087fa4ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:43120,DS-1da41ea2-4e46-4d30-b914-363f662d2556,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-299173f8-a5cf-4165-9cf6-6efb77fe594b,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-e16817e7-5ce3-46f0-9464-85ba9a6e6074,DISK], DatanodeInfoWithStorage[127.0.0.1:44254,DS-54ab3ad6-e30b-4f4a-ae99-d0f0591ba1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-911d5cfe-a5b5-4f06-8126-81188b21c0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-f87ffa32-a080-4f30-b39a-3a3c0837b549,DISK], DatanodeInfoWithStorage[127.0.0.1:44524,DS-98f55705-d214-4bfb-a593-0642969847c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-386971003-172.17.0.10-1595833341754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40692,DS-30face8b-dc59-41a1-a3c5-bc8087fa4ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:43120,DS-1da41ea2-4e46-4d30-b914-363f662d2556,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-299173f8-a5cf-4165-9cf6-6efb77fe594b,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-e16817e7-5ce3-46f0-9464-85ba9a6e6074,DISK], DatanodeInfoWithStorage[127.0.0.1:44254,DS-54ab3ad6-e30b-4f4a-ae99-d0f0591ba1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-911d5cfe-a5b5-4f06-8126-81188b21c0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-f87ffa32-a080-4f30-b39a-3a3c0837b549,DISK], DatanodeInfoWithStorage[127.0.0.1:44524,DS-98f55705-d214-4bfb-a593-0642969847c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1587735462-172.17.0.10-1595833448424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38445,DS-9b48ac2a-5f26-4f2b-a484-3dd576afa7db,DISK], DatanodeInfoWithStorage[127.0.0.1:46182,DS-33cefee8-b92c-4986-8ff5-135e60879467,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-8df6438e-d353-456f-8e35-71a46584cbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-73dd2c5f-f37d-4868-acbc-3c7f5cfb9d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-cba1a32a-543e-40c2-8ab9-2fdb551cde69,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-8dcc16c0-4a4a-4b91-9990-e70b03f412d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-a0757cb5-dc79-4119-923a-9c0641fcfc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-8982731f-e261-4b5c-991a-6056da73eff7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1587735462-172.17.0.10-1595833448424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38445,DS-9b48ac2a-5f26-4f2b-a484-3dd576afa7db,DISK], DatanodeInfoWithStorage[127.0.0.1:46182,DS-33cefee8-b92c-4986-8ff5-135e60879467,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-8df6438e-d353-456f-8e35-71a46584cbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-73dd2c5f-f37d-4868-acbc-3c7f5cfb9d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-cba1a32a-543e-40c2-8ab9-2fdb551cde69,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-8dcc16c0-4a4a-4b91-9990-e70b03f412d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-a0757cb5-dc79-4119-923a-9c0641fcfc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-8982731f-e261-4b5c-991a-6056da73eff7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-128367493-172.17.0.10-1595833487339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38291,DS-b34509be-dd05-4e58-af32-43984a34f029,DISK], DatanodeInfoWithStorage[127.0.0.1:35647,DS-c72473c9-577e-4869-8957-209ca180bcee,DISK], DatanodeInfoWithStorage[127.0.0.1:44856,DS-ce410dec-82d1-4555-879a-22d12c39e6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-5b582214-f194-41bb-af3f-8501c4596b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-7187287d-4278-4002-9f2b-25a6b3b8bba3,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-3149b2cf-b4cb-48d0-9520-769e2c4b2ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-76c7aa99-5a86-4a0f-9210-81063017e058,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-fd1e241b-fdd5-48f7-9b32-bf9e6cd1ef43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-128367493-172.17.0.10-1595833487339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38291,DS-b34509be-dd05-4e58-af32-43984a34f029,DISK], DatanodeInfoWithStorage[127.0.0.1:35647,DS-c72473c9-577e-4869-8957-209ca180bcee,DISK], DatanodeInfoWithStorage[127.0.0.1:44856,DS-ce410dec-82d1-4555-879a-22d12c39e6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-5b582214-f194-41bb-af3f-8501c4596b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-7187287d-4278-4002-9f2b-25a6b3b8bba3,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-3149b2cf-b4cb-48d0-9520-769e2c4b2ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-76c7aa99-5a86-4a0f-9210-81063017e058,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-fd1e241b-fdd5-48f7-9b32-bf9e6cd1ef43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-889458342-172.17.0.10-1595833868510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33804,DS-0b45920c-5fff-4354-b284-f1127cffc277,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-9a6ee497-aab6-4474-ae84-69a5599a2abb,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-7965e1f7-a317-4738-a430-56e2925e7eac,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-4f68b96e-4e53-443e-b7d5-be8b4b68e7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39712,DS-6fb1d40e-e460-49ea-b145-dae48bd63db1,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-8c2e2b97-d0f1-4ae4-bf80-82ad3943fe05,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-be513b7c-bce4-48de-9811-0d06a81d29f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-c67ad669-8b64-4d2c-8902-451f3e8b4334,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-889458342-172.17.0.10-1595833868510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33804,DS-0b45920c-5fff-4354-b284-f1127cffc277,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-9a6ee497-aab6-4474-ae84-69a5599a2abb,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-7965e1f7-a317-4738-a430-56e2925e7eac,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-4f68b96e-4e53-443e-b7d5-be8b4b68e7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39712,DS-6fb1d40e-e460-49ea-b145-dae48bd63db1,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-8c2e2b97-d0f1-4ae4-bf80-82ad3943fe05,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-be513b7c-bce4-48de-9811-0d06a81d29f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-c67ad669-8b64-4d2c-8902-451f3e8b4334,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1635641558-172.17.0.10-1595833946385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43031,DS-b3fdb5b2-18f5-4a00-b041-7e2a2738b287,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-3c6c3aa5-60ac-467e-8ba3-90fabf144cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-69042d4e-d089-4040-8aa3-af8f25e399e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-ae551a68-995b-428a-a956-d47fd67987ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-16aacd23-ec9c-420b-a266-6e1fcabc3063,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-d24c51a8-5e69-49d5-b236-af167e75ca16,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-33872206-4c4a-4325-a5b3-4accad62d018,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-78d04fb7-dfda-47ff-844b-db1442cc46a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1635641558-172.17.0.10-1595833946385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43031,DS-b3fdb5b2-18f5-4a00-b041-7e2a2738b287,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-3c6c3aa5-60ac-467e-8ba3-90fabf144cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-69042d4e-d089-4040-8aa3-af8f25e399e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-ae551a68-995b-428a-a956-d47fd67987ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-16aacd23-ec9c-420b-a266-6e1fcabc3063,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-d24c51a8-5e69-49d5-b236-af167e75ca16,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-33872206-4c4a-4325-a5b3-4accad62d018,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-78d04fb7-dfda-47ff-844b-db1442cc46a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-684606873-172.17.0.10-1595834435747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36930,DS-d6241c32-6e9c-4552-be2d-83ce4ccf9e95,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-d503bba8-1659-434f-812f-bf5ab701328b,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-2d2cf64a-d55f-4c2c-8457-6a04bf6735f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-7d23d551-565f-4d91-a0e0-99dc014fb4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-913cd530-2062-4d37-b1c6-ccff144149ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-11354dd0-c634-4da9-bbc0-b35f3166d106,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-9c73961a-66f9-46be-9e14-ddd2e9338ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-00ebaf08-4043-4ad4-8d05-bc5deff3383a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-684606873-172.17.0.10-1595834435747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36930,DS-d6241c32-6e9c-4552-be2d-83ce4ccf9e95,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-d503bba8-1659-434f-812f-bf5ab701328b,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-2d2cf64a-d55f-4c2c-8457-6a04bf6735f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-7d23d551-565f-4d91-a0e0-99dc014fb4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-913cd530-2062-4d37-b1c6-ccff144149ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-11354dd0-c634-4da9-bbc0-b35f3166d106,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-9c73961a-66f9-46be-9e14-ddd2e9338ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-00ebaf08-4043-4ad4-8d05-bc5deff3383a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1804827430-172.17.0.10-1595834754636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37356,DS-1d7960cf-2943-4661-8e9e-0f409210abcb,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-a940b46e-73f2-4080-846b-212c04bcd36d,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-b7f17958-f8b6-448d-b566-66b2df2a0e69,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-acf8fa62-49b5-4f9e-a5c2-c31b599f3731,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-6b4e772b-d72e-4b2a-9639-75f5abaa0d04,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-54872e79-2671-4294-a0ac-1b4531f0605a,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-fcb5eedb-e016-4b8d-845a-dad962a92db6,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-57ee2b26-691b-4000-80a6-3e6d140dc83e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1804827430-172.17.0.10-1595834754636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37356,DS-1d7960cf-2943-4661-8e9e-0f409210abcb,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-a940b46e-73f2-4080-846b-212c04bcd36d,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-b7f17958-f8b6-448d-b566-66b2df2a0e69,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-acf8fa62-49b5-4f9e-a5c2-c31b599f3731,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-6b4e772b-d72e-4b2a-9639-75f5abaa0d04,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-54872e79-2671-4294-a0ac-1b4531f0605a,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-fcb5eedb-e016-4b8d-845a-dad962a92db6,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-57ee2b26-691b-4000-80a6-3e6d140dc83e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-264466961-172.17.0.10-1595834866119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39005,DS-d09152e7-a53b-44bb-91c5-1ed6d8c9d729,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-bfbd928d-689c-45fe-b147-aab2f5006ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-913d1c2c-59ba-4ac1-ba4e-2df53fa55f46,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-1ee2d9e2-daed-4cab-8bc2-64afb2eaa355,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-fe5c838b-95bf-47de-9f09-02fe0d443b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-237d1a79-2321-44a0-ae6e-1f9c13cabf0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-fc5c832e-cb39-4284-af94-828a64257aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-79a84bb8-bb42-4166-870e-67b37909722a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-264466961-172.17.0.10-1595834866119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39005,DS-d09152e7-a53b-44bb-91c5-1ed6d8c9d729,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-bfbd928d-689c-45fe-b147-aab2f5006ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-913d1c2c-59ba-4ac1-ba4e-2df53fa55f46,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-1ee2d9e2-daed-4cab-8bc2-64afb2eaa355,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-fe5c838b-95bf-47de-9f09-02fe0d443b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-237d1a79-2321-44a0-ae6e-1f9c13cabf0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-fc5c832e-cb39-4284-af94-828a64257aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-79a84bb8-bb42-4166-870e-67b37909722a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-82422041-172.17.0.10-1595835076005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35200,DS-7b75e700-a152-4373-bc70-fc5ed8e131a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-c76713ba-871c-4739-8502-2e525cf57e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-7850277c-eeea-45e4-8a4f-2d2ec3910a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-e9745622-4a97-484f-aa0f-edf4dd4853f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44858,DS-ce91e2d9-717d-4857-b508-4475973b244b,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-1c745e97-b587-4c0c-8b54-4054ee56f0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-ec7d800f-9992-4e63-908d-e1651430fc87,DISK], DatanodeInfoWithStorage[127.0.0.1:45723,DS-eb2d8242-0289-4890-aa9a-df6a84b593fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-82422041-172.17.0.10-1595835076005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35200,DS-7b75e700-a152-4373-bc70-fc5ed8e131a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-c76713ba-871c-4739-8502-2e525cf57e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-7850277c-eeea-45e4-8a4f-2d2ec3910a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-e9745622-4a97-484f-aa0f-edf4dd4853f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44858,DS-ce91e2d9-717d-4857-b508-4475973b244b,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-1c745e97-b587-4c0c-8b54-4054ee56f0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-ec7d800f-9992-4e63-908d-e1651430fc87,DISK], DatanodeInfoWithStorage[127.0.0.1:45723,DS-eb2d8242-0289-4890-aa9a-df6a84b593fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461086235-172.17.0.10-1595835475816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33237,DS-f851289b-d0f9-459a-bf7f-0d34e7928973,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-7d7dcb65-9a0c-494e-a520-e67e2730ce23,DISK], DatanodeInfoWithStorage[127.0.0.1:45182,DS-a28efeaf-8ab6-407d-b00b-8d2f0e8214eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-0e9c0b4d-7996-47de-bef6-c5f9d0985e75,DISK], DatanodeInfoWithStorage[127.0.0.1:43841,DS-69bc5cec-1310-45a5-a149-00df246988da,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-1696d942-32c1-425f-bcba-1ac6f772e766,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-b469b5ff-bec4-432b-a215-533b31b9d5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-bf78d3db-0809-4b19-b773-16d6f565bfb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461086235-172.17.0.10-1595835475816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33237,DS-f851289b-d0f9-459a-bf7f-0d34e7928973,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-7d7dcb65-9a0c-494e-a520-e67e2730ce23,DISK], DatanodeInfoWithStorage[127.0.0.1:45182,DS-a28efeaf-8ab6-407d-b00b-8d2f0e8214eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-0e9c0b4d-7996-47de-bef6-c5f9d0985e75,DISK], DatanodeInfoWithStorage[127.0.0.1:43841,DS-69bc5cec-1310-45a5-a149-00df246988da,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-1696d942-32c1-425f-bcba-1ac6f772e766,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-b469b5ff-bec4-432b-a215-533b31b9d5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-bf78d3db-0809-4b19-b773-16d6f565bfb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1073563795-172.17.0.10-1595835697056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39267,DS-10024609-89e1-412a-afc5-4c9ed43dae4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-8514ab74-c702-4b21-8bc3-0d740899ae81,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-e4058d1c-8032-46d4-b202-7809a22e90d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-212a7a96-83e2-4c48-a9a6-b4ccc656ea2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-7f17dd60-4960-47b6-9c7b-940145dc4cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-e1dd95dc-bb03-46dd-97d2-031b9993aa77,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-4e253ce8-5eba-41cb-87ec-526a36c7cd52,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-aa6eefea-d0c1-42dc-867f-281bd7c0421b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1073563795-172.17.0.10-1595835697056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39267,DS-10024609-89e1-412a-afc5-4c9ed43dae4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-8514ab74-c702-4b21-8bc3-0d740899ae81,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-e4058d1c-8032-46d4-b202-7809a22e90d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-212a7a96-83e2-4c48-a9a6-b4ccc656ea2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-7f17dd60-4960-47b6-9c7b-940145dc4cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-e1dd95dc-bb03-46dd-97d2-031b9993aa77,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-4e253ce8-5eba-41cb-87ec-526a36c7cd52,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-aa6eefea-d0c1-42dc-867f-281bd7c0421b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5191
