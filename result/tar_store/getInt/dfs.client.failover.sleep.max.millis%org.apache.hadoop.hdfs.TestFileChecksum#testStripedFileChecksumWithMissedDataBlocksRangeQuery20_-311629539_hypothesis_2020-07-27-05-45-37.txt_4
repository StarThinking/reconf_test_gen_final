reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 150
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 150
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-508777586-172.17.0.13-1595828794105:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33478,DS-7d6358a9-c1c8-45e5-ae57-5b06d815e808,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-c5af4d52-642b-47fe-a443-b62492bd6a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-1c1437c1-93d5-479f-bbda-171dfea38dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-c79e56bf-c04c-4146-b03f-a7e90eeae56d,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-18615d5c-0e26-4fb6-bf8d-9268cd4988bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-30b1d34a-0d7a-4d9d-b503-415142a35bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42340,DS-ece2479a-83d7-4e6d-8de9-47a0be54333d,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-f0a372e9-a8e9-42bf-87b3-8790c086e13f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-508777586-172.17.0.13-1595828794105:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33478,DS-7d6358a9-c1c8-45e5-ae57-5b06d815e808,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-c5af4d52-642b-47fe-a443-b62492bd6a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-1c1437c1-93d5-479f-bbda-171dfea38dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-c79e56bf-c04c-4146-b03f-a7e90eeae56d,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-18615d5c-0e26-4fb6-bf8d-9268cd4988bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-30b1d34a-0d7a-4d9d-b503-415142a35bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42340,DS-ece2479a-83d7-4e6d-8de9-47a0be54333d,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-f0a372e9-a8e9-42bf-87b3-8790c086e13f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 150
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1402121295-172.17.0.13-1595828981888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43660,DS-5229bb02-cb2f-4c25-81d8-4b87d9934593,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-6039bf9b-139a-49b8-a2ba-063e189eef77,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-12fcc4fa-2dd9-4ae4-8e06-b4b862061061,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-a3525b2c-9a2a-4bec-8b8d-da5892e47d69,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-33057757-916d-4510-8576-293c707a2246,DISK], DatanodeInfoWithStorage[127.0.0.1:40707,DS-539892a9-4442-48b7-be69-401a56ed1d20,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-c1360557-0ca2-4eee-b23d-773aa3db37eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-d6396f8c-8011-49a0-a108-ac939258ab96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1402121295-172.17.0.13-1595828981888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43660,DS-5229bb02-cb2f-4c25-81d8-4b87d9934593,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-6039bf9b-139a-49b8-a2ba-063e189eef77,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-12fcc4fa-2dd9-4ae4-8e06-b4b862061061,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-a3525b2c-9a2a-4bec-8b8d-da5892e47d69,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-33057757-916d-4510-8576-293c707a2246,DISK], DatanodeInfoWithStorage[127.0.0.1:40707,DS-539892a9-4442-48b7-be69-401a56ed1d20,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-c1360557-0ca2-4eee-b23d-773aa3db37eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-d6396f8c-8011-49a0-a108-ac939258ab96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 150
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1757290856-172.17.0.13-1595829123411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38688,DS-102d35ac-a188-4253-9f8e-20e6ba5f3335,DISK], DatanodeInfoWithStorage[127.0.0.1:43240,DS-7b922fe3-faf0-49bb-b9f8-ed7795396114,DISK], DatanodeInfoWithStorage[127.0.0.1:36453,DS-105c56b1-4e15-4d5f-8898-d7924fbd9c31,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-8acbd175-0b03-4a2b-9e2e-984918ad0a30,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-d67fc8ae-43d7-4587-b6e4-66c94d6bd763,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-1d18dc5f-8a2c-4ab1-a0ef-814e411c8adf,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-47172777-57cc-4b8e-a8d1-3a1a6d074cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-79a43781-ae57-4c8b-8947-52851a55364c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1757290856-172.17.0.13-1595829123411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38688,DS-102d35ac-a188-4253-9f8e-20e6ba5f3335,DISK], DatanodeInfoWithStorage[127.0.0.1:43240,DS-7b922fe3-faf0-49bb-b9f8-ed7795396114,DISK], DatanodeInfoWithStorage[127.0.0.1:36453,DS-105c56b1-4e15-4d5f-8898-d7924fbd9c31,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-8acbd175-0b03-4a2b-9e2e-984918ad0a30,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-d67fc8ae-43d7-4587-b6e4-66c94d6bd763,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-1d18dc5f-8a2c-4ab1-a0ef-814e411c8adf,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-47172777-57cc-4b8e-a8d1-3a1a6d074cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-79a43781-ae57-4c8b-8947-52851a55364c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 150
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-787706534-172.17.0.13-1595830018033:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37599,DS-4d635b06-c4a8-44f3-9c5a-9fc8476d9b30,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-95967c12-f7f5-4dab-8053-9c84bbc75a43,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-81dcbfe6-55c4-4aca-b844-7777589f1ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-9906aca0-421c-448a-a143-fb94bb9c2c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-92587ccd-c5f3-4dbb-871d-74a69287314c,DISK], DatanodeInfoWithStorage[127.0.0.1:46854,DS-8032a852-e36a-4c6f-8789-ce3e02b7d9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-45d0ffb4-598d-43c4-8279-a701e9382e00,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-8710f28d-808d-4ea4-b738-d6ef7d472208,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-787706534-172.17.0.13-1595830018033:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37599,DS-4d635b06-c4a8-44f3-9c5a-9fc8476d9b30,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-95967c12-f7f5-4dab-8053-9c84bbc75a43,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-81dcbfe6-55c4-4aca-b844-7777589f1ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-9906aca0-421c-448a-a143-fb94bb9c2c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-92587ccd-c5f3-4dbb-871d-74a69287314c,DISK], DatanodeInfoWithStorage[127.0.0.1:46854,DS-8032a852-e36a-4c6f-8789-ce3e02b7d9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-45d0ffb4-598d-43c4-8279-a701e9382e00,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-8710f28d-808d-4ea4-b738-d6ef7d472208,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 150
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-567577802-172.17.0.13-1595830181503:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40374,DS-18644fa9-7f39-4dfd-98eb-e3f6da431548,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-b3984711-2936-4377-8ebd-c6e14f0e6561,DISK], DatanodeInfoWithStorage[127.0.0.1:35789,DS-16c768dc-7787-4611-a6ad-3ebb6cea1173,DISK], DatanodeInfoWithStorage[127.0.0.1:43304,DS-c88e63cd-1b5d-42ff-8651-08b353f6a441,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-5859b91d-0dfb-44e2-9844-c73405027c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41221,DS-21929855-aeed-4de6-84d2-e935d5e15e58,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-77db9bc1-baa0-42a4-9591-724d99f58d61,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-85bcc6fa-9177-43d4-9b85-84ba436d8081,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-567577802-172.17.0.13-1595830181503:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40374,DS-18644fa9-7f39-4dfd-98eb-e3f6da431548,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-b3984711-2936-4377-8ebd-c6e14f0e6561,DISK], DatanodeInfoWithStorage[127.0.0.1:35789,DS-16c768dc-7787-4611-a6ad-3ebb6cea1173,DISK], DatanodeInfoWithStorage[127.0.0.1:43304,DS-c88e63cd-1b5d-42ff-8651-08b353f6a441,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-5859b91d-0dfb-44e2-9844-c73405027c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41221,DS-21929855-aeed-4de6-84d2-e935d5e15e58,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-77db9bc1-baa0-42a4-9591-724d99f58d61,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-85bcc6fa-9177-43d4-9b85-84ba436d8081,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 150
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-369083400-172.17.0.13-1595830477393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38636,DS-abf0cf36-251e-4658-89b1-428e266b79e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-7851df1a-0e59-495a-99b3-94d852ca45d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-0af538ed-8bde-4d8e-8f91-515e365a5558,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-cc2fd54a-5d74-4e4d-a33c-69150b0a166a,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-e9b06438-9c4d-4198-8c1f-7f262be342b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-2bc3e2c1-391a-4d0a-ada0-081beaf86f74,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-5da1f63a-ab22-4005-b0af-c33f9e258a70,DISK], DatanodeInfoWithStorage[127.0.0.1:40856,DS-88506631-cb4c-49c4-abc2-72917c087308,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-369083400-172.17.0.13-1595830477393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38636,DS-abf0cf36-251e-4658-89b1-428e266b79e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-7851df1a-0e59-495a-99b3-94d852ca45d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-0af538ed-8bde-4d8e-8f91-515e365a5558,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-cc2fd54a-5d74-4e4d-a33c-69150b0a166a,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-e9b06438-9c4d-4198-8c1f-7f262be342b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-2bc3e2c1-391a-4d0a-ada0-081beaf86f74,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-5da1f63a-ab22-4005-b0af-c33f9e258a70,DISK], DatanodeInfoWithStorage[127.0.0.1:40856,DS-88506631-cb4c-49c4-abc2-72917c087308,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 150
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-695539722-172.17.0.13-1595831251532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40038,DS-92f40171-4951-44ec-bcdc-17e0ac686fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:42457,DS-7ed3f75d-105c-4025-83ea-c99893044f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-7e34ffda-2a97-4edd-b6d3-14234da94825,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-ea49cb25-7067-48c9-a2c3-216232774460,DISK], DatanodeInfoWithStorage[127.0.0.1:33219,DS-a01bf62c-6942-4aa9-9dc8-db434ac63f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-15b8ff80-cde1-4cb6-b465-078b10bceb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-2a350de7-3f9f-47ed-af3a-962f377f3ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-40964145-c1a7-4004-a337-3a174626f1d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-695539722-172.17.0.13-1595831251532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40038,DS-92f40171-4951-44ec-bcdc-17e0ac686fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:42457,DS-7ed3f75d-105c-4025-83ea-c99893044f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-7e34ffda-2a97-4edd-b6d3-14234da94825,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-ea49cb25-7067-48c9-a2c3-216232774460,DISK], DatanodeInfoWithStorage[127.0.0.1:33219,DS-a01bf62c-6942-4aa9-9dc8-db434ac63f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-15b8ff80-cde1-4cb6-b465-078b10bceb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-2a350de7-3f9f-47ed-af3a-962f377f3ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-40964145-c1a7-4004-a337-3a174626f1d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 150
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-842187655-172.17.0.13-1595831511542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39978,DS-dc63b52f-727f-424a-89bf-81fd27b64d29,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-9378609d-c45d-4a53-b87f-d4522d7808cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38720,DS-5be0fa20-d0ed-407f-9017-3257a498263d,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-caaa6f55-d4a1-4a80-b522-1c274b950fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-e390bb86-6d9f-405a-a91a-b86fdb4d591c,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-3af6ccb9-e535-4f59-b890-00b1233bb95d,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-f33f7eee-40de-48dc-a444-308d67a2a269,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-f8ed8764-fc56-4d6e-badf-ede1b4b7fb75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-842187655-172.17.0.13-1595831511542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39978,DS-dc63b52f-727f-424a-89bf-81fd27b64d29,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-9378609d-c45d-4a53-b87f-d4522d7808cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38720,DS-5be0fa20-d0ed-407f-9017-3257a498263d,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-caaa6f55-d4a1-4a80-b522-1c274b950fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-e390bb86-6d9f-405a-a91a-b86fdb4d591c,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-3af6ccb9-e535-4f59-b890-00b1233bb95d,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-f33f7eee-40de-48dc-a444-308d67a2a269,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-f8ed8764-fc56-4d6e-badf-ede1b4b7fb75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 150
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1612645797-172.17.0.13-1595831677745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35593,DS-bf44fc5b-b277-4c0f-bf79-dcd8a8b29668,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-6200e76a-5164-4c10-9c25-02a3df352c99,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-56eaa58e-2166-4374-be90-3db164b5978a,DISK], DatanodeInfoWithStorage[127.0.0.1:42354,DS-011e9245-c243-4382-ad92-65574660d7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-68b9f212-22f6-40c2-aa33-7d5f15c83bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33375,DS-a2e9b8ae-5e25-433d-aced-15f508b4f349,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-0ad07e25-0c17-4c29-b34b-8e26dccf371f,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-14dd29e2-5067-4d5e-a740-c0e9e55d9a43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1612645797-172.17.0.13-1595831677745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35593,DS-bf44fc5b-b277-4c0f-bf79-dcd8a8b29668,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-6200e76a-5164-4c10-9c25-02a3df352c99,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-56eaa58e-2166-4374-be90-3db164b5978a,DISK], DatanodeInfoWithStorage[127.0.0.1:42354,DS-011e9245-c243-4382-ad92-65574660d7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-68b9f212-22f6-40c2-aa33-7d5f15c83bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33375,DS-a2e9b8ae-5e25-433d-aced-15f508b4f349,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-0ad07e25-0c17-4c29-b34b-8e26dccf371f,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-14dd29e2-5067-4d5e-a740-c0e9e55d9a43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 150
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1903753953-172.17.0.13-1595832079102:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45671,DS-8fb6c475-27ec-430a-b1ba-fb40df68c8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-14a08daa-ac23-4d8b-b98c-48cf77bf198a,DISK], DatanodeInfoWithStorage[127.0.0.1:36910,DS-d7c18880-6450-4412-b20d-5c9a319f0624,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-25d6fc12-d470-401e-b352-21234fac39a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-cea55573-49fb-432f-814c-9426db502383,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-ca840c0d-de91-4ad8-bbaf-005428ba206c,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-2e6101b1-1f64-4b0e-a132-c4c3ee6c1338,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-02632d4d-2a19-4ce0-998d-d19a19d8681d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1903753953-172.17.0.13-1595832079102:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45671,DS-8fb6c475-27ec-430a-b1ba-fb40df68c8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-14a08daa-ac23-4d8b-b98c-48cf77bf198a,DISK], DatanodeInfoWithStorage[127.0.0.1:36910,DS-d7c18880-6450-4412-b20d-5c9a319f0624,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-25d6fc12-d470-401e-b352-21234fac39a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-cea55573-49fb-432f-814c-9426db502383,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-ca840c0d-de91-4ad8-bbaf-005428ba206c,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-2e6101b1-1f64-4b0e-a132-c4c3ee6c1338,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-02632d4d-2a19-4ce0-998d-d19a19d8681d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 150
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-471209187-172.17.0.13-1595832827057:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40666,DS-9ac93b1f-1a87-463e-9a80-826d8aa62e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-3672e187-06bf-43f9-a2f1-6733030279ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46495,DS-6ccf8239-0981-454e-95b3-ffd3227da18d,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-b4211400-beaa-4395-b613-8462d40be90f,DISK], DatanodeInfoWithStorage[127.0.0.1:46634,DS-5949a68b-1f6b-4847-8305-0e2645919318,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-1dac046a-83be-4525-a72c-995ea83f3629,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-fb8551f2-cfcf-43df-9b15-81cb993c826c,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-a32b037e-8016-42c6-8c92-fd941bd313d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-471209187-172.17.0.13-1595832827057:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40666,DS-9ac93b1f-1a87-463e-9a80-826d8aa62e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-3672e187-06bf-43f9-a2f1-6733030279ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46495,DS-6ccf8239-0981-454e-95b3-ffd3227da18d,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-b4211400-beaa-4395-b613-8462d40be90f,DISK], DatanodeInfoWithStorage[127.0.0.1:46634,DS-5949a68b-1f6b-4847-8305-0e2645919318,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-1dac046a-83be-4525-a72c-995ea83f3629,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-fb8551f2-cfcf-43df-9b15-81cb993c826c,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-a32b037e-8016-42c6-8c92-fd941bd313d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 150
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1735069456-172.17.0.13-1595832916751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43600,DS-100109e9-d898-4f08-8944-7b62e651cfe4,DISK], DatanodeInfoWithStorage[127.0.0.1:37123,DS-d1ec33b1-99d8-4494-9fc5-ce0dde44b082,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-c921f5ee-e215-44a4-90c0-a0edede4a719,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-cf19889f-e2e7-493a-954e-8bcefde12769,DISK], DatanodeInfoWithStorage[127.0.0.1:33900,DS-5810396d-cbbf-469a-8971-ec95a28aa626,DISK], DatanodeInfoWithStorage[127.0.0.1:44240,DS-c254da83-f89e-45a5-b101-a28c69042d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45704,DS-a7aba640-da68-4e49-8d2f-4c68057974a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-cad2d688-c7c4-48ae-a8f3-88b94e9b5de8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1735069456-172.17.0.13-1595832916751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43600,DS-100109e9-d898-4f08-8944-7b62e651cfe4,DISK], DatanodeInfoWithStorage[127.0.0.1:37123,DS-d1ec33b1-99d8-4494-9fc5-ce0dde44b082,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-c921f5ee-e215-44a4-90c0-a0edede4a719,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-cf19889f-e2e7-493a-954e-8bcefde12769,DISK], DatanodeInfoWithStorage[127.0.0.1:33900,DS-5810396d-cbbf-469a-8971-ec95a28aa626,DISK], DatanodeInfoWithStorage[127.0.0.1:44240,DS-c254da83-f89e-45a5-b101-a28c69042d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45704,DS-a7aba640-da68-4e49-8d2f-4c68057974a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-cad2d688-c7c4-48ae-a8f3-88b94e9b5de8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 150
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-634520679-172.17.0.13-1595833110202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36984,DS-75c9fd19-15b2-4271-9eb2-5fe697d8c5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-a1b681cf-7764-4541-9365-102ce1bdca0d,DISK], DatanodeInfoWithStorage[127.0.0.1:32824,DS-e142a265-53e9-435f-9c3b-71d073918ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-b73b40f8-ba02-4099-a747-9c1fe91fb06f,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-79d9faed-c13f-4948-9275-cd72b64c60f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-517e47ac-f8b4-45bf-aa3f-fac883772eda,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-1a04ef3e-a9d9-492f-bf66-1cb59521b2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-f70619ec-b891-4abe-a46b-89fc32b78d50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-634520679-172.17.0.13-1595833110202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36984,DS-75c9fd19-15b2-4271-9eb2-5fe697d8c5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-a1b681cf-7764-4541-9365-102ce1bdca0d,DISK], DatanodeInfoWithStorage[127.0.0.1:32824,DS-e142a265-53e9-435f-9c3b-71d073918ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-b73b40f8-ba02-4099-a747-9c1fe91fb06f,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-79d9faed-c13f-4948-9275-cd72b64c60f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-517e47ac-f8b4-45bf-aa3f-fac883772eda,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-1a04ef3e-a9d9-492f-bf66-1cb59521b2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-f70619ec-b891-4abe-a46b-89fc32b78d50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 150
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1178696122-172.17.0.13-1595833552487:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40635,DS-2e71772e-e284-43d3-8548-f6d8458f2ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-1d3eccad-85fe-4833-9b99-2b5857bc43a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-3467fe93-7958-4578-8b03-a037ed8c2f89,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-0c4b615e-5668-46f8-aace-22ad9fce1ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-7e848ba3-1f18-45ae-96de-011e6e72d91c,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-da697859-3d04-4535-9f86-5e695af2d1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37611,DS-e36013bb-6313-4b43-8da4-aaac86130fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-ea24313b-ecb5-47ef-9f4e-bf5c6f4177b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1178696122-172.17.0.13-1595833552487:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40635,DS-2e71772e-e284-43d3-8548-f6d8458f2ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-1d3eccad-85fe-4833-9b99-2b5857bc43a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-3467fe93-7958-4578-8b03-a037ed8c2f89,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-0c4b615e-5668-46f8-aace-22ad9fce1ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-7e848ba3-1f18-45ae-96de-011e6e72d91c,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-da697859-3d04-4535-9f86-5e695af2d1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37611,DS-e36013bb-6313-4b43-8da4-aaac86130fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-ea24313b-ecb5-47ef-9f4e-bf5c6f4177b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 150
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2145921835-172.17.0.13-1595833784284:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39025,DS-733bf9fa-1af0-4588-952c-b5e3bf6514ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-816b7e23-162d-461b-975a-20a118c17fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-ddaf16ca-fd16-4352-a911-6e17b35f2cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:34302,DS-fecf6387-4464-49e3-9b5a-436ec67f897c,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-07f09850-1a61-4614-8967-ebed7371fc30,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-9943e603-c8a4-4ead-a4a0-9a933f101168,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-8a077bb9-d928-47aa-85f7-324b2182c3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-5e8344f1-5ad6-4ba1-86ab-cd86324c602f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2145921835-172.17.0.13-1595833784284:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39025,DS-733bf9fa-1af0-4588-952c-b5e3bf6514ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-816b7e23-162d-461b-975a-20a118c17fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-ddaf16ca-fd16-4352-a911-6e17b35f2cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:34302,DS-fecf6387-4464-49e3-9b5a-436ec67f897c,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-07f09850-1a61-4614-8967-ebed7371fc30,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-9943e603-c8a4-4ead-a4a0-9a933f101168,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-8a077bb9-d928-47aa-85f7-324b2182c3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-5e8344f1-5ad6-4ba1-86ab-cd86324c602f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 150
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1470706133-172.17.0.13-1595833829668:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43535,DS-53bee5a3-9f49-4959-b34b-9fb6524e16f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-27641a30-8280-4244-8d31-19e5d8684164,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-f22bbeaf-c56a-4052-8aca-bf6cd7fd6b50,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-f81e1f9b-e01c-4ec2-b900-7304e57bd435,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-fc41fab2-71d8-43f1-9b55-335cdbe97e91,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-bbf76fac-6a19-4443-af2a-6b48f400e879,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-7ae83fa0-dd67-44e0-ad6a-0f29e17e7699,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-89917f90-39a9-4e8b-96aa-10ec1d72dfff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1470706133-172.17.0.13-1595833829668:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43535,DS-53bee5a3-9f49-4959-b34b-9fb6524e16f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-27641a30-8280-4244-8d31-19e5d8684164,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-f22bbeaf-c56a-4052-8aca-bf6cd7fd6b50,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-f81e1f9b-e01c-4ec2-b900-7304e57bd435,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-fc41fab2-71d8-43f1-9b55-335cdbe97e91,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-bbf76fac-6a19-4443-af2a-6b48f400e879,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-7ae83fa0-dd67-44e0-ad6a-0f29e17e7699,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-89917f90-39a9-4e8b-96aa-10ec1d72dfff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 150
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-38370696-172.17.0.13-1595833909572:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44022,DS-3aee0a68-1f1b-4c0d-bca2-cf212463a7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-1311301b-37d3-4a68-ab6a-dcc350e33010,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-2aa9236d-dbb5-452c-b7cc-c3ea3e8e3f56,DISK], DatanodeInfoWithStorage[127.0.0.1:41590,DS-d6b57873-965c-4fe6-8818-bde405c07048,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-b7c63782-b767-4c5e-9495-1a58f27ee79a,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-7f02aff6-e51e-4570-b736-ddf31c97b2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-494beb72-a6d3-4a79-bb88-4e34f2519d85,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-62693b9a-8046-4a1c-b3b5-88d6d410aac2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-38370696-172.17.0.13-1595833909572:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44022,DS-3aee0a68-1f1b-4c0d-bca2-cf212463a7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-1311301b-37d3-4a68-ab6a-dcc350e33010,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-2aa9236d-dbb5-452c-b7cc-c3ea3e8e3f56,DISK], DatanodeInfoWithStorage[127.0.0.1:41590,DS-d6b57873-965c-4fe6-8818-bde405c07048,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-b7c63782-b767-4c5e-9495-1a58f27ee79a,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-7f02aff6-e51e-4570-b736-ddf31c97b2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-494beb72-a6d3-4a79-bb88-4e34f2519d85,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-62693b9a-8046-4a1c-b3b5-88d6d410aac2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 150
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1894806093-172.17.0.13-1595833958972:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37462,DS-fc260efb-5523-43ca-ac6b-d0bd044fdba8,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-0de85a35-a486-4a24-971a-a674d50ffd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-cb1e930b-86de-4d9d-bb3a-f79f7a2549ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-f13087e9-efe1-46f2-a3c1-9d04891f7f34,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-5193a121-c800-414d-bc9a-6cb86de565d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40258,DS-05ffb956-1917-4655-994e-3d6d8c2208c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-709e0ee5-2982-4e32-a2a5-89432ac4e3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-472bbfa9-f55c-460a-836a-d9f6c8077a40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1894806093-172.17.0.13-1595833958972:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37462,DS-fc260efb-5523-43ca-ac6b-d0bd044fdba8,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-0de85a35-a486-4a24-971a-a674d50ffd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-cb1e930b-86de-4d9d-bb3a-f79f7a2549ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-f13087e9-efe1-46f2-a3c1-9d04891f7f34,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-5193a121-c800-414d-bc9a-6cb86de565d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40258,DS-05ffb956-1917-4655-994e-3d6d8c2208c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-709e0ee5-2982-4e32-a2a5-89432ac4e3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-472bbfa9-f55c-460a-836a-d9f6c8077a40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 150
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1160320867-172.17.0.13-1595834909394:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42494,DS-c4d671f9-a60b-40dd-9cc0-31314e66fd80,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-96610e1f-146e-4870-8cc0-245a1194576e,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-cb4258bd-5f70-454e-9b47-7daa879035dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42960,DS-433ea496-3232-4088-8701-17f3ce93a66c,DISK], DatanodeInfoWithStorage[127.0.0.1:39271,DS-b87db12e-2020-46ba-9cc6-2713ff511e53,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-b4904d50-ee3c-4c93-b243-6c22103ea1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38484,DS-2b1c9b94-30a2-4d31-a0cd-9aa6d5738910,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-9ed06b3f-77b8-4bf2-a96e-f6b23d55198f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1160320867-172.17.0.13-1595834909394:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42494,DS-c4d671f9-a60b-40dd-9cc0-31314e66fd80,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-96610e1f-146e-4870-8cc0-245a1194576e,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-cb4258bd-5f70-454e-9b47-7daa879035dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42960,DS-433ea496-3232-4088-8701-17f3ce93a66c,DISK], DatanodeInfoWithStorage[127.0.0.1:39271,DS-b87db12e-2020-46ba-9cc6-2713ff511e53,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-b4904d50-ee3c-4c93-b243-6c22103ea1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38484,DS-2b1c9b94-30a2-4d31-a0cd-9aa6d5738910,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-9ed06b3f-77b8-4bf2-a96e-f6b23d55198f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 150
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-277225502-172.17.0.13-1595835441129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38517,DS-60cba813-3920-4f49-aa65-d1be92b28b34,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-0834ea08-cedf-40aa-aa5b-890bd247de88,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-1141ca71-0c64-405e-8a70-4e88be0cd467,DISK], DatanodeInfoWithStorage[127.0.0.1:42072,DS-d24a53d7-80fd-4fea-b545-2d04c19fd153,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-ca7fbefa-db42-4144-95d6-debf5778d331,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-7baa1904-f608-413e-93cd-02e62c820bda,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-5ae267c9-4916-422e-9218-3c953ff96964,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-79fe6aca-c738-4bd4-92ae-d7506c22881e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-277225502-172.17.0.13-1595835441129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38517,DS-60cba813-3920-4f49-aa65-d1be92b28b34,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-0834ea08-cedf-40aa-aa5b-890bd247de88,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-1141ca71-0c64-405e-8a70-4e88be0cd467,DISK], DatanodeInfoWithStorage[127.0.0.1:42072,DS-d24a53d7-80fd-4fea-b545-2d04c19fd153,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-ca7fbefa-db42-4144-95d6-debf5778d331,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-7baa1904-f608-413e-93cd-02e62c820bda,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-5ae267c9-4916-422e-9218-3c953ff96964,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-79fe6aca-c738-4bd4-92ae-d7506c22881e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 6734
