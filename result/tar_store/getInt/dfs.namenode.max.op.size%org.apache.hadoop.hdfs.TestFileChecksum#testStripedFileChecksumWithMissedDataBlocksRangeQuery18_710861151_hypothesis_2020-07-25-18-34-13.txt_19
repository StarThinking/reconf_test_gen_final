reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 104857600
v2: 52428800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 104857600
v2: 52428800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1066899963-172.17.0.2-1595702338227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46184,DS-690ef286-418e-4b3f-a7a4-bd4f644e2223,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-a1206b89-f81a-4303-950b-836ddaa17504,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-700bf668-dca9-47b1-8a10-07f1f1c8c1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44609,DS-788bdb8f-eaf9-4cf3-b2a3-3215ea31cf3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-a735cc6c-29a7-4227-90d3-22d1e7fb2c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-f2193efc-57d4-4669-ba91-f29036ea2604,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-296cdf28-ba5f-42bb-9065-6cc707926ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-fe0c88d6-bd23-4e6f-a7cb-4b661e2fe2fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1066899963-172.17.0.2-1595702338227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46184,DS-690ef286-418e-4b3f-a7a4-bd4f644e2223,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-a1206b89-f81a-4303-950b-836ddaa17504,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-700bf668-dca9-47b1-8a10-07f1f1c8c1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44609,DS-788bdb8f-eaf9-4cf3-b2a3-3215ea31cf3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-a735cc6c-29a7-4227-90d3-22d1e7fb2c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-f2193efc-57d4-4669-ba91-f29036ea2604,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-296cdf28-ba5f-42bb-9065-6cc707926ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-fe0c88d6-bd23-4e6f-a7cb-4b661e2fe2fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 104857600
v2: 52428800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1915603291-172.17.0.2-1595702426899:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35106,DS-51773d99-924e-4a16-ad39-a49cbee185d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-aaca2b78-911c-4fc6-902f-bd3ef6ff7086,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-658b2f9a-9849-43bc-b41e-f1c96d675e74,DISK], DatanodeInfoWithStorage[127.0.0.1:40570,DS-636e22c3-de65-435f-8d7b-d04e9406297d,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-213dc8ea-6937-4fec-b9fe-7863226ecf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-10babb21-3f5a-4693-9fb0-f6dd1755dbc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-de179418-97c3-4c3f-b2c0-92bf0aa48e59,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-fd472a7b-4f74-4edd-b5a4-9aaabaf8f801,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1915603291-172.17.0.2-1595702426899:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35106,DS-51773d99-924e-4a16-ad39-a49cbee185d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-aaca2b78-911c-4fc6-902f-bd3ef6ff7086,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-658b2f9a-9849-43bc-b41e-f1c96d675e74,DISK], DatanodeInfoWithStorage[127.0.0.1:40570,DS-636e22c3-de65-435f-8d7b-d04e9406297d,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-213dc8ea-6937-4fec-b9fe-7863226ecf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-10babb21-3f5a-4693-9fb0-f6dd1755dbc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-de179418-97c3-4c3f-b2c0-92bf0aa48e59,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-fd472a7b-4f74-4edd-b5a4-9aaabaf8f801,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 104857600
v2: 52428800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-459215010-172.17.0.2-1595702611529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37596,DS-dd53cee4-eca4-495e-beae-476b3e4807b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-70489b74-a1b0-457c-9d94-a78327403c58,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-9f7cfb0f-4969-4e32-82d8-be68cec45b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40686,DS-3ef019f1-d215-4c35-a78f-3334f68e18bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-00bb3e0b-0d04-4e0f-a25c-345d82560992,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-ec812256-21a6-49c7-8fa2-e872297b97d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-4d8e1f84-205f-4cca-8501-5881a74a1b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-32463bb4-54f6-410c-a1d5-dc7b94741082,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-459215010-172.17.0.2-1595702611529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37596,DS-dd53cee4-eca4-495e-beae-476b3e4807b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-70489b74-a1b0-457c-9d94-a78327403c58,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-9f7cfb0f-4969-4e32-82d8-be68cec45b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40686,DS-3ef019f1-d215-4c35-a78f-3334f68e18bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-00bb3e0b-0d04-4e0f-a25c-345d82560992,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-ec812256-21a6-49c7-8fa2-e872297b97d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-4d8e1f84-205f-4cca-8501-5881a74a1b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-32463bb4-54f6-410c-a1d5-dc7b94741082,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 104857600
v2: 52428800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-178314306-172.17.0.2-1595704014184:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39350,DS-ecb94c48-d441-4dfa-a039-5638e90f19ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-2d77f17d-80d0-42e6-b1e1-84d30748ceb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42215,DS-e7d9e1d4-95f9-4e37-bf81-021f71853906,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-b23e8c81-1360-4881-958c-f60aa641e16e,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-84f85358-37fd-4fbc-92ee-c43dfc478e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38243,DS-6ceb1d66-24f5-4eeb-93b7-2d79e67bafab,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-fb56f27a-592f-40f4-8e4e-d58bb4e38822,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-5d13a579-4e3b-4900-bada-8de5bc0f8810,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-178314306-172.17.0.2-1595704014184:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39350,DS-ecb94c48-d441-4dfa-a039-5638e90f19ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-2d77f17d-80d0-42e6-b1e1-84d30748ceb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42215,DS-e7d9e1d4-95f9-4e37-bf81-021f71853906,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-b23e8c81-1360-4881-958c-f60aa641e16e,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-84f85358-37fd-4fbc-92ee-c43dfc478e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38243,DS-6ceb1d66-24f5-4eeb-93b7-2d79e67bafab,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-fb56f27a-592f-40f4-8e4e-d58bb4e38822,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-5d13a579-4e3b-4900-bada-8de5bc0f8810,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 104857600
v2: 52428800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1386719893-172.17.0.2-1595704197574:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37847,DS-c84f13d3-cb8b-4dd0-ab87-971b601f1dea,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-a80b4ef1-4503-4570-b27e-cf4bdfb727a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37481,DS-fe94e6c3-2c61-4d46-8123-c6807bccaf9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-646c0636-628b-41c7-adfc-c754db9aa05a,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-fd17e44d-c726-452a-97a5-d351bbcea84b,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-3a69323b-416b-48f4-a624-c64f70d753d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-79f9ca14-cbba-417f-a8f8-dc8080b264f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-d140b2f5-3646-4ecc-ba26-e08cc5ea1591,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1386719893-172.17.0.2-1595704197574:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37847,DS-c84f13d3-cb8b-4dd0-ab87-971b601f1dea,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-a80b4ef1-4503-4570-b27e-cf4bdfb727a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37481,DS-fe94e6c3-2c61-4d46-8123-c6807bccaf9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-646c0636-628b-41c7-adfc-c754db9aa05a,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-fd17e44d-c726-452a-97a5-d351bbcea84b,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-3a69323b-416b-48f4-a624-c64f70d753d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-79f9ca14-cbba-417f-a8f8-dc8080b264f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-d140b2f5-3646-4ecc-ba26-e08cc5ea1591,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 104857600
v2: 52428800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-746205500-172.17.0.2-1595704424366:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38454,DS-9dccef2b-b770-45e4-a8cc-ba553bc491fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-7969748d-8955-45c2-9c7f-8c45c760b3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-c3fc4f77-e9fa-4f0e-a7ce-9a8ac826a75b,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-ed108a46-800b-4dac-9cbc-d88b09b231bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-425fa2b1-9675-44bf-ba01-6be9246689c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-15a7fa28-55b6-4bc0-9a86-6712bca9b444,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-191edba8-4e60-43b7-9d0f-da9b3f31f0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-256062af-5c2a-45da-a17c-db034fdcc7f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-746205500-172.17.0.2-1595704424366:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38454,DS-9dccef2b-b770-45e4-a8cc-ba553bc491fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-7969748d-8955-45c2-9c7f-8c45c760b3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-c3fc4f77-e9fa-4f0e-a7ce-9a8ac826a75b,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-ed108a46-800b-4dac-9cbc-d88b09b231bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-425fa2b1-9675-44bf-ba01-6be9246689c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-15a7fa28-55b6-4bc0-9a86-6712bca9b444,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-191edba8-4e60-43b7-9d0f-da9b3f31f0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-256062af-5c2a-45da-a17c-db034fdcc7f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 104857600
v2: 52428800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-700137136-172.17.0.2-1595704887427:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34280,DS-bcc94743-17de-486d-96fb-51daaa6805cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-098cfff0-54a9-4f69-bc47-5f690d46521b,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-0e261a89-2bfa-41f2-ba73-5b914a1048ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-ca299872-1af6-42ba-a450-a6b6204f0f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-d3771a20-377b-4e98-8bd5-37d227e45222,DISK], DatanodeInfoWithStorage[127.0.0.1:43112,DS-f80318ea-8b97-45cd-aa90-5467c4d49f12,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-25d1cc64-db1e-41b7-8d8d-4be567f65f09,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-efef95ee-4af9-4492-b084-c3837fc9d565,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-700137136-172.17.0.2-1595704887427:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34280,DS-bcc94743-17de-486d-96fb-51daaa6805cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-098cfff0-54a9-4f69-bc47-5f690d46521b,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-0e261a89-2bfa-41f2-ba73-5b914a1048ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-ca299872-1af6-42ba-a450-a6b6204f0f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-d3771a20-377b-4e98-8bd5-37d227e45222,DISK], DatanodeInfoWithStorage[127.0.0.1:43112,DS-f80318ea-8b97-45cd-aa90-5467c4d49f12,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-25d1cc64-db1e-41b7-8d8d-4be567f65f09,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-efef95ee-4af9-4492-b084-c3837fc9d565,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 104857600
v2: 52428800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-526784157-172.17.0.2-1595705528393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36340,DS-e4b741c6-b37e-4b1c-af7b-8dbc8e97d95c,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-11c923f6-8680-4dad-8ec6-c0af3976b448,DISK], DatanodeInfoWithStorage[127.0.0.1:39734,DS-172d31a5-ebba-414d-bfa6-1b12ec75384b,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-09d524ee-b409-43bd-9c52-f19d73b58208,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-02bf370a-3ee4-4961-9f87-1d7e041a49c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-97da85e0-0af1-446e-8de1-0b226a8551bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-e00b9d05-78c1-4b89-a8c0-c11210a6a817,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-1fefda55-7e7d-41c2-81bb-cdcd67408c08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-526784157-172.17.0.2-1595705528393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36340,DS-e4b741c6-b37e-4b1c-af7b-8dbc8e97d95c,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-11c923f6-8680-4dad-8ec6-c0af3976b448,DISK], DatanodeInfoWithStorage[127.0.0.1:39734,DS-172d31a5-ebba-414d-bfa6-1b12ec75384b,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-09d524ee-b409-43bd-9c52-f19d73b58208,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-02bf370a-3ee4-4961-9f87-1d7e041a49c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-97da85e0-0af1-446e-8de1-0b226a8551bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-e00b9d05-78c1-4b89-a8c0-c11210a6a817,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-1fefda55-7e7d-41c2-81bb-cdcd67408c08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 104857600
v2: 52428800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1826280445-172.17.0.2-1595706200688:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46400,DS-7e66b3e0-a414-4ca3-8cac-701234e4ab42,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-c85a3d69-1cc6-4ecb-a51b-8dd7f9a1ddef,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-0795d573-ac94-436b-9944-8dc6d432a7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-8b305a34-5613-4ffd-b349-6635d6975f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-ad3ffa76-da5d-43d2-90cd-a188036b1440,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-ad18bd1f-fe03-4c60-a172-91b5654e9da0,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-ebeea57d-5728-4183-9e12-f2632fcdf3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-a11e412f-af95-4365-b127-dbc73d49de6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1826280445-172.17.0.2-1595706200688:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46400,DS-7e66b3e0-a414-4ca3-8cac-701234e4ab42,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-c85a3d69-1cc6-4ecb-a51b-8dd7f9a1ddef,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-0795d573-ac94-436b-9944-8dc6d432a7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-8b305a34-5613-4ffd-b349-6635d6975f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-ad3ffa76-da5d-43d2-90cd-a188036b1440,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-ad18bd1f-fe03-4c60-a172-91b5654e9da0,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-ebeea57d-5728-4183-9e12-f2632fcdf3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-a11e412f-af95-4365-b127-dbc73d49de6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 104857600
v2: 52428800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1137514138-172.17.0.2-1595706889724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40029,DS-9090030f-9fc8-4837-bdd3-eb8c671f8b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-74fa1dbf-6ec9-44a6-b432-bfacb28ca908,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-06bfeff9-e1cc-4be7-bfcb-917bf51dd88e,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-b60fa255-497a-4179-b861-6572558490ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-f44d8f8f-ad17-49b2-8bd6-b8ce17a45c85,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-a8291fb9-5bdd-4920-871f-86c4c1392f04,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-9a1a1ba9-8a07-4786-b5ce-327d0761e80b,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-a25af7fa-0777-4e85-921d-4da70e1d2134,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1137514138-172.17.0.2-1595706889724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40029,DS-9090030f-9fc8-4837-bdd3-eb8c671f8b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-74fa1dbf-6ec9-44a6-b432-bfacb28ca908,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-06bfeff9-e1cc-4be7-bfcb-917bf51dd88e,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-b60fa255-497a-4179-b861-6572558490ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-f44d8f8f-ad17-49b2-8bd6-b8ce17a45c85,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-a8291fb9-5bdd-4920-871f-86c4c1392f04,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-9a1a1ba9-8a07-4786-b5ce-327d0761e80b,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-a25af7fa-0777-4e85-921d-4da70e1d2134,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 104857600
v2: 52428800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1534043176-172.17.0.2-1595707540811:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41163,DS-6dc9af40-967c-4525-be58-54f0f6ed5b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-f3fe5caf-ba85-445e-ba8a-2ee26bfc4c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-ffeae2c4-f4a1-4f3e-95f4-35015182a01b,DISK], DatanodeInfoWithStorage[127.0.0.1:43370,DS-0f8f1ccd-44c4-4f66-976b-023e0a9fcd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-5b87dc0a-59b7-4aa9-bcde-fa317782d9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-5c3c68a6-338f-443e-bb6e-33b4bdef1985,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-c83be443-f9ad-4e7c-87d9-2cdd5932b348,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-a49b9066-3072-47be-a0be-dad133caba7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1534043176-172.17.0.2-1595707540811:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41163,DS-6dc9af40-967c-4525-be58-54f0f6ed5b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-f3fe5caf-ba85-445e-ba8a-2ee26bfc4c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-ffeae2c4-f4a1-4f3e-95f4-35015182a01b,DISK], DatanodeInfoWithStorage[127.0.0.1:43370,DS-0f8f1ccd-44c4-4f66-976b-023e0a9fcd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-5b87dc0a-59b7-4aa9-bcde-fa317782d9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-5c3c68a6-338f-443e-bb6e-33b4bdef1985,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-c83be443-f9ad-4e7c-87d9-2cdd5932b348,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-a49b9066-3072-47be-a0be-dad133caba7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 104857600
v2: 52428800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1966360212-172.17.0.2-1595707619176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39448,DS-53810a37-9c08-4485-8f7f-1a0115eec4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-6c711bde-7ac0-4e69-97b1-b64be16bdd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-0a6b99c8-3dca-4069-b623-7ba22edddb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-2ac2c08c-edec-4b9c-a8ff-1588a3ce144d,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-5b915eac-03cb-4262-b626-a860ba1fe7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-623682ad-a64e-40a4-ba94-5ef3371f153f,DISK], DatanodeInfoWithStorage[127.0.0.1:43887,DS-239f3489-6c8f-475b-871e-d1d618ac05cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34511,DS-f1927a63-eab4-4ab6-9f68-29dc01f07891,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1966360212-172.17.0.2-1595707619176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39448,DS-53810a37-9c08-4485-8f7f-1a0115eec4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-6c711bde-7ac0-4e69-97b1-b64be16bdd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-0a6b99c8-3dca-4069-b623-7ba22edddb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-2ac2c08c-edec-4b9c-a8ff-1588a3ce144d,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-5b915eac-03cb-4262-b626-a860ba1fe7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-623682ad-a64e-40a4-ba94-5ef3371f153f,DISK], DatanodeInfoWithStorage[127.0.0.1:43887,DS-239f3489-6c8f-475b-871e-d1d618ac05cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34511,DS-f1927a63-eab4-4ab6-9f68-29dc01f07891,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 104857600
v2: 52428800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2108683617-172.17.0.2-1595708049606:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43060,DS-2f6b6c48-6c4b-45e8-942a-5769c46d15c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-d87ccb82-ec4d-4832-91b1-27c7c8b2c440,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-64a280bc-5917-4dd7-881d-a2e21c58d117,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-85cba15c-c731-4437-bc9c-d5c2b4b7667d,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-4d522a3b-f48d-4c7a-b990-09316a2838e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-e9170fbb-0a62-4e83-9c68-e6f5147b4003,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-804f07fb-5d08-4fbc-b56e-b6262ea3ca4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-3c83e0c6-aa3d-4a26-8598-03ded33206d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2108683617-172.17.0.2-1595708049606:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43060,DS-2f6b6c48-6c4b-45e8-942a-5769c46d15c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-d87ccb82-ec4d-4832-91b1-27c7c8b2c440,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-64a280bc-5917-4dd7-881d-a2e21c58d117,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-85cba15c-c731-4437-bc9c-d5c2b4b7667d,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-4d522a3b-f48d-4c7a-b990-09316a2838e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-e9170fbb-0a62-4e83-9c68-e6f5147b4003,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-804f07fb-5d08-4fbc-b56e-b6262ea3ca4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-3c83e0c6-aa3d-4a26-8598-03ded33206d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 104857600
v2: 52428800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1258381618-172.17.0.2-1595708226890:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43074,DS-dfad09c2-1e74-4ed0-b094-4f82733821c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45725,DS-cee96eb0-ed2e-48cd-8483-cd9ccef75368,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-00648e78-d5ef-429e-9d78-6ee2d973afb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-9c14dc12-ddf3-4d6e-ae88-9af9a1e89ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-6898cbd7-3b20-4028-9c4f-5485925271a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-f9179a50-f0f1-4965-95cc-5be760cdb8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-d31f9edb-6d4f-4ab6-a8f9-18178957495d,DISK], DatanodeInfoWithStorage[127.0.0.1:33229,DS-45705045-eeeb-4e4d-919d-b59fc1cbc4c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1258381618-172.17.0.2-1595708226890:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43074,DS-dfad09c2-1e74-4ed0-b094-4f82733821c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45725,DS-cee96eb0-ed2e-48cd-8483-cd9ccef75368,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-00648e78-d5ef-429e-9d78-6ee2d973afb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-9c14dc12-ddf3-4d6e-ae88-9af9a1e89ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-6898cbd7-3b20-4028-9c4f-5485925271a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-f9179a50-f0f1-4965-95cc-5be760cdb8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-d31f9edb-6d4f-4ab6-a8f9-18178957495d,DISK], DatanodeInfoWithStorage[127.0.0.1:33229,DS-45705045-eeeb-4e4d-919d-b59fc1cbc4c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 104857600
v2: 52428800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-757298662-172.17.0.2-1595708305223:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37167,DS-ec042aaf-e7af-4b0e-8de6-61ea53d6da23,DISK], DatanodeInfoWithStorage[127.0.0.1:37625,DS-cd75ccd2-fdbe-4088-afb6-e168f7eba545,DISK], DatanodeInfoWithStorage[127.0.0.1:46844,DS-d096c402-b696-44df-affd-9d13e62b72f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-a19f4dc8-17e6-4b65-9d54-00cffc9a66d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-52472954-d950-4a07-ac8e-be7600d7a26c,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-225c1cf7-9948-4eee-9114-9eebbe91bbed,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-f1e68710-9625-4f0e-bf20-81938a7846ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40560,DS-dd36ffd8-fa70-425f-bada-9360ceb12a69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-757298662-172.17.0.2-1595708305223:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37167,DS-ec042aaf-e7af-4b0e-8de6-61ea53d6da23,DISK], DatanodeInfoWithStorage[127.0.0.1:37625,DS-cd75ccd2-fdbe-4088-afb6-e168f7eba545,DISK], DatanodeInfoWithStorage[127.0.0.1:46844,DS-d096c402-b696-44df-affd-9d13e62b72f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-a19f4dc8-17e6-4b65-9d54-00cffc9a66d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-52472954-d950-4a07-ac8e-be7600d7a26c,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-225c1cf7-9948-4eee-9114-9eebbe91bbed,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-f1e68710-9625-4f0e-bf20-81938a7846ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40560,DS-dd36ffd8-fa70-425f-bada-9360ceb12a69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 104857600
v2: 52428800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1607731308-172.17.0.2-1595708543749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36293,DS-0c904789-bcae-4ce9-86c4-f025e2578f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-43b7aa6d-8157-4cf2-93f2-2cd36d338258,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-a064f117-61b6-48b7-b2e1-caa9d1826021,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-119fe80c-fb46-481e-87ee-55f8931425c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-e86587b7-7035-4066-a6f3-2ea87d0506a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-4422dd58-c45e-4db9-bb71-6bbd3927aa32,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-a3ae9302-2f27-4cca-9f60-0ac40d21d793,DISK], DatanodeInfoWithStorage[127.0.0.1:36881,DS-b1aede4b-0dfd-4eeb-aab7-92e4df72aa10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1607731308-172.17.0.2-1595708543749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36293,DS-0c904789-bcae-4ce9-86c4-f025e2578f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-43b7aa6d-8157-4cf2-93f2-2cd36d338258,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-a064f117-61b6-48b7-b2e1-caa9d1826021,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-119fe80c-fb46-481e-87ee-55f8931425c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-e86587b7-7035-4066-a6f3-2ea87d0506a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-4422dd58-c45e-4db9-bb71-6bbd3927aa32,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-a3ae9302-2f27-4cca-9f60-0ac40d21d793,DISK], DatanodeInfoWithStorage[127.0.0.1:36881,DS-b1aede4b-0dfd-4eeb-aab7-92e4df72aa10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 104857600
v2: 52428800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1231966192-172.17.0.2-1595708598204:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44112,DS-05cf76dc-19bd-4668-96bb-e74034236939,DISK], DatanodeInfoWithStorage[127.0.0.1:36945,DS-bd068ca7-6a1f-4a5b-95af-9b3cb41324c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44771,DS-6c59e692-f0b7-4d85-bcf1-4259876c360a,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-b30393cc-ccd2-4285-ad42-09cdb0b21523,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-15ebc102-aecb-450b-b38e-70f05aa20fef,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-10c6a006-f061-4d50-9ab8-fb6425b72234,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-7270ef19-87ee-4db6-b1fb-90c7128fc0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-9291caf8-bc0c-4b37-b48b-d2b300df9844,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1231966192-172.17.0.2-1595708598204:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44112,DS-05cf76dc-19bd-4668-96bb-e74034236939,DISK], DatanodeInfoWithStorage[127.0.0.1:36945,DS-bd068ca7-6a1f-4a5b-95af-9b3cb41324c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44771,DS-6c59e692-f0b7-4d85-bcf1-4259876c360a,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-b30393cc-ccd2-4285-ad42-09cdb0b21523,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-15ebc102-aecb-450b-b38e-70f05aa20fef,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-10c6a006-f061-4d50-9ab8-fb6425b72234,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-7270ef19-87ee-4db6-b1fb-90c7128fc0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-9291caf8-bc0c-4b37-b48b-d2b300df9844,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6751
