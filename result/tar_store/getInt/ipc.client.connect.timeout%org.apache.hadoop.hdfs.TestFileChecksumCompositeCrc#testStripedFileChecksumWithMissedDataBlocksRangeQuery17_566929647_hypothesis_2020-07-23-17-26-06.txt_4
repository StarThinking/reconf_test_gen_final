reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 20000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 20000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1964609408-172.17.0.20-1595525246571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37693,DS-668b6aef-28a4-4ac1-bf44-4dae2691133c,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-fffe881c-bea7-42d9-9824-03d93e9c290d,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-38358d5a-7ba7-4201-8bc7-72a0d6002d15,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-45be664b-90dc-4f1d-8c98-9026bc76e3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-643233a3-acf4-4169-adc9-965a96aa7799,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-39365b11-dc0b-4ea0-8bc1-9a49914b0880,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-8b4e1ed3-edb4-42c2-bbbf-0cade111709c,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-ea141372-8664-41ba-90c4-f619fe8f74a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1964609408-172.17.0.20-1595525246571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37693,DS-668b6aef-28a4-4ac1-bf44-4dae2691133c,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-fffe881c-bea7-42d9-9824-03d93e9c290d,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-38358d5a-7ba7-4201-8bc7-72a0d6002d15,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-45be664b-90dc-4f1d-8c98-9026bc76e3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-643233a3-acf4-4169-adc9-965a96aa7799,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-39365b11-dc0b-4ea0-8bc1-9a49914b0880,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-8b4e1ed3-edb4-42c2-bbbf-0cade111709c,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-ea141372-8664-41ba-90c4-f619fe8f74a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 20000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-279850369-172.17.0.20-1595525420654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33473,DS-01a3af11-a497-4834-bbbe-2fa8191e9ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-de99a5b9-dec2-4d12-816b-6381eae61120,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-9653a26b-c5cf-4126-93c9-dc6c554fd082,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-e04803e8-fa5c-4dce-832f-b4b8d82d3f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-70c7f3d5-0547-433a-aff1-43770cebc682,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-852f3957-2ce8-487b-9316-3ccba19014a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-b0978f21-1e0f-4b9e-af64-1dd32f999b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-068448ca-09fe-433d-b3da-099fa2010a35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-279850369-172.17.0.20-1595525420654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33473,DS-01a3af11-a497-4834-bbbe-2fa8191e9ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-de99a5b9-dec2-4d12-816b-6381eae61120,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-9653a26b-c5cf-4126-93c9-dc6c554fd082,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-e04803e8-fa5c-4dce-832f-b4b8d82d3f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-70c7f3d5-0547-433a-aff1-43770cebc682,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-852f3957-2ce8-487b-9316-3ccba19014a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-b0978f21-1e0f-4b9e-af64-1dd32f999b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-068448ca-09fe-433d-b3da-099fa2010a35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 20000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-616513799-172.17.0.20-1595526093740:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44058,DS-1e5a3d3b-1362-4bc6-8332-e511f6182891,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-acfa5225-5947-4f58-90f0-f1904d65ee1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-ce7a39ab-b57a-4cba-9b12-e5a50f05e14a,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-98186fda-202c-42c2-b5e0-7685fbbdde97,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-25611352-562b-48e3-9647-0435ed1996ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-647adb23-5903-454f-baac-8e539c0ad519,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-d1f564ba-257b-42a3-b3dd-96c1781a6f93,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-ef89d11c-e621-4bf0-9169-06655b05c611,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-616513799-172.17.0.20-1595526093740:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44058,DS-1e5a3d3b-1362-4bc6-8332-e511f6182891,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-acfa5225-5947-4f58-90f0-f1904d65ee1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-ce7a39ab-b57a-4cba-9b12-e5a50f05e14a,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-98186fda-202c-42c2-b5e0-7685fbbdde97,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-25611352-562b-48e3-9647-0435ed1996ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-647adb23-5903-454f-baac-8e539c0ad519,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-d1f564ba-257b-42a3-b3dd-96c1781a6f93,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-ef89d11c-e621-4bf0-9169-06655b05c611,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 20000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-235507893-172.17.0.20-1595526465227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43938,DS-b2e590a1-790b-44f7-829a-ebf53aa8f3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-0cba5db0-448f-4b1b-9394-df10987aa799,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-2e3783b5-f9f2-47af-98f2-aa9c88c06e56,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-7628eaf5-707e-4baf-b4d2-5b17a7c499ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42251,DS-fbbff2e0-0604-4ed7-8dcd-87a5a7a79870,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-ea7890b8-64c9-449c-8749-a121c1723263,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-f7f1a15c-2fd5-452d-b6ec-6d7e72fb8a43,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-5e55fa6a-2277-493c-8f9a-cddb67ee9f03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-235507893-172.17.0.20-1595526465227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43938,DS-b2e590a1-790b-44f7-829a-ebf53aa8f3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-0cba5db0-448f-4b1b-9394-df10987aa799,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-2e3783b5-f9f2-47af-98f2-aa9c88c06e56,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-7628eaf5-707e-4baf-b4d2-5b17a7c499ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42251,DS-fbbff2e0-0604-4ed7-8dcd-87a5a7a79870,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-ea7890b8-64c9-449c-8749-a121c1723263,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-f7f1a15c-2fd5-452d-b6ec-6d7e72fb8a43,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-5e55fa6a-2277-493c-8f9a-cddb67ee9f03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 20000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-46706966-172.17.0.20-1595526579488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34624,DS-8c75c6f8-0561-457a-8b6b-9876662181bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-515a9967-821a-4c56-af91-ae720f67df83,DISK], DatanodeInfoWithStorage[127.0.0.1:45870,DS-3a2ae497-8e4f-422c-b37f-f20c02a2ac31,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-4b659408-c315-4614-87a1-c8aff02923d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-5338b4d7-672f-4d7f-b164-6174be4a42c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45178,DS-6dc7da57-3a71-4ecd-88e3-9f304ad27db1,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-fdbe8c50-b9fb-4c29-84ef-5e2455fe0a26,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-eb51ab0d-d1e1-4095-9733-276f1345437c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-46706966-172.17.0.20-1595526579488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34624,DS-8c75c6f8-0561-457a-8b6b-9876662181bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-515a9967-821a-4c56-af91-ae720f67df83,DISK], DatanodeInfoWithStorage[127.0.0.1:45870,DS-3a2ae497-8e4f-422c-b37f-f20c02a2ac31,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-4b659408-c315-4614-87a1-c8aff02923d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-5338b4d7-672f-4d7f-b164-6174be4a42c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45178,DS-6dc7da57-3a71-4ecd-88e3-9f304ad27db1,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-fdbe8c50-b9fb-4c29-84ef-5e2455fe0a26,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-eb51ab0d-d1e1-4095-9733-276f1345437c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 20000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1449458271-172.17.0.20-1595526880896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45428,DS-7d020f60-84b2-48cf-ae0f-6db58114aff8,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-c1a817f4-dbd4-427b-bcf2-237e8d143000,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-52779cb2-25ca-45a4-b42f-06435bb0457f,DISK], DatanodeInfoWithStorage[127.0.0.1:45199,DS-b8968861-b321-4a3f-86d3-ed94d6d2d48e,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-2a53e843-2047-428d-9e70-0f7aa341106f,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-b49a1383-688c-4ad9-97c2-9cf58710b795,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-1d67008c-98af-4573-9b74-1ef5f4185b86,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-4c323f3c-7d51-476c-91bc-1d9f53dc727c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1449458271-172.17.0.20-1595526880896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45428,DS-7d020f60-84b2-48cf-ae0f-6db58114aff8,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-c1a817f4-dbd4-427b-bcf2-237e8d143000,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-52779cb2-25ca-45a4-b42f-06435bb0457f,DISK], DatanodeInfoWithStorage[127.0.0.1:45199,DS-b8968861-b321-4a3f-86d3-ed94d6d2d48e,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-2a53e843-2047-428d-9e70-0f7aa341106f,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-b49a1383-688c-4ad9-97c2-9cf58710b795,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-1d67008c-98af-4573-9b74-1ef5f4185b86,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-4c323f3c-7d51-476c-91bc-1d9f53dc727c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 20000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-649546013-172.17.0.20-1595528063367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41675,DS-643faf43-5801-484e-b13a-b39819889dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40863,DS-210b138f-a23d-4cd2-8a83-46b2962f9eed,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-02acd80d-62bc-4e8b-aae4-136abe53b93d,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-39b8e6c0-ece6-442c-8199-904145a6fc74,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-65a9a520-b03b-483f-b0fb-8753f21f88bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-164aefa1-b284-4004-89fe-7fa70b390036,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-953a344a-53de-437d-835c-488b0ae384c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33301,DS-048706bd-1356-4840-9738-7cd259d03781,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-649546013-172.17.0.20-1595528063367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41675,DS-643faf43-5801-484e-b13a-b39819889dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40863,DS-210b138f-a23d-4cd2-8a83-46b2962f9eed,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-02acd80d-62bc-4e8b-aae4-136abe53b93d,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-39b8e6c0-ece6-442c-8199-904145a6fc74,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-65a9a520-b03b-483f-b0fb-8753f21f88bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-164aefa1-b284-4004-89fe-7fa70b390036,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-953a344a-53de-437d-835c-488b0ae384c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33301,DS-048706bd-1356-4840-9738-7cd259d03781,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 20000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-422239502-172.17.0.20-1595528164499:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35141,DS-754cf07c-ec0b-4947-9709-4a23cf0ddca3,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-d77385c4-aa63-4a81-9dbb-2a5854a1e852,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-0f2252fa-bb83-4cab-bd3c-cf9289b51389,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-55ac53bf-a22d-4b6f-a6bc-a612fee9adfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-20fc71d0-ba0b-423d-93b5-8f8dbe61952e,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-832b259b-3782-4988-843a-e412f085ec65,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-ea6dbc0c-fc32-446f-a8e8-eaebba5815a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-6aaed197-c7d0-4f30-836e-0517a859f497,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-422239502-172.17.0.20-1595528164499:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35141,DS-754cf07c-ec0b-4947-9709-4a23cf0ddca3,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-d77385c4-aa63-4a81-9dbb-2a5854a1e852,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-0f2252fa-bb83-4cab-bd3c-cf9289b51389,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-55ac53bf-a22d-4b6f-a6bc-a612fee9adfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-20fc71d0-ba0b-423d-93b5-8f8dbe61952e,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-832b259b-3782-4988-843a-e412f085ec65,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-ea6dbc0c-fc32-446f-a8e8-eaebba5815a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-6aaed197-c7d0-4f30-836e-0517a859f497,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 20000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1038829040-172.17.0.20-1595528775051:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34233,DS-e123c143-16ab-4c18-8f83-eeaf5676a6df,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-b78dc519-398f-4b6b-82ba-df4e84a98c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-626ddb53-919c-49fe-8cf0-0908669460b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-2122358e-bd7f-44e5-a527-bd4991c94c54,DISK], DatanodeInfoWithStorage[127.0.0.1:35659,DS-d7d5cfe4-6250-4572-9a99-cf1186731af3,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-5d59de17-8c00-4cfe-86f5-9a8f17945b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-5c7f0a6e-9a0f-4778-aa77-42b16176b0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-e99ee797-9465-433d-ad73-ca7928b60666,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1038829040-172.17.0.20-1595528775051:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34233,DS-e123c143-16ab-4c18-8f83-eeaf5676a6df,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-b78dc519-398f-4b6b-82ba-df4e84a98c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-626ddb53-919c-49fe-8cf0-0908669460b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-2122358e-bd7f-44e5-a527-bd4991c94c54,DISK], DatanodeInfoWithStorage[127.0.0.1:35659,DS-d7d5cfe4-6250-4572-9a99-cf1186731af3,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-5d59de17-8c00-4cfe-86f5-9a8f17945b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-5c7f0a6e-9a0f-4778-aa77-42b16176b0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-e99ee797-9465-433d-ad73-ca7928b60666,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 20000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-638399922-172.17.0.20-1595528909039:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36879,DS-3be22370-2b10-449b-9b99-ed41ad026631,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-83a4f293-9d88-4070-ac58-ba525dd2b762,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-48d9312e-ad9c-4940-8633-9d9744b4bdbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-eade0aac-426e-4f65-ad06-9e91b397552f,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-c2ae7f80-fcaa-43a5-8032-2a5efda66d49,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-8cdf45ed-0f94-4531-b2d7-1a1713a155c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41864,DS-3cc4d256-46a9-4546-89d9-d53c147ce504,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-85a71882-cdaa-406c-9535-c77f909c7758,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-638399922-172.17.0.20-1595528909039:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36879,DS-3be22370-2b10-449b-9b99-ed41ad026631,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-83a4f293-9d88-4070-ac58-ba525dd2b762,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-48d9312e-ad9c-4940-8633-9d9744b4bdbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-eade0aac-426e-4f65-ad06-9e91b397552f,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-c2ae7f80-fcaa-43a5-8032-2a5efda66d49,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-8cdf45ed-0f94-4531-b2d7-1a1713a155c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41864,DS-3cc4d256-46a9-4546-89d9-d53c147ce504,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-85a71882-cdaa-406c-9535-c77f909c7758,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 20000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1431736509-172.17.0.20-1595529004403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41317,DS-83b2d4dc-8f22-4a81-b7bd-ee94872f3f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-f74517b5-4827-4cd0-a53a-a3a47dc72fce,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-1d6d2ea4-abff-4b06-8986-cb2dd8607d73,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-64aeaaeb-b957-40c0-a821-d30ee8c32b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-65edea09-1207-44c4-9131-f081586358ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-6240e788-a358-48d9-adec-ecb9cfd9cb52,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-3c7ba20d-790c-4ca8-92df-bb80c38bb98f,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-79e7bd86-bcc7-401f-950a-a0746a473db6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1431736509-172.17.0.20-1595529004403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41317,DS-83b2d4dc-8f22-4a81-b7bd-ee94872f3f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-f74517b5-4827-4cd0-a53a-a3a47dc72fce,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-1d6d2ea4-abff-4b06-8986-cb2dd8607d73,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-64aeaaeb-b957-40c0-a821-d30ee8c32b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-65edea09-1207-44c4-9131-f081586358ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-6240e788-a358-48d9-adec-ecb9cfd9cb52,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-3c7ba20d-790c-4ca8-92df-bb80c38bb98f,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-79e7bd86-bcc7-401f-950a-a0746a473db6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 20000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1516571029-172.17.0.20-1595529796979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36494,DS-0c3fb03a-a13b-43c8-8ac3-fbe51d1cf09f,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-2324c684-10ab-47a6-b19a-cd33cfba58b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40173,DS-51bdf128-5ed4-4a22-b3e7-0449fe3c6af5,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-1a583f3e-eb95-4a32-b24c-29be34aeaf86,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-ebdfb76a-ee5f-43d5-a427-cdd6dc8fb5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-60da2d1d-8e22-4e09-b1d6-d8940c4f5783,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-d724a976-44ee-45d1-9130-73baeed93da1,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-17ecf9b6-3eb4-4bd3-ab38-48cdfebae99a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1516571029-172.17.0.20-1595529796979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36494,DS-0c3fb03a-a13b-43c8-8ac3-fbe51d1cf09f,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-2324c684-10ab-47a6-b19a-cd33cfba58b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40173,DS-51bdf128-5ed4-4a22-b3e7-0449fe3c6af5,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-1a583f3e-eb95-4a32-b24c-29be34aeaf86,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-ebdfb76a-ee5f-43d5-a427-cdd6dc8fb5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-60da2d1d-8e22-4e09-b1d6-d8940c4f5783,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-d724a976-44ee-45d1-9130-73baeed93da1,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-17ecf9b6-3eb4-4bd3-ab38-48cdfebae99a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 20000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2023293922-172.17.0.20-1595530083764:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38319,DS-57c3e51b-5380-4b8f-bbde-49c4e3c3ea75,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-43421207-c496-45ca-bdc7-69611cf4c133,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-04f40912-7eda-468d-a293-d5db6a266672,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-3fe0d128-e3d3-451a-8d4c-3cc251595df1,DISK], DatanodeInfoWithStorage[127.0.0.1:36945,DS-6ca88f17-24c6-445b-b5e5-bdbf6ce288af,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-92849d88-23b2-421a-8cf9-28f96c1ab1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-bc2ba73b-e21d-4158-8f6f-a22ad37329fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-35f5eeb8-421d-4db4-82b9-f84cf9f4e1a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2023293922-172.17.0.20-1595530083764:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38319,DS-57c3e51b-5380-4b8f-bbde-49c4e3c3ea75,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-43421207-c496-45ca-bdc7-69611cf4c133,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-04f40912-7eda-468d-a293-d5db6a266672,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-3fe0d128-e3d3-451a-8d4c-3cc251595df1,DISK], DatanodeInfoWithStorage[127.0.0.1:36945,DS-6ca88f17-24c6-445b-b5e5-bdbf6ce288af,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-92849d88-23b2-421a-8cf9-28f96c1ab1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-bc2ba73b-e21d-4158-8f6f-a22ad37329fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-35f5eeb8-421d-4db4-82b9-f84cf9f4e1a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 20000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-833654064-172.17.0.20-1595530150850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35074,DS-2d0bfdd5-e675-4a6e-8f0e-dbf9e6db4465,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-987effe4-665d-48ee-99b2-3983258808e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44984,DS-27e19f47-84eb-4122-8ce8-425511271816,DISK], DatanodeInfoWithStorage[127.0.0.1:42925,DS-cec2ffef-8172-477d-9217-8e14cae01091,DISK], DatanodeInfoWithStorage[127.0.0.1:32824,DS-73941b67-4932-4e6f-9209-79207461d693,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-3d640a5a-9a1f-4515-8e06-3e0c8ca2ec6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-d7318173-7c64-4617-a92f-cca758031d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-d131d5a6-4459-4a04-a4da-edb6887cd80b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-833654064-172.17.0.20-1595530150850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35074,DS-2d0bfdd5-e675-4a6e-8f0e-dbf9e6db4465,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-987effe4-665d-48ee-99b2-3983258808e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44984,DS-27e19f47-84eb-4122-8ce8-425511271816,DISK], DatanodeInfoWithStorage[127.0.0.1:42925,DS-cec2ffef-8172-477d-9217-8e14cae01091,DISK], DatanodeInfoWithStorage[127.0.0.1:32824,DS-73941b67-4932-4e6f-9209-79207461d693,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-3d640a5a-9a1f-4515-8e06-3e0c8ca2ec6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-d7318173-7c64-4617-a92f-cca758031d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-d131d5a6-4459-4a04-a4da-edb6887cd80b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 20000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-651424185-172.17.0.20-1595530370226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35053,DS-8629a358-42e1-48f1-8708-64de0d5da9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-46c8f286-42d8-475c-9f0d-a04faf1a8200,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-ef89bc72-e4e2-4a15-98e2-1d62ad6906d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-c5750726-de41-428a-b709-6acf1e489df9,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-0f8f2651-5601-498c-bfce-1e18d19b9939,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-e04b8cd4-c93a-401a-9997-3c2bd821b34f,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-75301d3a-cdc5-4bfb-b8b2-6881b09f5728,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-b4beb6c6-84e8-41d0-862e-db8241754f50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-651424185-172.17.0.20-1595530370226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35053,DS-8629a358-42e1-48f1-8708-64de0d5da9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-46c8f286-42d8-475c-9f0d-a04faf1a8200,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-ef89bc72-e4e2-4a15-98e2-1d62ad6906d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-c5750726-de41-428a-b709-6acf1e489df9,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-0f8f2651-5601-498c-bfce-1e18d19b9939,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-e04b8cd4-c93a-401a-9997-3c2bd821b34f,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-75301d3a-cdc5-4bfb-b8b2-6881b09f5728,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-b4beb6c6-84e8-41d0-862e-db8241754f50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5261
