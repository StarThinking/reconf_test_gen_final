reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1702000856-172.17.0.11-1595604510016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35264,DS-abe56ea3-9bf7-452b-ab57-502458190783,DISK], DatanodeInfoWithStorage[127.0.0.1:44518,DS-f1dbcd13-68a3-4d33-a3a5-19a0336e85fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-9b2154c3-4fcf-4f19-ae6e-8657349ea65f,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-07fbc599-d358-4545-8c53-87ad290aaaac,DISK], DatanodeInfoWithStorage[127.0.0.1:41694,DS-79a21fad-28ab-4844-881e-9154dc8b2d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-f77c55b2-0ac4-4be5-967a-c5d053aaaf82,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-353b1189-e9f7-4a81-bdb4-eeb15f05b4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33348,DS-029a70d4-ca2e-4085-a369-832974bcfaf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1702000856-172.17.0.11-1595604510016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35264,DS-abe56ea3-9bf7-452b-ab57-502458190783,DISK], DatanodeInfoWithStorage[127.0.0.1:44518,DS-f1dbcd13-68a3-4d33-a3a5-19a0336e85fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-9b2154c3-4fcf-4f19-ae6e-8657349ea65f,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-07fbc599-d358-4545-8c53-87ad290aaaac,DISK], DatanodeInfoWithStorage[127.0.0.1:41694,DS-79a21fad-28ab-4844-881e-9154dc8b2d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-f77c55b2-0ac4-4be5-967a-c5d053aaaf82,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-353b1189-e9f7-4a81-bdb4-eeb15f05b4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33348,DS-029a70d4-ca2e-4085-a369-832974bcfaf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-529129253-172.17.0.11-1595604611282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39851,DS-f87543eb-469f-4736-9fc5-4dce87d02b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37721,DS-f6300540-ec06-477b-bbdb-3673df335c37,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-69387451-36a4-4afa-8106-93e9f6df572f,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-55638c5d-afb0-47ac-9c3a-7d823aeebcaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-bdb97581-34a4-42fd-ac27-16ca86d5a28f,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-57f663fa-13d2-44d5-9993-72e0301ac388,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-fc68acd1-d251-4ce7-aa09-829be9b647ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-1c82b24c-6f00-4ef9-8494-5c3c765409a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-529129253-172.17.0.11-1595604611282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39851,DS-f87543eb-469f-4736-9fc5-4dce87d02b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37721,DS-f6300540-ec06-477b-bbdb-3673df335c37,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-69387451-36a4-4afa-8106-93e9f6df572f,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-55638c5d-afb0-47ac-9c3a-7d823aeebcaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-bdb97581-34a4-42fd-ac27-16ca86d5a28f,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-57f663fa-13d2-44d5-9993-72e0301ac388,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-fc68acd1-d251-4ce7-aa09-829be9b647ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-1c82b24c-6f00-4ef9-8494-5c3c765409a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-983599743-172.17.0.11-1595605689387:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43070,DS-80e025b7-9957-4840-980d-a56e0db22c43,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-8784aa4d-82b8-4f3c-8852-9a65115abe8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-0c7ee828-72d2-4396-8e99-9f482d06a16e,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-ccf78f74-3169-4d87-97bc-d5773f8fffb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-dff5fceb-fea4-48c4-ac8f-25487504df2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-af3ae881-43ca-4ae3-9878-b115f6986618,DISK], DatanodeInfoWithStorage[127.0.0.1:35276,DS-b64ed1cd-752a-431b-a9d5-1613827c1100,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-6f5ea9a0-f8ee-4a85-b6de-a36b9de03959,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-983599743-172.17.0.11-1595605689387:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43070,DS-80e025b7-9957-4840-980d-a56e0db22c43,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-8784aa4d-82b8-4f3c-8852-9a65115abe8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-0c7ee828-72d2-4396-8e99-9f482d06a16e,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-ccf78f74-3169-4d87-97bc-d5773f8fffb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-dff5fceb-fea4-48c4-ac8f-25487504df2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-af3ae881-43ca-4ae3-9878-b115f6986618,DISK], DatanodeInfoWithStorage[127.0.0.1:35276,DS-b64ed1cd-752a-431b-a9d5-1613827c1100,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-6f5ea9a0-f8ee-4a85-b6de-a36b9de03959,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-75487067-172.17.0.11-1595606199756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40840,DS-0540b12d-16f7-4a70-8f8f-7dcacf2b71f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-5f1c9e62-ca53-4281-ac73-5f301662ee52,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-7d482824-79d2-4be5-95cf-9f52c7bcca2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-fe70ad59-5d96-4b8d-bf5b-2eb7339c69e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-b7625dde-0bfb-448f-87c5-51578b40654e,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-68e5b117-d5cf-4a4e-af4e-af94be1d67b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34291,DS-a36af06b-1b3d-43c3-9383-db2e6915c6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-c9d02a76-8ee6-4188-ad4a-b3837b54bdf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-75487067-172.17.0.11-1595606199756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40840,DS-0540b12d-16f7-4a70-8f8f-7dcacf2b71f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-5f1c9e62-ca53-4281-ac73-5f301662ee52,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-7d482824-79d2-4be5-95cf-9f52c7bcca2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-fe70ad59-5d96-4b8d-bf5b-2eb7339c69e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-b7625dde-0bfb-448f-87c5-51578b40654e,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-68e5b117-d5cf-4a4e-af4e-af94be1d67b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34291,DS-a36af06b-1b3d-43c3-9383-db2e6915c6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-c9d02a76-8ee6-4188-ad4a-b3837b54bdf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-623918841-172.17.0.11-1595606272272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43284,DS-9e063c78-bd41-47fb-a2f0-264b1bb4d059,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-d22a22c9-40bc-43f0-b390-a817ca209ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-0ac2091d-9548-4a3c-ab97-a8fb83946173,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-5c01d6c7-2af1-493f-9b5e-2f82c0af1ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-bff3aa45-f717-4113-8a0a-e65d9ff01731,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-51650ec5-8e22-4457-8bc9-df37c587b26f,DISK], DatanodeInfoWithStorage[127.0.0.1:43932,DS-632518e9-00cd-49bd-bd5d-48ca0b8bb13f,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-8c97e1ce-742e-443b-be56-a807bf65d92b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-623918841-172.17.0.11-1595606272272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43284,DS-9e063c78-bd41-47fb-a2f0-264b1bb4d059,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-d22a22c9-40bc-43f0-b390-a817ca209ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-0ac2091d-9548-4a3c-ab97-a8fb83946173,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-5c01d6c7-2af1-493f-9b5e-2f82c0af1ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-bff3aa45-f717-4113-8a0a-e65d9ff01731,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-51650ec5-8e22-4457-8bc9-df37c587b26f,DISK], DatanodeInfoWithStorage[127.0.0.1:43932,DS-632518e9-00cd-49bd-bd5d-48ca0b8bb13f,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-8c97e1ce-742e-443b-be56-a807bf65d92b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2069491822-172.17.0.11-1595606752937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38475,DS-d66e99e1-9a17-44ed-be30-067ec7b76124,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-58ae77fb-464c-4db2-b9ee-aebcbcb747dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-c1f599c2-a343-4264-b3b7-f08199121c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-9227a8ca-88ef-482b-abe7-a64a62ae77c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-ee048d25-da1e-44ee-bd23-a961f350eedf,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-f415d4de-5cec-44aa-9e6c-2f0855885509,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-1fb576a5-5ff3-4659-8e97-cfd43e1cff1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-ffbdb3e6-ca12-4b03-a40f-8dbae2f3b079,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2069491822-172.17.0.11-1595606752937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38475,DS-d66e99e1-9a17-44ed-be30-067ec7b76124,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-58ae77fb-464c-4db2-b9ee-aebcbcb747dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-c1f599c2-a343-4264-b3b7-f08199121c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-9227a8ca-88ef-482b-abe7-a64a62ae77c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-ee048d25-da1e-44ee-bd23-a961f350eedf,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-f415d4de-5cec-44aa-9e6c-2f0855885509,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-1fb576a5-5ff3-4659-8e97-cfd43e1cff1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-ffbdb3e6-ca12-4b03-a40f-8dbae2f3b079,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-653497576-172.17.0.11-1595607016185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39149,DS-95bc62d9-78db-4362-81cf-fdcfe3627fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-5b33f3be-2c95-45b5-a8b7-d9e469492658,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-4bdf8200-0043-4e65-847d-ee81af5d2a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-c2b60a4b-7d09-4410-bf66-e7d754a2d989,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-6c04c6c3-d80d-4dfc-a6c3-eaff2ffd9bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-29e6ef44-63a3-4482-bb76-5a82befe78f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-6d579dd7-3628-4d99-8019-0ce829809f33,DISK], DatanodeInfoWithStorage[127.0.0.1:36946,DS-6475f89e-7f74-42d2-a31a-8e669098d667,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-653497576-172.17.0.11-1595607016185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39149,DS-95bc62d9-78db-4362-81cf-fdcfe3627fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-5b33f3be-2c95-45b5-a8b7-d9e469492658,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-4bdf8200-0043-4e65-847d-ee81af5d2a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-c2b60a4b-7d09-4410-bf66-e7d754a2d989,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-6c04c6c3-d80d-4dfc-a6c3-eaff2ffd9bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-29e6ef44-63a3-4482-bb76-5a82befe78f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-6d579dd7-3628-4d99-8019-0ce829809f33,DISK], DatanodeInfoWithStorage[127.0.0.1:36946,DS-6475f89e-7f74-42d2-a31a-8e669098d667,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1521866288-172.17.0.11-1595607201277:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39585,DS-e15f3fc1-1315-4ea9-868c-5cf00ed02dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-226d1d6e-095a-4c7a-86c1-1bc0cc569e71,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-8dec1409-abc1-43ab-880f-55f2cf6b6f82,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-070abc5c-b7d6-40fb-81a4-99767527750a,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-e986d520-df05-422d-9540-2f8b3e147b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-5ea3da3c-3991-413a-bbc1-214c6144ae54,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-e7f091d0-b55e-43e3-bdda-abfa27f41276,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-4bd8b08f-69fc-4987-8f8d-2fc2f4c5ff2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1521866288-172.17.0.11-1595607201277:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39585,DS-e15f3fc1-1315-4ea9-868c-5cf00ed02dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-226d1d6e-095a-4c7a-86c1-1bc0cc569e71,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-8dec1409-abc1-43ab-880f-55f2cf6b6f82,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-070abc5c-b7d6-40fb-81a4-99767527750a,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-e986d520-df05-422d-9540-2f8b3e147b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-5ea3da3c-3991-413a-bbc1-214c6144ae54,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-e7f091d0-b55e-43e3-bdda-abfa27f41276,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-4bd8b08f-69fc-4987-8f8d-2fc2f4c5ff2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-815789274-172.17.0.11-1595607308446:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41095,DS-32705e8d-0437-4409-9b2d-4bb1dcd77bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-ef9da778-04a2-4d59-b1ad-bb6fb6878e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-c066d2e7-3e16-47dd-8500-98e381e4d2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-a03e2ad3-7310-40f3-b389-1b40d1dbe1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-80b90225-ddeb-4671-bcd7-00dd90ea09e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-a8021c04-f602-4bed-8ee8-54527fd3b17e,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-1c71e24b-a379-4c20-a8a6-c9662c188fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:37791,DS-85299cbe-2b43-4f94-887a-863100045d92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-815789274-172.17.0.11-1595607308446:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41095,DS-32705e8d-0437-4409-9b2d-4bb1dcd77bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-ef9da778-04a2-4d59-b1ad-bb6fb6878e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-c066d2e7-3e16-47dd-8500-98e381e4d2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-a03e2ad3-7310-40f3-b389-1b40d1dbe1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-80b90225-ddeb-4671-bcd7-00dd90ea09e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-a8021c04-f602-4bed-8ee8-54527fd3b17e,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-1c71e24b-a379-4c20-a8a6-c9662c188fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:37791,DS-85299cbe-2b43-4f94-887a-863100045d92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1831683340-172.17.0.11-1595607420229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33208,DS-91446e6e-8ab7-4296-9ab9-fed85f36bb43,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-78b6122e-b4af-480e-aa61-fe3f42548ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-b335cb14-6f58-43df-b30a-a813eaa9b5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-92dcda84-dee8-4ff8-95b7-0bae1dbfaebc,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-e150fffb-b086-4dbc-aa46-90f9e596fe8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-dd9eb880-013b-47b8-a932-21ee7648cba9,DISK], DatanodeInfoWithStorage[127.0.0.1:46467,DS-1e5f3338-91c2-4c82-b27e-c0cccf8c3f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-264b3f8b-52b8-4c14-91c2-090e5cff2eec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1831683340-172.17.0.11-1595607420229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33208,DS-91446e6e-8ab7-4296-9ab9-fed85f36bb43,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-78b6122e-b4af-480e-aa61-fe3f42548ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-b335cb14-6f58-43df-b30a-a813eaa9b5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-92dcda84-dee8-4ff8-95b7-0bae1dbfaebc,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-e150fffb-b086-4dbc-aa46-90f9e596fe8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-dd9eb880-013b-47b8-a932-21ee7648cba9,DISK], DatanodeInfoWithStorage[127.0.0.1:46467,DS-1e5f3338-91c2-4c82-b27e-c0cccf8c3f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-264b3f8b-52b8-4c14-91c2-090e5cff2eec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-765563239-172.17.0.11-1595607537198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40310,DS-05501ee3-d724-486c-bda4-5cb46d1d33a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-9f61a2fa-8500-42f7-83e2-b58f4ab75347,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-6cd16604-d11f-4122-aa84-67f8b98a8bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-a48e735d-167d-4cf0-bf71-fa3adad5d8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-6dbb2130-1f49-437b-af92-d6643d28534b,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-59f01061-ade4-46b4-9e70-9ed852993add,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-03b5bf44-0980-4261-832e-aaa0cd2c5c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-d1e0a0ff-4432-4dec-b877-7e7859d68b13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-765563239-172.17.0.11-1595607537198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40310,DS-05501ee3-d724-486c-bda4-5cb46d1d33a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-9f61a2fa-8500-42f7-83e2-b58f4ab75347,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-6cd16604-d11f-4122-aa84-67f8b98a8bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-a48e735d-167d-4cf0-bf71-fa3adad5d8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-6dbb2130-1f49-437b-af92-d6643d28534b,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-59f01061-ade4-46b4-9e70-9ed852993add,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-03b5bf44-0980-4261-832e-aaa0cd2c5c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-d1e0a0ff-4432-4dec-b877-7e7859d68b13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-888710309-172.17.0.11-1595607616412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46183,DS-dc31bf2d-569a-4a8d-b73d-a830fcaac903,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-3eac7eb1-ab10-462f-a625-17ddc59fc4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40913,DS-63272ade-1a13-4cc9-802c-eed1bd52deb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-0d6deb4e-0284-423d-ae7a-ecf7722b1c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-c9b9df21-498a-4307-b95c-18c683355eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43347,DS-06a2b9e1-7409-4c33-8c66-0e979680b25e,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-5b286c89-74f8-425c-a2e2-827bb3e425cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44195,DS-fcf987c7-0189-48e1-8a1f-8ac186bbbbb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-888710309-172.17.0.11-1595607616412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46183,DS-dc31bf2d-569a-4a8d-b73d-a830fcaac903,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-3eac7eb1-ab10-462f-a625-17ddc59fc4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40913,DS-63272ade-1a13-4cc9-802c-eed1bd52deb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-0d6deb4e-0284-423d-ae7a-ecf7722b1c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-c9b9df21-498a-4307-b95c-18c683355eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43347,DS-06a2b9e1-7409-4c33-8c66-0e979680b25e,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-5b286c89-74f8-425c-a2e2-827bb3e425cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44195,DS-fcf987c7-0189-48e1-8a1f-8ac186bbbbb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1951979518-172.17.0.11-1595608438863:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40573,DS-62542ca2-49ca-4238-afd9-ccdb0f5dfcd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-a3a3f847-5785-48f9-a84d-e4819ac125cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-233f6244-4403-410c-9263-7a7078ad29c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-66e331e8-4bb2-4c33-a5da-fb383e65e592,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-6058fd16-f78e-4c23-a9e7-a8680f9896bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-440eca3a-29d9-4baa-9e23-9eba463982b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-f69d7d60-4080-4ffe-a4dc-019373dd367a,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-18b19528-6497-451a-b499-b2bdbc767ec8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1951979518-172.17.0.11-1595608438863:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40573,DS-62542ca2-49ca-4238-afd9-ccdb0f5dfcd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-a3a3f847-5785-48f9-a84d-e4819ac125cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-233f6244-4403-410c-9263-7a7078ad29c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-66e331e8-4bb2-4c33-a5da-fb383e65e592,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-6058fd16-f78e-4c23-a9e7-a8680f9896bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-440eca3a-29d9-4baa-9e23-9eba463982b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-f69d7d60-4080-4ffe-a4dc-019373dd367a,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-18b19528-6497-451a-b499-b2bdbc767ec8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1858905693-172.17.0.11-1595608896800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39987,DS-8d517272-d1ac-4306-9b28-a2b04446e435,DISK], DatanodeInfoWithStorage[127.0.0.1:39577,DS-b457cb46-597b-456d-afcc-ff996853ace5,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-06544af2-9a90-468e-ac55-b250b140fc03,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-576b6ceb-6faf-4fa6-bc2a-f993346e192d,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-1cebdaa8-b873-4747-9f78-2754545efe7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-b02dc1d9-0e16-4453-a538-3ab1712882b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-b2572b5d-b8c7-4e15-9373-10c35d4d06ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-0a358440-6fa7-467a-ab38-da788f20a7b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1858905693-172.17.0.11-1595608896800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39987,DS-8d517272-d1ac-4306-9b28-a2b04446e435,DISK], DatanodeInfoWithStorage[127.0.0.1:39577,DS-b457cb46-597b-456d-afcc-ff996853ace5,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-06544af2-9a90-468e-ac55-b250b140fc03,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-576b6ceb-6faf-4fa6-bc2a-f993346e192d,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-1cebdaa8-b873-4747-9f78-2754545efe7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-b02dc1d9-0e16-4453-a538-3ab1712882b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-b2572b5d-b8c7-4e15-9373-10c35d4d06ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-0a358440-6fa7-467a-ab38-da788f20a7b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1899135439-172.17.0.11-1595608933722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38564,DS-9ccfa8d0-c046-463c-b884-da373cd35b19,DISK], DatanodeInfoWithStorage[127.0.0.1:41110,DS-a5022fde-e19b-42d3-99d2-270b22543122,DISK], DatanodeInfoWithStorage[127.0.0.1:42818,DS-a257716c-d245-4d50-bed7-c5a04648a317,DISK], DatanodeInfoWithStorage[127.0.0.1:42764,DS-13400199-2a1f-4e6c-85af-d1582914baa4,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-db01f07c-935b-4360-8d50-362cd698b37e,DISK], DatanodeInfoWithStorage[127.0.0.1:45361,DS-b6ee7afb-50e4-4240-8854-186481e04ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-cbb1da72-2716-4a30-8246-f21475dcb97a,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-b5b1b819-ee8e-4cf7-981d-909e61cb1236,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1899135439-172.17.0.11-1595608933722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38564,DS-9ccfa8d0-c046-463c-b884-da373cd35b19,DISK], DatanodeInfoWithStorage[127.0.0.1:41110,DS-a5022fde-e19b-42d3-99d2-270b22543122,DISK], DatanodeInfoWithStorage[127.0.0.1:42818,DS-a257716c-d245-4d50-bed7-c5a04648a317,DISK], DatanodeInfoWithStorage[127.0.0.1:42764,DS-13400199-2a1f-4e6c-85af-d1582914baa4,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-db01f07c-935b-4360-8d50-362cd698b37e,DISK], DatanodeInfoWithStorage[127.0.0.1:45361,DS-b6ee7afb-50e4-4240-8854-186481e04ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-cbb1da72-2716-4a30-8246-f21475dcb97a,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-b5b1b819-ee8e-4cf7-981d-909e61cb1236,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5248
