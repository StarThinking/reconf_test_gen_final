reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1263755136-172.17.0.16-1596027934324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34675,DS-4c4b27a5-6f90-4eae-8ce8-15dd3ca26019,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-32f74ea6-7cf7-407c-ac05-cbd86af473ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-f6a0560d-4d70-46ff-9b31-6278847e5de5,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-a3105bab-3790-4853-913e-bc8b240d60c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-934eecb1-29b6-45ce-8e2b-c3401c0478de,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-163478a3-e0b4-4f37-ba90-389c47dfe5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-ed113302-b88c-4f76-80f3-89a5ff8e9e19,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-f1267d82-ed4c-44fc-a7be-02edffd28c7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1263755136-172.17.0.16-1596027934324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34675,DS-4c4b27a5-6f90-4eae-8ce8-15dd3ca26019,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-32f74ea6-7cf7-407c-ac05-cbd86af473ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-f6a0560d-4d70-46ff-9b31-6278847e5de5,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-a3105bab-3790-4853-913e-bc8b240d60c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-934eecb1-29b6-45ce-8e2b-c3401c0478de,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-163478a3-e0b4-4f37-ba90-389c47dfe5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-ed113302-b88c-4f76-80f3-89a5ff8e9e19,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-f1267d82-ed4c-44fc-a7be-02edffd28c7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-270223963-172.17.0.16-1596028199805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35085,DS-68f651e0-10d4-4f17-9572-6e1bf52924b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-7f55356f-7958-4b2c-9a57-439eacdc0a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-6b081cfc-94e0-4c7a-af60-3c29dc51ca50,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-3da26bd5-8246-4bef-85fe-f486d5dc62fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-daa53c82-0b21-4886-ae92-c6dc7ccb339f,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-f7ce79d2-213f-45a3-bc4c-acc263449205,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-56c58740-022d-449b-bbaf-c6f93ab11914,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-776669eb-4ea8-408e-9774-1a4139f5ad88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-270223963-172.17.0.16-1596028199805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35085,DS-68f651e0-10d4-4f17-9572-6e1bf52924b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-7f55356f-7958-4b2c-9a57-439eacdc0a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-6b081cfc-94e0-4c7a-af60-3c29dc51ca50,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-3da26bd5-8246-4bef-85fe-f486d5dc62fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-daa53c82-0b21-4886-ae92-c6dc7ccb339f,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-f7ce79d2-213f-45a3-bc4c-acc263449205,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-56c58740-022d-449b-bbaf-c6f93ab11914,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-776669eb-4ea8-408e-9774-1a4139f5ad88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1964060193-172.17.0.16-1596028303527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40234,DS-d70a5800-f2cd-445d-bc9b-72d16c8f81be,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-3a250d25-3f35-49c1-9ffc-72a1997a842b,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-29af6ebd-cbd3-4226-a58d-2021bcffac4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-9058f09d-da20-4ed2-a123-63f89d9bf48a,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-fe230603-767e-4316-afa5-18559ff047fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-8cd68264-c5e9-4b1f-8b2e-af3c74d7f145,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-602fec38-0a46-4a7b-b965-71aeeb8e9dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-01e6484a-80b9-450d-86c2-b0223abcf1c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1964060193-172.17.0.16-1596028303527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40234,DS-d70a5800-f2cd-445d-bc9b-72d16c8f81be,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-3a250d25-3f35-49c1-9ffc-72a1997a842b,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-29af6ebd-cbd3-4226-a58d-2021bcffac4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-9058f09d-da20-4ed2-a123-63f89d9bf48a,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-fe230603-767e-4316-afa5-18559ff047fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-8cd68264-c5e9-4b1f-8b2e-af3c74d7f145,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-602fec38-0a46-4a7b-b965-71aeeb8e9dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-01e6484a-80b9-450d-86c2-b0223abcf1c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1383515929-172.17.0.16-1596028413970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34221,DS-c897c0fa-36f8-4c96-99d9-8a051009a256,DISK], DatanodeInfoWithStorage[127.0.0.1:39420,DS-40030a31-d4f9-48e7-bf67-71609656dab2,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-d80a665e-9ed1-4fc4-9f0d-7dc372ce7f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-aa4b6468-f346-45c9-a4bb-d8d5ed841f75,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-20ed5b7e-6e8d-4f94-8252-594649448ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-b24d9519-830c-4acf-9117-a6126a20bfd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-c3b137b5-d47e-41b6-abcc-379b4e73c007,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-c36b46e3-102d-4f7b-8fc9-a53c90f423c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1383515929-172.17.0.16-1596028413970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34221,DS-c897c0fa-36f8-4c96-99d9-8a051009a256,DISK], DatanodeInfoWithStorage[127.0.0.1:39420,DS-40030a31-d4f9-48e7-bf67-71609656dab2,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-d80a665e-9ed1-4fc4-9f0d-7dc372ce7f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-aa4b6468-f346-45c9-a4bb-d8d5ed841f75,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-20ed5b7e-6e8d-4f94-8252-594649448ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-b24d9519-830c-4acf-9117-a6126a20bfd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-c3b137b5-d47e-41b6-abcc-379b4e73c007,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-c36b46e3-102d-4f7b-8fc9-a53c90f423c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1731412721-172.17.0.16-1596028582160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42171,DS-bcebf44b-4bab-4e32-be93-c13213c12618,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-9854a852-eea9-478e-9205-9988d44a1ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-4eb3d3bf-1762-4dde-8b82-b40204af36ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34596,DS-411694fc-88ef-472b-abab-8cc0348949b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-65373d08-d02a-4d09-a752-2ce30244adbd,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-a2b984cc-b6f0-4697-8822-3a67aac60370,DISK], DatanodeInfoWithStorage[127.0.0.1:37862,DS-87ccac7e-f82e-452b-afe3-9cd7bc3c85ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-1376cdd4-589c-4904-a937-05858229819f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1731412721-172.17.0.16-1596028582160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42171,DS-bcebf44b-4bab-4e32-be93-c13213c12618,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-9854a852-eea9-478e-9205-9988d44a1ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-4eb3d3bf-1762-4dde-8b82-b40204af36ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34596,DS-411694fc-88ef-472b-abab-8cc0348949b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-65373d08-d02a-4d09-a752-2ce30244adbd,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-a2b984cc-b6f0-4697-8822-3a67aac60370,DISK], DatanodeInfoWithStorage[127.0.0.1:37862,DS-87ccac7e-f82e-452b-afe3-9cd7bc3c85ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-1376cdd4-589c-4904-a937-05858229819f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-913087413-172.17.0.16-1596028657181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35169,DS-b9076b31-3a9a-4a70-8976-020172965388,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-80d60c15-9cb1-4768-8bbe-e580b541c8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-f541f5f5-22bd-4eea-b968-ad1fb633f913,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-53d2133d-e26f-448b-9a1f-4314d26ad7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-53069153-76c0-4d20-a26b-971c7fb616f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33003,DS-dbb81abe-09b5-434b-8dbf-ab0b96379ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-e1fcd8fe-9fef-4a3a-b0e4-019c0d8ecfe4,DISK], DatanodeInfoWithStorage[127.0.0.1:34429,DS-3857571b-7bd4-47d2-9eb0-cc0649ed1c2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-913087413-172.17.0.16-1596028657181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35169,DS-b9076b31-3a9a-4a70-8976-020172965388,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-80d60c15-9cb1-4768-8bbe-e580b541c8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-f541f5f5-22bd-4eea-b968-ad1fb633f913,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-53d2133d-e26f-448b-9a1f-4314d26ad7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-53069153-76c0-4d20-a26b-971c7fb616f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33003,DS-dbb81abe-09b5-434b-8dbf-ab0b96379ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-e1fcd8fe-9fef-4a3a-b0e4-019c0d8ecfe4,DISK], DatanodeInfoWithStorage[127.0.0.1:34429,DS-3857571b-7bd4-47d2-9eb0-cc0649ed1c2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-679383112-172.17.0.16-1596028701624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35488,DS-10df292f-1113-4e55-be98-0bb89f840782,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-8449b543-a000-491c-b26c-86c022c4c8f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-0a0fcd70-b5d2-458c-b465-e71cc48d54aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-23387c35-0c0a-4951-9b8f-20bfa0e026ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-2f30c2c4-d631-4134-adbc-2be7aa660b14,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-849a0302-540c-4242-bd34-386ac76eaf3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-b5f09031-e36f-4699-9704-57f77ef36e79,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-9b71b82a-8084-464c-a25f-e93d9257d168,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-679383112-172.17.0.16-1596028701624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35488,DS-10df292f-1113-4e55-be98-0bb89f840782,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-8449b543-a000-491c-b26c-86c022c4c8f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-0a0fcd70-b5d2-458c-b465-e71cc48d54aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-23387c35-0c0a-4951-9b8f-20bfa0e026ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-2f30c2c4-d631-4134-adbc-2be7aa660b14,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-849a0302-540c-4242-bd34-386ac76eaf3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-b5f09031-e36f-4699-9704-57f77ef36e79,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-9b71b82a-8084-464c-a25f-e93d9257d168,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-127478845-172.17.0.16-1596029288735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35730,DS-4d733926-9b1a-45a9-a159-f6b08bcbcfd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-329b8760-8712-436b-9b59-03ef25f8bcd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-ab47c583-790b-4d91-8006-cb4a9a55005c,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-ccbb9798-38e2-4c88-8eea-266b85ff7ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-9c7ba5de-7df8-4cfd-bd88-d79063d918b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-826a3bd7-4661-4d38-ada9-08defb3bd5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-1b7a166e-136c-4263-a50e-1be120a21d12,DISK], DatanodeInfoWithStorage[127.0.0.1:35641,DS-5681ca84-2c3d-47b7-a661-597f390e2b79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-127478845-172.17.0.16-1596029288735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35730,DS-4d733926-9b1a-45a9-a159-f6b08bcbcfd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-329b8760-8712-436b-9b59-03ef25f8bcd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-ab47c583-790b-4d91-8006-cb4a9a55005c,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-ccbb9798-38e2-4c88-8eea-266b85ff7ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-9c7ba5de-7df8-4cfd-bd88-d79063d918b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-826a3bd7-4661-4d38-ada9-08defb3bd5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-1b7a166e-136c-4263-a50e-1be120a21d12,DISK], DatanodeInfoWithStorage[127.0.0.1:35641,DS-5681ca84-2c3d-47b7-a661-597f390e2b79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1234895935-172.17.0.16-1596029413937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42410,DS-3f3f8e2c-78fc-4322-bb2b-f6407c79f723,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-b178bdb7-0130-4628-a9a1-98ec60e4843b,DISK], DatanodeInfoWithStorage[127.0.0.1:44325,DS-d50e2b5b-0d05-426f-84cb-c0a6fe079d34,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-795d3efc-14a0-4fa1-8979-8abc3c727dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-cbe77c01-c3d3-42cb-8732-ded7011fbca7,DISK], DatanodeInfoWithStorage[127.0.0.1:41127,DS-0fe908e8-1fef-4b59-b112-7a298c0302c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-59f8656c-faa7-4a12-86c1-1dfa868ed296,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-bd21aa62-f368-4e4b-ab9d-7b8788af6998,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1234895935-172.17.0.16-1596029413937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42410,DS-3f3f8e2c-78fc-4322-bb2b-f6407c79f723,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-b178bdb7-0130-4628-a9a1-98ec60e4843b,DISK], DatanodeInfoWithStorage[127.0.0.1:44325,DS-d50e2b5b-0d05-426f-84cb-c0a6fe079d34,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-795d3efc-14a0-4fa1-8979-8abc3c727dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-cbe77c01-c3d3-42cb-8732-ded7011fbca7,DISK], DatanodeInfoWithStorage[127.0.0.1:41127,DS-0fe908e8-1fef-4b59-b112-7a298c0302c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-59f8656c-faa7-4a12-86c1-1dfa868ed296,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-bd21aa62-f368-4e4b-ab9d-7b8788af6998,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1978073590-172.17.0.16-1596029450585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36051,DS-ccd53bd2-93a7-49c4-83d4-2914ed2c0f83,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-38095dce-6f02-44d4-971e-26bc43b7b668,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-647caebe-161c-41e0-9a60-5803c677d59d,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-f59d369d-214b-4a7d-ad0a-6744a3f2e525,DISK], DatanodeInfoWithStorage[127.0.0.1:39717,DS-7c915cdc-4344-49fd-8ad2-750e8b3d933c,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-7de92f38-b900-4f82-abf6-aa82167012d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-c74113cb-7293-4759-ac63-2a5853260f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34979,DS-48d38ea0-67fe-4003-919e-b6c87cac910f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1978073590-172.17.0.16-1596029450585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36051,DS-ccd53bd2-93a7-49c4-83d4-2914ed2c0f83,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-38095dce-6f02-44d4-971e-26bc43b7b668,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-647caebe-161c-41e0-9a60-5803c677d59d,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-f59d369d-214b-4a7d-ad0a-6744a3f2e525,DISK], DatanodeInfoWithStorage[127.0.0.1:39717,DS-7c915cdc-4344-49fd-8ad2-750e8b3d933c,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-7de92f38-b900-4f82-abf6-aa82167012d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-c74113cb-7293-4759-ac63-2a5853260f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34979,DS-48d38ea0-67fe-4003-919e-b6c87cac910f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1834499649-172.17.0.16-1596029779445:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37592,DS-22470ef9-275e-4eeb-bd50-b01c4b3189e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-f92326e8-473a-4f39-8eaa-d06ffe1ec9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-61810c78-48d4-4b6d-8045-6314cee2237f,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-a8ac53bb-3c26-483e-98aa-b9129ca62d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-e6712eac-1caa-4583-b3c9-854b3a16ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-98ed1440-0bd7-4635-9a03-e7379254cf85,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-b2794000-3e78-4654-aa02-058b85f78923,DISK], DatanodeInfoWithStorage[127.0.0.1:34246,DS-85373052-a14e-4d2c-a0f0-a6acc234304a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1834499649-172.17.0.16-1596029779445:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37592,DS-22470ef9-275e-4eeb-bd50-b01c4b3189e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-f92326e8-473a-4f39-8eaa-d06ffe1ec9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-61810c78-48d4-4b6d-8045-6314cee2237f,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-a8ac53bb-3c26-483e-98aa-b9129ca62d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-e6712eac-1caa-4583-b3c9-854b3a16ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-98ed1440-0bd7-4635-9a03-e7379254cf85,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-b2794000-3e78-4654-aa02-058b85f78923,DISK], DatanodeInfoWithStorage[127.0.0.1:34246,DS-85373052-a14e-4d2c-a0f0-a6acc234304a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1961305567-172.17.0.16-1596030189244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37823,DS-32fea503-6258-4d0c-ad81-02ddc461f62b,DISK], DatanodeInfoWithStorage[127.0.0.1:35787,DS-884ecd90-ffb6-4d64-976e-4a1a5deb70fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-4e06c0b0-af42-4b51-8b8d-7f18290dc4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-21958bf4-20e7-4bc8-a223-a4a024f36a32,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-aafc6a5a-a94a-4518-baa7-af0fc0f2f5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-5509abfd-ebc5-49c0-89f5-cfa67e26b13a,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-34f282b2-f904-488d-9201-d2fa8e8dd87e,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-370cf34d-5bb1-473e-a76f-c4b61ee58d91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1961305567-172.17.0.16-1596030189244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37823,DS-32fea503-6258-4d0c-ad81-02ddc461f62b,DISK], DatanodeInfoWithStorage[127.0.0.1:35787,DS-884ecd90-ffb6-4d64-976e-4a1a5deb70fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-4e06c0b0-af42-4b51-8b8d-7f18290dc4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-21958bf4-20e7-4bc8-a223-a4a024f36a32,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-aafc6a5a-a94a-4518-baa7-af0fc0f2f5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-5509abfd-ebc5-49c0-89f5-cfa67e26b13a,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-34f282b2-f904-488d-9201-d2fa8e8dd87e,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-370cf34d-5bb1-473e-a76f-c4b61ee58d91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1490556853-172.17.0.16-1596030366341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37715,DS-a996cfe3-faec-41b0-8eab-3ea9298f958c,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-a5a17789-c62f-49f0-ab0d-488748abced7,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-a250acd9-86b6-410f-904d-6c4430f30ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-7633695f-fca3-4f25-8b1b-8b8a397aff37,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-3b6cd157-1ae4-40a5-9dbe-5510e48ecfe9,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-fb651805-f7f2-4701-bc8e-aa080d52ef92,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-24ef83a9-65f9-4990-b354-78c321338a86,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-b63d1c9c-0f54-4f36-8bd0-3d8eb9772366,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1490556853-172.17.0.16-1596030366341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37715,DS-a996cfe3-faec-41b0-8eab-3ea9298f958c,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-a5a17789-c62f-49f0-ab0d-488748abced7,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-a250acd9-86b6-410f-904d-6c4430f30ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-7633695f-fca3-4f25-8b1b-8b8a397aff37,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-3b6cd157-1ae4-40a5-9dbe-5510e48ecfe9,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-fb651805-f7f2-4701-bc8e-aa080d52ef92,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-24ef83a9-65f9-4990-b354-78c321338a86,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-b63d1c9c-0f54-4f36-8bd0-3d8eb9772366,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1005039794-172.17.0.16-1596030464862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39804,DS-9d91e73c-5166-4a40-a04a-68a04ebfcc32,DISK], DatanodeInfoWithStorage[127.0.0.1:44226,DS-701fbd5f-25bf-4942-bf1c-1cfc89762709,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-1011b489-513a-42e9-bf1c-2f62f25983f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-5bb56973-b4e8-435a-81fe-d2370f14d136,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-f5b671ac-d263-4d13-9e57-37ac82de780c,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-799c85a0-39ee-42bb-9906-2bfe552f79c4,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-6d657e48-7f4e-449b-9dbe-9c030a3a749c,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-ff315b19-80d6-4861-b13b-3cc836cde003,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1005039794-172.17.0.16-1596030464862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39804,DS-9d91e73c-5166-4a40-a04a-68a04ebfcc32,DISK], DatanodeInfoWithStorage[127.0.0.1:44226,DS-701fbd5f-25bf-4942-bf1c-1cfc89762709,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-1011b489-513a-42e9-bf1c-2f62f25983f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-5bb56973-b4e8-435a-81fe-d2370f14d136,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-f5b671ac-d263-4d13-9e57-37ac82de780c,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-799c85a0-39ee-42bb-9906-2bfe552f79c4,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-6d657e48-7f4e-449b-9dbe-9c030a3a749c,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-ff315b19-80d6-4861-b13b-3cc836cde003,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1671417632-172.17.0.16-1596030578315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44938,DS-4f669e86-8882-4894-8c32-ea781189dda5,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-f09b64ff-c769-4f5a-899d-5a3702f507a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-231ec961-d94e-4abf-a392-75c8c16d32bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-21251c46-48bb-4385-bdca-cf16ffce4c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-07b3ed30-2cf9-4f15-8214-620e12a87d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45419,DS-fb47dd6a-0bd9-4387-8e52-f5059baa2bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-2e33ac2f-0391-40a5-a9b9-bf98b26e9217,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-0005d050-148c-4aea-aff1-c4b276445cf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1671417632-172.17.0.16-1596030578315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44938,DS-4f669e86-8882-4894-8c32-ea781189dda5,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-f09b64ff-c769-4f5a-899d-5a3702f507a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-231ec961-d94e-4abf-a392-75c8c16d32bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-21251c46-48bb-4385-bdca-cf16ffce4c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-07b3ed30-2cf9-4f15-8214-620e12a87d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45419,DS-fb47dd6a-0bd9-4387-8e52-f5059baa2bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-2e33ac2f-0391-40a5-a9b9-bf98b26e9217,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-0005d050-148c-4aea-aff1-c4b276445cf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-752551556-172.17.0.16-1596030610355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40996,DS-4acbd019-f45e-4eb7-af86-38a2b1fe5146,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-6af75332-ab02-4f59-a9c9-653239be72b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-884ba3db-a162-4629-9969-13ed994c61cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-12c74631-d549-4dfc-a2a6-6384684a0e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41693,DS-90d808bb-4b27-41aa-bc9b-8307d6432d03,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-ec1b3ba4-8502-4ec0-b3e6-586f6a88ecb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-ea934852-d98a-451d-a31a-e5cce70489eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42394,DS-79f69be9-3d1d-412e-9eba-92ae33d89c6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-752551556-172.17.0.16-1596030610355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40996,DS-4acbd019-f45e-4eb7-af86-38a2b1fe5146,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-6af75332-ab02-4f59-a9c9-653239be72b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-884ba3db-a162-4629-9969-13ed994c61cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-12c74631-d549-4dfc-a2a6-6384684a0e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41693,DS-90d808bb-4b27-41aa-bc9b-8307d6432d03,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-ec1b3ba4-8502-4ec0-b3e6-586f6a88ecb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-ea934852-d98a-451d-a31a-e5cce70489eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42394,DS-79f69be9-3d1d-412e-9eba-92ae33d89c6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-104321574-172.17.0.16-1596030674668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34180,DS-81567712-1eb9-4fc9-b1b3-50d9688408fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-b56cd762-7d05-4c2d-9119-6148177b07c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-109ab88e-f1b1-43cd-8da7-a1bb37d802ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-49ba36fe-3cbd-406f-9143-076baf979a25,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-fa20d5b0-f223-4508-a81c-42e7eb4883b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-7fd665e6-3327-4e64-ae42-54afd3466982,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-98861d69-1eeb-4949-b7b6-9577172cbd26,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-1aef5ade-6ddd-4d30-9409-8837c3972dc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-104321574-172.17.0.16-1596030674668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34180,DS-81567712-1eb9-4fc9-b1b3-50d9688408fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-b56cd762-7d05-4c2d-9119-6148177b07c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-109ab88e-f1b1-43cd-8da7-a1bb37d802ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-49ba36fe-3cbd-406f-9143-076baf979a25,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-fa20d5b0-f223-4508-a81c-42e7eb4883b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-7fd665e6-3327-4e64-ae42-54afd3466982,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-98861d69-1eeb-4949-b7b6-9577172cbd26,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-1aef5ade-6ddd-4d30-9409-8837c3972dc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 3750
