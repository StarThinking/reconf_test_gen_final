reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDiffReport#testDiffReportWithOpenFiles
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDiffReport#testDiffReportWithOpenFiles
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34398,DS-bbc2ea21-9e99-443e-9259-f4a42fe917a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-916a6769-b1c7-4926-a997-cfcf9c4fd0c2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34398,DS-bbc2ea21-9e99-443e-9259-f4a42fe917a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-916a6769-b1c7-4926-a997-cfcf9c4fd0c2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34398,DS-bbc2ea21-9e99-443e-9259-f4a42fe917a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-916a6769-b1c7-4926-a997-cfcf9c4fd0c2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34398,DS-bbc2ea21-9e99-443e-9259-f4a42fe917a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-916a6769-b1c7-4926-a997-cfcf9c4fd0c2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDiffReport#testDiffReportWithOpenFiles
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33993,DS-e34ff920-6aef-4660-8acc-e5f1188b9d45,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-cc0d74ba-83c1-465a-8f8b-b83ef31c97e0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33993,DS-e34ff920-6aef-4660-8acc-e5f1188b9d45,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-cc0d74ba-83c1-465a-8f8b-b83ef31c97e0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33993,DS-e34ff920-6aef-4660-8acc-e5f1188b9d45,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-cc0d74ba-83c1-465a-8f8b-b83ef31c97e0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33993,DS-e34ff920-6aef-4660-8acc-e5f1188b9d45,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-cc0d74ba-83c1-465a-8f8b-b83ef31c97e0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDiffReport#testDiffReportWithOpenFiles
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39342,DS-2d45d914-f540-4f20-a47e-14edbba959aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-88cf3399-cbf8-4508-b944-0e22d9e62c31,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40839,DS-88cf3399-cbf8-4508-b944-0e22d9e62c31,DISK], DatanodeInfoWithStorage[127.0.0.1:39342,DS-2d45d914-f540-4f20-a47e-14edbba959aa,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39342,DS-2d45d914-f540-4f20-a47e-14edbba959aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-88cf3399-cbf8-4508-b944-0e22d9e62c31,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40839,DS-88cf3399-cbf8-4508-b944-0e22d9e62c31,DISK], DatanodeInfoWithStorage[127.0.0.1:39342,DS-2d45d914-f540-4f20-a47e-14edbba959aa,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDiffReport#testDiffReportWithOpenFiles
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40449,DS-b3f9e668-f78a-4471-bf00-f4d8e5c0e9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44869,DS-beafe87a-d8da-4a31-82b5-156f93656bf0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40449,DS-b3f9e668-f78a-4471-bf00-f4d8e5c0e9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44869,DS-beafe87a-d8da-4a31-82b5-156f93656bf0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40449,DS-b3f9e668-f78a-4471-bf00-f4d8e5c0e9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44869,DS-beafe87a-d8da-4a31-82b5-156f93656bf0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40449,DS-b3f9e668-f78a-4471-bf00-f4d8e5c0e9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44869,DS-beafe87a-d8da-4a31-82b5-156f93656bf0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDiffReport#testDiffReportWithOpenFiles
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33875,DS-37493310-72bf-41e0-ade2-9baa79951fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-4cca8044-b993-456e-ac16-d214ff56c964,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33875,DS-37493310-72bf-41e0-ade2-9baa79951fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-4cca8044-b993-456e-ac16-d214ff56c964,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33875,DS-37493310-72bf-41e0-ade2-9baa79951fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-4cca8044-b993-456e-ac16-d214ff56c964,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33875,DS-37493310-72bf-41e0-ade2-9baa79951fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-4cca8044-b993-456e-ac16-d214ff56c964,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDiffReport#testDiffReportWithOpenFiles
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38193,DS-b23b1c69-8010-40e1-9ba3-e512179c911b,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-26391e4f-87d6-4b74-9224-7113f1b0eed8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38193,DS-b23b1c69-8010-40e1-9ba3-e512179c911b,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-26391e4f-87d6-4b74-9224-7113f1b0eed8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38193,DS-b23b1c69-8010-40e1-9ba3-e512179c911b,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-26391e4f-87d6-4b74-9224-7113f1b0eed8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38193,DS-b23b1c69-8010-40e1-9ba3-e512179c911b,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-26391e4f-87d6-4b74-9224-7113f1b0eed8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDiffReport#testDiffReportWithOpenFiles
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45724,DS-42c9e210-2818-4542-b973-c022a24800a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-ea6dce87-d76c-43c2-8c4d-29c3adc56334,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46654,DS-ea6dce87-d76c-43c2-8c4d-29c3adc56334,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-42c9e210-2818-4542-b973-c022a24800a2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45724,DS-42c9e210-2818-4542-b973-c022a24800a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-ea6dce87-d76c-43c2-8c4d-29c3adc56334,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46654,DS-ea6dce87-d76c-43c2-8c4d-29c3adc56334,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-42c9e210-2818-4542-b973-c022a24800a2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDiffReport#testDiffReportWithOpenFiles
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46857,DS-853713b4-9ddf-42c1-a77e-25b36deed094,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-03f233c4-f4ba-48d8-9b4c-527ce437a31f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46857,DS-853713b4-9ddf-42c1-a77e-25b36deed094,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-03f233c4-f4ba-48d8-9b4c-527ce437a31f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46857,DS-853713b4-9ddf-42c1-a77e-25b36deed094,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-03f233c4-f4ba-48d8-9b4c-527ce437a31f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46857,DS-853713b4-9ddf-42c1-a77e-25b36deed094,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-03f233c4-f4ba-48d8-9b4c-527ce437a31f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDiffReport#testDiffReportWithOpenFiles
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38230,DS-0ae20c38-c6d2-4781-9021-107084397e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35342,DS-8ebf4b1b-ff3c-43ab-91fd-b4518e47e9d9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38230,DS-0ae20c38-c6d2-4781-9021-107084397e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35342,DS-8ebf4b1b-ff3c-43ab-91fd-b4518e47e9d9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38230,DS-0ae20c38-c6d2-4781-9021-107084397e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35342,DS-8ebf4b1b-ff3c-43ab-91fd-b4518e47e9d9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38230,DS-0ae20c38-c6d2-4781-9021-107084397e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35342,DS-8ebf4b1b-ff3c-43ab-91fd-b4518e47e9d9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDiffReport#testDiffReportWithOpenFiles
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42496,DS-9985131d-85a0-463e-9faa-45cfdc73b405,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-fa69842f-2fa9-4732-9a34-e29a4642a29c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42496,DS-9985131d-85a0-463e-9faa-45cfdc73b405,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-fa69842f-2fa9-4732-9a34-e29a4642a29c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42496,DS-9985131d-85a0-463e-9faa-45cfdc73b405,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-fa69842f-2fa9-4732-9a34-e29a4642a29c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42496,DS-9985131d-85a0-463e-9faa-45cfdc73b405,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-fa69842f-2fa9-4732-9a34-e29a4642a29c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 833
