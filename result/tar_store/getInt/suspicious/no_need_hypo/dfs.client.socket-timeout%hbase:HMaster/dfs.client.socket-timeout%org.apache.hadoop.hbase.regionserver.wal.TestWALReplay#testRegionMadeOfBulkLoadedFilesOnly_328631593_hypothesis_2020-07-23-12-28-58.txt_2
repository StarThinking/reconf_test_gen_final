reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37379,DS-dc873325-d021-4414-bfe4-0aa3deea270d,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-a51f6d22-5c24-441f-be8d-f73196c6b842,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37379,DS-dc873325-d021-4414-bfe4-0aa3deea270d,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-a51f6d22-5c24-441f-be8d-f73196c6b842,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37379,DS-dc873325-d021-4414-bfe4-0aa3deea270d,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-a51f6d22-5c24-441f-be8d-f73196c6b842,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37379,DS-dc873325-d021-4414-bfe4-0aa3deea270d,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-a51f6d22-5c24-441f-be8d-f73196c6b842,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34077,DS-7cfe9e4f-0668-46df-bbff-c707b1cfd4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-9c2c839e-c7dd-4f7c-8a10-62c8dded04be,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34077,DS-7cfe9e4f-0668-46df-bbff-c707b1cfd4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-9c2c839e-c7dd-4f7c-8a10-62c8dded04be,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34077,DS-7cfe9e4f-0668-46df-bbff-c707b1cfd4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-9c2c839e-c7dd-4f7c-8a10-62c8dded04be,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34077,DS-7cfe9e4f-0668-46df-bbff-c707b1cfd4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-9c2c839e-c7dd-4f7c-8a10-62c8dded04be,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34649,DS-cc990363-06e7-42e2-bd6b-b90f17dee653,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-ebb1ef14-770b-4525-a316-a9a8dc57914f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34649,DS-cc990363-06e7-42e2-bd6b-b90f17dee653,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-ebb1ef14-770b-4525-a316-a9a8dc57914f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34649,DS-cc990363-06e7-42e2-bd6b-b90f17dee653,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-ebb1ef14-770b-4525-a316-a9a8dc57914f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34649,DS-cc990363-06e7-42e2-bd6b-b90f17dee653,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-ebb1ef14-770b-4525-a316-a9a8dc57914f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39148,DS-ae98fe16-0151-474b-839b-6f830ebec707,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-1aabb8d6-ba76-4741-8e96-86043f3a8154,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39148,DS-ae98fe16-0151-474b-839b-6f830ebec707,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-1aabb8d6-ba76-4741-8e96-86043f3a8154,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39148,DS-ae98fe16-0151-474b-839b-6f830ebec707,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-1aabb8d6-ba76-4741-8e96-86043f3a8154,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39148,DS-ae98fe16-0151-474b-839b-6f830ebec707,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-1aabb8d6-ba76-4741-8e96-86043f3a8154,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33962,DS-a9877bca-fa83-4544-a266-58b204963f34,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-80bdc402-ad23-4e30-8a0b-6da80caaaf90,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33962,DS-a9877bca-fa83-4544-a266-58b204963f34,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-80bdc402-ad23-4e30-8a0b-6da80caaaf90,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33962,DS-a9877bca-fa83-4544-a266-58b204963f34,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-80bdc402-ad23-4e30-8a0b-6da80caaaf90,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33962,DS-a9877bca-fa83-4544-a266-58b204963f34,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-80bdc402-ad23-4e30-8a0b-6da80caaaf90,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38247,DS-84d7a024-3e66-49d2-be87-986534a00402,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-08483cc8-bd7c-4842-8ca3-0ebc5be91d06,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38247,DS-84d7a024-3e66-49d2-be87-986534a00402,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-08483cc8-bd7c-4842-8ca3-0ebc5be91d06,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38247,DS-84d7a024-3e66-49d2-be87-986534a00402,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-08483cc8-bd7c-4842-8ca3-0ebc5be91d06,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38247,DS-84d7a024-3e66-49d2-be87-986534a00402,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-08483cc8-bd7c-4842-8ca3-0ebc5be91d06,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40983,DS-85e5a7ba-c2ed-478e-9908-20a0172a8e25,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-d709a953-8cee-4364-9fcd-23373147153d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40983,DS-85e5a7ba-c2ed-478e-9908-20a0172a8e25,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-d709a953-8cee-4364-9fcd-23373147153d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40983,DS-85e5a7ba-c2ed-478e-9908-20a0172a8e25,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-d709a953-8cee-4364-9fcd-23373147153d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40983,DS-85e5a7ba-c2ed-478e-9908-20a0172a8e25,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-d709a953-8cee-4364-9fcd-23373147153d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34968,DS-79a3ffec-b389-4a65-8869-359045872715,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-a662de5d-7d10-459e-b0f6-ddca9986b66e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34968,DS-79a3ffec-b389-4a65-8869-359045872715,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-a662de5d-7d10-459e-b0f6-ddca9986b66e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34968,DS-79a3ffec-b389-4a65-8869-359045872715,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-a662de5d-7d10-459e-b0f6-ddca9986b66e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34968,DS-79a3ffec-b389-4a65-8869-359045872715,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-a662de5d-7d10-459e-b0f6-ddca9986b66e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33622,DS-4f09fe9a-f5ae-4d16-86df-1da76b4bbaba,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-6d5eb10a-441d-43b6-92a3-fb200e9c5513,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37861,DS-6d5eb10a-441d-43b6-92a3-fb200e9c5513,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-4f09fe9a-f5ae-4d16-86df-1da76b4bbaba,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33622,DS-4f09fe9a-f5ae-4d16-86df-1da76b4bbaba,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-6d5eb10a-441d-43b6-92a3-fb200e9c5513,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37861,DS-6d5eb10a-441d-43b6-92a3-fb200e9c5513,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-4f09fe9a-f5ae-4d16-86df-1da76b4bbaba,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45506,DS-794021cd-c779-47d1-8402-f3024bdbcd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41053,DS-853cb0e9-ae04-463c-802b-851064703c7b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41053,DS-853cb0e9-ae04-463c-802b-851064703c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-794021cd-c779-47d1-8402-f3024bdbcd7c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45506,DS-794021cd-c779-47d1-8402-f3024bdbcd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41053,DS-853cb0e9-ae04-463c-802b-851064703c7b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41053,DS-853cb0e9-ae04-463c-802b-851064703c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-794021cd-c779-47d1-8402-f3024bdbcd7c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45789,DS-767273c4-4912-4cfc-b24c-ea0814a6cdd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-3fbed60c-0a7a-4e0e-9bed-5d3e938e765b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38703,DS-3fbed60c-0a7a-4e0e-9bed-5d3e938e765b,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-767273c4-4912-4cfc-b24c-ea0814a6cdd9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45789,DS-767273c4-4912-4cfc-b24c-ea0814a6cdd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-3fbed60c-0a7a-4e0e-9bed-5d3e938e765b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38703,DS-3fbed60c-0a7a-4e0e-9bed-5d3e938e765b,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-767273c4-4912-4cfc-b24c-ea0814a6cdd9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38134,DS-aca0a3ea-a47c-4494-92f2-28ebfe8e020e,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-bdae3c86-6d2e-4b04-9e30-866ef3754b04,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38134,DS-aca0a3ea-a47c-4494-92f2-28ebfe8e020e,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-bdae3c86-6d2e-4b04-9e30-866ef3754b04,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38134,DS-aca0a3ea-a47c-4494-92f2-28ebfe8e020e,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-bdae3c86-6d2e-4b04-9e30-866ef3754b04,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38134,DS-aca0a3ea-a47c-4494-92f2-28ebfe8e020e,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-bdae3c86-6d2e-4b04-9e30-866ef3754b04,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42873,DS-76b4d494-5467-465a-8f9f-79c94d78ffae,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-0f51c0a7-d65e-45f1-81f7-42fe74324f28,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42873,DS-76b4d494-5467-465a-8f9f-79c94d78ffae,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-0f51c0a7-d65e-45f1-81f7-42fe74324f28,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42873,DS-76b4d494-5467-465a-8f9f-79c94d78ffae,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-0f51c0a7-d65e-45f1-81f7-42fe74324f28,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42873,DS-76b4d494-5467-465a-8f9f-79c94d78ffae,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-0f51c0a7-d65e-45f1-81f7-42fe74324f28,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33873,DS-840b57b4-f22b-434b-afee-6d316339cea5,DISK], DatanodeInfoWithStorage[127.0.0.1:44693,DS-dc9388f8-b032-4000-a1c1-e7695f324c41,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44693,DS-dc9388f8-b032-4000-a1c1-e7695f324c41,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-840b57b4-f22b-434b-afee-6d316339cea5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33873,DS-840b57b4-f22b-434b-afee-6d316339cea5,DISK], DatanodeInfoWithStorage[127.0.0.1:44693,DS-dc9388f8-b032-4000-a1c1-e7695f324c41,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44693,DS-dc9388f8-b032-4000-a1c1-e7695f324c41,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-840b57b4-f22b-434b-afee-6d316339cea5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35744,DS-8116753d-5727-405d-8b22-b3e8c5eeb58f,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-2385fab0-3a74-491e-b060-b03d180b04ab,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35744,DS-8116753d-5727-405d-8b22-b3e8c5eeb58f,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-2385fab0-3a74-491e-b060-b03d180b04ab,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35744,DS-8116753d-5727-405d-8b22-b3e8c5eeb58f,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-2385fab0-3a74-491e-b060-b03d180b04ab,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35744,DS-8116753d-5727-405d-8b22-b3e8c5eeb58f,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-2385fab0-3a74-491e-b060-b03d180b04ab,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41883,DS-1b4f8370-96b4-4930-b51c-db1f622f19e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-4d187668-8a51-4e4e-9146-7f9f04e1c90c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41919,DS-4d187668-8a51-4e4e-9146-7f9f04e1c90c,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-1b4f8370-96b4-4930-b51c-db1f622f19e9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41883,DS-1b4f8370-96b4-4930-b51c-db1f622f19e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-4d187668-8a51-4e4e-9146-7f9f04e1c90c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41919,DS-4d187668-8a51-4e4e-9146-7f9f04e1c90c,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-1b4f8370-96b4-4930-b51c-db1f622f19e9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43771,DS-90a7f2a5-5f04-48f7-87da-06edc0a34db5,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-5e46bafd-36bf-48c5-9eb4-8b225f005f7f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43771,DS-90a7f2a5-5f04-48f7-87da-06edc0a34db5,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-5e46bafd-36bf-48c5-9eb4-8b225f005f7f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43771,DS-90a7f2a5-5f04-48f7-87da-06edc0a34db5,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-5e46bafd-36bf-48c5-9eb4-8b225f005f7f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43771,DS-90a7f2a5-5f04-48f7-87da-06edc0a34db5,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-5e46bafd-36bf-48c5-9eb4-8b225f005f7f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43105,DS-4f72a492-a262-4c4f-91eb-a59a347d8a59,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-fb289783-d2ed-4c01-be47-b90f782544b1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43105,DS-4f72a492-a262-4c4f-91eb-a59a347d8a59,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-fb289783-d2ed-4c01-be47-b90f782544b1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43105,DS-4f72a492-a262-4c4f-91eb-a59a347d8a59,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-fb289783-d2ed-4c01-be47-b90f782544b1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43105,DS-4f72a492-a262-4c4f-91eb-a59a347d8a59,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-fb289783-d2ed-4c01-be47-b90f782544b1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35973,DS-0bf2e477-8e0a-4cbf-ac10-9061814e58b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-13117e6e-3609-4c10-a337-357dfb35065a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35973,DS-0bf2e477-8e0a-4cbf-ac10-9061814e58b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-13117e6e-3609-4c10-a337-357dfb35065a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35973,DS-0bf2e477-8e0a-4cbf-ac10-9061814e58b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-13117e6e-3609-4c10-a337-357dfb35065a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35973,DS-0bf2e477-8e0a-4cbf-ac10-9061814e58b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-13117e6e-3609-4c10-a337-357dfb35065a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36645,DS-19ace08d-fb51-4be1-ba06-47c7ded01a40,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-38ea2c83-a57a-48af-92f7-ccc0bd5f799a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36645,DS-19ace08d-fb51-4be1-ba06-47c7ded01a40,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-38ea2c83-a57a-48af-92f7-ccc0bd5f799a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36645,DS-19ace08d-fb51-4be1-ba06-47c7ded01a40,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-38ea2c83-a57a-48af-92f7-ccc0bd5f799a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36645,DS-19ace08d-fb51-4be1-ba06-47c7ded01a40,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-38ea2c83-a57a-48af-92f7-ccc0bd5f799a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Append sequenceId=4, requesting roll of WAL
stackTrace: org.apache.hadoop.hbase.regionserver.wal.DamagedWALException: Append sequenceId=4, requesting roll of WAL
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1081)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:964)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:873)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:129)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39778,DS-9ec84629-8410-497f-a1a2-102fad8e03ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-f254fad0-d119-42c7-85a3-32d20440b90b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44005,DS-f254fad0-d119-42c7-85a3-32d20440b90b,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-9ec84629-8410-497f-a1a2-102fad8e03ca,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35252,DS-61659d71-1381-4a8d-b833-9d5b63ff2d88,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-f87944e0-22b9-4d12-bbd4-5794409962e6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41220,DS-f87944e0-22b9-4d12-bbd4-5794409962e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35252,DS-61659d71-1381-4a8d-b833-9d5b63ff2d88,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35252,DS-61659d71-1381-4a8d-b833-9d5b63ff2d88,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-f87944e0-22b9-4d12-bbd4-5794409962e6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41220,DS-f87944e0-22b9-4d12-bbd4-5794409962e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35252,DS-61659d71-1381-4a8d-b833-9d5b63ff2d88,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33753,DS-b0b1de7d-73c2-433f-88b6-bc4c2261de82,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-a46f8473-e4c5-42fa-9817-57b94724370e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43313,DS-a46f8473-e4c5-42fa-9817-57b94724370e,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-b0b1de7d-73c2-433f-88b6-bc4c2261de82,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33753,DS-b0b1de7d-73c2-433f-88b6-bc4c2261de82,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-a46f8473-e4c5-42fa-9817-57b94724370e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43313,DS-a46f8473-e4c5-42fa-9817-57b94724370e,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-b0b1de7d-73c2-433f-88b6-bc4c2261de82,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35130,DS-10d0be61-7229-417e-a0f7-b3b49c47d29e,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-8df83af9-d11a-48b7-88d8-54a25048f88f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46331,DS-8df83af9-d11a-48b7-88d8-54a25048f88f,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-10d0be61-7229-417e-a0f7-b3b49c47d29e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35130,DS-10d0be61-7229-417e-a0f7-b3b49c47d29e,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-8df83af9-d11a-48b7-88d8-54a25048f88f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46331,DS-8df83af9-d11a-48b7-88d8-54a25048f88f,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-10d0be61-7229-417e-a0f7-b3b49c47d29e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44339,DS-76a68c5b-9c17-45dd-ba7e-68125ec8c9cc,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-86f2babc-5ebc-4fef-936e-beb2c06f0373,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44339,DS-76a68c5b-9c17-45dd-ba7e-68125ec8c9cc,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-86f2babc-5ebc-4fef-936e-beb2c06f0373,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44339,DS-76a68c5b-9c17-45dd-ba7e-68125ec8c9cc,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-86f2babc-5ebc-4fef-936e-beb2c06f0373,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44339,DS-76a68c5b-9c17-45dd-ba7e-68125ec8c9cc,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-86f2babc-5ebc-4fef-936e-beb2c06f0373,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34780,DS-ec78dc80-e10e-4a55-aeee-63e123ba4397,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-dae31c1a-b526-460c-8e87-0b2dacd3c23b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33785,DS-dae31c1a-b526-460c-8e87-0b2dacd3c23b,DISK], DatanodeInfoWithStorage[127.0.0.1:34780,DS-ec78dc80-e10e-4a55-aeee-63e123ba4397,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34780,DS-ec78dc80-e10e-4a55-aeee-63e123ba4397,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-dae31c1a-b526-460c-8e87-0b2dacd3c23b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33785,DS-dae31c1a-b526-460c-8e87-0b2dacd3c23b,DISK], DatanodeInfoWithStorage[127.0.0.1:34780,DS-ec78dc80-e10e-4a55-aeee-63e123ba4397,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32778,DS-7083f9e4-87c3-4e28-a48e-0b6098eeca27,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-09c85449-c4ee-4178-83ef-816189d3b570,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32778,DS-7083f9e4-87c3-4e28-a48e-0b6098eeca27,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-09c85449-c4ee-4178-83ef-816189d3b570,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32778,DS-7083f9e4-87c3-4e28-a48e-0b6098eeca27,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-09c85449-c4ee-4178-83ef-816189d3b570,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32778,DS-7083f9e4-87c3-4e28-a48e-0b6098eeca27,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-09c85449-c4ee-4178-83ef-816189d3b570,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44811,DS-04edc7e8-c138-4a28-90fb-31a85b5c1ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-d33cb734-4400-41b2-92a8-9c0b1050971e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33668,DS-d33cb734-4400-41b2-92a8-9c0b1050971e,DISK], DatanodeInfoWithStorage[127.0.0.1:44811,DS-04edc7e8-c138-4a28-90fb-31a85b5c1ee9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44811,DS-04edc7e8-c138-4a28-90fb-31a85b5c1ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-d33cb734-4400-41b2-92a8-9c0b1050971e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33668,DS-d33cb734-4400-41b2-92a8-9c0b1050971e,DISK], DatanodeInfoWithStorage[127.0.0.1:44811,DS-04edc7e8-c138-4a28-90fb-31a85b5c1ee9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39794,DS-c9c267bd-4302-44fd-9497-77ccca96bea0,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-541ed240-7e06-4fd2-bd78-70957e9020c0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36064,DS-541ed240-7e06-4fd2-bd78-70957e9020c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39794,DS-c9c267bd-4302-44fd-9497-77ccca96bea0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39794,DS-c9c267bd-4302-44fd-9497-77ccca96bea0,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-541ed240-7e06-4fd2-bd78-70957e9020c0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36064,DS-541ed240-7e06-4fd2-bd78-70957e9020c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39794,DS-c9c267bd-4302-44fd-9497-77ccca96bea0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly has not been updated !
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45139,DS-5a55c7c1-3b6e-47f3-a826-feab22eac9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-0f31804d-0615-40b7-a79c-30b8657e7c9d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45139,DS-5a55c7c1-3b6e-47f3-a826-feab22eac9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-0f31804d-0615-40b7-a79c-30b8657e7c9d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45139,DS-5a55c7c1-3b6e-47f3-a826-feab22eac9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-0f31804d-0615-40b7-a79c-30b8657e7c9d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45139,DS-5a55c7c1-3b6e-47f3-a826-feab22eac9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-0f31804d-0615-40b7-a79c-30b8657e7c9d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33548,DS-c1be4c3f-ea27-4741-9351-c3a918dba359,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-1c15abc2-aac8-42f3-8a1a-cd8e612de87f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33548,DS-c1be4c3f-ea27-4741-9351-c3a918dba359,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-1c15abc2-aac8-42f3-8a1a-cd8e612de87f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33548,DS-c1be4c3f-ea27-4741-9351-c3a918dba359,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-1c15abc2-aac8-42f3-8a1a-cd8e612de87f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33548,DS-c1be4c3f-ea27-4741-9351-c3a918dba359,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-1c15abc2-aac8-42f3-8a1a-cd8e612de87f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Append sequenceId=4, requesting roll of WAL
stackTrace: org.apache.hadoop.hbase.regionserver.wal.DamagedWALException: Append sequenceId=4, requesting roll of WAL
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1081)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:964)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:873)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:129)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37406,DS-d4de517f-c50d-4d6b-ade4-49b6fc3a8ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-d96c5a18-9f41-4863-9d4d-c0a7284e7eab,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37433,DS-d96c5a18-9f41-4863-9d4d-c0a7284e7eab,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-d4de517f-c50d-4d6b-ade4-49b6fc3a8ef9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37632,DS-50b7bd04-f147-4ba8-a20b-5cfd35626bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-7504ca7c-c8df-43c4-8eb0-d4087336b769,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37632,DS-50b7bd04-f147-4ba8-a20b-5cfd35626bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-7504ca7c-c8df-43c4-8eb0-d4087336b769,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37632,DS-50b7bd04-f147-4ba8-a20b-5cfd35626bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-7504ca7c-c8df-43c4-8eb0-d4087336b769,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37632,DS-50b7bd04-f147-4ba8-a20b-5cfd35626bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-7504ca7c-c8df-43c4-8eb0-d4087336b769,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39011,DS-29c6fec3-a1a8-40b7-991e-b44aa23ab6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-212d74ee-58c0-48e2-9f34-da697c886e1b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39011,DS-29c6fec3-a1a8-40b7-991e-b44aa23ab6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-212d74ee-58c0-48e2-9f34-da697c886e1b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39011,DS-29c6fec3-a1a8-40b7-991e-b44aa23ab6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-212d74ee-58c0-48e2-9f34-da697c886e1b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39011,DS-29c6fec3-a1a8-40b7-991e-b44aa23ab6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-212d74ee-58c0-48e2-9f34-da697c886e1b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46614,DS-4addc868-42f9-435b-b31e-2ddef8369c38,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-013a28b9-f03c-4f9e-a248-56103b7bb76b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46614,DS-4addc868-42f9-435b-b31e-2ddef8369c38,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-013a28b9-f03c-4f9e-a248-56103b7bb76b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46614,DS-4addc868-42f9-435b-b31e-2ddef8369c38,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-013a28b9-f03c-4f9e-a248-56103b7bb76b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46614,DS-4addc868-42f9-435b-b31e-2ddef8369c38,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-013a28b9-f03c-4f9e-a248-56103b7bb76b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34384,DS-6e7557c3-18fb-4a45-bd8f-97a82b2ae272,DISK], DatanodeInfoWithStorage[127.0.0.1:41173,DS-6bf47349-ff6c-441b-a248-5a0481894a7b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34384,DS-6e7557c3-18fb-4a45-bd8f-97a82b2ae272,DISK], DatanodeInfoWithStorage[127.0.0.1:41173,DS-6bf47349-ff6c-441b-a248-5a0481894a7b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34384,DS-6e7557c3-18fb-4a45-bd8f-97a82b2ae272,DISK], DatanodeInfoWithStorage[127.0.0.1:41173,DS-6bf47349-ff6c-441b-a248-5a0481894a7b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34384,DS-6e7557c3-18fb-4a45-bd8f-97a82b2ae272,DISK], DatanodeInfoWithStorage[127.0.0.1:41173,DS-6bf47349-ff6c-441b-a248-5a0481894a7b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40024,DS-979ca215-944f-4dc5-8876-468275a5d850,DISK], DatanodeInfoWithStorage[127.0.0.1:44997,DS-2ae9535a-344e-4c9a-801a-60f6d8e3177a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44997,DS-2ae9535a-344e-4c9a-801a-60f6d8e3177a,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-979ca215-944f-4dc5-8876-468275a5d850,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40024,DS-979ca215-944f-4dc5-8876-468275a5d850,DISK], DatanodeInfoWithStorage[127.0.0.1:44997,DS-2ae9535a-344e-4c9a-801a-60f6d8e3177a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44997,DS-2ae9535a-344e-4c9a-801a-60f6d8e3177a,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-979ca215-944f-4dc5-8876-468275a5d850,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34788,DS-d173d684-ee9c-4bd6-820d-d3e8c9267e98,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-b6d62f7b-dd41-4893-b977-fe04c1832e31,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34788,DS-d173d684-ee9c-4bd6-820d-d3e8c9267e98,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-b6d62f7b-dd41-4893-b977-fe04c1832e31,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34788,DS-d173d684-ee9c-4bd6-820d-d3e8c9267e98,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-b6d62f7b-dd41-4893-b977-fe04c1832e31,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34788,DS-d173d684-ee9c-4bd6-820d-d3e8c9267e98,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-b6d62f7b-dd41-4893-b977-fe04c1832e31,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43436,DS-0e05fe29-d029-45dc-bedf-1c49b9066581,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-53503940-816a-4642-8ffa-2e8ba10ef0bd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43436,DS-0e05fe29-d029-45dc-bedf-1c49b9066581,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-53503940-816a-4642-8ffa-2e8ba10ef0bd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43436,DS-0e05fe29-d029-45dc-bedf-1c49b9066581,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-53503940-816a-4642-8ffa-2e8ba10ef0bd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43436,DS-0e05fe29-d029-45dc-bedf-1c49b9066581,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-53503940-816a-4642-8ffa-2e8ba10ef0bd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43291,DS-b27a4450-92c3-450d-a748-ae5d8e1fab06,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-35ad6270-d888-4710-87ac-7dbcb60444e5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43291,DS-b27a4450-92c3-450d-a748-ae5d8e1fab06,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-35ad6270-d888-4710-87ac-7dbcb60444e5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43291,DS-b27a4450-92c3-450d-a748-ae5d8e1fab06,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-35ad6270-d888-4710-87ac-7dbcb60444e5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43291,DS-b27a4450-92c3-450d-a748-ae5d8e1fab06,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-35ad6270-d888-4710-87ac-7dbcb60444e5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33670,DS-577114a1-07a9-477a-b173-9933de0bf2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-bfe84e87-224f-4353-b942-c3b8e6799998,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33670,DS-577114a1-07a9-477a-b173-9933de0bf2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-bfe84e87-224f-4353-b942-c3b8e6799998,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33670,DS-577114a1-07a9-477a-b173-9933de0bf2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-bfe84e87-224f-4353-b942-c3b8e6799998,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33670,DS-577114a1-07a9-477a-b173-9933de0bf2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-bfe84e87-224f-4353-b942-c3b8e6799998,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43698,DS-1eda7dbb-0542-41e4-92a0-2e8a5ebb203c,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-6032f09a-205f-40f3-befe-85c5eff66a4b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40377,DS-6032f09a-205f-40f3-befe-85c5eff66a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-1eda7dbb-0542-41e4-92a0-2e8a5ebb203c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43698,DS-1eda7dbb-0542-41e4-92a0-2e8a5ebb203c,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-6032f09a-205f-40f3-befe-85c5eff66a4b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40377,DS-6032f09a-205f-40f3-befe-85c5eff66a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-1eda7dbb-0542-41e4-92a0-2e8a5ebb203c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42004,DS-57e586f5-60a6-4112-9cd5-15fb5b4143db,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-511370e8-efaf-4699-a626-4d5bc78cd504,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42004,DS-57e586f5-60a6-4112-9cd5-15fb5b4143db,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-511370e8-efaf-4699-a626-4d5bc78cd504,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42004,DS-57e586f5-60a6-4112-9cd5-15fb5b4143db,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-511370e8-efaf-4699-a626-4d5bc78cd504,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42004,DS-57e586f5-60a6-4112-9cd5-15fb5b4143db,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-511370e8-efaf-4699-a626-4d5bc78cd504,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36648,DS-f53d8cd9-75f1-4623-91ef-512c07d01270,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-76e90440-e532-4c95-a2fe-1f305b8a80a8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36648,DS-f53d8cd9-75f1-4623-91ef-512c07d01270,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-76e90440-e532-4c95-a2fe-1f305b8a80a8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36648,DS-f53d8cd9-75f1-4623-91ef-512c07d01270,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-76e90440-e532-4c95-a2fe-1f305b8a80a8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36648,DS-f53d8cd9-75f1-4623-91ef-512c07d01270,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-76e90440-e532-4c95-a2fe-1f305b8a80a8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37342,DS-8f0f827a-90c5-43d9-87c7-86a781275608,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-25f6f518-4895-4722-ad25-98dcef82739d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34943,DS-25f6f518-4895-4722-ad25-98dcef82739d,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-8f0f827a-90c5-43d9-87c7-86a781275608,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37342,DS-8f0f827a-90c5-43d9-87c7-86a781275608,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-25f6f518-4895-4722-ad25-98dcef82739d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34943,DS-25f6f518-4895-4722-ad25-98dcef82739d,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-8f0f827a-90c5-43d9-87c7-86a781275608,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41610,DS-c4beaef0-1986-4200-bb2c-c24e91db25af,DISK], DatanodeInfoWithStorage[127.0.0.1:34836,DS-a15f8afc-0c83-4191-aa92-dc92d1d157ea,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41610,DS-c4beaef0-1986-4200-bb2c-c24e91db25af,DISK], DatanodeInfoWithStorage[127.0.0.1:34836,DS-a15f8afc-0c83-4191-aa92-dc92d1d157ea,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41610,DS-c4beaef0-1986-4200-bb2c-c24e91db25af,DISK], DatanodeInfoWithStorage[127.0.0.1:34836,DS-a15f8afc-0c83-4191-aa92-dc92d1d157ea,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41610,DS-c4beaef0-1986-4200-bb2c-c24e91db25af,DISK], DatanodeInfoWithStorage[127.0.0.1:34836,DS-a15f8afc-0c83-4191-aa92-dc92d1d157ea,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32840,DS-1dae9f22-e54b-440c-9af6-a545e3f363f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-d957fcda-1d83-4e4f-80e5-16707aaf8929,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45304,DS-d957fcda-1d83-4e4f-80e5-16707aaf8929,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-1dae9f22-e54b-440c-9af6-a545e3f363f6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32840,DS-1dae9f22-e54b-440c-9af6-a545e3f363f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-d957fcda-1d83-4e4f-80e5-16707aaf8929,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45304,DS-d957fcda-1d83-4e4f-80e5-16707aaf8929,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-1dae9f22-e54b-440c-9af6-a545e3f363f6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39433,DS-acb7a1b4-4896-4973-888b-eba833904646,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-7a987625-871f-458d-b0dc-54a0d51de0cd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39433,DS-acb7a1b4-4896-4973-888b-eba833904646,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-7a987625-871f-458d-b0dc-54a0d51de0cd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39433,DS-acb7a1b4-4896-4973-888b-eba833904646,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-7a987625-871f-458d-b0dc-54a0d51de0cd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39433,DS-acb7a1b4-4896-4973-888b-eba833904646,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-7a987625-871f-458d-b0dc-54a0d51de0cd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37409,DS-fdc103d7-5569-49d1-9ea7-0b18facbf49b,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-2ef251bb-9c1d-4750-b288-58e0ca18f19a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37409,DS-fdc103d7-5569-49d1-9ea7-0b18facbf49b,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-2ef251bb-9c1d-4750-b288-58e0ca18f19a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37409,DS-fdc103d7-5569-49d1-9ea7-0b18facbf49b,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-2ef251bb-9c1d-4750-b288-58e0ca18f19a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37409,DS-fdc103d7-5569-49d1-9ea7-0b18facbf49b,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-2ef251bb-9c1d-4750-b288-58e0ca18f19a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37873,DS-2016661e-cbcf-4aff-9dde-ef18fd9354e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-d7f3f538-3bcb-4ad8-9eab-bbf063fa0e46,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37873,DS-2016661e-cbcf-4aff-9dde-ef18fd9354e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-d7f3f538-3bcb-4ad8-9eab-bbf063fa0e46,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37873,DS-2016661e-cbcf-4aff-9dde-ef18fd9354e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-d7f3f538-3bcb-4ad8-9eab-bbf063fa0e46,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37873,DS-2016661e-cbcf-4aff-9dde-ef18fd9354e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-d7f3f538-3bcb-4ad8-9eab-bbf063fa0e46,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44085,DS-053dd1a3-fc8c-4240-b139-35fef4987ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-09403b15-5cc2-4657-93b0-5a758688ea42,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44085,DS-053dd1a3-fc8c-4240-b139-35fef4987ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-09403b15-5cc2-4657-93b0-5a758688ea42,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44085,DS-053dd1a3-fc8c-4240-b139-35fef4987ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-09403b15-5cc2-4657-93b0-5a758688ea42,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44085,DS-053dd1a3-fc8c-4240-b139-35fef4987ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-09403b15-5cc2-4657-93b0-5a758688ea42,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38472,DS-0693072b-4031-4e4b-9963-2cc2e7672418,DISK], DatanodeInfoWithStorage[127.0.0.1:35323,DS-55e9369e-d449-4a01-abf1-e38f9b9ea568,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38472,DS-0693072b-4031-4e4b-9963-2cc2e7672418,DISK], DatanodeInfoWithStorage[127.0.0.1:35323,DS-55e9369e-d449-4a01-abf1-e38f9b9ea568,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38472,DS-0693072b-4031-4e4b-9963-2cc2e7672418,DISK], DatanodeInfoWithStorage[127.0.0.1:35323,DS-55e9369e-d449-4a01-abf1-e38f9b9ea568,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38472,DS-0693072b-4031-4e4b-9963-2cc2e7672418,DISK], DatanodeInfoWithStorage[127.0.0.1:35323,DS-55e9369e-d449-4a01-abf1-e38f9b9ea568,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42143,DS-e4827f9a-6579-47d2-9e3a-7532ebe1e132,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-e6cf58ea-8f38-4f1d-a5c1-4c2047a57ccb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42143,DS-e4827f9a-6579-47d2-9e3a-7532ebe1e132,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-e6cf58ea-8f38-4f1d-a5c1-4c2047a57ccb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42143,DS-e4827f9a-6579-47d2-9e3a-7532ebe1e132,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-e6cf58ea-8f38-4f1d-a5c1-4c2047a57ccb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42143,DS-e4827f9a-6579-47d2-9e3a-7532ebe1e132,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-e6cf58ea-8f38-4f1d-a5c1-4c2047a57ccb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45493,DS-df4f2938-c882-4d14-9fcb-ec912becab8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-4bbbcd3c-2286-4bbc-93dc-a0b3a1e84e51,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34815,DS-4bbbcd3c-2286-4bbc-93dc-a0b3a1e84e51,DISK], DatanodeInfoWithStorage[127.0.0.1:45493,DS-df4f2938-c882-4d14-9fcb-ec912becab8a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45493,DS-df4f2938-c882-4d14-9fcb-ec912becab8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-4bbbcd3c-2286-4bbc-93dc-a0b3a1e84e51,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34815,DS-4bbbcd3c-2286-4bbc-93dc-a0b3a1e84e51,DISK], DatanodeInfoWithStorage[127.0.0.1:45493,DS-df4f2938-c882-4d14-9fcb-ec912becab8a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35461,DS-af763dc8-ed75-4c23-85dd-98a59ed68702,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-7509eba8-b6a2-45f3-9339-88eed49c3c68,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35461,DS-af763dc8-ed75-4c23-85dd-98a59ed68702,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-7509eba8-b6a2-45f3-9339-88eed49c3c68,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35461,DS-af763dc8-ed75-4c23-85dd-98a59ed68702,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-7509eba8-b6a2-45f3-9339-88eed49c3c68,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35461,DS-af763dc8-ed75-4c23-85dd-98a59ed68702,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-7509eba8-b6a2-45f3-9339-88eed49c3c68,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37283,DS-a9b69c47-902a-4897-9504-00b02f994ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-12b5f171-267c-438a-bf83-fa7927d8c862,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37283,DS-a9b69c47-902a-4897-9504-00b02f994ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-12b5f171-267c-438a-bf83-fa7927d8c862,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37283,DS-a9b69c47-902a-4897-9504-00b02f994ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-12b5f171-267c-438a-bf83-fa7927d8c862,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37283,DS-a9b69c47-902a-4897-9504-00b02f994ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-12b5f171-267c-438a-bf83-fa7927d8c862,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36294,DS-d57b33b4-db90-4129-84d7-7bf4014f8ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-bb6508c1-d05f-483f-b9a0-060300aed7ce,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36294,DS-d57b33b4-db90-4129-84d7-7bf4014f8ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-bb6508c1-d05f-483f-b9a0-060300aed7ce,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36294,DS-d57b33b4-db90-4129-84d7-7bf4014f8ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-bb6508c1-d05f-483f-b9a0-060300aed7ce,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36294,DS-d57b33b4-db90-4129-84d7-7bf4014f8ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-bb6508c1-d05f-483f-b9a0-060300aed7ce,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38044,DS-eaaca2cc-0713-47e2-a870-b1f9908222dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-fe8ada05-02dd-4f61-927a-7259af1903eb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38044,DS-eaaca2cc-0713-47e2-a870-b1f9908222dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-fe8ada05-02dd-4f61-927a-7259af1903eb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38044,DS-eaaca2cc-0713-47e2-a870-b1f9908222dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-fe8ada05-02dd-4f61-927a-7259af1903eb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38044,DS-eaaca2cc-0713-47e2-a870-b1f9908222dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-fe8ada05-02dd-4f61-927a-7259af1903eb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)


v1v2 failed with probability 50 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: might be true error
Total execution time in seconds : 14859
