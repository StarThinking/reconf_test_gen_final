reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43754,DS-e652572e-65bf-4a46-a163-6baf0b343a99,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-ff670b26-e52e-4134-9f5a-f1f5453018c5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37372,DS-ff670b26-e52e-4134-9f5a-f1f5453018c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-e652572e-65bf-4a46-a163-6baf0b343a99,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43754,DS-e652572e-65bf-4a46-a163-6baf0b343a99,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-ff670b26-e52e-4134-9f5a-f1f5453018c5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37372,DS-ff670b26-e52e-4134-9f5a-f1f5453018c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-e652572e-65bf-4a46-a163-6baf0b343a99,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39641,DS-3491c189-2911-4bd7-b9b2-3b3bb5e7bbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-dc3a59ec-78c0-439c-91bf-58ef5eb30453,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39641,DS-3491c189-2911-4bd7-b9b2-3b3bb5e7bbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-dc3a59ec-78c0-439c-91bf-58ef5eb30453,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39641,DS-3491c189-2911-4bd7-b9b2-3b3bb5e7bbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-dc3a59ec-78c0-439c-91bf-58ef5eb30453,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39641,DS-3491c189-2911-4bd7-b9b2-3b3bb5e7bbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-dc3a59ec-78c0-439c-91bf-58ef5eb30453,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36277,DS-50788747-2cc5-4862-9043-c71f20f4ee5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-149e8da5-10c6-49ee-80d5-a1f20beaa1a1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36277,DS-50788747-2cc5-4862-9043-c71f20f4ee5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-149e8da5-10c6-49ee-80d5-a1f20beaa1a1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36277,DS-50788747-2cc5-4862-9043-c71f20f4ee5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-149e8da5-10c6-49ee-80d5-a1f20beaa1a1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36277,DS-50788747-2cc5-4862-9043-c71f20f4ee5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-149e8da5-10c6-49ee-80d5-a1f20beaa1a1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46557,DS-b55ace5b-1ebd-4030-bbd0-a5168fa4ab25,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-22f00c57-083b-456c-ac71-36c3fbe8ce31,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46557,DS-b55ace5b-1ebd-4030-bbd0-a5168fa4ab25,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-22f00c57-083b-456c-ac71-36c3fbe8ce31,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46557,DS-b55ace5b-1ebd-4030-bbd0-a5168fa4ab25,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-22f00c57-083b-456c-ac71-36c3fbe8ce31,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46557,DS-b55ace5b-1ebd-4030-bbd0-a5168fa4ab25,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-22f00c57-083b-456c-ac71-36c3fbe8ce31,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41809,DS-330ca57d-4882-4a42-a0ae-b044a8d8d3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-fd08217b-7436-4022-92e5-1b3f3e320061,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40266,DS-fd08217b-7436-4022-92e5-1b3f3e320061,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-330ca57d-4882-4a42-a0ae-b044a8d8d3ae,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41809,DS-330ca57d-4882-4a42-a0ae-b044a8d8d3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-fd08217b-7436-4022-92e5-1b3f3e320061,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40266,DS-fd08217b-7436-4022-92e5-1b3f3e320061,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-330ca57d-4882-4a42-a0ae-b044a8d8d3ae,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45796,DS-5c76faaf-73a5-4c7a-adcd-4583bddddce3,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-21f25733-7cd5-421d-98da-1f9539cc9a87,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45796,DS-5c76faaf-73a5-4c7a-adcd-4583bddddce3,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-21f25733-7cd5-421d-98da-1f9539cc9a87,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45796,DS-5c76faaf-73a5-4c7a-adcd-4583bddddce3,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-21f25733-7cd5-421d-98da-1f9539cc9a87,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45796,DS-5c76faaf-73a5-4c7a-adcd-4583bddddce3,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-21f25733-7cd5-421d-98da-1f9539cc9a87,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33655,DS-3c80a409-a689-4b05-930e-7627e6033ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-e864eafb-e291-404d-a630-0ad91f6396c2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35554,DS-e864eafb-e291-404d-a630-0ad91f6396c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-3c80a409-a689-4b05-930e-7627e6033ea2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33655,DS-3c80a409-a689-4b05-930e-7627e6033ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-e864eafb-e291-404d-a630-0ad91f6396c2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35554,DS-e864eafb-e291-404d-a630-0ad91f6396c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-3c80a409-a689-4b05-930e-7627e6033ea2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39185,DS-ccc1a001-7fba-49a4-a252-d3143226723b,DISK], DatanodeInfoWithStorage[127.0.0.1:39718,DS-dd81c01a-2136-4deb-9163-75c04aac9015,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39185,DS-ccc1a001-7fba-49a4-a252-d3143226723b,DISK], DatanodeInfoWithStorage[127.0.0.1:39718,DS-dd81c01a-2136-4deb-9163-75c04aac9015,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39185,DS-ccc1a001-7fba-49a4-a252-d3143226723b,DISK], DatanodeInfoWithStorage[127.0.0.1:39718,DS-dd81c01a-2136-4deb-9163-75c04aac9015,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39185,DS-ccc1a001-7fba-49a4-a252-d3143226723b,DISK], DatanodeInfoWithStorage[127.0.0.1:39718,DS-dd81c01a-2136-4deb-9163-75c04aac9015,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42068,DS-33bd6ae6-4e34-4e3d-a894-4736a424f220,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-83840f0f-db6b-447e-9fb9-ed00e6031397,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36805,DS-83840f0f-db6b-447e-9fb9-ed00e6031397,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-33bd6ae6-4e34-4e3d-a894-4736a424f220,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42068,DS-33bd6ae6-4e34-4e3d-a894-4736a424f220,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-83840f0f-db6b-447e-9fb9-ed00e6031397,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36805,DS-83840f0f-db6b-447e-9fb9-ed00e6031397,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-33bd6ae6-4e34-4e3d-a894-4736a424f220,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40721,DS-c9963000-dbff-46e9-b7dc-eabe0681ad0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-69e2bb37-b3bf-4ec3-b8bb-904ab376f86c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40721,DS-c9963000-dbff-46e9-b7dc-eabe0681ad0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-69e2bb37-b3bf-4ec3-b8bb-904ab376f86c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40721,DS-c9963000-dbff-46e9-b7dc-eabe0681ad0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-69e2bb37-b3bf-4ec3-b8bb-904ab376f86c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40721,DS-c9963000-dbff-46e9-b7dc-eabe0681ad0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-69e2bb37-b3bf-4ec3-b8bb-904ab376f86c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 2642
