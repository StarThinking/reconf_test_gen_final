reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 600
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testPointInTimeSnapshotCopiesForOpenFiles
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 600
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testPointInTimeSnapshotCopiesForOpenFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37942,DS-b6ee18af-0288-420b-9a0d-35058f1cfc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-da0e841d-a471-47b5-ba89-3916e7ab0024,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37942,DS-b6ee18af-0288-420b-9a0d-35058f1cfc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-da0e841d-a471-47b5-ba89-3916e7ab0024,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37942,DS-b6ee18af-0288-420b-9a0d-35058f1cfc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-da0e841d-a471-47b5-ba89-3916e7ab0024,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37942,DS-b6ee18af-0288-420b-9a0d-35058f1cfc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-da0e841d-a471-47b5-ba89-3916e7ab0024,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 600
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testPointInTimeSnapshotCopiesForOpenFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42153,DS-3a968b27-f953-4908-8a6a-89acd5d0bfe5,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-c538097d-88d6-4a0b-9412-136b16ffa6cb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42153,DS-3a968b27-f953-4908-8a6a-89acd5d0bfe5,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-c538097d-88d6-4a0b-9412-136b16ffa6cb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42153,DS-3a968b27-f953-4908-8a6a-89acd5d0bfe5,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-c538097d-88d6-4a0b-9412-136b16ffa6cb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42153,DS-3a968b27-f953-4908-8a6a-89acd5d0bfe5,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-c538097d-88d6-4a0b-9412-136b16ffa6cb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 600
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testPointInTimeSnapshotCopiesForOpenFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43805,DS-246cb659-1e5a-462d-8e46-e1783b4112fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-a3af5f6c-325c-460a-b324-27ceb5111b26,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43805,DS-246cb659-1e5a-462d-8e46-e1783b4112fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-a3af5f6c-325c-460a-b324-27ceb5111b26,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43805,DS-246cb659-1e5a-462d-8e46-e1783b4112fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-a3af5f6c-325c-460a-b324-27ceb5111b26,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43805,DS-246cb659-1e5a-462d-8e46-e1783b4112fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-a3af5f6c-325c-460a-b324-27ceb5111b26,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 600
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testPointInTimeSnapshotCopiesForOpenFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37138,DS-51c34d36-1392-419c-af9c-d54538773ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-3d90d1b5-558f-4a92-8fba-7c6863d71bbe,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37138,DS-51c34d36-1392-419c-af9c-d54538773ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-3d90d1b5-558f-4a92-8fba-7c6863d71bbe,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37138,DS-51c34d36-1392-419c-af9c-d54538773ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-3d90d1b5-558f-4a92-8fba-7c6863d71bbe,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37138,DS-51c34d36-1392-419c-af9c-d54538773ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-3d90d1b5-558f-4a92-8fba-7c6863d71bbe,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 600
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testPointInTimeSnapshotCopiesForOpenFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43410,DS-36a9ce4a-1d37-4bdb-a62f-9625c7e770b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-4ebbb47b-5717-40ad-a4a5-cc75c9a890a9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43410,DS-36a9ce4a-1d37-4bdb-a62f-9625c7e770b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-4ebbb47b-5717-40ad-a4a5-cc75c9a890a9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43410,DS-36a9ce4a-1d37-4bdb-a62f-9625c7e770b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-4ebbb47b-5717-40ad-a4a5-cc75c9a890a9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43410,DS-36a9ce4a-1d37-4bdb-a62f-9625c7e770b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-4ebbb47b-5717-40ad-a4a5-cc75c9a890a9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 600
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testPointInTimeSnapshotCopiesForOpenFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43714,DS-950ab060-3763-4e80-896f-12d5e9b924b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-6669986c-60c8-45fa-8220-cca5500f3371,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43714,DS-950ab060-3763-4e80-896f-12d5e9b924b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-6669986c-60c8-45fa-8220-cca5500f3371,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43714,DS-950ab060-3763-4e80-896f-12d5e9b924b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-6669986c-60c8-45fa-8220-cca5500f3371,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43714,DS-950ab060-3763-4e80-896f-12d5e9b924b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-6669986c-60c8-45fa-8220-cca5500f3371,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 600
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testPointInTimeSnapshotCopiesForOpenFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36083,DS-c7aee077-df18-4778-b7a8-d47ae6aacd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-00425863-37e2-4dec-b12a-8cc19aafb558,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36083,DS-c7aee077-df18-4778-b7a8-d47ae6aacd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-00425863-37e2-4dec-b12a-8cc19aafb558,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36083,DS-c7aee077-df18-4778-b7a8-d47ae6aacd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-00425863-37e2-4dec-b12a-8cc19aafb558,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36083,DS-c7aee077-df18-4778-b7a8-d47ae6aacd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-00425863-37e2-4dec-b12a-8cc19aafb558,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 600
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testPointInTimeSnapshotCopiesForOpenFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35265,DS-cca0c990-76f2-4322-824a-45e4f033dc76,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-4a259b70-bdd8-49fc-a7b8-43044738211f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35265,DS-cca0c990-76f2-4322-824a-45e4f033dc76,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-4a259b70-bdd8-49fc-a7b8-43044738211f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35265,DS-cca0c990-76f2-4322-824a-45e4f033dc76,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-4a259b70-bdd8-49fc-a7b8-43044738211f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35265,DS-cca0c990-76f2-4322-824a-45e4f033dc76,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-4a259b70-bdd8-49fc-a7b8-43044738211f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 600
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testPointInTimeSnapshotCopiesForOpenFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34778,DS-5309d66b-ec64-47ab-9e67-39ae68f4e2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-5d971bc4-3ae2-4aeb-84ba-762c03c94ea4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34778,DS-5309d66b-ec64-47ab-9e67-39ae68f4e2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-5d971bc4-3ae2-4aeb-84ba-762c03c94ea4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34778,DS-5309d66b-ec64-47ab-9e67-39ae68f4e2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-5d971bc4-3ae2-4aeb-84ba-762c03c94ea4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34778,DS-5309d66b-ec64-47ab-9e67-39ae68f4e2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-5d971bc4-3ae2-4aeb-84ba-762c03c94ea4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 600
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testPointInTimeSnapshotCopiesForOpenFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46221,DS-506c5bf2-8a48-4672-a2a3-6dd065dc5c19,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-89cf1856-b62b-49f7-91cd-2f423424303b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46221,DS-506c5bf2-8a48-4672-a2a3-6dd065dc5c19,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-89cf1856-b62b-49f7-91cd-2f423424303b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46221,DS-506c5bf2-8a48-4672-a2a3-6dd065dc5c19,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-89cf1856-b62b-49f7-91cd-2f423424303b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46221,DS-506c5bf2-8a48-4672-a2a3-6dd065dc5c19,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-89cf1856-b62b-49f7-91cd-2f423424303b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 27
v1v1v2v2 failed with probability 0 out of 27
result: might be true error
Total execution time in seconds : 2008
