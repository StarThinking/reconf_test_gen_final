reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42384,DS-cc88bf3b-493c-47a8-ac67-63efdc9b53bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-9f1cca8f-b606-443a-b286-9b23a0f15c85,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42384,DS-cc88bf3b-493c-47a8-ac67-63efdc9b53bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-9f1cca8f-b606-443a-b286-9b23a0f15c85,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42384,DS-cc88bf3b-493c-47a8-ac67-63efdc9b53bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-9f1cca8f-b606-443a-b286-9b23a0f15c85,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42384,DS-cc88bf3b-493c-47a8-ac67-63efdc9b53bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-9f1cca8f-b606-443a-b286-9b23a0f15c85,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37878,DS-265fc30a-1ea3-4e9f-ac80-3c70f6fa7ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-1cbd9f31-ba30-4a06-b572-1a7d0df9e21c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37878,DS-265fc30a-1ea3-4e9f-ac80-3c70f6fa7ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-1cbd9f31-ba30-4a06-b572-1a7d0df9e21c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37878,DS-265fc30a-1ea3-4e9f-ac80-3c70f6fa7ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-1cbd9f31-ba30-4a06-b572-1a7d0df9e21c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37878,DS-265fc30a-1ea3-4e9f-ac80-3c70f6fa7ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-1cbd9f31-ba30-4a06-b572-1a7d0df9e21c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38235,DS-dd3b45d9-24b9-4044-9a8b-c45896a5c098,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-90eb3d82-a9c4-4b32-871f-7d66b150e24d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38235,DS-dd3b45d9-24b9-4044-9a8b-c45896a5c098,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-90eb3d82-a9c4-4b32-871f-7d66b150e24d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38235,DS-dd3b45d9-24b9-4044-9a8b-c45896a5c098,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-90eb3d82-a9c4-4b32-871f-7d66b150e24d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38235,DS-dd3b45d9-24b9-4044-9a8b-c45896a5c098,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-90eb3d82-a9c4-4b32-871f-7d66b150e24d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45143,DS-39d8eaec-46a2-4f41-8f93-1bf3940a196d,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-b82213fd-7ea5-48ae-86ec-e5854893e602,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37580,DS-b82213fd-7ea5-48ae-86ec-e5854893e602,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-39d8eaec-46a2-4f41-8f93-1bf3940a196d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45143,DS-39d8eaec-46a2-4f41-8f93-1bf3940a196d,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-b82213fd-7ea5-48ae-86ec-e5854893e602,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37580,DS-b82213fd-7ea5-48ae-86ec-e5854893e602,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-39d8eaec-46a2-4f41-8f93-1bf3940a196d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39332,DS-ded56bd4-7ed5-4f81-8a96-336b5558196e,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-a12a5837-254e-4d04-a999-a83dca4bd7a3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33770,DS-a12a5837-254e-4d04-a999-a83dca4bd7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39332,DS-ded56bd4-7ed5-4f81-8a96-336b5558196e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39332,DS-ded56bd4-7ed5-4f81-8a96-336b5558196e,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-a12a5837-254e-4d04-a999-a83dca4bd7a3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33770,DS-a12a5837-254e-4d04-a999-a83dca4bd7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39332,DS-ded56bd4-7ed5-4f81-8a96-336b5558196e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46882,DS-dc933e28-a6a8-4e40-bc0e-b8883784d00f,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-0074ea30-47f7-4dec-961d-efd1d43b0640,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46882,DS-dc933e28-a6a8-4e40-bc0e-b8883784d00f,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-0074ea30-47f7-4dec-961d-efd1d43b0640,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46882,DS-dc933e28-a6a8-4e40-bc0e-b8883784d00f,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-0074ea30-47f7-4dec-961d-efd1d43b0640,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46882,DS-dc933e28-a6a8-4e40-bc0e-b8883784d00f,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-0074ea30-47f7-4dec-961d-efd1d43b0640,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32797,DS-b1f191ca-16d3-41a9-ae13-c07d57068cca,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-91ccbd60-035b-4568-89db-0efbd79be331,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32797,DS-b1f191ca-16d3-41a9-ae13-c07d57068cca,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-91ccbd60-035b-4568-89db-0efbd79be331,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32797,DS-b1f191ca-16d3-41a9-ae13-c07d57068cca,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-91ccbd60-035b-4568-89db-0efbd79be331,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32797,DS-b1f191ca-16d3-41a9-ae13-c07d57068cca,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-91ccbd60-035b-4568-89db-0efbd79be331,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46698,DS-1016d252-8986-44f7-ba8e-758e8dbb9876,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-85ada5e6-455a-4723-886d-10b653e4b53c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46698,DS-1016d252-8986-44f7-ba8e-758e8dbb9876,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-85ada5e6-455a-4723-886d-10b653e4b53c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46698,DS-1016d252-8986-44f7-ba8e-758e8dbb9876,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-85ada5e6-455a-4723-886d-10b653e4b53c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46698,DS-1016d252-8986-44f7-ba8e-758e8dbb9876,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-85ada5e6-455a-4723-886d-10b653e4b53c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39505,DS-9044c1b9-3b60-47d2-9bee-106a32a56cac,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-41a84082-c949-4715-83b6-ed073d3794a6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39505,DS-9044c1b9-3b60-47d2-9bee-106a32a56cac,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-41a84082-c949-4715-83b6-ed073d3794a6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39505,DS-9044c1b9-3b60-47d2-9bee-106a32a56cac,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-41a84082-c949-4715-83b6-ed073d3794a6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39505,DS-9044c1b9-3b60-47d2-9bee-106a32a56cac,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-41a84082-c949-4715-83b6-ed073d3794a6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:NameNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36791,DS-759546e3-4a7d-4719-8560-f876a279fcaa,DISK], DatanodeInfoWithStorage[127.0.0.1:44154,DS-4f58723b-178e-4cb7-8b2d-4d417070c0ca,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44154,DS-4f58723b-178e-4cb7-8b2d-4d417070c0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36791,DS-759546e3-4a7d-4719-8560-f876a279fcaa,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36791,DS-759546e3-4a7d-4719-8560-f876a279fcaa,DISK], DatanodeInfoWithStorage[127.0.0.1:44154,DS-4f58723b-178e-4cb7-8b2d-4d417070c0ca,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44154,DS-4f58723b-178e-4cb7-8b2d-4d417070c0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36791,DS-759546e3-4a7d-4719-8560-f876a279fcaa,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 12
v1v1v2v2 failed with probability 0 out of 12
result: might be true error
Total execution time in seconds : 855
