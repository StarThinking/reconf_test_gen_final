reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-693166978-172.17.0.2-1595851924645:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34867,DS-921b2fe5-ffb9-43a0-a54d-62bf6d2f40d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-fdd92f7a-1725-4518-ac5d-152f4c91168a,DISK], DatanodeInfoWithStorage[127.0.0.1:38419,DS-60a6bd17-a54a-4e91-9aa6-e175f119dafb,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-4f9e14ac-c13d-4157-bb5a-d64bd82f0dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-88c67f63-f72a-47f8-bc33-f77237f8aec8,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-060d631b-9b89-4de6-bb3d-d944ff5470bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-8291e574-b3b4-4a41-afdc-38bbf55bcbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-3f114790-e6bf-468d-8512-7910ac066b85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-693166978-172.17.0.2-1595851924645:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34867,DS-921b2fe5-ffb9-43a0-a54d-62bf6d2f40d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-fdd92f7a-1725-4518-ac5d-152f4c91168a,DISK], DatanodeInfoWithStorage[127.0.0.1:38419,DS-60a6bd17-a54a-4e91-9aa6-e175f119dafb,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-4f9e14ac-c13d-4157-bb5a-d64bd82f0dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-88c67f63-f72a-47f8-bc33-f77237f8aec8,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-060d631b-9b89-4de6-bb3d-d944ff5470bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-8291e574-b3b4-4a41-afdc-38bbf55bcbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-3f114790-e6bf-468d-8512-7910ac066b85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1172090846-172.17.0.2-1595852345453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39962,DS-fc175176-f7d3-4a73-89e8-0e9395fbbf41,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-79612557-5026-4402-9bfe-669717f35a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-81758303-6fb5-463b-a856-eafb6546fbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-28bf814d-1f6d-4f74-aa4f-cd49b8169722,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-c99c3dc7-1e56-4e52-82f5-bd59bd5e7014,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-f93c83f9-8943-4af0-89e4-eabf3daf3bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-bf2768b0-b85f-4fd6-a9ce-92c6b028d84a,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-287a3ad1-c50d-4c96-9766-2aaab46b20f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1172090846-172.17.0.2-1595852345453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39962,DS-fc175176-f7d3-4a73-89e8-0e9395fbbf41,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-79612557-5026-4402-9bfe-669717f35a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-81758303-6fb5-463b-a856-eafb6546fbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-28bf814d-1f6d-4f74-aa4f-cd49b8169722,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-c99c3dc7-1e56-4e52-82f5-bd59bd5e7014,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-f93c83f9-8943-4af0-89e4-eabf3daf3bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-bf2768b0-b85f-4fd6-a9ce-92c6b028d84a,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-287a3ad1-c50d-4c96-9766-2aaab46b20f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-724874337-172.17.0.2-1595852386600:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35908,DS-2ac2f8d0-4a04-40c9-8c76-0dfc30e7490b,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-04bfd947-4201-461d-8582-6a1fbd348a30,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-81ca0d2e-8f70-4e88-a2b9-57246481a211,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-b7504425-a484-4534-b400-7af87b616013,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-6be48af4-fe35-48c6-a66f-2e10c2dde48f,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-5a381ad7-3c9e-4378-8b79-293835e5e50b,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-34543138-6887-4b5f-9a9a-b461b366ad7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-167527af-94e3-4160-af23-55ecda3e88b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-724874337-172.17.0.2-1595852386600:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35908,DS-2ac2f8d0-4a04-40c9-8c76-0dfc30e7490b,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-04bfd947-4201-461d-8582-6a1fbd348a30,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-81ca0d2e-8f70-4e88-a2b9-57246481a211,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-b7504425-a484-4534-b400-7af87b616013,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-6be48af4-fe35-48c6-a66f-2e10c2dde48f,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-5a381ad7-3c9e-4378-8b79-293835e5e50b,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-34543138-6887-4b5f-9a9a-b461b366ad7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-167527af-94e3-4160-af23-55ecda3e88b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1047155863-172.17.0.2-1595852773382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45724,DS-dbdcfa22-db54-462b-97bd-bce050465eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-28cc9556-09a5-4293-aeb7-e83b93bcfc92,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-53cd2fc1-da48-4398-b928-b00c56ee9a54,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-4dab4c51-376e-4eb5-84d9-647b1001462a,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-578c4ebb-e496-4383-a490-fc29864f099a,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-59693092-2405-4591-99eb-2898a3d81794,DISK], DatanodeInfoWithStorage[127.0.0.1:40229,DS-5b509b6a-7816-431b-bdc9-eaa491145d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-3452f33a-d769-42ba-a51a-5b3f12e85551,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1047155863-172.17.0.2-1595852773382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45724,DS-dbdcfa22-db54-462b-97bd-bce050465eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-28cc9556-09a5-4293-aeb7-e83b93bcfc92,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-53cd2fc1-da48-4398-b928-b00c56ee9a54,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-4dab4c51-376e-4eb5-84d9-647b1001462a,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-578c4ebb-e496-4383-a490-fc29864f099a,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-59693092-2405-4591-99eb-2898a3d81794,DISK], DatanodeInfoWithStorage[127.0.0.1:40229,DS-5b509b6a-7816-431b-bdc9-eaa491145d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-3452f33a-d769-42ba-a51a-5b3f12e85551,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1945572569-172.17.0.2-1595853228179:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45983,DS-eb896042-7413-413a-b04f-1071089faf5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-a389f061-5885-4fc5-92d2-b194bb38436c,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-5ce25bba-ed82-4c67-b3ac-bb2a31b6f814,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-0ca88dd4-9f28-4d87-85da-00f2b8e8c9df,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-a5c6c00f-78e4-4534-ba1f-e7c50d1cc168,DISK], DatanodeInfoWithStorage[127.0.0.1:45561,DS-b4165d03-c8bb-4bce-bcff-777eca27bbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-45676387-03df-468f-9da7-a9742d13ab66,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-eda6e603-6f87-4985-942e-83cb7823c25d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1945572569-172.17.0.2-1595853228179:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45983,DS-eb896042-7413-413a-b04f-1071089faf5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-a389f061-5885-4fc5-92d2-b194bb38436c,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-5ce25bba-ed82-4c67-b3ac-bb2a31b6f814,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-0ca88dd4-9f28-4d87-85da-00f2b8e8c9df,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-a5c6c00f-78e4-4534-ba1f-e7c50d1cc168,DISK], DatanodeInfoWithStorage[127.0.0.1:45561,DS-b4165d03-c8bb-4bce-bcff-777eca27bbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-45676387-03df-468f-9da7-a9742d13ab66,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-eda6e603-6f87-4985-942e-83cb7823c25d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1318576030-172.17.0.2-1595853759079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40674,DS-da48582e-3ddb-4e88-b77d-fe5824d4d1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-e7054a8d-3df8-40ab-b7ff-0c527a7c226f,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-77fa6858-acb2-4175-b3cc-1b70763c4372,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-3d27e1dd-9677-4e6a-bfe2-4742732948aa,DISK], DatanodeInfoWithStorage[127.0.0.1:32924,DS-c5e20d23-606e-438d-822e-9a7261222af1,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-a5cd7540-5f94-41f9-8c9c-721272974535,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-1fcf6d17-a195-4210-9437-59a251073162,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-c718e9da-788d-436f-a89d-7ee5d93fe694,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1318576030-172.17.0.2-1595853759079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40674,DS-da48582e-3ddb-4e88-b77d-fe5824d4d1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-e7054a8d-3df8-40ab-b7ff-0c527a7c226f,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-77fa6858-acb2-4175-b3cc-1b70763c4372,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-3d27e1dd-9677-4e6a-bfe2-4742732948aa,DISK], DatanodeInfoWithStorage[127.0.0.1:32924,DS-c5e20d23-606e-438d-822e-9a7261222af1,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-a5cd7540-5f94-41f9-8c9c-721272974535,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-1fcf6d17-a195-4210-9437-59a251073162,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-c718e9da-788d-436f-a89d-7ee5d93fe694,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-304904307-172.17.0.2-1595853796149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33856,DS-9403949e-f667-4d9b-89e4-d3d136cf07a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-7cf9c72b-3ddf-44e5-bbb7-d44f2b74b1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-835b6d96-f119-43a8-bf47-5172c8fa626d,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-29656cbc-3625-4e52-993f-715c29c2456d,DISK], DatanodeInfoWithStorage[127.0.0.1:46003,DS-b7db5350-8aa6-4634-a2aa-004898f70b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-0fc79fc1-f27b-4a80-8834-9a22ba40399d,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-f470e46b-d689-4467-870b-437dc2bf57af,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-0c2f3425-d963-4eb9-9eb6-6eaa40145f84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-304904307-172.17.0.2-1595853796149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33856,DS-9403949e-f667-4d9b-89e4-d3d136cf07a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-7cf9c72b-3ddf-44e5-bbb7-d44f2b74b1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-835b6d96-f119-43a8-bf47-5172c8fa626d,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-29656cbc-3625-4e52-993f-715c29c2456d,DISK], DatanodeInfoWithStorage[127.0.0.1:46003,DS-b7db5350-8aa6-4634-a2aa-004898f70b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-0fc79fc1-f27b-4a80-8834-9a22ba40399d,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-f470e46b-d689-4467-870b-437dc2bf57af,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-0c2f3425-d963-4eb9-9eb6-6eaa40145f84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-123312164-172.17.0.2-1595853827808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33300,DS-47bfac5a-f4f1-4fda-9898-b06a88c599af,DISK], DatanodeInfoWithStorage[127.0.0.1:34245,DS-4acc3ce1-cf46-4f04-b38d-d7f700f39ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-f916c9ad-ad3f-4fe1-8720-24d3816eba13,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-2fc57c30-c6fe-4041-991e-848ff68fe2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-d4da28e7-fa49-4d58-a413-509dfb2c7cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-8a79bb5a-773b-46e8-b33e-7de217cccc60,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-2e4fccb9-f275-466d-a556-1e384d5d72b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-dfff6e23-e7c3-4d39-be80-ee4ab4475d68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-123312164-172.17.0.2-1595853827808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33300,DS-47bfac5a-f4f1-4fda-9898-b06a88c599af,DISK], DatanodeInfoWithStorage[127.0.0.1:34245,DS-4acc3ce1-cf46-4f04-b38d-d7f700f39ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-f916c9ad-ad3f-4fe1-8720-24d3816eba13,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-2fc57c30-c6fe-4041-991e-848ff68fe2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-d4da28e7-fa49-4d58-a413-509dfb2c7cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-8a79bb5a-773b-46e8-b33e-7de217cccc60,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-2e4fccb9-f275-466d-a556-1e384d5d72b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-dfff6e23-e7c3-4d39-be80-ee4ab4475d68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1262029644-172.17.0.2-1595854841792:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45384,DS-2bda063a-b71a-4f3b-8bdb-dace5000b62e,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-0349316e-2c0c-4e0e-982f-275352b4e8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-ec053bef-a5f0-4d56-941b-334fb677ab1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-f5b1fead-a2dc-474d-be1e-a94b6eb5c282,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-abe74e5c-ccc9-4a16-bbe9-0d96a85c3d47,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-5d3c5304-9f40-433f-b9d1-0f6b0e6e6f18,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-13e19939-0745-4a9c-ba30-1bc4a68cadbb,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-e9a3d40a-18cb-4845-a8d0-f9e1942ff3e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1262029644-172.17.0.2-1595854841792:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45384,DS-2bda063a-b71a-4f3b-8bdb-dace5000b62e,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-0349316e-2c0c-4e0e-982f-275352b4e8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-ec053bef-a5f0-4d56-941b-334fb677ab1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-f5b1fead-a2dc-474d-be1e-a94b6eb5c282,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-abe74e5c-ccc9-4a16-bbe9-0d96a85c3d47,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-5d3c5304-9f40-433f-b9d1-0f6b0e6e6f18,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-13e19939-0745-4a9c-ba30-1bc4a68cadbb,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-e9a3d40a-18cb-4845-a8d0-f9e1942ff3e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2072598903-172.17.0.2-1595854914909:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40791,DS-350ea85c-c39b-49c8-8c2e-d22c205a4983,DISK], DatanodeInfoWithStorage[127.0.0.1:35414,DS-190757a6-db70-45c1-96eb-d7c34ac34b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36410,DS-66658e30-0410-4bcd-84a0-8d9e87c261f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-34d0694d-6300-4034-a843-9b2ed148e86a,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-4b1211e4-58b3-45a2-b4a6-35a84fdd6334,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-a419cce7-55e7-411e-adf1-9d9bddcd3759,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-e5b71ad8-8034-47d7-8253-02f52d5c7008,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-7f3a1877-d342-43ff-ab36-6ff2ef29b6e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2072598903-172.17.0.2-1595854914909:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40791,DS-350ea85c-c39b-49c8-8c2e-d22c205a4983,DISK], DatanodeInfoWithStorage[127.0.0.1:35414,DS-190757a6-db70-45c1-96eb-d7c34ac34b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36410,DS-66658e30-0410-4bcd-84a0-8d9e87c261f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-34d0694d-6300-4034-a843-9b2ed148e86a,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-4b1211e4-58b3-45a2-b4a6-35a84fdd6334,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-a419cce7-55e7-411e-adf1-9d9bddcd3759,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-e5b71ad8-8034-47d7-8253-02f52d5c7008,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-7f3a1877-d342-43ff-ab36-6ff2ef29b6e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-439514092-172.17.0.2-1595855455104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43742,DS-326977ff-32f6-4149-9f66-1eb3139df465,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-96335726-afa2-4a89-8c0b-2dccae784593,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-8e7639aa-b0e9-40f5-8af2-40514625884e,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-686a94e0-c398-4e2a-97f5-f39116c2e154,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-59f0e6c5-3e84-4131-86de-04605705b69f,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-e090ebb9-eb6f-47da-adab-eaf766a59cca,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-151e8146-ee36-4e02-bb44-e6b50b9cdc84,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-45a73d8f-297f-4e03-83e9-9759721acc12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-439514092-172.17.0.2-1595855455104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43742,DS-326977ff-32f6-4149-9f66-1eb3139df465,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-96335726-afa2-4a89-8c0b-2dccae784593,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-8e7639aa-b0e9-40f5-8af2-40514625884e,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-686a94e0-c398-4e2a-97f5-f39116c2e154,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-59f0e6c5-3e84-4131-86de-04605705b69f,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-e090ebb9-eb6f-47da-adab-eaf766a59cca,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-151e8146-ee36-4e02-bb44-e6b50b9cdc84,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-45a73d8f-297f-4e03-83e9-9759721acc12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-472944024-172.17.0.2-1595856054330:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33258,DS-8a1c422d-023a-4c36-8f18-d6e286bcf047,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-c789d3a6-5680-4d2b-b6a7-ee4bacda010c,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-747eb1d2-5ce1-4ccc-90ec-49a7c91e9dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39818,DS-737285ab-6ca5-4f5f-bfc7-bf55ad542102,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-05efb4e1-775a-4083-96dc-3d939da50919,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-f601b2b2-5d3b-47ce-966f-48c18d18f26e,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-2b2478e1-e79a-40af-999c-ad8f0b1675dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-91445d86-2680-4874-b050-1b2701a15d6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-472944024-172.17.0.2-1595856054330:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33258,DS-8a1c422d-023a-4c36-8f18-d6e286bcf047,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-c789d3a6-5680-4d2b-b6a7-ee4bacda010c,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-747eb1d2-5ce1-4ccc-90ec-49a7c91e9dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39818,DS-737285ab-6ca5-4f5f-bfc7-bf55ad542102,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-05efb4e1-775a-4083-96dc-3d939da50919,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-f601b2b2-5d3b-47ce-966f-48c18d18f26e,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-2b2478e1-e79a-40af-999c-ad8f0b1675dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-91445d86-2680-4874-b050-1b2701a15d6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-540551460-172.17.0.2-1595856134010:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35364,DS-b3ff48ea-470a-41c1-a300-be18bed6df14,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-2a2fa2d6-dcca-4248-95cc-94f8cc0dd320,DISK], DatanodeInfoWithStorage[127.0.0.1:40472,DS-b4754c54-3bba-4d6a-bef9-0a92599dc2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-53bcb60d-b768-4ed7-be27-3572f2727d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-26f31be7-543d-4f8f-913c-0633739324bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-11e91a80-7509-4de6-ada7-42aeb2aab9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-bf011706-a536-40cf-a6c0-3199f7d56360,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-a761c679-9dfc-46cc-8e9a-815c983eeb23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-540551460-172.17.0.2-1595856134010:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35364,DS-b3ff48ea-470a-41c1-a300-be18bed6df14,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-2a2fa2d6-dcca-4248-95cc-94f8cc0dd320,DISK], DatanodeInfoWithStorage[127.0.0.1:40472,DS-b4754c54-3bba-4d6a-bef9-0a92599dc2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-53bcb60d-b768-4ed7-be27-3572f2727d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-26f31be7-543d-4f8f-913c-0633739324bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-11e91a80-7509-4de6-ada7-42aeb2aab9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-bf011706-a536-40cf-a6c0-3199f7d56360,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-a761c679-9dfc-46cc-8e9a-815c983eeb23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1846606325-172.17.0.2-1595856539481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35875,DS-93fdd041-6b7c-480f-ab25-97cf291d8896,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-79793fb0-6a3d-4236-a7f1-11acfaf42a41,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-af027cf9-72cd-4d86-bc07-3253c230d6df,DISK], DatanodeInfoWithStorage[127.0.0.1:33913,DS-82b01026-1473-42e6-bb9f-26537067a906,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-3d3188c8-f259-4bd2-a9e1-52319783a90f,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-dd31fa24-cf49-48df-92c9-c5a0d5a03417,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-a7147dee-3a0e-4f4f-9a78-e8428e2f0092,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-199e3303-7394-403a-b19c-2f0969d937e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1846606325-172.17.0.2-1595856539481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35875,DS-93fdd041-6b7c-480f-ab25-97cf291d8896,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-79793fb0-6a3d-4236-a7f1-11acfaf42a41,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-af027cf9-72cd-4d86-bc07-3253c230d6df,DISK], DatanodeInfoWithStorage[127.0.0.1:33913,DS-82b01026-1473-42e6-bb9f-26537067a906,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-3d3188c8-f259-4bd2-a9e1-52319783a90f,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-dd31fa24-cf49-48df-92c9-c5a0d5a03417,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-a7147dee-3a0e-4f4f-9a78-e8428e2f0092,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-199e3303-7394-403a-b19c-2f0969d937e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-203531467-172.17.0.2-1595856744988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42088,DS-d4376b1a-ad28-4cbb-a9f0-e1be841d4844,DISK], DatanodeInfoWithStorage[127.0.0.1:43981,DS-dd125998-70d5-4dd5-b585-5c97ab2bcb26,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-72676af7-8ada-42fc-bc12-2e2c4d4e3b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-415c72f5-4bef-4535-83d1-fa36b73a1f35,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-38ef8bb0-b2fe-4dd9-8264-0e8972be5bff,DISK], DatanodeInfoWithStorage[127.0.0.1:38554,DS-792e24e3-3879-4b1b-900b-dc04ea6fc9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46297,DS-b1735fc7-137d-4f55-b801-62d95cdd7925,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-8bf47e2c-f890-41b3-b528-9171f2c68ed9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-203531467-172.17.0.2-1595856744988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42088,DS-d4376b1a-ad28-4cbb-a9f0-e1be841d4844,DISK], DatanodeInfoWithStorage[127.0.0.1:43981,DS-dd125998-70d5-4dd5-b585-5c97ab2bcb26,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-72676af7-8ada-42fc-bc12-2e2c4d4e3b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-415c72f5-4bef-4535-83d1-fa36b73a1f35,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-38ef8bb0-b2fe-4dd9-8264-0e8972be5bff,DISK], DatanodeInfoWithStorage[127.0.0.1:38554,DS-792e24e3-3879-4b1b-900b-dc04ea6fc9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46297,DS-b1735fc7-137d-4f55-b801-62d95cdd7925,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-8bf47e2c-f890-41b3-b528-9171f2c68ed9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: might be true error
Total execution time in seconds : 5448
