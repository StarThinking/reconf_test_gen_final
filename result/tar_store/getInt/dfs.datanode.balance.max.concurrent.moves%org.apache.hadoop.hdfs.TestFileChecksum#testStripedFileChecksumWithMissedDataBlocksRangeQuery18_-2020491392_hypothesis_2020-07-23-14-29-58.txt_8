reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1283940954-172.17.0.7-1595514756321:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34491,DS-cce50f86-dcff-4141-8024-0c780c7681e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46559,DS-f41c8036-7b79-4076-93a9-789bc4977cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-5d046aaf-fe25-4e2a-9e66-14f8eb2acb55,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-812d9d8e-701a-484e-b8cb-9b1c7a47deab,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-3b52dac3-c54c-4f6d-b294-af6c5a4f5dab,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-b84acec5-d0fe-4af1-80d4-fe1de1d43516,DISK], DatanodeInfoWithStorage[127.0.0.1:35995,DS-1234e085-c94b-422f-816d-39f0b1b80f93,DISK], DatanodeInfoWithStorage[127.0.0.1:45532,DS-989d29db-8eb3-4122-94e2-68cdfc56b225,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1283940954-172.17.0.7-1595514756321:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34491,DS-cce50f86-dcff-4141-8024-0c780c7681e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46559,DS-f41c8036-7b79-4076-93a9-789bc4977cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-5d046aaf-fe25-4e2a-9e66-14f8eb2acb55,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-812d9d8e-701a-484e-b8cb-9b1c7a47deab,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-3b52dac3-c54c-4f6d-b294-af6c5a4f5dab,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-b84acec5-d0fe-4af1-80d4-fe1de1d43516,DISK], DatanodeInfoWithStorage[127.0.0.1:35995,DS-1234e085-c94b-422f-816d-39f0b1b80f93,DISK], DatanodeInfoWithStorage[127.0.0.1:45532,DS-989d29db-8eb3-4122-94e2-68cdfc56b225,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1427575184-172.17.0.7-1595515786444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37660,DS-0702a469-2f1d-446d-a689-c1d5d8710d33,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-3a202de0-3e54-4c4d-a54b-133ca58ec53e,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-71bbad92-a88e-4a72-a650-fa16c942b03b,DISK], DatanodeInfoWithStorage[127.0.0.1:40962,DS-3a0f64e8-f234-4f2d-a4d7-55e051d007b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-2e4785c8-2600-41ac-aef1-3269a9b475b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-b15f3215-c103-48b4-b9b1-eb4c1ab66430,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-ce8d506e-4472-4af4-b34e-8cd666d2bf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-a01f65b6-f771-4fe7-abd8-a965e565824a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1427575184-172.17.0.7-1595515786444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37660,DS-0702a469-2f1d-446d-a689-c1d5d8710d33,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-3a202de0-3e54-4c4d-a54b-133ca58ec53e,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-71bbad92-a88e-4a72-a650-fa16c942b03b,DISK], DatanodeInfoWithStorage[127.0.0.1:40962,DS-3a0f64e8-f234-4f2d-a4d7-55e051d007b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-2e4785c8-2600-41ac-aef1-3269a9b475b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-b15f3215-c103-48b4-b9b1-eb4c1ab66430,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-ce8d506e-4472-4af4-b34e-8cd666d2bf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-a01f65b6-f771-4fe7-abd8-a965e565824a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-331443366-172.17.0.7-1595516013399:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40733,DS-b9db1aa2-aa3f-462b-b324-4037f6ced983,DISK], DatanodeInfoWithStorage[127.0.0.1:35004,DS-96b9958b-9859-41e9-a51f-18fda9d068ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-5d244759-2c9b-4c4f-b2b1-83fe0b69fc1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37084,DS-f9604fef-8a57-4704-99b4-97b24aa46664,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-ec803764-0036-4054-badd-0c73d7d30b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-dfbe38e4-3d68-4a17-87f8-518950dd6e96,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-5760ac90-bad8-413d-8dae-09fe3e036502,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-7529223d-9511-4f28-882a-70c86483aa2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-331443366-172.17.0.7-1595516013399:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40733,DS-b9db1aa2-aa3f-462b-b324-4037f6ced983,DISK], DatanodeInfoWithStorage[127.0.0.1:35004,DS-96b9958b-9859-41e9-a51f-18fda9d068ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-5d244759-2c9b-4c4f-b2b1-83fe0b69fc1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37084,DS-f9604fef-8a57-4704-99b4-97b24aa46664,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-ec803764-0036-4054-badd-0c73d7d30b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-dfbe38e4-3d68-4a17-87f8-518950dd6e96,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-5760ac90-bad8-413d-8dae-09fe3e036502,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-7529223d-9511-4f28-882a-70c86483aa2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-789127379-172.17.0.7-1595516155372:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38786,DS-3738e31d-d6f6-429b-b004-066d450af343,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-0ed7f28b-5866-4871-affe-3d48872fece1,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-e1ea3723-8011-4588-ba8c-fb831b65d30d,DISK], DatanodeInfoWithStorage[127.0.0.1:46329,DS-cd84aa28-ffe3-45be-b8d1-bbc3c275e791,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-ddac2e38-8806-46af-a595-eb14cbb3d402,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-5790c16e-c07d-40e7-b588-11962a99c83f,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-ea7db00e-fdad-42f8-a44a-db44adbe4af0,DISK], DatanodeInfoWithStorage[127.0.0.1:39775,DS-187b98ab-9fe2-4ebf-9f8c-86fcdef55709,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-789127379-172.17.0.7-1595516155372:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38786,DS-3738e31d-d6f6-429b-b004-066d450af343,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-0ed7f28b-5866-4871-affe-3d48872fece1,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-e1ea3723-8011-4588-ba8c-fb831b65d30d,DISK], DatanodeInfoWithStorage[127.0.0.1:46329,DS-cd84aa28-ffe3-45be-b8d1-bbc3c275e791,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-ddac2e38-8806-46af-a595-eb14cbb3d402,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-5790c16e-c07d-40e7-b588-11962a99c83f,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-ea7db00e-fdad-42f8-a44a-db44adbe4af0,DISK], DatanodeInfoWithStorage[127.0.0.1:39775,DS-187b98ab-9fe2-4ebf-9f8c-86fcdef55709,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-172571664-172.17.0.7-1595516825321:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35926,DS-cda474f1-7927-4120-b679-04012139c03b,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-31e49e53-2bfb-49cc-bba1-21bc045c3798,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-64801e1b-30ef-4ff9-a04e-318d8494684f,DISK], DatanodeInfoWithStorage[127.0.0.1:35276,DS-4566bf7f-c72b-4d26-839d-d239a674d698,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-16f100d9-b5ed-47dc-8352-38ffa4befc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-6e458f94-d70b-4790-86ba-1f514026a3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-cdcfa1d4-a1f3-4a5f-9d1e-cf0234157fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39684,DS-1f6a9056-7fa7-49ce-8922-404cf33d602c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-172571664-172.17.0.7-1595516825321:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35926,DS-cda474f1-7927-4120-b679-04012139c03b,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-31e49e53-2bfb-49cc-bba1-21bc045c3798,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-64801e1b-30ef-4ff9-a04e-318d8494684f,DISK], DatanodeInfoWithStorage[127.0.0.1:35276,DS-4566bf7f-c72b-4d26-839d-d239a674d698,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-16f100d9-b5ed-47dc-8352-38ffa4befc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-6e458f94-d70b-4790-86ba-1f514026a3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-cdcfa1d4-a1f3-4a5f-9d1e-cf0234157fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39684,DS-1f6a9056-7fa7-49ce-8922-404cf33d602c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-423999535-172.17.0.7-1595517043808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43041,DS-7086e026-0173-4067-ba77-2af5a4ec1c33,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-53306547-b153-45ac-b756-a0564468549e,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-79f4227e-32e3-41ae-91da-bb02414a6248,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-4d6d4556-aef0-4d20-8536-c10e81d7c6af,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-f6c2977c-b434-4cb0-9c38-90ff0af8f99f,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-ab34d376-80bb-471c-ac12-1aae958a6b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-730997bf-7bf2-4189-8831-d16b4913c236,DISK], DatanodeInfoWithStorage[127.0.0.1:43690,DS-583deac9-1300-4493-bb47-8219bec31598,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-423999535-172.17.0.7-1595517043808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43041,DS-7086e026-0173-4067-ba77-2af5a4ec1c33,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-53306547-b153-45ac-b756-a0564468549e,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-79f4227e-32e3-41ae-91da-bb02414a6248,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-4d6d4556-aef0-4d20-8536-c10e81d7c6af,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-f6c2977c-b434-4cb0-9c38-90ff0af8f99f,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-ab34d376-80bb-471c-ac12-1aae958a6b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-730997bf-7bf2-4189-8831-d16b4913c236,DISK], DatanodeInfoWithStorage[127.0.0.1:43690,DS-583deac9-1300-4493-bb47-8219bec31598,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1337580115-172.17.0.7-1595517418507:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42288,DS-b6b7fbda-890f-4d65-963a-ce0c11c42e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-a90c7d1a-4697-4605-8752-ace4d1199573,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-23843648-2744-4eed-bfb7-9ea35ddeb650,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-69c99dba-fc3f-496d-96e4-93fad2804af0,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-6d4ac603-d145-4c0b-9440-e92080769702,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-2e5d735a-ac50-480a-99c2-78d30f1d8018,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-119ec5f4-274c-4246-b2d5-875ca0838f95,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-93a02e88-fc24-4d55-bcb0-4411f024efd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1337580115-172.17.0.7-1595517418507:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42288,DS-b6b7fbda-890f-4d65-963a-ce0c11c42e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-a90c7d1a-4697-4605-8752-ace4d1199573,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-23843648-2744-4eed-bfb7-9ea35ddeb650,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-69c99dba-fc3f-496d-96e4-93fad2804af0,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-6d4ac603-d145-4c0b-9440-e92080769702,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-2e5d735a-ac50-480a-99c2-78d30f1d8018,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-119ec5f4-274c-4246-b2d5-875ca0838f95,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-93a02e88-fc24-4d55-bcb0-4411f024efd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-20787719-172.17.0.7-1595517797625:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41069,DS-3ab5d22d-e9a9-4201-b601-3836abdc71d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-656a8142-139b-4844-8815-25b96818ee39,DISK], DatanodeInfoWithStorage[127.0.0.1:37283,DS-4b002365-2a8f-4ae7-a535-132c9d2cd98c,DISK], DatanodeInfoWithStorage[127.0.0.1:42298,DS-6dbb8833-48f4-46b5-b6be-d68a31a662e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-bfd5b53a-7199-472d-8cfe-224f88ffb9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-627cb465-ec31-43a4-a9ff-147ed7f1d8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-a425d8d1-7424-4bfc-88d8-1d86538a9da4,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-e7101c61-11b2-44a1-8a17-50d3c1f4d3f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-20787719-172.17.0.7-1595517797625:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41069,DS-3ab5d22d-e9a9-4201-b601-3836abdc71d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-656a8142-139b-4844-8815-25b96818ee39,DISK], DatanodeInfoWithStorage[127.0.0.1:37283,DS-4b002365-2a8f-4ae7-a535-132c9d2cd98c,DISK], DatanodeInfoWithStorage[127.0.0.1:42298,DS-6dbb8833-48f4-46b5-b6be-d68a31a662e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-bfd5b53a-7199-472d-8cfe-224f88ffb9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-627cb465-ec31-43a4-a9ff-147ed7f1d8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-a425d8d1-7424-4bfc-88d8-1d86538a9da4,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-e7101c61-11b2-44a1-8a17-50d3c1f4d3f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2077285343-172.17.0.7-1595517882631:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38773,DS-8bc37d3d-8164-4a43-a34f-de4c1bb12749,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-6d1ef2b0-9abd-4a94-b1bc-fcd9a1e1df54,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-52265501-cfdb-4dee-8c2a-53647f09c32c,DISK], DatanodeInfoWithStorage[127.0.0.1:44900,DS-679a3e8a-6782-4a50-9555-ccc750bcd4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-dc6ec690-b695-4509-9b63-cc2c5313807d,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-48656152-edc8-4742-abce-5ef09501e3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-f6f23487-17f4-46c2-b156-6d03d0a2b75a,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-b49a0ddc-3875-46d0-9129-c302e6812aaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2077285343-172.17.0.7-1595517882631:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38773,DS-8bc37d3d-8164-4a43-a34f-de4c1bb12749,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-6d1ef2b0-9abd-4a94-b1bc-fcd9a1e1df54,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-52265501-cfdb-4dee-8c2a-53647f09c32c,DISK], DatanodeInfoWithStorage[127.0.0.1:44900,DS-679a3e8a-6782-4a50-9555-ccc750bcd4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-dc6ec690-b695-4509-9b63-cc2c5313807d,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-48656152-edc8-4742-abce-5ef09501e3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-f6f23487-17f4-46c2-b156-6d03d0a2b75a,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-b49a0ddc-3875-46d0-9129-c302e6812aaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-63576037-172.17.0.7-1595518139158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37153,DS-cc204f17-b6ea-4569-adad-33523018fd01,DISK], DatanodeInfoWithStorage[127.0.0.1:38838,DS-fe9dc0e8-0a47-4479-bd37-8c43f70b755c,DISK], DatanodeInfoWithStorage[127.0.0.1:42176,DS-e90d4004-3e6f-413f-a1ad-336456c8458c,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-2bce845e-e8d1-4f1d-bb2e-eb80f98f86e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-dc4b5bb6-470a-4cb1-b0d5-79b877834280,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-c8a6ad34-4c0b-428a-becf-de71a95faf79,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-382f7010-1a79-4de2-a7c0-c680229fed0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-ecb72e08-115a-4868-8dca-843028661500,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-63576037-172.17.0.7-1595518139158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37153,DS-cc204f17-b6ea-4569-adad-33523018fd01,DISK], DatanodeInfoWithStorage[127.0.0.1:38838,DS-fe9dc0e8-0a47-4479-bd37-8c43f70b755c,DISK], DatanodeInfoWithStorage[127.0.0.1:42176,DS-e90d4004-3e6f-413f-a1ad-336456c8458c,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-2bce845e-e8d1-4f1d-bb2e-eb80f98f86e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-dc4b5bb6-470a-4cb1-b0d5-79b877834280,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-c8a6ad34-4c0b-428a-becf-de71a95faf79,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-382f7010-1a79-4de2-a7c0-c680229fed0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-ecb72e08-115a-4868-8dca-843028661500,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1277288400-172.17.0.7-1595518499190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45215,DS-1bfd93b8-76e3-4b5f-9c4c-57130bc9c288,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-cf90cb1d-4f0a-4f8c-82ac-d4f624b751ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-eac9a881-6a79-4430-918f-c3377fe8de37,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-7edfdcd9-16e9-44be-81d9-acb16530e730,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-a012df6b-3eb1-40d1-ab7b-d4568fc17644,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-ac5803d0-9cfa-4803-9120-3556e776481d,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-a5804eee-5313-4605-9f43-676efc29d977,DISK], DatanodeInfoWithStorage[127.0.0.1:34965,DS-fcfaf389-c2ea-4e50-b47a-064c601fc0cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1277288400-172.17.0.7-1595518499190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45215,DS-1bfd93b8-76e3-4b5f-9c4c-57130bc9c288,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-cf90cb1d-4f0a-4f8c-82ac-d4f624b751ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-eac9a881-6a79-4430-918f-c3377fe8de37,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-7edfdcd9-16e9-44be-81d9-acb16530e730,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-a012df6b-3eb1-40d1-ab7b-d4568fc17644,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-ac5803d0-9cfa-4803-9120-3556e776481d,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-a5804eee-5313-4605-9f43-676efc29d977,DISK], DatanodeInfoWithStorage[127.0.0.1:34965,DS-fcfaf389-c2ea-4e50-b47a-064c601fc0cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1597771970-172.17.0.7-1595518680526:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40514,DS-4d006280-7468-4d08-a420-24999d2673ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-a6f6e5df-bc4b-4ffb-89e6-db2390d38192,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-ce1e94e4-6259-414b-8e22-5e4c799e021e,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-460eba41-2615-4390-a9fc-4f2e8cd6a2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-6d044b70-d2e0-4c4b-92a0-df33d2801aab,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-2bfc4790-f8fe-4c3f-86e1-9437ae0b1cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-1d657763-65b7-48bf-b005-de6e8d8e244c,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-7bc1182b-f241-448e-a7cf-f2608c8bb872,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1597771970-172.17.0.7-1595518680526:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40514,DS-4d006280-7468-4d08-a420-24999d2673ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-a6f6e5df-bc4b-4ffb-89e6-db2390d38192,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-ce1e94e4-6259-414b-8e22-5e4c799e021e,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-460eba41-2615-4390-a9fc-4f2e8cd6a2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-6d044b70-d2e0-4c4b-92a0-df33d2801aab,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-2bfc4790-f8fe-4c3f-86e1-9437ae0b1cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-1d657763-65b7-48bf-b005-de6e8d8e244c,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-7bc1182b-f241-448e-a7cf-f2608c8bb872,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1969862681-172.17.0.7-1595518814312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42593,DS-b6388b7b-8583-42b8-9f89-f2ffc6be0ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-a26df8d5-6499-4ffa-8d8d-15b1a04c9e71,DISK], DatanodeInfoWithStorage[127.0.0.1:44636,DS-67f183c1-44da-4002-a082-00aa41037b56,DISK], DatanodeInfoWithStorage[127.0.0.1:43209,DS-dbb58027-857c-42c9-81eb-feac1b12ede4,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-f3476f33-4827-4015-bbfd-e68be56ea1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42752,DS-89ae06d4-5489-49f1-a066-fc9066570164,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-7f53ba1a-8ac7-49a7-9d47-cdee0243ff90,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-b329b8e6-c58d-4870-ac56-d625cb7c905a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1969862681-172.17.0.7-1595518814312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42593,DS-b6388b7b-8583-42b8-9f89-f2ffc6be0ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-a26df8d5-6499-4ffa-8d8d-15b1a04c9e71,DISK], DatanodeInfoWithStorage[127.0.0.1:44636,DS-67f183c1-44da-4002-a082-00aa41037b56,DISK], DatanodeInfoWithStorage[127.0.0.1:43209,DS-dbb58027-857c-42c9-81eb-feac1b12ede4,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-f3476f33-4827-4015-bbfd-e68be56ea1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42752,DS-89ae06d4-5489-49f1-a066-fc9066570164,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-7f53ba1a-8ac7-49a7-9d47-cdee0243ff90,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-b329b8e6-c58d-4870-ac56-d625cb7c905a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1531423764-172.17.0.7-1595518994155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38666,DS-f005de45-2dad-47e6-9598-b4000f672975,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-f2ff139d-4f62-4d06-92ba-61bba537b085,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-7cde8c7c-faef-46bf-88df-7d9e51a8fa4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39679,DS-8151e7bb-41f7-49cb-b5d9-3e6cc2b8c2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42127,DS-5d679278-6913-480d-a13c-a6cf0148279b,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-395ad9ac-a0bf-41ec-b392-46fec05da357,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-96fefbeb-53aa-46f3-a40c-ec7dd7ac36ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-a0271c2d-a0a7-4433-9566-0a25d4870888,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1531423764-172.17.0.7-1595518994155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38666,DS-f005de45-2dad-47e6-9598-b4000f672975,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-f2ff139d-4f62-4d06-92ba-61bba537b085,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-7cde8c7c-faef-46bf-88df-7d9e51a8fa4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39679,DS-8151e7bb-41f7-49cb-b5d9-3e6cc2b8c2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42127,DS-5d679278-6913-480d-a13c-a6cf0148279b,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-395ad9ac-a0bf-41ec-b392-46fec05da357,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-96fefbeb-53aa-46f3-a40c-ec7dd7ac36ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-a0271c2d-a0a7-4433-9566-0a25d4870888,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1812124268-172.17.0.7-1595519363506:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40073,DS-531ddb57-46c2-4703-b0cf-0ff6dd6ce4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-5487c961-e5c9-472d-8b9c-960b9eda9905,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-8e705b92-ed9d-4493-a8af-d8b90b47a963,DISK], DatanodeInfoWithStorage[127.0.0.1:39958,DS-8bace075-c4ad-433d-89f4-ed686ee94835,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-b5afcb6d-9124-4f71-95b1-71aa54559888,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-4ef5e2b5-bb74-493c-a1e4-147a536bad5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-d79a9f8e-7337-43f4-a839-ff89ddc815e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45254,DS-ec6231c7-d42a-46cc-92f7-9d1deb5f705c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1812124268-172.17.0.7-1595519363506:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40073,DS-531ddb57-46c2-4703-b0cf-0ff6dd6ce4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-5487c961-e5c9-472d-8b9c-960b9eda9905,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-8e705b92-ed9d-4493-a8af-d8b90b47a963,DISK], DatanodeInfoWithStorage[127.0.0.1:39958,DS-8bace075-c4ad-433d-89f4-ed686ee94835,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-b5afcb6d-9124-4f71-95b1-71aa54559888,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-4ef5e2b5-bb74-493c-a1e4-147a536bad5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-d79a9f8e-7337-43f4-a839-ff89ddc815e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45254,DS-ec6231c7-d42a-46cc-92f7-9d1deb5f705c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1152036379-172.17.0.7-1595520423901:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36824,DS-10358ab3-c986-405e-9b48-d5dafa881b13,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-0adf2d22-05bd-4c04-b543-e421076c5cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-d85e3c0a-4ef6-41bf-89de-162dcc49ad8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41932,DS-acaa1513-1da5-4a65-b668-47684b5b1835,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-117db872-c4cd-4220-ae39-d807497f43fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-ac59fd41-1282-406c-bf30-4aebf31b49e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-041ed14f-0253-4c69-9274-b4040f9ca283,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-6c673e7e-50e6-41cb-af8f-b74d5890f0a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1152036379-172.17.0.7-1595520423901:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36824,DS-10358ab3-c986-405e-9b48-d5dafa881b13,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-0adf2d22-05bd-4c04-b543-e421076c5cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-d85e3c0a-4ef6-41bf-89de-162dcc49ad8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41932,DS-acaa1513-1da5-4a65-b668-47684b5b1835,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-117db872-c4cd-4220-ae39-d807497f43fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-ac59fd41-1282-406c-bf30-4aebf31b49e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-041ed14f-0253-4c69-9274-b4040f9ca283,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-6c673e7e-50e6-41cb-af8f-b74d5890f0a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-771746712-172.17.0.7-1595520598213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32825,DS-c0aa5ec7-6871-4b18-982b-78e4991e560c,DISK], DatanodeInfoWithStorage[127.0.0.1:40120,DS-10790834-831f-474e-ac91-c17b0c3ad854,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-41fe2512-a7d7-4b0a-920f-8a23cd16659d,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-8b30aaca-dca0-41e9-b996-2aa2f69f6b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-f17e48ae-9dbf-4e40-b2bf-eec5bd35ac59,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-40a0b407-eab6-4bdb-9744-d350bcebb9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-7c5b4fbb-2fe9-4bb4-981e-270d9c950923,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-34426da0-6c7a-480f-ac24-3f13a539a2e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-771746712-172.17.0.7-1595520598213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32825,DS-c0aa5ec7-6871-4b18-982b-78e4991e560c,DISK], DatanodeInfoWithStorage[127.0.0.1:40120,DS-10790834-831f-474e-ac91-c17b0c3ad854,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-41fe2512-a7d7-4b0a-920f-8a23cd16659d,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-8b30aaca-dca0-41e9-b996-2aa2f69f6b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-f17e48ae-9dbf-4e40-b2bf-eec5bd35ac59,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-40a0b407-eab6-4bdb-9744-d350bcebb9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-7c5b4fbb-2fe9-4bb4-981e-270d9c950923,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-34426da0-6c7a-480f-ac24-3f13a539a2e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-560639503-172.17.0.7-1595520694806:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42324,DS-6cd99c44-f3c2-4537-b2b6-bb21de48b8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-7c26d3b6-7fad-4c64-b56a-9370a762a916,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-e1cd544e-8b37-4f1f-8411-b9fb5cd18a75,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-6644a390-92ae-48ed-b318-b27dcf2643ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-639f972b-38e7-4597-a7b3-109cf3f7bc31,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-da512346-6d15-4376-94f4-28dfabf9e685,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-60a8ff72-2a7b-4c40-99bf-1ecbfa44f349,DISK], DatanodeInfoWithStorage[127.0.0.1:36175,DS-2b94b414-2bd4-4d4a-b0cb-c3ad7c484101,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-560639503-172.17.0.7-1595520694806:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42324,DS-6cd99c44-f3c2-4537-b2b6-bb21de48b8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-7c26d3b6-7fad-4c64-b56a-9370a762a916,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-e1cd544e-8b37-4f1f-8411-b9fb5cd18a75,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-6644a390-92ae-48ed-b318-b27dcf2643ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-639f972b-38e7-4597-a7b3-109cf3f7bc31,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-da512346-6d15-4376-94f4-28dfabf9e685,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-60a8ff72-2a7b-4c40-99bf-1ecbfa44f349,DISK], DatanodeInfoWithStorage[127.0.0.1:36175,DS-2b94b414-2bd4-4d4a-b0cb-c3ad7c484101,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1064237314-172.17.0.7-1595521042453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36244,DS-3050db8f-9602-4a29-8f46-a054928bd8de,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-8ad3b478-2091-46a2-b80d-9ef149d31ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-de8ae43b-a7dd-416a-8661-0385814d6f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-b6c0a23b-a48e-40f6-b82f-8b4723860ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-9acdaa51-05e6-46e9-bb7f-ff4167f119ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-7b7a1689-8632-4a9d-b83f-f5b2d97e967c,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-1986b9f7-fa26-4f9b-98b6-3699fd37f7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-99792551-993b-49e3-97c9-b45d33943bfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1064237314-172.17.0.7-1595521042453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36244,DS-3050db8f-9602-4a29-8f46-a054928bd8de,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-8ad3b478-2091-46a2-b80d-9ef149d31ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-de8ae43b-a7dd-416a-8661-0385814d6f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-b6c0a23b-a48e-40f6-b82f-8b4723860ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-9acdaa51-05e6-46e9-bb7f-ff4167f119ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-7b7a1689-8632-4a9d-b83f-f5b2d97e967c,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-1986b9f7-fa26-4f9b-98b6-3699fd37f7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-99792551-993b-49e3-97c9-b45d33943bfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-522085106-172.17.0.7-1595521210779:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33077,DS-8b4054ae-3a8e-4cb8-8ea7-0be8a2859f90,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-dc4ce32c-7d50-4352-a629-abeb5b830c63,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-d4c67f4e-c9a9-42c9-bcb4-1533e3f04db9,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-bfb74c45-e50f-4afc-94e1-3c5a7d160d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-e0d9ada4-ef42-42cf-9df7-051ecf2561b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43446,DS-7ea8f996-592f-4957-a0df-6414726ca059,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-86ac11a5-8efd-4cc8-836f-ba59cc28d6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-9f6d80a6-8d8f-42e0-91ac-307bfa0dda6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-522085106-172.17.0.7-1595521210779:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33077,DS-8b4054ae-3a8e-4cb8-8ea7-0be8a2859f90,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-dc4ce32c-7d50-4352-a629-abeb5b830c63,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-d4c67f4e-c9a9-42c9-bcb4-1533e3f04db9,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-bfb74c45-e50f-4afc-94e1-3c5a7d160d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-e0d9ada4-ef42-42cf-9df7-051ecf2561b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43446,DS-7ea8f996-592f-4957-a0df-6414726ca059,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-86ac11a5-8efd-4cc8-836f-ba59cc28d6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-9f6d80a6-8d8f-42e0-91ac-307bfa0dda6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 6901
