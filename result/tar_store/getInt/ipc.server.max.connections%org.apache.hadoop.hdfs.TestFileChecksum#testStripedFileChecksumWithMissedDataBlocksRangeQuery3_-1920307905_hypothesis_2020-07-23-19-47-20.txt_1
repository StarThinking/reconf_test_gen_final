reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1718567249-172.17.0.16-1595533874602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33323,DS-88e7b7e8-976c-4d6e-9f99-757f941ac34c,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-8c3baae7-e8ae-4bd4-b658-2fa31e5d5078,DISK], DatanodeInfoWithStorage[127.0.0.1:46181,DS-6674976b-baae-48bd-93a8-2dc512e888ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-1f3f220e-f4ad-46ba-ae2f-89503ea865de,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-8c009555-797b-4c5b-93c3-0b4428fc859b,DISK], DatanodeInfoWithStorage[127.0.0.1:45775,DS-8fa2db0b-f26d-4b00-9c45-68b709fb142a,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-e37a52e2-262c-452e-bf7a-fc89b6afa70e,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-7625257b-e26d-4b8a-847a-b007cc70439e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1718567249-172.17.0.16-1595533874602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33323,DS-88e7b7e8-976c-4d6e-9f99-757f941ac34c,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-8c3baae7-e8ae-4bd4-b658-2fa31e5d5078,DISK], DatanodeInfoWithStorage[127.0.0.1:46181,DS-6674976b-baae-48bd-93a8-2dc512e888ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-1f3f220e-f4ad-46ba-ae2f-89503ea865de,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-8c009555-797b-4c5b-93c3-0b4428fc859b,DISK], DatanodeInfoWithStorage[127.0.0.1:45775,DS-8fa2db0b-f26d-4b00-9c45-68b709fb142a,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-e37a52e2-262c-452e-bf7a-fc89b6afa70e,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-7625257b-e26d-4b8a-847a-b007cc70439e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1282217154-172.17.0.16-1595534533330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41932,DS-4d6f7eaf-67e8-4bcc-bc90-0e49abe8cbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-36c52e44-7292-4e99-81a8-ef135b098a52,DISK], DatanodeInfoWithStorage[127.0.0.1:40572,DS-7733ceba-f80d-4855-b8fe-5ed6ec290b44,DISK], DatanodeInfoWithStorage[127.0.0.1:36816,DS-4f20c64c-e9f0-4095-a698-8e855784978d,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-fb0df431-4068-46ff-b471-d6890b250e55,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-2a64fc8d-553e-4389-b8f7-5561329220f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-981362d5-9221-4b74-ad3c-2c2953e84af4,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-8cc94631-c14b-4179-972d-4a82b26da7c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1282217154-172.17.0.16-1595534533330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41932,DS-4d6f7eaf-67e8-4bcc-bc90-0e49abe8cbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-36c52e44-7292-4e99-81a8-ef135b098a52,DISK], DatanodeInfoWithStorage[127.0.0.1:40572,DS-7733ceba-f80d-4855-b8fe-5ed6ec290b44,DISK], DatanodeInfoWithStorage[127.0.0.1:36816,DS-4f20c64c-e9f0-4095-a698-8e855784978d,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-fb0df431-4068-46ff-b471-d6890b250e55,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-2a64fc8d-553e-4389-b8f7-5561329220f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-981362d5-9221-4b74-ad3c-2c2953e84af4,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-8cc94631-c14b-4179-972d-4a82b26da7c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514811649-172.17.0.16-1595534608894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36928,DS-7589f639-dda4-4b30-8795-6ee27d63f526,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-7d325da2-3cb1-40eb-b665-73239d189d03,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-59fcc7c6-364c-4660-addb-1c07cf7cca31,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-b37ed7f2-771b-40a1-8f7d-f88dba24255c,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-de604d1f-4fc4-4644-bf19-f2b0796cec02,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-b4372b0d-1107-462b-9ee2-93807053b8af,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-4820f3dc-a341-4469-85aa-e607dff32d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39681,DS-f5892c31-8534-49b9-a164-eea7d44cf8bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514811649-172.17.0.16-1595534608894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36928,DS-7589f639-dda4-4b30-8795-6ee27d63f526,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-7d325da2-3cb1-40eb-b665-73239d189d03,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-59fcc7c6-364c-4660-addb-1c07cf7cca31,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-b37ed7f2-771b-40a1-8f7d-f88dba24255c,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-de604d1f-4fc4-4644-bf19-f2b0796cec02,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-b4372b0d-1107-462b-9ee2-93807053b8af,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-4820f3dc-a341-4469-85aa-e607dff32d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39681,DS-f5892c31-8534-49b9-a164-eea7d44cf8bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-547013417-172.17.0.16-1595534883532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46614,DS-67d430eb-f022-41df-b3b4-87096af2db4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-e0494a72-eaad-4bd4-adc4-9c7e89d5e48b,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-11ab45d8-bd1f-474e-8678-1250f9b6dbee,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-8f4ffce9-81e6-45d9-a111-9739f573e25e,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-a5a45ada-4f81-4540-acde-7b9f6fecf101,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-ec20a736-463b-4bab-8d43-de5a07d78523,DISK], DatanodeInfoWithStorage[127.0.0.1:32929,DS-4d255386-6372-4d20-9e68-8c976c7c5867,DISK], DatanodeInfoWithStorage[127.0.0.1:38420,DS-b926f950-8b33-415c-8fd1-b598f579fbb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-547013417-172.17.0.16-1595534883532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46614,DS-67d430eb-f022-41df-b3b4-87096af2db4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-e0494a72-eaad-4bd4-adc4-9c7e89d5e48b,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-11ab45d8-bd1f-474e-8678-1250f9b6dbee,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-8f4ffce9-81e6-45d9-a111-9739f573e25e,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-a5a45ada-4f81-4540-acde-7b9f6fecf101,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-ec20a736-463b-4bab-8d43-de5a07d78523,DISK], DatanodeInfoWithStorage[127.0.0.1:32929,DS-4d255386-6372-4d20-9e68-8c976c7c5867,DISK], DatanodeInfoWithStorage[127.0.0.1:38420,DS-b926f950-8b33-415c-8fd1-b598f579fbb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1455433980-172.17.0.16-1595535160196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39845,DS-e9e880fd-97c7-4bb0-bcab-7b0bfa56c46f,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-651a60cc-30c6-46a4-8a99-bc2101304337,DISK], DatanodeInfoWithStorage[127.0.0.1:35910,DS-0bd28dac-9a63-4661-870d-222b61837de1,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-c81f0dd2-ed6f-4cb4-b229-267e1843de1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-c5980892-3383-4731-96c9-dbbd9fe72293,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-65ebd935-f58b-46e2-a1da-44bb9bfe7320,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-d223c760-e582-4c81-8a72-117251d234b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-2e634b27-cd2c-4daa-9679-18f5f37534c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1455433980-172.17.0.16-1595535160196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39845,DS-e9e880fd-97c7-4bb0-bcab-7b0bfa56c46f,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-651a60cc-30c6-46a4-8a99-bc2101304337,DISK], DatanodeInfoWithStorage[127.0.0.1:35910,DS-0bd28dac-9a63-4661-870d-222b61837de1,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-c81f0dd2-ed6f-4cb4-b229-267e1843de1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-c5980892-3383-4731-96c9-dbbd9fe72293,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-65ebd935-f58b-46e2-a1da-44bb9bfe7320,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-d223c760-e582-4c81-8a72-117251d234b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-2e634b27-cd2c-4daa-9679-18f5f37534c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1494112391-172.17.0.16-1595535204064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44702,DS-84b8a052-825b-46d8-a87e-ece4fefd3479,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-b8cd6309-7c10-4294-acb1-2d47c78713a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-86b98538-8b29-4836-843a-6b2d14ac3ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-9b251d92-f0ce-4d6e-a15a-0b87051dcd74,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-c898f320-404b-4da1-9936-7b8b4815e68a,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-8049248e-092d-4e78-b4a6-cc40871f76c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-a9b305dc-871d-4b58-a687-914f1d07d1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-24086402-198c-4203-92bd-0a574069c00f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1494112391-172.17.0.16-1595535204064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44702,DS-84b8a052-825b-46d8-a87e-ece4fefd3479,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-b8cd6309-7c10-4294-acb1-2d47c78713a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-86b98538-8b29-4836-843a-6b2d14ac3ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-9b251d92-f0ce-4d6e-a15a-0b87051dcd74,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-c898f320-404b-4da1-9936-7b8b4815e68a,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-8049248e-092d-4e78-b4a6-cc40871f76c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-a9b305dc-871d-4b58-a687-914f1d07d1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-24086402-198c-4203-92bd-0a574069c00f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-29295116-172.17.0.16-1595536585725:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42451,DS-9a830490-a90a-4663-8bec-55f16f6a0073,DISK], DatanodeInfoWithStorage[127.0.0.1:32970,DS-5cc6ca75-bb8f-40fe-aaff-a719d929a235,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-5bf76513-d1f9-45ff-8776-5511bf4300ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-1d78929c-2e8b-4ef9-be51-ee936d7907aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-9035c35b-6131-4675-bf78-c220d90d4604,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-45f8fec1-c222-4b00-a4fa-01d40849137e,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-15fa7541-0909-40f6-9a42-60f2162a734a,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-b523605a-80da-418f-8267-3b9f61f0197b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-29295116-172.17.0.16-1595536585725:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42451,DS-9a830490-a90a-4663-8bec-55f16f6a0073,DISK], DatanodeInfoWithStorage[127.0.0.1:32970,DS-5cc6ca75-bb8f-40fe-aaff-a719d929a235,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-5bf76513-d1f9-45ff-8776-5511bf4300ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-1d78929c-2e8b-4ef9-be51-ee936d7907aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-9035c35b-6131-4675-bf78-c220d90d4604,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-45f8fec1-c222-4b00-a4fa-01d40849137e,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-15fa7541-0909-40f6-9a42-60f2162a734a,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-b523605a-80da-418f-8267-3b9f61f0197b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-30848460-172.17.0.16-1595536805868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41422,DS-b2c5965c-5c43-4886-b8f7-3cda66aa9a28,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-e03371c8-2098-494a-ae73-0e6d49e65da3,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-0d91e421-76ff-48a8-b4e6-fa7c3763a5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-f6f812ae-ab75-4695-8fe6-37b8b06a7a69,DISK], DatanodeInfoWithStorage[127.0.0.1:34218,DS-318822de-308f-4bc6-8e8f-b33e3578ffaf,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-243d1de7-15cc-4740-a2aa-7bfb923d3e42,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-fafba294-a728-4f45-a8f3-dd1f104ab9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-628a0d8e-894a-4722-8c0c-aec17bfc80e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-30848460-172.17.0.16-1595536805868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41422,DS-b2c5965c-5c43-4886-b8f7-3cda66aa9a28,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-e03371c8-2098-494a-ae73-0e6d49e65da3,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-0d91e421-76ff-48a8-b4e6-fa7c3763a5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-f6f812ae-ab75-4695-8fe6-37b8b06a7a69,DISK], DatanodeInfoWithStorage[127.0.0.1:34218,DS-318822de-308f-4bc6-8e8f-b33e3578ffaf,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-243d1de7-15cc-4740-a2aa-7bfb923d3e42,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-fafba294-a728-4f45-a8f3-dd1f104ab9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-628a0d8e-894a-4722-8c0c-aec17bfc80e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-254152317-172.17.0.16-1595536850152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39652,DS-f36c4620-dcd0-4df4-8399-2d8088f210bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-b2712e8e-d53b-4324-9e34-804dbbc2df28,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-3cfb2462-44e4-4a72-9a10-2650b0b8ac91,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-71b3ec47-27a2-4708-820d-b872205f14e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-bf5de15b-5abc-4c46-ae2d-8b0ae3b3977f,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-c0ae5264-ace6-4c63-9b30-c0ddbc0a88fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42111,DS-31b6dc16-b5d5-4e72-b6b8-1661508f44ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-f89e0b9e-4b1f-4531-bd6f-7d953d44ca74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-254152317-172.17.0.16-1595536850152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39652,DS-f36c4620-dcd0-4df4-8399-2d8088f210bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-b2712e8e-d53b-4324-9e34-804dbbc2df28,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-3cfb2462-44e4-4a72-9a10-2650b0b8ac91,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-71b3ec47-27a2-4708-820d-b872205f14e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-bf5de15b-5abc-4c46-ae2d-8b0ae3b3977f,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-c0ae5264-ace6-4c63-9b30-c0ddbc0a88fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42111,DS-31b6dc16-b5d5-4e72-b6b8-1661508f44ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-f89e0b9e-4b1f-4531-bd6f-7d953d44ca74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663824914-172.17.0.16-1595537535318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46322,DS-d8704290-77f2-4f9c-b45d-cfeb7b62853a,DISK], DatanodeInfoWithStorage[127.0.0.1:45084,DS-b9197434-2105-45bc-b26f-ab6761a0d209,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-144a04a2-d07e-48dd-8564-cab00fd976e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-88b3b5dd-aa37-4184-ae81-ae83d434a0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-408041bc-0706-4b90-ba7e-6ceb5de30532,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-8bb9a490-751b-42e1-a2b9-7e50ae63689e,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-c9d0718e-dc96-4dbf-ab81-617d2b465f96,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-30813d47-5029-41a2-bcac-f9c59198e4e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663824914-172.17.0.16-1595537535318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46322,DS-d8704290-77f2-4f9c-b45d-cfeb7b62853a,DISK], DatanodeInfoWithStorage[127.0.0.1:45084,DS-b9197434-2105-45bc-b26f-ab6761a0d209,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-144a04a2-d07e-48dd-8564-cab00fd976e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-88b3b5dd-aa37-4184-ae81-ae83d434a0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-408041bc-0706-4b90-ba7e-6ceb5de30532,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-8bb9a490-751b-42e1-a2b9-7e50ae63689e,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-c9d0718e-dc96-4dbf-ab81-617d2b465f96,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-30813d47-5029-41a2-bcac-f9c59198e4e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-986482923-172.17.0.16-1595537781108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39109,DS-ec33db5e-8433-426d-b6a0-66959b955467,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-6db93c49-47bb-42e9-bbcb-233255743ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-ade7e15e-f4dc-48bb-a3d0-3d94f34cb85a,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-d2e6cc1b-9e67-43db-b6cf-243e9e8e6f57,DISK], DatanodeInfoWithStorage[127.0.0.1:38877,DS-416ba42a-e32a-4a84-901f-7a77914c1ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-7b22f757-7e14-4b5f-aac2-71318aa6c3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-34211199-ef7e-4a5c-a233-f81fabd58574,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-c429bca2-719f-4d8b-af63-d5fb36e45ec1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-986482923-172.17.0.16-1595537781108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39109,DS-ec33db5e-8433-426d-b6a0-66959b955467,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-6db93c49-47bb-42e9-bbcb-233255743ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-ade7e15e-f4dc-48bb-a3d0-3d94f34cb85a,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-d2e6cc1b-9e67-43db-b6cf-243e9e8e6f57,DISK], DatanodeInfoWithStorage[127.0.0.1:38877,DS-416ba42a-e32a-4a84-901f-7a77914c1ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-7b22f757-7e14-4b5f-aac2-71318aa6c3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-34211199-ef7e-4a5c-a233-f81fabd58574,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-c429bca2-719f-4d8b-af63-d5fb36e45ec1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-911319551-172.17.0.16-1595537821119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42741,DS-ad4fb792-5277-41f7-baa6-9daf8fbd2763,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-94573271-89e1-40ac-87ae-f4f6016f7efc,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-ffae9c46-9f01-4521-be6f-869b5a01ae44,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-911edd45-db4b-45b1-a9a7-1dbd483390d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-29682297-9ad1-4520-9599-c279692e5bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-53e9cfad-40ca-4439-b796-f885fa24614e,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-aec80783-589f-4f8f-ac29-3acf3d3fcceb,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-b0248709-d1e7-4897-b688-3e52585e624b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-911319551-172.17.0.16-1595537821119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42741,DS-ad4fb792-5277-41f7-baa6-9daf8fbd2763,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-94573271-89e1-40ac-87ae-f4f6016f7efc,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-ffae9c46-9f01-4521-be6f-869b5a01ae44,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-911edd45-db4b-45b1-a9a7-1dbd483390d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-29682297-9ad1-4520-9599-c279692e5bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-53e9cfad-40ca-4439-b796-f885fa24614e,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-aec80783-589f-4f8f-ac29-3acf3d3fcceb,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-b0248709-d1e7-4897-b688-3e52585e624b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-580957100-172.17.0.16-1595538045526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45721,DS-b52e8358-d422-421f-bb4b-17ff6c1b4b86,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-0ff74a4c-b5b8-4e0f-84f3-9edd33e95e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-dc8f25a1-f69d-4afb-9828-42dc5fa31fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-da03fd33-32f0-4dd7-82d7-7f96a5bc63d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-76be782b-6453-4cb9-99fb-2cba1f4baa12,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-78a33295-1d1e-4740-8ddd-057e21101bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-04a069b1-f80a-4104-bc8e-d0d8158169bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-ff399696-5ede-45db-bd68-70e9bee52250,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-580957100-172.17.0.16-1595538045526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45721,DS-b52e8358-d422-421f-bb4b-17ff6c1b4b86,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-0ff74a4c-b5b8-4e0f-84f3-9edd33e95e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-dc8f25a1-f69d-4afb-9828-42dc5fa31fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-da03fd33-32f0-4dd7-82d7-7f96a5bc63d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-76be782b-6453-4cb9-99fb-2cba1f4baa12,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-78a33295-1d1e-4740-8ddd-057e21101bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-04a069b1-f80a-4104-bc8e-d0d8158169bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-ff399696-5ede-45db-bd68-70e9bee52250,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5465
