reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1381425235-172.17.0.9-1595862691972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45201,DS-90f98fb0-3e5d-4873-91ad-fcb271665284,DISK], DatanodeInfoWithStorage[127.0.0.1:43253,DS-d4164492-56b1-4f73-9758-bf522abb5d44,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-3a68226d-6c88-4cd1-84df-e1e7885038f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45406,DS-e07e34e9-25b0-49ea-a57f-d5685c6b1940,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-812223ff-21b7-41e5-a38b-c9884b9664ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-a4068ab5-b434-4390-8a84-1712c845910b,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-1b406233-d3d1-46b4-b3c7-ac14e40e19d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-12ba33e6-5d78-4a4f-9efc-22eb42868d74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1381425235-172.17.0.9-1595862691972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45201,DS-90f98fb0-3e5d-4873-91ad-fcb271665284,DISK], DatanodeInfoWithStorage[127.0.0.1:43253,DS-d4164492-56b1-4f73-9758-bf522abb5d44,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-3a68226d-6c88-4cd1-84df-e1e7885038f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45406,DS-e07e34e9-25b0-49ea-a57f-d5685c6b1940,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-812223ff-21b7-41e5-a38b-c9884b9664ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-a4068ab5-b434-4390-8a84-1712c845910b,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-1b406233-d3d1-46b4-b3c7-ac14e40e19d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-12ba33e6-5d78-4a4f-9efc-22eb42868d74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2041257329-172.17.0.9-1595862867284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41036,DS-80553f35-1990-47f7-b16c-f64c17e00085,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-46ca995a-a48d-42a3-b81d-2a4f44649dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-756196e7-c0bb-4702-9ab1-3b576548705f,DISK], DatanodeInfoWithStorage[127.0.0.1:37649,DS-7011c0b3-d53e-4f49-8d9d-05aa5e2bffc1,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-98b9773a-0ea3-4e6e-85b5-0ac7a489b998,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-ae020c66-94bf-4f89-a0bd-a65b197debdd,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-4d896a2c-8209-4eea-8403-fab2fac4345a,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-c1bc2176-9e87-4d77-99c0-2ca9bfa989f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2041257329-172.17.0.9-1595862867284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41036,DS-80553f35-1990-47f7-b16c-f64c17e00085,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-46ca995a-a48d-42a3-b81d-2a4f44649dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-756196e7-c0bb-4702-9ab1-3b576548705f,DISK], DatanodeInfoWithStorage[127.0.0.1:37649,DS-7011c0b3-d53e-4f49-8d9d-05aa5e2bffc1,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-98b9773a-0ea3-4e6e-85b5-0ac7a489b998,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-ae020c66-94bf-4f89-a0bd-a65b197debdd,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-4d896a2c-8209-4eea-8403-fab2fac4345a,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-c1bc2176-9e87-4d77-99c0-2ca9bfa989f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-756450614-172.17.0.9-1595862898946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41929,DS-19c9c1ee-8593-47e0-aaee-d94b1089a35a,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-e7453759-969a-4b70-998d-361a02273c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36990,DS-3a92f857-af55-4a67-b1ea-2146ad0e6f14,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-0665ea34-4cd9-4cf0-b74e-182906347b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-3dacf912-3995-4a2b-b4bf-0144c0627ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-fc440bfd-f033-4689-9800-52c669a0a517,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-4c630493-9a4c-414b-b7a7-d9c0a4f64ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-3b4357f9-14f1-48a7-ad9d-330e334ec0bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-756450614-172.17.0.9-1595862898946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41929,DS-19c9c1ee-8593-47e0-aaee-d94b1089a35a,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-e7453759-969a-4b70-998d-361a02273c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36990,DS-3a92f857-af55-4a67-b1ea-2146ad0e6f14,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-0665ea34-4cd9-4cf0-b74e-182906347b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-3dacf912-3995-4a2b-b4bf-0144c0627ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-fc440bfd-f033-4689-9800-52c669a0a517,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-4c630493-9a4c-414b-b7a7-d9c0a4f64ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-3b4357f9-14f1-48a7-ad9d-330e334ec0bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1833263147-172.17.0.9-1595863154821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37719,DS-a08fa4b6-879a-4eb9-bd6f-41bdba85686e,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-202adb82-0c8a-4a73-a96e-85a60520b746,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-06f3f244-d5e4-45de-b628-b159d55a890d,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-978dd215-fb62-47ce-946a-4f6b165213e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-8990d8c3-ec3e-40d1-ab3f-b64982eb0569,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-51041f53-8635-406e-ad8c-dc9f8d6f5c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-86d3cbc8-9f71-44ed-ac17-c382989b8115,DISK], DatanodeInfoWithStorage[127.0.0.1:41766,DS-bcf227a5-a52c-4bf4-85be-d71d93db687b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1833263147-172.17.0.9-1595863154821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37719,DS-a08fa4b6-879a-4eb9-bd6f-41bdba85686e,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-202adb82-0c8a-4a73-a96e-85a60520b746,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-06f3f244-d5e4-45de-b628-b159d55a890d,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-978dd215-fb62-47ce-946a-4f6b165213e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-8990d8c3-ec3e-40d1-ab3f-b64982eb0569,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-51041f53-8635-406e-ad8c-dc9f8d6f5c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-86d3cbc8-9f71-44ed-ac17-c382989b8115,DISK], DatanodeInfoWithStorage[127.0.0.1:41766,DS-bcf227a5-a52c-4bf4-85be-d71d93db687b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2085032165-172.17.0.9-1595863307807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40745,DS-31373a5b-c74e-4872-98dc-7570957a5e04,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-10feffb6-7344-48e0-8efd-040f4c83334e,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-13dd642b-bcb8-48a8-b2b1-24d9e160b440,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-ec8b7075-e9ce-423a-868a-75ada2040737,DISK], DatanodeInfoWithStorage[127.0.0.1:46758,DS-b8a2edb3-31bf-48c2-8e8f-77ab25ab68e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-27cbb562-d7d8-4656-92fa-03fd7f298b52,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-d7fc85d9-4036-4613-9b3c-02533e5bf3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-da4535ab-345f-4c61-8cef-47955d7c75e2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2085032165-172.17.0.9-1595863307807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40745,DS-31373a5b-c74e-4872-98dc-7570957a5e04,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-10feffb6-7344-48e0-8efd-040f4c83334e,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-13dd642b-bcb8-48a8-b2b1-24d9e160b440,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-ec8b7075-e9ce-423a-868a-75ada2040737,DISK], DatanodeInfoWithStorage[127.0.0.1:46758,DS-b8a2edb3-31bf-48c2-8e8f-77ab25ab68e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-27cbb562-d7d8-4656-92fa-03fd7f298b52,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-d7fc85d9-4036-4613-9b3c-02533e5bf3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-da4535ab-345f-4c61-8cef-47955d7c75e2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-886223690-172.17.0.9-1595863541130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43256,DS-db8d2193-ce40-43bb-befb-ba1a59e1ef0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-f91dfdf5-9364-4f77-89fb-fe32c169fa48,DISK], DatanodeInfoWithStorage[127.0.0.1:39352,DS-3e7270d3-3037-4732-b526-4d75210c14ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-8ee236a9-d875-40ed-ac13-f165b17d7b81,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-9c40bfb0-062c-463c-824d-e5f5fe8aa5df,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-0403edef-2b9a-46d0-a77a-63beef04293a,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-761d7eda-c0b6-4792-9ebf-5897c901cb54,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-01db2af3-f5f5-416a-865b-00339d7e4a26,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-886223690-172.17.0.9-1595863541130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43256,DS-db8d2193-ce40-43bb-befb-ba1a59e1ef0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-f91dfdf5-9364-4f77-89fb-fe32c169fa48,DISK], DatanodeInfoWithStorage[127.0.0.1:39352,DS-3e7270d3-3037-4732-b526-4d75210c14ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-8ee236a9-d875-40ed-ac13-f165b17d7b81,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-9c40bfb0-062c-463c-824d-e5f5fe8aa5df,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-0403edef-2b9a-46d0-a77a-63beef04293a,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-761d7eda-c0b6-4792-9ebf-5897c901cb54,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-01db2af3-f5f5-416a-865b-00339d7e4a26,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1272806400-172.17.0.9-1595863605983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43947,DS-f9ed3461-1f7a-488c-9f51-516f333dbae2,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-6512b375-4520-447d-a4b2-60c16c1de1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-e0dec788-d296-4dd2-924e-1ebf52591e57,DISK], DatanodeInfoWithStorage[127.0.0.1:42136,DS-42120751-9650-4ea0-99bb-0e82611ba801,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-f0d4a622-3da5-4cb2-a3b0-057b689058e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-ebddf0bd-9c4d-456b-afc1-be2225a19075,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-a281b13d-e3eb-44a0-8ab0-c1b5c6584396,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-f370696a-11f7-4cbe-997a-a47599786670,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1272806400-172.17.0.9-1595863605983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43947,DS-f9ed3461-1f7a-488c-9f51-516f333dbae2,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-6512b375-4520-447d-a4b2-60c16c1de1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-e0dec788-d296-4dd2-924e-1ebf52591e57,DISK], DatanodeInfoWithStorage[127.0.0.1:42136,DS-42120751-9650-4ea0-99bb-0e82611ba801,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-f0d4a622-3da5-4cb2-a3b0-057b689058e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-ebddf0bd-9c4d-456b-afc1-be2225a19075,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-a281b13d-e3eb-44a0-8ab0-c1b5c6584396,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-f370696a-11f7-4cbe-997a-a47599786670,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1710514553-172.17.0.9-1595863681101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37227,DS-fc4f961f-55c2-4838-875d-158989da9c64,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-3eca09b8-be11-4da0-a0cc-e4feb9cc2648,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-b6296741-fd6c-41e2-81aa-bb40bddf9826,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-0136493f-b73d-4345-84f0-f06dd9990ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-492eb95d-f24e-443f-9a5c-897b1d65c9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-73148dac-153c-45fa-b2d6-d64dc05d38e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-b192a682-21e3-4cf8-8b72-b2222a915a36,DISK], DatanodeInfoWithStorage[127.0.0.1:35936,DS-fc8e1e44-fa84-46ec-a868-783f81d95af2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1710514553-172.17.0.9-1595863681101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37227,DS-fc4f961f-55c2-4838-875d-158989da9c64,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-3eca09b8-be11-4da0-a0cc-e4feb9cc2648,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-b6296741-fd6c-41e2-81aa-bb40bddf9826,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-0136493f-b73d-4345-84f0-f06dd9990ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-492eb95d-f24e-443f-9a5c-897b1d65c9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-73148dac-153c-45fa-b2d6-d64dc05d38e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-b192a682-21e3-4cf8-8b72-b2222a915a36,DISK], DatanodeInfoWithStorage[127.0.0.1:35936,DS-fc8e1e44-fa84-46ec-a868-783f81d95af2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-803963398-172.17.0.9-1595863719366:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43038,DS-8b630f75-60c5-4b6b-bbeb-30f2c75bfb90,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-f091995e-5804-4a55-aed3-a769415e191b,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-0e274db6-e481-4b38-91ea-d5a85ac79c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-c4c36c2d-88fe-4380-a719-36efc8d2b230,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-aaa64bbe-7caf-42d1-a5e9-a1951a47d1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-21b7d855-cfdd-4b96-a467-8c1058db4249,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-19f1103c-ca84-4748-8c7b-773767fdc95f,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-ed2cb590-d291-487d-ab1d-8e670a8a8e68,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-803963398-172.17.0.9-1595863719366:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43038,DS-8b630f75-60c5-4b6b-bbeb-30f2c75bfb90,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-f091995e-5804-4a55-aed3-a769415e191b,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-0e274db6-e481-4b38-91ea-d5a85ac79c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-c4c36c2d-88fe-4380-a719-36efc8d2b230,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-aaa64bbe-7caf-42d1-a5e9-a1951a47d1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-21b7d855-cfdd-4b96-a467-8c1058db4249,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-19f1103c-ca84-4748-8c7b-773767fdc95f,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-ed2cb590-d291-487d-ab1d-8e670a8a8e68,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-847703509-172.17.0.9-1595863888738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42372,DS-100fe816-34c9-4403-b4d3-e07e027cc2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-e64cf914-9198-47f9-9dab-80cf782a1bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-44ce1816-8174-4582-8182-6a318b4347d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-3a9cbb41-c542-45f2-93d4-820226be2676,DISK], DatanodeInfoWithStorage[127.0.0.1:37764,DS-29fe698a-d7c8-4cdc-8bd6-04ad072d2bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-6ace6ae5-2287-4dfb-911b-96e608bb5be5,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-6e10b92c-aa9b-43af-95e3-e0226ca6b225,DISK], DatanodeInfoWithStorage[127.0.0.1:45457,DS-3c1069ed-ccde-4b77-9881-6e3128e022ca,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-847703509-172.17.0.9-1595863888738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42372,DS-100fe816-34c9-4403-b4d3-e07e027cc2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-e64cf914-9198-47f9-9dab-80cf782a1bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-44ce1816-8174-4582-8182-6a318b4347d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-3a9cbb41-c542-45f2-93d4-820226be2676,DISK], DatanodeInfoWithStorage[127.0.0.1:37764,DS-29fe698a-d7c8-4cdc-8bd6-04ad072d2bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-6ace6ae5-2287-4dfb-911b-96e608bb5be5,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-6e10b92c-aa9b-43af-95e3-e0226ca6b225,DISK], DatanodeInfoWithStorage[127.0.0.1:45457,DS-3c1069ed-ccde-4b77-9881-6e3128e022ca,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-413793542-172.17.0.9-1595864284994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34795,DS-f956b7f2-5e8e-4e6b-bf9d-cef48fad40ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-b99ebb9c-c0ce-4a29-a419-a05f6501f9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-2fe254ac-9c2f-4faa-b3b2-d4e64d876f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-fab82e4f-ccd6-4960-9e66-fda1982fb515,DISK], DatanodeInfoWithStorage[127.0.0.1:39269,DS-5a6533c8-9cc8-4040-8619-1bb8ac251f74,DISK], DatanodeInfoWithStorage[127.0.0.1:37352,DS-33464d61-2a43-4b2a-9988-c5fe386a248c,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-d4a573f0-4ff0-4e94-98c1-cde3a4fe033b,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-7aa32beb-8507-4aff-ba13-ae47b74dff8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-413793542-172.17.0.9-1595864284994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34795,DS-f956b7f2-5e8e-4e6b-bf9d-cef48fad40ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-b99ebb9c-c0ce-4a29-a419-a05f6501f9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-2fe254ac-9c2f-4faa-b3b2-d4e64d876f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-fab82e4f-ccd6-4960-9e66-fda1982fb515,DISK], DatanodeInfoWithStorage[127.0.0.1:39269,DS-5a6533c8-9cc8-4040-8619-1bb8ac251f74,DISK], DatanodeInfoWithStorage[127.0.0.1:37352,DS-33464d61-2a43-4b2a-9988-c5fe386a248c,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-d4a573f0-4ff0-4e94-98c1-cde3a4fe033b,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-7aa32beb-8507-4aff-ba13-ae47b74dff8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1368933073-172.17.0.9-1595864350493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35282,DS-265e3a9c-e6ac-4ce4-bc22-627dee978037,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-0b4f69a4-23f9-4ad3-b211-80274f84e1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-668ef6dc-93a9-4687-b986-218ac2c55e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-7cc60ee1-ed20-4b95-82cd-3f6d9728a46b,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-ecb0e63f-5be1-4a64-a93a-da4ea02e5fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-de4519d5-3357-46f9-94ef-20cd88052132,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-98900a74-09ed-4f63-86f0-7c219532873e,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-f9ce6c44-cae7-4d68-a736-1016aabd955a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1368933073-172.17.0.9-1595864350493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35282,DS-265e3a9c-e6ac-4ce4-bc22-627dee978037,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-0b4f69a4-23f9-4ad3-b211-80274f84e1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-668ef6dc-93a9-4687-b986-218ac2c55e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-7cc60ee1-ed20-4b95-82cd-3f6d9728a46b,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-ecb0e63f-5be1-4a64-a93a-da4ea02e5fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-de4519d5-3357-46f9-94ef-20cd88052132,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-98900a74-09ed-4f63-86f0-7c219532873e,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-f9ce6c44-cae7-4d68-a736-1016aabd955a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-637259990-172.17.0.9-1595864486458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42683,DS-9fba91d5-7ed9-4bf7-8d59-2c6e74d9ccf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-017868a8-b9d2-4643-830d-a0cddd87ce1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-23a03529-1c83-4b2d-a640-63a19ddf531b,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-679b001e-9665-4c53-93f7-441021063ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-3a78bf25-b910-4d8f-bee5-6c96e85dafa0,DISK], DatanodeInfoWithStorage[127.0.0.1:40852,DS-db975d0c-622b-47b8-86b4-3dd0edf6c753,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-1d336f67-6c6e-4844-b1df-86428f2d4d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-36398a4e-7107-4937-bfc5-518ba8421e5f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-637259990-172.17.0.9-1595864486458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42683,DS-9fba91d5-7ed9-4bf7-8d59-2c6e74d9ccf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-017868a8-b9d2-4643-830d-a0cddd87ce1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-23a03529-1c83-4b2d-a640-63a19ddf531b,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-679b001e-9665-4c53-93f7-441021063ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-3a78bf25-b910-4d8f-bee5-6c96e85dafa0,DISK], DatanodeInfoWithStorage[127.0.0.1:40852,DS-db975d0c-622b-47b8-86b4-3dd0edf6c753,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-1d336f67-6c6e-4844-b1df-86428f2d4d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-36398a4e-7107-4937-bfc5-518ba8421e5f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-125923705-172.17.0.9-1595864596154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43733,DS-89aa8fd3-e0a3-44e2-805c-9dced608b0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-09305599-1b2e-4717-8e6d-00e4956f6f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-c6f9133a-91e7-4db4-8472-99acf51d68f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42312,DS-3a88a99c-abbd-4fe7-8ae2-6e521c3f5d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-26f8b314-3821-42bf-8290-add75684c703,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-2709de5b-ea8b-4acb-9f1d-8e8f0ca0643e,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-5cb18296-21da-4023-96f3-56cf842868bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-a98f371d-dff5-4370-8801-86ebb66e4f76,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-125923705-172.17.0.9-1595864596154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43733,DS-89aa8fd3-e0a3-44e2-805c-9dced608b0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-09305599-1b2e-4717-8e6d-00e4956f6f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-c6f9133a-91e7-4db4-8472-99acf51d68f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42312,DS-3a88a99c-abbd-4fe7-8ae2-6e521c3f5d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-26f8b314-3821-42bf-8290-add75684c703,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-2709de5b-ea8b-4acb-9f1d-8e8f0ca0643e,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-5cb18296-21da-4023-96f3-56cf842868bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-a98f371d-dff5-4370-8801-86ebb66e4f76,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1138468480-172.17.0.9-1595864698370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39238,DS-d7f64982-d10e-42df-9663-940f794eb84c,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-dda8880a-6e55-485a-a18c-5e8f64ea5fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-5ca0a4ae-c423-4295-98e2-17afa742df8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-c7bc8292-d1df-4143-b262-3b711d8c2a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35425,DS-a94ee26e-4fc7-4028-b9d3-ef224b3c58c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-14674699-d334-4cac-92fb-1c1fd7430390,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-83d6b0a3-a366-4664-b20b-405f19930a03,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-23df3f9a-171f-4a0e-8615-ea36d2bb226a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1138468480-172.17.0.9-1595864698370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39238,DS-d7f64982-d10e-42df-9663-940f794eb84c,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-dda8880a-6e55-485a-a18c-5e8f64ea5fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-5ca0a4ae-c423-4295-98e2-17afa742df8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-c7bc8292-d1df-4143-b262-3b711d8c2a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35425,DS-a94ee26e-4fc7-4028-b9d3-ef224b3c58c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-14674699-d334-4cac-92fb-1c1fd7430390,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-83d6b0a3-a366-4664-b20b-405f19930a03,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-23df3f9a-171f-4a0e-8615-ea36d2bb226a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-563219904-172.17.0.9-1595864980915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38145,DS-e381456c-ee83-4fc5-862d-c365eb3d8958,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-68b6ae94-d575-4af1-b5dc-918f8d560fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-91a4c9fd-f156-4f1d-ab3d-532e3a720fba,DISK], DatanodeInfoWithStorage[127.0.0.1:34448,DS-16a332ce-299b-4b09-94a7-79523338ff31,DISK], DatanodeInfoWithStorage[127.0.0.1:43506,DS-19f8c8a0-8e0b-4ee5-827a-be41cfb54397,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-3e9ed712-6744-4045-a264-5e3223e084cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-6e5a8198-92c3-43fd-8695-c110f266bc34,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-c1c9643f-8c9d-481c-941d-c380398af171,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-563219904-172.17.0.9-1595864980915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38145,DS-e381456c-ee83-4fc5-862d-c365eb3d8958,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-68b6ae94-d575-4af1-b5dc-918f8d560fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-91a4c9fd-f156-4f1d-ab3d-532e3a720fba,DISK], DatanodeInfoWithStorage[127.0.0.1:34448,DS-16a332ce-299b-4b09-94a7-79523338ff31,DISK], DatanodeInfoWithStorage[127.0.0.1:43506,DS-19f8c8a0-8e0b-4ee5-827a-be41cfb54397,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-3e9ed712-6744-4045-a264-5e3223e084cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-6e5a8198-92c3-43fd-8695-c110f266bc34,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-c1c9643f-8c9d-481c-941d-c380398af171,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1963873542-172.17.0.9-1595865008119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44702,DS-6b436d4e-9870-43ed-aca9-394eed96012d,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-5706280e-705e-4fae-9e1a-f887378273f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-74ea12f6-5c0d-47cd-8840-7b993e71aa38,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-194a8331-31ac-4049-b404-329f35208683,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-b25782e9-bbc4-47ac-a0b4-240fc6da2dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-8886f8a1-1139-4600-a72c-28e4ab0deb84,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-0655f7fb-7e51-42db-af64-96a4064a1dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-c8abea59-4a40-46a6-884a-5b95d5569fc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1963873542-172.17.0.9-1595865008119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44702,DS-6b436d4e-9870-43ed-aca9-394eed96012d,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-5706280e-705e-4fae-9e1a-f887378273f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-74ea12f6-5c0d-47cd-8840-7b993e71aa38,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-194a8331-31ac-4049-b404-329f35208683,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-b25782e9-bbc4-47ac-a0b4-240fc6da2dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-8886f8a1-1139-4600-a72c-28e4ab0deb84,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-0655f7fb-7e51-42db-af64-96a4064a1dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-c8abea59-4a40-46a6-884a-5b95d5569fc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1469294312-172.17.0.9-1595865333693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45497,DS-ebcc107b-4c38-484b-83a4-943499447b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-3bdd44d7-dddd-4e1b-ac77-2768c2ffdd10,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-6fd2ac25-f78f-4ecd-99cb-c1fa5579de74,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-bbaf47b9-d0e9-4afb-92d5-177ce8e9b313,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-2c5ca682-0e9f-4613-92b9-77d08fddc989,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-8db594f5-9b1f-4415-9208-0ff1383a1732,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-4d75fa0f-4f4c-4e7c-91c0-a82bc7d1ee7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-df33e1cb-acd4-4064-8e52-2907d831c7bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1469294312-172.17.0.9-1595865333693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45497,DS-ebcc107b-4c38-484b-83a4-943499447b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-3bdd44d7-dddd-4e1b-ac77-2768c2ffdd10,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-6fd2ac25-f78f-4ecd-99cb-c1fa5579de74,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-bbaf47b9-d0e9-4afb-92d5-177ce8e9b313,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-2c5ca682-0e9f-4613-92b9-77d08fddc989,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-8db594f5-9b1f-4415-9208-0ff1383a1732,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-4d75fa0f-4f4c-4e7c-91c0-a82bc7d1ee7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-df33e1cb-acd4-4064-8e52-2907d831c7bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-153908126-172.17.0.9-1595865372589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33174,DS-6eaf2ff6-3406-4434-810d-14bde5c7a3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-fa3f35b7-395a-4d8b-8013-62a6f2a389c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-a47907bf-3f84-42b0-ac60-151516ac1e03,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-e730e417-4013-4bf9-aabb-fc4a353cd415,DISK], DatanodeInfoWithStorage[127.0.0.1:33375,DS-805f7d8e-ea52-4114-bbf3-999f24196ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-35f9222e-c94a-4e99-ab2e-0abf67391df4,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-fe13b65b-d6cf-4870-b362-1967945d1601,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-f11627ca-bbf3-4f29-bb7d-d26c1090b59a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-153908126-172.17.0.9-1595865372589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33174,DS-6eaf2ff6-3406-4434-810d-14bde5c7a3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-fa3f35b7-395a-4d8b-8013-62a6f2a389c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-a47907bf-3f84-42b0-ac60-151516ac1e03,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-e730e417-4013-4bf9-aabb-fc4a353cd415,DISK], DatanodeInfoWithStorage[127.0.0.1:33375,DS-805f7d8e-ea52-4114-bbf3-999f24196ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-35f9222e-c94a-4e99-ab2e-0abf67391df4,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-fe13b65b-d6cf-4870-b362-1967945d1601,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-f11627ca-bbf3-4f29-bb7d-d26c1090b59a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-557680957-172.17.0.9-1595865581572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36731,DS-57ee7283-d7ce-42c8-8676-870fcf7fad5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-2aeb9575-8546-4bcc-9e42-34707273fd11,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-2102dcb7-3156-4848-b090-8492fb4c70d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-19526cf3-3fc7-4939-8d66-b261409b32d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-ad6fdd6b-b501-4c79-aa8d-62641641b365,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-5e4a6d9c-221f-4b81-b698-d59b038a0205,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-0509515a-6a0a-4de7-be69-60a1c629a3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-d96f37a9-d293-48e1-b37f-d35942822b7a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-557680957-172.17.0.9-1595865581572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36731,DS-57ee7283-d7ce-42c8-8676-870fcf7fad5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-2aeb9575-8546-4bcc-9e42-34707273fd11,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-2102dcb7-3156-4848-b090-8492fb4c70d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-19526cf3-3fc7-4939-8d66-b261409b32d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-ad6fdd6b-b501-4c79-aa8d-62641641b365,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-5e4a6d9c-221f-4b81-b698-d59b038a0205,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-0509515a-6a0a-4de7-be69-60a1c629a3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-d96f37a9-d293-48e1-b37f-d35942822b7a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-355452962-172.17.0.9-1595865760764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33245,DS-c89b5156-df56-4ad0-b5a0-a3d6ef810cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-1cd24313-0fa6-45a8-9587-004966f80531,DISK], DatanodeInfoWithStorage[127.0.0.1:33372,DS-aa6afca0-7344-443c-8f26-2c9fec4a6b86,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-c0bc5130-5dfb-46cd-8fa7-53f7380d1989,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-5b95f44b-051b-45fa-a6ed-bb2b7462df67,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-2a0aa8a6-d331-4366-8bc9-233c2069c6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-d592c402-1c5f-4c31-906f-813adc2eaf20,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-5b41de00-adb2-4e84-8d78-4a2fe075ec6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-355452962-172.17.0.9-1595865760764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33245,DS-c89b5156-df56-4ad0-b5a0-a3d6ef810cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-1cd24313-0fa6-45a8-9587-004966f80531,DISK], DatanodeInfoWithStorage[127.0.0.1:33372,DS-aa6afca0-7344-443c-8f26-2c9fec4a6b86,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-c0bc5130-5dfb-46cd-8fa7-53f7380d1989,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-5b95f44b-051b-45fa-a6ed-bb2b7462df67,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-2a0aa8a6-d331-4366-8bc9-233c2069c6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-d592c402-1c5f-4c31-906f-813adc2eaf20,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-5b41de00-adb2-4e84-8d78-4a2fe075ec6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1617760102-172.17.0.9-1595865890263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46105,DS-25eba019-4292-4a09-8b99-b5ddfd70271f,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-8ac37bb8-a08f-4347-81be-7b2737fa9da2,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-79940efe-d39c-4f6a-a4d9-9c80a00f3497,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-3555b38f-7b62-40d3-afa5-0bcdb95c3053,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-d831e95f-9d5e-4681-8127-0b7af861a8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-dcadca92-f441-462d-a003-2996b735beea,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-0674fca2-4e1a-4e4c-9d50-6d3d4b4cbe97,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-b272cd56-bf01-4c25-b0ee-403643d6c6a8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1617760102-172.17.0.9-1595865890263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46105,DS-25eba019-4292-4a09-8b99-b5ddfd70271f,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-8ac37bb8-a08f-4347-81be-7b2737fa9da2,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-79940efe-d39c-4f6a-a4d9-9c80a00f3497,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-3555b38f-7b62-40d3-afa5-0bcdb95c3053,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-d831e95f-9d5e-4681-8127-0b7af861a8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-dcadca92-f441-462d-a003-2996b735beea,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-0674fca2-4e1a-4e4c-9d50-6d3d4b4cbe97,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-b272cd56-bf01-4c25-b0ee-403643d6c6a8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-476972177-172.17.0.9-1595866091224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45001,DS-89d7ecae-666a-44b0-9676-36e5d8bdff86,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-e36ea9b9-2a98-4292-ad1c-16c1653bf896,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-879f7923-8344-4fe2-977c-42be5e895ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-3812a2bc-ef02-48dc-8578-ccd4a7aabb25,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-8fdded56-374d-4573-a3b4-9aa23d8e63d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44517,DS-279bf98e-4a30-4319-967f-d402e2981b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36296,DS-d1d4a66b-6258-45db-b92f-9b8a7ca482cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-d075ab0c-22b3-4563-b5ae-dac12e6655d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-476972177-172.17.0.9-1595866091224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45001,DS-89d7ecae-666a-44b0-9676-36e5d8bdff86,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-e36ea9b9-2a98-4292-ad1c-16c1653bf896,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-879f7923-8344-4fe2-977c-42be5e895ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-3812a2bc-ef02-48dc-8578-ccd4a7aabb25,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-8fdded56-374d-4573-a3b4-9aa23d8e63d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44517,DS-279bf98e-4a30-4319-967f-d402e2981b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36296,DS-d1d4a66b-6258-45db-b92f-9b8a7ca482cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-d075ab0c-22b3-4563-b5ae-dac12e6655d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-272490550-172.17.0.9-1595866164508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42861,DS-bdf6ac60-a203-4e92-b32a-ce76d7b5ca08,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-f0d4783b-6041-43ab-87bc-49e005a7ce5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-ae288058-d719-4154-bb81-184fd4f95cba,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-72df2a89-9f7a-4eea-b27e-399e7d162a76,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-f0087404-5fc4-46a3-a96e-0ff175f055ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-1f81e9b7-46c8-4d33-b0ed-df5a5fbc2acf,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-e860bf25-04b0-46c6-8a74-efeb774a6319,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-e6639c84-69bc-4a57-bc6d-7b2588f61bb2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-272490550-172.17.0.9-1595866164508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42861,DS-bdf6ac60-a203-4e92-b32a-ce76d7b5ca08,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-f0d4783b-6041-43ab-87bc-49e005a7ce5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-ae288058-d719-4154-bb81-184fd4f95cba,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-72df2a89-9f7a-4eea-b27e-399e7d162a76,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-f0087404-5fc4-46a3-a96e-0ff175f055ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-1f81e9b7-46c8-4d33-b0ed-df5a5fbc2acf,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-e860bf25-04b0-46c6-8a74-efeb774a6319,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-e6639c84-69bc-4a57-bc6d-7b2588f61bb2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1984825382-172.17.0.9-1595866295206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36260,DS-9ad646d1-a55e-437d-bcc8-3abc3aef6ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:41323,DS-84bc151a-81a9-455f-9884-5ec779f7e77e,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-6f247b0f-b3dd-4597-8b78-8478357fe48c,DISK], DatanodeInfoWithStorage[127.0.0.1:43115,DS-925a127a-c15b-45b1-8b5c-336d06c2db9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-9ade271e-7b43-4192-8443-bc5e3009bafc,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-c315ea55-365f-4f7a-9957-5e9de92a2d02,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-96a27d8c-0d3a-470a-a1a3-deb3e0cc23b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-2db789a4-e77e-4109-af57-584e1fb24427,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1984825382-172.17.0.9-1595866295206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36260,DS-9ad646d1-a55e-437d-bcc8-3abc3aef6ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:41323,DS-84bc151a-81a9-455f-9884-5ec779f7e77e,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-6f247b0f-b3dd-4597-8b78-8478357fe48c,DISK], DatanodeInfoWithStorage[127.0.0.1:43115,DS-925a127a-c15b-45b1-8b5c-336d06c2db9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-9ade271e-7b43-4192-8443-bc5e3009bafc,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-c315ea55-365f-4f7a-9957-5e9de92a2d02,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-96a27d8c-0d3a-470a-a1a3-deb3e0cc23b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-2db789a4-e77e-4109-af57-584e1fb24427,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1174308090-172.17.0.9-1595866390758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42665,DS-ccb8ef43-6af7-4bd5-a66d-7700351ddd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-e5339594-50a9-48d2-a61f-95c73a24fe7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-b76e41a9-5cbe-4fd0-b7e4-ec04eb8f0408,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-83dcc156-2dd8-408b-b50d-96ae067cbc20,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-4f78e59c-4096-43bc-9f87-56a9ba9bace6,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-f34c5c13-aed5-49e4-9aaf-f5db0ddedf87,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-392f05fb-9c5d-45f4-9fd5-e063df15604a,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-f152458f-a96f-4fe4-8141-5c5e9274040b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1174308090-172.17.0.9-1595866390758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42665,DS-ccb8ef43-6af7-4bd5-a66d-7700351ddd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-e5339594-50a9-48d2-a61f-95c73a24fe7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-b76e41a9-5cbe-4fd0-b7e4-ec04eb8f0408,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-83dcc156-2dd8-408b-b50d-96ae067cbc20,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-4f78e59c-4096-43bc-9f87-56a9ba9bace6,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-f34c5c13-aed5-49e4-9aaf-f5db0ddedf87,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-392f05fb-9c5d-45f4-9fd5-e063df15604a,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-f152458f-a96f-4fe4-8141-5c5e9274040b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-173567703-172.17.0.9-1595866420495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36946,DS-d5b67db1-088a-4a3f-a9eb-b442ab86d8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-d6cfad69-f09b-418e-9999-95858c53fa90,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-64c17375-5dc7-46ef-98a2-30e3a3ca821e,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-d591ee55-31cf-4f77-95ee-1ba6fd4ae5da,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-fd5d1b7a-3e34-41d9-8c16-1835fc8420a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-a4242a39-b61d-4971-8072-2ce094ef78e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35612,DS-ad463f55-745c-4018-9df8-0b6392bfe27f,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-c1bf0c47-a583-40d1-bd87-b558580b6a27,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-173567703-172.17.0.9-1595866420495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36946,DS-d5b67db1-088a-4a3f-a9eb-b442ab86d8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-d6cfad69-f09b-418e-9999-95858c53fa90,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-64c17375-5dc7-46ef-98a2-30e3a3ca821e,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-d591ee55-31cf-4f77-95ee-1ba6fd4ae5da,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-fd5d1b7a-3e34-41d9-8c16-1835fc8420a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-a4242a39-b61d-4971-8072-2ce094ef78e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35612,DS-ad463f55-745c-4018-9df8-0b6392bfe27f,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-c1bf0c47-a583-40d1-bd87-b558580b6a27,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1007718626-172.17.0.9-1595866457427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39836,DS-5bd1ddf1-c75d-4773-a02c-da5a5dd15917,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-eafc9e75-8bf6-45cf-b441-b084046f91f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-fa8a3343-5a3e-4d00-80a0-d7103f826613,DISK], DatanodeInfoWithStorage[127.0.0.1:39200,DS-1b47e363-8af3-4d22-ae81-d9daac4f484c,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-cd785f17-6c7b-4879-97b0-d70cfb665fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-8e376bcf-add6-4321-83b5-fc7621a062e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-9963de4a-69c6-4570-9a7c-1220cb238c63,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-9c9326fe-774a-4d74-be89-bae6c3b5082f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1007718626-172.17.0.9-1595866457427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39836,DS-5bd1ddf1-c75d-4773-a02c-da5a5dd15917,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-eafc9e75-8bf6-45cf-b441-b084046f91f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-fa8a3343-5a3e-4d00-80a0-d7103f826613,DISK], DatanodeInfoWithStorage[127.0.0.1:39200,DS-1b47e363-8af3-4d22-ae81-d9daac4f484c,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-cd785f17-6c7b-4879-97b0-d70cfb665fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-8e376bcf-add6-4321-83b5-fc7621a062e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-9963de4a-69c6-4570-9a7c-1220cb238c63,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-9c9326fe-774a-4d74-be89-bae6c3b5082f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-503168989-172.17.0.9-1595866568228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39695,DS-3e0d43e7-a887-4bb4-a520-deb631f2f01f,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-7d1c8ac0-238c-47c5-8d4b-ac0a06fa0ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-a8599edb-f0a1-4a02-ad8e-3478043f6044,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-80849f8e-7b87-48c7-8ed6-fd470c05c21b,DISK], DatanodeInfoWithStorage[127.0.0.1:46239,DS-99f6ba0e-3111-48e1-a5c3-a0a7be997055,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-6568e83a-0ac7-40b8-9e9d-7a8c3b8fc85a,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-c9722368-7de1-4d4d-8ea1-1ee15acabdb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-9f80db7d-760b-431d-beb6-90756974862f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-503168989-172.17.0.9-1595866568228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39695,DS-3e0d43e7-a887-4bb4-a520-deb631f2f01f,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-7d1c8ac0-238c-47c5-8d4b-ac0a06fa0ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-a8599edb-f0a1-4a02-ad8e-3478043f6044,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-80849f8e-7b87-48c7-8ed6-fd470c05c21b,DISK], DatanodeInfoWithStorage[127.0.0.1:46239,DS-99f6ba0e-3111-48e1-a5c3-a0a7be997055,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-6568e83a-0ac7-40b8-9e9d-7a8c3b8fc85a,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-c9722368-7de1-4d4d-8ea1-1ee15acabdb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-9f80db7d-760b-431d-beb6-90756974862f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891760541-172.17.0.9-1595866704859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36625,DS-40551c67-b97b-443f-b99e-1c1a90085f29,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-c8e4dd21-9439-4856-8971-f251733c36a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43863,DS-c5dd31b3-cc4d-45f6-acf0-fba196e9c744,DISK], DatanodeInfoWithStorage[127.0.0.1:34186,DS-9d6ad267-b249-42ee-8b1c-8a1fe35c9d32,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-04402003-0fd1-43f4-bb46-4469b566a75f,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-b654e65f-f842-425a-83b8-57ae60443685,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-46f24d4e-9109-489c-a384-d5aec9cc1094,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-b82a30df-4f6c-4888-b37c-99a92e81271f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891760541-172.17.0.9-1595866704859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36625,DS-40551c67-b97b-443f-b99e-1c1a90085f29,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-c8e4dd21-9439-4856-8971-f251733c36a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43863,DS-c5dd31b3-cc4d-45f6-acf0-fba196e9c744,DISK], DatanodeInfoWithStorage[127.0.0.1:34186,DS-9d6ad267-b249-42ee-8b1c-8a1fe35c9d32,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-04402003-0fd1-43f4-bb46-4469b566a75f,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-b654e65f-f842-425a-83b8-57ae60443685,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-46f24d4e-9109-489c-a384-d5aec9cc1094,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-b82a30df-4f6c-4888-b37c-99a92e81271f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-608789045-172.17.0.9-1595866776344:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43620,DS-09227f23-e74e-4dad-a0e8-2ad1435f804d,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-bd1c8094-3c37-4e8d-9841-250d93d9019d,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-926557ba-e8bd-4721-8ee9-1ed4a85840fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-26ef87d2-987c-4ada-8a37-48e60e0be636,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-91342e57-248d-4a8f-b831-9426c695b1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-597a334d-0a88-4e6a-a98a-8e9be90e49ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41678,DS-64bde295-d5f8-465b-8091-2027e1c04732,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-6aa9b9e3-ee37-46f5-bdf7-fd12fe58364c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-608789045-172.17.0.9-1595866776344:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43620,DS-09227f23-e74e-4dad-a0e8-2ad1435f804d,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-bd1c8094-3c37-4e8d-9841-250d93d9019d,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-926557ba-e8bd-4721-8ee9-1ed4a85840fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-26ef87d2-987c-4ada-8a37-48e60e0be636,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-91342e57-248d-4a8f-b831-9426c695b1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-597a334d-0a88-4e6a-a98a-8e9be90e49ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41678,DS-64bde295-d5f8-465b-8091-2027e1c04732,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-6aa9b9e3-ee37-46f5-bdf7-fd12fe58364c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-198594303-172.17.0.9-1595866806247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37687,DS-56cae641-7c20-46ac-8a30-c15fee148f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46681,DS-4f27338a-d1cb-473c-9e19-6a1e5ba932bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42923,DS-ecff6d54-c84f-4bed-bc31-0d2fa1f7d90e,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-9e1ff0c7-c9fe-4222-8000-1d2030ac770d,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-692174b1-b342-46c0-8fb0-b081d51477c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-3bf4f3dd-a9d3-48d5-a6df-d68639777de6,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-24f58aa1-5f57-430c-8577-90b1a6a48333,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-9221d1c9-cc5f-406b-b5bd-88fa3821b27d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-198594303-172.17.0.9-1595866806247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37687,DS-56cae641-7c20-46ac-8a30-c15fee148f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46681,DS-4f27338a-d1cb-473c-9e19-6a1e5ba932bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42923,DS-ecff6d54-c84f-4bed-bc31-0d2fa1f7d90e,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-9e1ff0c7-c9fe-4222-8000-1d2030ac770d,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-692174b1-b342-46c0-8fb0-b081d51477c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-3bf4f3dd-a9d3-48d5-a6df-d68639777de6,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-24f58aa1-5f57-430c-8577-90b1a6a48333,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-9221d1c9-cc5f-406b-b5bd-88fa3821b27d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-609347009-172.17.0.9-1595867023717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34929,DS-ab78b740-0c10-493b-a6b4-81dc0522c22f,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-b02d8087-7a01-467b-9471-0641e1375343,DISK], DatanodeInfoWithStorage[127.0.0.1:46025,DS-09b41985-e5a5-4bf3-a179-c23b1fd62f14,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-84257ab3-1863-4cbb-b24e-a3e687b56ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:35139,DS-e0ef7045-7b1a-4500-bd61-1f14f644d182,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-1e43ee37-0096-47b8-b2e0-a3328b7bb28b,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-715611c7-3b1a-4482-be1c-f1cf544417fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43419,DS-d9606c77-c1c6-43d5-a196-4fc504f34065,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-609347009-172.17.0.9-1595867023717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34929,DS-ab78b740-0c10-493b-a6b4-81dc0522c22f,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-b02d8087-7a01-467b-9471-0641e1375343,DISK], DatanodeInfoWithStorage[127.0.0.1:46025,DS-09b41985-e5a5-4bf3-a179-c23b1fd62f14,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-84257ab3-1863-4cbb-b24e-a3e687b56ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:35139,DS-e0ef7045-7b1a-4500-bd61-1f14f644d182,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-1e43ee37-0096-47b8-b2e0-a3328b7bb28b,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-715611c7-3b1a-4482-be1c-f1cf544417fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43419,DS-d9606c77-c1c6-43d5-a196-4fc504f34065,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-976790696-172.17.0.9-1595867126217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44623,DS-fb8b087e-1fe9-4d5e-a1df-b64f860f4c95,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-c0a99521-5116-4151-a1c3-24baf7fd65d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-25c766e7-068a-4c93-be56-bf164d44e126,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-3fda9f79-28ec-4cb1-a4c5-b9a0949a6457,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-2a435659-2cf9-4b9d-9376-3c6cdf7dff62,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-a2940542-d0eb-4781-a47b-09e01c54b586,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-184456d2-c6c3-453b-bfc9-f57765c02145,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-53d8937c-7a31-4ff8-bbf3-552247d3aef6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-976790696-172.17.0.9-1595867126217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44623,DS-fb8b087e-1fe9-4d5e-a1df-b64f860f4c95,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-c0a99521-5116-4151-a1c3-24baf7fd65d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-25c766e7-068a-4c93-be56-bf164d44e126,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-3fda9f79-28ec-4cb1-a4c5-b9a0949a6457,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-2a435659-2cf9-4b9d-9376-3c6cdf7dff62,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-a2940542-d0eb-4781-a47b-09e01c54b586,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-184456d2-c6c3-453b-bfc9-f57765c02145,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-53d8937c-7a31-4ff8-bbf3-552247d3aef6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 15 out of 50
v1v1v2v2 failed with probability 18 out of 50
result: false positive !!!
Total execution time in seconds : 5263
