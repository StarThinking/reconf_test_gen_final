reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1657229045-172.17.0.4-1595609641501:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33043,DS-154a07c6-465a-4398-a3ec-0b0a95923057,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-574ee999-ea25-4d6d-988e-2508305ae420,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-2a485f54-5106-484f-8c9c-bf079b23bf3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-8123001b-ad78-460f-91cd-d1175c76b013,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-4b756968-d048-4701-b481-2f38130a542a,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-9f58ad36-22c0-4650-a574-91efbfa38546,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-618a7b2c-5cd1-4b7f-b335-28c8479a1255,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-630efa51-c9c1-4e75-bb58-8ec7c3a1715e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1657229045-172.17.0.4-1595609641501:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33043,DS-154a07c6-465a-4398-a3ec-0b0a95923057,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-574ee999-ea25-4d6d-988e-2508305ae420,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-2a485f54-5106-484f-8c9c-bf079b23bf3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-8123001b-ad78-460f-91cd-d1175c76b013,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-4b756968-d048-4701-b481-2f38130a542a,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-9f58ad36-22c0-4650-a574-91efbfa38546,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-618a7b2c-5cd1-4b7f-b335-28c8479a1255,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-630efa51-c9c1-4e75-bb58-8ec7c3a1715e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-573929455-172.17.0.4-1595610339146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45637,DS-82231a88-e2fc-4df9-a809-c461690aa81d,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-307005e5-12cf-4288-9a29-18ffc816b203,DISK], DatanodeInfoWithStorage[127.0.0.1:40719,DS-6ecc2058-a1da-4e71-8fe1-35742f5ceac8,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-58153f81-6399-4f0c-beed-b99fea5d138f,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-55594250-1bdb-4959-83e5-be34f297b21f,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-86236157-a248-49de-8603-537009043866,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-27f39395-cd0a-4c13-9cab-d60f6c4395ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-9f83efbe-5b00-48e8-b15f-966d428a0072,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-573929455-172.17.0.4-1595610339146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45637,DS-82231a88-e2fc-4df9-a809-c461690aa81d,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-307005e5-12cf-4288-9a29-18ffc816b203,DISK], DatanodeInfoWithStorage[127.0.0.1:40719,DS-6ecc2058-a1da-4e71-8fe1-35742f5ceac8,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-58153f81-6399-4f0c-beed-b99fea5d138f,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-55594250-1bdb-4959-83e5-be34f297b21f,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-86236157-a248-49de-8603-537009043866,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-27f39395-cd0a-4c13-9cab-d60f6c4395ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-9f83efbe-5b00-48e8-b15f-966d428a0072,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-285581091-172.17.0.4-1595610459195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39875,DS-92f76538-b665-4aa5-bec4-6ec305e1f5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-576b4462-d723-4680-9740-d67c174d06c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-97b121ee-e90c-47c2-8ea5-258477911728,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-8eaeb19b-fa3b-4df6-8840-3f9952172c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-5503fc45-1a83-4537-8d88-ad8c95959d89,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-07068794-73f6-46e2-b46a-a4e40f086f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-c58a1a58-97ce-439b-88ea-c97cc30719e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-16cdb782-8f03-46dc-b94d-0dec06dbea0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-285581091-172.17.0.4-1595610459195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39875,DS-92f76538-b665-4aa5-bec4-6ec305e1f5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-576b4462-d723-4680-9740-d67c174d06c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-97b121ee-e90c-47c2-8ea5-258477911728,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-8eaeb19b-fa3b-4df6-8840-3f9952172c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-5503fc45-1a83-4537-8d88-ad8c95959d89,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-07068794-73f6-46e2-b46a-a4e40f086f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-c58a1a58-97ce-439b-88ea-c97cc30719e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-16cdb782-8f03-46dc-b94d-0dec06dbea0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1138025254-172.17.0.4-1595610487864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44634,DS-ff85884e-d68a-4f24-a0a7-d6ca55ec1c01,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-f9f46af9-2d2d-42ed-941c-7d727c0b285d,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-28bcd0bb-eb8c-4b5a-8bed-773e3719ef0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42280,DS-8446e433-a38c-4fdc-ac99-08bcea3634c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-a3dc8a43-d734-467c-95f4-f0e454532d49,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-5d072399-8099-4cc1-9fe0-f76d3830a71b,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-34753d4d-c3c3-4ac7-b733-2a2a9c2f2f19,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-2d713a1c-e6b2-429e-b283-5fd43ce141a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1138025254-172.17.0.4-1595610487864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44634,DS-ff85884e-d68a-4f24-a0a7-d6ca55ec1c01,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-f9f46af9-2d2d-42ed-941c-7d727c0b285d,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-28bcd0bb-eb8c-4b5a-8bed-773e3719ef0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42280,DS-8446e433-a38c-4fdc-ac99-08bcea3634c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-a3dc8a43-d734-467c-95f4-f0e454532d49,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-5d072399-8099-4cc1-9fe0-f76d3830a71b,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-34753d4d-c3c3-4ac7-b733-2a2a9c2f2f19,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-2d713a1c-e6b2-429e-b283-5fd43ce141a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-348011724-172.17.0.4-1595610526530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36683,DS-f614c8c1-3cd8-4bea-a26b-a04846c612cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-2d502399-98c4-433c-9958-c7089918c0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-4783794c-624c-4e0c-83b4-d8272bea31d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35209,DS-c9437b1b-e5f3-48b7-b82b-b89834a4dea2,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-8b0c83e8-1ba4-453b-a932-19b7aa1d3b91,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-4d3b1777-d247-489d-ad6b-fd39581e67e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-b567fc6f-c2c0-48d3-a6cd-29d75a98bb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-a8a0aa4d-324d-4fe0-acf7-08cbe3017e1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-348011724-172.17.0.4-1595610526530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36683,DS-f614c8c1-3cd8-4bea-a26b-a04846c612cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-2d502399-98c4-433c-9958-c7089918c0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-4783794c-624c-4e0c-83b4-d8272bea31d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35209,DS-c9437b1b-e5f3-48b7-b82b-b89834a4dea2,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-8b0c83e8-1ba4-453b-a932-19b7aa1d3b91,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-4d3b1777-d247-489d-ad6b-fd39581e67e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-b567fc6f-c2c0-48d3-a6cd-29d75a98bb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-a8a0aa4d-324d-4fe0-acf7-08cbe3017e1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1297621579-172.17.0.4-1595611243392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35121,DS-dc608735-d85f-44ab-9b4a-9592f5da72c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-f1f75bc7-2df4-4bd8-8cb4-c01d24145cab,DISK], DatanodeInfoWithStorage[127.0.0.1:38361,DS-cfc2298b-74f8-4e88-bd69-4e418805bceb,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-12edbe25-fa9c-482d-81c3-17c32c526870,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-7c8fb980-5c53-458c-97a0-b4837238edb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-ba2a0ed0-0299-4967-a0b9-ae5f78df898b,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-56ff1334-0da0-4611-97ab-88ef4b20f546,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-16f3adb1-7cb5-4dcd-af0a-e4e2ba0a1291,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1297621579-172.17.0.4-1595611243392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35121,DS-dc608735-d85f-44ab-9b4a-9592f5da72c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-f1f75bc7-2df4-4bd8-8cb4-c01d24145cab,DISK], DatanodeInfoWithStorage[127.0.0.1:38361,DS-cfc2298b-74f8-4e88-bd69-4e418805bceb,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-12edbe25-fa9c-482d-81c3-17c32c526870,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-7c8fb980-5c53-458c-97a0-b4837238edb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-ba2a0ed0-0299-4967-a0b9-ae5f78df898b,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-56ff1334-0da0-4611-97ab-88ef4b20f546,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-16f3adb1-7cb5-4dcd-af0a-e4e2ba0a1291,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1878810890-172.17.0.4-1595611356080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46169,DS-d9be822d-52a5-41e7-9912-0774760ce316,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-a2a0b966-1a62-4be5-9a4e-6368c2ea35ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42337,DS-df954b3d-e71c-4683-b319-99e409109965,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-6d0131ae-1d5a-4f5c-ad77-66a37c738aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-416dc614-3064-4972-bf82-62b289d84d86,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-b20ae574-dc9b-4e09-95f1-9e86202a5984,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-7e638a7c-df19-4f45-a66f-c51ac093d007,DISK], DatanodeInfoWithStorage[127.0.0.1:41849,DS-a1afe094-3cf4-481f-b18f-4e3d9e140926,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1878810890-172.17.0.4-1595611356080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46169,DS-d9be822d-52a5-41e7-9912-0774760ce316,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-a2a0b966-1a62-4be5-9a4e-6368c2ea35ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42337,DS-df954b3d-e71c-4683-b319-99e409109965,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-6d0131ae-1d5a-4f5c-ad77-66a37c738aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-416dc614-3064-4972-bf82-62b289d84d86,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-b20ae574-dc9b-4e09-95f1-9e86202a5984,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-7e638a7c-df19-4f45-a66f-c51ac093d007,DISK], DatanodeInfoWithStorage[127.0.0.1:41849,DS-a1afe094-3cf4-481f-b18f-4e3d9e140926,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-296965508-172.17.0.4-1595611394524:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45098,DS-3bd98d13-0dea-4785-9eeb-321ab10f000d,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-6a3d4ffb-f9c6-4b27-acac-5b3ed2495dde,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-7448a464-c90c-4095-aee8-18b8fba23429,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-c9cb375a-ec9d-4311-8242-d32ef0af2356,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-5da9f86c-ec68-46d7-8fad-3926ed770991,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-a5e9288d-6a3f-41cc-bfad-641662ae9c34,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-32e0c6e0-d42f-4fb3-900d-6eca49476e21,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-edeaddf6-f063-408d-a9db-5a57c7f7ffa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-296965508-172.17.0.4-1595611394524:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45098,DS-3bd98d13-0dea-4785-9eeb-321ab10f000d,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-6a3d4ffb-f9c6-4b27-acac-5b3ed2495dde,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-7448a464-c90c-4095-aee8-18b8fba23429,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-c9cb375a-ec9d-4311-8242-d32ef0af2356,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-5da9f86c-ec68-46d7-8fad-3926ed770991,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-a5e9288d-6a3f-41cc-bfad-641662ae9c34,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-32e0c6e0-d42f-4fb3-900d-6eca49476e21,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-edeaddf6-f063-408d-a9db-5a57c7f7ffa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-958795488-172.17.0.4-1595611708904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36111,DS-80b37111-7938-4a01-891d-a5ebeac152c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-e3135ab5-91f1-4e98-ba23-58a5cfb303e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-3835e8ed-de2c-4614-b184-44334107c04b,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-4d5053cc-49c0-4027-871b-11b831c89c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-af3e9cb2-d6cd-4d22-b159-e03921c79024,DISK], DatanodeInfoWithStorage[127.0.0.1:40911,DS-27254a3f-7ed6-4959-98c2-2d6921ef5904,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-d891f57a-deb9-4c69-9e63-938d3f2d4174,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-18a51001-dc8d-4c93-b884-a57715b5f3d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-958795488-172.17.0.4-1595611708904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36111,DS-80b37111-7938-4a01-891d-a5ebeac152c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-e3135ab5-91f1-4e98-ba23-58a5cfb303e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-3835e8ed-de2c-4614-b184-44334107c04b,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-4d5053cc-49c0-4027-871b-11b831c89c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-af3e9cb2-d6cd-4d22-b159-e03921c79024,DISK], DatanodeInfoWithStorage[127.0.0.1:40911,DS-27254a3f-7ed6-4959-98c2-2d6921ef5904,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-d891f57a-deb9-4c69-9e63-938d3f2d4174,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-18a51001-dc8d-4c93-b884-a57715b5f3d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1990187751-172.17.0.4-1595611820175:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39417,DS-44b3f6e8-9ff3-43bf-a183-5cffddc5c3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-69b88e20-e3bb-4838-b864-e68ca82dee5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-5b0f9323-75a9-4728-93ff-287a3e516756,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-447be613-935e-4c2b-af5f-9ae0493f73e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-4ec719d8-8b53-4e70-88eb-afda5d62912b,DISK], DatanodeInfoWithStorage[127.0.0.1:46223,DS-c8f60723-a048-4ea8-9aaa-f01019496afb,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-527e79f4-51f3-45d0-9396-50afdc8edfa0,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-788ce7ca-8a2f-44f5-bda9-3d30b01749ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1990187751-172.17.0.4-1595611820175:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39417,DS-44b3f6e8-9ff3-43bf-a183-5cffddc5c3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-69b88e20-e3bb-4838-b864-e68ca82dee5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-5b0f9323-75a9-4728-93ff-287a3e516756,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-447be613-935e-4c2b-af5f-9ae0493f73e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-4ec719d8-8b53-4e70-88eb-afda5d62912b,DISK], DatanodeInfoWithStorage[127.0.0.1:46223,DS-c8f60723-a048-4ea8-9aaa-f01019496afb,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-527e79f4-51f3-45d0-9396-50afdc8edfa0,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-788ce7ca-8a2f-44f5-bda9-3d30b01749ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-189929472-172.17.0.4-1595612010882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46578,DS-36f11c54-c411-4340-9297-469506767d10,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-9a20d8b3-7f63-466b-a521-b0cc5cf7b6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-510bbf3e-086b-48f6-9aa4-13a22d7296e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-96dcb2f6-d23f-41bc-a567-83f76ef2d050,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-b957d67a-1212-4652-9cd4-d56395d5ba9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-692f3df5-ee6b-4c95-a33e-79f272dd600b,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-b5330b7d-f706-4956-9480-3a81b5d98e20,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-88151d30-cddc-4c60-a10d-72fd6221c601,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-189929472-172.17.0.4-1595612010882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46578,DS-36f11c54-c411-4340-9297-469506767d10,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-9a20d8b3-7f63-466b-a521-b0cc5cf7b6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-510bbf3e-086b-48f6-9aa4-13a22d7296e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-96dcb2f6-d23f-41bc-a567-83f76ef2d050,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-b957d67a-1212-4652-9cd4-d56395d5ba9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-692f3df5-ee6b-4c95-a33e-79f272dd600b,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-b5330b7d-f706-4956-9480-3a81b5d98e20,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-88151d30-cddc-4c60-a10d-72fd6221c601,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1693592604-172.17.0.4-1595612097735:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41563,DS-ebb1d738-0c67-492b-ad2c-6fb72c331374,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-92f95d03-219e-4f58-a3f0-f1ec9a5070a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-850d4f2a-20b5-46ad-bf31-a5a73dad3d25,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-89585def-557a-40f2-b3ae-6dce1443c928,DISK], DatanodeInfoWithStorage[127.0.0.1:34115,DS-8e10eb61-00c8-4b0b-a7e6-6c7f88fb2004,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-5ec76f90-1982-4260-af6b-7018381c0382,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-643ce508-3bff-428c-981a-51e6955b4ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-474328f2-4fe7-46cc-a75b-89a76f23bc6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1693592604-172.17.0.4-1595612097735:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41563,DS-ebb1d738-0c67-492b-ad2c-6fb72c331374,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-92f95d03-219e-4f58-a3f0-f1ec9a5070a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-850d4f2a-20b5-46ad-bf31-a5a73dad3d25,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-89585def-557a-40f2-b3ae-6dce1443c928,DISK], DatanodeInfoWithStorage[127.0.0.1:34115,DS-8e10eb61-00c8-4b0b-a7e6-6c7f88fb2004,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-5ec76f90-1982-4260-af6b-7018381c0382,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-643ce508-3bff-428c-981a-51e6955b4ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-474328f2-4fe7-46cc-a75b-89a76f23bc6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-79899809-172.17.0.4-1595612350590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40089,DS-f20d5c7b-67b6-4e35-95d7-1f4bf7a92fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:35146,DS-dcaab686-6313-4aa7-a648-eac0caa3497a,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-2ebb1154-7d86-42cb-a260-85f50fe56b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-4520d4dc-fa1c-41f3-af6d-210fbfd5cb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-d776c0dd-3150-4d61-9642-2da53c1ae4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-c2f77fd8-52d9-40a8-afef-ffa8dab9a6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41463,DS-ca51e352-28e3-4f57-a4bc-9bd7218aaa17,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-2170d546-1ca3-49c9-b42e-8101661133d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-79899809-172.17.0.4-1595612350590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40089,DS-f20d5c7b-67b6-4e35-95d7-1f4bf7a92fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:35146,DS-dcaab686-6313-4aa7-a648-eac0caa3497a,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-2ebb1154-7d86-42cb-a260-85f50fe56b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-4520d4dc-fa1c-41f3-af6d-210fbfd5cb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-d776c0dd-3150-4d61-9642-2da53c1ae4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-c2f77fd8-52d9-40a8-afef-ffa8dab9a6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41463,DS-ca51e352-28e3-4f57-a4bc-9bd7218aaa17,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-2170d546-1ca3-49c9-b42e-8101661133d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-928452072-172.17.0.4-1595612596705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33439,DS-6a7ebd09-6a64-4dad-b67b-c9d803c3bf86,DISK], DatanodeInfoWithStorage[127.0.0.1:41473,DS-a701c3a2-ce0e-4626-a07c-d3a5ac3e0896,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-227e5611-a390-4654-90e1-e05735809576,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-e8994745-604e-4407-91cb-7b13dbee451e,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-bbfbb099-203f-4843-aff4-69b336c56948,DISK], DatanodeInfoWithStorage[127.0.0.1:32924,DS-d229f21c-1874-41a0-8d02-ff8192b1f416,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-c573565b-8c6a-4044-9441-c1e93175cd48,DISK], DatanodeInfoWithStorage[127.0.0.1:40932,DS-df5f4a0a-3e13-4108-8761-e84492f05cc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-928452072-172.17.0.4-1595612596705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33439,DS-6a7ebd09-6a64-4dad-b67b-c9d803c3bf86,DISK], DatanodeInfoWithStorage[127.0.0.1:41473,DS-a701c3a2-ce0e-4626-a07c-d3a5ac3e0896,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-227e5611-a390-4654-90e1-e05735809576,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-e8994745-604e-4407-91cb-7b13dbee451e,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-bbfbb099-203f-4843-aff4-69b336c56948,DISK], DatanodeInfoWithStorage[127.0.0.1:32924,DS-d229f21c-1874-41a0-8d02-ff8192b1f416,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-c573565b-8c6a-4044-9441-c1e93175cd48,DISK], DatanodeInfoWithStorage[127.0.0.1:40932,DS-df5f4a0a-3e13-4108-8761-e84492f05cc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-42196063-172.17.0.4-1595612797075:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45319,DS-5dd98466-ac43-4f44-bfda-61b603b0e245,DISK], DatanodeInfoWithStorage[127.0.0.1:46816,DS-cd490bb4-954d-45eb-ba97-312f0045ba13,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-5996bede-54fb-4855-98a2-73810a40111e,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-65d5f242-9c68-4c26-9948-5bda7072840d,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-f41d5d5d-fd13-43fe-8802-63ba7d2c8aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-803dbbb3-a5e5-44ef-98b6-3b8201429e99,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-8aa0d2dc-22c2-44c0-baf7-7f5b15c9d517,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-36c3dd55-ab94-4379-bac5-a250c2a059e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-42196063-172.17.0.4-1595612797075:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45319,DS-5dd98466-ac43-4f44-bfda-61b603b0e245,DISK], DatanodeInfoWithStorage[127.0.0.1:46816,DS-cd490bb4-954d-45eb-ba97-312f0045ba13,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-5996bede-54fb-4855-98a2-73810a40111e,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-65d5f242-9c68-4c26-9948-5bda7072840d,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-f41d5d5d-fd13-43fe-8802-63ba7d2c8aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-803dbbb3-a5e5-44ef-98b6-3b8201429e99,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-8aa0d2dc-22c2-44c0-baf7-7f5b15c9d517,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-36c3dd55-ab94-4379-bac5-a250c2a059e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1172364849-172.17.0.4-1595613546417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37491,DS-9c45751b-c265-4e58-8cc1-2db31b74a62a,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-5d8c8d8e-bc21-44ce-a902-1cc70518ea3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-68438641-3142-4a97-9d4a-a2eb5666e02a,DISK], DatanodeInfoWithStorage[127.0.0.1:39785,DS-695b22f2-bc67-44df-b08c-3b256fc3f2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-e9baaf46-0a7d-4470-9ace-4cc2767127ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-891beaa7-f819-43de-8a8f-dd230fd8c64a,DISK], DatanodeInfoWithStorage[127.0.0.1:33648,DS-15c781a2-0341-4b41-9602-a2624b3827d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-db5d1aa0-459b-47a9-8beb-82092f1023e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1172364849-172.17.0.4-1595613546417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37491,DS-9c45751b-c265-4e58-8cc1-2db31b74a62a,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-5d8c8d8e-bc21-44ce-a902-1cc70518ea3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-68438641-3142-4a97-9d4a-a2eb5666e02a,DISK], DatanodeInfoWithStorage[127.0.0.1:39785,DS-695b22f2-bc67-44df-b08c-3b256fc3f2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-e9baaf46-0a7d-4470-9ace-4cc2767127ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-891beaa7-f819-43de-8a8f-dd230fd8c64a,DISK], DatanodeInfoWithStorage[127.0.0.1:33648,DS-15c781a2-0341-4b41-9602-a2624b3827d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-db5d1aa0-459b-47a9-8beb-82092f1023e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-668882685-172.17.0.4-1595614279462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45057,DS-52e0cb11-5e7c-46c9-8960-9f2d4fa9a834,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-c9ccaa17-0495-4ace-93c6-0559c59d9a26,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-35d94532-b358-4a24-a195-e9d1589cff72,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-4e22d8a5-c09b-4816-879b-ef3e7e760560,DISK], DatanodeInfoWithStorage[127.0.0.1:34867,DS-37cce4c0-b95f-46d6-a5c5-1cd7370365b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-5b0ebe91-6e20-411c-a7bb-1c99a2f22fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-ab5cf069-9160-4fc3-b10d-e4f46579086e,DISK], DatanodeInfoWithStorage[127.0.0.1:34809,DS-0a089d55-b086-4434-b026-d380dfe7f4d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-668882685-172.17.0.4-1595614279462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45057,DS-52e0cb11-5e7c-46c9-8960-9f2d4fa9a834,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-c9ccaa17-0495-4ace-93c6-0559c59d9a26,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-35d94532-b358-4a24-a195-e9d1589cff72,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-4e22d8a5-c09b-4816-879b-ef3e7e760560,DISK], DatanodeInfoWithStorage[127.0.0.1:34867,DS-37cce4c0-b95f-46d6-a5c5-1cd7370365b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-5b0ebe91-6e20-411c-a7bb-1c99a2f22fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-ab5cf069-9160-4fc3-b10d-e4f46579086e,DISK], DatanodeInfoWithStorage[127.0.0.1:34809,DS-0a089d55-b086-4434-b026-d380dfe7f4d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1207206483-172.17.0.4-1595614343242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34863,DS-0fca9d7e-b312-4e75-9d81-2ac2bcc183ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-5697c112-2919-4341-b619-896972c22c71,DISK], DatanodeInfoWithStorage[127.0.0.1:45431,DS-d825a15f-8198-4776-9246-642a29c5f693,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-42e1dfe5-f1c3-4e7e-a6a3-d3ab2dbf1b41,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-d8f56ac0-d1fa-4280-b889-6ee682181a58,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-1f628fde-fdfe-4a90-9e47-d59b78150f09,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-adaa6c64-6f4a-4eae-b66f-729aa6cc4c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-cec3a809-57f9-46cf-8bf9-ea6fad4a7b69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1207206483-172.17.0.4-1595614343242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34863,DS-0fca9d7e-b312-4e75-9d81-2ac2bcc183ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-5697c112-2919-4341-b619-896972c22c71,DISK], DatanodeInfoWithStorage[127.0.0.1:45431,DS-d825a15f-8198-4776-9246-642a29c5f693,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-42e1dfe5-f1c3-4e7e-a6a3-d3ab2dbf1b41,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-d8f56ac0-d1fa-4280-b889-6ee682181a58,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-1f628fde-fdfe-4a90-9e47-d59b78150f09,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-adaa6c64-6f4a-4eae-b66f-729aa6cc4c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-cec3a809-57f9-46cf-8bf9-ea6fad4a7b69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5483
