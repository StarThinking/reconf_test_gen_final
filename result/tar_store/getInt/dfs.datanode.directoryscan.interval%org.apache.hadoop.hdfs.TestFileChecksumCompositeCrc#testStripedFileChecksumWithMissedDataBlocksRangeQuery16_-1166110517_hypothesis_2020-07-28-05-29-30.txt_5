reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1873875607-172.17.0.5-1595914373054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37945,DS-60cbcb13-2044-48aa-b939-ba51b866cfc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-6eb3cf5c-d996-41b0-a123-81af9dcb9af3,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-7e8eae73-4a03-4e23-abf1-fff3e89d6a47,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-37fc067f-782a-4bc9-8a36-224542de769f,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-2730a71f-5aeb-403e-aa3f-4940ee4c017f,DISK], DatanodeInfoWithStorage[127.0.0.1:37872,DS-f5939d92-5daf-4f4f-97b5-a9cd13e1aadf,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-c89c98f5-f122-43e8-86ca-7da04ef9d2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-1c502646-983c-45bc-b944-075bd2205810,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1873875607-172.17.0.5-1595914373054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37945,DS-60cbcb13-2044-48aa-b939-ba51b866cfc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-6eb3cf5c-d996-41b0-a123-81af9dcb9af3,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-7e8eae73-4a03-4e23-abf1-fff3e89d6a47,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-37fc067f-782a-4bc9-8a36-224542de769f,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-2730a71f-5aeb-403e-aa3f-4940ee4c017f,DISK], DatanodeInfoWithStorage[127.0.0.1:37872,DS-f5939d92-5daf-4f4f-97b5-a9cd13e1aadf,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-c89c98f5-f122-43e8-86ca-7da04ef9d2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-1c502646-983c-45bc-b944-075bd2205810,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2080208101-172.17.0.5-1595914475992:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39735,DS-b5077fad-9fb8-40ee-9fc1-8d87d6d4273e,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-6ba9fecb-04aa-47c7-ab0c-17e84c80a7be,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-818f2a00-62a1-4dda-b579-83936e6f8475,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-c7120831-3886-47de-a956-cb31e5bc0446,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-123171f6-e242-4d26-84f3-a367f6863dff,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-8844ed13-a624-4a59-a738-fe8911f9713b,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-92349814-4042-4410-a40e-cde001402353,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-81d9591e-48c9-4a15-ad16-a876cdb0dfcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2080208101-172.17.0.5-1595914475992:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39735,DS-b5077fad-9fb8-40ee-9fc1-8d87d6d4273e,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-6ba9fecb-04aa-47c7-ab0c-17e84c80a7be,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-818f2a00-62a1-4dda-b579-83936e6f8475,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-c7120831-3886-47de-a956-cb31e5bc0446,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-123171f6-e242-4d26-84f3-a367f6863dff,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-8844ed13-a624-4a59-a738-fe8911f9713b,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-92349814-4042-4410-a40e-cde001402353,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-81d9591e-48c9-4a15-ad16-a876cdb0dfcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1028792560-172.17.0.5-1595914716403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41035,DS-b2206378-d290-48a3-adc6-ec50aff270f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-203cef22-24d6-4c2b-8ce3-b3cdf1406195,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-2df3a3be-6f09-40f1-9904-3134f6728869,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-5707495e-13f7-4352-bb4a-a16c5403515b,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-840e65a5-e2d0-4f1c-b5b6-ce008af8a9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39588,DS-e911cc4e-254b-4698-889e-0d0e8cfd4982,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-f659d3b1-8732-4d85-abb0-3721b8dfa9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-7cb19a16-f159-4384-907d-0d1f4a1e81ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1028792560-172.17.0.5-1595914716403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41035,DS-b2206378-d290-48a3-adc6-ec50aff270f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-203cef22-24d6-4c2b-8ce3-b3cdf1406195,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-2df3a3be-6f09-40f1-9904-3134f6728869,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-5707495e-13f7-4352-bb4a-a16c5403515b,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-840e65a5-e2d0-4f1c-b5b6-ce008af8a9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39588,DS-e911cc4e-254b-4698-889e-0d0e8cfd4982,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-f659d3b1-8732-4d85-abb0-3721b8dfa9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-7cb19a16-f159-4384-907d-0d1f4a1e81ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1035952362-172.17.0.5-1595914792775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43201,DS-75b47a46-4f9b-497e-956b-4a39b491c7df,DISK], DatanodeInfoWithStorage[127.0.0.1:44273,DS-0c44906e-b69a-4822-8ebb-e8cacb2ae102,DISK], DatanodeInfoWithStorage[127.0.0.1:33012,DS-5c4537c3-94ab-47c1-90e7-377edae4933a,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-f39f4e74-1bee-465b-a0d4-4e19904f3410,DISK], DatanodeInfoWithStorage[127.0.0.1:45833,DS-5e501a3b-02aa-4ac7-af6d-56b727f734ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-2e5fd31b-94e4-4dae-8235-0998f69b75bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-110a573d-18d8-4a4b-982b-3707a3149b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-060b8048-9b04-422b-be71-71396d0820b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1035952362-172.17.0.5-1595914792775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43201,DS-75b47a46-4f9b-497e-956b-4a39b491c7df,DISK], DatanodeInfoWithStorage[127.0.0.1:44273,DS-0c44906e-b69a-4822-8ebb-e8cacb2ae102,DISK], DatanodeInfoWithStorage[127.0.0.1:33012,DS-5c4537c3-94ab-47c1-90e7-377edae4933a,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-f39f4e74-1bee-465b-a0d4-4e19904f3410,DISK], DatanodeInfoWithStorage[127.0.0.1:45833,DS-5e501a3b-02aa-4ac7-af6d-56b727f734ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-2e5fd31b-94e4-4dae-8235-0998f69b75bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-110a573d-18d8-4a4b-982b-3707a3149b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-060b8048-9b04-422b-be71-71396d0820b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2046060173-172.17.0.5-1595915402744:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37078,DS-97ba7fc2-db14-4420-9860-1bbefa521916,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-21d6c0ec-df42-43ff-b287-2b6f7596c942,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-433dbc51-95be-44df-a1f6-ee5fe47f2a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-7227171f-7674-4547-a69c-5a099530f004,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-07b923c9-2c4e-405b-a8f6-3f4de9d80135,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-33bceee4-1420-4d37-9a53-f0b0c4110ade,DISK], DatanodeInfoWithStorage[127.0.0.1:43115,DS-608dc62d-56e1-4d92-a7c6-17edc49f25c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-e7e69491-71d7-44a9-bfcf-a98f44c48c03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2046060173-172.17.0.5-1595915402744:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37078,DS-97ba7fc2-db14-4420-9860-1bbefa521916,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-21d6c0ec-df42-43ff-b287-2b6f7596c942,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-433dbc51-95be-44df-a1f6-ee5fe47f2a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-7227171f-7674-4547-a69c-5a099530f004,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-07b923c9-2c4e-405b-a8f6-3f4de9d80135,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-33bceee4-1420-4d37-9a53-f0b0c4110ade,DISK], DatanodeInfoWithStorage[127.0.0.1:43115,DS-608dc62d-56e1-4d92-a7c6-17edc49f25c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-e7e69491-71d7-44a9-bfcf-a98f44c48c03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1532899597-172.17.0.5-1595915733341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41697,DS-b52607b7-cdcd-4371-9606-34cc94f9e8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-04c595fe-42e5-4a23-8738-fc1a374eae92,DISK], DatanodeInfoWithStorage[127.0.0.1:44228,DS-e73a8b84-9764-4146-9761-1b9730792170,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-07343cf4-335a-4dbc-9560-dbe621b9e3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-37da0de4-1678-4a29-a9c2-eda815398ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-e1bd2bc0-7897-4e58-9789-61d900565921,DISK], DatanodeInfoWithStorage[127.0.0.1:36964,DS-4b093c24-2e80-4e82-b07a-80a89d7671b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39406,DS-e8d26538-7534-441c-974f-2302183c4c66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1532899597-172.17.0.5-1595915733341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41697,DS-b52607b7-cdcd-4371-9606-34cc94f9e8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-04c595fe-42e5-4a23-8738-fc1a374eae92,DISK], DatanodeInfoWithStorage[127.0.0.1:44228,DS-e73a8b84-9764-4146-9761-1b9730792170,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-07343cf4-335a-4dbc-9560-dbe621b9e3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-37da0de4-1678-4a29-a9c2-eda815398ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-e1bd2bc0-7897-4e58-9789-61d900565921,DISK], DatanodeInfoWithStorage[127.0.0.1:36964,DS-4b093c24-2e80-4e82-b07a-80a89d7671b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39406,DS-e8d26538-7534-441c-974f-2302183c4c66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-837242057-172.17.0.5-1595915803272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33430,DS-66b8cc5d-be7b-404c-bdd5-02e4608b0c37,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-cb884434-c287-436a-b82e-9d41942f38bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-fc3fa1ab-55cb-470c-bf63-2ff91482a6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-2443055d-c755-4dc4-9652-40d87cf49080,DISK], DatanodeInfoWithStorage[127.0.0.1:44663,DS-cfd8284d-17cb-42a1-8dfd-daabf019fffc,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-483f4b82-34fd-45fb-a312-41af90973746,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-ce7ca2f1-9b49-488f-8450-91406b3d1ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:34375,DS-43539640-fc08-4fef-86d4-b4aeabf3b015,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-837242057-172.17.0.5-1595915803272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33430,DS-66b8cc5d-be7b-404c-bdd5-02e4608b0c37,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-cb884434-c287-436a-b82e-9d41942f38bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-fc3fa1ab-55cb-470c-bf63-2ff91482a6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-2443055d-c755-4dc4-9652-40d87cf49080,DISK], DatanodeInfoWithStorage[127.0.0.1:44663,DS-cfd8284d-17cb-42a1-8dfd-daabf019fffc,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-483f4b82-34fd-45fb-a312-41af90973746,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-ce7ca2f1-9b49-488f-8450-91406b3d1ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:34375,DS-43539640-fc08-4fef-86d4-b4aeabf3b015,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-97706606-172.17.0.5-1595916324133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43790,DS-672eaf9f-671c-43c4-85f9-73fdfaa11f97,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-cc94f4db-fd24-4184-a7d9-6dc47c175081,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-7f8c7486-377d-4969-a883-495fbf7c5cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38267,DS-b538efb0-2c8e-4047-bb8f-778e00451cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-5e68a9a7-9c03-4d58-a395-26bf26af3a40,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-bfe489a9-1040-4314-b04b-2d6abcb8b017,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-e4b29dc4-ded1-44c8-8a6b-1f3bb1fd8fba,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-c1150e7f-fb85-401d-ad8d-49acb1f8a893,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-97706606-172.17.0.5-1595916324133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43790,DS-672eaf9f-671c-43c4-85f9-73fdfaa11f97,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-cc94f4db-fd24-4184-a7d9-6dc47c175081,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-7f8c7486-377d-4969-a883-495fbf7c5cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38267,DS-b538efb0-2c8e-4047-bb8f-778e00451cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-5e68a9a7-9c03-4d58-a395-26bf26af3a40,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-bfe489a9-1040-4314-b04b-2d6abcb8b017,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-e4b29dc4-ded1-44c8-8a6b-1f3bb1fd8fba,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-c1150e7f-fb85-401d-ad8d-49acb1f8a893,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-562952582-172.17.0.5-1595916988079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46154,DS-496f6efb-921d-4bca-a2f0-67b24cf3601f,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-22af9e3e-7a62-4958-a144-b3de7d7639b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-979ed92a-bc61-406e-861e-142f6738f353,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-6b2f6b0c-664b-4fcd-93fe-5880e0068442,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-66525dfb-8128-49f2-81e0-d28ce92165bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-b2ce090c-176b-4968-827b-22a1180a88aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-4bf769af-6686-4b0c-bbfa-e0f35070b94e,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-6c71a8c3-aef3-4ed0-b8a8-a0bf75b20e1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-562952582-172.17.0.5-1595916988079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46154,DS-496f6efb-921d-4bca-a2f0-67b24cf3601f,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-22af9e3e-7a62-4958-a144-b3de7d7639b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-979ed92a-bc61-406e-861e-142f6738f353,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-6b2f6b0c-664b-4fcd-93fe-5880e0068442,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-66525dfb-8128-49f2-81e0-d28ce92165bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-b2ce090c-176b-4968-827b-22a1180a88aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-4bf769af-6686-4b0c-bbfa-e0f35070b94e,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-6c71a8c3-aef3-4ed0-b8a8-a0bf75b20e1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1992158167-172.17.0.5-1595917049863:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34077,DS-27296573-60e7-46a1-b13b-5acbe15e4345,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-444c0e03-29b7-47c9-857a-58682404d7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45977,DS-5357cc8a-7c36-46ff-bb9d-5e156c681240,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-bbdfcbd7-f22c-4d84-b21e-eb5983145670,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-809da80c-84b5-4949-8250-6357dcf424a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-500dce0e-5657-4ce3-a18d-caff7c604df5,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-fb3ca871-b849-48ac-b1dc-f8707ea8c990,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-309c3179-5e6b-4f73-9707-eaa762e40c48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1992158167-172.17.0.5-1595917049863:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34077,DS-27296573-60e7-46a1-b13b-5acbe15e4345,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-444c0e03-29b7-47c9-857a-58682404d7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45977,DS-5357cc8a-7c36-46ff-bb9d-5e156c681240,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-bbdfcbd7-f22c-4d84-b21e-eb5983145670,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-809da80c-84b5-4949-8250-6357dcf424a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-500dce0e-5657-4ce3-a18d-caff7c604df5,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-fb3ca871-b849-48ac-b1dc-f8707ea8c990,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-309c3179-5e6b-4f73-9707-eaa762e40c48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1846190943-172.17.0.5-1595917394695:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45733,DS-9cfa49f7-1634-4150-bb7a-06998274878f,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-d9719981-c7e4-4244-ba90-866548fc7471,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-7807aed6-cf97-424e-9e1a-e270a7a276c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-ae7c0f38-57c4-4de0-b296-5e11f98ad2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-0849a4e0-6ab3-4fe0-8581-345c72059afe,DISK], DatanodeInfoWithStorage[127.0.0.1:46834,DS-7b23e020-a1bd-49d2-b441-0c8cd0749d78,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-048c383f-b7f8-4f87-9e56-8e6439dee480,DISK], DatanodeInfoWithStorage[127.0.0.1:39145,DS-c8c9c9a7-c477-4c33-903f-44123b1df94e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1846190943-172.17.0.5-1595917394695:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45733,DS-9cfa49f7-1634-4150-bb7a-06998274878f,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-d9719981-c7e4-4244-ba90-866548fc7471,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-7807aed6-cf97-424e-9e1a-e270a7a276c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-ae7c0f38-57c4-4de0-b296-5e11f98ad2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-0849a4e0-6ab3-4fe0-8581-345c72059afe,DISK], DatanodeInfoWithStorage[127.0.0.1:46834,DS-7b23e020-a1bd-49d2-b441-0c8cd0749d78,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-048c383f-b7f8-4f87-9e56-8e6439dee480,DISK], DatanodeInfoWithStorage[127.0.0.1:39145,DS-c8c9c9a7-c477-4c33-903f-44123b1df94e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-66231199-172.17.0.5-1595917492993:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39851,DS-f3972116-d891-4714-8a58-78e98fc35873,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-4018b5c7-ca5b-4e6f-ae40-3d445c08e3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-d1e83d24-76eb-4fc7-8c21-ebdd58ace290,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-300c3f15-f036-46f2-b694-6392e7889b54,DISK], DatanodeInfoWithStorage[127.0.0.1:38500,DS-e007bc53-d4bb-40bf-92f2-7804794dcd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-4632b31d-aeca-4f4a-918c-48485f455556,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-ea382f47-393f-4015-8cfa-9caea8047e07,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-5992398e-3f1f-4dcc-9f09-7d0dca5b675a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-66231199-172.17.0.5-1595917492993:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39851,DS-f3972116-d891-4714-8a58-78e98fc35873,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-4018b5c7-ca5b-4e6f-ae40-3d445c08e3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-d1e83d24-76eb-4fc7-8c21-ebdd58ace290,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-300c3f15-f036-46f2-b694-6392e7889b54,DISK], DatanodeInfoWithStorage[127.0.0.1:38500,DS-e007bc53-d4bb-40bf-92f2-7804794dcd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-4632b31d-aeca-4f4a-918c-48485f455556,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-ea382f47-393f-4015-8cfa-9caea8047e07,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-5992398e-3f1f-4dcc-9f09-7d0dca5b675a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-753359768-172.17.0.5-1595917914659:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34730,DS-3f6c3183-a1f1-44d9-b142-6ba7ac210807,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-1e4eb6e8-9eca-485f-b718-b4be128426eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-592b670e-697d-425d-9888-d5be943e60b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-d2fa7846-b592-4bb5-ae73-5fdd38d46736,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-88702621-5fd2-4134-b946-bd0149673d67,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-4ce8c186-0f18-4df0-b1a6-1e8ec7f28dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-0e02417b-358f-4f2e-9411-33495258fdbd,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-84c979f0-10cf-410e-8198-19f0a68d25b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-753359768-172.17.0.5-1595917914659:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34730,DS-3f6c3183-a1f1-44d9-b142-6ba7ac210807,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-1e4eb6e8-9eca-485f-b718-b4be128426eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-592b670e-697d-425d-9888-d5be943e60b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-d2fa7846-b592-4bb5-ae73-5fdd38d46736,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-88702621-5fd2-4134-b946-bd0149673d67,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-4ce8c186-0f18-4df0-b1a6-1e8ec7f28dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-0e02417b-358f-4f2e-9411-33495258fdbd,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-84c979f0-10cf-410e-8198-19f0a68d25b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1184366476-172.17.0.5-1595917980875:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38956,DS-329d57fc-9f3d-4626-be6c-a48980caa0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-1bf91ed7-5e9a-4781-af11-dbf8d44417ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-b5f34ffc-87f7-40dc-b60f-e584f6aec881,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-ae036351-add8-49c7-a7a6-00bfb16d65fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-09e1dc72-d745-4d32-a379-e48ac6fb60df,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-0c202971-e194-4553-91c7-424c0608ff1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34944,DS-de802fbe-661d-4190-97a9-c9427cf2db5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33696,DS-29554169-1ab5-4fa4-b9f7-9b562cedb60c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1184366476-172.17.0.5-1595917980875:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38956,DS-329d57fc-9f3d-4626-be6c-a48980caa0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-1bf91ed7-5e9a-4781-af11-dbf8d44417ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-b5f34ffc-87f7-40dc-b60f-e584f6aec881,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-ae036351-add8-49c7-a7a6-00bfb16d65fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-09e1dc72-d745-4d32-a379-e48ac6fb60df,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-0c202971-e194-4553-91c7-424c0608ff1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34944,DS-de802fbe-661d-4190-97a9-c9427cf2db5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33696,DS-29554169-1ab5-4fa4-b9f7-9b562cedb60c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-565685345-172.17.0.5-1595918437430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33239,DS-e65c3aea-ea85-4cfe-a6ac-c19dcc82e847,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-b49010df-13e6-4121-be55-b79c367330a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-2cf72a08-4468-47b8-ab2d-ca9cf78d60b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-a66a1589-9abe-44c4-a6f5-2f8ca2976a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-78ff5bc7-0960-45c4-8454-75bc5338b644,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-ed772c6f-a94d-4c0d-9d00-4ec2643b7120,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-dc28f12e-3c1b-42ba-a248-bb4d770b9feb,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-07b47635-8b52-46ef-b284-de1beb70d89c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-565685345-172.17.0.5-1595918437430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33239,DS-e65c3aea-ea85-4cfe-a6ac-c19dcc82e847,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-b49010df-13e6-4121-be55-b79c367330a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-2cf72a08-4468-47b8-ab2d-ca9cf78d60b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-a66a1589-9abe-44c4-a6f5-2f8ca2976a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-78ff5bc7-0960-45c4-8454-75bc5338b644,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-ed772c6f-a94d-4c0d-9d00-4ec2643b7120,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-dc28f12e-3c1b-42ba-a248-bb4d770b9feb,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-07b47635-8b52-46ef-b284-de1beb70d89c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1910132259-172.17.0.5-1595918606843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34811,DS-8c8ede1c-757f-47e3-aba6-111e21e80ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-5ca63b0f-3e23-43b8-9a40-af09e6ec9765,DISK], DatanodeInfoWithStorage[127.0.0.1:33751,DS-4749b3ec-c7fb-4e4e-b701-f968f9339be8,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-9aae1c35-f582-43c8-9a9e-401d58dfe080,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-c997f404-0841-44fe-9e3c-62ce9b57a66e,DISK], DatanodeInfoWithStorage[127.0.0.1:34383,DS-6ec6b779-86e8-4687-ad39-c109dffdf9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-8f6f855d-7e05-43cf-afdc-ece543f6f679,DISK], DatanodeInfoWithStorage[127.0.0.1:40081,DS-d986c1f0-a7d1-4bf8-987f-041f5e83c005,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1910132259-172.17.0.5-1595918606843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34811,DS-8c8ede1c-757f-47e3-aba6-111e21e80ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-5ca63b0f-3e23-43b8-9a40-af09e6ec9765,DISK], DatanodeInfoWithStorage[127.0.0.1:33751,DS-4749b3ec-c7fb-4e4e-b701-f968f9339be8,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-9aae1c35-f582-43c8-9a9e-401d58dfe080,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-c997f404-0841-44fe-9e3c-62ce9b57a66e,DISK], DatanodeInfoWithStorage[127.0.0.1:34383,DS-6ec6b779-86e8-4687-ad39-c109dffdf9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-8f6f855d-7e05-43cf-afdc-ece543f6f679,DISK], DatanodeInfoWithStorage[127.0.0.1:40081,DS-d986c1f0-a7d1-4bf8-987f-041f5e83c005,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-931569723-172.17.0.5-1595918642683:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43999,DS-ef9ebcd3-60f8-4b12-80c2-39148928e3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-ea73483f-1081-4da6-ad34-88d69f1b5fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-7aa69ee0-d2c2-4966-9feb-ec9168649428,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-fd3ad1bf-afe5-4937-bc2a-e0696de881a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-231d4853-0c41-46c5-8ef9-b1d891113180,DISK], DatanodeInfoWithStorage[127.0.0.1:32954,DS-c085d08e-c2c6-43bf-88e4-04fef7c10a41,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-6869eccb-0ea9-4e72-834b-7586c4f8caf1,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-74c60f85-f501-4dd6-a205-b8476e0a56a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-931569723-172.17.0.5-1595918642683:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43999,DS-ef9ebcd3-60f8-4b12-80c2-39148928e3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-ea73483f-1081-4da6-ad34-88d69f1b5fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-7aa69ee0-d2c2-4966-9feb-ec9168649428,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-fd3ad1bf-afe5-4937-bc2a-e0696de881a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-231d4853-0c41-46c5-8ef9-b1d891113180,DISK], DatanodeInfoWithStorage[127.0.0.1:32954,DS-c085d08e-c2c6-43bf-88e4-04fef7c10a41,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-6869eccb-0ea9-4e72-834b-7586c4f8caf1,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-74c60f85-f501-4dd6-a205-b8476e0a56a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-139117179-172.17.0.5-1595918800067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39835,DS-9ca8ae9e-a003-4cb7-9429-eed67d1a5a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-0f8b7ed3-18b2-4701-9776-aa9cc193587c,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-b0cf828b-7231-4856-9c41-32baf07460aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-49889fe8-4dbc-4e2d-aebc-44858be40b08,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-5340892b-5fc2-46a8-9339-0d25139916ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-62f281ed-776e-445a-988b-daa8c0afc4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46535,DS-f7f87290-0af6-4d40-90aa-8c5516eeac26,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-8ba9fbdc-6832-4752-b3c2-92a3d9a019bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-139117179-172.17.0.5-1595918800067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39835,DS-9ca8ae9e-a003-4cb7-9429-eed67d1a5a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-0f8b7ed3-18b2-4701-9776-aa9cc193587c,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-b0cf828b-7231-4856-9c41-32baf07460aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-49889fe8-4dbc-4e2d-aebc-44858be40b08,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-5340892b-5fc2-46a8-9339-0d25139916ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-62f281ed-776e-445a-988b-daa8c0afc4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46535,DS-f7f87290-0af6-4d40-90aa-8c5516eeac26,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-8ba9fbdc-6832-4752-b3c2-92a3d9a019bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-458502954-172.17.0.5-1595918987296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36853,DS-3844ce7e-661f-456f-8bf1-344734bf7139,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-c8599539-9fb1-4f66-be54-bfaa31234aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-0f4be51e-2e78-495e-b421-d3e11a9cf3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-b65096a1-fe52-4702-aca6-8a2297220e23,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-4ec9d0de-bd45-486c-ad84-d32c71dd7797,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-9b303a01-38ce-45d7-9cbe-4364ed9f0cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-ea72ddaf-e1e4-4862-9798-05563c96eaed,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-42ae3cdb-6f6c-489a-a47f-0a96a5de2076,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-458502954-172.17.0.5-1595918987296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36853,DS-3844ce7e-661f-456f-8bf1-344734bf7139,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-c8599539-9fb1-4f66-be54-bfaa31234aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-0f4be51e-2e78-495e-b421-d3e11a9cf3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-b65096a1-fe52-4702-aca6-8a2297220e23,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-4ec9d0de-bd45-486c-ad84-d32c71dd7797,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-9b303a01-38ce-45d7-9cbe-4364ed9f0cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-ea72ddaf-e1e4-4862-9798-05563c96eaed,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-42ae3cdb-6f6c-489a-a47f-0a96a5de2076,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: might be true error
Total execution time in seconds : 4900
