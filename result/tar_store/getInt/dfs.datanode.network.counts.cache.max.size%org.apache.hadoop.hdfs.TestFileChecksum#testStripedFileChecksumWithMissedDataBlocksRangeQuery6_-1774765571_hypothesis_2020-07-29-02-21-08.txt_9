reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1953228467-172.17.0.19-1595989393724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34795,DS-a02851a1-446d-46f1-a7b2-1d92fe7df52b,DISK], DatanodeInfoWithStorage[127.0.0.1:39303,DS-78fdbe28-6a4c-4384-a3fc-610d2c0da7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-3b2d67be-81e9-4342-999a-26cc3ec8dde2,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-7c36478e-64d9-4c28-a7cc-495e7b65f0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-0181a890-2c15-4e2e-86a6-c97c26bb8544,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-aec6a275-fcde-409e-91df-3f1a05d05b73,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-7a89bbd5-8e7e-4478-8fdc-2d69642773d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-7a48ad7f-db0c-4f6b-92ae-267c60ca2566,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1953228467-172.17.0.19-1595989393724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34795,DS-a02851a1-446d-46f1-a7b2-1d92fe7df52b,DISK], DatanodeInfoWithStorage[127.0.0.1:39303,DS-78fdbe28-6a4c-4384-a3fc-610d2c0da7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-3b2d67be-81e9-4342-999a-26cc3ec8dde2,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-7c36478e-64d9-4c28-a7cc-495e7b65f0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-0181a890-2c15-4e2e-86a6-c97c26bb8544,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-aec6a275-fcde-409e-91df-3f1a05d05b73,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-7a89bbd5-8e7e-4478-8fdc-2d69642773d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-7a48ad7f-db0c-4f6b-92ae-267c60ca2566,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1283935553-172.17.0.19-1595989658008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44379,DS-dac3f2b8-a499-4e53-acda-a2fec21b17c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-f56e5978-72d6-443c-860f-a14bebaec913,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-a7efde03-cd8d-4388-8174-9536747634cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-8a4cc9dd-6676-4b3a-8eaf-346dc1968a48,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-d7e2c9bf-57d0-4d20-ab4c-5a8e53e68c13,DISK], DatanodeInfoWithStorage[127.0.0.1:41942,DS-af6668c4-1e1c-475a-b10f-7e3d978437f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-0bd76288-73ef-4c7f-b541-4cf8213a95d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-f4829871-3357-45d3-8f0e-55fd907bb5e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1283935553-172.17.0.19-1595989658008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44379,DS-dac3f2b8-a499-4e53-acda-a2fec21b17c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-f56e5978-72d6-443c-860f-a14bebaec913,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-a7efde03-cd8d-4388-8174-9536747634cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-8a4cc9dd-6676-4b3a-8eaf-346dc1968a48,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-d7e2c9bf-57d0-4d20-ab4c-5a8e53e68c13,DISK], DatanodeInfoWithStorage[127.0.0.1:41942,DS-af6668c4-1e1c-475a-b10f-7e3d978437f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-0bd76288-73ef-4c7f-b541-4cf8213a95d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-f4829871-3357-45d3-8f0e-55fd907bb5e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1886093159-172.17.0.19-1595989859194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40752,DS-c8727884-476e-43bb-830c-47a33b794d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-5db56b07-2d72-4dae-8b4f-73de28864e23,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-a6f52827-91c8-4c99-9d85-2295383eb96e,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-845f5a8e-19da-4a76-a399-259fcf7219ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-06dd31c1-acf0-499e-ae83-62c064eae48f,DISK], DatanodeInfoWithStorage[127.0.0.1:40318,DS-6b94c1d5-56ea-48d9-89b1-e35dc8ccd39f,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-70e34d9b-7b94-4ec1-b9ea-0010b9a46430,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-d2cd0f38-076f-4ba2-a1b9-c72c518f27e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1886093159-172.17.0.19-1595989859194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40752,DS-c8727884-476e-43bb-830c-47a33b794d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-5db56b07-2d72-4dae-8b4f-73de28864e23,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-a6f52827-91c8-4c99-9d85-2295383eb96e,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-845f5a8e-19da-4a76-a399-259fcf7219ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-06dd31c1-acf0-499e-ae83-62c064eae48f,DISK], DatanodeInfoWithStorage[127.0.0.1:40318,DS-6b94c1d5-56ea-48d9-89b1-e35dc8ccd39f,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-70e34d9b-7b94-4ec1-b9ea-0010b9a46430,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-d2cd0f38-076f-4ba2-a1b9-c72c518f27e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1916150685-172.17.0.19-1595989890594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33753,DS-05589969-7f9d-4500-8eec-adb0070fb219,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-a6836efa-1f8b-47ca-852f-c3f3b20d58db,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-1a97c667-0cde-425e-aae0-6529fa9e5c48,DISK], DatanodeInfoWithStorage[127.0.0.1:37675,DS-79cdca38-6da0-42e6-b28e-2783b8427538,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-5e93ed5b-a99b-4507-a93d-38d027b3357f,DISK], DatanodeInfoWithStorage[127.0.0.1:39896,DS-15672a3e-e2f7-4fef-bedf-cf2d5aa2f6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37673,DS-e041496b-6c43-471b-9a22-0e8fb8dc8ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-b2eab62a-def9-4159-bf22-847ccd097380,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1916150685-172.17.0.19-1595989890594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33753,DS-05589969-7f9d-4500-8eec-adb0070fb219,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-a6836efa-1f8b-47ca-852f-c3f3b20d58db,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-1a97c667-0cde-425e-aae0-6529fa9e5c48,DISK], DatanodeInfoWithStorage[127.0.0.1:37675,DS-79cdca38-6da0-42e6-b28e-2783b8427538,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-5e93ed5b-a99b-4507-a93d-38d027b3357f,DISK], DatanodeInfoWithStorage[127.0.0.1:39896,DS-15672a3e-e2f7-4fef-bedf-cf2d5aa2f6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37673,DS-e041496b-6c43-471b-9a22-0e8fb8dc8ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-b2eab62a-def9-4159-bf22-847ccd097380,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2024040908-172.17.0.19-1595989957845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33961,DS-6ba37682-201d-47c6-bc71-28d3299cafea,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-9891c135-6d82-4ad2-914e-0586b07af180,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-d13d7a2b-be82-420b-b464-4bcd0c2dce94,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-3e1d6d5e-aad3-480e-b0cd-ff5891616fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-346d7448-7736-4df3-94d9-db0a494243cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-096e227a-48a3-40d7-ad5a-a80ebe7e4326,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-af94dbbd-5964-4e15-8581-829d2c832bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-9769f0b3-9358-41ff-b045-9a0277f84ba1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2024040908-172.17.0.19-1595989957845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33961,DS-6ba37682-201d-47c6-bc71-28d3299cafea,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-9891c135-6d82-4ad2-914e-0586b07af180,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-d13d7a2b-be82-420b-b464-4bcd0c2dce94,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-3e1d6d5e-aad3-480e-b0cd-ff5891616fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-346d7448-7736-4df3-94d9-db0a494243cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-096e227a-48a3-40d7-ad5a-a80ebe7e4326,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-af94dbbd-5964-4e15-8581-829d2c832bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-9769f0b3-9358-41ff-b045-9a0277f84ba1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1771466988-172.17.0.19-1595990264419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43425,DS-b07970ca-3d37-4cc9-97ca-196574284613,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-05edb44d-5447-45b6-a668-c7fc12d2f935,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-4ecb6be4-40c5-4210-98c6-59679dd5ad46,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-270b9b7d-9817-4d64-8523-e2b3e8b79b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-53f5bac0-9eda-428f-b6e3-eeea12b0ba8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-04f371e3-012d-4678-8750-d11799696d50,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-6bf1dbfd-0fc6-47fc-a57c-671682b25abe,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-a24e2c7c-2f1d-4499-89d4-678b3cf339cc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1771466988-172.17.0.19-1595990264419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43425,DS-b07970ca-3d37-4cc9-97ca-196574284613,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-05edb44d-5447-45b6-a668-c7fc12d2f935,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-4ecb6be4-40c5-4210-98c6-59679dd5ad46,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-270b9b7d-9817-4d64-8523-e2b3e8b79b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-53f5bac0-9eda-428f-b6e3-eeea12b0ba8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-04f371e3-012d-4678-8750-d11799696d50,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-6bf1dbfd-0fc6-47fc-a57c-671682b25abe,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-a24e2c7c-2f1d-4499-89d4-678b3cf339cc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1403116182-172.17.0.19-1595990308313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41474,DS-4c74f6ed-9ed5-4261-b522-85ecadeb14ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-cf752ea0-ec00-4441-9362-e8e32ed74871,DISK], DatanodeInfoWithStorage[127.0.0.1:37766,DS-ae99ba71-d3e0-456f-af57-69ac73a522b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-e8a2c2ae-dd64-44f7-b976-e9da47ea6432,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-47f1ffc2-62ef-4bd1-a1fb-cd94e0a46b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-7376e928-f53a-4e3a-8c6d-b47e445c98c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-1d9f5843-ac5c-499c-8c2c-5c55afdaca46,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-6470b158-b8be-415a-a1b0-da23fc92ba0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1403116182-172.17.0.19-1595990308313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41474,DS-4c74f6ed-9ed5-4261-b522-85ecadeb14ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-cf752ea0-ec00-4441-9362-e8e32ed74871,DISK], DatanodeInfoWithStorage[127.0.0.1:37766,DS-ae99ba71-d3e0-456f-af57-69ac73a522b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-e8a2c2ae-dd64-44f7-b976-e9da47ea6432,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-47f1ffc2-62ef-4bd1-a1fb-cd94e0a46b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-7376e928-f53a-4e3a-8c6d-b47e445c98c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-1d9f5843-ac5c-499c-8c2c-5c55afdaca46,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-6470b158-b8be-415a-a1b0-da23fc92ba0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1318738568-172.17.0.19-1595990385314:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41342,DS-c63c5f83-7074-48ba-97b0-d99d5419ddc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-938d697c-52e1-4cf3-ba9f-06fa53a491da,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-3854497b-c47a-48e7-87a8-008716849024,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-f3ed49dd-13c3-4dbd-8bd3-934680be5dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-346cdf0d-7d58-4559-b7ec-ef31588f3b54,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-2b41cbbb-b6c3-43f2-9ca1-b0093a0f9c84,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-632bb32d-1a35-4cc4-9d41-9e9a120c3b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-6b8ed5b2-79e5-4c90-9fb1-9cc18cf4d3eb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1318738568-172.17.0.19-1595990385314:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41342,DS-c63c5f83-7074-48ba-97b0-d99d5419ddc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-938d697c-52e1-4cf3-ba9f-06fa53a491da,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-3854497b-c47a-48e7-87a8-008716849024,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-f3ed49dd-13c3-4dbd-8bd3-934680be5dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-346cdf0d-7d58-4559-b7ec-ef31588f3b54,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-2b41cbbb-b6c3-43f2-9ca1-b0093a0f9c84,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-632bb32d-1a35-4cc4-9d41-9e9a120c3b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-6b8ed5b2-79e5-4c90-9fb1-9cc18cf4d3eb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1016101195-172.17.0.19-1595990474140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35113,DS-adf90c4d-53e8-4708-a7f1-d27ca7918bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-a99c7e52-6165-4c08-86ab-1fb043537133,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-6ea1694e-c2d4-426b-b373-e2c657737fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-fe133df8-79ae-48f7-8288-8073091ee1f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44636,DS-0d26d7ed-4943-417f-ab37-4317088f883b,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-e1bbbe99-96b5-400e-87ba-4c1bd37a08b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37763,DS-1596ee6d-1849-447b-a105-589cd97e9efa,DISK], DatanodeInfoWithStorage[127.0.0.1:35080,DS-bae52d59-d446-4ba7-ac12-6789d3e45d1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1016101195-172.17.0.19-1595990474140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35113,DS-adf90c4d-53e8-4708-a7f1-d27ca7918bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-a99c7e52-6165-4c08-86ab-1fb043537133,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-6ea1694e-c2d4-426b-b373-e2c657737fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-fe133df8-79ae-48f7-8288-8073091ee1f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44636,DS-0d26d7ed-4943-417f-ab37-4317088f883b,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-e1bbbe99-96b5-400e-87ba-4c1bd37a08b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37763,DS-1596ee6d-1849-447b-a105-589cd97e9efa,DISK], DatanodeInfoWithStorage[127.0.0.1:35080,DS-bae52d59-d446-4ba7-ac12-6789d3e45d1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2001281231-172.17.0.19-1595990649027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35657,DS-a5ab6f31-fa90-4cc4-902c-946175a6ff3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-e0e02799-8dc0-46b8-97b4-5c6fdeca401c,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-b99e269b-ddf4-4078-a521-9f47b53d5539,DISK], DatanodeInfoWithStorage[127.0.0.1:37107,DS-d730aed7-4c14-4561-8ca3-8b7ce677b8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-8d9087b4-b8ca-4b6d-99c6-73afb96a69ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-0d3dbeb7-ee6b-41fb-a266-4a0de37a277d,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-7b2f7b60-974d-4b80-83b5-7ef192f84e43,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-eacea93e-9687-4247-ad67-cc4e09f8bdde,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2001281231-172.17.0.19-1595990649027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35657,DS-a5ab6f31-fa90-4cc4-902c-946175a6ff3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-e0e02799-8dc0-46b8-97b4-5c6fdeca401c,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-b99e269b-ddf4-4078-a521-9f47b53d5539,DISK], DatanodeInfoWithStorage[127.0.0.1:37107,DS-d730aed7-4c14-4561-8ca3-8b7ce677b8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-8d9087b4-b8ca-4b6d-99c6-73afb96a69ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-0d3dbeb7-ee6b-41fb-a266-4a0de37a277d,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-7b2f7b60-974d-4b80-83b5-7ef192f84e43,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-eacea93e-9687-4247-ad67-cc4e09f8bdde,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-638385862-172.17.0.19-1595990784536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45499,DS-9a297b1d-4258-4423-b6f8-a195393beb1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-b4b1cca6-a1e2-463b-aff1-b77796286d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-33836da4-6ddb-4632-ad48-d3ac30bc9a07,DISK], DatanodeInfoWithStorage[127.0.0.1:37440,DS-2869ba23-0f04-4d9d-b5a2-38f2a6809147,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-c16c3af2-2db5-4f82-b071-06bb4edcbaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-1795fac2-cf71-4d1c-8d21-5edf50dacbde,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-731a930a-e4b5-4cbf-8fd1-be92ec7f94ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-e577e4b5-d0a1-478b-850a-127f60f3dd56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-638385862-172.17.0.19-1595990784536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45499,DS-9a297b1d-4258-4423-b6f8-a195393beb1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-b4b1cca6-a1e2-463b-aff1-b77796286d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-33836da4-6ddb-4632-ad48-d3ac30bc9a07,DISK], DatanodeInfoWithStorage[127.0.0.1:37440,DS-2869ba23-0f04-4d9d-b5a2-38f2a6809147,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-c16c3af2-2db5-4f82-b071-06bb4edcbaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-1795fac2-cf71-4d1c-8d21-5edf50dacbde,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-731a930a-e4b5-4cbf-8fd1-be92ec7f94ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-e577e4b5-d0a1-478b-850a-127f60f3dd56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1871780092-172.17.0.19-1595991274120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39725,DS-68d3fd9a-179e-4722-8e07-7ee58543a44d,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-3e8e0e9d-04dc-4c9f-9bf5-cd5f9667c036,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-5d9e6797-b817-4cfe-a9ca-1469559a01df,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-b68d2f3d-9546-40b1-8a99-77d25dd36b01,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-0ee76c7f-9f24-495a-9068-cca187cfa59d,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-23f90ce2-8b8c-469a-8d62-2a643935f02a,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-7b123e88-a8c3-498f-80d7-85375000d454,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-8e42ef49-0771-4884-ac6d-b6b3baef694d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1871780092-172.17.0.19-1595991274120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39725,DS-68d3fd9a-179e-4722-8e07-7ee58543a44d,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-3e8e0e9d-04dc-4c9f-9bf5-cd5f9667c036,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-5d9e6797-b817-4cfe-a9ca-1469559a01df,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-b68d2f3d-9546-40b1-8a99-77d25dd36b01,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-0ee76c7f-9f24-495a-9068-cca187cfa59d,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-23f90ce2-8b8c-469a-8d62-2a643935f02a,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-7b123e88-a8c3-498f-80d7-85375000d454,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-8e42ef49-0771-4884-ac6d-b6b3baef694d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-866088711-172.17.0.19-1595991433608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39396,DS-af0dd499-a1a9-4abb-b97a-337de23b2954,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-4d7a16f9-cdd3-4e87-bad5-98552d459ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-8563a480-4a08-451f-8541-ab7a733ca56e,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-228f3018-d094-435f-bb91-8791e4800071,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-bad70f8f-3910-41c2-9dc2-8b9f84da4b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-b64e1176-e8d4-44f5-856d-e7727da23690,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-3ebf59dd-58d9-49ba-867e-b1f19e3ee6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-61919898-9008-40b0-a354-05a14baff180,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-866088711-172.17.0.19-1595991433608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39396,DS-af0dd499-a1a9-4abb-b97a-337de23b2954,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-4d7a16f9-cdd3-4e87-bad5-98552d459ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-8563a480-4a08-451f-8541-ab7a733ca56e,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-228f3018-d094-435f-bb91-8791e4800071,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-bad70f8f-3910-41c2-9dc2-8b9f84da4b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-b64e1176-e8d4-44f5-856d-e7727da23690,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-3ebf59dd-58d9-49ba-867e-b1f19e3ee6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-61919898-9008-40b0-a354-05a14baff180,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1877373811-172.17.0.19-1595991541793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34067,DS-4008e957-5de3-428c-a4fe-f1e27d0f4d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-ea7aa29c-5822-4c13-bb4a-71b38e167d08,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-597461a6-d1e2-4065-99a8-552b1ce40ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-08941b0a-1c0c-48f6-8ef9-6472e7463f84,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-e715e6fe-9c02-461c-ba5c-73c619df464f,DISK], DatanodeInfoWithStorage[127.0.0.1:35030,DS-68056065-9b92-40e8-8144-0837d91d4c65,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-35c4299a-c023-4a4b-abc0-17cc9112cf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-37a33010-df52-45de-9795-db730076d59f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1877373811-172.17.0.19-1595991541793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34067,DS-4008e957-5de3-428c-a4fe-f1e27d0f4d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-ea7aa29c-5822-4c13-bb4a-71b38e167d08,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-597461a6-d1e2-4065-99a8-552b1ce40ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-08941b0a-1c0c-48f6-8ef9-6472e7463f84,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-e715e6fe-9c02-461c-ba5c-73c619df464f,DISK], DatanodeInfoWithStorage[127.0.0.1:35030,DS-68056065-9b92-40e8-8144-0837d91d4c65,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-35c4299a-c023-4a4b-abc0-17cc9112cf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-37a33010-df52-45de-9795-db730076d59f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700878165-172.17.0.19-1595991737930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38025,DS-62589645-d85f-4f5f-9e13-7d90756db35c,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-89086440-9760-4396-a3af-59f00ffbe9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-c60648c6-0538-4db1-a9b4-f9c94fde11f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-8f04c388-0f2e-49a0-9a7c-e9ef8d31934a,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-5844750d-742e-44cc-b4f6-d5dd515d5742,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-7a48e7fc-c100-427a-9174-f11b48895a47,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-100111c4-1f2e-479a-af84-c9573ff472e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-b840b90d-2026-433a-a375-9d1f4a29e834,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700878165-172.17.0.19-1595991737930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38025,DS-62589645-d85f-4f5f-9e13-7d90756db35c,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-89086440-9760-4396-a3af-59f00ffbe9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-c60648c6-0538-4db1-a9b4-f9c94fde11f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-8f04c388-0f2e-49a0-9a7c-e9ef8d31934a,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-5844750d-742e-44cc-b4f6-d5dd515d5742,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-7a48e7fc-c100-427a-9174-f11b48895a47,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-100111c4-1f2e-479a-af84-c9573ff472e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-b840b90d-2026-433a-a375-9d1f4a29e834,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1512136669-172.17.0.19-1595991870021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35058,DS-00bd6ecb-b56f-4aaa-b96f-1d03a39c29d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-2c5b47a8-4e27-4159-9c91-71f8126657bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-c1427993-68b5-4747-8d8c-634de15149d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43913,DS-4c279750-5c32-4f6f-8a5c-f3f0993e4bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39571,DS-d8f1b2f4-0c2d-4bf2-af8e-8ce7ec0a587a,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-e9c12549-b5bf-4590-8a38-561950fd4554,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-3cc4d7c2-3dac-4d7e-ae2a-25bebacc0e03,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-80c7b762-d1ce-4bee-a389-009a6d2ed303,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1512136669-172.17.0.19-1595991870021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35058,DS-00bd6ecb-b56f-4aaa-b96f-1d03a39c29d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-2c5b47a8-4e27-4159-9c91-71f8126657bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-c1427993-68b5-4747-8d8c-634de15149d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43913,DS-4c279750-5c32-4f6f-8a5c-f3f0993e4bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39571,DS-d8f1b2f4-0c2d-4bf2-af8e-8ce7ec0a587a,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-e9c12549-b5bf-4590-8a38-561950fd4554,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-3cc4d7c2-3dac-4d7e-ae2a-25bebacc0e03,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-80c7b762-d1ce-4bee-a389-009a6d2ed303,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130428396-172.17.0.19-1595991967101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43754,DS-12f1d60f-a1b7-4245-9f3b-c1df5610c6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-649d6867-6747-4b95-825f-eda8e536d3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34994,DS-39600bf9-d89e-4632-9bf0-9ae7f5a0c5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-1412cd6f-d17f-469f-b9cf-756f149d15b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-56c57def-5840-48a4-a373-c82091ce7979,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-a99188c8-684e-40eb-a347-987eb75fe3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39209,DS-1f6eb183-f889-4f7d-b35a-d79ae9019c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46288,DS-524d7a85-72de-4427-8d02-4e9578aaa771,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130428396-172.17.0.19-1595991967101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43754,DS-12f1d60f-a1b7-4245-9f3b-c1df5610c6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-649d6867-6747-4b95-825f-eda8e536d3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34994,DS-39600bf9-d89e-4632-9bf0-9ae7f5a0c5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-1412cd6f-d17f-469f-b9cf-756f149d15b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-56c57def-5840-48a4-a373-c82091ce7979,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-a99188c8-684e-40eb-a347-987eb75fe3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39209,DS-1f6eb183-f889-4f7d-b35a-d79ae9019c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46288,DS-524d7a85-72de-4427-8d02-4e9578aaa771,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-505332726-172.17.0.19-1595992029837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38300,DS-29f05174-d9f6-44ec-9192-79fb3ce0c0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-7261c068-b0be-43db-84ee-6ab9dc08c071,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-c6e25941-dc11-4aff-bc04-d4e09e8ced8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-c24042aa-f786-42a1-8e30-34342a191884,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-53679a69-e171-499f-bccb-226261c5d446,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-a9544d8d-708a-439b-8442-d752fe88acb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-3becbfe2-6184-4981-92cd-2f09b7872421,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-327ca8ed-1ad7-4062-8d17-233aefd2a390,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-505332726-172.17.0.19-1595992029837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38300,DS-29f05174-d9f6-44ec-9192-79fb3ce0c0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-7261c068-b0be-43db-84ee-6ab9dc08c071,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-c6e25941-dc11-4aff-bc04-d4e09e8ced8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-c24042aa-f786-42a1-8e30-34342a191884,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-53679a69-e171-499f-bccb-226261c5d446,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-a9544d8d-708a-439b-8442-d752fe88acb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-3becbfe2-6184-4981-92cd-2f09b7872421,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-327ca8ed-1ad7-4062-8d17-233aefd2a390,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1608119820-172.17.0.19-1595992059409:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37779,DS-b8dbe9ea-6013-4fa9-9a6f-44158741bfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-681f5a7f-9c11-4645-95d0-51302daf58db,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-4d0403d6-adff-4f8c-ab01-137f7b3b7a16,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-f824b9e5-2e5b-4a67-9b8e-c52d02ce7fca,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-b1eff827-f065-4970-b831-f4ff708e82e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-7b206af2-672c-44b1-8973-f3a47183d71e,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-f7f94229-f21a-4665-b365-564ae63384d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-eac125b7-fbc0-4174-a1e0-4d4f2b5ae6f0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1608119820-172.17.0.19-1595992059409:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37779,DS-b8dbe9ea-6013-4fa9-9a6f-44158741bfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-681f5a7f-9c11-4645-95d0-51302daf58db,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-4d0403d6-adff-4f8c-ab01-137f7b3b7a16,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-f824b9e5-2e5b-4a67-9b8e-c52d02ce7fca,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-b1eff827-f065-4970-b831-f4ff708e82e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-7b206af2-672c-44b1-8973-f3a47183d71e,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-f7f94229-f21a-4665-b365-564ae63384d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-eac125b7-fbc0-4174-a1e0-4d4f2b5ae6f0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1978043928-172.17.0.19-1595992160995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44071,DS-48067b41-8996-47cc-8587-7c7f646bd741,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-ae02f8e0-dc81-4233-8e39-c30b247dd05e,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-0a766d1e-4877-44da-8730-56ea4bd54c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-f26c819e-a524-4cfc-866a-729b3080c12e,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-9bcf2c47-81ee-4304-8119-db06858ffdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-03dccc8a-10c3-428c-bd77-5861c9cda1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-d29e90bf-4448-4fc8-8783-898e857275b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-c4bc7858-bfb9-4ab5-8b83-2f1b6bff7ba8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1978043928-172.17.0.19-1595992160995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44071,DS-48067b41-8996-47cc-8587-7c7f646bd741,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-ae02f8e0-dc81-4233-8e39-c30b247dd05e,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-0a766d1e-4877-44da-8730-56ea4bd54c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-f26c819e-a524-4cfc-866a-729b3080c12e,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-9bcf2c47-81ee-4304-8119-db06858ffdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-03dccc8a-10c3-428c-bd77-5861c9cda1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-d29e90bf-4448-4fc8-8783-898e857275b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-c4bc7858-bfb9-4ab5-8b83-2f1b6bff7ba8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1299919753-172.17.0.19-1595992230135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40711,DS-0250d849-41a7-45e9-a48c-8752ced47e75,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-647e9709-709a-4c75-88f6-75d03c2f8aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-11ef2f94-b8a4-4436-b60e-84ffea574178,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-bb71b330-d42f-4aa0-a288-f488995e393c,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-8f176cb0-3cda-498c-a536-4658337602d2,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-47aa0562-72e8-400b-9e40-3005d04b65b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-4cea7c07-9016-44c4-b379-b42536303304,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-343b355c-6f82-4dcc-b86c-88b91cafe768,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1299919753-172.17.0.19-1595992230135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40711,DS-0250d849-41a7-45e9-a48c-8752ced47e75,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-647e9709-709a-4c75-88f6-75d03c2f8aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-11ef2f94-b8a4-4436-b60e-84ffea574178,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-bb71b330-d42f-4aa0-a288-f488995e393c,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-8f176cb0-3cda-498c-a536-4658337602d2,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-47aa0562-72e8-400b-9e40-3005d04b65b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-4cea7c07-9016-44c4-b379-b42536303304,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-343b355c-6f82-4dcc-b86c-88b91cafe768,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2031472413-172.17.0.19-1595992399004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40756,DS-79099654-f221-4394-87ce-b362e6bfb9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-29813893-82f9-423d-8585-ee74d16872fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-c6a7d2e7-e378-4fd4-8631-273db8dfea9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-25e099f2-72ee-4693-bd43-935328ae404f,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-3572ec3c-4dcd-4d5d-b70e-48546df6160b,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-f95226f3-1f89-4fc3-a63a-18c5fc2daecf,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-80ae3bf6-21cb-444f-acf2-d9a5d1ca5286,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-cff1d1b2-cace-44f0-bd18-a11e06ea634b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2031472413-172.17.0.19-1595992399004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40756,DS-79099654-f221-4394-87ce-b362e6bfb9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-29813893-82f9-423d-8585-ee74d16872fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-c6a7d2e7-e378-4fd4-8631-273db8dfea9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-25e099f2-72ee-4693-bd43-935328ae404f,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-3572ec3c-4dcd-4d5d-b70e-48546df6160b,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-f95226f3-1f89-4fc3-a63a-18c5fc2daecf,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-80ae3bf6-21cb-444f-acf2-d9a5d1ca5286,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-cff1d1b2-cace-44f0-bd18-a11e06ea634b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-590023691-172.17.0.19-1595992788203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36254,DS-50eccb6a-8654-47f8-9349-faee226fbc07,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-49094221-b144-4428-9562-c90a24bf5bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-c89de0c7-177f-49c3-8aac-d7fa32db2817,DISK], DatanodeInfoWithStorage[127.0.0.1:45392,DS-c39b845c-d3c0-49e4-b50b-759e2af913f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-296cbd2a-b768-4dd6-bc30-f6247933898f,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-c2165ddf-c49b-4ece-a969-3c861cdb1a58,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-6e8f8fef-93fe-4103-8f56-9049c8c178e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-81fc8b3a-87e2-4a6a-aa1a-3bf6f9c32699,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-590023691-172.17.0.19-1595992788203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36254,DS-50eccb6a-8654-47f8-9349-faee226fbc07,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-49094221-b144-4428-9562-c90a24bf5bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-c89de0c7-177f-49c3-8aac-d7fa32db2817,DISK], DatanodeInfoWithStorage[127.0.0.1:45392,DS-c39b845c-d3c0-49e4-b50b-759e2af913f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-296cbd2a-b768-4dd6-bc30-f6247933898f,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-c2165ddf-c49b-4ece-a969-3c861cdb1a58,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-6e8f8fef-93fe-4103-8f56-9049c8c178e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-81fc8b3a-87e2-4a6a-aa1a-3bf6f9c32699,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1449192706-172.17.0.19-1595992822965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45870,DS-23ba59c4-c117-4aca-a09f-2b0d7adc5503,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-11c8a093-9df8-4aaa-bac2-df22ebf5f096,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-049b2841-841d-45fa-94d3-affadbbc2e73,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-28ea7bcb-f208-4591-9e5e-58be541bceeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-81268ba1-8123-425a-8a33-e3a3673c1006,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-ef9ac719-c673-41d8-b16d-18ccf36df83f,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-3b836a98-c386-4bd0-b071-1a0b4f5dee85,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-815482ac-d6fa-4d1a-a5c2-d411ac3c553b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1449192706-172.17.0.19-1595992822965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45870,DS-23ba59c4-c117-4aca-a09f-2b0d7adc5503,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-11c8a093-9df8-4aaa-bac2-df22ebf5f096,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-049b2841-841d-45fa-94d3-affadbbc2e73,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-28ea7bcb-f208-4591-9e5e-58be541bceeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-81268ba1-8123-425a-8a33-e3a3673c1006,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-ef9ac719-c673-41d8-b16d-18ccf36df83f,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-3b836a98-c386-4bd0-b071-1a0b4f5dee85,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-815482ac-d6fa-4d1a-a5c2-d411ac3c553b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-28593452-172.17.0.19-1595993275027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37987,DS-6798e89b-2016-4c68-bf9a-bb11bc8c1c13,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-76bac33c-358e-4b84-9a96-c944d4839af5,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-8fc86429-8cc2-454e-9a9d-c165b14d4214,DISK], DatanodeInfoWithStorage[127.0.0.1:46329,DS-757a0aa4-4f50-4100-913b-f78f62571fea,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-c8d5da5a-db04-494d-bcfa-fa26db068ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-120f139f-5277-4e63-b681-dda963fdd2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45084,DS-178c3c22-db78-4b60-bb12-316fa4420cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35743,DS-e4c62b8f-5334-414d-9293-d5162b2eaae1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-28593452-172.17.0.19-1595993275027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37987,DS-6798e89b-2016-4c68-bf9a-bb11bc8c1c13,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-76bac33c-358e-4b84-9a96-c944d4839af5,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-8fc86429-8cc2-454e-9a9d-c165b14d4214,DISK], DatanodeInfoWithStorage[127.0.0.1:46329,DS-757a0aa4-4f50-4100-913b-f78f62571fea,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-c8d5da5a-db04-494d-bcfa-fa26db068ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-120f139f-5277-4e63-b681-dda963fdd2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45084,DS-178c3c22-db78-4b60-bb12-316fa4420cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35743,DS-e4c62b8f-5334-414d-9293-d5162b2eaae1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1758305784-172.17.0.19-1595994074924:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44435,DS-0fc6ff9d-2bd5-477d-8583-30de815688b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-8d76fe6b-bf0c-41b3-84cf-a545ff1d8a63,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-06ad062d-a77b-4cb7-bc5c-6674d212ae61,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-8dd3f547-91e6-4774-9611-0987bafe458f,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-64a17d90-27c8-4ca6-b7d7-8ba104c62861,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-0ded8f56-bc69-41d3-a0b9-0c520bd71517,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-2cf1f26b-2066-4348-b338-55a25b66363a,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-076e5f25-b9c4-40f7-a2b0-478ea72f0542,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1758305784-172.17.0.19-1595994074924:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44435,DS-0fc6ff9d-2bd5-477d-8583-30de815688b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-8d76fe6b-bf0c-41b3-84cf-a545ff1d8a63,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-06ad062d-a77b-4cb7-bc5c-6674d212ae61,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-8dd3f547-91e6-4774-9611-0987bafe458f,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-64a17d90-27c8-4ca6-b7d7-8ba104c62861,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-0ded8f56-bc69-41d3-a0b9-0c520bd71517,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-2cf1f26b-2066-4348-b338-55a25b66363a,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-076e5f25-b9c4-40f7-a2b0-478ea72f0542,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1027068023-172.17.0.19-1595994228343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35054,DS-77c02f4c-2b2e-4c7f-894f-a1a88f1a6b40,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-b1aaabc3-69e7-4242-95cc-5cf382eab0de,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-d380885a-b780-46e1-a933-4e330eeac387,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-69b52b97-50fa-4d6e-8d80-9377be542830,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-6271f59f-1f21-4ef9-938c-4139a750c02a,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-74fb3aac-0807-475c-8979-4b7d9c36db78,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-1bbaced5-979d-4eab-b238-6ef998d57874,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-756c709e-85b6-451a-8e47-1fd1b9661459,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1027068023-172.17.0.19-1595994228343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35054,DS-77c02f4c-2b2e-4c7f-894f-a1a88f1a6b40,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-b1aaabc3-69e7-4242-95cc-5cf382eab0de,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-d380885a-b780-46e1-a933-4e330eeac387,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-69b52b97-50fa-4d6e-8d80-9377be542830,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-6271f59f-1f21-4ef9-938c-4139a750c02a,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-74fb3aac-0807-475c-8979-4b7d9c36db78,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-1bbaced5-979d-4eab-b238-6ef998d57874,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-756c709e-85b6-451a-8e47-1fd1b9661459,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124986899-172.17.0.19-1595994265916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39473,DS-c7e1f6bf-5aaf-48f9-96a0-6344284dda9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-e43f1470-f4fb-4838-b438-a7b68bff9220,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-ce892a99-cd74-4bf3-aa06-ba03501e02be,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-24b84789-3568-4ccb-96c4-9105a55be880,DISK], DatanodeInfoWithStorage[127.0.0.1:46844,DS-95810e84-2807-4c17-84df-3b60b208746d,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-2f187b65-a1d9-4951-961b-d06673b5373f,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-db81f726-a193-47f4-afdb-53e6937ba9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-d5ca1f85-6954-4d28-af57-1059ef20a266,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124986899-172.17.0.19-1595994265916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39473,DS-c7e1f6bf-5aaf-48f9-96a0-6344284dda9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-e43f1470-f4fb-4838-b438-a7b68bff9220,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-ce892a99-cd74-4bf3-aa06-ba03501e02be,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-24b84789-3568-4ccb-96c4-9105a55be880,DISK], DatanodeInfoWithStorage[127.0.0.1:46844,DS-95810e84-2807-4c17-84df-3b60b208746d,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-2f187b65-a1d9-4951-961b-d06673b5373f,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-db81f726-a193-47f4-afdb-53e6937ba9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-d5ca1f85-6954-4d28-af57-1059ef20a266,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2041472570-172.17.0.19-1595994383421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44349,DS-852883c2-54a1-40f2-a399-1804ab97e9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-333da3bd-02b4-439b-91cf-2e9e9fa40cea,DISK], DatanodeInfoWithStorage[127.0.0.1:38509,DS-9f379893-87d8-4759-9d22-5d480401cd50,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-af726421-fdec-4da4-aae2-314fbac2960a,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-d42200e4-7bb5-4df2-a319-665c3e40299e,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-81305ac3-52a5-4042-a152-a53a40426077,DISK], DatanodeInfoWithStorage[127.0.0.1:39683,DS-d9fd4a18-c8ef-491d-b849-5108f751d99f,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-7ef90804-b088-41e2-844a-75345ee6a69b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2041472570-172.17.0.19-1595994383421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44349,DS-852883c2-54a1-40f2-a399-1804ab97e9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-333da3bd-02b4-439b-91cf-2e9e9fa40cea,DISK], DatanodeInfoWithStorage[127.0.0.1:38509,DS-9f379893-87d8-4759-9d22-5d480401cd50,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-af726421-fdec-4da4-aae2-314fbac2960a,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-d42200e4-7bb5-4df2-a319-665c3e40299e,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-81305ac3-52a5-4042-a152-a53a40426077,DISK], DatanodeInfoWithStorage[127.0.0.1:39683,DS-d9fd4a18-c8ef-491d-b849-5108f751d99f,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-7ef90804-b088-41e2-844a-75345ee6a69b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 5205
