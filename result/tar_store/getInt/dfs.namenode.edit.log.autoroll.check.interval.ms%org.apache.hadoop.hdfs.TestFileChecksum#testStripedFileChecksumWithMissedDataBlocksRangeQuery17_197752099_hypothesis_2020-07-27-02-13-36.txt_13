reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1789671008-172.17.0.15-1595816274170:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39067,DS-0bd0d9b8-df4c-4558-b262-49984a828307,DISK], DatanodeInfoWithStorage[127.0.0.1:38486,DS-b8f0dff4-d2b0-4969-9adf-1ed72d8e7d77,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-59bf52f0-4076-4a58-be6b-b0203de3f3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-100b0436-f395-43bd-b352-140f856d53de,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-fef5de85-5dc8-4c37-9b34-6a03c85c1940,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-cfcb278b-78b7-4362-8832-772d2932e636,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-a8b86f4d-892b-44f3-8832-3feb8544918d,DISK], DatanodeInfoWithStorage[127.0.0.1:33533,DS-c30ade87-3109-4ed7-982f-0e0e682bdf13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1789671008-172.17.0.15-1595816274170:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39067,DS-0bd0d9b8-df4c-4558-b262-49984a828307,DISK], DatanodeInfoWithStorage[127.0.0.1:38486,DS-b8f0dff4-d2b0-4969-9adf-1ed72d8e7d77,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-59bf52f0-4076-4a58-be6b-b0203de3f3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-100b0436-f395-43bd-b352-140f856d53de,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-fef5de85-5dc8-4c37-9b34-6a03c85c1940,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-cfcb278b-78b7-4362-8832-772d2932e636,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-a8b86f4d-892b-44f3-8832-3feb8544918d,DISK], DatanodeInfoWithStorage[127.0.0.1:33533,DS-c30ade87-3109-4ed7-982f-0e0e682bdf13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-637064126-172.17.0.15-1595816384201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35296,DS-b5c0b248-0f5b-4c7a-8a52-dfffe847c40a,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-a342db47-1949-487b-b5d2-273007d10944,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-53c023e5-bd51-4914-adfb-6cbc1f3006a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-7c2b1070-fb69-4fce-8c22-7bde14eebb45,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-c1c36d5f-72e4-4c00-9cbe-902b7aa72bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:39541,DS-8359a52b-32e7-48d3-af5e-a631f836969a,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-c36dbc31-36ed-4bd7-8633-0dd73efded0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-bc7d1b92-b555-4c25-bdc9-6e98e270e519,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-637064126-172.17.0.15-1595816384201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35296,DS-b5c0b248-0f5b-4c7a-8a52-dfffe847c40a,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-a342db47-1949-487b-b5d2-273007d10944,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-53c023e5-bd51-4914-adfb-6cbc1f3006a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-7c2b1070-fb69-4fce-8c22-7bde14eebb45,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-c1c36d5f-72e4-4c00-9cbe-902b7aa72bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:39541,DS-8359a52b-32e7-48d3-af5e-a631f836969a,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-c36dbc31-36ed-4bd7-8633-0dd73efded0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-bc7d1b92-b555-4c25-bdc9-6e98e270e519,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-72879983-172.17.0.15-1595816479140:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34115,DS-8e3a5cec-01de-4eab-a2a1-92f41e8b3b87,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-49927341-f214-419b-9a05-73903b3b1ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-b041660e-a23b-4570-aaca-b9bc6c5c04c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-92468222-1b49-4222-89c9-21565988c08f,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-44775fd6-c4a1-4bed-8dcf-a1c7fc4f3e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-84384e35-0752-4e1e-b65b-ef230f80b74a,DISK], DatanodeInfoWithStorage[127.0.0.1:41819,DS-b29e9097-a184-47cb-894b-9acb194ca685,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-91a1511b-983a-4c76-8c92-c5e6d35a5614,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-72879983-172.17.0.15-1595816479140:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34115,DS-8e3a5cec-01de-4eab-a2a1-92f41e8b3b87,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-49927341-f214-419b-9a05-73903b3b1ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-b041660e-a23b-4570-aaca-b9bc6c5c04c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-92468222-1b49-4222-89c9-21565988c08f,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-44775fd6-c4a1-4bed-8dcf-a1c7fc4f3e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-84384e35-0752-4e1e-b65b-ef230f80b74a,DISK], DatanodeInfoWithStorage[127.0.0.1:41819,DS-b29e9097-a184-47cb-894b-9acb194ca685,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-91a1511b-983a-4c76-8c92-c5e6d35a5614,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-672615819-172.17.0.15-1595816887709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45460,DS-62b09620-37c7-4f6a-8c34-a8708b18d30d,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-13d9ebb4-1d9b-481d-a822-af522371b6da,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-3966822a-4191-4fe3-94d3-f47c12f009cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-3c813a56-5c58-4e81-88ab-d2a76aef9c94,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-2875db68-6192-4b57-abd4-dada6538f53a,DISK], DatanodeInfoWithStorage[127.0.0.1:34309,DS-f1c28cd8-3d2a-4972-8ca3-976ba4be291b,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-a5930281-83ad-4cd1-a21d-7e9b286eb027,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-99ac9dbb-ea13-4fa9-8eee-60bc22601946,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-672615819-172.17.0.15-1595816887709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45460,DS-62b09620-37c7-4f6a-8c34-a8708b18d30d,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-13d9ebb4-1d9b-481d-a822-af522371b6da,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-3966822a-4191-4fe3-94d3-f47c12f009cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-3c813a56-5c58-4e81-88ab-d2a76aef9c94,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-2875db68-6192-4b57-abd4-dada6538f53a,DISK], DatanodeInfoWithStorage[127.0.0.1:34309,DS-f1c28cd8-3d2a-4972-8ca3-976ba4be291b,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-a5930281-83ad-4cd1-a21d-7e9b286eb027,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-99ac9dbb-ea13-4fa9-8eee-60bc22601946,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-990850476-172.17.0.15-1595817052729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37282,DS-0f4b305e-47e9-46c3-a447-8094134aeb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-20c9c4dd-6c92-48af-9bb8-a216380c0488,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-2592824b-6b40-4ed1-8d1e-44a77f99154c,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-81d25b25-54c6-4d91-9d4d-74111074848d,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-2e0faa17-4a8f-4d74-b41e-6bfb3e7a7bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-e01efdc0-3c88-40bb-8725-dd29b666774f,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-adf03411-5346-49d1-8a72-edb224e664f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-5aab38e5-778e-465d-ac11-dc23cfbc28cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-990850476-172.17.0.15-1595817052729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37282,DS-0f4b305e-47e9-46c3-a447-8094134aeb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-20c9c4dd-6c92-48af-9bb8-a216380c0488,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-2592824b-6b40-4ed1-8d1e-44a77f99154c,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-81d25b25-54c6-4d91-9d4d-74111074848d,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-2e0faa17-4a8f-4d74-b41e-6bfb3e7a7bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-e01efdc0-3c88-40bb-8725-dd29b666774f,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-adf03411-5346-49d1-8a72-edb224e664f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-5aab38e5-778e-465d-ac11-dc23cfbc28cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1737048465-172.17.0.15-1595817087372:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35839,DS-73d4b60e-7638-468c-be79-ac9095169bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36610,DS-0f15db28-3b2f-41e1-a671-423550e3bab3,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-490bacb9-487b-4340-896d-fea7f8fcc8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-0ed13c99-27db-42ee-b2a8-ff3c274ec037,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-e9df3c95-5a40-4fef-bc88-c8e21edc3b19,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-5d3c65da-1930-4147-b396-9c2844ed9755,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-0363be6c-0078-4445-84c6-37ff7fe554d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44417,DS-2970bf7d-f0c7-4369-9ee2-0d33355121ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1737048465-172.17.0.15-1595817087372:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35839,DS-73d4b60e-7638-468c-be79-ac9095169bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36610,DS-0f15db28-3b2f-41e1-a671-423550e3bab3,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-490bacb9-487b-4340-896d-fea7f8fcc8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-0ed13c99-27db-42ee-b2a8-ff3c274ec037,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-e9df3c95-5a40-4fef-bc88-c8e21edc3b19,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-5d3c65da-1930-4147-b396-9c2844ed9755,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-0363be6c-0078-4445-84c6-37ff7fe554d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44417,DS-2970bf7d-f0c7-4369-9ee2-0d33355121ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-326993923-172.17.0.15-1595817404116:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39016,DS-e6114117-db75-4a66-8d02-c68d6eff63f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-5e4471bb-91e9-49fb-8234-f8061462e3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-95cd66bd-42e4-42be-b051-8ca146ab8c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-ae6a3e47-614b-4d96-bf9a-a347a0f17029,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-efdead67-a681-44be-866e-0165801ef530,DISK], DatanodeInfoWithStorage[127.0.0.1:35113,DS-cefc7d1c-df6c-4d78-9b3d-4d3a7bf04ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-be0babf6-c90f-4030-9bae-3a95ac258924,DISK], DatanodeInfoWithStorage[127.0.0.1:33913,DS-77930f60-f591-4a01-8879-68b8a5b40418,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-326993923-172.17.0.15-1595817404116:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39016,DS-e6114117-db75-4a66-8d02-c68d6eff63f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-5e4471bb-91e9-49fb-8234-f8061462e3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-95cd66bd-42e4-42be-b051-8ca146ab8c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-ae6a3e47-614b-4d96-bf9a-a347a0f17029,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-efdead67-a681-44be-866e-0165801ef530,DISK], DatanodeInfoWithStorage[127.0.0.1:35113,DS-cefc7d1c-df6c-4d78-9b3d-4d3a7bf04ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-be0babf6-c90f-4030-9bae-3a95ac258924,DISK], DatanodeInfoWithStorage[127.0.0.1:33913,DS-77930f60-f591-4a01-8879-68b8a5b40418,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-286533837-172.17.0.15-1595818008616:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35009,DS-35a2c5fb-090d-44b2-bfb2-2ef23c32489b,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-fb773d8a-f4af-45fd-a780-eae3fa9c214e,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-2f23cca2-510c-4338-b81c-4142bb3d18ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-72c3e462-16da-4ea6-b15a-40cf7ee3fdc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-dfe1efe2-2972-4f61-8e7f-cde730774dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-0be02682-68ae-4792-afd0-b8ed3e81a8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-8436b4a7-4ce2-4b8e-9e95-1779b82ce686,DISK], DatanodeInfoWithStorage[127.0.0.1:41912,DS-86c43dc1-d8ae-49f2-9a7f-a5921aafc748,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-286533837-172.17.0.15-1595818008616:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35009,DS-35a2c5fb-090d-44b2-bfb2-2ef23c32489b,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-fb773d8a-f4af-45fd-a780-eae3fa9c214e,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-2f23cca2-510c-4338-b81c-4142bb3d18ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-72c3e462-16da-4ea6-b15a-40cf7ee3fdc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-dfe1efe2-2972-4f61-8e7f-cde730774dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-0be02682-68ae-4792-afd0-b8ed3e81a8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-8436b4a7-4ce2-4b8e-9e95-1779b82ce686,DISK], DatanodeInfoWithStorage[127.0.0.1:41912,DS-86c43dc1-d8ae-49f2-9a7f-a5921aafc748,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1948618610-172.17.0.15-1595818364312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33675,DS-d008e5b0-3a3b-40ac-89fd-26d2dc3420d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-212ae977-9638-498c-86e4-d9dc35a6e8de,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-d220a599-dcff-4173-acbc-43b3951531ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-ab7c544e-3795-4c0c-8077-8ef06273c134,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-783548fe-170d-4e3e-a26a-8ba33d812541,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-24c86895-2832-431e-9d93-30d5c360dde0,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-adcb0b2d-0419-46c2-8e33-6c2389b26027,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-fd9cf418-0996-4b06-8a23-5e2149403aff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1948618610-172.17.0.15-1595818364312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33675,DS-d008e5b0-3a3b-40ac-89fd-26d2dc3420d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-212ae977-9638-498c-86e4-d9dc35a6e8de,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-d220a599-dcff-4173-acbc-43b3951531ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-ab7c544e-3795-4c0c-8077-8ef06273c134,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-783548fe-170d-4e3e-a26a-8ba33d812541,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-24c86895-2832-431e-9d93-30d5c360dde0,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-adcb0b2d-0419-46c2-8e33-6c2389b26027,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-fd9cf418-0996-4b06-8a23-5e2149403aff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2066491642-172.17.0.15-1595819887177:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37702,DS-c1804eb3-ee38-41fc-a5fb-c6e2170b0cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-6b0a2f6e-aae4-412f-a3b8-2abeff010f02,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-c5022f37-b790-4d38-b112-9ef06ad3be85,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-2eed14b4-e829-4496-afe2-0ba4367396ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-87f28459-3fd3-4c52-8104-128f3359c9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-2d6cdfde-ff0e-43e6-9084-844284d336ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-8b606966-b389-42ec-80dc-de6cd56b2d29,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-ce5e3437-30fd-42e0-bb14-4dc4c311e255,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2066491642-172.17.0.15-1595819887177:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37702,DS-c1804eb3-ee38-41fc-a5fb-c6e2170b0cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-6b0a2f6e-aae4-412f-a3b8-2abeff010f02,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-c5022f37-b790-4d38-b112-9ef06ad3be85,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-2eed14b4-e829-4496-afe2-0ba4367396ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-87f28459-3fd3-4c52-8104-128f3359c9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-2d6cdfde-ff0e-43e6-9084-844284d336ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-8b606966-b389-42ec-80dc-de6cd56b2d29,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-ce5e3437-30fd-42e0-bb14-4dc4c311e255,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1042178213-172.17.0.15-1595820450278:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37234,DS-28ddba9f-be40-49af-8210-e20f9eb0d54f,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-54a498b3-e9d9-45a9-aee0-62a457b54dba,DISK], DatanodeInfoWithStorage[127.0.0.1:46816,DS-2fc24349-ad28-4aad-80a9-72697cdcf641,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-4bf98b30-6940-4a9a-b2c5-f2149f2fab5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-88b05371-9657-4aba-8f35-288ad7e8101e,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-f0e60cca-dbd5-4e81-b286-7a0c41b8490a,DISK], DatanodeInfoWithStorage[127.0.0.1:40289,DS-4e28da21-fe65-48b0-a588-02508e4387e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-9d33ab4f-2b21-4fc0-9df5-084b88b6d0bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1042178213-172.17.0.15-1595820450278:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37234,DS-28ddba9f-be40-49af-8210-e20f9eb0d54f,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-54a498b3-e9d9-45a9-aee0-62a457b54dba,DISK], DatanodeInfoWithStorage[127.0.0.1:46816,DS-2fc24349-ad28-4aad-80a9-72697cdcf641,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-4bf98b30-6940-4a9a-b2c5-f2149f2fab5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-88b05371-9657-4aba-8f35-288ad7e8101e,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-f0e60cca-dbd5-4e81-b286-7a0c41b8490a,DISK], DatanodeInfoWithStorage[127.0.0.1:40289,DS-4e28da21-fe65-48b0-a588-02508e4387e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-9d33ab4f-2b21-4fc0-9df5-084b88b6d0bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1901781300-172.17.0.15-1595820543068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35030,DS-36755701-b902-4757-aeee-62e2c3fdc44e,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-e2e4c523-c122-42bd-b791-778f8a9d2e91,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-d799b375-6574-42d6-bc21-7eb31c080875,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-6e9ac37f-a544-4a5b-85c9-59dd10b50385,DISK], DatanodeInfoWithStorage[127.0.0.1:35604,DS-3dca725f-132f-4693-a3af-4b1e3df1dc77,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-aaf08b80-e6cc-486a-8964-49b8a3037bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-16aad510-4246-401a-b984-7f36f7d8145c,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-7259af40-3418-4e6d-afea-cabc51e02e20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1901781300-172.17.0.15-1595820543068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35030,DS-36755701-b902-4757-aeee-62e2c3fdc44e,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-e2e4c523-c122-42bd-b791-778f8a9d2e91,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-d799b375-6574-42d6-bc21-7eb31c080875,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-6e9ac37f-a544-4a5b-85c9-59dd10b50385,DISK], DatanodeInfoWithStorage[127.0.0.1:35604,DS-3dca725f-132f-4693-a3af-4b1e3df1dc77,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-aaf08b80-e6cc-486a-8964-49b8a3037bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-16aad510-4246-401a-b984-7f36f7d8145c,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-7259af40-3418-4e6d-afea-cabc51e02e20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2097230363-172.17.0.15-1595820775264:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41228,DS-7f79f61c-4a28-4e0b-899a-2221f68695e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-23031247-8268-4c6b-9617-7f6fddb8e38d,DISK], DatanodeInfoWithStorage[127.0.0.1:44869,DS-381b1127-2fe8-478c-80b9-d19e20aa5c54,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-b6703042-9b51-4b60-8c0c-cd9a93d16d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-94c5ca2e-0eb6-450e-99f9-b743c4685d47,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-ec32daf0-34f7-4a36-930b-a3a895ec4884,DISK], DatanodeInfoWithStorage[127.0.0.1:40428,DS-307e8c2d-beb0-41a6-93d2-0a1ef2a8b663,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-39b23c01-9a7c-416f-9e89-1d320d070a7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2097230363-172.17.0.15-1595820775264:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41228,DS-7f79f61c-4a28-4e0b-899a-2221f68695e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-23031247-8268-4c6b-9617-7f6fddb8e38d,DISK], DatanodeInfoWithStorage[127.0.0.1:44869,DS-381b1127-2fe8-478c-80b9-d19e20aa5c54,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-b6703042-9b51-4b60-8c0c-cd9a93d16d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-94c5ca2e-0eb6-450e-99f9-b743c4685d47,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-ec32daf0-34f7-4a36-930b-a3a895ec4884,DISK], DatanodeInfoWithStorage[127.0.0.1:40428,DS-307e8c2d-beb0-41a6-93d2-0a1ef2a8b663,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-39b23c01-9a7c-416f-9e89-1d320d070a7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-762334896-172.17.0.15-1595820913496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44094,DS-8724d9fb-43a4-412b-85bd-350b5c3d0095,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-411d8756-eb26-4da6-8e97-20f99a52f7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-6c194ad8-0f60-4136-8880-eec3c795bf5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42501,DS-01956c5c-957a-40dd-9711-a9e0fb70abf8,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-c3a39480-283c-4ecc-a611-bcf9960545eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-b0d334d2-b648-4579-aeeb-1c5e7f9208ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-ef51d99d-cbb8-4d61-a6e1-505995e70c02,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-2e0a7186-1bf7-4561-9104-d98e456080c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-762334896-172.17.0.15-1595820913496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44094,DS-8724d9fb-43a4-412b-85bd-350b5c3d0095,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-411d8756-eb26-4da6-8e97-20f99a52f7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-6c194ad8-0f60-4136-8880-eec3c795bf5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42501,DS-01956c5c-957a-40dd-9711-a9e0fb70abf8,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-c3a39480-283c-4ecc-a611-bcf9960545eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-b0d334d2-b648-4579-aeeb-1c5e7f9208ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-ef51d99d-cbb8-4d61-a6e1-505995e70c02,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-2e0a7186-1bf7-4561-9104-d98e456080c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-647842383-172.17.0.15-1595821093093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43678,DS-3dda540f-8d2c-409e-8350-3548fe5078eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-639ac084-5d84-42b0-a29f-95537c66f71c,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-226a9edf-166f-4828-8f63-aa595cf337e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-aaae804b-be14-45e5-94a4-078860cc9856,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-b443bb04-6e2f-4ac3-91eb-a248b3ce779b,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-a9ea3ab7-d351-4ea8-a607-3cd2f437709e,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-c1b327b6-5a8a-46f0-93d4-c17d48ede076,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-b2fe527d-b110-4285-a9f9-81d725845a9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-647842383-172.17.0.15-1595821093093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43678,DS-3dda540f-8d2c-409e-8350-3548fe5078eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-639ac084-5d84-42b0-a29f-95537c66f71c,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-226a9edf-166f-4828-8f63-aa595cf337e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-aaae804b-be14-45e5-94a4-078860cc9856,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-b443bb04-6e2f-4ac3-91eb-a248b3ce779b,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-a9ea3ab7-d351-4ea8-a607-3cd2f437709e,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-c1b327b6-5a8a-46f0-93d4-c17d48ede076,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-b2fe527d-b110-4285-a9f9-81d725845a9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1132901872-172.17.0.15-1595821130512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34671,DS-ecac0623-07d4-4ab8-beaa-b33676144b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-d56c231e-80da-4cc0-89ac-4fe7ecd11e56,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-aad2bb0b-6420-4a17-acfe-bbf7a6a94412,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-c9cf241d-2343-4665-8923-1d3b77069f04,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-8ab74f0e-161a-4f75-bfd3-caf5307d0b38,DISK], DatanodeInfoWithStorage[127.0.0.1:45023,DS-bd2fd389-1ca0-4431-98d3-b65a18f1ed91,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-57f2e4ba-0297-4096-8d46-7a6ea91331e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-7540512f-e66d-403f-9a66-577dd9396757,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1132901872-172.17.0.15-1595821130512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34671,DS-ecac0623-07d4-4ab8-beaa-b33676144b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-d56c231e-80da-4cc0-89ac-4fe7ecd11e56,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-aad2bb0b-6420-4a17-acfe-bbf7a6a94412,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-c9cf241d-2343-4665-8923-1d3b77069f04,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-8ab74f0e-161a-4f75-bfd3-caf5307d0b38,DISK], DatanodeInfoWithStorage[127.0.0.1:45023,DS-bd2fd389-1ca0-4431-98d3-b65a18f1ed91,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-57f2e4ba-0297-4096-8d46-7a6ea91331e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-7540512f-e66d-403f-9a66-577dd9396757,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5135
