reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1195307507-172.17.0.2-1595945981916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33073,DS-66897a83-af7b-4639-bc3d-5b1a991a73fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46224,DS-1dd0405a-893a-43d0-a66a-c18091bc5d78,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-3492e431-bc04-4ec3-b40d-6cf00dcf4378,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-80ef46f3-8a65-4d09-ab43-9add777b2ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-f5c5a36f-3ccc-43b3-8148-14e6037d0990,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-83fb2d8a-0bc0-4e43-90f8-08a24aca0641,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-c6665a48-bc14-42b9-a4fd-dd19f2ca9614,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-1d829d7f-9dc0-4014-9696-0bc48cc04edd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1195307507-172.17.0.2-1595945981916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33073,DS-66897a83-af7b-4639-bc3d-5b1a991a73fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46224,DS-1dd0405a-893a-43d0-a66a-c18091bc5d78,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-3492e431-bc04-4ec3-b40d-6cf00dcf4378,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-80ef46f3-8a65-4d09-ab43-9add777b2ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-f5c5a36f-3ccc-43b3-8148-14e6037d0990,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-83fb2d8a-0bc0-4e43-90f8-08a24aca0641,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-c6665a48-bc14-42b9-a4fd-dd19f2ca9614,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-1d829d7f-9dc0-4014-9696-0bc48cc04edd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-433683538-172.17.0.2-1595946130092:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34890,DS-f151e00b-953c-4f22-9ea7-85c1ae4d6126,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-7bee68fa-efd6-442b-9350-db5406d61e47,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-0b4995b5-dbb6-4728-bb9b-435f703cfe2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-77d9dd87-c366-4dc8-a4ef-7476e608cbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-08720423-1f16-443c-b0c4-9ddb71487978,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-b3d6658a-53b8-4d8f-b782-cfb0710b23cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-8856a28f-c4ce-4899-b306-338538cb6bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-07dd7e82-5be0-4302-8cdd-0ab1b1f87ee6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-433683538-172.17.0.2-1595946130092:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34890,DS-f151e00b-953c-4f22-9ea7-85c1ae4d6126,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-7bee68fa-efd6-442b-9350-db5406d61e47,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-0b4995b5-dbb6-4728-bb9b-435f703cfe2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-77d9dd87-c366-4dc8-a4ef-7476e608cbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-08720423-1f16-443c-b0c4-9ddb71487978,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-b3d6658a-53b8-4d8f-b782-cfb0710b23cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-8856a28f-c4ce-4899-b306-338538cb6bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-07dd7e82-5be0-4302-8cdd-0ab1b1f87ee6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-686140918-172.17.0.2-1595946654750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36545,DS-06a06c6c-6a13-4426-a2cd-242d499376e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-3ab99090-ccf0-46e1-a1a0-0e103eb5ef2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33788,DS-3d5403b2-ed92-4c26-bec3-0fe13088715d,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-3e6633b3-d3f6-485c-94c6-5f919f84da7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33821,DS-c161a961-fc42-4c2c-8090-02bf898ef262,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-d468e80f-7644-472e-a203-44bc81549553,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-1f6dc87e-c979-4ee5-9fed-43e174a8d783,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-c3925f80-10cb-4408-a4e4-98748165e796,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-686140918-172.17.0.2-1595946654750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36545,DS-06a06c6c-6a13-4426-a2cd-242d499376e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-3ab99090-ccf0-46e1-a1a0-0e103eb5ef2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33788,DS-3d5403b2-ed92-4c26-bec3-0fe13088715d,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-3e6633b3-d3f6-485c-94c6-5f919f84da7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33821,DS-c161a961-fc42-4c2c-8090-02bf898ef262,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-d468e80f-7644-472e-a203-44bc81549553,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-1f6dc87e-c979-4ee5-9fed-43e174a8d783,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-c3925f80-10cb-4408-a4e4-98748165e796,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1915568714-172.17.0.2-1595946894603:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40736,DS-306f71c3-e7a8-4661-8eab-e4cf594933b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-cfb4479f-e92c-410f-b7c2-2ba132813949,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-41130c3e-5198-4934-b134-665a794ef1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-4a7a48ef-d9b0-4fef-80f3-4439553ef62b,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-48066773-acfb-4ef0-87af-6bbb25632e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-fc89ec74-16ed-4fa2-a855-9b37f6f94614,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-49139137-6d7b-4a4d-9945-6b6bfb188400,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-bd561dbb-e578-4a18-a570-952e49d52880,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1915568714-172.17.0.2-1595946894603:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40736,DS-306f71c3-e7a8-4661-8eab-e4cf594933b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-cfb4479f-e92c-410f-b7c2-2ba132813949,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-41130c3e-5198-4934-b134-665a794ef1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-4a7a48ef-d9b0-4fef-80f3-4439553ef62b,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-48066773-acfb-4ef0-87af-6bbb25632e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-fc89ec74-16ed-4fa2-a855-9b37f6f94614,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-49139137-6d7b-4a4d-9945-6b6bfb188400,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-bd561dbb-e578-4a18-a570-952e49d52880,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-42968121-172.17.0.2-1595946971491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44745,DS-a3d67109-93db-43d4-ab85-5227065c5f07,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-b6e39dd8-7223-452f-8c6f-646006211516,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-7532169c-7d3f-445b-9150-2e6c4d32900c,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-775b7df2-d6d6-44df-9a79-11671550d6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-a65d4258-7fc5-4211-82dc-b4a2f735938a,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-1126d744-3752-4960-a020-d2ad3c6176a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-4e96aade-fb7b-44e2-ac3c-be3e58a36302,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-ca3a66ef-22e5-4069-9b61-9e14c5e83817,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-42968121-172.17.0.2-1595946971491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44745,DS-a3d67109-93db-43d4-ab85-5227065c5f07,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-b6e39dd8-7223-452f-8c6f-646006211516,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-7532169c-7d3f-445b-9150-2e6c4d32900c,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-775b7df2-d6d6-44df-9a79-11671550d6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-a65d4258-7fc5-4211-82dc-b4a2f735938a,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-1126d744-3752-4960-a020-d2ad3c6176a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-4e96aade-fb7b-44e2-ac3c-be3e58a36302,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-ca3a66ef-22e5-4069-9b61-9e14c5e83817,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-678702818-172.17.0.2-1595947006867:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33246,DS-c291de4c-ee0d-4696-87f0-a2e30d800d50,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-e16d17ed-db74-4944-874b-0cc1c655b0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-4e5ae052-28cb-417f-93f2-cdb28cb4739f,DISK], DatanodeInfoWithStorage[127.0.0.1:46012,DS-8c9465cc-0733-4be8-bccf-d8a8d8f9ec98,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-d975f013-8f3e-4591-83c2-18caa0204da3,DISK], DatanodeInfoWithStorage[127.0.0.1:42202,DS-a6dda475-9005-4448-8061-cb94a1ab57ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-d8734922-eb13-4b08-98d7-3b016e7450ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-33bb7392-bb5c-413e-bdcf-32e7723c9137,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-678702818-172.17.0.2-1595947006867:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33246,DS-c291de4c-ee0d-4696-87f0-a2e30d800d50,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-e16d17ed-db74-4944-874b-0cc1c655b0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-4e5ae052-28cb-417f-93f2-cdb28cb4739f,DISK], DatanodeInfoWithStorage[127.0.0.1:46012,DS-8c9465cc-0733-4be8-bccf-d8a8d8f9ec98,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-d975f013-8f3e-4591-83c2-18caa0204da3,DISK], DatanodeInfoWithStorage[127.0.0.1:42202,DS-a6dda475-9005-4448-8061-cb94a1ab57ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-d8734922-eb13-4b08-98d7-3b016e7450ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-33bb7392-bb5c-413e-bdcf-32e7723c9137,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1539616367-172.17.0.2-1595947040527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44232,DS-1d4af3ba-cd9f-4390-b21e-9eaf275a7a03,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-f446aa86-7bad-4c2c-bbf4-4d20db6700e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-cb76f5d8-be78-4023-9673-ff61af0746c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-a88093a4-4031-403c-9ad5-e0266a912736,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-cc16d108-7300-48dc-aa00-8a3b3bf97796,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-6d111803-3bc8-4267-b483-8d58e100f774,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-8759475f-7489-4a31-b1fc-ac1953af3dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-7880569c-20bb-4f0d-a519-8ebd4bb6c43e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1539616367-172.17.0.2-1595947040527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44232,DS-1d4af3ba-cd9f-4390-b21e-9eaf275a7a03,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-f446aa86-7bad-4c2c-bbf4-4d20db6700e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-cb76f5d8-be78-4023-9673-ff61af0746c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-a88093a4-4031-403c-9ad5-e0266a912736,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-cc16d108-7300-48dc-aa00-8a3b3bf97796,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-6d111803-3bc8-4267-b483-8d58e100f774,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-8759475f-7489-4a31-b1fc-ac1953af3dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-7880569c-20bb-4f0d-a519-8ebd4bb6c43e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1374406492-172.17.0.2-1595947144411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41714,DS-f13e4b71-b610-4849-b4ae-20bb7d3241fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-7df9b396-f10e-4770-b243-33dfbc94867f,DISK], DatanodeInfoWithStorage[127.0.0.1:44658,DS-db5d3727-fb4b-49a0-883b-f00e177eafa4,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-27b09b69-06cd-4ff6-88d6-d721fcba1560,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-b1257592-a681-4a52-a188-263352063ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-63ad6b18-e4e5-4ca0-9696-86d15d4f776f,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-ff8abbd2-d8b1-43fb-9a1d-5ee35920839b,DISK], DatanodeInfoWithStorage[127.0.0.1:40892,DS-c05c7345-71f9-40e3-a9e0-ae74d80df295,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1374406492-172.17.0.2-1595947144411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41714,DS-f13e4b71-b610-4849-b4ae-20bb7d3241fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-7df9b396-f10e-4770-b243-33dfbc94867f,DISK], DatanodeInfoWithStorage[127.0.0.1:44658,DS-db5d3727-fb4b-49a0-883b-f00e177eafa4,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-27b09b69-06cd-4ff6-88d6-d721fcba1560,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-b1257592-a681-4a52-a188-263352063ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-63ad6b18-e4e5-4ca0-9696-86d15d4f776f,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-ff8abbd2-d8b1-43fb-9a1d-5ee35920839b,DISK], DatanodeInfoWithStorage[127.0.0.1:40892,DS-c05c7345-71f9-40e3-a9e0-ae74d80df295,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1311526293-172.17.0.2-1595948186974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36388,DS-a6c2ccb2-de87-4be3-afa6-26c998ec2ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-55469258-b9e8-4224-a79b-7addcb375e48,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-5c23bc16-8fdd-42a1-9f86-e9674b71848c,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-6f6cb056-1ed8-4700-b707-d29536f7cc41,DISK], DatanodeInfoWithStorage[127.0.0.1:42523,DS-72453f7c-3f60-411f-adc4-fac6e83c01e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-15571dfb-ab4b-4158-a259-41cb447ec264,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-f57ac648-6912-4b6d-bf62-0e5d7aeb160c,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-8e937dd6-5810-4710-af3e-9d509c1f7085,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1311526293-172.17.0.2-1595948186974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36388,DS-a6c2ccb2-de87-4be3-afa6-26c998ec2ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-55469258-b9e8-4224-a79b-7addcb375e48,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-5c23bc16-8fdd-42a1-9f86-e9674b71848c,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-6f6cb056-1ed8-4700-b707-d29536f7cc41,DISK], DatanodeInfoWithStorage[127.0.0.1:42523,DS-72453f7c-3f60-411f-adc4-fac6e83c01e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-15571dfb-ab4b-4158-a259-41cb447ec264,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-f57ac648-6912-4b6d-bf62-0e5d7aeb160c,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-8e937dd6-5810-4710-af3e-9d509c1f7085,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1751535836-172.17.0.2-1595948638443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38740,DS-9a5068c6-b842-4c01-b93c-caf09b1739d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-86f71419-cb47-4010-9c21-83f58091d385,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-47742837-e8b5-4b88-868b-709d7bdab9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45473,DS-bb49974b-6935-41cf-984e-604af5348495,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-68beaec3-17c2-4e57-863c-f9aea2399e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-d0239bc2-fbb4-49c1-84f1-a9d500909984,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-52e54fd4-7e45-49ec-8749-da945dc725ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36251,DS-935fff2a-a83e-4fdf-b4fe-0da67ffd8a39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1751535836-172.17.0.2-1595948638443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38740,DS-9a5068c6-b842-4c01-b93c-caf09b1739d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-86f71419-cb47-4010-9c21-83f58091d385,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-47742837-e8b5-4b88-868b-709d7bdab9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45473,DS-bb49974b-6935-41cf-984e-604af5348495,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-68beaec3-17c2-4e57-863c-f9aea2399e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-d0239bc2-fbb4-49c1-84f1-a9d500909984,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-52e54fd4-7e45-49ec-8749-da945dc725ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36251,DS-935fff2a-a83e-4fdf-b4fe-0da67ffd8a39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1181525047-172.17.0.2-1595948847867:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35475,DS-4f376717-6858-4b4d-9391-7ab0f7276d20,DISK], DatanodeInfoWithStorage[127.0.0.1:34266,DS-09453ed4-4228-4368-b50d-c32cd49b4744,DISK], DatanodeInfoWithStorage[127.0.0.1:34046,DS-3225f848-e0bf-483e-806b-390f23b6ad25,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-03156de3-1528-4dc7-9408-42f037c0ea42,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-bd52cb4f-f7e5-4132-9d20-4e385d1db442,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-3a83844a-b33a-4eb5-9df6-126bda4f6652,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-23ff261c-2c9e-470f-a48c-b46ca43a5109,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-6cc9e732-8584-4924-8b28-18434b9e514b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1181525047-172.17.0.2-1595948847867:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35475,DS-4f376717-6858-4b4d-9391-7ab0f7276d20,DISK], DatanodeInfoWithStorage[127.0.0.1:34266,DS-09453ed4-4228-4368-b50d-c32cd49b4744,DISK], DatanodeInfoWithStorage[127.0.0.1:34046,DS-3225f848-e0bf-483e-806b-390f23b6ad25,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-03156de3-1528-4dc7-9408-42f037c0ea42,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-bd52cb4f-f7e5-4132-9d20-4e385d1db442,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-3a83844a-b33a-4eb5-9df6-126bda4f6652,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-23ff261c-2c9e-470f-a48c-b46ca43a5109,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-6cc9e732-8584-4924-8b28-18434b9e514b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-181104775-172.17.0.2-1595949001115:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45638,DS-16caec01-17c9-49dc-970e-cd398c9ce129,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-3826b4af-51f1-4635-9d67-076f4463302f,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-70a78f6f-bc7b-45b6-b8ef-15777d7d4eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34149,DS-66358634-0b61-40a1-a75d-cb6e7d732564,DISK], DatanodeInfoWithStorage[127.0.0.1:39819,DS-b5aece98-5be0-4f53-af61-14913e4bae68,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-4d53f3a0-1197-48ec-8126-a88d8db117dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41547,DS-ad10c06e-91c1-4cb3-9346-bf5c9d29bcf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-265580ed-89a3-43e7-ab60-f8f66525a92f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-181104775-172.17.0.2-1595949001115:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45638,DS-16caec01-17c9-49dc-970e-cd398c9ce129,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-3826b4af-51f1-4635-9d67-076f4463302f,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-70a78f6f-bc7b-45b6-b8ef-15777d7d4eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34149,DS-66358634-0b61-40a1-a75d-cb6e7d732564,DISK], DatanodeInfoWithStorage[127.0.0.1:39819,DS-b5aece98-5be0-4f53-af61-14913e4bae68,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-4d53f3a0-1197-48ec-8126-a88d8db117dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41547,DS-ad10c06e-91c1-4cb3-9346-bf5c9d29bcf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-265580ed-89a3-43e7-ab60-f8f66525a92f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1262187548-172.17.0.2-1595949175172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39307,DS-43029e45-4d4b-43ae-b4ed-b8579cdc4121,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-a3063a6a-98c9-4656-9fbe-eb18a7740840,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-26a24314-158c-450f-948e-51082d91b922,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-f5d38120-760e-4c37-8844-e7f829bba6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-bbf886a9-351a-456a-9011-32be8b6fdb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-ef051464-87e4-4a21-9366-c5e2bffe9cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-9e42f9c3-5979-45b5-b5a5-6d8b78bed9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-0ab7a3d1-b701-4624-89c3-61e3b27394f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1262187548-172.17.0.2-1595949175172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39307,DS-43029e45-4d4b-43ae-b4ed-b8579cdc4121,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-a3063a6a-98c9-4656-9fbe-eb18a7740840,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-26a24314-158c-450f-948e-51082d91b922,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-f5d38120-760e-4c37-8844-e7f829bba6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-bbf886a9-351a-456a-9011-32be8b6fdb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-ef051464-87e4-4a21-9366-c5e2bffe9cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-9e42f9c3-5979-45b5-b5a5-6d8b78bed9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-0ab7a3d1-b701-4624-89c3-61e3b27394f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1957002030-172.17.0.2-1595949388716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34586,DS-d5a6f6d0-f49e-47b0-9380-7776d244b43a,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-fa0f8e86-e383-4a9e-9897-6b16542a0b01,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-27bf1e16-11ae-4ed2-b8bc-5e1a2ee5bc81,DISK], DatanodeInfoWithStorage[127.0.0.1:41404,DS-7af2b39f-e659-468f-9493-e8461cb20f84,DISK], DatanodeInfoWithStorage[127.0.0.1:42154,DS-6376159f-a8c7-4867-98a1-092b7cc0d53b,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-91f5dbf2-f7d6-4000-9092-92b78186d158,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-eb9e253f-54bc-4515-b756-a71f796e9191,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-261dc5c3-1a42-4343-8c4a-32495353ac7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1957002030-172.17.0.2-1595949388716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34586,DS-d5a6f6d0-f49e-47b0-9380-7776d244b43a,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-fa0f8e86-e383-4a9e-9897-6b16542a0b01,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-27bf1e16-11ae-4ed2-b8bc-5e1a2ee5bc81,DISK], DatanodeInfoWithStorage[127.0.0.1:41404,DS-7af2b39f-e659-468f-9493-e8461cb20f84,DISK], DatanodeInfoWithStorage[127.0.0.1:42154,DS-6376159f-a8c7-4867-98a1-092b7cc0d53b,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-91f5dbf2-f7d6-4000-9092-92b78186d158,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-eb9e253f-54bc-4515-b756-a71f796e9191,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-261dc5c3-1a42-4343-8c4a-32495353ac7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1198628887-172.17.0.2-1595949486247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39730,DS-66aad650-a08f-41f2-896b-5368a76deb75,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-cfaa32c2-3aa2-4c48-a146-420a58c7abdd,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-558c1734-a4c4-4b5c-9e90-bb18e94fa9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-54d01357-6349-4e0b-8ef9-569fcaa69c42,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-5ce41ffd-d6e7-4232-a18a-14556ced0bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43697,DS-b3ab4103-b1a8-4de6-9ac5-d5fd5264ac4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-af90c41c-1189-4b50-a915-7129fef41297,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-00455f68-26d6-47c1-a23c-b986ee5c49b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1198628887-172.17.0.2-1595949486247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39730,DS-66aad650-a08f-41f2-896b-5368a76deb75,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-cfaa32c2-3aa2-4c48-a146-420a58c7abdd,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-558c1734-a4c4-4b5c-9e90-bb18e94fa9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-54d01357-6349-4e0b-8ef9-569fcaa69c42,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-5ce41ffd-d6e7-4232-a18a-14556ced0bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43697,DS-b3ab4103-b1a8-4de6-9ac5-d5fd5264ac4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-af90c41c-1189-4b50-a915-7129fef41297,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-00455f68-26d6-47c1-a23c-b986ee5c49b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1220209097-172.17.0.2-1595949753316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34187,DS-bc91eed3-4d0b-499a-98ac-0bd89136b88f,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-a1c671b6-c7cf-4784-ac27-274b6a00a8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-90afd804-0137-4026-986b-89547e0b5e58,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-b94d05a4-b3fb-4f21-97e4-1e80066fe152,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-e4110854-340a-4114-91c4-bdd9f928f911,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-bd25137a-0734-40d3-894b-31113b49b66a,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-6aa1ac81-d271-4dab-bc3e-31cad3f94cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-568b9f66-8dbb-4186-aca2-d6db58bb6868,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1220209097-172.17.0.2-1595949753316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34187,DS-bc91eed3-4d0b-499a-98ac-0bd89136b88f,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-a1c671b6-c7cf-4784-ac27-274b6a00a8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-90afd804-0137-4026-986b-89547e0b5e58,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-b94d05a4-b3fb-4f21-97e4-1e80066fe152,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-e4110854-340a-4114-91c4-bdd9f928f911,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-bd25137a-0734-40d3-894b-31113b49b66a,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-6aa1ac81-d271-4dab-bc3e-31cad3f94cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-568b9f66-8dbb-4186-aca2-d6db58bb6868,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-457115168-172.17.0.2-1595949815651:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39809,DS-4b830f4d-9c82-49af-8be9-b7d7307871a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36686,DS-f9963145-21ed-4e46-8375-367d89eb798b,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-38f23b17-c4f4-467c-b8ab-2fbdd406e1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-24d14c57-4c5f-45b9-a7da-7372df662948,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-0672868c-e07c-4f2d-9511-f83ef33bd0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-6f375b68-509b-41c7-b746-7101f40f2eab,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-4e30c5e0-2156-4be0-aeda-0afd0f19628c,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-69031756-9ebd-4d43-a212-03624a5241c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-457115168-172.17.0.2-1595949815651:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39809,DS-4b830f4d-9c82-49af-8be9-b7d7307871a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36686,DS-f9963145-21ed-4e46-8375-367d89eb798b,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-38f23b17-c4f4-467c-b8ab-2fbdd406e1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-24d14c57-4c5f-45b9-a7da-7372df662948,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-0672868c-e07c-4f2d-9511-f83ef33bd0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-6f375b68-509b-41c7-b746-7101f40f2eab,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-4e30c5e0-2156-4be0-aeda-0afd0f19628c,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-69031756-9ebd-4d43-a212-03624a5241c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-485738321-172.17.0.2-1595950060731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40278,DS-deed22d8-ce5d-47e0-8673-66fd743c708e,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-b42eb98f-8cc0-41c2-9673-d1a0ac7c9775,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-67aae9e5-0cb1-428d-a664-281567abccb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-033b5961-069c-4e2b-a7a2-8bae26eebe6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-304fae2f-1b3f-45d6-9cce-b1b6b20ab648,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-b1d406a0-bce5-4a3c-921c-e876bd62ffa8,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-5971aed6-870e-4cb7-9a5b-d13025bb3968,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-a7a705ae-afde-4a2c-972a-b2be64a004c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-485738321-172.17.0.2-1595950060731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40278,DS-deed22d8-ce5d-47e0-8673-66fd743c708e,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-b42eb98f-8cc0-41c2-9673-d1a0ac7c9775,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-67aae9e5-0cb1-428d-a664-281567abccb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-033b5961-069c-4e2b-a7a2-8bae26eebe6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-304fae2f-1b3f-45d6-9cce-b1b6b20ab648,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-b1d406a0-bce5-4a3c-921c-e876bd62ffa8,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-5971aed6-870e-4cb7-9a5b-d13025bb3968,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-a7a705ae-afde-4a2c-972a-b2be64a004c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5290
