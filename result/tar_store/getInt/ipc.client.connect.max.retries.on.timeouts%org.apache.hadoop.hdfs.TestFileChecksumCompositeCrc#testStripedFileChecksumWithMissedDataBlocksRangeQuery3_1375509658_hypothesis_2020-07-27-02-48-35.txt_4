reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319236548-172.17.0.2-1595818130940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41807,DS-3ed5c39e-e243-42dd-8b44-18c32dcb9c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-ca2c9f1e-1d7a-4837-b34b-650c90e92bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-142b93af-ae91-44dc-8c5b-b07c0b7df50c,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-5689acf5-de72-45a5-a1fa-54d066006c95,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-711edfd6-9aea-4abd-8180-06f6babff4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-570f6410-fbe5-40e1-ab90-0eae77f783e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-9df16acc-038a-4e62-9585-3cf10a14b4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-4dcf70e9-8aac-4338-b259-4533323319e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319236548-172.17.0.2-1595818130940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41807,DS-3ed5c39e-e243-42dd-8b44-18c32dcb9c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-ca2c9f1e-1d7a-4837-b34b-650c90e92bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-142b93af-ae91-44dc-8c5b-b07c0b7df50c,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-5689acf5-de72-45a5-a1fa-54d066006c95,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-711edfd6-9aea-4abd-8180-06f6babff4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-570f6410-fbe5-40e1-ab90-0eae77f783e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-9df16acc-038a-4e62-9585-3cf10a14b4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-4dcf70e9-8aac-4338-b259-4533323319e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1508920017-172.17.0.2-1595818157817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38751,DS-c8af95b4-8b69-4de2-b323-d21eddbd13c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-bacff697-4375-4861-97e7-692d3d4f1dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-74d8c9cf-7db6-4cca-be28-ca46954322f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-06221e6c-52a0-437f-9cb0-8b942df2eca6,DISK], DatanodeInfoWithStorage[127.0.0.1:32931,DS-33e7a8a5-6a21-4bd0-ac82-8e237fc7944f,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-2dabacf1-c3e7-445f-94b1-14c1232bed72,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-7355b6fa-e07f-4f19-93be-70075ae92fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-99ab809a-9614-4a7e-8e99-358f18115225,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1508920017-172.17.0.2-1595818157817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38751,DS-c8af95b4-8b69-4de2-b323-d21eddbd13c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-bacff697-4375-4861-97e7-692d3d4f1dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-74d8c9cf-7db6-4cca-be28-ca46954322f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-06221e6c-52a0-437f-9cb0-8b942df2eca6,DISK], DatanodeInfoWithStorage[127.0.0.1:32931,DS-33e7a8a5-6a21-4bd0-ac82-8e237fc7944f,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-2dabacf1-c3e7-445f-94b1-14c1232bed72,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-7355b6fa-e07f-4f19-93be-70075ae92fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-99ab809a-9614-4a7e-8e99-358f18115225,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2079611460-172.17.0.2-1595818624079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44753,DS-8e01bcf3-e375-41ff-9628-d1bf808d6e75,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-30e45cb6-6aec-485b-b5e2-2ff4633cd09a,DISK], DatanodeInfoWithStorage[127.0.0.1:43213,DS-6edef99c-9bf5-42f9-a362-59542465c264,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-61a885f5-1ea3-416b-814c-f01f8900ea73,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-704167a5-fbed-4a75-bdcb-2ca3ce625fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-4ec5b575-9f28-49ac-b01e-6ce487662ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-53701f87-3b9c-429b-8aa0-43db0ab4a974,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-01d359cc-87ad-4123-8c4f-6ca3c0617f24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2079611460-172.17.0.2-1595818624079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44753,DS-8e01bcf3-e375-41ff-9628-d1bf808d6e75,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-30e45cb6-6aec-485b-b5e2-2ff4633cd09a,DISK], DatanodeInfoWithStorage[127.0.0.1:43213,DS-6edef99c-9bf5-42f9-a362-59542465c264,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-61a885f5-1ea3-416b-814c-f01f8900ea73,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-704167a5-fbed-4a75-bdcb-2ca3ce625fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-4ec5b575-9f28-49ac-b01e-6ce487662ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-53701f87-3b9c-429b-8aa0-43db0ab4a974,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-01d359cc-87ad-4123-8c4f-6ca3c0617f24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1697756789-172.17.0.2-1595818736467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40403,DS-759c5858-0b5f-46b8-9c7e-d2d0bdcd8bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36686,DS-073d22b8-92d0-40b9-9916-f3fc6d7db0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-d9ea2f35-7c6c-4b95-b14e-fcf9d1482b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-d54e421d-5377-4fc6-a19d-f33bc45f72bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-5d0d8b36-66a4-4d33-9035-167a79befc80,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-d931c1b8-379b-4b8a-abab-710ee4b30c16,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-08416a92-6a62-4fd7-9774-87851e6d5473,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-0d0b419c-8758-40d2-92aa-95e80d8882ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1697756789-172.17.0.2-1595818736467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40403,DS-759c5858-0b5f-46b8-9c7e-d2d0bdcd8bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36686,DS-073d22b8-92d0-40b9-9916-f3fc6d7db0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-d9ea2f35-7c6c-4b95-b14e-fcf9d1482b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-d54e421d-5377-4fc6-a19d-f33bc45f72bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-5d0d8b36-66a4-4d33-9035-167a79befc80,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-d931c1b8-379b-4b8a-abab-710ee4b30c16,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-08416a92-6a62-4fd7-9774-87851e6d5473,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-0d0b419c-8758-40d2-92aa-95e80d8882ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1156175271-172.17.0.2-1595819289182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42616,DS-0bb32708-c3eb-4935-a996-d505428e83f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-fe63ed17-284c-4f73-a480-db2ca1230377,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-4c2cc00c-f793-4c19-b9b7-2a4664a7e51f,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-aa13b4f9-6ee7-4d6a-9224-1cbf8cb2b599,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-c05b594a-d457-48eb-9d16-5cddbba3c1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-6f46093c-7896-4cb3-a224-572f35b79e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-294db7d8-dcff-44ea-9cd1-e5542be76ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-1562d919-f6f1-400f-9699-1f9f9755f626,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1156175271-172.17.0.2-1595819289182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42616,DS-0bb32708-c3eb-4935-a996-d505428e83f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-fe63ed17-284c-4f73-a480-db2ca1230377,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-4c2cc00c-f793-4c19-b9b7-2a4664a7e51f,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-aa13b4f9-6ee7-4d6a-9224-1cbf8cb2b599,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-c05b594a-d457-48eb-9d16-5cddbba3c1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-6f46093c-7896-4cb3-a224-572f35b79e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-294db7d8-dcff-44ea-9cd1-e5542be76ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-1562d919-f6f1-400f-9699-1f9f9755f626,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-89401427-172.17.0.2-1595819324338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45750,DS-b802a74a-2a03-458f-978a-667f94bf2f07,DISK], DatanodeInfoWithStorage[127.0.0.1:42818,DS-49bdb37c-1da6-4c22-9a82-b95a739f0382,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-35ee45f5-9445-4224-b01a-9b642dd3dd2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-4cad9e96-72c5-44e4-a271-3a7387dfb45d,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-d23e1d85-5c4d-47a0-9a1e-cd7a2f26f43a,DISK], DatanodeInfoWithStorage[127.0.0.1:33822,DS-89785980-f126-4648-9b35-5377edb2d284,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-a33c891c-6fce-4bbc-919a-84af5b9f4991,DISK], DatanodeInfoWithStorage[127.0.0.1:39955,DS-5fbc2d08-b322-44e8-83e7-aecd9b34fb78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-89401427-172.17.0.2-1595819324338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45750,DS-b802a74a-2a03-458f-978a-667f94bf2f07,DISK], DatanodeInfoWithStorage[127.0.0.1:42818,DS-49bdb37c-1da6-4c22-9a82-b95a739f0382,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-35ee45f5-9445-4224-b01a-9b642dd3dd2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-4cad9e96-72c5-44e4-a271-3a7387dfb45d,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-d23e1d85-5c4d-47a0-9a1e-cd7a2f26f43a,DISK], DatanodeInfoWithStorage[127.0.0.1:33822,DS-89785980-f126-4648-9b35-5377edb2d284,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-a33c891c-6fce-4bbc-919a-84af5b9f4991,DISK], DatanodeInfoWithStorage[127.0.0.1:39955,DS-5fbc2d08-b322-44e8-83e7-aecd9b34fb78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1081911490-172.17.0.2-1595819447364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34867,DS-85b6cebf-26f1-44e5-8f8e-385631cc1115,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-cc97c378-ef63-42f4-a23c-038b6bdec427,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-d912245b-ccf2-4e8d-a31d-b2d4f7cd23c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-dad84b5b-00ab-4fee-8f24-9ec1735d064c,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-20c6b4f4-8bcd-4bb5-9862-68e679bd6b13,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-867f12af-7e85-449e-82bd-729e8bd79626,DISK], DatanodeInfoWithStorage[127.0.0.1:44260,DS-a2731959-d2ed-465a-aa14-e5c6c351eafc,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-d21d8e1d-6c6f-4a61-b5fa-bddf60e056fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1081911490-172.17.0.2-1595819447364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34867,DS-85b6cebf-26f1-44e5-8f8e-385631cc1115,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-cc97c378-ef63-42f4-a23c-038b6bdec427,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-d912245b-ccf2-4e8d-a31d-b2d4f7cd23c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-dad84b5b-00ab-4fee-8f24-9ec1735d064c,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-20c6b4f4-8bcd-4bb5-9862-68e679bd6b13,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-867f12af-7e85-449e-82bd-729e8bd79626,DISK], DatanodeInfoWithStorage[127.0.0.1:44260,DS-a2731959-d2ed-465a-aa14-e5c6c351eafc,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-d21d8e1d-6c6f-4a61-b5fa-bddf60e056fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-582510116-172.17.0.2-1595819825920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41031,DS-64c9f237-8a9c-402c-b1a2-f7c56f6e4554,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-b29f9654-46bd-47d6-b1c2-10852b61d66a,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-7880847b-c8c8-480c-acaf-05794cfa75d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-3228dbf4-a5be-4947-88cd-466ff44a35cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-8694021d-a88b-4c90-99e6-3b14abaa7af2,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-a97969a2-1d82-4176-98f1-ae65a838628b,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-c8d0543a-536f-42a0-adb5-2a011061d640,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-50c86c5b-3c0c-4b0b-8202-465aa406c676,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-582510116-172.17.0.2-1595819825920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41031,DS-64c9f237-8a9c-402c-b1a2-f7c56f6e4554,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-b29f9654-46bd-47d6-b1c2-10852b61d66a,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-7880847b-c8c8-480c-acaf-05794cfa75d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-3228dbf4-a5be-4947-88cd-466ff44a35cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-8694021d-a88b-4c90-99e6-3b14abaa7af2,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-a97969a2-1d82-4176-98f1-ae65a838628b,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-c8d0543a-536f-42a0-adb5-2a011061d640,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-50c86c5b-3c0c-4b0b-8202-465aa406c676,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2025283203-172.17.0.2-1595820318916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35867,DS-e740b18d-419e-439d-8d04-4dbbe51c5ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-65ebd04e-e641-4672-a8e5-9bdc7115e7af,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-e79852df-ad4b-421e-af9c-299d106434fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-cac00931-7c0f-4a66-a437-a700ae1168a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-437a9432-987c-45b2-b149-b9904bca8084,DISK], DatanodeInfoWithStorage[127.0.0.1:45749,DS-1229f2d9-49ed-4818-9cfc-1173fd3b866d,DISK], DatanodeInfoWithStorage[127.0.0.1:41508,DS-143adbbd-5a8f-4131-b1f4-73551ff3a845,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-e525b092-2c3d-404d-8ddc-dddb5817ed98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2025283203-172.17.0.2-1595820318916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35867,DS-e740b18d-419e-439d-8d04-4dbbe51c5ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-65ebd04e-e641-4672-a8e5-9bdc7115e7af,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-e79852df-ad4b-421e-af9c-299d106434fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-cac00931-7c0f-4a66-a437-a700ae1168a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-437a9432-987c-45b2-b149-b9904bca8084,DISK], DatanodeInfoWithStorage[127.0.0.1:45749,DS-1229f2d9-49ed-4818-9cfc-1173fd3b866d,DISK], DatanodeInfoWithStorage[127.0.0.1:41508,DS-143adbbd-5a8f-4131-b1f4-73551ff3a845,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-e525b092-2c3d-404d-8ddc-dddb5817ed98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-88142220-172.17.0.2-1595820392009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41984,DS-a2d7ade7-4c89-4f8e-8fb6-121d9aaf4380,DISK], DatanodeInfoWithStorage[127.0.0.1:33612,DS-c84dd0d7-b4e8-461b-bf0d-8aecc3a1b272,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-74991344-c708-4d28-b565-042835540e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-a8bd46e0-caf7-42f1-9cff-acf5d164bef7,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-04448e14-dc9f-467a-83fa-afbaa8a495f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-7a6b5eba-7a54-40c6-95d2-e9ccf29a71a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-3b4c0c48-cf7e-439b-bdf2-8112e428af61,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-8b1dfe8e-a237-4fd9-b87e-506a3d526aee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-88142220-172.17.0.2-1595820392009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41984,DS-a2d7ade7-4c89-4f8e-8fb6-121d9aaf4380,DISK], DatanodeInfoWithStorage[127.0.0.1:33612,DS-c84dd0d7-b4e8-461b-bf0d-8aecc3a1b272,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-74991344-c708-4d28-b565-042835540e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-a8bd46e0-caf7-42f1-9cff-acf5d164bef7,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-04448e14-dc9f-467a-83fa-afbaa8a495f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-7a6b5eba-7a54-40c6-95d2-e9ccf29a71a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-3b4c0c48-cf7e-439b-bdf2-8112e428af61,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-8b1dfe8e-a237-4fd9-b87e-506a3d526aee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1050377676-172.17.0.2-1595820574824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44341,DS-de7fb31e-d9ab-4319-87cf-0401ddb79f02,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-744b8527-3425-41ae-ab1e-83b18ccfe026,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-81c67b70-ea08-4105-9433-cb098ab45ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-a22eed50-9de4-4299-9fd3-55d861f325b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-7f7a9fe6-5bb8-485e-a093-0c91797972c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-13231dad-3189-4530-b788-fe35532f8459,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-590fb2a9-a9d5-4760-883b-ca92583099c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-03110713-6e56-4b1b-8110-cdc1f1065ea4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1050377676-172.17.0.2-1595820574824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44341,DS-de7fb31e-d9ab-4319-87cf-0401ddb79f02,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-744b8527-3425-41ae-ab1e-83b18ccfe026,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-81c67b70-ea08-4105-9433-cb098ab45ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-a22eed50-9de4-4299-9fd3-55d861f325b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-7f7a9fe6-5bb8-485e-a093-0c91797972c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-13231dad-3189-4530-b788-fe35532f8459,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-590fb2a9-a9d5-4760-883b-ca92583099c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-03110713-6e56-4b1b-8110-cdc1f1065ea4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86185057-172.17.0.2-1595820766491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45675,DS-0830a9bd-009d-4ca9-bf1f-a60878e66a53,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-bb7909b8-2e87-48f5-9486-3cc311e8d843,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-329a9825-fe75-4e8d-8e2d-193a85d54283,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-8155cbee-d81f-4ce7-99a5-e0729519d1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35891,DS-365a87ac-a8d6-4758-9774-77288d5d3572,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-818ee574-264c-4005-a005-5875d3b96862,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-9d57c424-23f3-4733-be42-f2bf5bbcfe0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-6fadf8a5-6de2-4674-b2af-07884006c677,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86185057-172.17.0.2-1595820766491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45675,DS-0830a9bd-009d-4ca9-bf1f-a60878e66a53,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-bb7909b8-2e87-48f5-9486-3cc311e8d843,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-329a9825-fe75-4e8d-8e2d-193a85d54283,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-8155cbee-d81f-4ce7-99a5-e0729519d1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35891,DS-365a87ac-a8d6-4758-9774-77288d5d3572,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-818ee574-264c-4005-a005-5875d3b96862,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-9d57c424-23f3-4733-be42-f2bf5bbcfe0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-6fadf8a5-6de2-4674-b2af-07884006c677,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1351889528-172.17.0.2-1595821251232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38688,DS-a5db572c-d519-423e-9e1a-f4681ea4f9de,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-e47c6169-8dfe-49de-85fc-2ff722ef0ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-fb181d9e-0935-4ed3-b868-3852657f5d45,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-dc309248-17ef-432e-8aca-3adc0302deee,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-3cbdb329-591f-44b6-bdb9-52874c01997a,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-f831f1c5-66f3-40c6-9c60-3f4a68a6ef57,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-c9f77b69-48eb-4faf-b575-158ce317a74a,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-2a556209-5680-4156-b3a6-263a76049322,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1351889528-172.17.0.2-1595821251232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38688,DS-a5db572c-d519-423e-9e1a-f4681ea4f9de,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-e47c6169-8dfe-49de-85fc-2ff722ef0ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-fb181d9e-0935-4ed3-b868-3852657f5d45,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-dc309248-17ef-432e-8aca-3adc0302deee,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-3cbdb329-591f-44b6-bdb9-52874c01997a,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-f831f1c5-66f3-40c6-9c60-3f4a68a6ef57,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-c9f77b69-48eb-4faf-b575-158ce317a74a,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-2a556209-5680-4156-b3a6-263a76049322,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1399009046-172.17.0.2-1595821926635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41347,DS-02c3831f-f837-44b9-9b31-4e9b0f33c013,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-b5c5fa40-594c-40dd-8206-224bdfc46376,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-b8eaa7b0-be65-4add-b769-10824ce35196,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-f660cf55-ba11-4922-9100-ade7ed4e1e54,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-403d0881-cbac-4ee9-bedf-fdbc3588205e,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-8be6c83d-b466-47ac-9a8b-def65e950c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34225,DS-8f493dad-8e02-4a72-a5b1-99f7112a193b,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-f6eb420a-b80b-49f0-9451-ad18fd614b5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1399009046-172.17.0.2-1595821926635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41347,DS-02c3831f-f837-44b9-9b31-4e9b0f33c013,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-b5c5fa40-594c-40dd-8206-224bdfc46376,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-b8eaa7b0-be65-4add-b769-10824ce35196,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-f660cf55-ba11-4922-9100-ade7ed4e1e54,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-403d0881-cbac-4ee9-bedf-fdbc3588205e,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-8be6c83d-b466-47ac-9a8b-def65e950c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34225,DS-8f493dad-8e02-4a72-a5b1-99f7112a193b,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-f6eb420a-b80b-49f0-9451-ad18fd614b5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1185078289-172.17.0.2-1595822001134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33321,DS-ba53f123-2900-4de6-bffb-b236cd7934d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-2f60f248-7dbc-47d5-8338-a2335262e974,DISK], DatanodeInfoWithStorage[127.0.0.1:42423,DS-18c422ec-64cc-4e2c-9d13-ff90e89e95ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-c3dccca8-beaf-4d84-88b1-2349cb2e738e,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-37ad9f44-b3a2-4a82-a78b-eea67e29e5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36442,DS-cea6d9c5-a2e5-4e71-b9b0-4ab569daec67,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-9a513206-0e77-4ac4-98b1-981ed6d0d551,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-58576237-c321-4ab1-bfc1-fd968453e6cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1185078289-172.17.0.2-1595822001134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33321,DS-ba53f123-2900-4de6-bffb-b236cd7934d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-2f60f248-7dbc-47d5-8338-a2335262e974,DISK], DatanodeInfoWithStorage[127.0.0.1:42423,DS-18c422ec-64cc-4e2c-9d13-ff90e89e95ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-c3dccca8-beaf-4d84-88b1-2349cb2e738e,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-37ad9f44-b3a2-4a82-a78b-eea67e29e5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36442,DS-cea6d9c5-a2e5-4e71-b9b0-4ab569daec67,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-9a513206-0e77-4ac4-98b1-981ed6d0d551,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-58576237-c321-4ab1-bfc1-fd968453e6cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1789846129-172.17.0.2-1595822428252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41906,DS-77c954d6-df4e-4107-abae-2c5925669be7,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-1d93e219-9e45-42c0-b007-c59f5e22bc55,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-7d915fa1-6ce6-49f4-84e7-f45d7577ce3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-6c0ce561-506d-400a-8f76-30b85aa2a286,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-0a05e194-b1fc-4084-b594-b80039d53f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-dcf3537c-cb8c-4a83-9dfe-974e23d5b9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41539,DS-b2f6d9da-37a8-4fe9-90d0-313188e58372,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-e99512f0-211a-4d68-9252-5a47ff6e5258,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1789846129-172.17.0.2-1595822428252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41906,DS-77c954d6-df4e-4107-abae-2c5925669be7,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-1d93e219-9e45-42c0-b007-c59f5e22bc55,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-7d915fa1-6ce6-49f4-84e7-f45d7577ce3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-6c0ce561-506d-400a-8f76-30b85aa2a286,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-0a05e194-b1fc-4084-b594-b80039d53f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-dcf3537c-cb8c-4a83-9dfe-974e23d5b9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41539,DS-b2f6d9da-37a8-4fe9-90d0-313188e58372,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-e99512f0-211a-4d68-9252-5a47ff6e5258,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-687540632-172.17.0.2-1595822595094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38895,DS-56a81007-b3c4-47c7-9a68-6423b7f4b1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-ce03496f-a30e-4556-939e-7b9a0c5ab16a,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-d0c4ff84-938d-4ecf-94b9-b47d7a09b86f,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-284d845c-eb13-4d24-9e94-583b3026dfe6,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-314ab7a1-aacf-44c1-9668-18af18703b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-b542afe4-b3bb-462d-a24b-b3b0c5c3c82c,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-77a6ffe6-60d7-4f23-bfb8-1760dfffd90e,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-5a721528-fbe3-43d9-b133-c4e9eb853f19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-687540632-172.17.0.2-1595822595094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38895,DS-56a81007-b3c4-47c7-9a68-6423b7f4b1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-ce03496f-a30e-4556-939e-7b9a0c5ab16a,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-d0c4ff84-938d-4ecf-94b9-b47d7a09b86f,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-284d845c-eb13-4d24-9e94-583b3026dfe6,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-314ab7a1-aacf-44c1-9668-18af18703b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-b542afe4-b3bb-462d-a24b-b3b0c5c3c82c,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-77a6ffe6-60d7-4f23-bfb8-1760dfffd90e,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-5a721528-fbe3-43d9-b133-c4e9eb853f19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-169008014-172.17.0.2-1595822797755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35825,DS-255a8e20-196e-483f-8387-89771955002e,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-e6117c5e-5857-480d-9c60-05031491d7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-2e59dde6-08d4-40f5-99e3-82ab3ac739b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-b64921c2-f010-4f6f-9543-847f43965050,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-5330285f-6d85-4590-ad85-2f052ecd21c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-28df63de-0b1d-4f18-8f1f-2a7a0038bafc,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-0f24f32e-d618-4c3b-a24b-d453950970c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-2a7b8957-9db1-4187-9d19-888ba761caa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-169008014-172.17.0.2-1595822797755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35825,DS-255a8e20-196e-483f-8387-89771955002e,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-e6117c5e-5857-480d-9c60-05031491d7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-2e59dde6-08d4-40f5-99e3-82ab3ac739b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-b64921c2-f010-4f6f-9543-847f43965050,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-5330285f-6d85-4590-ad85-2f052ecd21c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-28df63de-0b1d-4f18-8f1f-2a7a0038bafc,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-0f24f32e-d618-4c3b-a24b-d453950970c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-2a7b8957-9db1-4187-9d19-888ba761caa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2013283310-172.17.0.2-1595823287291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43514,DS-11f9534f-cb2f-4ac6-8f26-73afdcac0cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-9b00fbc8-212a-49c8-ad4b-a5136ed20a75,DISK], DatanodeInfoWithStorage[127.0.0.1:34429,DS-4df409d7-4561-4d48-8609-6c050595345c,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-2d4bdc6f-877a-4ed3-883b-ac768b264e61,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-43e1428c-6952-416f-a32b-62018c7dabbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-0709c9cc-3b46-4c42-873b-0cc38c7895fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-f383459a-a77c-416c-a84a-dc841d8a3b05,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-b02c62cb-dcfd-4d58-bf64-6303a66e9414,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2013283310-172.17.0.2-1595823287291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43514,DS-11f9534f-cb2f-4ac6-8f26-73afdcac0cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-9b00fbc8-212a-49c8-ad4b-a5136ed20a75,DISK], DatanodeInfoWithStorage[127.0.0.1:34429,DS-4df409d7-4561-4d48-8609-6c050595345c,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-2d4bdc6f-877a-4ed3-883b-ac768b264e61,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-43e1428c-6952-416f-a32b-62018c7dabbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-0709c9cc-3b46-4c42-873b-0cc38c7895fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-f383459a-a77c-416c-a84a-dc841d8a3b05,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-b02c62cb-dcfd-4d58-bf64-6303a66e9414,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5439
