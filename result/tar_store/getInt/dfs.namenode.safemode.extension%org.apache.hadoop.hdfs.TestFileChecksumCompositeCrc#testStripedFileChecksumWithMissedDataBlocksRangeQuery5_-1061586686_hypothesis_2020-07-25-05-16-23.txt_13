reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 30000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 30000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1488531560-172.17.0.18-1595654524901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41029,DS-f75e9456-9150-4c2a-b587-f10a686978c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-7ecde188-984a-4454-90dd-e6811c9d9134,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-7f50f4e0-c423-4160-8a1b-9219189e7ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:41851,DS-c10d756a-f88b-45bf-a4fd-a1d7a12fa857,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-71d32f08-2809-40ef-8b8d-ac0a308cbde5,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-8f1d0fc5-76d7-4742-8adc-12a2bfed6277,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-d1022b4f-f75e-4dd1-8822-0c5d9854083d,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-2cdccfd7-4097-493a-8fc9-3d38792c1f08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1488531560-172.17.0.18-1595654524901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41029,DS-f75e9456-9150-4c2a-b587-f10a686978c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-7ecde188-984a-4454-90dd-e6811c9d9134,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-7f50f4e0-c423-4160-8a1b-9219189e7ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:41851,DS-c10d756a-f88b-45bf-a4fd-a1d7a12fa857,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-71d32f08-2809-40ef-8b8d-ac0a308cbde5,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-8f1d0fc5-76d7-4742-8adc-12a2bfed6277,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-d1022b4f-f75e-4dd1-8822-0c5d9854083d,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-2cdccfd7-4097-493a-8fc9-3d38792c1f08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 30000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-551707324-172.17.0.18-1595654778635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44697,DS-dd932a57-acd8-481f-83ff-bba83bd67d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-a8659f18-5f2f-4430-a306-5865a667d890,DISK], DatanodeInfoWithStorage[127.0.0.1:37304,DS-f09763de-3e56-45fb-a463-1ce2cba335c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-f01a6ffb-7d01-4048-bd6a-65f140b35e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-d7072908-5231-4020-8917-d074d8acdca9,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-93f58918-964c-4c91-8a1e-69b44fa13f65,DISK], DatanodeInfoWithStorage[127.0.0.1:36516,DS-f5c0368f-f6d0-4871-8285-cc1889079555,DISK], DatanodeInfoWithStorage[127.0.0.1:42072,DS-30932c34-cfa2-4bf7-9f69-5742e7dd8165,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-551707324-172.17.0.18-1595654778635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44697,DS-dd932a57-acd8-481f-83ff-bba83bd67d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-a8659f18-5f2f-4430-a306-5865a667d890,DISK], DatanodeInfoWithStorage[127.0.0.1:37304,DS-f09763de-3e56-45fb-a463-1ce2cba335c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-f01a6ffb-7d01-4048-bd6a-65f140b35e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-d7072908-5231-4020-8917-d074d8acdca9,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-93f58918-964c-4c91-8a1e-69b44fa13f65,DISK], DatanodeInfoWithStorage[127.0.0.1:36516,DS-f5c0368f-f6d0-4871-8285-cc1889079555,DISK], DatanodeInfoWithStorage[127.0.0.1:42072,DS-30932c34-cfa2-4bf7-9f69-5742e7dd8165,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 30000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-293960615-172.17.0.18-1595654817402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35631,DS-14b32b61-1c7a-4c03-9615-83c76c69f626,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-a9d1c965-c913-418d-bf14-2a590068a7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-74b99638-5b91-4092-832d-101118d12dab,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-b65bcb05-b55d-4d6c-a5b3-0ef1086c55fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-ee8c160a-03be-4876-abc2-3771ddd04ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-a83fc678-bbcb-404a-a932-92cff6cba299,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-d462ca2a-458b-4786-952e-d8ce5efb27e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-0466d5be-1861-4ea6-a882-203872945144,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-293960615-172.17.0.18-1595654817402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35631,DS-14b32b61-1c7a-4c03-9615-83c76c69f626,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-a9d1c965-c913-418d-bf14-2a590068a7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-74b99638-5b91-4092-832d-101118d12dab,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-b65bcb05-b55d-4d6c-a5b3-0ef1086c55fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-ee8c160a-03be-4876-abc2-3771ddd04ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-a83fc678-bbcb-404a-a932-92cff6cba299,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-d462ca2a-458b-4786-952e-d8ce5efb27e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-0466d5be-1861-4ea6-a882-203872945144,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 30000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1886114363-172.17.0.18-1595655354332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39865,DS-7d62f5b5-6010-40ad-87b6-aa89ae37eb58,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-dd59d7c6-1833-4d1c-be5e-9ec69dd2eadc,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-a553ec78-d921-484e-9717-9a7d282f812d,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-caad9502-9545-41ab-bb8a-ae35c587e24b,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-fcbf3380-1e1b-48dd-958d-689a625fb23c,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-ac239894-9a70-4329-9bcf-a25c58635cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-0245a937-e1bd-455e-811f-97a13f3e3328,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-7be08028-a39d-4ed1-a096-bd24391500d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1886114363-172.17.0.18-1595655354332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39865,DS-7d62f5b5-6010-40ad-87b6-aa89ae37eb58,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-dd59d7c6-1833-4d1c-be5e-9ec69dd2eadc,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-a553ec78-d921-484e-9717-9a7d282f812d,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-caad9502-9545-41ab-bb8a-ae35c587e24b,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-fcbf3380-1e1b-48dd-958d-689a625fb23c,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-ac239894-9a70-4329-9bcf-a25c58635cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-0245a937-e1bd-455e-811f-97a13f3e3328,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-7be08028-a39d-4ed1-a096-bd24391500d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 30000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1030973092-172.17.0.18-1595655640606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42245,DS-0bc21383-f59c-4e67-9783-d50695785ced,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-601cafe2-bb90-40e7-b7aa-782d1e0ab16c,DISK], DatanodeInfoWithStorage[127.0.0.1:40154,DS-3c9ed5d3-a683-4f02-8720-df74f4d6b66e,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-6bf548e8-76bb-45f8-bba9-d0a18f204de0,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-b17bf7db-2538-45f3-b89a-e53777c645ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-8209b1a1-bbd2-40d2-9c15-e67b72062dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-d2ad46d0-1526-4bb4-82de-4cd846c1255a,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-2f95989c-664f-4fff-b4b1-43bb515dc098,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1030973092-172.17.0.18-1595655640606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42245,DS-0bc21383-f59c-4e67-9783-d50695785ced,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-601cafe2-bb90-40e7-b7aa-782d1e0ab16c,DISK], DatanodeInfoWithStorage[127.0.0.1:40154,DS-3c9ed5d3-a683-4f02-8720-df74f4d6b66e,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-6bf548e8-76bb-45f8-bba9-d0a18f204de0,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-b17bf7db-2538-45f3-b89a-e53777c645ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-8209b1a1-bbd2-40d2-9c15-e67b72062dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-d2ad46d0-1526-4bb4-82de-4cd846c1255a,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-2f95989c-664f-4fff-b4b1-43bb515dc098,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 30000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-463681677-172.17.0.18-1595655871910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35891,DS-ae17faae-49cd-4d8f-ad4e-f92ef554f4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-a4549e18-04fd-4e4a-ab6d-0cd0b8312f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-a8f7d109-86ea-4010-95a2-aef8203a5b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-ddd349d7-1933-4303-9b7c-e357d19f79a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-c1835db6-9f14-4997-a931-a879349bf209,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-64d03f0b-47a4-4bd1-baf8-fad6235d6493,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-4aeda36a-1fe7-4862-a888-de4a760fdc08,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-f63c8536-2e1e-4a4a-9aeb-d76e71218df0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-463681677-172.17.0.18-1595655871910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35891,DS-ae17faae-49cd-4d8f-ad4e-f92ef554f4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-a4549e18-04fd-4e4a-ab6d-0cd0b8312f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-a8f7d109-86ea-4010-95a2-aef8203a5b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-ddd349d7-1933-4303-9b7c-e357d19f79a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-c1835db6-9f14-4997-a931-a879349bf209,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-64d03f0b-47a4-4bd1-baf8-fad6235d6493,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-4aeda36a-1fe7-4862-a888-de4a760fdc08,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-f63c8536-2e1e-4a4a-9aeb-d76e71218df0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 30000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-278636270-172.17.0.18-1595656156703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38624,DS-46aba664-1128-4e8c-bfcc-26b16adcb697,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-c0d1c074-493c-46e2-95e4-3ccf78ac9986,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-daf259f1-59bf-40c8-82d1-9abf5b9c0121,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-b7f145eb-de17-4e1f-afe6-ebacb4a6007d,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-7e4d2598-86c9-42ea-8137-dc4b3d968a14,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-434b81f2-bfb3-4483-a37c-97b158a9a8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-5a6d0e71-0ff8-4ec7-bd79-8336cd192235,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-0a0f867e-7422-42fd-a2f4-075c3c20728c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-278636270-172.17.0.18-1595656156703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38624,DS-46aba664-1128-4e8c-bfcc-26b16adcb697,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-c0d1c074-493c-46e2-95e4-3ccf78ac9986,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-daf259f1-59bf-40c8-82d1-9abf5b9c0121,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-b7f145eb-de17-4e1f-afe6-ebacb4a6007d,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-7e4d2598-86c9-42ea-8137-dc4b3d968a14,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-434b81f2-bfb3-4483-a37c-97b158a9a8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-5a6d0e71-0ff8-4ec7-bd79-8336cd192235,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-0a0f867e-7422-42fd-a2f4-075c3c20728c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 30000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-469751978-172.17.0.18-1595656338381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40368,DS-24e4a3a7-2c13-4fad-9cc0-72f84c74856c,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-c982b0a2-e1b0-4304-9dc3-af59f71cf1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-5a2e4a35-8643-4f1a-bb55-156ce9a03c04,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-f6f34b42-9543-4be1-9c12-9c2136ad0511,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-09cecd5c-a645-4bed-aeb4-d733ce6774fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-1c84ca44-ed07-4bb5-b1fb-3cceb906d881,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-8a8ae9f6-9b27-4c04-a2b7-63d584a4b140,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-5afdfeb8-e858-4555-85fe-22eb1e4c95dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-469751978-172.17.0.18-1595656338381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40368,DS-24e4a3a7-2c13-4fad-9cc0-72f84c74856c,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-c982b0a2-e1b0-4304-9dc3-af59f71cf1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-5a2e4a35-8643-4f1a-bb55-156ce9a03c04,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-f6f34b42-9543-4be1-9c12-9c2136ad0511,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-09cecd5c-a645-4bed-aeb4-d733ce6774fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-1c84ca44-ed07-4bb5-b1fb-3cceb906d881,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-8a8ae9f6-9b27-4c04-a2b7-63d584a4b140,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-5afdfeb8-e858-4555-85fe-22eb1e4c95dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 30000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1578714464-172.17.0.18-1595656701378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39179,DS-a97a659d-bed6-44db-97d1-a8eb154691a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-b7400f45-bb42-4bce-9b01-3b4cb206bd4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45120,DS-13332bde-8e8f-467b-ad7e-a3a0c04b948a,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-bbeac71e-b2c7-4914-abeb-8266f531b254,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-9c1bfa5a-40db-425d-9138-d312d4694849,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-7cc9b189-c1fc-4d88-a2f3-e9982e824e03,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-3d6322dc-10d0-4628-9a3c-c7b6fa775ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:34734,DS-41f8370c-167b-47c2-8602-96f54bbbd237,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1578714464-172.17.0.18-1595656701378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39179,DS-a97a659d-bed6-44db-97d1-a8eb154691a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-b7400f45-bb42-4bce-9b01-3b4cb206bd4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45120,DS-13332bde-8e8f-467b-ad7e-a3a0c04b948a,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-bbeac71e-b2c7-4914-abeb-8266f531b254,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-9c1bfa5a-40db-425d-9138-d312d4694849,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-7cc9b189-c1fc-4d88-a2f3-e9982e824e03,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-3d6322dc-10d0-4628-9a3c-c7b6fa775ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:34734,DS-41f8370c-167b-47c2-8602-96f54bbbd237,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 30000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1291615271-172.17.0.18-1595657225335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36076,DS-edd8a853-ec19-4e98-a812-f06bd3e599a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-8d040d3a-1780-4c76-99a8-a3951bb17b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-d07cf7a5-40ad-4f64-ac9a-22ac2b0011a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-c7e079b6-99e4-4200-8a41-d85da790711c,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-184559e3-3aa7-4e98-9175-b2f3e64c0a11,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-cbba2878-2837-4cb8-813c-2667bedf3711,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-23e748e2-e90f-4e51-a9be-c061f054e7be,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-1713f2da-07ee-4389-bbae-22a4c3e306b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1291615271-172.17.0.18-1595657225335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36076,DS-edd8a853-ec19-4e98-a812-f06bd3e599a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-8d040d3a-1780-4c76-99a8-a3951bb17b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-d07cf7a5-40ad-4f64-ac9a-22ac2b0011a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-c7e079b6-99e4-4200-8a41-d85da790711c,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-184559e3-3aa7-4e98-9175-b2f3e64c0a11,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-cbba2878-2837-4cb8-813c-2667bedf3711,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-23e748e2-e90f-4e51-a9be-c061f054e7be,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-1713f2da-07ee-4389-bbae-22a4c3e306b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 30000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-899929476-172.17.0.18-1595657412626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38195,DS-50a82704-1780-418d-8322-75035fef6446,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-11860cdb-6920-4fdb-a4f7-a504f00d03a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-7ae13d02-d16c-4a4f-a019-efc96c29f7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35524,DS-248f86ae-3a77-4373-90b5-f17377a264d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-f7a62905-b747-4df7-8040-94381f77cda9,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-570a9ee6-c5a9-4486-9440-3f681be21578,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-71757a3d-86c4-4ba7-ad77-1f3b9ceafb02,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-bd5c817a-3bb6-4f05-a8b9-8cf367260d17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-899929476-172.17.0.18-1595657412626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38195,DS-50a82704-1780-418d-8322-75035fef6446,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-11860cdb-6920-4fdb-a4f7-a504f00d03a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-7ae13d02-d16c-4a4f-a019-efc96c29f7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35524,DS-248f86ae-3a77-4373-90b5-f17377a264d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-f7a62905-b747-4df7-8040-94381f77cda9,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-570a9ee6-c5a9-4486-9440-3f681be21578,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-71757a3d-86c4-4ba7-ad77-1f3b9ceafb02,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-bd5c817a-3bb6-4f05-a8b9-8cf367260d17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 30000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1289093736-172.17.0.18-1595657954258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37869,DS-7e15c11d-a222-48ca-8e09-16507096e285,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-70fa7da8-8295-4470-b2bc-5f41258a9d85,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-0cc79e3e-0d4d-4916-8b7e-edb2e200055f,DISK], DatanodeInfoWithStorage[127.0.0.1:45532,DS-aff396f6-41c0-49d2-a730-9eea66e6df5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-598f1203-579e-4d2a-8e10-4b765205635f,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-30564e9c-7a7b-4f9c-aa01-ddddf6fd97c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-3c266e63-2bb3-4823-8921-4208f4d9f3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-9e55a46c-7647-4df9-99ad-e3590d21499c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1289093736-172.17.0.18-1595657954258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37869,DS-7e15c11d-a222-48ca-8e09-16507096e285,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-70fa7da8-8295-4470-b2bc-5f41258a9d85,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-0cc79e3e-0d4d-4916-8b7e-edb2e200055f,DISK], DatanodeInfoWithStorage[127.0.0.1:45532,DS-aff396f6-41c0-49d2-a730-9eea66e6df5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-598f1203-579e-4d2a-8e10-4b765205635f,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-30564e9c-7a7b-4f9c-aa01-ddddf6fd97c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-3c266e63-2bb3-4823-8921-4208f4d9f3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-9e55a46c-7647-4df9-99ad-e3590d21499c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 30000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1624455829-172.17.0.18-1595658397100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45563,DS-dd8c6c7a-9c21-4dd4-bc98-eb70ce33df66,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-de688165-2998-4650-a37c-c43fdfeb32b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-01447e41-7a05-4d8d-909e-60e139ea2af8,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-dbc9bdff-a1ac-41b9-82e3-2869629af598,DISK], DatanodeInfoWithStorage[127.0.0.1:46138,DS-ebfff91f-b776-45f8-8085-99a1fa5cf25c,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-6a76a7d0-d8c1-42c5-b013-388decc4ea86,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-a7ad664d-823d-4424-8745-16b811e5d5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37634,DS-f4f64633-64f7-4bca-bce0-c716bbfded26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1624455829-172.17.0.18-1595658397100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45563,DS-dd8c6c7a-9c21-4dd4-bc98-eb70ce33df66,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-de688165-2998-4650-a37c-c43fdfeb32b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-01447e41-7a05-4d8d-909e-60e139ea2af8,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-dbc9bdff-a1ac-41b9-82e3-2869629af598,DISK], DatanodeInfoWithStorage[127.0.0.1:46138,DS-ebfff91f-b776-45f8-8085-99a1fa5cf25c,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-6a76a7d0-d8c1-42c5-b013-388decc4ea86,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-a7ad664d-823d-4424-8745-16b811e5d5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37634,DS-f4f64633-64f7-4bca-bce0-c716bbfded26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 30000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2090211677-172.17.0.18-1595658502807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35226,DS-9eba706a-cb12-477a-b7eb-f8ea4930f5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33776,DS-621e6abc-70a5-43f0-94c4-639187d9258f,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-981f3726-7566-4598-8f8b-e07b17ea52f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-af5d5930-00eb-43bf-9e24-f818ebfe2057,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-b24af8b3-5c1f-4ae6-9e2a-0ffa9a9cea1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-27290987-b9bb-47cb-b804-d5e9239f1ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-29815c80-717c-46b8-b6d4-fa7a0a0b4078,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-768fc2bf-c4db-4a46-aed2-e4c52ddf9c44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2090211677-172.17.0.18-1595658502807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35226,DS-9eba706a-cb12-477a-b7eb-f8ea4930f5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33776,DS-621e6abc-70a5-43f0-94c4-639187d9258f,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-981f3726-7566-4598-8f8b-e07b17ea52f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-af5d5930-00eb-43bf-9e24-f818ebfe2057,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-b24af8b3-5c1f-4ae6-9e2a-0ffa9a9cea1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-27290987-b9bb-47cb-b804-d5e9239f1ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-29815c80-717c-46b8-b6d4-fa7a0a0b4078,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-768fc2bf-c4db-4a46-aed2-e4c52ddf9c44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 30000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2135185361-172.17.0.18-1595658646864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38462,DS-e6bd94e8-f964-4806-bca1-15d081cb776f,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-a5c486b1-17df-4d03-aa2a-b768e5901dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-7cd37bfc-410b-4c5d-a566-a8c537d6e4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-b31b4eb9-f93c-42d9-809c-6d4712e9cc39,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-358192d3-09d2-488b-a17e-8912b115c038,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-6c4bf1d1-f870-420f-8929-2727f6950041,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-935a6b1e-8516-4b44-a949-d62304081dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-44f6667c-dd4e-4116-8480-0176b1b96db8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2135185361-172.17.0.18-1595658646864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38462,DS-e6bd94e8-f964-4806-bca1-15d081cb776f,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-a5c486b1-17df-4d03-aa2a-b768e5901dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-7cd37bfc-410b-4c5d-a566-a8c537d6e4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-b31b4eb9-f93c-42d9-809c-6d4712e9cc39,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-358192d3-09d2-488b-a17e-8912b115c038,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-6c4bf1d1-f870-420f-8929-2727f6950041,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-935a6b1e-8516-4b44-a949-d62304081dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-44f6667c-dd4e-4116-8480-0176b1b96db8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 30000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-713613688-172.17.0.18-1595658794461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39777,DS-2bbe4bd2-b668-4863-9266-29fbbc453a16,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-3cf22f96-a407-419b-96b8-23e55d31bf44,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-ab07026e-93eb-4fde-af1c-96ba9de2ac78,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-d1eb0236-7c4b-4084-b4ed-36641c889073,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-8f9e3891-f46e-4950-ac27-dcb27a7b5885,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-7a46e08b-8630-4c39-a8d9-5803cc78276f,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-75ea63fc-9943-4869-acb9-c0549f00ace0,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-be066e19-d20a-4738-9c40-2feb177f0a3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-713613688-172.17.0.18-1595658794461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39777,DS-2bbe4bd2-b668-4863-9266-29fbbc453a16,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-3cf22f96-a407-419b-96b8-23e55d31bf44,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-ab07026e-93eb-4fde-af1c-96ba9de2ac78,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-d1eb0236-7c4b-4084-b4ed-36641c889073,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-8f9e3891-f46e-4950-ac27-dcb27a7b5885,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-7a46e08b-8630-4c39-a8d9-5803cc78276f,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-75ea63fc-9943-4869-acb9-c0549f00ace0,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-be066e19-d20a-4738-9c40-2feb177f0a3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 30000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-421068482-172.17.0.18-1595659217562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44470,DS-ca57d378-53e8-4374-918a-44a845f6df9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-158d2b1d-0c24-4c2d-9ea4-9efcfb5dabaa,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-5ffe7c43-7344-4f09-a0bb-b987a4118736,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-8c369e4c-d76e-4467-b7db-445b536a60e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-1879ef83-c351-4eca-b1be-28ca47136384,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-222cbda8-7226-4fe6-a151-b81f3745999a,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-0b24c1a1-fe4c-4c83-bda6-6c489af65d15,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-ca8a6fbe-4161-4d31-b227-a2805653dbbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-421068482-172.17.0.18-1595659217562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44470,DS-ca57d378-53e8-4374-918a-44a845f6df9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-158d2b1d-0c24-4c2d-9ea4-9efcfb5dabaa,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-5ffe7c43-7344-4f09-a0bb-b987a4118736,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-8c369e4c-d76e-4467-b7db-445b536a60e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-1879ef83-c351-4eca-b1be-28ca47136384,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-222cbda8-7226-4fe6-a151-b81f3745999a,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-0b24c1a1-fe4c-4c83-bda6-6c489af65d15,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-ca8a6fbe-4161-4d31-b227-a2805653dbbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5438
