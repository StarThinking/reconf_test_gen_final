reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-851062342-172.17.0.10-1595942790700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44856,DS-081c7c89-062b-4aea-9ed9-b9694402e9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-029afc09-6df5-441d-ba88-ee188f1dff9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-2619886f-5426-4f19-a15b-9caa6ea7cdeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-cec0447e-7aaa-4179-bd05-179ef65cd97e,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-04876d76-1318-4e49-9550-0443ed1fb71b,DISK], DatanodeInfoWithStorage[127.0.0.1:34168,DS-10f88c19-a883-4a6e-b0d7-6944a68099b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-c7ee1864-b96a-4e41-8d05-e2125e99d4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-193bd4bf-2e73-48ac-b9ad-fc4fd6234142,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-851062342-172.17.0.10-1595942790700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44856,DS-081c7c89-062b-4aea-9ed9-b9694402e9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-029afc09-6df5-441d-ba88-ee188f1dff9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-2619886f-5426-4f19-a15b-9caa6ea7cdeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-cec0447e-7aaa-4179-bd05-179ef65cd97e,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-04876d76-1318-4e49-9550-0443ed1fb71b,DISK], DatanodeInfoWithStorage[127.0.0.1:34168,DS-10f88c19-a883-4a6e-b0d7-6944a68099b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-c7ee1864-b96a-4e41-8d05-e2125e99d4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-193bd4bf-2e73-48ac-b9ad-fc4fd6234142,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1105398558-172.17.0.10-1595943017440:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34230,DS-84a5f203-bb57-4510-a6c1-596ee6ecf408,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-7cb46d44-77fd-4163-92bd-3fae35119416,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-1d98bca2-d969-4937-a903-6f45c9221c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-7288bed2-309e-400d-a559-732d67cd9af7,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-1c7a688a-ca8b-461a-a660-1c4f7c2f6353,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-bbe04575-2499-474d-8b7c-8d0b3d6f723e,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-c68fa5cb-d4fe-456a-a1a6-c189fb0a9fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-ce4f4238-bb2c-44b3-b10d-658008842afd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1105398558-172.17.0.10-1595943017440:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34230,DS-84a5f203-bb57-4510-a6c1-596ee6ecf408,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-7cb46d44-77fd-4163-92bd-3fae35119416,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-1d98bca2-d969-4937-a903-6f45c9221c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-7288bed2-309e-400d-a559-732d67cd9af7,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-1c7a688a-ca8b-461a-a660-1c4f7c2f6353,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-bbe04575-2499-474d-8b7c-8d0b3d6f723e,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-c68fa5cb-d4fe-456a-a1a6-c189fb0a9fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-ce4f4238-bb2c-44b3-b10d-658008842afd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-178825802-172.17.0.10-1595943153839:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41113,DS-59acbf8c-fe40-4184-a7b8-d062f6106c39,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-f54f9120-589a-4280-bccc-565f45227fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-259b060b-7a48-421c-b222-d58fc2363edf,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-4d040fbf-aa79-413c-8277-5399c13d0bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-05f1b6c9-da57-407e-90fd-2a0e7df9a88e,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-d6b6b25a-88ef-496a-a947-165e302c003c,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-e3e3e0cc-776d-43f6-91e4-d8fa911785cf,DISK], DatanodeInfoWithStorage[127.0.0.1:32954,DS-468f8c8b-4511-4ce0-bb57-a6725dc74127,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-178825802-172.17.0.10-1595943153839:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41113,DS-59acbf8c-fe40-4184-a7b8-d062f6106c39,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-f54f9120-589a-4280-bccc-565f45227fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-259b060b-7a48-421c-b222-d58fc2363edf,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-4d040fbf-aa79-413c-8277-5399c13d0bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-05f1b6c9-da57-407e-90fd-2a0e7df9a88e,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-d6b6b25a-88ef-496a-a947-165e302c003c,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-e3e3e0cc-776d-43f6-91e4-d8fa911785cf,DISK], DatanodeInfoWithStorage[127.0.0.1:32954,DS-468f8c8b-4511-4ce0-bb57-a6725dc74127,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-363187632-172.17.0.10-1595943638502:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36558,DS-5f106348-7bf3-4683-9b4a-70a5c73f2e99,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-a4fc7485-2147-42bf-9259-44934326548b,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-c5dc57b7-eff1-4c9e-8fb2-a35e8c263369,DISK], DatanodeInfoWithStorage[127.0.0.1:45471,DS-45a65880-be17-41e8-94a8-328c924cc7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-ab7772fd-ba57-4446-ad92-8c500062c056,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-c85edee4-bc79-47fb-ba97-df5de103ed6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-d337892a-d5d2-4feb-855b-802b550cebe7,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-87fdca62-0214-4839-8150-a5d5c594055c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-363187632-172.17.0.10-1595943638502:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36558,DS-5f106348-7bf3-4683-9b4a-70a5c73f2e99,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-a4fc7485-2147-42bf-9259-44934326548b,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-c5dc57b7-eff1-4c9e-8fb2-a35e8c263369,DISK], DatanodeInfoWithStorage[127.0.0.1:45471,DS-45a65880-be17-41e8-94a8-328c924cc7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-ab7772fd-ba57-4446-ad92-8c500062c056,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-c85edee4-bc79-47fb-ba97-df5de103ed6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-d337892a-d5d2-4feb-855b-802b550cebe7,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-87fdca62-0214-4839-8150-a5d5c594055c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-334277669-172.17.0.10-1595944046385:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42912,DS-c56aacdb-769d-4caf-aad3-15788e80d36e,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-d24af1cc-edf8-4c8c-8eb4-d6fe5098d03b,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-66c0a4f2-71c9-4825-92c3-e6bd41356f42,DISK], DatanodeInfoWithStorage[127.0.0.1:36746,DS-2f5db9f5-f7e3-4fcf-abef-95e1e939c161,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-3b7aa820-61ca-4fc4-8ae1-6fb5fce75a48,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-9ce963ce-29db-4057-bd9a-67bb3291ece7,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-2fe2eac3-eca1-4672-90c0-003cd996eb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-ab711dfb-3322-4e6e-9383-fcf2775edc73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-334277669-172.17.0.10-1595944046385:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42912,DS-c56aacdb-769d-4caf-aad3-15788e80d36e,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-d24af1cc-edf8-4c8c-8eb4-d6fe5098d03b,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-66c0a4f2-71c9-4825-92c3-e6bd41356f42,DISK], DatanodeInfoWithStorage[127.0.0.1:36746,DS-2f5db9f5-f7e3-4fcf-abef-95e1e939c161,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-3b7aa820-61ca-4fc4-8ae1-6fb5fce75a48,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-9ce963ce-29db-4057-bd9a-67bb3291ece7,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-2fe2eac3-eca1-4672-90c0-003cd996eb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-ab711dfb-3322-4e6e-9383-fcf2775edc73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-413141571-172.17.0.10-1595944385863:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34177,DS-987262b2-659e-46f0-b5ba-89b81fdbdeac,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-f2c235e7-665f-4a61-b652-0f7577b66779,DISK], DatanodeInfoWithStorage[127.0.0.1:38233,DS-aba1ea3c-44f1-406b-bad3-2da677e472ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42706,DS-1c2bcc17-fb85-4e12-b449-e51562d8c0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-f8624ad1-691d-499d-8ba9-2741e5a510ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-310ac0ba-8610-41c5-989c-aecadc928028,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-fad3e375-128d-4b78-83e9-a448aae03e23,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-1b9c840f-81ba-49a8-8903-32c424633cc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-413141571-172.17.0.10-1595944385863:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34177,DS-987262b2-659e-46f0-b5ba-89b81fdbdeac,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-f2c235e7-665f-4a61-b652-0f7577b66779,DISK], DatanodeInfoWithStorage[127.0.0.1:38233,DS-aba1ea3c-44f1-406b-bad3-2da677e472ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42706,DS-1c2bcc17-fb85-4e12-b449-e51562d8c0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-f8624ad1-691d-499d-8ba9-2741e5a510ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-310ac0ba-8610-41c5-989c-aecadc928028,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-fad3e375-128d-4b78-83e9-a448aae03e23,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-1b9c840f-81ba-49a8-8903-32c424633cc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2116118971-172.17.0.10-1595944522725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39067,DS-cbb56bd5-e1f2-41a1-ae4d-9dfe22bb0b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-895bc551-3715-40da-96f5-125d5af6f82a,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-840d62d2-4a78-4736-b9f3-aad61baaddb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-1399519b-ec36-43f8-977b-ad3905628c98,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-562d9df6-3589-46db-861d-a0cc661a4f45,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-c2bdc3f5-0507-44ac-8e29-d5f367da0a12,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-2fb3222c-9a5b-4b93-8c96-5bb30896c99b,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-fd199e0a-3030-4b85-8269-568dd53278d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2116118971-172.17.0.10-1595944522725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39067,DS-cbb56bd5-e1f2-41a1-ae4d-9dfe22bb0b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-895bc551-3715-40da-96f5-125d5af6f82a,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-840d62d2-4a78-4736-b9f3-aad61baaddb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-1399519b-ec36-43f8-977b-ad3905628c98,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-562d9df6-3589-46db-861d-a0cc661a4f45,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-c2bdc3f5-0507-44ac-8e29-d5f367da0a12,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-2fb3222c-9a5b-4b93-8c96-5bb30896c99b,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-fd199e0a-3030-4b85-8269-568dd53278d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-340427717-172.17.0.10-1595944655299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35482,DS-6fe7ce20-af65-4e33-8045-af82085e4d11,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-9430863e-33cd-4640-aa19-b146a60efc22,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-f0065367-e81c-4d53-9604-cf68e6629199,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-a6302e95-d207-4cd6-a66d-aa8327af08e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-ee8e26bf-ce66-4e66-b803-29a690dc2d93,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-e9f94a85-ccf0-497e-a121-92e9cdd30108,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-9111531c-8a69-4dfb-b593-ebba10ef5f97,DISK], DatanodeInfoWithStorage[127.0.0.1:40117,DS-5fc6e0c5-0268-47de-b113-3642af531b82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-340427717-172.17.0.10-1595944655299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35482,DS-6fe7ce20-af65-4e33-8045-af82085e4d11,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-9430863e-33cd-4640-aa19-b146a60efc22,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-f0065367-e81c-4d53-9604-cf68e6629199,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-a6302e95-d207-4cd6-a66d-aa8327af08e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-ee8e26bf-ce66-4e66-b803-29a690dc2d93,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-e9f94a85-ccf0-497e-a121-92e9cdd30108,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-9111531c-8a69-4dfb-b593-ebba10ef5f97,DISK], DatanodeInfoWithStorage[127.0.0.1:40117,DS-5fc6e0c5-0268-47de-b113-3642af531b82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-240761295-172.17.0.10-1595946243411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46680,DS-0e60dc02-d61a-4deb-9ecf-eade12f20cad,DISK], DatanodeInfoWithStorage[127.0.0.1:43011,DS-31311f89-f8d8-4b24-9a4a-05c38905d7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-9338f763-e085-4da7-9bba-d8073d3b7564,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-495a2380-6d37-43bd-b571-9cd3b6804a42,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-66b6976b-a3cd-40f8-bab9-4092656502dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-858d3f91-412a-431e-b055-30f63f61bebc,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-a38c5a15-7114-4ff9-ba2e-5f541afdf647,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-fada7378-aa6c-414c-86e8-5f0fd875094c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-240761295-172.17.0.10-1595946243411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46680,DS-0e60dc02-d61a-4deb-9ecf-eade12f20cad,DISK], DatanodeInfoWithStorage[127.0.0.1:43011,DS-31311f89-f8d8-4b24-9a4a-05c38905d7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-9338f763-e085-4da7-9bba-d8073d3b7564,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-495a2380-6d37-43bd-b571-9cd3b6804a42,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-66b6976b-a3cd-40f8-bab9-4092656502dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-858d3f91-412a-431e-b055-30f63f61bebc,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-a38c5a15-7114-4ff9-ba2e-5f541afdf647,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-fada7378-aa6c-414c-86e8-5f0fd875094c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1380185846-172.17.0.10-1595946389300:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35511,DS-16104a6e-6cc9-4162-9265-3b46b0687e06,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-a42c39aa-d253-40ec-b145-ccbecc1d03b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-1556b6cf-a592-4f8d-aecc-3a52d02556b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-38f482c7-ee41-4c57-9533-37a9699b54a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-d3b3d15e-1a6c-4609-b667-eaaea74aa0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-82281bfe-22e9-43e6-bda9-9f30f9198122,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-c03ba9fc-73ef-4f15-add9-13d15bf2bcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43164,DS-7169c99e-0b40-4902-9a27-e7e306a27663,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1380185846-172.17.0.10-1595946389300:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35511,DS-16104a6e-6cc9-4162-9265-3b46b0687e06,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-a42c39aa-d253-40ec-b145-ccbecc1d03b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-1556b6cf-a592-4f8d-aecc-3a52d02556b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-38f482c7-ee41-4c57-9533-37a9699b54a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-d3b3d15e-1a6c-4609-b667-eaaea74aa0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-82281bfe-22e9-43e6-bda9-9f30f9198122,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-c03ba9fc-73ef-4f15-add9-13d15bf2bcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43164,DS-7169c99e-0b40-4902-9a27-e7e306a27663,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1067924717-172.17.0.10-1595946572654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39577,DS-edc4e635-951e-46c3-b6ba-7b2d1351694c,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-1161418d-dd00-4333-828c-c51e8cace846,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-a2a5d063-c6d8-4ac9-a143-7332a1036f91,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-c142e279-b16b-4d75-9a08-13c9b9d2670e,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-516ba58e-bde0-42c8-97da-ea4410a0f081,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-d3ce7881-7f91-4cce-be40-69a9b2ddc8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-28c8238a-7a6a-45bf-863d-92fcf59cd070,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-7c79a08e-826c-4ffe-b91e-b605123a3ba1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1067924717-172.17.0.10-1595946572654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39577,DS-edc4e635-951e-46c3-b6ba-7b2d1351694c,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-1161418d-dd00-4333-828c-c51e8cace846,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-a2a5d063-c6d8-4ac9-a143-7332a1036f91,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-c142e279-b16b-4d75-9a08-13c9b9d2670e,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-516ba58e-bde0-42c8-97da-ea4410a0f081,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-d3ce7881-7f91-4cce-be40-69a9b2ddc8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-28c8238a-7a6a-45bf-863d-92fcf59cd070,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-7c79a08e-826c-4ffe-b91e-b605123a3ba1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1530773937-172.17.0.10-1595946607264:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36987,DS-0b075339-57d6-473d-9521-694e5c6483f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-d49640c3-e277-4d7f-af13-9367f59f1b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-37a48ef9-8b9b-4f20-bf58-34d1a413c6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-c2d21c25-5d31-4409-9a9a-8de3593f33d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-4ac3c1a4-1098-4160-bee9-9abce3d2cc84,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-f8fdb74c-29fb-4e21-8e0f-9b0b3c0ef8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-22816619-a3c5-4eb5-a9ad-8d7855a60d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-21b73b30-d9c6-44a2-8ab3-0e4d5b4527fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1530773937-172.17.0.10-1595946607264:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36987,DS-0b075339-57d6-473d-9521-694e5c6483f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-d49640c3-e277-4d7f-af13-9367f59f1b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-37a48ef9-8b9b-4f20-bf58-34d1a413c6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-c2d21c25-5d31-4409-9a9a-8de3593f33d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-4ac3c1a4-1098-4160-bee9-9abce3d2cc84,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-f8fdb74c-29fb-4e21-8e0f-9b0b3c0ef8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-22816619-a3c5-4eb5-a9ad-8d7855a60d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-21b73b30-d9c6-44a2-8ab3-0e4d5b4527fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-950360014-172.17.0.10-1595947257077:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43953,DS-ce7cf2ed-0e49-44f3-853b-562d875dae23,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-fcac64af-3a5b-45a8-891a-b294f4d4068e,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-502e3c5e-2339-45ca-8674-c17dcc4edf63,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-4e65bf90-65ee-4fa8-929c-27d4bb442d33,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-bc809064-9f6e-4502-82e6-ce205a951080,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-9395620b-1a8d-4ef2-9ddc-6ce6f6b9f8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-292a2c0d-b733-4116-ad97-c841f95866bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-a5851a42-d9e0-4a38-878a-b3215694c9cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-950360014-172.17.0.10-1595947257077:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43953,DS-ce7cf2ed-0e49-44f3-853b-562d875dae23,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-fcac64af-3a5b-45a8-891a-b294f4d4068e,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-502e3c5e-2339-45ca-8674-c17dcc4edf63,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-4e65bf90-65ee-4fa8-929c-27d4bb442d33,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-bc809064-9f6e-4502-82e6-ce205a951080,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-9395620b-1a8d-4ef2-9ddc-6ce6f6b9f8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-292a2c0d-b733-4116-ad97-c841f95866bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-a5851a42-d9e0-4a38-878a-b3215694c9cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-260067714-172.17.0.10-1595947421801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42762,DS-e5a519b3-3a36-48b3-a69f-9f4b1179443c,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-2ddb8261-e39c-48cf-be5a-9ae5fee137b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-931eb612-be66-47fe-984f-79ac46858991,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-a03d5f7f-c477-43a2-8cf6-16d541f76952,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-25a414f0-6692-4afb-9eda-885461da247b,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-7e91a79b-8c40-471e-97b5-d013e4ab6017,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-9a2c5dc4-8b04-4a13-8e5d-91a71360a3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-c6323f20-9656-45b1-9a8b-4d3482fbcbe3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-260067714-172.17.0.10-1595947421801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42762,DS-e5a519b3-3a36-48b3-a69f-9f4b1179443c,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-2ddb8261-e39c-48cf-be5a-9ae5fee137b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-931eb612-be66-47fe-984f-79ac46858991,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-a03d5f7f-c477-43a2-8cf6-16d541f76952,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-25a414f0-6692-4afb-9eda-885461da247b,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-7e91a79b-8c40-471e-97b5-d013e4ab6017,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-9a2c5dc4-8b04-4a13-8e5d-91a71360a3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-c6323f20-9656-45b1-9a8b-4d3482fbcbe3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-551910146-172.17.0.10-1595947452229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44938,DS-3c095572-ff68-4b10-9571-21592190c3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-eb6977a6-f996-407c-8138-21931225f7da,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-5aa9aa42-bf8e-40c9-aee7-19d379b932a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-df669aea-6fe2-4068-b98c-50eee28736c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-221a5c25-6664-448b-9fdb-74ae9ceb89c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-ad560fef-1f75-4662-a2b3-bebbf4588560,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-0b2e75fd-ad04-4950-b62a-4f3cd9debcac,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-40b01cf5-7c79-4aaa-8448-0a8ebf06682f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-551910146-172.17.0.10-1595947452229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44938,DS-3c095572-ff68-4b10-9571-21592190c3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-eb6977a6-f996-407c-8138-21931225f7da,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-5aa9aa42-bf8e-40c9-aee7-19d379b932a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-df669aea-6fe2-4068-b98c-50eee28736c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-221a5c25-6664-448b-9fdb-74ae9ceb89c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-ad560fef-1f75-4662-a2b3-bebbf4588560,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-0b2e75fd-ad04-4950-b62a-4f3cd9debcac,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-40b01cf5-7c79-4aaa-8448-0a8ebf06682f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-26780941-172.17.0.10-1595947592000:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44882,DS-9319ab83-26b0-446d-879b-db1423464081,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-27cda97b-5bc8-4e62-80ec-f749e07b5618,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-66bfc2bb-f96e-4d9c-921e-db0ae0849bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:44856,DS-874ce7ab-3953-4427-9849-2e9675188118,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-293e3291-3307-4278-934e-a5fd5bc21a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37023,DS-0657b7cb-5494-4257-908c-9879eec35f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-7095d395-9586-4b2b-9f8a-d3d89580bf75,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-9a78d0f9-7088-4332-b727-94f6b0df9354,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-26780941-172.17.0.10-1595947592000:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44882,DS-9319ab83-26b0-446d-879b-db1423464081,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-27cda97b-5bc8-4e62-80ec-f749e07b5618,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-66bfc2bb-f96e-4d9c-921e-db0ae0849bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:44856,DS-874ce7ab-3953-4427-9849-2e9675188118,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-293e3291-3307-4278-934e-a5fd5bc21a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37023,DS-0657b7cb-5494-4257-908c-9879eec35f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-7095d395-9586-4b2b-9f8a-d3d89580bf75,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-9a78d0f9-7088-4332-b727-94f6b0df9354,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1267339309-172.17.0.10-1595947697423:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37925,DS-6a0b62d8-bccd-4c26-9c91-5df28bf076ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-3a2dc857-bc38-4100-9b0e-346fcd5b605f,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-598a444b-947f-48ad-8c79-20ca4ff37bca,DISK], DatanodeInfoWithStorage[127.0.0.1:33778,DS-b39ef594-c5f6-4330-b8d7-e20eeaf08639,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-3c89ae6e-e98d-4df1-9e8d-cba65b8752a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-29ac0972-0ae2-419d-8875-5d90950edde8,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-0693d077-8a41-4a4b-8a94-6fd4a6c7c5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39057,DS-bdfe5e5d-7962-4024-9c71-49a1deefa792,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1267339309-172.17.0.10-1595947697423:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37925,DS-6a0b62d8-bccd-4c26-9c91-5df28bf076ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-3a2dc857-bc38-4100-9b0e-346fcd5b605f,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-598a444b-947f-48ad-8c79-20ca4ff37bca,DISK], DatanodeInfoWithStorage[127.0.0.1:33778,DS-b39ef594-c5f6-4330-b8d7-e20eeaf08639,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-3c89ae6e-e98d-4df1-9e8d-cba65b8752a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-29ac0972-0ae2-419d-8875-5d90950edde8,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-0693d077-8a41-4a4b-8a94-6fd4a6c7c5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39057,DS-bdfe5e5d-7962-4024-9c71-49a1deefa792,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-769067751-172.17.0.10-1595947732930:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39333,DS-ebf9d49c-f9b6-43ec-b4e9-3608ba2df74e,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-015f71e3-22a5-4a42-918b-7fd15efc8674,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-ba01d15a-cc27-4305-b469-56db9ca70868,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-94c61966-fae2-448b-a020-39733dc0819a,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-e9a81835-6993-4a4f-a884-f562921d4c24,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-6569d3e6-b219-4087-8c02-0bb100bd2166,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-a884db86-7a9b-4787-8b7c-778856d35784,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-597ad217-5424-4d56-b38c-bc0e1fbe1431,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-769067751-172.17.0.10-1595947732930:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39333,DS-ebf9d49c-f9b6-43ec-b4e9-3608ba2df74e,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-015f71e3-22a5-4a42-918b-7fd15efc8674,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-ba01d15a-cc27-4305-b469-56db9ca70868,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-94c61966-fae2-448b-a020-39733dc0819a,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-e9a81835-6993-4a4f-a884-f562921d4c24,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-6569d3e6-b219-4087-8c02-0bb100bd2166,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-a884db86-7a9b-4787-8b7c-778856d35784,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-597ad217-5424-4d56-b38c-bc0e1fbe1431,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5196
