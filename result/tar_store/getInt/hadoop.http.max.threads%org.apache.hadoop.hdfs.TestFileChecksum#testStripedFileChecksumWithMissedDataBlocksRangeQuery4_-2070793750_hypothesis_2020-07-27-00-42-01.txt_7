reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1560273883-172.17.0.18-1595810586447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45994,DS-5ea9cf88-a92c-4081-9b4b-ea43dda06186,DISK], DatanodeInfoWithStorage[127.0.0.1:37807,DS-0ac3a5c6-28e8-4f51-bfb7-f1bc4d52d9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37576,DS-bdf5cc48-d561-4b6d-8d93-088a66418b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-13a34ec2-f8d4-4373-9b87-b0fa57d3b9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-23646da5-0fee-48dd-8ade-bef6bdd4b7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-f78e2bce-5c98-48ef-a6c6-7baba8e52fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-b2a75a3e-8188-46e4-b6e4-330fc2a7c464,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-137dd738-7974-46c0-8aa2-e2d4b93e2f73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1560273883-172.17.0.18-1595810586447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45994,DS-5ea9cf88-a92c-4081-9b4b-ea43dda06186,DISK], DatanodeInfoWithStorage[127.0.0.1:37807,DS-0ac3a5c6-28e8-4f51-bfb7-f1bc4d52d9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37576,DS-bdf5cc48-d561-4b6d-8d93-088a66418b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-13a34ec2-f8d4-4373-9b87-b0fa57d3b9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-23646da5-0fee-48dd-8ade-bef6bdd4b7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-f78e2bce-5c98-48ef-a6c6-7baba8e52fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-b2a75a3e-8188-46e4-b6e4-330fc2a7c464,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-137dd738-7974-46c0-8aa2-e2d4b93e2f73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1575950702-172.17.0.18-1595810634193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34039,DS-0c387279-a221-49fe-80ec-2385fe0eaccb,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-5fe4f58c-6070-42ed-a389-a7175bd9fa9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38644,DS-99cf9627-fe3a-478f-a5f8-ee9918122627,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-fe499589-aaa5-4dc4-81af-c8ce06a5bcaa,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-4ba2af23-c5a2-43ce-9369-025b1ffc7002,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-169a57d1-29b3-4cf5-97c1-6d6289bcdc08,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-8322348b-b2f4-42ce-8149-a8af11bdd91b,DISK], DatanodeInfoWithStorage[127.0.0.1:33686,DS-12af7531-639c-420a-97db-731ee6f7367b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1575950702-172.17.0.18-1595810634193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34039,DS-0c387279-a221-49fe-80ec-2385fe0eaccb,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-5fe4f58c-6070-42ed-a389-a7175bd9fa9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38644,DS-99cf9627-fe3a-478f-a5f8-ee9918122627,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-fe499589-aaa5-4dc4-81af-c8ce06a5bcaa,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-4ba2af23-c5a2-43ce-9369-025b1ffc7002,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-169a57d1-29b3-4cf5-97c1-6d6289bcdc08,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-8322348b-b2f4-42ce-8149-a8af11bdd91b,DISK], DatanodeInfoWithStorage[127.0.0.1:33686,DS-12af7531-639c-420a-97db-731ee6f7367b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1320973619-172.17.0.18-1595810678622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46837,DS-f2542ef1-abac-472c-aa97-6da1d6529bea,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-1c655584-3871-424c-83d1-1805fcaea1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-10df3024-0e1c-4cf3-860a-b6d84a4b0bce,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-98872edb-340b-4637-aa01-372fa37ccaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:39853,DS-46caf198-c874-40a9-9585-478c100b673f,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-3c1d9bbf-dc0a-44c3-b2b4-89b97057b985,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-dfc9a83a-8a08-4035-a699-d1e7342924e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-5bdc0245-dbbb-4231-9a80-fc87c229b831,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1320973619-172.17.0.18-1595810678622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46837,DS-f2542ef1-abac-472c-aa97-6da1d6529bea,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-1c655584-3871-424c-83d1-1805fcaea1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-10df3024-0e1c-4cf3-860a-b6d84a4b0bce,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-98872edb-340b-4637-aa01-372fa37ccaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:39853,DS-46caf198-c874-40a9-9585-478c100b673f,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-3c1d9bbf-dc0a-44c3-b2b4-89b97057b985,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-dfc9a83a-8a08-4035-a699-d1e7342924e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-5bdc0245-dbbb-4231-9a80-fc87c229b831,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-667871758-172.17.0.18-1595811399004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39892,DS-3dd7194d-de63-4453-843b-3d54ba2aadf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-92338bbc-d6c2-4026-b3b3-af1518fabd15,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-fd72d63f-00a3-42c1-832e-38e36fa20d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44041,DS-06a679b7-f4dc-48e4-946a-c75da447e01b,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-9f170fe3-db43-4f55-beae-145e8307497d,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-07b796f2-9e1f-45ca-9651-c8e9d14d5408,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-84034926-2d6f-4d5f-bf9e-b1eeaf90ad8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-f7e339e6-7797-4e4d-9813-6f568d346b44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-667871758-172.17.0.18-1595811399004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39892,DS-3dd7194d-de63-4453-843b-3d54ba2aadf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-92338bbc-d6c2-4026-b3b3-af1518fabd15,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-fd72d63f-00a3-42c1-832e-38e36fa20d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44041,DS-06a679b7-f4dc-48e4-946a-c75da447e01b,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-9f170fe3-db43-4f55-beae-145e8307497d,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-07b796f2-9e1f-45ca-9651-c8e9d14d5408,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-84034926-2d6f-4d5f-bf9e-b1eeaf90ad8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-f7e339e6-7797-4e4d-9813-6f568d346b44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-297633269-172.17.0.18-1595811628542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38215,DS-dd25487e-4ce8-42be-8eab-9018235449f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-2b7f221d-ea80-4954-b774-b25d72adcf97,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-6e6df8a4-c958-4835-86e5-d60fd723a8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-e99e3ce2-dbaf-4aff-8f35-e0a1ca4c4d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-f0fa5abf-423b-4502-b17d-9198c859802b,DISK], DatanodeInfoWithStorage[127.0.0.1:39489,DS-29eb1466-da09-4a4d-b04d-8fb5eff9a0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-db2e8dc1-8a03-41cc-937a-ae07232985fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36262,DS-448e4970-97e1-4f8c-bf53-4132e187606e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-297633269-172.17.0.18-1595811628542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38215,DS-dd25487e-4ce8-42be-8eab-9018235449f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-2b7f221d-ea80-4954-b774-b25d72adcf97,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-6e6df8a4-c958-4835-86e5-d60fd723a8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-e99e3ce2-dbaf-4aff-8f35-e0a1ca4c4d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-f0fa5abf-423b-4502-b17d-9198c859802b,DISK], DatanodeInfoWithStorage[127.0.0.1:39489,DS-29eb1466-da09-4a4d-b04d-8fb5eff9a0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-db2e8dc1-8a03-41cc-937a-ae07232985fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36262,DS-448e4970-97e1-4f8c-bf53-4132e187606e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851264528-172.17.0.18-1595811722843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38344,DS-490405c6-c057-4c0f-ab8e-1ac6af99f5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-b35a6b1e-5de0-4814-b0bd-b63585a6a138,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-9197b988-b43b-4190-8277-971cfb1422d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-9c597bbc-24e0-4c34-8af9-3d84822a35e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-1d6f7584-d450-4569-9317-582b21019c51,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-f4ac2545-ec8b-49cb-be12-e8705f7dc976,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-090c8c4d-755d-424b-b6a9-94de5d0f8049,DISK], DatanodeInfoWithStorage[127.0.0.1:46467,DS-e9b7f182-bb1f-4ec1-b906-ea013e8d6430,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851264528-172.17.0.18-1595811722843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38344,DS-490405c6-c057-4c0f-ab8e-1ac6af99f5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-b35a6b1e-5de0-4814-b0bd-b63585a6a138,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-9197b988-b43b-4190-8277-971cfb1422d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-9c597bbc-24e0-4c34-8af9-3d84822a35e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-1d6f7584-d450-4569-9317-582b21019c51,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-f4ac2545-ec8b-49cb-be12-e8705f7dc976,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-090c8c4d-755d-424b-b6a9-94de5d0f8049,DISK], DatanodeInfoWithStorage[127.0.0.1:46467,DS-e9b7f182-bb1f-4ec1-b906-ea013e8d6430,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1951079211-172.17.0.18-1595811869362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37074,DS-f56555cd-61ec-4b81-8d09-4d7c471c8878,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-0c02eee0-6d40-418b-aad6-376ca51aa131,DISK], DatanodeInfoWithStorage[127.0.0.1:42886,DS-602f9cf1-d154-41e5-9a2d-e4a41e8c5a07,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-6c59e5c5-f312-4e0d-972b-492105578c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40072,DS-5b5eff88-62f4-413b-bb7c-bc418f7498a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-a37259c9-3007-475e-aa65-88b0172b5609,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-56826b1b-d15f-4535-b488-9fbe170a9c58,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-da31e14f-7cdb-4ef6-84c6-d061c398f9ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1951079211-172.17.0.18-1595811869362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37074,DS-f56555cd-61ec-4b81-8d09-4d7c471c8878,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-0c02eee0-6d40-418b-aad6-376ca51aa131,DISK], DatanodeInfoWithStorage[127.0.0.1:42886,DS-602f9cf1-d154-41e5-9a2d-e4a41e8c5a07,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-6c59e5c5-f312-4e0d-972b-492105578c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40072,DS-5b5eff88-62f4-413b-bb7c-bc418f7498a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-a37259c9-3007-475e-aa65-88b0172b5609,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-56826b1b-d15f-4535-b488-9fbe170a9c58,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-da31e14f-7cdb-4ef6-84c6-d061c398f9ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1903090796-172.17.0.18-1595812620630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44707,DS-d64bc12d-94cd-4a5a-a673-3fe04d929666,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-3a38f301-b48b-4304-856e-e759546dd9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-aeb42331-e88f-4fbe-83da-ef980fc682a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-8201484b-9e73-41d4-857e-c23012393d60,DISK], DatanodeInfoWithStorage[127.0.0.1:41101,DS-c7ee4428-fd29-4a5a-a216-2f06b5777201,DISK], DatanodeInfoWithStorage[127.0.0.1:41127,DS-53ffc966-426e-439d-aa09-7c18078843ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-e51feba7-887c-4c78-b63a-589767a5fdbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-36f8ec70-eb87-4907-8de5-db3c7d065f90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1903090796-172.17.0.18-1595812620630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44707,DS-d64bc12d-94cd-4a5a-a673-3fe04d929666,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-3a38f301-b48b-4304-856e-e759546dd9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-aeb42331-e88f-4fbe-83da-ef980fc682a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-8201484b-9e73-41d4-857e-c23012393d60,DISK], DatanodeInfoWithStorage[127.0.0.1:41101,DS-c7ee4428-fd29-4a5a-a216-2f06b5777201,DISK], DatanodeInfoWithStorage[127.0.0.1:41127,DS-53ffc966-426e-439d-aa09-7c18078843ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-e51feba7-887c-4c78-b63a-589767a5fdbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-36f8ec70-eb87-4907-8de5-db3c7d065f90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-940283844-172.17.0.18-1595812928175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42481,DS-74ea1586-2f78-4bdb-bc9b-6b345c82fd1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-5b1df5e2-a25c-4f0a-b614-d17cc6a6b47f,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-7340ce1f-b4ef-4ec3-80c5-60c0adf3c22e,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-3e540a6e-2687-4e21-bf1b-05072a792fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-6788d272-c107-4fdc-8c64-81a1999aa99c,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-b627bba1-8668-4938-82fe-6ccf13efe10c,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-cb199d9c-97f7-4832-88c1-bcb82b38d811,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-db9002b0-fbf5-4094-b7a9-6399d0b5242d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-940283844-172.17.0.18-1595812928175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42481,DS-74ea1586-2f78-4bdb-bc9b-6b345c82fd1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-5b1df5e2-a25c-4f0a-b614-d17cc6a6b47f,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-7340ce1f-b4ef-4ec3-80c5-60c0adf3c22e,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-3e540a6e-2687-4e21-bf1b-05072a792fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-6788d272-c107-4fdc-8c64-81a1999aa99c,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-b627bba1-8668-4938-82fe-6ccf13efe10c,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-cb199d9c-97f7-4832-88c1-bcb82b38d811,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-db9002b0-fbf5-4094-b7a9-6399d0b5242d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1543513671-172.17.0.18-1595812970371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35603,DS-fb5f6464-0ed8-4b88-861a-48a2bac444ce,DISK], DatanodeInfoWithStorage[127.0.0.1:32883,DS-6b260d85-7659-47d5-ac34-6b82386b00c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-33a87ca8-c0fe-4875-8157-98ba6f5e373b,DISK], DatanodeInfoWithStorage[127.0.0.1:43927,DS-f265f9c7-6166-41f3-a6f6-83465930d541,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-61189a0c-c2ba-4fe4-89f6-eaa93e20dc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-9f8674bd-32a0-4d17-9beb-9d5cefdce04a,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-1a76c301-16f9-462a-8d70-e6d52516f6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-3ba8d8dc-80a4-4481-b403-ae0f4cc99844,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1543513671-172.17.0.18-1595812970371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35603,DS-fb5f6464-0ed8-4b88-861a-48a2bac444ce,DISK], DatanodeInfoWithStorage[127.0.0.1:32883,DS-6b260d85-7659-47d5-ac34-6b82386b00c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-33a87ca8-c0fe-4875-8157-98ba6f5e373b,DISK], DatanodeInfoWithStorage[127.0.0.1:43927,DS-f265f9c7-6166-41f3-a6f6-83465930d541,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-61189a0c-c2ba-4fe4-89f6-eaa93e20dc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-9f8674bd-32a0-4d17-9beb-9d5cefdce04a,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-1a76c301-16f9-462a-8d70-e6d52516f6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-3ba8d8dc-80a4-4481-b403-ae0f4cc99844,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1221784961-172.17.0.18-1595813374852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42336,DS-b16a15b4-5a5c-4002-9b3b-660b26edd0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-cca6e91b-04e6-4854-9105-a899758af5da,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-53745863-0d68-422e-87ad-1f3b29af77aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-ed08383f-6cbc-4de7-9c76-e9ec7637e7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-9dcb6aea-ebd3-44d1-8b8e-13a95153c089,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-96f2a1bc-6cb5-4f12-a005-2afa4b3047b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-4e334bab-7391-4322-9389-95b1051e0838,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-d3c30bbf-a677-4ecf-916e-3abe3686b81d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1221784961-172.17.0.18-1595813374852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42336,DS-b16a15b4-5a5c-4002-9b3b-660b26edd0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-cca6e91b-04e6-4854-9105-a899758af5da,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-53745863-0d68-422e-87ad-1f3b29af77aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-ed08383f-6cbc-4de7-9c76-e9ec7637e7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-9dcb6aea-ebd3-44d1-8b8e-13a95153c089,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-96f2a1bc-6cb5-4f12-a005-2afa4b3047b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-4e334bab-7391-4322-9389-95b1051e0838,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-d3c30bbf-a677-4ecf-916e-3abe3686b81d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-911141228-172.17.0.18-1595813567284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41708,DS-ebea1342-87be-4d1c-91f2-cc536a17fcd6,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-ac912293-7f53-47ec-adb8-6dcf920ccd4c,DISK], DatanodeInfoWithStorage[127.0.0.1:32996,DS-163d167f-a3e4-4fd1-8707-bf9f4764462d,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-8396b981-6b38-41f5-af6e-8e3418af8565,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-0ca44c53-f1bc-4a2a-8a45-5eb7803948ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-ccd57756-b335-4e78-b1c5-9218230e25a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-2f6dbd38-7cf0-4e45-80e4-878b1acb51b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-59cbbeeb-263f-4b20-95c2-aa2836c5b919,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-911141228-172.17.0.18-1595813567284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41708,DS-ebea1342-87be-4d1c-91f2-cc536a17fcd6,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-ac912293-7f53-47ec-adb8-6dcf920ccd4c,DISK], DatanodeInfoWithStorage[127.0.0.1:32996,DS-163d167f-a3e4-4fd1-8707-bf9f4764462d,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-8396b981-6b38-41f5-af6e-8e3418af8565,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-0ca44c53-f1bc-4a2a-8a45-5eb7803948ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-ccd57756-b335-4e78-b1c5-9218230e25a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-2f6dbd38-7cf0-4e45-80e4-878b1acb51b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-59cbbeeb-263f-4b20-95c2-aa2836c5b919,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1285348013-172.17.0.18-1595813694091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43048,DS-8281023f-58b6-49dc-80eb-f0209cec1c83,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-c3e5f6f8-6583-49f8-951a-3a592238cf50,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-ae1f7c6b-1acf-46c7-bd4b-e609e6d42df9,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-a9606fa6-2bba-4bc8-908b-e77923c59556,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-062a0819-e3cd-494f-be0b-a64b5d57d340,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-116fa52b-f3a5-4e3c-95a2-152fe79b1ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-d61c78df-d434-41aa-ba7e-14ad1fbb905a,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-01533c33-fe7a-40fe-906f-de54653a5cb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1285348013-172.17.0.18-1595813694091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43048,DS-8281023f-58b6-49dc-80eb-f0209cec1c83,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-c3e5f6f8-6583-49f8-951a-3a592238cf50,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-ae1f7c6b-1acf-46c7-bd4b-e609e6d42df9,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-a9606fa6-2bba-4bc8-908b-e77923c59556,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-062a0819-e3cd-494f-be0b-a64b5d57d340,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-116fa52b-f3a5-4e3c-95a2-152fe79b1ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-d61c78df-d434-41aa-ba7e-14ad1fbb905a,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-01533c33-fe7a-40fe-906f-de54653a5cb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-545242899-172.17.0.18-1595814004658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45872,DS-6238b9fa-9eb1-4bd7-b580-472e48e6ede5,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-1cd25b38-a021-461f-9662-2cec2226f7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-f3bf2246-54b5-4080-ac59-5356b5348f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-44f7e5c5-adc9-4326-9f84-644e06bbf390,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-93799326-5b6c-4935-968a-48ac4a25c2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-79f75e28-50b1-4b05-aa98-7b0bfc2302f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45217,DS-99330520-b3e5-4942-9178-e729612f2680,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-48fc1bca-7769-43be-805e-de42d493c0f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-545242899-172.17.0.18-1595814004658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45872,DS-6238b9fa-9eb1-4bd7-b580-472e48e6ede5,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-1cd25b38-a021-461f-9662-2cec2226f7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-f3bf2246-54b5-4080-ac59-5356b5348f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-44f7e5c5-adc9-4326-9f84-644e06bbf390,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-93799326-5b6c-4935-968a-48ac4a25c2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-79f75e28-50b1-4b05-aa98-7b0bfc2302f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45217,DS-99330520-b3e5-4942-9178-e729612f2680,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-48fc1bca-7769-43be-805e-de42d493c0f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1957397640-172.17.0.18-1595814298875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36352,DS-93d3ae2b-fc97-4fe3-944c-8cba62336e69,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-38ae1424-e7f9-4f52-8a59-b57566946862,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-3b9e27b8-66a0-497c-99a9-8a438c810ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-fce4bc97-1910-446c-b8ce-1ae7ea500072,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-d0ff3dd9-457b-4649-b931-1a7ba9176de2,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-2cf71141-c29c-497d-bcc3-30015fb38f30,DISK], DatanodeInfoWithStorage[127.0.0.1:39698,DS-e2ba828f-0b8a-42c3-8b4a-8c9faea9aaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-3d8b7e8e-cf37-4b20-b4f0-b735a8ee028b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1957397640-172.17.0.18-1595814298875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36352,DS-93d3ae2b-fc97-4fe3-944c-8cba62336e69,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-38ae1424-e7f9-4f52-8a59-b57566946862,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-3b9e27b8-66a0-497c-99a9-8a438c810ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-fce4bc97-1910-446c-b8ce-1ae7ea500072,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-d0ff3dd9-457b-4649-b931-1a7ba9176de2,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-2cf71141-c29c-497d-bcc3-30015fb38f30,DISK], DatanodeInfoWithStorage[127.0.0.1:39698,DS-e2ba828f-0b8a-42c3-8b4a-8c9faea9aaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-3d8b7e8e-cf37-4b20-b4f0-b735a8ee028b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1565282505-172.17.0.18-1595815010564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38698,DS-866e21b7-9d28-4d28-be3c-046d80d72f95,DISK], DatanodeInfoWithStorage[127.0.0.1:46111,DS-673eb8a2-d3c6-4776-8378-70c4a6449349,DISK], DatanodeInfoWithStorage[127.0.0.1:40995,DS-edbbb590-c6f0-4baa-ade9-8615ef867580,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-71f4d562-7d37-443c-8e6f-adf4b58aa906,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-6502d152-5077-4ba8-bc44-0b0dfc86a157,DISK], DatanodeInfoWithStorage[127.0.0.1:37323,DS-a136cfbf-51c4-414b-8cca-c75a495ce6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-d3cd71b1-274d-499b-b7aa-b17c1b6ebed6,DISK], DatanodeInfoWithStorage[127.0.0.1:35370,DS-73b47909-6bd5-494d-b113-a0ba84a95276,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1565282505-172.17.0.18-1595815010564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38698,DS-866e21b7-9d28-4d28-be3c-046d80d72f95,DISK], DatanodeInfoWithStorage[127.0.0.1:46111,DS-673eb8a2-d3c6-4776-8378-70c4a6449349,DISK], DatanodeInfoWithStorage[127.0.0.1:40995,DS-edbbb590-c6f0-4baa-ade9-8615ef867580,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-71f4d562-7d37-443c-8e6f-adf4b58aa906,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-6502d152-5077-4ba8-bc44-0b0dfc86a157,DISK], DatanodeInfoWithStorage[127.0.0.1:37323,DS-a136cfbf-51c4-414b-8cca-c75a495ce6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-d3cd71b1-274d-499b-b7aa-b17c1b6ebed6,DISK], DatanodeInfoWithStorage[127.0.0.1:35370,DS-73b47909-6bd5-494d-b113-a0ba84a95276,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1578945033-172.17.0.18-1595816159610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41163,DS-24a4bd96-02d5-4bb9-81e6-a8054b82c550,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-2cbdb9e7-675f-454d-aec9-b36682fed5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43143,DS-247dcd57-df57-4ada-aac5-72ef3d8747b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-7d944f7d-e819-45fd-b776-87d7e96c0f24,DISK], DatanodeInfoWithStorage[127.0.0.1:35477,DS-f253ec46-bfdb-4554-82d5-d523b526ad69,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-79fecfd5-3473-41f4-9f64-5687d31dd127,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-498a4104-18e9-4ab2-9919-bec00328e1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-220d4f6f-805c-49fa-9bed-8fadb5081c05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1578945033-172.17.0.18-1595816159610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41163,DS-24a4bd96-02d5-4bb9-81e6-a8054b82c550,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-2cbdb9e7-675f-454d-aec9-b36682fed5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43143,DS-247dcd57-df57-4ada-aac5-72ef3d8747b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-7d944f7d-e819-45fd-b776-87d7e96c0f24,DISK], DatanodeInfoWithStorage[127.0.0.1:35477,DS-f253ec46-bfdb-4554-82d5-d523b526ad69,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-79fecfd5-3473-41f4-9f64-5687d31dd127,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-498a4104-18e9-4ab2-9919-bec00328e1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-220d4f6f-805c-49fa-9bed-8fadb5081c05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1059615462-172.17.0.18-1595816438165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40121,DS-fb4588fc-e253-424e-a982-b0c5de002c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-17f27cfd-a4c9-4328-a578-b35b10567881,DISK], DatanodeInfoWithStorage[127.0.0.1:39201,DS-b1bd80bd-1c44-4478-b607-b2efa6d27bca,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-26559a8a-2a5f-41b2-8ef9-57e4be0f12ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-34705c88-056c-4d76-8fcc-5afc2af7cac5,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-b417a4f9-f9bd-4369-a7da-e05d3c16ab01,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-834d9d7b-242e-401f-a733-73660749df53,DISK], DatanodeInfoWithStorage[127.0.0.1:36667,DS-a79b4c11-7e53-47fb-88dc-94ad04184587,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1059615462-172.17.0.18-1595816438165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40121,DS-fb4588fc-e253-424e-a982-b0c5de002c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-17f27cfd-a4c9-4328-a578-b35b10567881,DISK], DatanodeInfoWithStorage[127.0.0.1:39201,DS-b1bd80bd-1c44-4478-b607-b2efa6d27bca,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-26559a8a-2a5f-41b2-8ef9-57e4be0f12ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-34705c88-056c-4d76-8fcc-5afc2af7cac5,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-b417a4f9-f9bd-4369-a7da-e05d3c16ab01,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-834d9d7b-242e-401f-a733-73660749df53,DISK], DatanodeInfoWithStorage[127.0.0.1:36667,DS-a79b4c11-7e53-47fb-88dc-94ad04184587,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1439454309-172.17.0.18-1595816811024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42438,DS-ebf7dcba-f4e8-4f2d-aa0e-203974776bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40644,DS-d743b5f5-5c6c-4bed-92b0-9bf4fbde4074,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-35ab459b-5ea3-49cf-a35c-7d9c84cc6be8,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-4a59e104-0d49-464b-a773-9a320556796c,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-3752f720-be27-4309-912c-461b0824e779,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-e66b7e8d-8806-47b1-8c02-c4bf459d623a,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-cf7b4454-c6c5-4be3-92f8-71ec0a48d0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-e087692f-f704-49d1-9c2a-d798ec65f654,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1439454309-172.17.0.18-1595816811024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42438,DS-ebf7dcba-f4e8-4f2d-aa0e-203974776bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40644,DS-d743b5f5-5c6c-4bed-92b0-9bf4fbde4074,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-35ab459b-5ea3-49cf-a35c-7d9c84cc6be8,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-4a59e104-0d49-464b-a773-9a320556796c,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-3752f720-be27-4309-912c-461b0824e779,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-e66b7e8d-8806-47b1-8c02-c4bf459d623a,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-cf7b4454-c6c5-4be3-92f8-71ec0a48d0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-e087692f-f704-49d1-9c2a-d798ec65f654,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-859552007-172.17.0.18-1595816938304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44576,DS-4b57bbe1-26fa-40d0-8a32-081030b46ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-1d9485e9-f34d-43c4-bd2f-823e3f7ac00d,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-2491e434-ad3a-4758-bb27-e30803008fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-8ada488a-b359-4f4e-8995-7514a873c3df,DISK], DatanodeInfoWithStorage[127.0.0.1:40996,DS-d426a2b5-d0bf-4022-b65d-521c97fe5058,DISK], DatanodeInfoWithStorage[127.0.0.1:41241,DS-8a33d2ea-ae34-4e62-bc11-10672ddb264c,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-bd85436b-61e8-4ce1-b2ee-52e1e0de4cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-085d6fd3-c88a-4100-977c-ca822b2a79b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-859552007-172.17.0.18-1595816938304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44576,DS-4b57bbe1-26fa-40d0-8a32-081030b46ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-1d9485e9-f34d-43c4-bd2f-823e3f7ac00d,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-2491e434-ad3a-4758-bb27-e30803008fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-8ada488a-b359-4f4e-8995-7514a873c3df,DISK], DatanodeInfoWithStorage[127.0.0.1:40996,DS-d426a2b5-d0bf-4022-b65d-521c97fe5058,DISK], DatanodeInfoWithStorage[127.0.0.1:41241,DS-8a33d2ea-ae34-4e62-bc11-10672ddb264c,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-bd85436b-61e8-4ce1-b2ee-52e1e0de4cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-085d6fd3-c88a-4100-977c-ca822b2a79b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6831
