reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-275029503-172.17.0.2-1595573487445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44030,DS-2a4969b3-5436-4804-a203-c688f75e24ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-ddf1db36-b2cf-4b34-a16c-6a66fcc62719,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-25042260-8aea-4540-b1b6-e4b3f913982d,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-be30cfc9-95db-4859-accc-64a1da60fd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41780,DS-70e3734f-4004-4193-b30a-f7c887974d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39094,DS-632917e5-5ffa-4a55-86f5-a242a0cfbb33,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-46bcaaa1-5c3a-4b3b-920d-b875fde6ccbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-7a544560-8201-498d-8865-ff18a5224280,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-275029503-172.17.0.2-1595573487445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44030,DS-2a4969b3-5436-4804-a203-c688f75e24ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-ddf1db36-b2cf-4b34-a16c-6a66fcc62719,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-25042260-8aea-4540-b1b6-e4b3f913982d,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-be30cfc9-95db-4859-accc-64a1da60fd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41780,DS-70e3734f-4004-4193-b30a-f7c887974d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39094,DS-632917e5-5ffa-4a55-86f5-a242a0cfbb33,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-46bcaaa1-5c3a-4b3b-920d-b875fde6ccbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-7a544560-8201-498d-8865-ff18a5224280,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1129856560-172.17.0.2-1595574166209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32792,DS-0baa1fa7-71ad-4664-8de2-6133f19b45a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-ab670cbd-2192-4752-825a-8d3c769dd1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-c886bbd8-4115-45e6-bff1-66b962653376,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-8f5f610d-53c0-4a0b-86a0-4b49da2116e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-6f5c14b9-4bad-46bf-a974-d6809eb70273,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-ac3ed0eb-1ba7-47b8-a919-5f1876151270,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-e3ee1dce-0f37-45b4-aa91-1a6a511256a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-a30c815a-02ef-4b0a-97a2-d1993bdf9a3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1129856560-172.17.0.2-1595574166209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32792,DS-0baa1fa7-71ad-4664-8de2-6133f19b45a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-ab670cbd-2192-4752-825a-8d3c769dd1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-c886bbd8-4115-45e6-bff1-66b962653376,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-8f5f610d-53c0-4a0b-86a0-4b49da2116e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-6f5c14b9-4bad-46bf-a974-d6809eb70273,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-ac3ed0eb-1ba7-47b8-a919-5f1876151270,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-e3ee1dce-0f37-45b4-aa91-1a6a511256a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-a30c815a-02ef-4b0a-97a2-d1993bdf9a3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-498979810-172.17.0.2-1595574231947:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35945,DS-845c1eb7-d2fc-4a4d-9166-ae2b21abcf76,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-ad0bdbe9-4514-4a6c-8ec9-47f7c783de2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-208ce64a-f945-408a-af89-c2131ba06902,DISK], DatanodeInfoWithStorage[127.0.0.1:36005,DS-03cfdc81-a888-4b20-9213-d3a98898d61a,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-0f97eb10-34ac-465d-846c-b1d9e09492b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-389ade9f-6821-4c74-bad6-512ad7aee2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-79f463d3-dc74-48b8-8fc6-c0b5a064fd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-40c94a79-cb8c-419e-84f4-4608e26a7399,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-498979810-172.17.0.2-1595574231947:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35945,DS-845c1eb7-d2fc-4a4d-9166-ae2b21abcf76,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-ad0bdbe9-4514-4a6c-8ec9-47f7c783de2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-208ce64a-f945-408a-af89-c2131ba06902,DISK], DatanodeInfoWithStorage[127.0.0.1:36005,DS-03cfdc81-a888-4b20-9213-d3a98898d61a,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-0f97eb10-34ac-465d-846c-b1d9e09492b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-389ade9f-6821-4c74-bad6-512ad7aee2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-79f463d3-dc74-48b8-8fc6-c0b5a064fd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-40c94a79-cb8c-419e-84f4-4608e26a7399,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1240888407-172.17.0.2-1595574419590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41799,DS-0c007d13-4b3a-43c2-9642-1d8830b0af93,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-82ebb370-7910-467d-b4a3-ef94c14b3d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-894f5188-d645-4d65-b1a2-06b1d2f1b024,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-7fc1aaf5-ec24-4dbc-8701-2ba72d4a444d,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-2abae947-48b6-4687-86eb-e6eb9ebfe558,DISK], DatanodeInfoWithStorage[127.0.0.1:34266,DS-b2c39aa2-b8e9-44f2-8650-b62c7b72a0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-5e1d6843-7263-40e9-9caa-c1cbb0609b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-c720ed94-299f-416c-93ac-215ecd338775,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1240888407-172.17.0.2-1595574419590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41799,DS-0c007d13-4b3a-43c2-9642-1d8830b0af93,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-82ebb370-7910-467d-b4a3-ef94c14b3d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-894f5188-d645-4d65-b1a2-06b1d2f1b024,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-7fc1aaf5-ec24-4dbc-8701-2ba72d4a444d,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-2abae947-48b6-4687-86eb-e6eb9ebfe558,DISK], DatanodeInfoWithStorage[127.0.0.1:34266,DS-b2c39aa2-b8e9-44f2-8650-b62c7b72a0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-5e1d6843-7263-40e9-9caa-c1cbb0609b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-c720ed94-299f-416c-93ac-215ecd338775,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1367443274-172.17.0.2-1595575645987:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33624,DS-c30a94ea-210a-4067-9880-4d9802a9dace,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-ecb85aaa-e1ee-47e0-885a-05807d0bc9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-6454846b-f53e-4aaa-91ca-9a5403de0b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-db8fd002-59d9-4f5d-9b7c-0f2b0595a049,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-6f93fd08-50c3-43e4-96b9-dbcdc0f70375,DISK], DatanodeInfoWithStorage[127.0.0.1:33135,DS-a70dcd35-9d45-49da-9c5f-637cae19feb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-c532e945-8b98-419e-9e5d-1c4ce773bedb,DISK], DatanodeInfoWithStorage[127.0.0.1:42373,DS-d86e6d36-4fc4-4af3-b417-52b75c0a9cde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1367443274-172.17.0.2-1595575645987:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33624,DS-c30a94ea-210a-4067-9880-4d9802a9dace,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-ecb85aaa-e1ee-47e0-885a-05807d0bc9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-6454846b-f53e-4aaa-91ca-9a5403de0b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-db8fd002-59d9-4f5d-9b7c-0f2b0595a049,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-6f93fd08-50c3-43e4-96b9-dbcdc0f70375,DISK], DatanodeInfoWithStorage[127.0.0.1:33135,DS-a70dcd35-9d45-49da-9c5f-637cae19feb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-c532e945-8b98-419e-9e5d-1c4ce773bedb,DISK], DatanodeInfoWithStorage[127.0.0.1:42373,DS-d86e6d36-4fc4-4af3-b417-52b75c0a9cde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-925970717-172.17.0.2-1595575902777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38168,DS-5bc71caa-d176-424a-b81c-27dc7432a61b,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-58c57264-81c8-4412-bb9d-7272276ead09,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-fbc00a1a-1b08-4508-a415-8b4dbcc78f69,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-e9732d74-c462-4385-8738-4d9ddd99b420,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-cdf7f0dd-1442-4112-b69b-167dcad4c479,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-96444282-5212-4509-b6d1-45766b719c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43503,DS-6831058e-33c3-4e09-878a-45e69351b156,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-1313a1e1-c64c-4912-960f-5c4b827472ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-925970717-172.17.0.2-1595575902777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38168,DS-5bc71caa-d176-424a-b81c-27dc7432a61b,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-58c57264-81c8-4412-bb9d-7272276ead09,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-fbc00a1a-1b08-4508-a415-8b4dbcc78f69,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-e9732d74-c462-4385-8738-4d9ddd99b420,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-cdf7f0dd-1442-4112-b69b-167dcad4c479,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-96444282-5212-4509-b6d1-45766b719c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43503,DS-6831058e-33c3-4e09-878a-45e69351b156,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-1313a1e1-c64c-4912-960f-5c4b827472ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-446734866-172.17.0.2-1595576094748:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34698,DS-0736d9af-7af7-44fa-a734-76eb0af8139c,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-e2e1ee0b-4f37-47c0-b71f-33aa3338be8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43375,DS-b30c397a-ba7a-4dae-8ac0-efb2c43d567b,DISK], DatanodeInfoWithStorage[127.0.0.1:44260,DS-98eb13d3-13e4-4410-8cf0-cbed0e2c30c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-3087a1fa-0ebb-4e58-ae6b-a075a19e6026,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-3770329f-ac45-4ecb-81a7-47a1b17e5957,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-edeb8c02-626b-4e6a-8e2c-76f7b200d4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-7ab6ab72-d2dc-4360-83a7-e4c14d76c1c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-446734866-172.17.0.2-1595576094748:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34698,DS-0736d9af-7af7-44fa-a734-76eb0af8139c,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-e2e1ee0b-4f37-47c0-b71f-33aa3338be8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43375,DS-b30c397a-ba7a-4dae-8ac0-efb2c43d567b,DISK], DatanodeInfoWithStorage[127.0.0.1:44260,DS-98eb13d3-13e4-4410-8cf0-cbed0e2c30c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-3087a1fa-0ebb-4e58-ae6b-a075a19e6026,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-3770329f-ac45-4ecb-81a7-47a1b17e5957,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-edeb8c02-626b-4e6a-8e2c-76f7b200d4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-7ab6ab72-d2dc-4360-83a7-e4c14d76c1c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1211183439-172.17.0.2-1595576304819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38640,DS-a5dab795-414e-4681-b3e9-1f1571272883,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-de802709-af08-4f71-a194-d28193d5ae7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-fd3736bc-cee6-4f05-8b5b-192fee6625a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-c040de4b-00c9-406f-a0f2-19dabf91d71b,DISK], DatanodeInfoWithStorage[127.0.0.1:37228,DS-d32a8c39-1944-4843-89e5-3acdc7dcaf39,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-3b89e71a-824e-4cb0-af78-1c156ec86f63,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-e8d758b7-779e-40e5-9b91-75a3a1d9ffbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-0ce2daca-63c3-41a3-b18e-8177929b7278,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1211183439-172.17.0.2-1595576304819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38640,DS-a5dab795-414e-4681-b3e9-1f1571272883,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-de802709-af08-4f71-a194-d28193d5ae7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-fd3736bc-cee6-4f05-8b5b-192fee6625a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-c040de4b-00c9-406f-a0f2-19dabf91d71b,DISK], DatanodeInfoWithStorage[127.0.0.1:37228,DS-d32a8c39-1944-4843-89e5-3acdc7dcaf39,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-3b89e71a-824e-4cb0-af78-1c156ec86f63,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-e8d758b7-779e-40e5-9b91-75a3a1d9ffbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-0ce2daca-63c3-41a3-b18e-8177929b7278,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1004840772-172.17.0.2-1595576501734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37094,DS-4460e0f6-1b93-4a70-8639-4f3ccfd2a430,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-3369123f-fbe2-441b-b034-998f89fda8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-4a1cd2a1-51fd-4e37-8b00-ecf64f0ce1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-31cfe660-1b70-48b5-8f9c-13cf12fe490a,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-626fbae0-cab6-4439-8298-d6610df0eb69,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-c3d9df27-e1cd-44f2-897b-8fc912d5c72a,DISK], DatanodeInfoWithStorage[127.0.0.1:41189,DS-8a0d83d2-db13-472a-9ba0-f4f923c4624b,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-3d2a9c17-e174-4b1c-b1a0-c6f615e90506,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1004840772-172.17.0.2-1595576501734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37094,DS-4460e0f6-1b93-4a70-8639-4f3ccfd2a430,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-3369123f-fbe2-441b-b034-998f89fda8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-4a1cd2a1-51fd-4e37-8b00-ecf64f0ce1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-31cfe660-1b70-48b5-8f9c-13cf12fe490a,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-626fbae0-cab6-4439-8298-d6610df0eb69,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-c3d9df27-e1cd-44f2-897b-8fc912d5c72a,DISK], DatanodeInfoWithStorage[127.0.0.1:41189,DS-8a0d83d2-db13-472a-9ba0-f4f923c4624b,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-3d2a9c17-e174-4b1c-b1a0-c6f615e90506,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-555326665-172.17.0.2-1595576535659:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44312,DS-6d79c51a-c870-4d45-a1db-a7e0744b4ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:34033,DS-f7085cc2-1268-4766-8657-c41d7463f84e,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-5bfe9f95-7426-40d9-965a-6a19a7bbfc74,DISK], DatanodeInfoWithStorage[127.0.0.1:35092,DS-a322a1dc-039f-488b-b3e5-27292f86d66d,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-c6313ec3-e366-4b77-acf8-ec7e661276a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-8a9c0a99-0b1f-4bcf-b199-8e242e8e3148,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-605609eb-aa5f-4d8e-ab84-849cc180a905,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-bb6df7ff-16fb-4c6f-a91d-799406762572,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-555326665-172.17.0.2-1595576535659:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44312,DS-6d79c51a-c870-4d45-a1db-a7e0744b4ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:34033,DS-f7085cc2-1268-4766-8657-c41d7463f84e,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-5bfe9f95-7426-40d9-965a-6a19a7bbfc74,DISK], DatanodeInfoWithStorage[127.0.0.1:35092,DS-a322a1dc-039f-488b-b3e5-27292f86d66d,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-c6313ec3-e366-4b77-acf8-ec7e661276a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-8a9c0a99-0b1f-4bcf-b199-8e242e8e3148,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-605609eb-aa5f-4d8e-ab84-849cc180a905,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-bb6df7ff-16fb-4c6f-a91d-799406762572,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1647964452-172.17.0.2-1595577199016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36028,DS-6ee0e7a4-ffda-4077-b0cd-2d81dd1d5760,DISK], DatanodeInfoWithStorage[127.0.0.1:43783,DS-2e5f2ee1-9b97-43f0-8ed8-fa86562ee2be,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-cbe9c6a8-0081-42d9-a28b-2c16dc84ec32,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-73071e09-006d-4dfd-8e71-41e703321b78,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-9f2ca8af-970c-4c29-a972-2c4033971499,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-864221d1-6b11-41e9-a7c9-c9552870eacc,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-4f706486-b097-4053-abaf-be5239d3e5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-4a0586a2-6228-4871-a081-c6cc1625e618,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1647964452-172.17.0.2-1595577199016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36028,DS-6ee0e7a4-ffda-4077-b0cd-2d81dd1d5760,DISK], DatanodeInfoWithStorage[127.0.0.1:43783,DS-2e5f2ee1-9b97-43f0-8ed8-fa86562ee2be,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-cbe9c6a8-0081-42d9-a28b-2c16dc84ec32,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-73071e09-006d-4dfd-8e71-41e703321b78,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-9f2ca8af-970c-4c29-a972-2c4033971499,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-864221d1-6b11-41e9-a7c9-c9552870eacc,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-4f706486-b097-4053-abaf-be5239d3e5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-4a0586a2-6228-4871-a081-c6cc1625e618,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2028461952-172.17.0.2-1595577232566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35824,DS-2239a9af-d07e-485a-a5cb-1b5dbfd9186c,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-ea9b7e08-ed98-4d99-a37b-e61c4cb0c833,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-1d285cb8-ff5d-4c0a-a131-547ed6f5a451,DISK], DatanodeInfoWithStorage[127.0.0.1:35428,DS-599863d3-5345-4989-b528-3e5ccf266e71,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-2a3ef088-7096-4e4a-9318-e6227aec3668,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-fc18a5d9-4434-47a6-807b-e2f069b64dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-2f9d11d5-8f4b-4276-bb10-083161efd7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41388,DS-8d6acc44-9705-403f-88da-3e56f7b142e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2028461952-172.17.0.2-1595577232566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35824,DS-2239a9af-d07e-485a-a5cb-1b5dbfd9186c,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-ea9b7e08-ed98-4d99-a37b-e61c4cb0c833,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-1d285cb8-ff5d-4c0a-a131-547ed6f5a451,DISK], DatanodeInfoWithStorage[127.0.0.1:35428,DS-599863d3-5345-4989-b528-3e5ccf266e71,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-2a3ef088-7096-4e4a-9318-e6227aec3668,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-fc18a5d9-4434-47a6-807b-e2f069b64dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-2f9d11d5-8f4b-4276-bb10-083161efd7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41388,DS-8d6acc44-9705-403f-88da-3e56f7b142e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-837859028-172.17.0.2-1595577348498:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36182,DS-d10d905e-ce13-4e35-b3f5-e900312bfd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-6a116084-36a3-4ae5-a353-25f8d90fd7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44514,DS-6029448f-4889-4b1d-b8f8-3b2bef26b70f,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-80f04f20-89d7-4691-84f0-e9f5459cf7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39292,DS-ec919b80-9813-45d4-8273-657b285edc66,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-ed642f14-bdf4-4d7e-b460-322d003e9eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-961bcc91-3242-4171-b650-0803f5f9be33,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-2f43fdc9-7308-44df-90c4-fddfec405e5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-837859028-172.17.0.2-1595577348498:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36182,DS-d10d905e-ce13-4e35-b3f5-e900312bfd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-6a116084-36a3-4ae5-a353-25f8d90fd7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44514,DS-6029448f-4889-4b1d-b8f8-3b2bef26b70f,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-80f04f20-89d7-4691-84f0-e9f5459cf7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39292,DS-ec919b80-9813-45d4-8273-657b285edc66,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-ed642f14-bdf4-4d7e-b460-322d003e9eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-961bcc91-3242-4171-b650-0803f5f9be33,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-2f43fdc9-7308-44df-90c4-fddfec405e5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-700393299-172.17.0.2-1595577387575:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43408,DS-6e3a769c-4197-4247-9a4c-14f59beda398,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-5fb1e9ad-54d5-4657-bc23-b26b94982858,DISK], DatanodeInfoWithStorage[127.0.0.1:34293,DS-2deaac29-515d-433d-8609-b558a5d93937,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-73c4838d-fdc9-4db1-a065-554c81fd3a75,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-e3d80224-088c-43a7-b3d3-039da3a56cda,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-2e6252cc-1802-4813-9b1f-ba645a5ff05e,DISK], DatanodeInfoWithStorage[127.0.0.1:39463,DS-bc852e30-55c7-4056-89a5-603618daafdc,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-c77a373c-824d-4138-b17f-580166bc11a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-700393299-172.17.0.2-1595577387575:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43408,DS-6e3a769c-4197-4247-9a4c-14f59beda398,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-5fb1e9ad-54d5-4657-bc23-b26b94982858,DISK], DatanodeInfoWithStorage[127.0.0.1:34293,DS-2deaac29-515d-433d-8609-b558a5d93937,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-73c4838d-fdc9-4db1-a065-554c81fd3a75,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-e3d80224-088c-43a7-b3d3-039da3a56cda,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-2e6252cc-1802-4813-9b1f-ba645a5ff05e,DISK], DatanodeInfoWithStorage[127.0.0.1:39463,DS-bc852e30-55c7-4056-89a5-603618daafdc,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-c77a373c-824d-4138-b17f-580166bc11a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-508789553-172.17.0.2-1595578004666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40865,DS-2d38b0be-94bc-4761-8e00-a54ed1e1f526,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-2f288d55-854c-4d36-8251-cfd71ff84729,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-df59b228-e20e-46b1-9770-fab3534f9ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-014119e2-bf99-4ce6-846b-b863c5b18a48,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-4f6c94e0-9849-4cf5-9557-3aa4217c316d,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-0b07c795-8c64-46e7-a75b-f5e3a04fc5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-bbaf19a4-6b06-4f43-810e-ff6008220250,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-405f51b3-33f2-4480-898b-d673d02e6e8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-508789553-172.17.0.2-1595578004666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40865,DS-2d38b0be-94bc-4761-8e00-a54ed1e1f526,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-2f288d55-854c-4d36-8251-cfd71ff84729,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-df59b228-e20e-46b1-9770-fab3534f9ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-014119e2-bf99-4ce6-846b-b863c5b18a48,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-4f6c94e0-9849-4cf5-9557-3aa4217c316d,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-0b07c795-8c64-46e7-a75b-f5e3a04fc5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-bbaf19a4-6b06-4f43-810e-ff6008220250,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-405f51b3-33f2-4480-898b-d673d02e6e8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-832897750-172.17.0.2-1595578321398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39672,DS-c30b873c-419f-4695-b16d-e42a7cf8e8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-784851cc-6693-40fc-af60-1c3a3c3f59fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38828,DS-b400858d-4f4e-4a6c-bd9d-f3f762d7d558,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-d63c89eb-b90f-4d8f-b566-ea145f1a5fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-955ea005-09f6-48a3-a02f-e605bd274a63,DISK], DatanodeInfoWithStorage[127.0.0.1:35998,DS-a576cf93-8180-42ef-9f27-265c39faef70,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-5a47a835-34ce-4dfd-a409-fe372c859af8,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-1b3a4e37-615a-46f7-8cd0-e36e27d50847,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-832897750-172.17.0.2-1595578321398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39672,DS-c30b873c-419f-4695-b16d-e42a7cf8e8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-784851cc-6693-40fc-af60-1c3a3c3f59fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38828,DS-b400858d-4f4e-4a6c-bd9d-f3f762d7d558,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-d63c89eb-b90f-4d8f-b566-ea145f1a5fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-955ea005-09f6-48a3-a02f-e605bd274a63,DISK], DatanodeInfoWithStorage[127.0.0.1:35998,DS-a576cf93-8180-42ef-9f27-265c39faef70,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-5a47a835-34ce-4dfd-a409-fe372c859af8,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-1b3a4e37-615a-46f7-8cd0-e36e27d50847,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-225636190-172.17.0.2-1595578792249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35373,DS-3abf45fd-ae6f-4bdd-bb2a-8639da63a83d,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-c74d0029-2a55-47cb-98a4-45753aa546fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36605,DS-1ecb0f9b-d5f4-4d42-abdd-f594d5837ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-11700c88-f675-4fca-aead-98c767546b47,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-bf515f79-9111-4f96-a11f-0cef0b196699,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-17066388-e0ad-4f80-94f7-600b86a0a87e,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-553a7c3f-867b-4297-9954-999002bdb285,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-b325ff8a-42ab-43d6-8dda-c49496974fb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-225636190-172.17.0.2-1595578792249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35373,DS-3abf45fd-ae6f-4bdd-bb2a-8639da63a83d,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-c74d0029-2a55-47cb-98a4-45753aa546fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36605,DS-1ecb0f9b-d5f4-4d42-abdd-f594d5837ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-11700c88-f675-4fca-aead-98c767546b47,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-bf515f79-9111-4f96-a11f-0cef0b196699,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-17066388-e0ad-4f80-94f7-600b86a0a87e,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-553a7c3f-867b-4297-9954-999002bdb285,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-b325ff8a-42ab-43d6-8dda-c49496974fb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-713568317-172.17.0.2-1595578908017:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44022,DS-df44bb3d-f288-4af5-8ef4-f6924f0dc75a,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-27b2a557-a8a0-4d45-bdac-d58129583f76,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-bd10d20f-18f0-42f7-a025-33d5d33e7665,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-c75c2110-e705-4a99-a6e5-1a808b0667a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-7d08a286-d668-419a-80b5-f061aae86fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-1bb2e935-ed9f-490e-83e0-96db123b416d,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-e245b42a-7484-444a-a576-836ca18f3517,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-3f35b40d-e4b7-4996-be41-27be4fa016c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-713568317-172.17.0.2-1595578908017:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44022,DS-df44bb3d-f288-4af5-8ef4-f6924f0dc75a,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-27b2a557-a8a0-4d45-bdac-d58129583f76,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-bd10d20f-18f0-42f7-a025-33d5d33e7665,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-c75c2110-e705-4a99-a6e5-1a808b0667a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-7d08a286-d668-419a-80b5-f061aae86fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-1bb2e935-ed9f-490e-83e0-96db123b416d,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-e245b42a-7484-444a-a576-836ca18f3517,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-3f35b40d-e4b7-4996-be41-27be4fa016c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-277271094-172.17.0.2-1595579014616:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37458,DS-93a23ee3-804d-49e1-a0e9-76ad73bb5ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-83af6048-64dc-4043-bc94-7f99e8db5114,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-77e9d5a7-8301-432a-aafe-90faa688740e,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-0be1f5fc-680f-447f-a83a-e0187902f65b,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-de63b2b1-f42c-47a6-a576-58b70854049a,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-cf8d71de-6231-4fd5-827c-55b3d8635c47,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-37f28b0c-cf9f-418f-8b6b-b23a8ba94541,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-097c3bbe-8549-407e-880d-e2dfff4d2025,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-277271094-172.17.0.2-1595579014616:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37458,DS-93a23ee3-804d-49e1-a0e9-76ad73bb5ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-83af6048-64dc-4043-bc94-7f99e8db5114,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-77e9d5a7-8301-432a-aafe-90faa688740e,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-0be1f5fc-680f-447f-a83a-e0187902f65b,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-de63b2b1-f42c-47a6-a576-58b70854049a,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-cf8d71de-6231-4fd5-827c-55b3d8635c47,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-37f28b0c-cf9f-418f-8b6b-b23a8ba94541,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-097c3bbe-8549-407e-880d-e2dfff4d2025,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5599
