reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-936149065-172.17.0.18-1595806893675:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39773,DS-6929f9a4-60cd-48e2-8ee6-57621eb9feba,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-b45f5c99-7700-4170-adde-cd1b2dba5419,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-9e874770-9c7b-479c-88c5-a82fa2454992,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-c781adee-bd25-4c50-a73a-72a3f8f9e104,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-96b214d4-065a-47dc-9777-dd5bf689e244,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-4e07776e-fa93-461f-9af2-15b43b1e407d,DISK], DatanodeInfoWithStorage[127.0.0.1:44444,DS-bd8373dc-4d49-4422-9632-e19997f28e70,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-eb6361ea-1463-4fd7-87fe-7d51cc07383c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-936149065-172.17.0.18-1595806893675:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39773,DS-6929f9a4-60cd-48e2-8ee6-57621eb9feba,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-b45f5c99-7700-4170-adde-cd1b2dba5419,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-9e874770-9c7b-479c-88c5-a82fa2454992,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-c781adee-bd25-4c50-a73a-72a3f8f9e104,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-96b214d4-065a-47dc-9777-dd5bf689e244,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-4e07776e-fa93-461f-9af2-15b43b1e407d,DISK], DatanodeInfoWithStorage[127.0.0.1:44444,DS-bd8373dc-4d49-4422-9632-e19997f28e70,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-eb6361ea-1463-4fd7-87fe-7d51cc07383c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-353693754-172.17.0.18-1595807250556:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46489,DS-fd2c41fa-f35c-4228-acaa-0386527edb8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-8e9395e3-0a9d-4cb4-8db3-2598f307a04e,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-fbf29e81-66d0-42ee-bbb9-8b44a396f908,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-fcebc88f-4d2d-4fe7-bcb2-0c07d765c725,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-cb326b59-d6fb-4912-8479-a8c2a06fdee3,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-7c679710-0007-40f7-b3a5-0a761020e828,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-1b07bf6a-153c-4f94-83b8-04bf8288351c,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-69152db3-2b9f-41c8-8afd-3534c0b38ebd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-353693754-172.17.0.18-1595807250556:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46489,DS-fd2c41fa-f35c-4228-acaa-0386527edb8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-8e9395e3-0a9d-4cb4-8db3-2598f307a04e,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-fbf29e81-66d0-42ee-bbb9-8b44a396f908,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-fcebc88f-4d2d-4fe7-bcb2-0c07d765c725,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-cb326b59-d6fb-4912-8479-a8c2a06fdee3,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-7c679710-0007-40f7-b3a5-0a761020e828,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-1b07bf6a-153c-4f94-83b8-04bf8288351c,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-69152db3-2b9f-41c8-8afd-3534c0b38ebd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-325939847-172.17.0.18-1595807318324:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38255,DS-8857f1c8-25bd-4b97-9a0e-0ca5ef4da763,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-18b8837c-6a58-4393-bde5-f8d9d10dbc87,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-93d6c301-b883-4e8a-b874-d1c42a064321,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-52a8db7d-e856-4cf2-a949-4d142014ae46,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-f72540f9-fa42-4393-8266-ebe1a99341db,DISK], DatanodeInfoWithStorage[127.0.0.1:34032,DS-9fb57040-5e22-4f0a-a6c7-4c07cbee2b75,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-c38f088e-b6d7-456a-b1f9-4f26622f1e86,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-1577b596-46ea-4d37-8096-bb563d430ba4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-325939847-172.17.0.18-1595807318324:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38255,DS-8857f1c8-25bd-4b97-9a0e-0ca5ef4da763,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-18b8837c-6a58-4393-bde5-f8d9d10dbc87,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-93d6c301-b883-4e8a-b874-d1c42a064321,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-52a8db7d-e856-4cf2-a949-4d142014ae46,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-f72540f9-fa42-4393-8266-ebe1a99341db,DISK], DatanodeInfoWithStorage[127.0.0.1:34032,DS-9fb57040-5e22-4f0a-a6c7-4c07cbee2b75,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-c38f088e-b6d7-456a-b1f9-4f26622f1e86,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-1577b596-46ea-4d37-8096-bb563d430ba4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1551382340-172.17.0.18-1595807541415:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43844,DS-0fc551c5-0ca3-4d9b-9b38-53de45715e23,DISK], DatanodeInfoWithStorage[127.0.0.1:36816,DS-f4013f0e-11ea-48e1-9634-414077ad6b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-5e9d2320-b92a-4f0a-9e34-629f3c14e931,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-e9ce4926-b1da-4cca-9e0c-02473279f9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-e00728cb-4cf5-4f58-bc46-78720129bef9,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-d3e9d8f9-e8cf-4dd3-9a34-fe6ee4b2be0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-d0fb5fe5-5f0b-40b0-afc7-e532a35d0482,DISK], DatanodeInfoWithStorage[127.0.0.1:40644,DS-59a68209-f725-4c11-8cd8-2041c7845e20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1551382340-172.17.0.18-1595807541415:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43844,DS-0fc551c5-0ca3-4d9b-9b38-53de45715e23,DISK], DatanodeInfoWithStorage[127.0.0.1:36816,DS-f4013f0e-11ea-48e1-9634-414077ad6b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-5e9d2320-b92a-4f0a-9e34-629f3c14e931,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-e9ce4926-b1da-4cca-9e0c-02473279f9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-e00728cb-4cf5-4f58-bc46-78720129bef9,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-d3e9d8f9-e8cf-4dd3-9a34-fe6ee4b2be0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-d0fb5fe5-5f0b-40b0-afc7-e532a35d0482,DISK], DatanodeInfoWithStorage[127.0.0.1:40644,DS-59a68209-f725-4c11-8cd8-2041c7845e20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-693460929-172.17.0.18-1595807842621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34056,DS-be897659-db8d-486d-aa4a-58b464855c76,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-4b7d65b5-ad40-4954-82b6-8bb3674c1565,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-5c73b76b-a8c0-4420-a51a-24c72690b4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-843bc2a6-76a6-40dd-b5ac-631831e8f65a,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-0dbc6773-f216-4070-b927-95091b8436cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-c1dee250-5d3c-4e09-ba1f-45224a6236d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-11cf0728-2d28-41e9-a8cf-9ebb98b45b90,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-75b33596-7ee2-44a9-8bd0-2e2d6c5aa43a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-693460929-172.17.0.18-1595807842621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34056,DS-be897659-db8d-486d-aa4a-58b464855c76,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-4b7d65b5-ad40-4954-82b6-8bb3674c1565,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-5c73b76b-a8c0-4420-a51a-24c72690b4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-843bc2a6-76a6-40dd-b5ac-631831e8f65a,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-0dbc6773-f216-4070-b927-95091b8436cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-c1dee250-5d3c-4e09-ba1f-45224a6236d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-11cf0728-2d28-41e9-a8cf-9ebb98b45b90,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-75b33596-7ee2-44a9-8bd0-2e2d6c5aa43a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-187188035-172.17.0.18-1595808145150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38816,DS-7e8246ed-caef-4c3d-886b-95e7933e0c50,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-f667fe07-e818-49de-a75b-db4e81917679,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-c0aa6000-6e0d-4af1-9da6-18084d027464,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-0518269f-0f75-4a89-beb5-869c21537d44,DISK], DatanodeInfoWithStorage[127.0.0.1:43697,DS-cfc75406-3ee3-4295-81d2-99d194da0f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-8fe47e9b-a42a-46fc-8ed1-01950b3b371a,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-70f22d6a-2a1a-419d-982a-0fd895732a04,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-5e1e428e-15e1-405c-9253-9b09a2f6116a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-187188035-172.17.0.18-1595808145150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38816,DS-7e8246ed-caef-4c3d-886b-95e7933e0c50,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-f667fe07-e818-49de-a75b-db4e81917679,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-c0aa6000-6e0d-4af1-9da6-18084d027464,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-0518269f-0f75-4a89-beb5-869c21537d44,DISK], DatanodeInfoWithStorage[127.0.0.1:43697,DS-cfc75406-3ee3-4295-81d2-99d194da0f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-8fe47e9b-a42a-46fc-8ed1-01950b3b371a,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-70f22d6a-2a1a-419d-982a-0fd895732a04,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-5e1e428e-15e1-405c-9253-9b09a2f6116a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1862835653-172.17.0.18-1595808209482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39739,DS-3b1d19ad-e208-4145-8697-af6c15a3745e,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-aeb8bb7a-6107-4910-8570-e8f1dea924e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-4a3f34d2-832f-46fd-82b3-7a29b567b438,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-707447ab-da1a-4ce1-a040-2d1be82a04eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35270,DS-ffa1f420-1465-4d7d-b434-b118904fe19f,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-71c4fe86-b062-4dd3-adb9-2c3a9964851d,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-91b11755-4740-4684-8ace-e498f52f6b43,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-f04008f7-3b9f-497a-91d0-ad286a8a1adb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1862835653-172.17.0.18-1595808209482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39739,DS-3b1d19ad-e208-4145-8697-af6c15a3745e,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-aeb8bb7a-6107-4910-8570-e8f1dea924e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-4a3f34d2-832f-46fd-82b3-7a29b567b438,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-707447ab-da1a-4ce1-a040-2d1be82a04eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35270,DS-ffa1f420-1465-4d7d-b434-b118904fe19f,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-71c4fe86-b062-4dd3-adb9-2c3a9964851d,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-91b11755-4740-4684-8ace-e498f52f6b43,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-f04008f7-3b9f-497a-91d0-ad286a8a1adb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1891557109-172.17.0.18-1595808499644:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45933,DS-c00fa9db-ae41-4829-9fbb-2283a2b67858,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-55bef4b1-ea62-43df-96ec-c3dc0dd44c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-19e1caec-ecf6-406a-9330-8e613ae012ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-eeea21aa-f874-455c-95f1-f00c3dc30dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-e3f67496-c00b-4ae3-b5e6-e239fa09aea0,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-55823811-2e9b-41a1-9a6e-34e99b0c6166,DISK], DatanodeInfoWithStorage[127.0.0.1:40828,DS-82f51392-9ffb-4f06-bcb1-3b49db72a6af,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-d33764eb-aa46-49c5-b4ac-5c421421167e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1891557109-172.17.0.18-1595808499644:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45933,DS-c00fa9db-ae41-4829-9fbb-2283a2b67858,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-55bef4b1-ea62-43df-96ec-c3dc0dd44c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-19e1caec-ecf6-406a-9330-8e613ae012ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-eeea21aa-f874-455c-95f1-f00c3dc30dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-e3f67496-c00b-4ae3-b5e6-e239fa09aea0,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-55823811-2e9b-41a1-9a6e-34e99b0c6166,DISK], DatanodeInfoWithStorage[127.0.0.1:40828,DS-82f51392-9ffb-4f06-bcb1-3b49db72a6af,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-d33764eb-aa46-49c5-b4ac-5c421421167e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1748193451-172.17.0.18-1595808821793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43862,DS-809b965a-6f3e-4222-90a4-294f3d5daf75,DISK], DatanodeInfoWithStorage[127.0.0.1:36579,DS-71f30001-f04d-4f6d-9cd4-e8084d6eb256,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-0a50b468-1e2a-457e-b8d1-fce139217d44,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-75346534-bee3-4045-8141-3dc61283b439,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-3bfbcf26-ade4-47f8-a882-9877b8d868ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-87e5ad07-feaf-4613-845d-4b7a83617686,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-179691be-ff7d-4c0b-9e6e-47c01698ddaa,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-fccf081d-7a57-4f20-8467-b90cdb95e1c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1748193451-172.17.0.18-1595808821793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43862,DS-809b965a-6f3e-4222-90a4-294f3d5daf75,DISK], DatanodeInfoWithStorage[127.0.0.1:36579,DS-71f30001-f04d-4f6d-9cd4-e8084d6eb256,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-0a50b468-1e2a-457e-b8d1-fce139217d44,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-75346534-bee3-4045-8141-3dc61283b439,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-3bfbcf26-ade4-47f8-a882-9877b8d868ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-87e5ad07-feaf-4613-845d-4b7a83617686,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-179691be-ff7d-4c0b-9e6e-47c01698ddaa,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-fccf081d-7a57-4f20-8467-b90cdb95e1c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-794397951-172.17.0.18-1595809598181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44649,DS-966e4c7a-ef2f-4937-a3e3-ce31eace9346,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-d0e85dc3-61a5-4cfc-a5bb-c66d5501abcb,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-34fb5a79-edb2-4c2f-a5a9-bdffbeb32ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:35441,DS-21377be6-4ec6-4236-973d-46585d5da136,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-c86fb327-99ac-4003-9953-af6188871da1,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-7ad56830-1f82-4f9c-81ec-e2fbac2230ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-d2e45cda-c799-4921-a09d-2a87615b6931,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-686d7cda-118d-4006-851e-7f312283fa5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-794397951-172.17.0.18-1595809598181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44649,DS-966e4c7a-ef2f-4937-a3e3-ce31eace9346,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-d0e85dc3-61a5-4cfc-a5bb-c66d5501abcb,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-34fb5a79-edb2-4c2f-a5a9-bdffbeb32ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:35441,DS-21377be6-4ec6-4236-973d-46585d5da136,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-c86fb327-99ac-4003-9953-af6188871da1,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-7ad56830-1f82-4f9c-81ec-e2fbac2230ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-d2e45cda-c799-4921-a09d-2a87615b6931,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-686d7cda-118d-4006-851e-7f312283fa5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2140448192-172.17.0.18-1595809933264:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46214,DS-d6679288-d855-4ed1-b0ee-742f060a6fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41575,DS-a64cda4a-74ff-4b69-b63c-11e0351bbc90,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-50cbb5ac-211a-4cb9-aa04-2d1d92bf909d,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-483b5c15-0be1-429c-9791-75ad154afa6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-f89d01c4-9361-4557-ac55-2a5a12628fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-6648fbd0-5639-4fdf-bf8a-298b728f997c,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-5e4ab2b7-27e9-406f-926f-cf2dd7ba8bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-0c08aca3-4297-4108-a7b0-998d0c3584d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2140448192-172.17.0.18-1595809933264:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46214,DS-d6679288-d855-4ed1-b0ee-742f060a6fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41575,DS-a64cda4a-74ff-4b69-b63c-11e0351bbc90,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-50cbb5ac-211a-4cb9-aa04-2d1d92bf909d,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-483b5c15-0be1-429c-9791-75ad154afa6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-f89d01c4-9361-4557-ac55-2a5a12628fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-6648fbd0-5639-4fdf-bf8a-298b728f997c,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-5e4ab2b7-27e9-406f-926f-cf2dd7ba8bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-0c08aca3-4297-4108-a7b0-998d0c3584d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-782821640-172.17.0.18-1595810000085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44104,DS-05e687bb-d5eb-45a1-8baf-0a3da628c16f,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-42642f3c-f718-4da5-8b23-dc7841dcdfa8,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-3a5bb0e9-8939-4f64-9b69-1d2e24754e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39785,DS-535bb0e0-a166-4d48-b151-af3c5ea95f03,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-03c90802-d2bd-4dea-9cec-1297fe65cb03,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-1a69c7c6-b79c-415f-8698-3358d9c63cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-2f071c90-a66b-45cc-ae7a-0295c1b316d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38500,DS-173aa9da-c7c5-4d7c-b207-1de93f0f47f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-782821640-172.17.0.18-1595810000085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44104,DS-05e687bb-d5eb-45a1-8baf-0a3da628c16f,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-42642f3c-f718-4da5-8b23-dc7841dcdfa8,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-3a5bb0e9-8939-4f64-9b69-1d2e24754e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39785,DS-535bb0e0-a166-4d48-b151-af3c5ea95f03,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-03c90802-d2bd-4dea-9cec-1297fe65cb03,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-1a69c7c6-b79c-415f-8698-3358d9c63cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-2f071c90-a66b-45cc-ae7a-0295c1b316d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38500,DS-173aa9da-c7c5-4d7c-b207-1de93f0f47f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1457005618-172.17.0.18-1595810204314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42374,DS-dcf7f41a-6813-46b7-873d-06853fc7f528,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-de2d70ce-e7d0-4204-a475-a6f5510d52fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-7ef31313-6411-4b5e-8600-2e6c9ae6df50,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-cad3b73a-6ee7-4b51-9468-42dd6bb196c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-966c3f51-a7ae-483d-887c-c5ec131ed9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-3c017cc2-1570-4b1d-8208-e7e40eb08a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-95376645-a206-4766-84e7-2e28293168ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-ae2c78ff-f6f1-48be-ac0f-95e417cb9854,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1457005618-172.17.0.18-1595810204314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42374,DS-dcf7f41a-6813-46b7-873d-06853fc7f528,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-de2d70ce-e7d0-4204-a475-a6f5510d52fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-7ef31313-6411-4b5e-8600-2e6c9ae6df50,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-cad3b73a-6ee7-4b51-9468-42dd6bb196c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-966c3f51-a7ae-483d-887c-c5ec131ed9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-3c017cc2-1570-4b1d-8208-e7e40eb08a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-95376645-a206-4766-84e7-2e28293168ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-ae2c78ff-f6f1-48be-ac0f-95e417cb9854,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1227407305-172.17.0.18-1595810516511:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44897,DS-1b1daab1-3f12-4f85-a145-5b8e1817ece6,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-d43d1de8-7528-4319-9b00-2dc710e93b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-342e5835-b8e1-4e44-9518-34345710c316,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-36331b7c-7fcb-4499-9bfa-65be2d9eabab,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-e7b15885-3de1-4f21-a2a8-7cdba2f0b0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-73d86f17-a886-4d39-992e-ff0b25f2d0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-38026802-b8f4-48ea-aec4-b5a80da1979c,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-57a2920b-d99c-46b9-98c5-c6a1476b6a55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1227407305-172.17.0.18-1595810516511:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44897,DS-1b1daab1-3f12-4f85-a145-5b8e1817ece6,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-d43d1de8-7528-4319-9b00-2dc710e93b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-342e5835-b8e1-4e44-9518-34345710c316,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-36331b7c-7fcb-4499-9bfa-65be2d9eabab,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-e7b15885-3de1-4f21-a2a8-7cdba2f0b0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-73d86f17-a886-4d39-992e-ff0b25f2d0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-38026802-b8f4-48ea-aec4-b5a80da1979c,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-57a2920b-d99c-46b9-98c5-c6a1476b6a55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-227285804-172.17.0.18-1595810667150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34852,DS-18773f75-0608-45e3-b14c-eac38d2ef37e,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-d272dde4-f6b3-45b3-b18d-613b372ccff2,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-fbd822c6-2db3-465f-b0af-7add8fc5fa57,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-c32df719-60eb-4931-b193-eeaafd212556,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-c404a2d0-fb9d-4ba6-a002-2aa2d01d9c61,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-79127e82-766e-4db4-9acf-fe6d69a5947c,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-99166378-70d9-4788-bfad-71ed925017d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-b2585cb6-2bd2-4906-9070-9cd3b63eeec1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-227285804-172.17.0.18-1595810667150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34852,DS-18773f75-0608-45e3-b14c-eac38d2ef37e,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-d272dde4-f6b3-45b3-b18d-613b372ccff2,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-fbd822c6-2db3-465f-b0af-7add8fc5fa57,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-c32df719-60eb-4931-b193-eeaafd212556,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-c404a2d0-fb9d-4ba6-a002-2aa2d01d9c61,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-79127e82-766e-4db4-9acf-fe6d69a5947c,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-99166378-70d9-4788-bfad-71ed925017d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-b2585cb6-2bd2-4906-9070-9cd3b63eeec1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1484226040-172.17.0.18-1595810815042:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37266,DS-12ef4503-c979-4554-bc09-74055020a769,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-bb653c8c-f317-487a-ae66-6b3027a820a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-27084a84-907d-4fad-a5dd-4e4959399840,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-8269878f-3b51-4109-9987-9b97e180c43e,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-98342389-8c5a-4ace-b165-be97db8ba226,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-54ac37b9-209a-4fab-ab60-5922dd85e91f,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-28936c8e-bbbf-4118-b187-9c593f367e58,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-6655d230-6173-44f5-a703-806c470c1b26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1484226040-172.17.0.18-1595810815042:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37266,DS-12ef4503-c979-4554-bc09-74055020a769,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-bb653c8c-f317-487a-ae66-6b3027a820a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-27084a84-907d-4fad-a5dd-4e4959399840,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-8269878f-3b51-4109-9987-9b97e180c43e,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-98342389-8c5a-4ace-b165-be97db8ba226,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-54ac37b9-209a-4fab-ab60-5922dd85e91f,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-28936c8e-bbbf-4118-b187-9c593f367e58,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-6655d230-6173-44f5-a703-806c470c1b26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-289089213-172.17.0.18-1595810850273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44625,DS-008f381e-49c2-44a3-9660-4a6347e9bc33,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-0dfd6c1f-17d2-44e8-901b-18584bb97c44,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-ddb541ab-4937-4a24-8458-a6f7a57fe367,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-6152a134-bb61-4986-ae15-be6528098aca,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-7be2f406-71dd-485e-be72-824e7741bb76,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-c0c13024-9f5e-40f7-a508-5ad4d96ecb69,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-5bffee6c-3a78-4195-ad28-c47166fc3b65,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-cd9da92f-022c-4f92-8db1-3ff592071a79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-289089213-172.17.0.18-1595810850273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44625,DS-008f381e-49c2-44a3-9660-4a6347e9bc33,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-0dfd6c1f-17d2-44e8-901b-18584bb97c44,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-ddb541ab-4937-4a24-8458-a6f7a57fe367,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-6152a134-bb61-4986-ae15-be6528098aca,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-7be2f406-71dd-485e-be72-824e7741bb76,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-c0c13024-9f5e-40f7-a508-5ad4d96ecb69,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-5bffee6c-3a78-4195-ad28-c47166fc3b65,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-cd9da92f-022c-4f92-8db1-3ff592071a79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2111425995-172.17.0.18-1595810886920:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39083,DS-41b216a3-c3d0-43ab-a2e5-d4704a276fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39691,DS-12c0356e-686f-4606-91a3-f97d4ddd3a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-b3123a0f-4054-4ae7-840c-7ce0beb6dfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-03c1e423-e311-4540-9816-f319864b0282,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-4ef6bf6c-31ce-4e8e-8042-1dcc7ad1adcc,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-3755e8bf-04cc-48a5-afd2-bd0d0273e137,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-549de3ad-a2a9-4210-81f6-7b84563cfc82,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-887fdaf8-014c-4f46-a967-8a5fb48f5a6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2111425995-172.17.0.18-1595810886920:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39083,DS-41b216a3-c3d0-43ab-a2e5-d4704a276fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39691,DS-12c0356e-686f-4606-91a3-f97d4ddd3a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-b3123a0f-4054-4ae7-840c-7ce0beb6dfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-03c1e423-e311-4540-9816-f319864b0282,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-4ef6bf6c-31ce-4e8e-8042-1dcc7ad1adcc,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-3755e8bf-04cc-48a5-afd2-bd0d0273e137,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-549de3ad-a2a9-4210-81f6-7b84563cfc82,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-887fdaf8-014c-4f46-a967-8a5fb48f5a6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-685181542-172.17.0.18-1595810962598:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36210,DS-81917747-315c-4a41-b3d1-79e30acd2378,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-49051fc6-3df8-45b5-a5d0-031284a68fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-4b9e8e9a-1a48-4dd7-aba3-0db9f14ce436,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-3220da48-ec75-48ae-9b18-d9bb40cb5ead,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-8e2da77f-6bc5-4849-a2c4-427e30b86dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-355de083-426f-4a54-8c74-e8662494b363,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-cfe67595-9ef1-4303-afe1-d8ce2afe9f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-e5a5da71-d3d4-4abf-8911-f6512dcbf514,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-685181542-172.17.0.18-1595810962598:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36210,DS-81917747-315c-4a41-b3d1-79e30acd2378,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-49051fc6-3df8-45b5-a5d0-031284a68fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-4b9e8e9a-1a48-4dd7-aba3-0db9f14ce436,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-3220da48-ec75-48ae-9b18-d9bb40cb5ead,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-8e2da77f-6bc5-4849-a2c4-427e30b86dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-355de083-426f-4a54-8c74-e8662494b363,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-cfe67595-9ef1-4303-afe1-d8ce2afe9f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-e5a5da71-d3d4-4abf-8911-f6512dcbf514,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-315980854-172.17.0.18-1595811391042:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43292,DS-6b9ab42b-6b45-4b41-b7e1-3d5b5e84c443,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-6e203746-8287-439a-86eb-400ccf162ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-a7ff86ee-76a2-4dc9-ba3f-0010e47552ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-c684a66f-199c-45ee-8117-17ee6824f695,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-eea0628e-002f-4660-ab76-35f8bbe1418d,DISK], DatanodeInfoWithStorage[127.0.0.1:45482,DS-d9fb8a2d-d3e9-492d-bca3-b50e0071013b,DISK], DatanodeInfoWithStorage[127.0.0.1:46046,DS-8c601785-00cd-471c-b6c3-1d2fa7ca2e87,DISK], DatanodeInfoWithStorage[127.0.0.1:37536,DS-b6ee9731-a983-497a-965c-00bc37aa48d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-315980854-172.17.0.18-1595811391042:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43292,DS-6b9ab42b-6b45-4b41-b7e1-3d5b5e84c443,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-6e203746-8287-439a-86eb-400ccf162ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-a7ff86ee-76a2-4dc9-ba3f-0010e47552ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-c684a66f-199c-45ee-8117-17ee6824f695,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-eea0628e-002f-4660-ab76-35f8bbe1418d,DISK], DatanodeInfoWithStorage[127.0.0.1:45482,DS-d9fb8a2d-d3e9-492d-bca3-b50e0071013b,DISK], DatanodeInfoWithStorage[127.0.0.1:46046,DS-8c601785-00cd-471c-b6c3-1d2fa7ca2e87,DISK], DatanodeInfoWithStorage[127.0.0.1:37536,DS-b6ee9731-a983-497a-965c-00bc37aa48d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-917433047-172.17.0.18-1595811854666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33080,DS-a76ab334-8c63-4b60-97ed-36b05d648087,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-52142201-960f-4354-87a6-837ac6087d11,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-9ac173c5-dded-495a-931b-4d70bebe3795,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-1502d065-1554-4049-a3c1-230b91f87631,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-6580d40c-b539-4f53-94f1-4688ef78e6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-1f366bb9-9596-493c-965f-f7cfae528410,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-2d0bf2ec-0296-46a1-a066-da35299b2e76,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-cd0debf9-d737-434d-87e4-625fa356ad5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-917433047-172.17.0.18-1595811854666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33080,DS-a76ab334-8c63-4b60-97ed-36b05d648087,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-52142201-960f-4354-87a6-837ac6087d11,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-9ac173c5-dded-495a-931b-4d70bebe3795,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-1502d065-1554-4049-a3c1-230b91f87631,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-6580d40c-b539-4f53-94f1-4688ef78e6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-1f366bb9-9596-493c-965f-f7cfae528410,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-2d0bf2ec-0296-46a1-a066-da35299b2e76,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-cd0debf9-d737-434d-87e4-625fa356ad5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-17035692-172.17.0.18-1595812022518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34655,DS-9e5e8c73-775e-45b5-b05e-42455c4fcf68,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-a7d30943-e8b9-4a6b-a1c6-388ba0c64766,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-1c2696b2-1300-46d9-b3e8-607755f42055,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-e81df6f2-098d-4095-bee3-245a9f519bef,DISK], DatanodeInfoWithStorage[127.0.0.1:41122,DS-12fa8d86-fbda-4803-8ae0-4bf905433100,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-ae346585-c46b-4dc2-b36f-6bf4e73a329b,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-9b438c14-aca2-42f0-a25f-e1fe8dd9bd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-cf64c7d4-3888-41c1-80e7-d48364b13549,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-17035692-172.17.0.18-1595812022518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34655,DS-9e5e8c73-775e-45b5-b05e-42455c4fcf68,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-a7d30943-e8b9-4a6b-a1c6-388ba0c64766,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-1c2696b2-1300-46d9-b3e8-607755f42055,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-e81df6f2-098d-4095-bee3-245a9f519bef,DISK], DatanodeInfoWithStorage[127.0.0.1:41122,DS-12fa8d86-fbda-4803-8ae0-4bf905433100,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-ae346585-c46b-4dc2-b36f-6bf4e73a329b,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-9b438c14-aca2-42f0-a25f-e1fe8dd9bd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-cf64c7d4-3888-41c1-80e7-d48364b13549,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5394
