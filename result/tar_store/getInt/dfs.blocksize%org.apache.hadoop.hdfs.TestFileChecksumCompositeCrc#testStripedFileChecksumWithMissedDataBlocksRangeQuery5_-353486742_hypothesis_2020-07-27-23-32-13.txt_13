reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1469893315-172.17.0.20-1595892887134:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33544,DS-1264e49e-ba95-4c2f-b8b6-166a826ce314,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-95db8a6d-dc54-474f-be35-5bba2f760c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37367,DS-254de89d-7199-4a2f-bbf1-14defe279fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-ef25cb91-b186-4291-aea8-1027db326e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-ca6168fd-3bd6-4e9e-a19d-c0b57f7d45ca,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-1066eca2-32d2-47c8-846e-0eeedb55bc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-7d96dd42-b321-43c9-923e-692329b4dde2,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-19186cb9-5ad9-4381-9787-e2e26ee8fef6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1469893315-172.17.0.20-1595892887134:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33544,DS-1264e49e-ba95-4c2f-b8b6-166a826ce314,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-95db8a6d-dc54-474f-be35-5bba2f760c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37367,DS-254de89d-7199-4a2f-bbf1-14defe279fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-ef25cb91-b186-4291-aea8-1027db326e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-ca6168fd-3bd6-4e9e-a19d-c0b57f7d45ca,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-1066eca2-32d2-47c8-846e-0eeedb55bc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-7d96dd42-b321-43c9-923e-692329b4dde2,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-19186cb9-5ad9-4381-9787-e2e26ee8fef6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-35333071-172.17.0.20-1595893494718:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41925,DS-2d2cfea1-cee2-4ca1-982e-e5c5c51a30d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-1529c647-5db2-4cbc-8949-d65657cc89a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44405,DS-c0d1bc86-9e29-44f1-a26e-c24821ceec6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-ade3a8b1-b1f3-4e28-beee-e1069d47bf25,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-359e28bd-94d6-4f86-af74-58bd3f732c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-bf6035e1-b425-4a1a-ac7d-cd24891683f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-b04e03de-f15b-4471-b78b-60545e1c076b,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-83cb2420-ff3e-45a3-bf86-7af2bd79d251,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-35333071-172.17.0.20-1595893494718:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41925,DS-2d2cfea1-cee2-4ca1-982e-e5c5c51a30d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-1529c647-5db2-4cbc-8949-d65657cc89a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44405,DS-c0d1bc86-9e29-44f1-a26e-c24821ceec6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-ade3a8b1-b1f3-4e28-beee-e1069d47bf25,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-359e28bd-94d6-4f86-af74-58bd3f732c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-bf6035e1-b425-4a1a-ac7d-cd24891683f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-b04e03de-f15b-4471-b78b-60545e1c076b,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-83cb2420-ff3e-45a3-bf86-7af2bd79d251,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1892674691-172.17.0.20-1595893629903:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34938,DS-1d1b11a7-0821-41fa-8a44-646141be3a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39406,DS-812ce35c-6101-4141-a237-7c37ce44297e,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-09a869dc-55d6-4b1b-8f68-ea8fa03a91a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-b4b74fa3-50ac-4150-82fe-9e1e724454f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-9057ba7b-c360-47da-9339-433d7b8ab150,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-09b92303-82ca-4385-901e-ae5d48877ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-8375e2aa-4b07-4931-8358-76c7c9e4f947,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-fb920e1c-61c9-4755-b5f6-823f7d85145c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1892674691-172.17.0.20-1595893629903:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34938,DS-1d1b11a7-0821-41fa-8a44-646141be3a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39406,DS-812ce35c-6101-4141-a237-7c37ce44297e,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-09a869dc-55d6-4b1b-8f68-ea8fa03a91a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-b4b74fa3-50ac-4150-82fe-9e1e724454f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-9057ba7b-c360-47da-9339-433d7b8ab150,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-09b92303-82ca-4385-901e-ae5d48877ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-8375e2aa-4b07-4931-8358-76c7c9e4f947,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-fb920e1c-61c9-4755-b5f6-823f7d85145c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2010104916-172.17.0.20-1595893832262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35949,DS-6e3de4e8-665a-4601-9983-fa4e37f88ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-9e2752cb-c8fa-4137-abc4-bab79b19ebc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-396ba3e6-4c15-4f48-b277-faa667e5d7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-61033c61-818f-4446-9d1e-0b4fe46967af,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-b9836302-264b-47a7-b942-536afa941ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:36538,DS-c40ad6c8-c199-4b4f-9439-e795ad71b1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-79263bb2-27c8-4a9b-848f-d629b8a37f93,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-5d7b53f3-24f7-4070-9c22-31f3aed10a6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2010104916-172.17.0.20-1595893832262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35949,DS-6e3de4e8-665a-4601-9983-fa4e37f88ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-9e2752cb-c8fa-4137-abc4-bab79b19ebc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-396ba3e6-4c15-4f48-b277-faa667e5d7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-61033c61-818f-4446-9d1e-0b4fe46967af,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-b9836302-264b-47a7-b942-536afa941ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:36538,DS-c40ad6c8-c199-4b4f-9439-e795ad71b1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-79263bb2-27c8-4a9b-848f-d629b8a37f93,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-5d7b53f3-24f7-4070-9c22-31f3aed10a6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1456951413-172.17.0.20-1595893870727:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43208,DS-316de59d-d974-46a5-b646-2489b6aeb0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-bd43d9df-bafb-49d2-9e62-f584d281e0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-52e16d4a-a053-4a3b-97fd-ff5da77c5ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-781e94f1-6251-46d5-a5c4-ea3b812f3501,DISK], DatanodeInfoWithStorage[127.0.0.1:43517,DS-ebc784f0-d7fc-4052-8a7c-49b602f6b6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44600,DS-253fa11c-d2be-455a-af4d-0e42c796fc50,DISK], DatanodeInfoWithStorage[127.0.0.1:41485,DS-9ae265e0-fcfd-49a9-9d5a-aab648be2427,DISK], DatanodeInfoWithStorage[127.0.0.1:34416,DS-c98096e9-95f9-4f2c-8821-bf050cdca1fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1456951413-172.17.0.20-1595893870727:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43208,DS-316de59d-d974-46a5-b646-2489b6aeb0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-bd43d9df-bafb-49d2-9e62-f584d281e0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-52e16d4a-a053-4a3b-97fd-ff5da77c5ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-781e94f1-6251-46d5-a5c4-ea3b812f3501,DISK], DatanodeInfoWithStorage[127.0.0.1:43517,DS-ebc784f0-d7fc-4052-8a7c-49b602f6b6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44600,DS-253fa11c-d2be-455a-af4d-0e42c796fc50,DISK], DatanodeInfoWithStorage[127.0.0.1:41485,DS-9ae265e0-fcfd-49a9-9d5a-aab648be2427,DISK], DatanodeInfoWithStorage[127.0.0.1:34416,DS-c98096e9-95f9-4f2c-8821-bf050cdca1fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-587975949-172.17.0.20-1595894173416:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35842,DS-267efce6-1d66-4c6b-a9bb-3c62efb66bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-2f4d52b1-dbea-406f-aa25-0aa6d91821d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-41b2e08e-1453-47cd-87d4-f5f24bd3092c,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-e7be43e2-5f12-48c9-83d3-6aca335707f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-3ef31b2a-da3c-4f5d-a29d-a3b66fdaa914,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-1e48a3ff-1b8d-431d-92a7-007c7b1cdd25,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-275308b4-134b-4a78-a998-2469f83fb29c,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-d07fcc3e-80fc-4fdf-bf0a-940e36d54210,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-587975949-172.17.0.20-1595894173416:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35842,DS-267efce6-1d66-4c6b-a9bb-3c62efb66bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-2f4d52b1-dbea-406f-aa25-0aa6d91821d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-41b2e08e-1453-47cd-87d4-f5f24bd3092c,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-e7be43e2-5f12-48c9-83d3-6aca335707f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-3ef31b2a-da3c-4f5d-a29d-a3b66fdaa914,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-1e48a3ff-1b8d-431d-92a7-007c7b1cdd25,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-275308b4-134b-4a78-a998-2469f83fb29c,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-d07fcc3e-80fc-4fdf-bf0a-940e36d54210,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-155376350-172.17.0.20-1595894580765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45924,DS-e18f6525-3e01-4357-9051-72af5bde6548,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-b3dcdeff-3b7d-435b-84ca-1422bb265af3,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-c1eb28fe-90a1-4ecb-898c-64c02e475ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:42978,DS-37a5329b-1405-444e-8ee2-33260aa57bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-17c4078b-5221-4d9c-b04b-6de6380f022b,DISK], DatanodeInfoWithStorage[127.0.0.1:33998,DS-c4473182-9654-4b38-a106-76855995cfd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-ae1ead94-01bf-474d-a0ca-e5f82ba6cce6,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-7bb1e8b9-93a9-4db1-a823-0eb156ea31d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-155376350-172.17.0.20-1595894580765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45924,DS-e18f6525-3e01-4357-9051-72af5bde6548,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-b3dcdeff-3b7d-435b-84ca-1422bb265af3,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-c1eb28fe-90a1-4ecb-898c-64c02e475ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:42978,DS-37a5329b-1405-444e-8ee2-33260aa57bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-17c4078b-5221-4d9c-b04b-6de6380f022b,DISK], DatanodeInfoWithStorage[127.0.0.1:33998,DS-c4473182-9654-4b38-a106-76855995cfd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-ae1ead94-01bf-474d-a0ca-e5f82ba6cce6,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-7bb1e8b9-93a9-4db1-a823-0eb156ea31d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1254849270-172.17.0.20-1595895087268:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40238,DS-8ef4df5e-a0c8-42c6-9464-4edfa695974c,DISK], DatanodeInfoWithStorage[127.0.0.1:34578,DS-a5520653-c920-4862-a953-2fb65b2cd2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-b9c1164a-0770-44b2-9a01-4e8cb81357d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42144,DS-bbadd932-1b11-4515-8fee-fc8c75d443cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-1f6308ea-5056-4fd1-8e61-adabc02831be,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-bff5460d-e3e8-4741-a18e-ac7526d26a64,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-1a78ddb0-7c3f-47a7-bee4-30c1471a70f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-d72503e8-f2b4-4f67-ab23-554a49268d2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1254849270-172.17.0.20-1595895087268:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40238,DS-8ef4df5e-a0c8-42c6-9464-4edfa695974c,DISK], DatanodeInfoWithStorage[127.0.0.1:34578,DS-a5520653-c920-4862-a953-2fb65b2cd2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-b9c1164a-0770-44b2-9a01-4e8cb81357d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42144,DS-bbadd932-1b11-4515-8fee-fc8c75d443cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-1f6308ea-5056-4fd1-8e61-adabc02831be,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-bff5460d-e3e8-4741-a18e-ac7526d26a64,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-1a78ddb0-7c3f-47a7-bee4-30c1471a70f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-d72503e8-f2b4-4f67-ab23-554a49268d2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1562385491-172.17.0.20-1595895589824:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39534,DS-898b8bcc-a462-4444-97c0-9d0d59e04862,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-9dc500a7-46be-42c0-b109-8f484507a522,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-8dc4c98d-2e95-47cb-bdb8-7cd025357e54,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-46fed78c-7297-4e2c-b638-56f6e8adbfe3,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-eeb2dff6-9512-4716-ad78-be7691aa6ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:36934,DS-58b1b592-b6b1-4977-a3e5-75a1bb19d1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-67d7e2cf-a4b2-4ca9-9dae-42b42ae67407,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-997bf9cf-ecc4-43e8-9f79-859e6a71aab9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1562385491-172.17.0.20-1595895589824:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39534,DS-898b8bcc-a462-4444-97c0-9d0d59e04862,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-9dc500a7-46be-42c0-b109-8f484507a522,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-8dc4c98d-2e95-47cb-bdb8-7cd025357e54,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-46fed78c-7297-4e2c-b638-56f6e8adbfe3,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-eeb2dff6-9512-4716-ad78-be7691aa6ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:36934,DS-58b1b592-b6b1-4977-a3e5-75a1bb19d1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-67d7e2cf-a4b2-4ca9-9dae-42b42ae67407,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-997bf9cf-ecc4-43e8-9f79-859e6a71aab9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1060527108-172.17.0.20-1595895887547:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42625,DS-e29fc2c2-1831-406f-93a0-a5348fee28f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44624,DS-6b3cf938-7434-4f97-8e0b-a7f16fa4bdaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37556,DS-3864735f-2f65-4efa-b282-a04428900988,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-f1d9a394-94be-4226-b4c8-b24f41807498,DISK], DatanodeInfoWithStorage[127.0.0.1:43919,DS-ffac1f54-63aa-4af7-83d6-7ee56e8864f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-2b8a130d-c0ab-40a1-84aa-145b489b3c05,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-72ec4849-118e-4190-b42b-ae702d10265b,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-8d95ff42-482a-4fe3-809e-1de58933aa20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1060527108-172.17.0.20-1595895887547:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42625,DS-e29fc2c2-1831-406f-93a0-a5348fee28f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44624,DS-6b3cf938-7434-4f97-8e0b-a7f16fa4bdaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37556,DS-3864735f-2f65-4efa-b282-a04428900988,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-f1d9a394-94be-4226-b4c8-b24f41807498,DISK], DatanodeInfoWithStorage[127.0.0.1:43919,DS-ffac1f54-63aa-4af7-83d6-7ee56e8864f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-2b8a130d-c0ab-40a1-84aa-145b489b3c05,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-72ec4849-118e-4190-b42b-ae702d10265b,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-8d95ff42-482a-4fe3-809e-1de58933aa20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2143154585-172.17.0.20-1595896098964:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35957,DS-dfa2ac19-3240-4029-82a5-d73b8ead2dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-4b5a312c-e506-43ba-9708-1c0e1851e2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-3cd203c6-a676-44fb-aa1b-5743b2dc9d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-a44ebb9e-7bd9-4c7b-bb36-556df04ca900,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-e2479c5d-af13-4624-a295-0cfc70f60299,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-ece4f478-9682-48dc-ad7e-c8826be93854,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-5d3d0c21-167c-4fe6-a341-7c469e2dd3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-824b28b8-e758-48ac-8949-f61b4222619f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2143154585-172.17.0.20-1595896098964:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35957,DS-dfa2ac19-3240-4029-82a5-d73b8ead2dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-4b5a312c-e506-43ba-9708-1c0e1851e2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-3cd203c6-a676-44fb-aa1b-5743b2dc9d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-a44ebb9e-7bd9-4c7b-bb36-556df04ca900,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-e2479c5d-af13-4624-a295-0cfc70f60299,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-ece4f478-9682-48dc-ad7e-c8826be93854,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-5d3d0c21-167c-4fe6-a341-7c469e2dd3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-824b28b8-e758-48ac-8949-f61b4222619f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-42960899-172.17.0.20-1595896319420:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41487,DS-5c5ea59e-2ed8-4254-95d6-970d21e65594,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-8243db59-b535-4fc6-92fe-bc573a29e97a,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-f8a842ff-d1bf-45a8-b955-d7660b9738ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-0e7d677a-fb79-4595-9d19-aad92bc6fbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-64f351b7-be42-4502-b60e-05c17a747f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37146,DS-bac7ff71-23f3-43b0-ae31-45a342277345,DISK], DatanodeInfoWithStorage[127.0.0.1:43209,DS-31518255-aac7-47af-98f6-7fec1108f546,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-6e636382-cdc6-4584-b447-7f1cc2013323,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-42960899-172.17.0.20-1595896319420:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41487,DS-5c5ea59e-2ed8-4254-95d6-970d21e65594,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-8243db59-b535-4fc6-92fe-bc573a29e97a,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-f8a842ff-d1bf-45a8-b955-d7660b9738ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-0e7d677a-fb79-4595-9d19-aad92bc6fbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-64f351b7-be42-4502-b60e-05c17a747f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37146,DS-bac7ff71-23f3-43b0-ae31-45a342277345,DISK], DatanodeInfoWithStorage[127.0.0.1:43209,DS-31518255-aac7-47af-98f6-7fec1108f546,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-6e636382-cdc6-4584-b447-7f1cc2013323,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1536446751-172.17.0.20-1595896365674:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45982,DS-871c01bd-453f-48cf-bdf0-3804410b8faa,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-5641e735-2205-409b-bb8d-baf141366880,DISK], DatanodeInfoWithStorage[127.0.0.1:39876,DS-dc00f09a-6fdf-4258-962d-62b96290930b,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-f583faae-c149-47db-9aab-742d30102b18,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-8805c99b-6c34-4a8c-adc4-48ebae2c6291,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-e0d25f91-f18e-4674-805e-0cd629cde812,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-57a757cc-60b7-434d-a0eb-f37761f1bf2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-3a52dbcc-76d2-42cc-ab4f-453f5982c3ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1536446751-172.17.0.20-1595896365674:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45982,DS-871c01bd-453f-48cf-bdf0-3804410b8faa,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-5641e735-2205-409b-bb8d-baf141366880,DISK], DatanodeInfoWithStorage[127.0.0.1:39876,DS-dc00f09a-6fdf-4258-962d-62b96290930b,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-f583faae-c149-47db-9aab-742d30102b18,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-8805c99b-6c34-4a8c-adc4-48ebae2c6291,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-e0d25f91-f18e-4674-805e-0cd629cde812,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-57a757cc-60b7-434d-a0eb-f37761f1bf2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-3a52dbcc-76d2-42cc-ab4f-453f5982c3ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1490616818-172.17.0.20-1595896439694:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33069,DS-d58de2f0-0edf-42eb-a735-34a779b1411e,DISK], DatanodeInfoWithStorage[127.0.0.1:43454,DS-d692fd4e-0e9b-475e-a605-17fc129eadc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-32498341-d7c4-46d1-9877-9f602bae142b,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-ceaf0ef0-37c7-4ec8-bff2-9bcf25da74e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38296,DS-49529ef1-b74f-47c3-b42e-f8a989be1cde,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-ece7d87d-d818-4933-9507-40890625e386,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-ee7fd7d3-a1aa-48ae-b76d-879b45e7c947,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-da63293f-5a58-4e10-b02a-5eb072b43ae5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1490616818-172.17.0.20-1595896439694:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33069,DS-d58de2f0-0edf-42eb-a735-34a779b1411e,DISK], DatanodeInfoWithStorage[127.0.0.1:43454,DS-d692fd4e-0e9b-475e-a605-17fc129eadc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-32498341-d7c4-46d1-9877-9f602bae142b,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-ceaf0ef0-37c7-4ec8-bff2-9bcf25da74e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38296,DS-49529ef1-b74f-47c3-b42e-f8a989be1cde,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-ece7d87d-d818-4933-9507-40890625e386,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-ee7fd7d3-a1aa-48ae-b76d-879b45e7c947,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-da63293f-5a58-4e10-b02a-5eb072b43ae5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2089377277-172.17.0.20-1595896605233:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42954,DS-50211c46-84ce-4187-a940-f023f41a1fba,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-44b448c5-866a-40f7-9395-8a0fea0bc3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-ea90ca12-6ba6-4f38-b383-b3df5800ffed,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-f6c9e831-f396-485e-84ec-66d674062d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-6bbe2cc8-ff33-4b45-8818-a2fef7d9eeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-8d8e6bf4-6ce9-45e2-a6e6-e88c3cc4d002,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-1df56770-20e4-4c6c-8ffa-8e1bdac7b1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45643,DS-8a5785e3-71b3-449a-829d-29ba9e476385,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2089377277-172.17.0.20-1595896605233:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42954,DS-50211c46-84ce-4187-a940-f023f41a1fba,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-44b448c5-866a-40f7-9395-8a0fea0bc3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-ea90ca12-6ba6-4f38-b383-b3df5800ffed,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-f6c9e831-f396-485e-84ec-66d674062d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-6bbe2cc8-ff33-4b45-8818-a2fef7d9eeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-8d8e6bf4-6ce9-45e2-a6e6-e88c3cc4d002,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-1df56770-20e4-4c6c-8ffa-8e1bdac7b1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45643,DS-8a5785e3-71b3-449a-829d-29ba9e476385,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-586835305-172.17.0.20-1595896764813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32929,DS-d140d780-9df3-42e6-99b6-76a97d0a768e,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-e72d0183-541a-4449-be95-17ecb0953c57,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-38139961-8649-406f-8743-3f80018e0420,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-ef49bec9-24d7-4082-b6ae-ba427c57031b,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-f1684e91-a364-42c4-ad76-b3ab14b7975f,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-91bd63f9-fc48-48fa-b8d2-fa947c0f891e,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-c855e3ca-1f3f-4c2a-abe9-92a64a609834,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-bce66b86-5c6a-4c36-83b2-dce900c9e860,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-586835305-172.17.0.20-1595896764813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32929,DS-d140d780-9df3-42e6-99b6-76a97d0a768e,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-e72d0183-541a-4449-be95-17ecb0953c57,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-38139961-8649-406f-8743-3f80018e0420,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-ef49bec9-24d7-4082-b6ae-ba427c57031b,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-f1684e91-a364-42c4-ad76-b3ab14b7975f,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-91bd63f9-fc48-48fa-b8d2-fa947c0f891e,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-c855e3ca-1f3f-4c2a-abe9-92a64a609834,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-bce66b86-5c6a-4c36-83b2-dce900c9e860,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1344647923-172.17.0.20-1595897320203:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42338,DS-7853e09e-cfc7-4214-bbcd-0be821fe5a44,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-994ec532-a9fd-4bb5-ae15-95df33921ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-05e20918-eb51-491c-a207-0a8f7b19ded1,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-2ff8d354-8d7b-4559-b5a0-1f06bdfeaf0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-af396e8f-1f85-4cca-ab77-65ac80d9292c,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-c75e40b7-73fd-4c3d-bbfc-36e791dd7ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-6fb0ed41-9300-4add-804b-e6ea5f2d5f52,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-ead7f227-c5bd-4be0-a37c-19cd0e202785,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1344647923-172.17.0.20-1595897320203:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42338,DS-7853e09e-cfc7-4214-bbcd-0be821fe5a44,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-994ec532-a9fd-4bb5-ae15-95df33921ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-05e20918-eb51-491c-a207-0a8f7b19ded1,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-2ff8d354-8d7b-4559-b5a0-1f06bdfeaf0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-af396e8f-1f85-4cca-ab77-65ac80d9292c,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-c75e40b7-73fd-4c3d-bbfc-36e791dd7ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-6fb0ed41-9300-4add-804b-e6ea5f2d5f52,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-ead7f227-c5bd-4be0-a37c-19cd0e202785,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-445110116-172.17.0.20-1595897474848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37222,DS-643849d4-185e-4a83-abf7-80f01616d6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-deb36968-41c1-4519-bc19-1a77fc3eec57,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-2f66661a-829a-4d4e-8c62-269a4a255ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-a8dd6a0a-e6db-4151-975a-e80bc00bf4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-aed72807-5be0-4132-9c7c-707e0b8ad5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-5c50d6e1-be2f-4756-ae5d-a570bc9a29a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-ba967091-3c97-4c00-9c54-1f40ef1ba919,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-13095aa9-bb8f-4afe-bd4b-5f69770f5ccd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-445110116-172.17.0.20-1595897474848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37222,DS-643849d4-185e-4a83-abf7-80f01616d6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-deb36968-41c1-4519-bc19-1a77fc3eec57,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-2f66661a-829a-4d4e-8c62-269a4a255ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-a8dd6a0a-e6db-4151-975a-e80bc00bf4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-aed72807-5be0-4132-9c7c-707e0b8ad5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-5c50d6e1-be2f-4756-ae5d-a570bc9a29a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-ba967091-3c97-4c00-9c54-1f40ef1ba919,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-13095aa9-bb8f-4afe-bd4b-5f69770f5ccd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2049933499-172.17.0.20-1595897739958:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33495,DS-f5f9dafa-4877-4d5d-9b18-03e40309f1df,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-d48360a0-2e12-4360-bb3c-06b6c9172a47,DISK], DatanodeInfoWithStorage[127.0.0.1:43253,DS-86577dc1-44d7-451f-8250-931a59d0a899,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-2cf6f21d-508d-408a-b956-c75ee388893c,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-5f8f08df-8ff9-4a22-b523-97dcb6d706ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-fd2ef4d5-4f77-4ec2-b9de-88bbac4f38f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-973f8d1e-d600-4f03-b78d-5615b61a64a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-e70e056a-222c-4450-adad-568457dfb9b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2049933499-172.17.0.20-1595897739958:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33495,DS-f5f9dafa-4877-4d5d-9b18-03e40309f1df,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-d48360a0-2e12-4360-bb3c-06b6c9172a47,DISK], DatanodeInfoWithStorage[127.0.0.1:43253,DS-86577dc1-44d7-451f-8250-931a59d0a899,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-2cf6f21d-508d-408a-b956-c75ee388893c,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-5f8f08df-8ff9-4a22-b523-97dcb6d706ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-fd2ef4d5-4f77-4ec2-b9de-88bbac4f38f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-973f8d1e-d600-4f03-b78d-5615b61a64a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-e70e056a-222c-4450-adad-568457dfb9b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-727799350-172.17.0.20-1595898089341:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37496,DS-dd6de18a-e9f2-40e2-9a09-5e4044cd96c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-df2bf7fe-ff3e-47cb-9aeb-886a692b7862,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-684c7009-865c-4095-8e9d-e3f2fcd10b76,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-0544e77d-f41d-41a9-8438-98666bafbbbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-115136d4-0332-4c73-bc15-6d53bcd8fd65,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-1bf7ebf6-d36d-42e0-a10a-8d5a1c177195,DISK], DatanodeInfoWithStorage[127.0.0.1:38135,DS-a4c1a618-8d9f-4dbf-9213-161831e9f0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-0328cc92-6ba9-4076-a487-2cb37bec3969,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-727799350-172.17.0.20-1595898089341:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37496,DS-dd6de18a-e9f2-40e2-9a09-5e4044cd96c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-df2bf7fe-ff3e-47cb-9aeb-886a692b7862,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-684c7009-865c-4095-8e9d-e3f2fcd10b76,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-0544e77d-f41d-41a9-8438-98666bafbbbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-115136d4-0332-4c73-bc15-6d53bcd8fd65,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-1bf7ebf6-d36d-42e0-a10a-8d5a1c177195,DISK], DatanodeInfoWithStorage[127.0.0.1:38135,DS-a4c1a618-8d9f-4dbf-9213-161831e9f0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-0328cc92-6ba9-4076-a487-2cb37bec3969,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: might be true error
Total execution time in seconds : 5648
