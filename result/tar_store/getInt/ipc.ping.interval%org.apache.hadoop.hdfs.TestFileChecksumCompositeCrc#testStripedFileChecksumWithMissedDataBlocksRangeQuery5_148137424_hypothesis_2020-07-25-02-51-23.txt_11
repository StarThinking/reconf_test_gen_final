reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-629624722-172.17.0.9-1595645622041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35644,DS-0ab30b57-df6c-495a-9b1f-134981f39ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-366f31c1-e8c0-4527-8935-994fdba7136e,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-9f41a898-fd1b-4dc5-be06-fb4a38f78a57,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-d2442d85-2b7e-44d6-81a5-b598e50dd7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-dba50823-a4ed-448f-ae6a-670d64eb283a,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-fc725a61-1772-49b9-b5b6-9ec1e1a7f5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-11d9215d-e01f-441c-9e2e-e3f1f8a6f059,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-d8d298c3-4587-4620-a6b1-3d8a4d35d205,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-629624722-172.17.0.9-1595645622041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35644,DS-0ab30b57-df6c-495a-9b1f-134981f39ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-366f31c1-e8c0-4527-8935-994fdba7136e,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-9f41a898-fd1b-4dc5-be06-fb4a38f78a57,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-d2442d85-2b7e-44d6-81a5-b598e50dd7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-dba50823-a4ed-448f-ae6a-670d64eb283a,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-fc725a61-1772-49b9-b5b6-9ec1e1a7f5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-11d9215d-e01f-441c-9e2e-e3f1f8a6f059,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-d8d298c3-4587-4620-a6b1-3d8a4d35d205,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-805502888-172.17.0.9-1595645852313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46752,DS-f56aed22-01db-4e1c-bda5-1d0a1859e896,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-0d8fc590-2bbf-4daa-a1c0-7d1b525684aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-d20ae025-5daa-4132-b351-91b67d6510b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-a783034e-779a-4b08-b8c1-856e09a62f18,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-0c7411f7-37c0-4585-8ddb-8f44be9eba2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-3dc9cbce-1cab-438c-9436-b9b80cfd4e44,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-a525b7d9-b5ff-432c-866d-9e6bf88e1ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-ee6519c5-4801-4d80-ad37-8e089acbb088,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-805502888-172.17.0.9-1595645852313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46752,DS-f56aed22-01db-4e1c-bda5-1d0a1859e896,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-0d8fc590-2bbf-4daa-a1c0-7d1b525684aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-d20ae025-5daa-4132-b351-91b67d6510b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-a783034e-779a-4b08-b8c1-856e09a62f18,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-0c7411f7-37c0-4585-8ddb-8f44be9eba2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-3dc9cbce-1cab-438c-9436-b9b80cfd4e44,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-a525b7d9-b5ff-432c-866d-9e6bf88e1ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-ee6519c5-4801-4d80-ad37-8e089acbb088,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-259313210-172.17.0.9-1595646193439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33594,DS-3d880d23-2570-4b46-8b82-6598f9a5508e,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-ff17924c-2693-4718-970a-cd29d7609b23,DISK], DatanodeInfoWithStorage[127.0.0.1:41071,DS-510209f7-bfa7-40bc-8ca6-ef25993d3f72,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-bfcb63f7-f404-4596-a95f-d6c36cd0b53b,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-8fb80732-efd7-43e7-a86d-b443b97c0b71,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-e5970d88-0a77-4a2c-a987-8ee0df6f41ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-21b6703e-7222-48f1-8eaf-83def77a98f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-d7c340e5-ac1b-4e25-a4fd-0e906e43e038,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-259313210-172.17.0.9-1595646193439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33594,DS-3d880d23-2570-4b46-8b82-6598f9a5508e,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-ff17924c-2693-4718-970a-cd29d7609b23,DISK], DatanodeInfoWithStorage[127.0.0.1:41071,DS-510209f7-bfa7-40bc-8ca6-ef25993d3f72,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-bfcb63f7-f404-4596-a95f-d6c36cd0b53b,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-8fb80732-efd7-43e7-a86d-b443b97c0b71,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-e5970d88-0a77-4a2c-a987-8ee0df6f41ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-21b6703e-7222-48f1-8eaf-83def77a98f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-d7c340e5-ac1b-4e25-a4fd-0e906e43e038,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-912140230-172.17.0.9-1595646347449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37951,DS-7243fa11-d0cf-4e97-bc0c-18e8cd89654f,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-9ab3b0b6-db7a-49fd-86d9-0bb004e28ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-c70f9dca-9d4c-4475-89f2-93316c03b12c,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-eb16f82e-4d5e-4079-9ae3-5069edce0a60,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-3cb14536-fba2-43ff-94f0-9f5ad83d66d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-97596cdf-1624-4542-a737-4be809cc23fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41849,DS-98df8b4b-9170-4c7b-bab5-b87f071828ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-7c4a45c2-346d-4d49-bdbb-75f3f6bd5010,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-912140230-172.17.0.9-1595646347449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37951,DS-7243fa11-d0cf-4e97-bc0c-18e8cd89654f,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-9ab3b0b6-db7a-49fd-86d9-0bb004e28ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-c70f9dca-9d4c-4475-89f2-93316c03b12c,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-eb16f82e-4d5e-4079-9ae3-5069edce0a60,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-3cb14536-fba2-43ff-94f0-9f5ad83d66d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-97596cdf-1624-4542-a737-4be809cc23fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41849,DS-98df8b4b-9170-4c7b-bab5-b87f071828ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-7c4a45c2-346d-4d49-bdbb-75f3f6bd5010,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1107744161-172.17.0.9-1595646584331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38071,DS-4ba20403-9618-4a04-b801-f9fe4c352bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-d60829fc-4b01-4e56-bad2-f3ba7dd2dc07,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-6bd88278-f594-4a88-a1b2-169aff62729b,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-88de1d79-3e86-440f-986f-2913a3d3eebf,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-c57e5c49-2589-4484-8824-6f531a8dfd20,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-0c136324-a4ac-4605-8102-b08ff1cfa2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34938,DS-a291d3c8-aeba-4ee0-bdc9-dd93c6b76e87,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-91c90c8e-045a-4d2e-9f1e-c9fc923ab451,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1107744161-172.17.0.9-1595646584331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38071,DS-4ba20403-9618-4a04-b801-f9fe4c352bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-d60829fc-4b01-4e56-bad2-f3ba7dd2dc07,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-6bd88278-f594-4a88-a1b2-169aff62729b,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-88de1d79-3e86-440f-986f-2913a3d3eebf,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-c57e5c49-2589-4484-8824-6f531a8dfd20,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-0c136324-a4ac-4605-8102-b08ff1cfa2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34938,DS-a291d3c8-aeba-4ee0-bdc9-dd93c6b76e87,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-91c90c8e-045a-4d2e-9f1e-c9fc923ab451,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1545871545-172.17.0.9-1595646662026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41268,DS-7adc11ae-686e-4cbd-97a3-5941248191b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38720,DS-c22ca6fa-bc9a-480a-b3c1-24f1011a1f37,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-e98dbcfe-9402-4b2b-bd9e-34d78b952684,DISK], DatanodeInfoWithStorage[127.0.0.1:40300,DS-bef541fc-468f-4a34-b478-c235cf8411c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-b0de5a39-f718-4586-9b3a-db85c70d7723,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-0b132057-31ce-45e2-8fe2-831d45c4d83b,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-1468be70-5d65-4d11-93d3-973b1a68a4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35383,DS-9874c6c7-6eff-4cbd-880b-b0569c49e0f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1545871545-172.17.0.9-1595646662026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41268,DS-7adc11ae-686e-4cbd-97a3-5941248191b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38720,DS-c22ca6fa-bc9a-480a-b3c1-24f1011a1f37,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-e98dbcfe-9402-4b2b-bd9e-34d78b952684,DISK], DatanodeInfoWithStorage[127.0.0.1:40300,DS-bef541fc-468f-4a34-b478-c235cf8411c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-b0de5a39-f718-4586-9b3a-db85c70d7723,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-0b132057-31ce-45e2-8fe2-831d45c4d83b,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-1468be70-5d65-4d11-93d3-973b1a68a4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35383,DS-9874c6c7-6eff-4cbd-880b-b0569c49e0f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1557904175-172.17.0.9-1595647015559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45723,DS-283ef2af-94c0-485d-99a5-e8cc4ea90f15,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-43915872-37bd-46c7-9f87-43a4f3078389,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-6b1d055c-537d-4bc4-b5a8-084063f75e38,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-a5f047fd-86fb-43a9-b900-d25003934c13,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-08dded4d-1382-47b7-ae80-8873856ef1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38907,DS-9c40b268-69c9-4008-b03e-ba95819677bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-5e79f0c6-127a-4ea9-962d-1e824be1589e,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-50adbbd1-5eaf-413a-8443-687c07a4ac1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1557904175-172.17.0.9-1595647015559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45723,DS-283ef2af-94c0-485d-99a5-e8cc4ea90f15,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-43915872-37bd-46c7-9f87-43a4f3078389,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-6b1d055c-537d-4bc4-b5a8-084063f75e38,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-a5f047fd-86fb-43a9-b900-d25003934c13,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-08dded4d-1382-47b7-ae80-8873856ef1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38907,DS-9c40b268-69c9-4008-b03e-ba95819677bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-5e79f0c6-127a-4ea9-962d-1e824be1589e,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-50adbbd1-5eaf-413a-8443-687c07a4ac1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1177673217-172.17.0.9-1595647422579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34349,DS-fb35b856-4d1c-40e5-9612-fcf7ca88d423,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-27e51403-6cac-4d3b-964e-c308a1cf018b,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-c467b906-189a-4e09-989e-e92f7fe16882,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-b603904c-1a48-4df5-86aa-27e33ced3d38,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-4eba26b9-84b0-41c4-9e5d-2a79ed70938a,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-1d835d19-b9f9-44bd-a354-7946122eb852,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-15526c5d-15e4-446d-8a2e-3669e5f8337c,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-d8cde303-6ab1-417e-858e-751283888683,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1177673217-172.17.0.9-1595647422579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34349,DS-fb35b856-4d1c-40e5-9612-fcf7ca88d423,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-27e51403-6cac-4d3b-964e-c308a1cf018b,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-c467b906-189a-4e09-989e-e92f7fe16882,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-b603904c-1a48-4df5-86aa-27e33ced3d38,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-4eba26b9-84b0-41c4-9e5d-2a79ed70938a,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-1d835d19-b9f9-44bd-a354-7946122eb852,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-15526c5d-15e4-446d-8a2e-3669e5f8337c,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-d8cde303-6ab1-417e-858e-751283888683,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2046682641-172.17.0.9-1595647784179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44313,DS-9d27b82c-6369-46d1-a4c1-7c0fb7055fee,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-b9a875f9-8694-4c3e-97fb-1fb498153ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-73263016-8a29-4d1c-8ad6-271d3a497ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-84e42bf2-a495-41ea-a859-c4991050e991,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-b8ad5771-efab-4279-96c1-9c194b859277,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-eca00f54-1cab-4782-9a81-4b4096208c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-54135da0-83eb-4f99-add9-9bb60fee8967,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-d8d024d3-29ec-40e7-8b81-163161685855,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2046682641-172.17.0.9-1595647784179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44313,DS-9d27b82c-6369-46d1-a4c1-7c0fb7055fee,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-b9a875f9-8694-4c3e-97fb-1fb498153ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-73263016-8a29-4d1c-8ad6-271d3a497ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-84e42bf2-a495-41ea-a859-c4991050e991,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-b8ad5771-efab-4279-96c1-9c194b859277,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-eca00f54-1cab-4782-9a81-4b4096208c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-54135da0-83eb-4f99-add9-9bb60fee8967,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-d8d024d3-29ec-40e7-8b81-163161685855,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1203240790-172.17.0.9-1595648070539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37428,DS-59791637-a70c-4821-bf58-18932c97fc70,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-bb5a8d67-ded5-4a77-815e-8c869742ccfe,DISK], DatanodeInfoWithStorage[127.0.0.1:42091,DS-6ee04b15-227d-439f-9fa9-659843830c81,DISK], DatanodeInfoWithStorage[127.0.0.1:36108,DS-d9c4100b-ca71-4368-a491-0b12eede239d,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-82628647-a1aa-4a2b-a17b-cb2eadc100d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40072,DS-b706d805-461e-4531-9c92-0b5ce3d8597c,DISK], DatanodeInfoWithStorage[127.0.0.1:42497,DS-fb8d8727-09c3-4fa1-be9a-c3117c678a45,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-3830712d-0838-44e2-96e9-7645758d50f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1203240790-172.17.0.9-1595648070539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37428,DS-59791637-a70c-4821-bf58-18932c97fc70,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-bb5a8d67-ded5-4a77-815e-8c869742ccfe,DISK], DatanodeInfoWithStorage[127.0.0.1:42091,DS-6ee04b15-227d-439f-9fa9-659843830c81,DISK], DatanodeInfoWithStorage[127.0.0.1:36108,DS-d9c4100b-ca71-4368-a491-0b12eede239d,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-82628647-a1aa-4a2b-a17b-cb2eadc100d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40072,DS-b706d805-461e-4531-9c92-0b5ce3d8597c,DISK], DatanodeInfoWithStorage[127.0.0.1:42497,DS-fb8d8727-09c3-4fa1-be9a-c3117c678a45,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-3830712d-0838-44e2-96e9-7645758d50f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-51201404-172.17.0.9-1595648431911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36768,DS-36b76b26-93d6-4b65-ba46-3d4725be5984,DISK], DatanodeInfoWithStorage[127.0.0.1:39221,DS-f31a20de-f06e-4416-9a54-2f81a2d02c70,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-09ad0bde-a2a7-479b-bb61-4c188b16cc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46804,DS-8f7ae212-c228-4bcd-bbb2-e118b79bb204,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-a4a88fe2-8dec-474f-9e4a-93a582b42919,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-06ae3c41-93b4-48fb-85ad-877b63b84bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-4e9c2e00-933c-4923-9e63-487bb5682a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-6a6e3a18-532d-448a-b82b-b5ede863170a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-51201404-172.17.0.9-1595648431911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36768,DS-36b76b26-93d6-4b65-ba46-3d4725be5984,DISK], DatanodeInfoWithStorage[127.0.0.1:39221,DS-f31a20de-f06e-4416-9a54-2f81a2d02c70,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-09ad0bde-a2a7-479b-bb61-4c188b16cc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46804,DS-8f7ae212-c228-4bcd-bbb2-e118b79bb204,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-a4a88fe2-8dec-474f-9e4a-93a582b42919,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-06ae3c41-93b4-48fb-85ad-877b63b84bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-4e9c2e00-933c-4923-9e63-487bb5682a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-6a6e3a18-532d-448a-b82b-b5ede863170a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1613675541-172.17.0.9-1595648726866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33267,DS-9ed116dd-e79d-4d71-899e-d71e0b58e88e,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-44b87c6e-7099-4dfe-91d9-acce76129bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-b279c661-449a-4dcc-a57f-8557a2ca05ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34765,DS-e85621e9-18d0-4f61-b501-e45925af29a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-b825f423-9903-47ce-953b-4cf311ed400f,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-9ca6d785-cf78-469e-9516-e269aa2c412a,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-e78e88a5-28e9-4287-9540-a408d5bfc893,DISK], DatanodeInfoWithStorage[127.0.0.1:43172,DS-f52fd427-ff02-43f9-83a0-5d877081d8e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1613675541-172.17.0.9-1595648726866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33267,DS-9ed116dd-e79d-4d71-899e-d71e0b58e88e,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-44b87c6e-7099-4dfe-91d9-acce76129bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-b279c661-449a-4dcc-a57f-8557a2ca05ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34765,DS-e85621e9-18d0-4f61-b501-e45925af29a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-b825f423-9903-47ce-953b-4cf311ed400f,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-9ca6d785-cf78-469e-9516-e269aa2c412a,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-e78e88a5-28e9-4287-9540-a408d5bfc893,DISK], DatanodeInfoWithStorage[127.0.0.1:43172,DS-f52fd427-ff02-43f9-83a0-5d877081d8e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1916370381-172.17.0.9-1595650638591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39070,DS-6be1dee6-05a4-43d0-999b-43547c952f46,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-1f2612d3-ae76-4863-abd1-31fc3ff52877,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-7545f2db-7e89-45fb-9bef-1798cd9b2324,DISK], DatanodeInfoWithStorage[127.0.0.1:36910,DS-a183bf24-87e9-4e8c-a96e-587918dd05bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-696065de-5282-4c85-bf8f-80231d4dbc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-c65bd408-665b-4c24-b393-115a5a504def,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-efc23c01-515b-433e-a9b5-6fda6f7aabf5,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-ec2da18a-bc14-489e-a0ca-e36a2a76f361,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1916370381-172.17.0.9-1595650638591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39070,DS-6be1dee6-05a4-43d0-999b-43547c952f46,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-1f2612d3-ae76-4863-abd1-31fc3ff52877,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-7545f2db-7e89-45fb-9bef-1798cd9b2324,DISK], DatanodeInfoWithStorage[127.0.0.1:36910,DS-a183bf24-87e9-4e8c-a96e-587918dd05bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-696065de-5282-4c85-bf8f-80231d4dbc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-c65bd408-665b-4c24-b393-115a5a504def,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-efc23c01-515b-433e-a9b5-6fda6f7aabf5,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-ec2da18a-bc14-489e-a0ca-e36a2a76f361,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5576
