reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-316426772-172.17.0.16-1595939264891:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44612,DS-ce45ca28-7005-4ac3-b284-7ad2f2e53862,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-e5da7056-e27c-4160-b13f-3d0a4633ce88,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-4b0e4c7c-8844-41c1-8242-9ebe5e45265e,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-2273f3d6-6522-4cf0-8d95-ddd233ca8dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-c2f976f3-d2a1-4658-ab12-55af6d6d28f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-8d3b7328-6c36-439f-93c8-0bdf71b0e3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-6aa13738-8d91-45da-b57c-0bde97a6ed3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-822c5860-c03d-4cf3-8de1-f11e785db3fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-316426772-172.17.0.16-1595939264891:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44612,DS-ce45ca28-7005-4ac3-b284-7ad2f2e53862,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-e5da7056-e27c-4160-b13f-3d0a4633ce88,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-4b0e4c7c-8844-41c1-8242-9ebe5e45265e,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-2273f3d6-6522-4cf0-8d95-ddd233ca8dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-c2f976f3-d2a1-4658-ab12-55af6d6d28f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-8d3b7328-6c36-439f-93c8-0bdf71b0e3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-6aa13738-8d91-45da-b57c-0bde97a6ed3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-822c5860-c03d-4cf3-8de1-f11e785db3fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-249734169-172.17.0.16-1595939686636:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41615,DS-7b559099-fa99-4b28-bb49-7cf42a1e77ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-e6cc4899-157b-4710-8826-83e146a034b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43390,DS-a27194b9-570e-4090-868c-994ab54f3c61,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-d343785a-571b-499e-a7cb-ac00f73ab28c,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-3f755976-96ce-44d5-b94d-e9dc5126c468,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-bc7ae914-40bb-41e8-8c31-8575cbd5583e,DISK], DatanodeInfoWithStorage[127.0.0.1:39500,DS-4859bba1-3fd7-4512-9605-30f2579857d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-350d601b-c286-47b0-ba09-13b308053679,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-249734169-172.17.0.16-1595939686636:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41615,DS-7b559099-fa99-4b28-bb49-7cf42a1e77ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-e6cc4899-157b-4710-8826-83e146a034b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43390,DS-a27194b9-570e-4090-868c-994ab54f3c61,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-d343785a-571b-499e-a7cb-ac00f73ab28c,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-3f755976-96ce-44d5-b94d-e9dc5126c468,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-bc7ae914-40bb-41e8-8c31-8575cbd5583e,DISK], DatanodeInfoWithStorage[127.0.0.1:39500,DS-4859bba1-3fd7-4512-9605-30f2579857d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-350d601b-c286-47b0-ba09-13b308053679,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-468673187-172.17.0.16-1595939804141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37784,DS-ca60d4e8-6de5-449f-ac49-6dfd1d7bcf79,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-1727cf6b-ad34-4463-b46c-b7c06133a0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-e75ed15f-8e71-4c5a-ad00-71af5ff13e35,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-0f110c65-76cb-4a6b-a57e-3976c394d69c,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-bc78fc1a-279d-4990-9d5c-d38bb52c5d86,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-a38a2d61-bdaa-43c6-9858-95424990ad61,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-18524b44-cbdb-4151-996a-c4bbb7f9da2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-8165f88a-6d37-4133-8652-60305515b2ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-468673187-172.17.0.16-1595939804141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37784,DS-ca60d4e8-6de5-449f-ac49-6dfd1d7bcf79,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-1727cf6b-ad34-4463-b46c-b7c06133a0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-e75ed15f-8e71-4c5a-ad00-71af5ff13e35,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-0f110c65-76cb-4a6b-a57e-3976c394d69c,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-bc78fc1a-279d-4990-9d5c-d38bb52c5d86,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-a38a2d61-bdaa-43c6-9858-95424990ad61,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-18524b44-cbdb-4151-996a-c4bbb7f9da2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-8165f88a-6d37-4133-8652-60305515b2ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-573137109-172.17.0.16-1595939841007:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38425,DS-a5fb61f2-673f-4d51-b800-00d7f8f38a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-c76582e6-93ff-47fe-9d5c-52e0e259564a,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-2ce30693-2bf8-4134-95bd-0b2b7b9aba71,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-f9570ec3-8065-42fe-8a42-a85c5dd0852c,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-479e4be3-e0a4-4e9a-b00c-1e2058815cde,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-e0857776-38aa-41fe-915a-3170e27ed04a,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-79398655-cb96-49de-bb82-9bf135d7a379,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-8a5d1427-7b3c-4ad8-8e3b-4d59b01e3b30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-573137109-172.17.0.16-1595939841007:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38425,DS-a5fb61f2-673f-4d51-b800-00d7f8f38a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-c76582e6-93ff-47fe-9d5c-52e0e259564a,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-2ce30693-2bf8-4134-95bd-0b2b7b9aba71,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-f9570ec3-8065-42fe-8a42-a85c5dd0852c,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-479e4be3-e0a4-4e9a-b00c-1e2058815cde,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-e0857776-38aa-41fe-915a-3170e27ed04a,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-79398655-cb96-49de-bb82-9bf135d7a379,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-8a5d1427-7b3c-4ad8-8e3b-4d59b01e3b30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1159414327-172.17.0.16-1595940543068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43417,DS-1a3d9fdf-651a-4e67-92e6-a91eac10c70e,DISK], DatanodeInfoWithStorage[127.0.0.1:42679,DS-8b4f8202-71fa-48ec-ad40-518c4ed9dfc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-2c03f78d-23de-42c1-8c40-f86d88c88378,DISK], DatanodeInfoWithStorage[127.0.0.1:46483,DS-c01e4383-9168-4c1e-9bfa-61742bdfbb20,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-e3a0a885-6bb2-458c-98fc-5069ae38136f,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-0aa952f4-f2e2-42be-a7b4-5de6cc230868,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-25388c22-1095-4c32-b771-6102fea9110b,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-9bdd0ef4-20ce-487c-bb1b-2c4d01b7a0b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1159414327-172.17.0.16-1595940543068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43417,DS-1a3d9fdf-651a-4e67-92e6-a91eac10c70e,DISK], DatanodeInfoWithStorage[127.0.0.1:42679,DS-8b4f8202-71fa-48ec-ad40-518c4ed9dfc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-2c03f78d-23de-42c1-8c40-f86d88c88378,DISK], DatanodeInfoWithStorage[127.0.0.1:46483,DS-c01e4383-9168-4c1e-9bfa-61742bdfbb20,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-e3a0a885-6bb2-458c-98fc-5069ae38136f,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-0aa952f4-f2e2-42be-a7b4-5de6cc230868,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-25388c22-1095-4c32-b771-6102fea9110b,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-9bdd0ef4-20ce-487c-bb1b-2c4d01b7a0b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1710480981-172.17.0.16-1595941100043:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35136,DS-cff24f62-2884-4b08-9900-48ad75c6876b,DISK], DatanodeInfoWithStorage[127.0.0.1:46223,DS-c025092e-75e5-4217-8f6a-59a8e276f173,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-6d6fdd83-7b97-4725-99ce-936783b4beb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-1ba65fe6-1e50-4901-aa28-d6e00c7173f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33755,DS-a9e7ab8d-5252-42c9-b196-aed81a461df6,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-f31b763b-cf9a-493c-a5a0-2af341dc70fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-edffa934-5494-4750-be03-b529b617f66b,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-c64867de-8210-42c9-bb29-90149ccb33e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1710480981-172.17.0.16-1595941100043:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35136,DS-cff24f62-2884-4b08-9900-48ad75c6876b,DISK], DatanodeInfoWithStorage[127.0.0.1:46223,DS-c025092e-75e5-4217-8f6a-59a8e276f173,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-6d6fdd83-7b97-4725-99ce-936783b4beb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-1ba65fe6-1e50-4901-aa28-d6e00c7173f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33755,DS-a9e7ab8d-5252-42c9-b196-aed81a461df6,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-f31b763b-cf9a-493c-a5a0-2af341dc70fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-edffa934-5494-4750-be03-b529b617f66b,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-c64867de-8210-42c9-bb29-90149ccb33e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1499629976-172.17.0.16-1595941332022:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45182,DS-a9d2e539-7ea9-4f40-83ad-de6506bfdc00,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-91ae98e7-7423-4994-b130-f74e22ae9dac,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-52931aea-a4d1-43e5-9bea-456e38cfcad5,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-be0aaf76-b6e7-44f5-853b-a414fb0175e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45646,DS-2906b766-b698-421e-a3ff-35b1e9aca4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-6e814942-6190-475d-a982-6f28c5d4979c,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-abb56955-0572-4188-89e9-8f356967bf3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-13a870c1-ef31-45ea-8150-d26d371d32bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1499629976-172.17.0.16-1595941332022:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45182,DS-a9d2e539-7ea9-4f40-83ad-de6506bfdc00,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-91ae98e7-7423-4994-b130-f74e22ae9dac,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-52931aea-a4d1-43e5-9bea-456e38cfcad5,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-be0aaf76-b6e7-44f5-853b-a414fb0175e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45646,DS-2906b766-b698-421e-a3ff-35b1e9aca4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-6e814942-6190-475d-a982-6f28c5d4979c,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-abb56955-0572-4188-89e9-8f356967bf3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-13a870c1-ef31-45ea-8150-d26d371d32bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1232938655-172.17.0.16-1595941947953:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40983,DS-bde65e5c-a5e4-4961-997e-3182c8b68a21,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-a5ea2c2d-996e-41ab-9703-7af5ea793749,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-66db454a-7a4b-47d4-8c8f-61e186d4be61,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-e549e5d6-09c7-4c1c-aeaf-d5938b605837,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-db5a4450-4c4d-436b-8942-9912b56c5168,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-1297a9c4-d8a5-4231-848e-431e18d2bbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-14baf5c8-705a-4b76-95f2-9286c2d63b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-6434495a-abc0-45b7-90cc-2e2b3836ddcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1232938655-172.17.0.16-1595941947953:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40983,DS-bde65e5c-a5e4-4961-997e-3182c8b68a21,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-a5ea2c2d-996e-41ab-9703-7af5ea793749,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-66db454a-7a4b-47d4-8c8f-61e186d4be61,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-e549e5d6-09c7-4c1c-aeaf-d5938b605837,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-db5a4450-4c4d-436b-8942-9912b56c5168,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-1297a9c4-d8a5-4231-848e-431e18d2bbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-14baf5c8-705a-4b76-95f2-9286c2d63b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-6434495a-abc0-45b7-90cc-2e2b3836ddcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-943990270-172.17.0.16-1595943027054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36122,DS-df256a73-a591-46ae-8fbf-90f6f04b5a40,DISK], DatanodeInfoWithStorage[127.0.0.1:41083,DS-2ee17335-ef94-4d01-b0e5-eea3e3e9bcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42693,DS-e850bdf8-4bc9-40a7-a02e-96278a0ccf67,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-5e16a8d0-3e5d-47a8-8d85-c4549a0513af,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-d658ea4c-557c-4646-9235-6ae986e37029,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-8b4db805-b45c-418f-8fd9-200619e86678,DISK], DatanodeInfoWithStorage[127.0.0.1:44268,DS-0a4f1e75-cd6a-4404-bb99-95862a469519,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-bebb3aa4-470e-4b12-a15b-fc045d67d00b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-943990270-172.17.0.16-1595943027054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36122,DS-df256a73-a591-46ae-8fbf-90f6f04b5a40,DISK], DatanodeInfoWithStorage[127.0.0.1:41083,DS-2ee17335-ef94-4d01-b0e5-eea3e3e9bcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42693,DS-e850bdf8-4bc9-40a7-a02e-96278a0ccf67,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-5e16a8d0-3e5d-47a8-8d85-c4549a0513af,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-d658ea4c-557c-4646-9235-6ae986e37029,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-8b4db805-b45c-418f-8fd9-200619e86678,DISK], DatanodeInfoWithStorage[127.0.0.1:44268,DS-0a4f1e75-cd6a-4404-bb99-95862a469519,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-bebb3aa4-470e-4b12-a15b-fc045d67d00b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-369756707-172.17.0.16-1595943320363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43166,DS-52005d6c-9f8f-48f6-9051-bfe8244d64f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-86a0aecd-746a-43b8-bc7a-87b43071f204,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-5497e9ac-03e5-4b5b-b1a7-3e6a93a80805,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-242861c9-5838-4603-af5c-2f25b7e3e547,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-145b4a86-2b0b-4856-a590-3b0c1dc6108a,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-620e5868-5aae-488c-8a36-c239c0c7c728,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-1042b597-5a62-4f0d-b1e6-5234ae0b49f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37352,DS-5712f5ae-2192-4856-8062-4cfafa3bd932,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-369756707-172.17.0.16-1595943320363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43166,DS-52005d6c-9f8f-48f6-9051-bfe8244d64f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-86a0aecd-746a-43b8-bc7a-87b43071f204,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-5497e9ac-03e5-4b5b-b1a7-3e6a93a80805,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-242861c9-5838-4603-af5c-2f25b7e3e547,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-145b4a86-2b0b-4856-a590-3b0c1dc6108a,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-620e5868-5aae-488c-8a36-c239c0c7c728,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-1042b597-5a62-4f0d-b1e6-5234ae0b49f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37352,DS-5712f5ae-2192-4856-8062-4cfafa3bd932,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-915463592-172.17.0.16-1595943637605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40932,DS-420d46cf-dfbe-4ce1-9d97-9fcd1485172c,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-867cc8a7-86ea-41f7-9b28-4f8951499c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-a012427c-263a-4035-b9f3-3c9ee6e4a411,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-9b420da1-e6af-4b79-a2f6-9b2dde3b6080,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-5fae96bd-3713-4779-ad65-6de2b91c8eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-8ff6c98f-3cb1-425c-82e8-313ddaeaf1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-574ae62d-1d82-453d-8d71-12e8505b240b,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-059a8678-7c53-499c-bf90-8c730f3a532c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-915463592-172.17.0.16-1595943637605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40932,DS-420d46cf-dfbe-4ce1-9d97-9fcd1485172c,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-867cc8a7-86ea-41f7-9b28-4f8951499c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-a012427c-263a-4035-b9f3-3c9ee6e4a411,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-9b420da1-e6af-4b79-a2f6-9b2dde3b6080,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-5fae96bd-3713-4779-ad65-6de2b91c8eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-8ff6c98f-3cb1-425c-82e8-313ddaeaf1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-574ae62d-1d82-453d-8d71-12e8505b240b,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-059a8678-7c53-499c-bf90-8c730f3a532c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-174289024-172.17.0.16-1595943705331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44796,DS-61a9bab0-46d0-4c09-afc5-2ecb86dad30a,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-b0c1ed21-9827-4ed8-a140-8d55bdeb27b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-76f52de5-03b3-449c-86a4-265574397be9,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-ecff9b5a-909a-434b-9b49-f0bb6b0a0bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-69e4f325-a4a2-4eaf-a7a8-3cdbef01d13c,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-856f0544-173c-4ce8-bcaa-b565a045667c,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-4ab0981a-9f6c-4b76-ba6f-b64f2f59c731,DISK], DatanodeInfoWithStorage[127.0.0.1:40172,DS-a92e7479-a3ee-4377-85be-b9992445b1c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-174289024-172.17.0.16-1595943705331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44796,DS-61a9bab0-46d0-4c09-afc5-2ecb86dad30a,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-b0c1ed21-9827-4ed8-a140-8d55bdeb27b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-76f52de5-03b3-449c-86a4-265574397be9,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-ecff9b5a-909a-434b-9b49-f0bb6b0a0bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-69e4f325-a4a2-4eaf-a7a8-3cdbef01d13c,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-856f0544-173c-4ce8-bcaa-b565a045667c,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-4ab0981a-9f6c-4b76-ba6f-b64f2f59c731,DISK], DatanodeInfoWithStorage[127.0.0.1:40172,DS-a92e7479-a3ee-4377-85be-b9992445b1c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: might be true error
Total execution time in seconds : 5765
