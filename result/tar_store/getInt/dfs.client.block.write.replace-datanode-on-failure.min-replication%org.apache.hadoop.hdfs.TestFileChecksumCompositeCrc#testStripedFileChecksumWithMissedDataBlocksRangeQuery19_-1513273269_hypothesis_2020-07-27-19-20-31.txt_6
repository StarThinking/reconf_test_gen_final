reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-970652451-172.17.0.7-1595878216874:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37276,DS-d9b15974-6966-43d2-85c3-a90c9dd1134c,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-d2904dae-82a2-46ba-b71e-e6fac1b6297a,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-21d54f4d-88db-46ba-a00f-5e5d7e8d6eae,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-43306b4e-a21b-4b38-a7ca-d37b35d5c919,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-e990d98f-5d06-4ab9-9b0f-402f80fca930,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-d8af75b1-0e94-4cc7-a846-9222fba54130,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-c49375b2-4cfa-46d0-8fd7-646da72e5c07,DISK], DatanodeInfoWithStorage[127.0.0.1:37810,DS-93cce44a-0988-44c6-ac7f-d8a76e4eac3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-970652451-172.17.0.7-1595878216874:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37276,DS-d9b15974-6966-43d2-85c3-a90c9dd1134c,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-d2904dae-82a2-46ba-b71e-e6fac1b6297a,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-21d54f4d-88db-46ba-a00f-5e5d7e8d6eae,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-43306b4e-a21b-4b38-a7ca-d37b35d5c919,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-e990d98f-5d06-4ab9-9b0f-402f80fca930,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-d8af75b1-0e94-4cc7-a846-9222fba54130,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-c49375b2-4cfa-46d0-8fd7-646da72e5c07,DISK], DatanodeInfoWithStorage[127.0.0.1:37810,DS-93cce44a-0988-44c6-ac7f-d8a76e4eac3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-870584738-172.17.0.7-1595878531963:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38451,DS-08244249-c5fa-4c34-aade-91d86e447f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-0082dbfc-c073-4007-9c29-2559109dc614,DISK], DatanodeInfoWithStorage[127.0.0.1:34329,DS-e67ad895-360e-48a5-bd1f-f06c05601c93,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-4d7905d9-937d-47ee-979a-73c03168a305,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-a4d9f9e9-83cc-4085-9437-524b933fea3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46757,DS-6a7b83c0-4cd9-4c52-8b70-5779e98dc25d,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-f5b1ee4b-e688-4140-ac3f-3f5840cc0f92,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-db78ec20-0e79-4a6f-8e0a-064f6ec807a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-870584738-172.17.0.7-1595878531963:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38451,DS-08244249-c5fa-4c34-aade-91d86e447f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-0082dbfc-c073-4007-9c29-2559109dc614,DISK], DatanodeInfoWithStorage[127.0.0.1:34329,DS-e67ad895-360e-48a5-bd1f-f06c05601c93,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-4d7905d9-937d-47ee-979a-73c03168a305,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-a4d9f9e9-83cc-4085-9437-524b933fea3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46757,DS-6a7b83c0-4cd9-4c52-8b70-5779e98dc25d,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-f5b1ee4b-e688-4140-ac3f-3f5840cc0f92,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-db78ec20-0e79-4a6f-8e0a-064f6ec807a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-54543821-172.17.0.7-1595878601328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43178,DS-2e2939c8-8ba2-449a-bac0-27ef1aebd833,DISK], DatanodeInfoWithStorage[127.0.0.1:46849,DS-1d010bf8-c64d-44cb-9dd8-38aefac2c0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-c2a78919-6aea-4c3b-b6a9-c49404e637a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-38ce1164-9b3a-4c64-bda3-86697bac89b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-1936f1bb-69d9-402a-b9c5-9c9fd0145e72,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-15aeab4a-ce0a-4721-a5a3-1406bfde4dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-4134c49c-359f-4381-8eea-e438ea49cbfb,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-13ad6a55-c892-478e-a18d-b0b61332e8ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-54543821-172.17.0.7-1595878601328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43178,DS-2e2939c8-8ba2-449a-bac0-27ef1aebd833,DISK], DatanodeInfoWithStorage[127.0.0.1:46849,DS-1d010bf8-c64d-44cb-9dd8-38aefac2c0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-c2a78919-6aea-4c3b-b6a9-c49404e637a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-38ce1164-9b3a-4c64-bda3-86697bac89b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-1936f1bb-69d9-402a-b9c5-9c9fd0145e72,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-15aeab4a-ce0a-4721-a5a3-1406bfde4dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-4134c49c-359f-4381-8eea-e438ea49cbfb,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-13ad6a55-c892-478e-a18d-b0b61332e8ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1856855638-172.17.0.7-1595878707024:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45604,DS-65729942-6e0d-4d6b-95e9-eddf1f59e3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38009,DS-de6c8cb2-b5ea-4074-9e67-04803e94d180,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-26505ad8-c540-453d-ba88-40e54b887b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-b1b8fd8c-c3f6-4423-8101-3ec02d3daf7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-7474487e-8713-490f-aa37-a6818852d1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-f270971e-9079-4d3a-a9a2-53177c1dd39c,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-3a444f72-fd46-4282-8c2d-ec428cfcea3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-25f4524b-baee-453d-b69e-57219f0dcbc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1856855638-172.17.0.7-1595878707024:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45604,DS-65729942-6e0d-4d6b-95e9-eddf1f59e3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38009,DS-de6c8cb2-b5ea-4074-9e67-04803e94d180,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-26505ad8-c540-453d-ba88-40e54b887b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-b1b8fd8c-c3f6-4423-8101-3ec02d3daf7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-7474487e-8713-490f-aa37-a6818852d1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-f270971e-9079-4d3a-a9a2-53177c1dd39c,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-3a444f72-fd46-4282-8c2d-ec428cfcea3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-25f4524b-baee-453d-b69e-57219f0dcbc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-54807376-172.17.0.7-1595878739347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36797,DS-dd4afd26-f8df-4f3b-8bc8-c7dee76f8055,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-40c00ed8-2285-45cb-9fec-34e1683eee63,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-c47746de-011a-41db-8403-659ffa64f593,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-3beb0d45-1c87-475d-aaab-4fad4be5b6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-323c802a-fbe8-4507-a990-00aa22d1c2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-7329e648-7d93-4b46-8580-33a7ef330bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-269b5909-a60d-4b0f-80c3-2e4903dcd457,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-3e1755bd-d915-401d-8a4d-8c4f7ef38926,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-54807376-172.17.0.7-1595878739347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36797,DS-dd4afd26-f8df-4f3b-8bc8-c7dee76f8055,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-40c00ed8-2285-45cb-9fec-34e1683eee63,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-c47746de-011a-41db-8403-659ffa64f593,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-3beb0d45-1c87-475d-aaab-4fad4be5b6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-323c802a-fbe8-4507-a990-00aa22d1c2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-7329e648-7d93-4b46-8580-33a7ef330bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-269b5909-a60d-4b0f-80c3-2e4903dcd457,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-3e1755bd-d915-401d-8a4d-8c4f7ef38926,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-930376707-172.17.0.7-1595879254134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33415,DS-0b4d8cb5-741b-4eaa-b5d5-e137366f580c,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-c606f827-320c-4652-a78c-db9e0c0b7e29,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-f07c102d-1bb0-4bba-be00-8f3b20db1669,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-20cef86f-270b-42ac-9979-c22e01a47d88,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-191afe72-9577-4971-83cd-1fb483864d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-f22550f7-40f8-434f-b55f-368147b4f7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-11f7a177-45b4-4a95-acf6-cd3be8cafc6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45969,DS-ee1f0a49-e8fa-4d7e-bc3f-954a2ee6147b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-930376707-172.17.0.7-1595879254134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33415,DS-0b4d8cb5-741b-4eaa-b5d5-e137366f580c,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-c606f827-320c-4652-a78c-db9e0c0b7e29,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-f07c102d-1bb0-4bba-be00-8f3b20db1669,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-20cef86f-270b-42ac-9979-c22e01a47d88,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-191afe72-9577-4971-83cd-1fb483864d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-f22550f7-40f8-434f-b55f-368147b4f7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-11f7a177-45b4-4a95-acf6-cd3be8cafc6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45969,DS-ee1f0a49-e8fa-4d7e-bc3f-954a2ee6147b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-653867944-172.17.0.7-1595880046665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43090,DS-38b75c2c-3c07-4d65-9eaa-dbf2a642700b,DISK], DatanodeInfoWithStorage[127.0.0.1:34973,DS-c6f0c950-efc0-4723-8650-d63cd6b47115,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-67831418-8c67-4ee3-85e6-8257098da5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-736d5dc8-65df-4df7-970d-030a687127e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-52855fee-106e-4d22-a62c-441b33c38f18,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-d5b15d08-54c3-4408-99af-f24cb40eecc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-417c8c7a-8545-4000-9e08-793c4369dc00,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-0996d6bc-8fb6-446d-996e-57491e99bad0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-653867944-172.17.0.7-1595880046665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43090,DS-38b75c2c-3c07-4d65-9eaa-dbf2a642700b,DISK], DatanodeInfoWithStorage[127.0.0.1:34973,DS-c6f0c950-efc0-4723-8650-d63cd6b47115,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-67831418-8c67-4ee3-85e6-8257098da5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-736d5dc8-65df-4df7-970d-030a687127e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-52855fee-106e-4d22-a62c-441b33c38f18,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-d5b15d08-54c3-4408-99af-f24cb40eecc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-417c8c7a-8545-4000-9e08-793c4369dc00,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-0996d6bc-8fb6-446d-996e-57491e99bad0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-4525623-172.17.0.7-1595880316955:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35165,DS-8a5d1ed3-6679-4518-b245-889b19e207c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45207,DS-e5c37c5d-7085-47a1-bd5f-04474d0d0fab,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-2d8f61c0-9435-45de-a6b7-1607434996e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-a3fc844b-3573-43c6-9e57-f9d405dd1465,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-a14a3409-c57b-4c35-9927-3c3df89b4c71,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-06e5bf8f-99b1-43c1-b7f6-63e9dce56685,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-8de5ddea-df43-443f-9c10-872bb52c5b14,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-0f971e85-9fe8-47f1-b208-44793c191f2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-4525623-172.17.0.7-1595880316955:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35165,DS-8a5d1ed3-6679-4518-b245-889b19e207c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45207,DS-e5c37c5d-7085-47a1-bd5f-04474d0d0fab,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-2d8f61c0-9435-45de-a6b7-1607434996e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-a3fc844b-3573-43c6-9e57-f9d405dd1465,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-a14a3409-c57b-4c35-9927-3c3df89b4c71,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-06e5bf8f-99b1-43c1-b7f6-63e9dce56685,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-8de5ddea-df43-443f-9c10-872bb52c5b14,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-0f971e85-9fe8-47f1-b208-44793c191f2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-133914584-172.17.0.7-1595881189621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39484,DS-baa3077c-ab4c-4af1-8cc3-f5dc68de20e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-2e695ce4-7501-46d9-b572-1640db1a0f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-3e347965-856f-44bc-a1c6-a3bca58e12b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41733,DS-8bb1cf30-3187-4f0a-9b81-04a3ff2db033,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-361df252-14f3-43c8-bb77-e131d806b673,DISK], DatanodeInfoWithStorage[127.0.0.1:43927,DS-36fb1cb1-29fe-4317-a746-051919625097,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-6828bb54-e2e6-4943-ab85-9ae9cf593a16,DISK], DatanodeInfoWithStorage[127.0.0.1:37755,DS-607aec9c-02b2-4ee3-98ee-f04a4682971e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-133914584-172.17.0.7-1595881189621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39484,DS-baa3077c-ab4c-4af1-8cc3-f5dc68de20e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-2e695ce4-7501-46d9-b572-1640db1a0f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-3e347965-856f-44bc-a1c6-a3bca58e12b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41733,DS-8bb1cf30-3187-4f0a-9b81-04a3ff2db033,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-361df252-14f3-43c8-bb77-e131d806b673,DISK], DatanodeInfoWithStorage[127.0.0.1:43927,DS-36fb1cb1-29fe-4317-a746-051919625097,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-6828bb54-e2e6-4943-ab85-9ae9cf593a16,DISK], DatanodeInfoWithStorage[127.0.0.1:37755,DS-607aec9c-02b2-4ee3-98ee-f04a4682971e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-801611160-172.17.0.7-1595881236495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43266,DS-173f6a59-3f68-4be4-9432-bc9508a26da3,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-f30bdd84-f641-474f-809c-d81eda911482,DISK], DatanodeInfoWithStorage[127.0.0.1:34246,DS-be2654b8-795c-4fc4-831b-2414b139639b,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-00f662f0-27e9-4d60-b00e-6bc4c5247663,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-1f636b06-7dcf-4ec2-b6cf-11c8594b86ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-39ca7d4e-6150-4acd-9848-a67eb4ffb7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-95dfb8e0-6d34-484a-a029-95b67cf9118d,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-0201656f-ee60-4066-a8a4-b1b85adc17a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-801611160-172.17.0.7-1595881236495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43266,DS-173f6a59-3f68-4be4-9432-bc9508a26da3,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-f30bdd84-f641-474f-809c-d81eda911482,DISK], DatanodeInfoWithStorage[127.0.0.1:34246,DS-be2654b8-795c-4fc4-831b-2414b139639b,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-00f662f0-27e9-4d60-b00e-6bc4c5247663,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-1f636b06-7dcf-4ec2-b6cf-11c8594b86ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-39ca7d4e-6150-4acd-9848-a67eb4ffb7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-95dfb8e0-6d34-484a-a029-95b67cf9118d,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-0201656f-ee60-4066-a8a4-b1b85adc17a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-90890045-172.17.0.7-1595881277174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36165,DS-39c7c4ba-579c-4a68-96d1-f42a9624cf83,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-a50e1aa0-3328-4085-9c4c-16bc02c88f47,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-03202091-a633-4544-827c-4ebdb0bc2d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-44a40f79-cb1b-4b9f-a3f3-8625a669c336,DISK], DatanodeInfoWithStorage[127.0.0.1:38806,DS-d7eaeb11-9e58-481c-a644-cd541fab37a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-a923f386-07aa-4a1c-a680-3ce7727e75a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-c3fb81e8-1039-4d2d-bab1-ca8fae4855e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-3f2e6814-86dc-4c66-880b-53a280cf5407,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-90890045-172.17.0.7-1595881277174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36165,DS-39c7c4ba-579c-4a68-96d1-f42a9624cf83,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-a50e1aa0-3328-4085-9c4c-16bc02c88f47,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-03202091-a633-4544-827c-4ebdb0bc2d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-44a40f79-cb1b-4b9f-a3f3-8625a669c336,DISK], DatanodeInfoWithStorage[127.0.0.1:38806,DS-d7eaeb11-9e58-481c-a644-cd541fab37a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-a923f386-07aa-4a1c-a680-3ce7727e75a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-c3fb81e8-1039-4d2d-bab1-ca8fae4855e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-3f2e6814-86dc-4c66-880b-53a280cf5407,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1712564418-172.17.0.7-1595881407187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34370,DS-5cfaaea5-daf1-4fba-801e-3bed8f23dcef,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-a9e72356-088d-423d-b24a-a72154bbda08,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-152da3d2-ffe9-495c-a717-1d20214691db,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-3a2e1f8f-d9d1-4f84-9ff9-4e438cd4a182,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-9c40d136-4eb8-4faa-a3b5-53ef598e69e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-44f60133-981a-4872-8e2c-fd44c5ab0d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-e4019ac6-13ef-4c44-a517-f419b55db80d,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-3ee45854-8783-4b42-9231-45c7c254ab9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1712564418-172.17.0.7-1595881407187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34370,DS-5cfaaea5-daf1-4fba-801e-3bed8f23dcef,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-a9e72356-088d-423d-b24a-a72154bbda08,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-152da3d2-ffe9-495c-a717-1d20214691db,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-3a2e1f8f-d9d1-4f84-9ff9-4e438cd4a182,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-9c40d136-4eb8-4faa-a3b5-53ef598e69e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-44f60133-981a-4872-8e2c-fd44c5ab0d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-e4019ac6-13ef-4c44-a517-f419b55db80d,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-3ee45854-8783-4b42-9231-45c7c254ab9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1335992014-172.17.0.7-1595881578863:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44717,DS-0f9799ab-2f33-4aca-8d97-15415b8417d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-c58d2994-eb5b-4388-9712-7e100ca1bd84,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-ddda4167-ed38-4674-a8d3-d447b09a028a,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-3945604d-a628-486a-9341-25348621e60a,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-4801abac-43cf-4cbc-972b-ea6c8c4c71e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39904,DS-9bf393d4-f30c-42a0-9a76-a3d662c9b771,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-518455fe-d6cc-43c1-a0ae-09fb088d6047,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-dd46bd94-74c4-46a5-8fed-71ad91799f69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1335992014-172.17.0.7-1595881578863:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44717,DS-0f9799ab-2f33-4aca-8d97-15415b8417d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-c58d2994-eb5b-4388-9712-7e100ca1bd84,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-ddda4167-ed38-4674-a8d3-d447b09a028a,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-3945604d-a628-486a-9341-25348621e60a,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-4801abac-43cf-4cbc-972b-ea6c8c4c71e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39904,DS-9bf393d4-f30c-42a0-9a76-a3d662c9b771,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-518455fe-d6cc-43c1-a0ae-09fb088d6047,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-dd46bd94-74c4-46a5-8fed-71ad91799f69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1749088150-172.17.0.7-1595881646771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37926,DS-3c9d900f-d990-4758-b3b5-2239d9cfdd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-4ea2c9f0-c320-4461-bc06-a4685d52a41f,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-8908db52-7e75-42ac-8431-6960ece2f4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44434,DS-bcd5f9aa-182d-4943-9e51-1c892bf8e7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-05e5a1bf-0d93-487b-b746-c01ed315ee65,DISK], DatanodeInfoWithStorage[127.0.0.1:43457,DS-cbdee88c-5419-4f29-805a-fbc32d10b8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-8f21a8d2-2ea2-4bed-ac22-8eb358ff70e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-f98babaa-0cfe-4449-8527-b15074cb1ff4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1749088150-172.17.0.7-1595881646771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37926,DS-3c9d900f-d990-4758-b3b5-2239d9cfdd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-4ea2c9f0-c320-4461-bc06-a4685d52a41f,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-8908db52-7e75-42ac-8431-6960ece2f4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44434,DS-bcd5f9aa-182d-4943-9e51-1c892bf8e7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-05e5a1bf-0d93-487b-b746-c01ed315ee65,DISK], DatanodeInfoWithStorage[127.0.0.1:43457,DS-cbdee88c-5419-4f29-805a-fbc32d10b8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-8f21a8d2-2ea2-4bed-ac22-8eb358ff70e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-f98babaa-0cfe-4449-8527-b15074cb1ff4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-362653149-172.17.0.7-1595881814775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35531,DS-32d3edf1-f0b1-4022-a6f8-1e177cc8b4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-252468a3-76bb-4e57-9a14-8406078eb73e,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-d3dbc27d-1f59-4422-868d-deab63951c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-01f19744-872a-48a2-be29-7f4ad22d336a,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-41052093-a5e9-451c-96b4-ed8ec8999a72,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-acdc1ec1-4eaa-4237-88b6-0e064099b32f,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-b05e1942-9c26-4c5f-ad6c-738719a0bcc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36596,DS-a9ca83e1-7a1f-4e9c-adf1-09e16762e997,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-362653149-172.17.0.7-1595881814775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35531,DS-32d3edf1-f0b1-4022-a6f8-1e177cc8b4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-252468a3-76bb-4e57-9a14-8406078eb73e,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-d3dbc27d-1f59-4422-868d-deab63951c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-01f19744-872a-48a2-be29-7f4ad22d336a,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-41052093-a5e9-451c-96b4-ed8ec8999a72,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-acdc1ec1-4eaa-4237-88b6-0e064099b32f,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-b05e1942-9c26-4c5f-ad6c-738719a0bcc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36596,DS-a9ca83e1-7a1f-4e9c-adf1-09e16762e997,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-939623839-172.17.0.7-1595882417709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33585,DS-4b86c5f0-4a33-4fb5-880e-0d95ae125576,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-29abf413-8d33-469f-a730-37f1988bec54,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-0faaf8d7-7bb8-4108-b283-fc3310336da0,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-bdff5874-4f6b-46f1-99c3-239cd4fea808,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-4970131e-7060-452a-9480-607785708f07,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-39aac4a3-3a86-4627-9f90-c13543149e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39386,DS-a642ece1-4ac4-4b30-9d7d-a459071012ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-6677e12a-48de-4ba8-ad2a-c5ccd1a80ba2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-939623839-172.17.0.7-1595882417709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33585,DS-4b86c5f0-4a33-4fb5-880e-0d95ae125576,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-29abf413-8d33-469f-a730-37f1988bec54,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-0faaf8d7-7bb8-4108-b283-fc3310336da0,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-bdff5874-4f6b-46f1-99c3-239cd4fea808,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-4970131e-7060-452a-9480-607785708f07,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-39aac4a3-3a86-4627-9f90-c13543149e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39386,DS-a642ece1-4ac4-4b30-9d7d-a459071012ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-6677e12a-48de-4ba8-ad2a-c5ccd1a80ba2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1119459708-172.17.0.7-1595882956951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37763,DS-3d0fddb1-1e1c-49c9-8af0-8fd0177645a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-9a246ae2-2900-4abc-91e9-73cc440f67ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-863de7f5-8a38-4db3-9fc0-c6fedf7628be,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-19550be5-f48c-4906-bac9-8a6d5744989c,DISK], DatanodeInfoWithStorage[127.0.0.1:33142,DS-f86e52eb-5d98-44d3-896c-d50384f57ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-1a902de4-e688-465d-bd30-a8c56330142a,DISK], DatanodeInfoWithStorage[127.0.0.1:44600,DS-1e287599-b9d8-4f5d-8329-aabc8e592767,DISK], DatanodeInfoWithStorage[127.0.0.1:42570,DS-8970334b-da81-408c-b2a3-7a55025704ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1119459708-172.17.0.7-1595882956951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37763,DS-3d0fddb1-1e1c-49c9-8af0-8fd0177645a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-9a246ae2-2900-4abc-91e9-73cc440f67ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-863de7f5-8a38-4db3-9fc0-c6fedf7628be,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-19550be5-f48c-4906-bac9-8a6d5744989c,DISK], DatanodeInfoWithStorage[127.0.0.1:33142,DS-f86e52eb-5d98-44d3-896c-d50384f57ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-1a902de4-e688-465d-bd30-a8c56330142a,DISK], DatanodeInfoWithStorage[127.0.0.1:44600,DS-1e287599-b9d8-4f5d-8329-aabc8e592767,DISK], DatanodeInfoWithStorage[127.0.0.1:42570,DS-8970334b-da81-408c-b2a3-7a55025704ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5381
