reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1291251004-172.17.0.11-1595889249167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33797,DS-f7c645dc-be46-4472-8b02-ade3b7df556b,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-8919fdf3-ffa0-4f5d-8078-c51c7b9ff0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-9ee15b73-fc1d-4926-9683-a8bb105e28c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-f8371121-9872-4da8-8c8a-2749fa612af6,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-e0d52f42-f03f-4f2d-9af7-2c3e411629d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-7c10ec46-a4b4-4235-a09a-fb242688405c,DISK], DatanodeInfoWithStorage[127.0.0.1:36820,DS-854deec6-1237-46dd-9597-c8588c7ae233,DISK], DatanodeInfoWithStorage[127.0.0.1:44405,DS-94a06ff5-c0d6-4aa0-ac93-befc57c470f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1291251004-172.17.0.11-1595889249167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33797,DS-f7c645dc-be46-4472-8b02-ade3b7df556b,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-8919fdf3-ffa0-4f5d-8078-c51c7b9ff0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-9ee15b73-fc1d-4926-9683-a8bb105e28c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-f8371121-9872-4da8-8c8a-2749fa612af6,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-e0d52f42-f03f-4f2d-9af7-2c3e411629d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-7c10ec46-a4b4-4235-a09a-fb242688405c,DISK], DatanodeInfoWithStorage[127.0.0.1:36820,DS-854deec6-1237-46dd-9597-c8588c7ae233,DISK], DatanodeInfoWithStorage[127.0.0.1:44405,DS-94a06ff5-c0d6-4aa0-ac93-befc57c470f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1408371555-172.17.0.11-1595889352421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44971,DS-aacc7851-a3c5-4379-9aae-481681e897f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-7927942f-0d30-4ea5-a6e2-93702f10576d,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-e6bf7f73-b0a6-4917-a9b6-68e0e079461d,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-fc93eb74-c32b-44b5-b713-ac2f589c404b,DISK], DatanodeInfoWithStorage[127.0.0.1:40291,DS-f0e1a2a4-9ab3-40e4-9e42-e2ddafa6a09c,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-f544188e-993f-419b-a0de-410509922c39,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-855ccd87-3f3f-4047-b138-7c10ce80a437,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-553eb28e-d082-4804-9794-3ed5749fd73a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1408371555-172.17.0.11-1595889352421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44971,DS-aacc7851-a3c5-4379-9aae-481681e897f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-7927942f-0d30-4ea5-a6e2-93702f10576d,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-e6bf7f73-b0a6-4917-a9b6-68e0e079461d,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-fc93eb74-c32b-44b5-b713-ac2f589c404b,DISK], DatanodeInfoWithStorage[127.0.0.1:40291,DS-f0e1a2a4-9ab3-40e4-9e42-e2ddafa6a09c,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-f544188e-993f-419b-a0de-410509922c39,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-855ccd87-3f3f-4047-b138-7c10ce80a437,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-553eb28e-d082-4804-9794-3ed5749fd73a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1968948951-172.17.0.11-1595889954362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39818,DS-92b8e22b-bc86-4211-b3d6-86fd10b8defc,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-364fdbd4-60cc-4aa7-985d-0c9ef872568e,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-bce9747d-2d4e-46d2-b7f2-189b911e985c,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-628144c5-7edf-459a-b177-a22e3d388361,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-35423718-524e-4be2-a1b5-0cfdeba7af1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-8192ecc8-11de-473d-88fb-9ef8de51a6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-0489004b-df66-4366-b8a3-270891981d74,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-828b9195-f0ed-45ec-86c9-cc36066a701f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1968948951-172.17.0.11-1595889954362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39818,DS-92b8e22b-bc86-4211-b3d6-86fd10b8defc,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-364fdbd4-60cc-4aa7-985d-0c9ef872568e,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-bce9747d-2d4e-46d2-b7f2-189b911e985c,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-628144c5-7edf-459a-b177-a22e3d388361,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-35423718-524e-4be2-a1b5-0cfdeba7af1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-8192ecc8-11de-473d-88fb-9ef8de51a6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-0489004b-df66-4366-b8a3-270891981d74,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-828b9195-f0ed-45ec-86c9-cc36066a701f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-123797156-172.17.0.11-1595890058030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33813,DS-6ae020b3-23df-47c4-a6f7-5503e9de2880,DISK], DatanodeInfoWithStorage[127.0.0.1:33897,DS-334addcd-75f2-4b83-bc14-027fb5cfdd06,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-ceb0d085-b605-45d7-92a8-d53d2f8266ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-4c77a6f1-b6e6-4235-afe2-5aff803734ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-edc002dc-a578-4358-bff6-4cb924717910,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-48460092-81c4-4a67-868d-0369517edefe,DISK], DatanodeInfoWithStorage[127.0.0.1:41048,DS-098764f7-54bf-4837-9184-c8caac785405,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-9ebf891e-41b3-4c7b-9579-16a9ae17038b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-123797156-172.17.0.11-1595890058030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33813,DS-6ae020b3-23df-47c4-a6f7-5503e9de2880,DISK], DatanodeInfoWithStorage[127.0.0.1:33897,DS-334addcd-75f2-4b83-bc14-027fb5cfdd06,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-ceb0d085-b605-45d7-92a8-d53d2f8266ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-4c77a6f1-b6e6-4235-afe2-5aff803734ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-edc002dc-a578-4358-bff6-4cb924717910,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-48460092-81c4-4a67-868d-0369517edefe,DISK], DatanodeInfoWithStorage[127.0.0.1:41048,DS-098764f7-54bf-4837-9184-c8caac785405,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-9ebf891e-41b3-4c7b-9579-16a9ae17038b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-621917820-172.17.0.11-1595890474576:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38697,DS-f7f9fc43-5d32-412c-a698-0358e1020a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-c35ddc25-ab14-4a89-b46d-622fcc90d17d,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-f04bcd10-9c21-43e7-bb27-260379ffe735,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-8e2a69e8-08b0-4f92-9500-a44aa407fd00,DISK], DatanodeInfoWithStorage[127.0.0.1:43773,DS-210fa7f1-63ee-480c-8a20-7868d2111792,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-1dd23dd8-fd11-4d2a-8c25-ea081a1f39e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-4e202dd7-5fe2-4412-82d0-5ff2761a2c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-a76877f8-8142-46f7-8fb2-54e980ce63f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-621917820-172.17.0.11-1595890474576:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38697,DS-f7f9fc43-5d32-412c-a698-0358e1020a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-c35ddc25-ab14-4a89-b46d-622fcc90d17d,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-f04bcd10-9c21-43e7-bb27-260379ffe735,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-8e2a69e8-08b0-4f92-9500-a44aa407fd00,DISK], DatanodeInfoWithStorage[127.0.0.1:43773,DS-210fa7f1-63ee-480c-8a20-7868d2111792,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-1dd23dd8-fd11-4d2a-8c25-ea081a1f39e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-4e202dd7-5fe2-4412-82d0-5ff2761a2c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-a76877f8-8142-46f7-8fb2-54e980ce63f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1749394413-172.17.0.11-1595890905062:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43836,DS-2c491666-78f9-477a-8a6e-b4baa68d0d37,DISK], DatanodeInfoWithStorage[127.0.0.1:32859,DS-9da60cb1-7bc8-4cba-9064-01f89f8ec195,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-c476d0db-f464-473f-b6b8-7aad68814d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-dd9f2be2-1a59-48b4-998c-14e524c135d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-7acc0fd3-46da-429b-88f0-64df4d6a76d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-bb4de7c6-b15c-41c8-9322-3383ae6ad097,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-e0d93bf3-8851-434e-bc06-b1687b5186d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-b63daf61-5d71-43a6-b18a-e06e97aa54b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1749394413-172.17.0.11-1595890905062:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43836,DS-2c491666-78f9-477a-8a6e-b4baa68d0d37,DISK], DatanodeInfoWithStorage[127.0.0.1:32859,DS-9da60cb1-7bc8-4cba-9064-01f89f8ec195,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-c476d0db-f464-473f-b6b8-7aad68814d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-dd9f2be2-1a59-48b4-998c-14e524c135d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-7acc0fd3-46da-429b-88f0-64df4d6a76d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-bb4de7c6-b15c-41c8-9322-3383ae6ad097,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-e0d93bf3-8851-434e-bc06-b1687b5186d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-b63daf61-5d71-43a6-b18a-e06e97aa54b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-882798815-172.17.0.11-1595891327270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38064,DS-ab577d63-6ae4-4023-a746-873dea9fa2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-70b5f7be-da67-46e3-a05b-9d13f448ad5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41486,DS-f3ad6928-0ea5-474c-a5ad-8c1face56cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-b6fb872f-ddc1-476f-ba93-5ea69cc4e476,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-6a0d24fe-b2db-4cee-a98c-2bd4b0108226,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-684a38e3-67e1-4f23-ab83-032a2ee080fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-56f42deb-dd9e-429a-ad0e-6be663a6613d,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-44f80ba8-1215-4cd3-8c62-7a9b0cc4fe81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-882798815-172.17.0.11-1595891327270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38064,DS-ab577d63-6ae4-4023-a746-873dea9fa2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-70b5f7be-da67-46e3-a05b-9d13f448ad5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41486,DS-f3ad6928-0ea5-474c-a5ad-8c1face56cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-b6fb872f-ddc1-476f-ba93-5ea69cc4e476,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-6a0d24fe-b2db-4cee-a98c-2bd4b0108226,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-684a38e3-67e1-4f23-ab83-032a2ee080fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-56f42deb-dd9e-429a-ad0e-6be663a6613d,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-44f80ba8-1215-4cd3-8c62-7a9b0cc4fe81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-936706268-172.17.0.11-1595891628332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44814,DS-e5fe1ba4-a61a-4988-90ba-267926b9afd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-e755db4d-3fc6-44e3-8d17-15da1ac64c44,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-c6a199bf-602a-4fb2-8857-c017e790b3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-9e4bb449-aff2-4b1c-979f-b1e15785d3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-addbdb3c-3ace-4414-b8a1-5c94d828a01f,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-f9b9b2d4-937c-42ba-b37f-6e9b4ee92e00,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-2f3c64bf-17e8-4195-86f5-57ba8d109d16,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-70565ec2-6951-4c3d-adaa-6ffbef4917da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-936706268-172.17.0.11-1595891628332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44814,DS-e5fe1ba4-a61a-4988-90ba-267926b9afd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-e755db4d-3fc6-44e3-8d17-15da1ac64c44,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-c6a199bf-602a-4fb2-8857-c017e790b3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-9e4bb449-aff2-4b1c-979f-b1e15785d3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-addbdb3c-3ace-4414-b8a1-5c94d828a01f,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-f9b9b2d4-937c-42ba-b37f-6e9b4ee92e00,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-2f3c64bf-17e8-4195-86f5-57ba8d109d16,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-70565ec2-6951-4c3d-adaa-6ffbef4917da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-94803425-172.17.0.11-1595892265389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36480,DS-9161b807-1e54-42f5-a0f5-fa6ca37a154e,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-db0f89cd-c88f-4e8e-9e54-ca3579bc75ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-f5d58e21-92f6-42ea-96dc-99f12b20086c,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-ca872a2f-109e-4e20-b7b4-35dcc7269fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-cbabde1d-5191-4106-89eb-1c6e32aa8321,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-c269b7c0-a504-4f13-a9c0-678e3c0a9568,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-93a68cfd-76ab-4e65-96aa-963f8155818d,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-66d995ee-2888-4503-8438-08b85b87172e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-94803425-172.17.0.11-1595892265389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36480,DS-9161b807-1e54-42f5-a0f5-fa6ca37a154e,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-db0f89cd-c88f-4e8e-9e54-ca3579bc75ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-f5d58e21-92f6-42ea-96dc-99f12b20086c,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-ca872a2f-109e-4e20-b7b4-35dcc7269fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-cbabde1d-5191-4106-89eb-1c6e32aa8321,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-c269b7c0-a504-4f13-a9c0-678e3c0a9568,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-93a68cfd-76ab-4e65-96aa-963f8155818d,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-66d995ee-2888-4503-8438-08b85b87172e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-181023089-172.17.0.11-1595892340156:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34446,DS-78a6aac0-b2eb-4004-bf05-af95bf7984f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-7188ac90-eb46-40cd-b89e-8b28ff29f732,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-b67321e6-7323-4d6f-9aae-5bb2ef8dfc78,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-b485fd50-2d61-4193-895c-68fe9eee36cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38706,DS-bdd38e2c-2add-4f81-9559-d2d266e46e01,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-3b111497-962f-443d-8e96-62974e972eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-0a9f4871-584b-4edf-ba3e-dab04fbf6bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-bd311843-1315-46a6-a154-47eff1582e8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-181023089-172.17.0.11-1595892340156:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34446,DS-78a6aac0-b2eb-4004-bf05-af95bf7984f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-7188ac90-eb46-40cd-b89e-8b28ff29f732,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-b67321e6-7323-4d6f-9aae-5bb2ef8dfc78,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-b485fd50-2d61-4193-895c-68fe9eee36cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38706,DS-bdd38e2c-2add-4f81-9559-d2d266e46e01,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-3b111497-962f-443d-8e96-62974e972eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-0a9f4871-584b-4edf-ba3e-dab04fbf6bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-bd311843-1315-46a6-a154-47eff1582e8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-157561388-172.17.0.11-1595892434305:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42288,DS-47a1e6d8-29a6-423c-93e8-a419386051dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-e1736b0e-ceb9-4aa9-acb9-53f5c3c1acfd,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-6bedd660-81b9-466c-956c-918a823b3906,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-e6277543-c384-4d10-8c8c-385b81450d03,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-fc77d679-2e5a-4937-be7e-c3a7e818c361,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-23224b7d-660a-40c5-ae4b-3e85e7ef18cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-a65c6db9-9b73-4149-b397-e59e83ad03b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-ce19581e-c062-4703-b49c-97f2f4f7fcbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-157561388-172.17.0.11-1595892434305:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42288,DS-47a1e6d8-29a6-423c-93e8-a419386051dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-e1736b0e-ceb9-4aa9-acb9-53f5c3c1acfd,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-6bedd660-81b9-466c-956c-918a823b3906,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-e6277543-c384-4d10-8c8c-385b81450d03,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-fc77d679-2e5a-4937-be7e-c3a7e818c361,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-23224b7d-660a-40c5-ae4b-3e85e7ef18cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-a65c6db9-9b73-4149-b397-e59e83ad03b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-ce19581e-c062-4703-b49c-97f2f4f7fcbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1226498034-172.17.0.11-1595892911634:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39656,DS-91df853f-91fb-48bc-b4a6-a4eb05757a44,DISK], DatanodeInfoWithStorage[127.0.0.1:36364,DS-3b2b76c7-17a5-49c3-b21a-0656c1f3c66e,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-ddc622f9-4c2e-47eb-806e-93ac72c9984c,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-d74f9af8-7bcb-46c6-b1fb-eb563a03ee67,DISK], DatanodeInfoWithStorage[127.0.0.1:42737,DS-29b9a4c3-89d5-43fe-87c9-0617c25c1121,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-91f0aca7-1964-4e0d-9c13-523cf81f0752,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-ba2d50ec-fc1d-41a9-81e2-07ce25ebdf1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-44027527-cfeb-452c-8096-6a03cae635b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1226498034-172.17.0.11-1595892911634:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39656,DS-91df853f-91fb-48bc-b4a6-a4eb05757a44,DISK], DatanodeInfoWithStorage[127.0.0.1:36364,DS-3b2b76c7-17a5-49c3-b21a-0656c1f3c66e,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-ddc622f9-4c2e-47eb-806e-93ac72c9984c,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-d74f9af8-7bcb-46c6-b1fb-eb563a03ee67,DISK], DatanodeInfoWithStorage[127.0.0.1:42737,DS-29b9a4c3-89d5-43fe-87c9-0617c25c1121,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-91f0aca7-1964-4e0d-9c13-523cf81f0752,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-ba2d50ec-fc1d-41a9-81e2-07ce25ebdf1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-44027527-cfeb-452c-8096-6a03cae635b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1572666926-172.17.0.11-1595893655480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45088,DS-0d268e10-d4e8-4ffe-89e5-c970f3ea53bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-ffea35dc-4bae-4360-acef-18534b793a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-fd708d50-650a-4be0-9030-911576a02d61,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-61223ec1-0a26-4c8b-a9e8-d46b6f7f4db9,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-dfea00e9-bead-4300-9985-19e467a0f1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-1e859b6e-9b4b-45e4-88d3-c21979461a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-642ef1a8-ba54-4097-8677-57fe7c7e01a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40555,DS-6abdecee-be83-4090-95f3-3ddf33fe2a3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1572666926-172.17.0.11-1595893655480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45088,DS-0d268e10-d4e8-4ffe-89e5-c970f3ea53bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-ffea35dc-4bae-4360-acef-18534b793a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-fd708d50-650a-4be0-9030-911576a02d61,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-61223ec1-0a26-4c8b-a9e8-d46b6f7f4db9,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-dfea00e9-bead-4300-9985-19e467a0f1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-1e859b6e-9b4b-45e4-88d3-c21979461a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-642ef1a8-ba54-4097-8677-57fe7c7e01a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40555,DS-6abdecee-be83-4090-95f3-3ddf33fe2a3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-925618818-172.17.0.11-1595894187616:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45757,DS-8ca9d2e6-15ff-4da1-8b5c-04de965d93d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46535,DS-7ec071dd-0e89-47d0-af3f-fd157e9c697d,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-b5eb5c64-1e7e-4eb7-a026-6f6168af03e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45955,DS-474bf305-f5a3-4942-b0df-9c8341be2d69,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-86bdf0e7-3b65-4c96-ab53-532db0164852,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-f6f74dc4-ceae-424e-8373-9443053dc1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-025b21b9-c0fc-4a57-a1eb-2f6f90cc9120,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-c69859eb-fd59-4bbe-b50b-960ad7941fcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-925618818-172.17.0.11-1595894187616:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45757,DS-8ca9d2e6-15ff-4da1-8b5c-04de965d93d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46535,DS-7ec071dd-0e89-47d0-af3f-fd157e9c697d,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-b5eb5c64-1e7e-4eb7-a026-6f6168af03e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45955,DS-474bf305-f5a3-4942-b0df-9c8341be2d69,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-86bdf0e7-3b65-4c96-ab53-532db0164852,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-f6f74dc4-ceae-424e-8373-9443053dc1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-025b21b9-c0fc-4a57-a1eb-2f6f90cc9120,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-c69859eb-fd59-4bbe-b50b-960ad7941fcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5239
