reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-913373625-172.17.0.11-1595838662691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42742,DS-69dc6011-4b76-45f4-b633-45af2668d823,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-c48e483f-c843-4965-b20e-f8eea56c8f27,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-1833b210-b1a8-489c-b821-3b3b0a18f95f,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-5defad84-eb25-4d64-9f46-b98133c6ca05,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-40fe94e0-35ca-4435-a593-e808729ab419,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-4a535780-75a3-4b3f-954c-21619cc3317f,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-e743cf24-0533-4ce6-8c39-91b2482698de,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-afc83031-fa2f-4e34-a7b2-a59313619214,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-913373625-172.17.0.11-1595838662691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42742,DS-69dc6011-4b76-45f4-b633-45af2668d823,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-c48e483f-c843-4965-b20e-f8eea56c8f27,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-1833b210-b1a8-489c-b821-3b3b0a18f95f,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-5defad84-eb25-4d64-9f46-b98133c6ca05,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-40fe94e0-35ca-4435-a593-e808729ab419,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-4a535780-75a3-4b3f-954c-21619cc3317f,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-e743cf24-0533-4ce6-8c39-91b2482698de,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-afc83031-fa2f-4e34-a7b2-a59313619214,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-591402362-172.17.0.11-1595838929697:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41208,DS-1d27a4f5-0d3e-4c20-a39a-7e6a9d7fae6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-30932de3-931b-4fdf-9eb4-e42ed1ee5ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-284ca267-ae88-4579-91d7-b800d76ea07e,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-a8df9bee-e299-41f0-b5ce-5dd927e28990,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-fd7c1c9f-886f-4e7b-b672-66991acf9ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-beb5b921-f0fd-44db-8467-29add5faf4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-335c1cb4-0fe9-408e-a7fa-8a97ba66c746,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-775848b7-44b9-4e7b-83d4-217bc9aee17f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-591402362-172.17.0.11-1595838929697:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41208,DS-1d27a4f5-0d3e-4c20-a39a-7e6a9d7fae6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-30932de3-931b-4fdf-9eb4-e42ed1ee5ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-284ca267-ae88-4579-91d7-b800d76ea07e,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-a8df9bee-e299-41f0-b5ce-5dd927e28990,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-fd7c1c9f-886f-4e7b-b672-66991acf9ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-beb5b921-f0fd-44db-8467-29add5faf4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-335c1cb4-0fe9-408e-a7fa-8a97ba66c746,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-775848b7-44b9-4e7b-83d4-217bc9aee17f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-438338705-172.17.0.11-1595839035894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46074,DS-b55570ca-1ae1-4e45-9a94-035d8238f89d,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-d0efb729-4f43-4c7f-8288-f0ab24c34408,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-77b624f2-4e5c-4089-b9f7-8696acd6e425,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-97dab635-2571-41a3-940f-7b6792de1c46,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-5b763b1c-9190-4a10-ab28-6e5c21da4c18,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-1e2c7de9-c614-44eb-a70b-19ac4bb6044e,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-7806c835-f30f-4801-be94-bf9ea1a3f3db,DISK], DatanodeInfoWithStorage[127.0.0.1:35530,DS-ebdfa19c-7f03-4560-a484-5823a4c0bd8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-438338705-172.17.0.11-1595839035894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46074,DS-b55570ca-1ae1-4e45-9a94-035d8238f89d,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-d0efb729-4f43-4c7f-8288-f0ab24c34408,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-77b624f2-4e5c-4089-b9f7-8696acd6e425,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-97dab635-2571-41a3-940f-7b6792de1c46,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-5b763b1c-9190-4a10-ab28-6e5c21da4c18,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-1e2c7de9-c614-44eb-a70b-19ac4bb6044e,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-7806c835-f30f-4801-be94-bf9ea1a3f3db,DISK], DatanodeInfoWithStorage[127.0.0.1:35530,DS-ebdfa19c-7f03-4560-a484-5823a4c0bd8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1360333122-172.17.0.11-1595839180727:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36761,DS-18bdf12f-8336-4fec-b60b-20248bb4b5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36437,DS-1e8332cf-1149-439c-86d4-4dafc02a8a75,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-43a9299d-4e33-4dae-b222-b83122f55444,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-34dc2800-ae59-44d9-a817-ccab05eb3250,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-7c348141-c208-44fe-89c5-80acdff7a5de,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-9fe446d8-64a8-4de2-bd74-d84ee7f38c74,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-fe07257f-2bb7-453c-bb48-6ca43567f362,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-b04170a5-210b-4178-9f78-e40dd6598260,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1360333122-172.17.0.11-1595839180727:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36761,DS-18bdf12f-8336-4fec-b60b-20248bb4b5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36437,DS-1e8332cf-1149-439c-86d4-4dafc02a8a75,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-43a9299d-4e33-4dae-b222-b83122f55444,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-34dc2800-ae59-44d9-a817-ccab05eb3250,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-7c348141-c208-44fe-89c5-80acdff7a5de,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-9fe446d8-64a8-4de2-bd74-d84ee7f38c74,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-fe07257f-2bb7-453c-bb48-6ca43567f362,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-b04170a5-210b-4178-9f78-e40dd6598260,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-599087125-172.17.0.11-1595839411993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44499,DS-bd80ffe7-06ae-4050-8ed3-d15fc5920b90,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-b0b2bdae-7e98-4aad-a243-323142f0e886,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-84cfd18c-6618-4f6a-82dd-2219a95ec52c,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-4e620344-7fd3-4982-8d5f-69c3d2ebc2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-bb96009b-7924-4cf1-bfc0-1e63b832d4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-11491c89-152d-4bd9-b9b4-a59ddd48d63c,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-fadf497e-0a36-45cf-8bdd-b917e33aa976,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-cd0fc31d-1901-4bf3-8ab3-38ad494123e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-599087125-172.17.0.11-1595839411993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44499,DS-bd80ffe7-06ae-4050-8ed3-d15fc5920b90,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-b0b2bdae-7e98-4aad-a243-323142f0e886,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-84cfd18c-6618-4f6a-82dd-2219a95ec52c,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-4e620344-7fd3-4982-8d5f-69c3d2ebc2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-bb96009b-7924-4cf1-bfc0-1e63b832d4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-11491c89-152d-4bd9-b9b4-a59ddd48d63c,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-fadf497e-0a36-45cf-8bdd-b917e33aa976,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-cd0fc31d-1901-4bf3-8ab3-38ad494123e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1105110782-172.17.0.11-1595839584903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46186,DS-c3cfd6ca-11f8-4c3b-afe9-8f438d9493b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-3d9ac459-47b9-43fa-95fd-291239df42a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-2588b251-4fdf-4368-ac84-0ca0c5bc17c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-e3131043-9f3d-4a06-bc44-12736d556287,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-6e34daa4-e534-433c-a799-ee61709a0f17,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-0fdfec4b-46ea-4ed7-b3d5-e89ec0617dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-babe141e-dd9c-4dfb-b233-48eb07e1d629,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-e73857ee-2fff-4a5f-8ac6-bed2363c0104,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1105110782-172.17.0.11-1595839584903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46186,DS-c3cfd6ca-11f8-4c3b-afe9-8f438d9493b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-3d9ac459-47b9-43fa-95fd-291239df42a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-2588b251-4fdf-4368-ac84-0ca0c5bc17c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-e3131043-9f3d-4a06-bc44-12736d556287,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-6e34daa4-e534-433c-a799-ee61709a0f17,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-0fdfec4b-46ea-4ed7-b3d5-e89ec0617dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-babe141e-dd9c-4dfb-b233-48eb07e1d629,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-e73857ee-2fff-4a5f-8ac6-bed2363c0104,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1749084104-172.17.0.11-1595840363909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33563,DS-70180bc1-9691-4a31-88c4-63770c5742d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-d3739b19-dcf5-4bcb-911e-677276b27a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-e22e861b-f950-4817-a403-c405d398cbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-2668b268-cf97-480e-ad7b-31416dc0b0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-23411d28-6eee-4155-923e-6b83fba8d8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-901d07d7-7ce4-4864-9296-67ab5e6162b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-2eb252fa-61ec-4022-bf82-f3088496a4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-a48062cb-1c57-4e58-a8bd-ca28520c8a0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1749084104-172.17.0.11-1595840363909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33563,DS-70180bc1-9691-4a31-88c4-63770c5742d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-d3739b19-dcf5-4bcb-911e-677276b27a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-e22e861b-f950-4817-a403-c405d398cbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-2668b268-cf97-480e-ad7b-31416dc0b0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-23411d28-6eee-4155-923e-6b83fba8d8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-901d07d7-7ce4-4864-9296-67ab5e6162b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-2eb252fa-61ec-4022-bf82-f3088496a4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-a48062cb-1c57-4e58-a8bd-ca28520c8a0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1581089120-172.17.0.11-1595840487865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44202,DS-2a986485-5f13-497f-9e94-bca15b0a05e5,DISK], DatanodeInfoWithStorage[127.0.0.1:32929,DS-58fa98d6-c463-4613-b048-be19311e4dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:38139,DS-f9add216-8395-4e7e-a5c8-16128331ddd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-e2160749-7b0f-4c6e-b3c2-4e67558b6106,DISK], DatanodeInfoWithStorage[127.0.0.1:45646,DS-844aac26-14c6-4af8-829e-6394c86c08f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-5da86047-91c2-4a32-ba2a-3aa1221e8da7,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-63fed7d7-4c3d-45b0-a6d0-da58292f73e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-749052b6-9bb3-4cf0-9c13-ac3ea7aacbcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1581089120-172.17.0.11-1595840487865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44202,DS-2a986485-5f13-497f-9e94-bca15b0a05e5,DISK], DatanodeInfoWithStorage[127.0.0.1:32929,DS-58fa98d6-c463-4613-b048-be19311e4dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:38139,DS-f9add216-8395-4e7e-a5c8-16128331ddd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-e2160749-7b0f-4c6e-b3c2-4e67558b6106,DISK], DatanodeInfoWithStorage[127.0.0.1:45646,DS-844aac26-14c6-4af8-829e-6394c86c08f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-5da86047-91c2-4a32-ba2a-3aa1221e8da7,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-63fed7d7-4c3d-45b0-a6d0-da58292f73e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-749052b6-9bb3-4cf0-9c13-ac3ea7aacbcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1190142192-172.17.0.11-1595840557478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45418,DS-1488d394-0fd9-492b-81d4-55996a633cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-03318190-d4e6-4edd-9ec9-6ecf34bf6696,DISK], DatanodeInfoWithStorage[127.0.0.1:33106,DS-b4c2b7b6-7859-48f7-8f6a-542c3eb8c8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-e8626430-46f1-4336-b3bb-983dbe8646f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42805,DS-89c1b7ca-2b45-4036-b899-ce168dc8e75c,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-997ae400-b8da-4e6c-ac54-8c4d70f9ed2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-defaf1f2-33f1-4a7a-9819-fe82c7697901,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-f7a770ef-c94b-401d-8ab6-923c6eb887ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1190142192-172.17.0.11-1595840557478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45418,DS-1488d394-0fd9-492b-81d4-55996a633cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-03318190-d4e6-4edd-9ec9-6ecf34bf6696,DISK], DatanodeInfoWithStorage[127.0.0.1:33106,DS-b4c2b7b6-7859-48f7-8f6a-542c3eb8c8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-e8626430-46f1-4336-b3bb-983dbe8646f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42805,DS-89c1b7ca-2b45-4036-b899-ce168dc8e75c,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-997ae400-b8da-4e6c-ac54-8c4d70f9ed2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-defaf1f2-33f1-4a7a-9819-fe82c7697901,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-f7a770ef-c94b-401d-8ab6-923c6eb887ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1857289860-172.17.0.11-1595841553899:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44930,DS-b1ee986a-2cc0-4240-abcf-d7c7e57ae6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-7121e50e-0768-440f-8bce-4f6f2e3d6827,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-4a197ddb-6d69-41fe-bea8-656cd29800dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-6ba61736-c067-47c4-a6e0-d573f6c17604,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-36ccade7-9880-49b3-8430-fec63a0654d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-447b188e-cf21-4391-8626-e00f3d1a6e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-2bab0357-9dc5-4383-ac83-bdbe649b08ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35714,DS-aa8470fe-5eee-48b7-a0fe-c6f59aed0127,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1857289860-172.17.0.11-1595841553899:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44930,DS-b1ee986a-2cc0-4240-abcf-d7c7e57ae6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-7121e50e-0768-440f-8bce-4f6f2e3d6827,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-4a197ddb-6d69-41fe-bea8-656cd29800dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-6ba61736-c067-47c4-a6e0-d573f6c17604,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-36ccade7-9880-49b3-8430-fec63a0654d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-447b188e-cf21-4391-8626-e00f3d1a6e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-2bab0357-9dc5-4383-ac83-bdbe649b08ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35714,DS-aa8470fe-5eee-48b7-a0fe-c6f59aed0127,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-655858055-172.17.0.11-1595842247553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46627,DS-3e08cdd1-9817-4613-9187-e55f62ae63f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-7fb27bd1-2d44-4222-bde2-a3f70b13231c,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-59877bc9-f185-4809-9eed-7d46a369d52c,DISK], DatanodeInfoWithStorage[127.0.0.1:34375,DS-5d6ac525-5eff-4efd-876a-3abe185a5b98,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-768f8453-74b5-46df-8099-53d3851cbedd,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-8dbfa3c6-9e74-49b2-a98f-745fd39e1c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-2f98d5db-7148-4415-977a-fc08161b877f,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-a2361c77-a4b7-4f78-9339-6731258b002c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-655858055-172.17.0.11-1595842247553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46627,DS-3e08cdd1-9817-4613-9187-e55f62ae63f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-7fb27bd1-2d44-4222-bde2-a3f70b13231c,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-59877bc9-f185-4809-9eed-7d46a369d52c,DISK], DatanodeInfoWithStorage[127.0.0.1:34375,DS-5d6ac525-5eff-4efd-876a-3abe185a5b98,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-768f8453-74b5-46df-8099-53d3851cbedd,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-8dbfa3c6-9e74-49b2-a98f-745fd39e1c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-2f98d5db-7148-4415-977a-fc08161b877f,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-a2361c77-a4b7-4f78-9339-6731258b002c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-940301315-172.17.0.11-1595842840759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41336,DS-a97a3398-1fb0-4c55-b333-b374313d5317,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-c83863eb-6dd0-4eca-9f0a-f483092ffb18,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-36c7acbe-0e8c-45f8-9cd5-c25a93cb7ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-f39d24c4-8386-4f52-a547-07d4cc032c91,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-aa556097-ee8c-4e25-9529-574533b6f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-b43915d0-f9d1-4784-9d3d-39bb64a6e7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46636,DS-5570a638-ccb0-4ded-b136-fa43f7a9f248,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-1a17d827-a17a-4b34-a0d1-a1119daa667c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-940301315-172.17.0.11-1595842840759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41336,DS-a97a3398-1fb0-4c55-b333-b374313d5317,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-c83863eb-6dd0-4eca-9f0a-f483092ffb18,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-36c7acbe-0e8c-45f8-9cd5-c25a93cb7ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-f39d24c4-8386-4f52-a547-07d4cc032c91,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-aa556097-ee8c-4e25-9529-574533b6f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-b43915d0-f9d1-4784-9d3d-39bb64a6e7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46636,DS-5570a638-ccb0-4ded-b136-fa43f7a9f248,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-1a17d827-a17a-4b34-a0d1-a1119daa667c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1091783450-172.17.0.11-1595843159943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39109,DS-c857b245-aaee-493e-afaa-ed930a7d9fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-2432aa23-9f53-4d6d-ac08-fe543e1b9ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-02fa9a18-ee3d-4bc7-a7c5-082fdc261ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:35902,DS-acf3b3a2-cc1a-4601-b6d7-2158343068a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-3f0b20f7-5a70-48ef-9eb8-c63233ac0698,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-d4867d7a-e536-473c-ae01-31a587c60e92,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-42d25357-d647-4970-8cb0-9cccd38b15ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-0347d4bd-d145-4917-bd68-afcb4c33e59f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1091783450-172.17.0.11-1595843159943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39109,DS-c857b245-aaee-493e-afaa-ed930a7d9fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-2432aa23-9f53-4d6d-ac08-fe543e1b9ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-02fa9a18-ee3d-4bc7-a7c5-082fdc261ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:35902,DS-acf3b3a2-cc1a-4601-b6d7-2158343068a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-3f0b20f7-5a70-48ef-9eb8-c63233ac0698,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-d4867d7a-e536-473c-ae01-31a587c60e92,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-42d25357-d647-4970-8cb0-9cccd38b15ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-0347d4bd-d145-4917-bd68-afcb4c33e59f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-531128313-172.17.0.11-1595843276357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39081,DS-a16dd915-8e1b-4e5b-aa11-30ebe0bd597c,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-4dc4e350-9055-497f-ab1b-664be400ac42,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-9978040d-8957-4ac5-91ac-08c972d1af53,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-61c11758-c3d3-4c10-a628-6c353771c608,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-fd87d363-4275-47ff-ae0d-62379416ba03,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-4373b440-7ba2-46ba-9eb7-ba68aa3ee457,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-47d77a62-e793-4ac3-af75-eff791b911e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42296,DS-939c0099-3aa1-45a9-8497-6da8b5eb7172,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-531128313-172.17.0.11-1595843276357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39081,DS-a16dd915-8e1b-4e5b-aa11-30ebe0bd597c,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-4dc4e350-9055-497f-ab1b-664be400ac42,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-9978040d-8957-4ac5-91ac-08c972d1af53,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-61c11758-c3d3-4c10-a628-6c353771c608,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-fd87d363-4275-47ff-ae0d-62379416ba03,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-4373b440-7ba2-46ba-9eb7-ba68aa3ee457,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-47d77a62-e793-4ac3-af75-eff791b911e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42296,DS-939c0099-3aa1-45a9-8497-6da8b5eb7172,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-956432292-172.17.0.11-1595843881381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42984,DS-92ad7e8d-d8e0-4190-8962-ecb105d3ceef,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-a08529b1-b1c5-4122-8280-6179f4a074c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-d95dcf54-92ed-4325-8caa-afe17d390507,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-4f0f8de3-52ff-42ef-a98c-7f9efbbeaec6,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-9f3623fb-e4a1-4ecb-87e6-69d6dff54c65,DISK], DatanodeInfoWithStorage[127.0.0.1:40831,DS-243f8abf-b607-4ce1-aa96-ffb7bcebbd88,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-45d0343e-58f5-4549-9984-7f49aa74255e,DISK], DatanodeInfoWithStorage[127.0.0.1:41155,DS-5f9a081b-031f-44b4-9204-1eaecddbfe3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-956432292-172.17.0.11-1595843881381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42984,DS-92ad7e8d-d8e0-4190-8962-ecb105d3ceef,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-a08529b1-b1c5-4122-8280-6179f4a074c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-d95dcf54-92ed-4325-8caa-afe17d390507,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-4f0f8de3-52ff-42ef-a98c-7f9efbbeaec6,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-9f3623fb-e4a1-4ecb-87e6-69d6dff54c65,DISK], DatanodeInfoWithStorage[127.0.0.1:40831,DS-243f8abf-b607-4ce1-aa96-ffb7bcebbd88,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-45d0343e-58f5-4549-9984-7f49aa74255e,DISK], DatanodeInfoWithStorage[127.0.0.1:41155,DS-5f9a081b-031f-44b4-9204-1eaecddbfe3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5564
