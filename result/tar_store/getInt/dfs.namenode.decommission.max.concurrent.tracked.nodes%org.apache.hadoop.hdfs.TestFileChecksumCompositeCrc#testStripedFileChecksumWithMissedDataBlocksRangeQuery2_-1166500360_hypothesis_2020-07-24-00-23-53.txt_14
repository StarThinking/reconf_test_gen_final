reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1280575753-172.17.0.9-1595550414049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34798,DS-1b60ae20-c71f-4ed5-8d96-53489f1c1c86,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-6f95e726-dda2-4166-a8a5-1487676c12ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-27801c25-1502-45a9-b28c-440194af1f39,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-411bc3d4-06c9-4bc0-ba02-fc74447ea866,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-c92c9841-da38-41ef-a7df-0f85728140f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-6dbfdf1c-968c-4157-8afc-6762a2b61653,DISK], DatanodeInfoWithStorage[127.0.0.1:35766,DS-efb84ed6-7ace-4d0d-8060-1fd073a3e17f,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-36ef286a-3853-4d42-b36f-b5cb91b673ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1280575753-172.17.0.9-1595550414049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34798,DS-1b60ae20-c71f-4ed5-8d96-53489f1c1c86,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-6f95e726-dda2-4166-a8a5-1487676c12ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-27801c25-1502-45a9-b28c-440194af1f39,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-411bc3d4-06c9-4bc0-ba02-fc74447ea866,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-c92c9841-da38-41ef-a7df-0f85728140f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-6dbfdf1c-968c-4157-8afc-6762a2b61653,DISK], DatanodeInfoWithStorage[127.0.0.1:35766,DS-efb84ed6-7ace-4d0d-8060-1fd073a3e17f,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-36ef286a-3853-4d42-b36f-b5cb91b673ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-536684565-172.17.0.9-1595550456139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44214,DS-d7051057-dbbe-46b6-be3b-922d240f11db,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-2dcb3abd-82a0-4c5e-98db-b0b6af3ccf67,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-b09a6b9b-f5d6-42d0-9dfd-7b797bc98ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-7878884a-0796-40a7-af73-6ff7bc8b8765,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-f085cb0f-80eb-4bd6-a5fb-a97a9656ddf8,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-2feae835-fa38-4c90-bf62-cc2820d6f51c,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-183144f1-f595-4454-aaec-61db6dcb26fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-a2722ecf-f2fb-420c-ae3e-e8bb24772163,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-536684565-172.17.0.9-1595550456139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44214,DS-d7051057-dbbe-46b6-be3b-922d240f11db,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-2dcb3abd-82a0-4c5e-98db-b0b6af3ccf67,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-b09a6b9b-f5d6-42d0-9dfd-7b797bc98ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-7878884a-0796-40a7-af73-6ff7bc8b8765,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-f085cb0f-80eb-4bd6-a5fb-a97a9656ddf8,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-2feae835-fa38-4c90-bf62-cc2820d6f51c,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-183144f1-f595-4454-aaec-61db6dcb26fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-a2722ecf-f2fb-420c-ae3e-e8bb24772163,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1511805492-172.17.0.9-1595551884112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42773,DS-bb3cf059-5c71-4171-934a-5abd690fc146,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-f8f31a06-b9d1-4e57-b951-6c0207bb52a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-c5f81d77-281e-487d-9803-84e49e66de97,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-58e1aa96-f693-4c03-ba32-f8972ad7ae22,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-a6d074c2-4caa-4309-8f95-6f7bd82727d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-bc9d0ac2-2f93-41f2-be84-ad1dde076b56,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-f72425f9-e1d2-432d-aa5f-b746f452e38b,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-036b5dd9-cdbd-4c2e-8cca-2712c4cdbf4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1511805492-172.17.0.9-1595551884112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42773,DS-bb3cf059-5c71-4171-934a-5abd690fc146,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-f8f31a06-b9d1-4e57-b951-6c0207bb52a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-c5f81d77-281e-487d-9803-84e49e66de97,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-58e1aa96-f693-4c03-ba32-f8972ad7ae22,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-a6d074c2-4caa-4309-8f95-6f7bd82727d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-bc9d0ac2-2f93-41f2-be84-ad1dde076b56,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-f72425f9-e1d2-432d-aa5f-b746f452e38b,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-036b5dd9-cdbd-4c2e-8cca-2712c4cdbf4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1472515352-172.17.0.9-1595552555038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36236,DS-30255850-13fd-490e-b9e1-35fbd5c4cede,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-8f684db7-1489-4c80-9bd7-6d7f55cabefe,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-42db435c-6813-4613-acea-2d9b66e5670b,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-f4824630-e9c3-4e15-841f-a11084f1a900,DISK], DatanodeInfoWithStorage[127.0.0.1:37707,DS-3230957c-92e4-4956-bfa4-4ec2a204fd6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-bc804d28-2a1e-45ab-aea3-1cdef8a0fa21,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-348c93a6-eeb5-453a-a266-574556ac92d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-0ea23bf9-ed94-47f6-b4fd-a8d8aa6baf17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1472515352-172.17.0.9-1595552555038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36236,DS-30255850-13fd-490e-b9e1-35fbd5c4cede,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-8f684db7-1489-4c80-9bd7-6d7f55cabefe,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-42db435c-6813-4613-acea-2d9b66e5670b,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-f4824630-e9c3-4e15-841f-a11084f1a900,DISK], DatanodeInfoWithStorage[127.0.0.1:37707,DS-3230957c-92e4-4956-bfa4-4ec2a204fd6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-bc804d28-2a1e-45ab-aea3-1cdef8a0fa21,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-348c93a6-eeb5-453a-a266-574556ac92d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-0ea23bf9-ed94-47f6-b4fd-a8d8aa6baf17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2080816336-172.17.0.9-1595552597052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35321,DS-8410a4d8-eacd-4e11-8e51-13fb36fdcbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-fe9e4326-69f3-4486-90cf-4ec67af56f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-18a8af0d-d6d2-4fc2-a82f-21cb6ec9a694,DISK], DatanodeInfoWithStorage[127.0.0.1:34001,DS-79b9022b-e96f-481b-b514-d555c78516c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-6081fbb9-4f08-468b-a00f-e29ad98f05b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-df52273f-98df-4f29-857d-cc9c9361a54f,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-0ddb97ab-ef20-461e-a832-67ecd4e262ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-1f4dc21a-39b3-4aec-83d4-286ef30a7be3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2080816336-172.17.0.9-1595552597052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35321,DS-8410a4d8-eacd-4e11-8e51-13fb36fdcbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-fe9e4326-69f3-4486-90cf-4ec67af56f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-18a8af0d-d6d2-4fc2-a82f-21cb6ec9a694,DISK], DatanodeInfoWithStorage[127.0.0.1:34001,DS-79b9022b-e96f-481b-b514-d555c78516c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-6081fbb9-4f08-468b-a00f-e29ad98f05b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-df52273f-98df-4f29-857d-cc9c9361a54f,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-0ddb97ab-ef20-461e-a832-67ecd4e262ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-1f4dc21a-39b3-4aec-83d4-286ef30a7be3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1123894053-172.17.0.9-1595552757684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42084,DS-00ebb40c-d6b5-4426-aebb-5f80de78317b,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-0a48c213-1aa9-44bd-86d2-75c2cfa33820,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-c8dfae2d-d052-4cd4-953f-ee310bd6dc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-5415a955-c677-4501-9a17-b1c957418173,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-bd6f063f-d08e-47af-b9bc-a3af767d08be,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-2ec21f66-4011-427e-b7f6-b9462c09a0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-d1f9d81e-16b8-4fa5-8f4c-053a2bab1269,DISK], DatanodeInfoWithStorage[127.0.0.1:41568,DS-043982c1-65bc-4349-8d91-be42312e8746,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1123894053-172.17.0.9-1595552757684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42084,DS-00ebb40c-d6b5-4426-aebb-5f80de78317b,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-0a48c213-1aa9-44bd-86d2-75c2cfa33820,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-c8dfae2d-d052-4cd4-953f-ee310bd6dc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-5415a955-c677-4501-9a17-b1c957418173,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-bd6f063f-d08e-47af-b9bc-a3af767d08be,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-2ec21f66-4011-427e-b7f6-b9462c09a0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-d1f9d81e-16b8-4fa5-8f4c-053a2bab1269,DISK], DatanodeInfoWithStorage[127.0.0.1:41568,DS-043982c1-65bc-4349-8d91-be42312e8746,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1138888142-172.17.0.9-1595552971018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41682,DS-dd06b784-1016-491d-81d5-41da6acf3185,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-cd9c5786-22f1-4ccb-b4c0-0fbadcd255ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42878,DS-6a4879e7-bd17-4665-b034-4767ec5577f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-3d2d3fec-18fa-4b53-8335-8cb55447781d,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-4c2591c3-0c5d-4aac-8930-931fb1300478,DISK], DatanodeInfoWithStorage[127.0.0.1:34825,DS-14be8b63-e653-41aa-9764-349f74d40055,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-85e25596-da22-4d75-a1fd-e2ad6c4711bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-db0a3ea2-1529-4a84-9dd4-1fbef975d571,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1138888142-172.17.0.9-1595552971018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41682,DS-dd06b784-1016-491d-81d5-41da6acf3185,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-cd9c5786-22f1-4ccb-b4c0-0fbadcd255ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42878,DS-6a4879e7-bd17-4665-b034-4767ec5577f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-3d2d3fec-18fa-4b53-8335-8cb55447781d,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-4c2591c3-0c5d-4aac-8930-931fb1300478,DISK], DatanodeInfoWithStorage[127.0.0.1:34825,DS-14be8b63-e653-41aa-9764-349f74d40055,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-85e25596-da22-4d75-a1fd-e2ad6c4711bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-db0a3ea2-1529-4a84-9dd4-1fbef975d571,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2060191362-172.17.0.9-1595553126743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44534,DS-6bef0b83-cfc8-44dd-a11a-f4adf3181b58,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-d4813f35-4751-4d47-b77d-458beca4b955,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-30e63862-e5dc-4721-ae71-1b1356ee549c,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-6a2d0794-2c93-49e7-ba10-d2dc5024e9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-05cb2319-d491-42c4-b410-906b6a3a7017,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-153deba6-9692-4210-b737-d100a81120b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-49e4a623-e353-404d-a0d9-3203ad980a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-1a422832-ed00-4c1a-9177-fc0b3eb04250,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2060191362-172.17.0.9-1595553126743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44534,DS-6bef0b83-cfc8-44dd-a11a-f4adf3181b58,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-d4813f35-4751-4d47-b77d-458beca4b955,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-30e63862-e5dc-4721-ae71-1b1356ee549c,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-6a2d0794-2c93-49e7-ba10-d2dc5024e9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-05cb2319-d491-42c4-b410-906b6a3a7017,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-153deba6-9692-4210-b737-d100a81120b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-49e4a623-e353-404d-a0d9-3203ad980a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-1a422832-ed00-4c1a-9177-fc0b3eb04250,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-38623997-172.17.0.9-1595553307028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46009,DS-662664e0-865c-4cc7-a80c-ed0b0c2c4479,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-927245aa-0e5e-423d-921c-77ee27860e32,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-1753022d-37f6-48bb-98c7-2c05c52220a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-c29480fc-2923-41cc-baf2-51cc2a40cb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-183f9dd5-e5f6-4d70-959f-88fde02bdaf3,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-31d744f6-4695-4485-a0d5-65466ba3aaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-3dd3f48f-cd95-4a40-8148-c81b93bd7f17,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-dd0c0214-9098-4798-ad5e-d43e4fb46163,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-38623997-172.17.0.9-1595553307028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46009,DS-662664e0-865c-4cc7-a80c-ed0b0c2c4479,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-927245aa-0e5e-423d-921c-77ee27860e32,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-1753022d-37f6-48bb-98c7-2c05c52220a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-c29480fc-2923-41cc-baf2-51cc2a40cb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-183f9dd5-e5f6-4d70-959f-88fde02bdaf3,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-31d744f6-4695-4485-a0d5-65466ba3aaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-3dd3f48f-cd95-4a40-8148-c81b93bd7f17,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-dd0c0214-9098-4798-ad5e-d43e4fb46163,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1378533110-172.17.0.9-1595553589672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46849,DS-e4837dc4-9462-48f8-abf4-3626de2307ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-689722b2-327e-4347-a75f-3dd90310a3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-43e0b9d5-8fc9-449b-a771-714f570b08d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38302,DS-5871c9e4-748a-48e9-b08a-f0ff9db1690f,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-7ee9455e-03f3-4343-9c73-a53ba7fba8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44045,DS-2214a27c-2702-4f9a-9f25-db2972b44921,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-ff32ebcc-7ab3-4bdc-8b9e-205138ed2e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-ed59d4f6-9cbf-4a16-8302-4562809086af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1378533110-172.17.0.9-1595553589672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46849,DS-e4837dc4-9462-48f8-abf4-3626de2307ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-689722b2-327e-4347-a75f-3dd90310a3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-43e0b9d5-8fc9-449b-a771-714f570b08d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38302,DS-5871c9e4-748a-48e9-b08a-f0ff9db1690f,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-7ee9455e-03f3-4343-9c73-a53ba7fba8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44045,DS-2214a27c-2702-4f9a-9f25-db2972b44921,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-ff32ebcc-7ab3-4bdc-8b9e-205138ed2e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-ed59d4f6-9cbf-4a16-8302-4562809086af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1707890733-172.17.0.9-1595553627245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46151,DS-832a6083-deee-463b-aa18-2f0da6a6e367,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-be676d29-3277-4831-8a28-aa7758df6d69,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-6e6c57da-ce56-4936-aec3-10750659606b,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-9b4e3522-ae61-4648-8161-290325977a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-58e336c5-e549-43f0-b381-40d771e4f9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35514,DS-5c8e24d6-742a-439c-a907-38b9cd4c62f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-8a145694-11f5-44c9-bc85-6d2dfeb0c8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-cfb3f6eb-7bf9-4815-8a06-2c6f3f7c4850,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1707890733-172.17.0.9-1595553627245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46151,DS-832a6083-deee-463b-aa18-2f0da6a6e367,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-be676d29-3277-4831-8a28-aa7758df6d69,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-6e6c57da-ce56-4936-aec3-10750659606b,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-9b4e3522-ae61-4648-8161-290325977a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-58e336c5-e549-43f0-b381-40d771e4f9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35514,DS-5c8e24d6-742a-439c-a907-38b9cd4c62f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-8a145694-11f5-44c9-bc85-6d2dfeb0c8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-cfb3f6eb-7bf9-4815-8a06-2c6f3f7c4850,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1718647188-172.17.0.9-1595553773781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38076,DS-9998bc31-7420-4ce8-a7a7-c24bf3cbc293,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-a738baba-b20f-496f-a323-368f9aff0156,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-d7c8bf9b-5558-46d2-a224-c57516efcd04,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-81c1e133-6b23-4cc8-ae2c-c59624416753,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-d55d1b6d-15ff-426f-901e-594f6680802b,DISK], DatanodeInfoWithStorage[127.0.0.1:37846,DS-9f83205b-a37f-487b-b31d-02b998ec71ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42612,DS-618d7c5d-9a0d-49f2-b686-b8d921fd8e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-4109ab64-5f75-411c-b8b1-ecccd08b1904,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1718647188-172.17.0.9-1595553773781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38076,DS-9998bc31-7420-4ce8-a7a7-c24bf3cbc293,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-a738baba-b20f-496f-a323-368f9aff0156,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-d7c8bf9b-5558-46d2-a224-c57516efcd04,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-81c1e133-6b23-4cc8-ae2c-c59624416753,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-d55d1b6d-15ff-426f-901e-594f6680802b,DISK], DatanodeInfoWithStorage[127.0.0.1:37846,DS-9f83205b-a37f-487b-b31d-02b998ec71ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42612,DS-618d7c5d-9a0d-49f2-b686-b8d921fd8e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-4109ab64-5f75-411c-b8b1-ecccd08b1904,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2026634949-172.17.0.9-1595553985336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42066,DS-089e40cb-6b83-4271-ba1d-521b6b1340e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-4c696388-6eb4-438d-8b03-357c769a6dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-abeb01ff-4950-4cb7-ad8c-3910c7dac692,DISK], DatanodeInfoWithStorage[127.0.0.1:40333,DS-c75e2a27-d1e8-410c-bdbc-21294b34f0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-7ddaf57b-27f9-43be-9088-99082c6dc4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-d5961f86-5f44-4864-bda3-523d1796e495,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-48088363-db8e-462f-9f40-352711d4dddb,DISK], DatanodeInfoWithStorage[127.0.0.1:38872,DS-266f1174-96ce-44ca-a892-7a7c3e51f79a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2026634949-172.17.0.9-1595553985336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42066,DS-089e40cb-6b83-4271-ba1d-521b6b1340e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-4c696388-6eb4-438d-8b03-357c769a6dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-abeb01ff-4950-4cb7-ad8c-3910c7dac692,DISK], DatanodeInfoWithStorage[127.0.0.1:40333,DS-c75e2a27-d1e8-410c-bdbc-21294b34f0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-7ddaf57b-27f9-43be-9088-99082c6dc4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-d5961f86-5f44-4864-bda3-523d1796e495,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-48088363-db8e-462f-9f40-352711d4dddb,DISK], DatanodeInfoWithStorage[127.0.0.1:38872,DS-266f1174-96ce-44ca-a892-7a7c3e51f79a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2067782159-172.17.0.9-1595554020427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36542,DS-9a34690c-896a-4877-92e2-8412cff872c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-d8e8622a-8691-4bdf-8fba-0e5f571f493a,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-98a73ceb-71da-4732-9b32-c7e3d57a5dee,DISK], DatanodeInfoWithStorage[127.0.0.1:46233,DS-bf3df59b-f366-4b76-82a8-8ab9dde7542a,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-8c5fffab-4651-4112-90a0-18f8cf08e4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35184,DS-1b79f329-bb5b-4320-b595-ea7580085c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-b40b9384-b821-4280-8c93-ae81478c7ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-1e533475-fe49-4b6b-ac03-5c5d5b2ac002,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2067782159-172.17.0.9-1595554020427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36542,DS-9a34690c-896a-4877-92e2-8412cff872c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-d8e8622a-8691-4bdf-8fba-0e5f571f493a,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-98a73ceb-71da-4732-9b32-c7e3d57a5dee,DISK], DatanodeInfoWithStorage[127.0.0.1:46233,DS-bf3df59b-f366-4b76-82a8-8ab9dde7542a,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-8c5fffab-4651-4112-90a0-18f8cf08e4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35184,DS-1b79f329-bb5b-4320-b595-ea7580085c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-b40b9384-b821-4280-8c93-ae81478c7ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-1e533475-fe49-4b6b-ac03-5c5d5b2ac002,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1449812314-172.17.0.9-1595554150898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38332,DS-cb7ab693-515d-4784-822e-3e4096f7c76b,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-d3cc2b87-3533-401b-9f36-c16d86aba7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34696,DS-37540ffa-6c27-406d-9370-d313d46c5224,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-f6dd69b6-394c-4a56-9fd5-1d45432ec8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-580707d1-4f2e-401e-b791-dbf61746c600,DISK], DatanodeInfoWithStorage[127.0.0.1:36053,DS-1e1f3a11-e535-48c6-8165-70f369fcd9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-ca3e49be-9541-4642-90b2-7edc713bb8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-c8565058-d4d2-4130-8a1c-e519ba752b98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1449812314-172.17.0.9-1595554150898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38332,DS-cb7ab693-515d-4784-822e-3e4096f7c76b,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-d3cc2b87-3533-401b-9f36-c16d86aba7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34696,DS-37540ffa-6c27-406d-9370-d313d46c5224,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-f6dd69b6-394c-4a56-9fd5-1d45432ec8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-580707d1-4f2e-401e-b791-dbf61746c600,DISK], DatanodeInfoWithStorage[127.0.0.1:36053,DS-1e1f3a11-e535-48c6-8165-70f369fcd9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-ca3e49be-9541-4642-90b2-7edc713bb8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-c8565058-d4d2-4130-8a1c-e519ba752b98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1787715062-172.17.0.9-1595554517429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45461,DS-88a04b26-8f4f-413a-b4e5-6f45871e0ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-4722883a-82f6-42f9-9116-fe1c75c5852e,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-d27ee14a-9924-459f-865f-3a7eba94ca37,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-cd22f794-c263-48e2-8ba6-26af958e0fae,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-fe40f312-1197-432b-b1fe-7494cdb88077,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-d69a1c28-0ca9-4db2-a394-f2b3d9a1109b,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-f9a05abe-6b06-4114-b763-3fe89fd5ca03,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-ac059d3e-de40-48b4-bf74-9b35062dc515,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1787715062-172.17.0.9-1595554517429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45461,DS-88a04b26-8f4f-413a-b4e5-6f45871e0ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-4722883a-82f6-42f9-9116-fe1c75c5852e,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-d27ee14a-9924-459f-865f-3a7eba94ca37,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-cd22f794-c263-48e2-8ba6-26af958e0fae,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-fe40f312-1197-432b-b1fe-7494cdb88077,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-d69a1c28-0ca9-4db2-a394-f2b3d9a1109b,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-f9a05abe-6b06-4114-b763-3fe89fd5ca03,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-ac059d3e-de40-48b4-bf74-9b35062dc515,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1547928818-172.17.0.9-1595554749833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46224,DS-7acaa373-d1b3-4ffc-be11-061868286588,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-276d14f7-eb1a-4616-bdbf-f6473a56c5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39392,DS-8318f49d-cdbb-4b8e-a97d-c7dc129dcc74,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-22eb98d9-96dd-45d8-b590-f4ba15d4aea9,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-dae2f04c-e8ed-41b3-a68d-0110fe2fa416,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-dba2b31b-334e-4295-8b77-c78936bef9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-9cfb8fe3-b330-4d25-bd03-8b27007f973c,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-00c6c873-2566-4361-bd26-e6b7b5489d02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1547928818-172.17.0.9-1595554749833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46224,DS-7acaa373-d1b3-4ffc-be11-061868286588,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-276d14f7-eb1a-4616-bdbf-f6473a56c5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39392,DS-8318f49d-cdbb-4b8e-a97d-c7dc129dcc74,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-22eb98d9-96dd-45d8-b590-f4ba15d4aea9,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-dae2f04c-e8ed-41b3-a68d-0110fe2fa416,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-dba2b31b-334e-4295-8b77-c78936bef9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-9cfb8fe3-b330-4d25-bd03-8b27007f973c,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-00c6c873-2566-4361-bd26-e6b7b5489d02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1390978143-172.17.0.9-1595555553113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35127,DS-b3a84bac-a7a6-4da9-acd7-ff0a8239c4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34804,DS-67c0ea1e-81a3-4b2d-955a-c51371dbc53d,DISK], DatanodeInfoWithStorage[127.0.0.1:43835,DS-b9ba14c3-2030-471b-8620-170b978f35d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-915f6b10-7fb6-4438-8e52-323402170a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-024807d0-07b9-4435-b05f-cdcf67bb2066,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-88e90a1d-5194-4313-b101-fcd5b2e27a94,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-8ba6121c-2b09-4612-bcf6-f65bc8a73805,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-92f2b4fe-d969-43a6-8547-2a5dcb454c3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1390978143-172.17.0.9-1595555553113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35127,DS-b3a84bac-a7a6-4da9-acd7-ff0a8239c4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34804,DS-67c0ea1e-81a3-4b2d-955a-c51371dbc53d,DISK], DatanodeInfoWithStorage[127.0.0.1:43835,DS-b9ba14c3-2030-471b-8620-170b978f35d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-915f6b10-7fb6-4438-8e52-323402170a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-024807d0-07b9-4435-b05f-cdcf67bb2066,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-88e90a1d-5194-4313-b101-fcd5b2e27a94,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-8ba6121c-2b09-4612-bcf6-f65bc8a73805,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-92f2b4fe-d969-43a6-8547-2a5dcb454c3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1969493137-172.17.0.9-1595555814791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38919,DS-452e2ca4-df36-4e28-8cab-fe6bdb66a3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-ed7b0f18-76b0-4e50-a689-c7f350a2be14,DISK], DatanodeInfoWithStorage[127.0.0.1:33245,DS-de77660b-ce1d-4dc5-a9c2-b0c33b02856f,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-33f4ed5e-a3c1-47c0-8c70-d83afb4b28c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37080,DS-4dd6b954-82d1-4c5c-bc5e-7e9aa8b0f181,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-25130576-7b19-4690-a336-f76eb9cbd1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-54230935-ea46-4cf7-bc4c-b537e3dcbaa3,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-192c115e-f48f-4b7d-a332-f9e527309e3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1969493137-172.17.0.9-1595555814791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38919,DS-452e2ca4-df36-4e28-8cab-fe6bdb66a3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-ed7b0f18-76b0-4e50-a689-c7f350a2be14,DISK], DatanodeInfoWithStorage[127.0.0.1:33245,DS-de77660b-ce1d-4dc5-a9c2-b0c33b02856f,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-33f4ed5e-a3c1-47c0-8c70-d83afb4b28c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37080,DS-4dd6b954-82d1-4c5c-bc5e-7e9aa8b0f181,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-25130576-7b19-4690-a336-f76eb9cbd1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-54230935-ea46-4cf7-bc4c-b537e3dcbaa3,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-192c115e-f48f-4b7d-a332-f9e527309e3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5680
