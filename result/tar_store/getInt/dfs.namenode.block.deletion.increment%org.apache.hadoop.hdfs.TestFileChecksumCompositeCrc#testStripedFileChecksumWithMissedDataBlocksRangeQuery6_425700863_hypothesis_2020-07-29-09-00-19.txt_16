reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1330781110-172.17.0.4-1596013372429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33461,DS-12927f61-4fe7-4e1a-b888-719063aa53fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-7bfaad5d-ea65-4d03-a48d-be200cf75cac,DISK], DatanodeInfoWithStorage[127.0.0.1:37458,DS-6fb0797c-700f-4580-86d7-37910546f236,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-d9ab0cb7-e812-4c82-8592-ec311466aced,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-877f4c96-cc93-4615-b366-2b0b82f127e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-94957971-7ac4-48ef-8c72-9fa3847f520e,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-fc0e7720-069d-4eee-8a12-0b0f1ffb9bce,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-1c1bb564-76e7-4289-9410-7103a5215448,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1330781110-172.17.0.4-1596013372429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33461,DS-12927f61-4fe7-4e1a-b888-719063aa53fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-7bfaad5d-ea65-4d03-a48d-be200cf75cac,DISK], DatanodeInfoWithStorage[127.0.0.1:37458,DS-6fb0797c-700f-4580-86d7-37910546f236,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-d9ab0cb7-e812-4c82-8592-ec311466aced,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-877f4c96-cc93-4615-b366-2b0b82f127e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-94957971-7ac4-48ef-8c72-9fa3847f520e,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-fc0e7720-069d-4eee-8a12-0b0f1ffb9bce,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-1c1bb564-76e7-4289-9410-7103a5215448,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-147377948-172.17.0.4-1596013585407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37152,DS-70b3275e-2196-4bdc-aa5e-edb3de083d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-2dc6d9fc-2d88-413c-9af0-016d98e09b51,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-86caccbf-8ea9-4c18-a6ea-353fc6be23d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-c520ef4f-af31-4c3f-918b-36238a484926,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-a45aff6d-2b10-4719-b72d-976fff8059e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-f034127c-01ba-4bd3-ad00-51ed441cac65,DISK], DatanodeInfoWithStorage[127.0.0.1:38061,DS-728ba069-a49c-4d3b-a669-579fe0c27ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-0e2425a9-c276-43e2-ad7f-d4274b54d7bc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-147377948-172.17.0.4-1596013585407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37152,DS-70b3275e-2196-4bdc-aa5e-edb3de083d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-2dc6d9fc-2d88-413c-9af0-016d98e09b51,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-86caccbf-8ea9-4c18-a6ea-353fc6be23d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-c520ef4f-af31-4c3f-918b-36238a484926,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-a45aff6d-2b10-4719-b72d-976fff8059e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-f034127c-01ba-4bd3-ad00-51ed441cac65,DISK], DatanodeInfoWithStorage[127.0.0.1:38061,DS-728ba069-a49c-4d3b-a669-579fe0c27ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-0e2425a9-c276-43e2-ad7f-d4274b54d7bc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-707151586-172.17.0.4-1596013630006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36869,DS-82385842-27e2-48c2-901a-a624a2c35377,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-cc81db57-9496-4288-abdb-c99e2e622c92,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-b84407ba-5f87-4c83-9f8e-6ca1669398f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-96b42a6e-4f3f-4f93-977c-2a0b28f51c51,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-bfabe9c3-473b-45c1-aed5-83fbb706102c,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-c13031a3-5ca7-46af-9232-d2ac1d288f51,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-2378e3f3-969e-41d4-ba14-1cb0600dc21b,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-404682b4-16bb-4baa-a816-2bcc370f4646,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-707151586-172.17.0.4-1596013630006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36869,DS-82385842-27e2-48c2-901a-a624a2c35377,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-cc81db57-9496-4288-abdb-c99e2e622c92,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-b84407ba-5f87-4c83-9f8e-6ca1669398f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-96b42a6e-4f3f-4f93-977c-2a0b28f51c51,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-bfabe9c3-473b-45c1-aed5-83fbb706102c,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-c13031a3-5ca7-46af-9232-d2ac1d288f51,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-2378e3f3-969e-41d4-ba14-1cb0600dc21b,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-404682b4-16bb-4baa-a816-2bcc370f4646,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1917522687-172.17.0.4-1596013973845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37474,DS-eff499d5-1bf6-4a77-ad91-7ff7ede11f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38145,DS-f6abefc9-e662-41a5-b4f8-17627cd489c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-da0cd886-fed4-4485-b7ef-b8b33e186b70,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-b37622b6-8fcc-4e82-9125-188127114161,DISK], DatanodeInfoWithStorage[127.0.0.1:34437,DS-a40f4883-394f-4908-bc29-ce2741f77219,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-04fa6b49-9d44-4202-ba43-3ba530db54ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-c3216779-bd56-4e4c-a15f-ca17ac2c8ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-d20be75b-608e-4375-8fa7-bfc3a76a4f32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1917522687-172.17.0.4-1596013973845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37474,DS-eff499d5-1bf6-4a77-ad91-7ff7ede11f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38145,DS-f6abefc9-e662-41a5-b4f8-17627cd489c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-da0cd886-fed4-4485-b7ef-b8b33e186b70,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-b37622b6-8fcc-4e82-9125-188127114161,DISK], DatanodeInfoWithStorage[127.0.0.1:34437,DS-a40f4883-394f-4908-bc29-ce2741f77219,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-04fa6b49-9d44-4202-ba43-3ba530db54ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-c3216779-bd56-4e4c-a15f-ca17ac2c8ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-d20be75b-608e-4375-8fa7-bfc3a76a4f32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-730123765-172.17.0.4-1596014005001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36339,DS-ee9bef13-0ab8-4bc0-a211-d278af892147,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-9d2666fd-d360-49f9-b2be-ad8acf0f71c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44815,DS-c2defac0-b50c-4c23-9f9d-f153514d69e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-8dece1b7-eb0d-492c-a964-cca5997cacd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-95565209-e684-4373-b608-46363f8e8460,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-22c24303-7ea7-441b-9af8-b88eb9af55ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-1ec515c3-aab6-497c-9eac-308eefcc1998,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-5170d8e7-ead9-4fb6-8a9c-c08fb9e92af4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-730123765-172.17.0.4-1596014005001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36339,DS-ee9bef13-0ab8-4bc0-a211-d278af892147,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-9d2666fd-d360-49f9-b2be-ad8acf0f71c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44815,DS-c2defac0-b50c-4c23-9f9d-f153514d69e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-8dece1b7-eb0d-492c-a964-cca5997cacd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-95565209-e684-4373-b608-46363f8e8460,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-22c24303-7ea7-441b-9af8-b88eb9af55ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-1ec515c3-aab6-497c-9eac-308eefcc1998,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-5170d8e7-ead9-4fb6-8a9c-c08fb9e92af4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-241038282-172.17.0.4-1596014046968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36607,DS-7c41aafa-c67c-4aa3-a5f3-b71cf9bd3d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-8239f4d5-58d0-4ad3-a408-3c2ce009625d,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-6078240e-562f-4aba-9e8f-adbe3428e80c,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-e50a49f0-cb56-43f2-8ed8-7494826edce7,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-8da6886b-33c0-4f41-b6bc-dd842fd76646,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-a19a465e-f4fd-4d3a-a110-b4e0a1274b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-98e50813-82e6-49c4-8a4a-6c08610a5e77,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-b9174950-937d-4f33-a32d-21c318a33796,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-241038282-172.17.0.4-1596014046968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36607,DS-7c41aafa-c67c-4aa3-a5f3-b71cf9bd3d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-8239f4d5-58d0-4ad3-a408-3c2ce009625d,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-6078240e-562f-4aba-9e8f-adbe3428e80c,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-e50a49f0-cb56-43f2-8ed8-7494826edce7,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-8da6886b-33c0-4f41-b6bc-dd842fd76646,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-a19a465e-f4fd-4d3a-a110-b4e0a1274b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-98e50813-82e6-49c4-8a4a-6c08610a5e77,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-b9174950-937d-4f33-a32d-21c318a33796,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1362130598-172.17.0.4-1596014129081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42319,DS-ed5e1205-33fd-426f-95d8-8bedd50535a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-2706c530-a41e-4e52-aff5-26b521543f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-6787146d-6759-4b7c-80e1-08bfed7b65ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41122,DS-1a722dd4-8509-4d85-b232-5815d388f4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-81354cbc-1bfd-46e2-beee-a9cc4a9a142c,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-06972f67-bbcb-4b72-a465-ff2d1f791613,DISK], DatanodeInfoWithStorage[127.0.0.1:40461,DS-fa0561a6-1654-42a0-8e30-c2e07d06f59a,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-78f11b9b-af00-459d-a327-8c9ee2df2b6a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1362130598-172.17.0.4-1596014129081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42319,DS-ed5e1205-33fd-426f-95d8-8bedd50535a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-2706c530-a41e-4e52-aff5-26b521543f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-6787146d-6759-4b7c-80e1-08bfed7b65ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41122,DS-1a722dd4-8509-4d85-b232-5815d388f4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-81354cbc-1bfd-46e2-beee-a9cc4a9a142c,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-06972f67-bbcb-4b72-a465-ff2d1f791613,DISK], DatanodeInfoWithStorage[127.0.0.1:40461,DS-fa0561a6-1654-42a0-8e30-c2e07d06f59a,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-78f11b9b-af00-459d-a327-8c9ee2df2b6a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1725322042-172.17.0.4-1596014228481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46248,DS-5f8d89cb-226d-4e89-90cd-79a9f13d5f85,DISK], DatanodeInfoWithStorage[127.0.0.1:44636,DS-7a57431d-a4af-4e7b-96aa-804a1910131e,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-35936e17-0dbc-45b8-b316-b7230f442036,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-defaf4db-eacb-4ba2-8026-275325858f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-306a9d98-31b2-4207-b3a3-512225d9e7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-f566b81c-bb4a-45c4-a416-b5792b930c98,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-77187da3-9562-4e35-aade-38dfb0ba57c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-0d4c339c-a059-4a26-bbe6-eb60886d4c0b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1725322042-172.17.0.4-1596014228481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46248,DS-5f8d89cb-226d-4e89-90cd-79a9f13d5f85,DISK], DatanodeInfoWithStorage[127.0.0.1:44636,DS-7a57431d-a4af-4e7b-96aa-804a1910131e,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-35936e17-0dbc-45b8-b316-b7230f442036,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-defaf4db-eacb-4ba2-8026-275325858f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-306a9d98-31b2-4207-b3a3-512225d9e7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-f566b81c-bb4a-45c4-a416-b5792b930c98,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-77187da3-9562-4e35-aade-38dfb0ba57c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-0d4c339c-a059-4a26-bbe6-eb60886d4c0b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-58684526-172.17.0.4-1596014324741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41057,DS-69bbd835-4690-4605-8563-1237b2dcc048,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-7135036d-0180-4865-b0d0-f445c581ddbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38726,DS-70e512a7-6cd8-46ff-8905-62284c472f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-696a85fd-cf3e-44f1-8e53-5cdcf0ee69ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-9a3593f0-125b-47d5-a77b-4e8750a34774,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-1c2cc487-2375-4862-a9c0-b3c7f5bea1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-b60e3c95-6ddb-4fb0-8e42-f852f3e64152,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-e1516bc9-ead1-43d6-8bef-1a02ab0fda03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-58684526-172.17.0.4-1596014324741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41057,DS-69bbd835-4690-4605-8563-1237b2dcc048,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-7135036d-0180-4865-b0d0-f445c581ddbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38726,DS-70e512a7-6cd8-46ff-8905-62284c472f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-696a85fd-cf3e-44f1-8e53-5cdcf0ee69ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-9a3593f0-125b-47d5-a77b-4e8750a34774,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-1c2cc487-2375-4862-a9c0-b3c7f5bea1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-b60e3c95-6ddb-4fb0-8e42-f852f3e64152,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-e1516bc9-ead1-43d6-8bef-1a02ab0fda03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-878589742-172.17.0.4-1596014508451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42204,DS-885bc313-6669-4bf1-965e-f76780d5f456,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-338a58c3-3af3-42b1-b358-be43476b2397,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-79f457cb-c6a8-469b-991d-7090ce907ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-dcff7397-901c-49c1-bb7c-464290e57b12,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-3480f871-f6eb-4842-8037-ff6b08bd1b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-d5dd3c7b-197e-4ff1-b6ab-9ab096c5ab00,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-73e72fe4-cf99-43f2-9946-babbbcda54de,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-772dcf9e-b75d-4c8c-af0e-dfc496ba0b76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-878589742-172.17.0.4-1596014508451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42204,DS-885bc313-6669-4bf1-965e-f76780d5f456,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-338a58c3-3af3-42b1-b358-be43476b2397,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-79f457cb-c6a8-469b-991d-7090ce907ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-dcff7397-901c-49c1-bb7c-464290e57b12,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-3480f871-f6eb-4842-8037-ff6b08bd1b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-d5dd3c7b-197e-4ff1-b6ab-9ab096c5ab00,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-73e72fe4-cf99-43f2-9946-babbbcda54de,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-772dcf9e-b75d-4c8c-af0e-dfc496ba0b76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1100924917-172.17.0.4-1596014638768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40896,DS-18576fe8-cf87-431f-9b8f-2e133ca74371,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-13dd40ba-ed1b-4417-83e9-c106eed65998,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-c60209b8-60d2-4b81-ab45-2f2ac3b274ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44673,DS-ec5e79d3-016f-46f7-9893-c48850f5d548,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-ae3bcf84-527b-4cce-b635-71ea43d193d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-0ba7b721-113f-4f8d-94d2-d8b2504cea2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-df64e05f-00be-475c-a655-8c1538eea4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-35bf4cc3-1bf8-44f9-b992-1b4af7b94170,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1100924917-172.17.0.4-1596014638768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40896,DS-18576fe8-cf87-431f-9b8f-2e133ca74371,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-13dd40ba-ed1b-4417-83e9-c106eed65998,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-c60209b8-60d2-4b81-ab45-2f2ac3b274ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44673,DS-ec5e79d3-016f-46f7-9893-c48850f5d548,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-ae3bcf84-527b-4cce-b635-71ea43d193d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-0ba7b721-113f-4f8d-94d2-d8b2504cea2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-df64e05f-00be-475c-a655-8c1538eea4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-35bf4cc3-1bf8-44f9-b992-1b4af7b94170,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1227650021-172.17.0.4-1596014831475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43869,DS-7a73ff97-6e0a-4a80-8b79-7e854e45d544,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-a163401f-98ab-44ee-8623-0532a97ed0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-1af5d757-4ce2-464c-b391-b24bf93c63f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-29493f61-603d-4483-8716-8cbd364069d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-97b3f176-62ee-40b9-8e39-76a17f9f5b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-0d7bf0bb-6b83-49b5-83ff-6f7f315b5bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-22a2e3f9-fb50-4f84-9302-3143e62b7591,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-76a72496-d9de-4364-a5d5-a8d709fd39e6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1227650021-172.17.0.4-1596014831475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43869,DS-7a73ff97-6e0a-4a80-8b79-7e854e45d544,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-a163401f-98ab-44ee-8623-0532a97ed0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-1af5d757-4ce2-464c-b391-b24bf93c63f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-29493f61-603d-4483-8716-8cbd364069d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-97b3f176-62ee-40b9-8e39-76a17f9f5b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-0d7bf0bb-6b83-49b5-83ff-6f7f315b5bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-22a2e3f9-fb50-4f84-9302-3143e62b7591,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-76a72496-d9de-4364-a5d5-a8d709fd39e6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-880640214-172.17.0.4-1596014966779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42056,DS-d0efabca-7e19-459a-94a9-cc84c3d6bd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-75c93c1a-924d-4c2a-a21f-bd18da8ae68a,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-e050149c-71ca-48a7-8202-15b937f239e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-6d14e50f-e8d9-477b-86e4-36539c88faac,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-02999f41-8779-437b-a429-aa9f1304c175,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-e22e2ae3-2b4a-4903-b639-b7d7532cac1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-f63c0b73-f407-4ef8-be8a-87e0236c275b,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-42d15050-d8f6-40d2-9815-c8b8c7c7ab9e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-880640214-172.17.0.4-1596014966779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42056,DS-d0efabca-7e19-459a-94a9-cc84c3d6bd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-75c93c1a-924d-4c2a-a21f-bd18da8ae68a,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-e050149c-71ca-48a7-8202-15b937f239e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-6d14e50f-e8d9-477b-86e4-36539c88faac,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-02999f41-8779-437b-a429-aa9f1304c175,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-e22e2ae3-2b4a-4903-b639-b7d7532cac1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-f63c0b73-f407-4ef8-be8a-87e0236c275b,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-42d15050-d8f6-40d2-9815-c8b8c7c7ab9e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951772905-172.17.0.4-1596015011385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38615,DS-a02462a9-cb63-4360-bfaf-becd1a516114,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-e56949b1-37b9-430d-a699-f04836e1c506,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-a98dd6f3-3984-4769-99bb-94c3314617a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-e795211f-23b8-4c87-a623-2522d908658f,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-5831b3cc-4788-401a-ad66-33d51bb50d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-6a8ed184-20ae-448d-be53-b6e526668cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-c96f2972-7c7a-493d-853b-77fbf3cc058a,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-8af87971-18f9-4ecb-b714-a44d93e8097b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951772905-172.17.0.4-1596015011385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38615,DS-a02462a9-cb63-4360-bfaf-becd1a516114,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-e56949b1-37b9-430d-a699-f04836e1c506,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-a98dd6f3-3984-4769-99bb-94c3314617a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-e795211f-23b8-4c87-a623-2522d908658f,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-5831b3cc-4788-401a-ad66-33d51bb50d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-6a8ed184-20ae-448d-be53-b6e526668cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-c96f2972-7c7a-493d-853b-77fbf3cc058a,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-8af87971-18f9-4ecb-b714-a44d93e8097b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1994135615-172.17.0.4-1596015105447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45817,DS-fdaf1237-262a-4a45-ab23-58ffae8c8d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34470,DS-c5169ebf-2566-4da0-ae90-cc653c10c50c,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-3cd33ad4-8d7e-4eaf-9b51-52867ae53017,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-dde327df-8ff5-4b5b-9d6d-b3f35df5a0de,DISK], DatanodeInfoWithStorage[127.0.0.1:42617,DS-85d43c3b-e731-40bb-95e4-5764f11bcf1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36454,DS-7dd86e3a-1bab-4d3b-99d9-5c48b57eeef9,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-2ca21e6d-c0e6-4b06-86bc-ad7e30e26316,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-096ec1e4-1ba5-48f5-b72e-8c222361a134,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1994135615-172.17.0.4-1596015105447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45817,DS-fdaf1237-262a-4a45-ab23-58ffae8c8d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34470,DS-c5169ebf-2566-4da0-ae90-cc653c10c50c,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-3cd33ad4-8d7e-4eaf-9b51-52867ae53017,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-dde327df-8ff5-4b5b-9d6d-b3f35df5a0de,DISK], DatanodeInfoWithStorage[127.0.0.1:42617,DS-85d43c3b-e731-40bb-95e4-5764f11bcf1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36454,DS-7dd86e3a-1bab-4d3b-99d9-5c48b57eeef9,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-2ca21e6d-c0e6-4b06-86bc-ad7e30e26316,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-096ec1e4-1ba5-48f5-b72e-8c222361a134,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-115188100-172.17.0.4-1596015148406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40007,DS-8caaf538-1a2d-447a-afd7-52565cf7ba1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-bf609383-4816-4f5e-8387-536421676eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40847,DS-6115b1ab-7a82-4ed7-9156-1c8f70b418f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-265a12a6-9d95-4f8e-a170-62092aff5f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-8158b046-89ba-4db7-9a60-6d188a73a464,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-f199fa2e-7843-4ad8-97e1-772cab8323ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-2f3811ac-f56e-43c8-ac39-c41aa7bc2f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-6688904d-c8d4-4d4b-8efb-971b10ed53f5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-115188100-172.17.0.4-1596015148406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40007,DS-8caaf538-1a2d-447a-afd7-52565cf7ba1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-bf609383-4816-4f5e-8387-536421676eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40847,DS-6115b1ab-7a82-4ed7-9156-1c8f70b418f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-265a12a6-9d95-4f8e-a170-62092aff5f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-8158b046-89ba-4db7-9a60-6d188a73a464,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-f199fa2e-7843-4ad8-97e1-772cab8323ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-2f3811ac-f56e-43c8-ac39-c41aa7bc2f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-6688904d-c8d4-4d4b-8efb-971b10ed53f5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-559748299-172.17.0.4-1596015229213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37339,DS-b9740553-a8e1-4501-9ec0-92f113d6c206,DISK], DatanodeInfoWithStorage[127.0.0.1:39418,DS-123ad733-5dd2-4a58-8c12-2f86fab786fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-28cdf06d-3c49-4d71-892a-7d5c7f7ab22e,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-e2cac90c-1189-4de9-b702-7affb98e1e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-85c9bb8e-d7ad-405a-995f-74756f7b2939,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-b39898be-6cf1-4263-b72a-8afa1fbba9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-5014a59a-aebf-4cdd-bb90-5595aec947c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-8e2d273c-9f6e-4baf-8b2d-1c63eb92e4cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-559748299-172.17.0.4-1596015229213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37339,DS-b9740553-a8e1-4501-9ec0-92f113d6c206,DISK], DatanodeInfoWithStorage[127.0.0.1:39418,DS-123ad733-5dd2-4a58-8c12-2f86fab786fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-28cdf06d-3c49-4d71-892a-7d5c7f7ab22e,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-e2cac90c-1189-4de9-b702-7affb98e1e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-85c9bb8e-d7ad-405a-995f-74756f7b2939,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-b39898be-6cf1-4263-b72a-8afa1fbba9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-5014a59a-aebf-4cdd-bb90-5595aec947c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-8e2d273c-9f6e-4baf-8b2d-1c63eb92e4cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-32078271-172.17.0.4-1596015277272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33143,DS-6551987b-5e89-47f6-ac33-cfb312da609c,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-4b91d7ac-aade-4088-b409-8d5fe9a2dd5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-5f42caa9-353b-4876-a373-a6d2e60e7005,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-7197a596-21cd-40a5-84f9-c68f110c94a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-709dd3f6-0173-4a41-abc5-180ea39d3402,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-9a090976-69b0-46f1-942a-f88f1c363b28,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-1b6a2dc1-974a-47e0-9bad-1c7d8b123c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-f9897e65-c8b4-428f-b853-fa42f6ec164c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-32078271-172.17.0.4-1596015277272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33143,DS-6551987b-5e89-47f6-ac33-cfb312da609c,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-4b91d7ac-aade-4088-b409-8d5fe9a2dd5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-5f42caa9-353b-4876-a373-a6d2e60e7005,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-7197a596-21cd-40a5-84f9-c68f110c94a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-709dd3f6-0173-4a41-abc5-180ea39d3402,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-9a090976-69b0-46f1-942a-f88f1c363b28,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-1b6a2dc1-974a-47e0-9bad-1c7d8b123c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-f9897e65-c8b4-428f-b853-fa42f6ec164c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-251401528-172.17.0.4-1596015613613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36067,DS-d7caff5e-57df-407c-acb2-62f7fcba3fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-2dc2797a-aca5-4f55-9e1c-f3c3c1fb23ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46047,DS-51436f24-b889-4bbc-a460-93cc76fd13ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43908,DS-e02dbdb8-b459-4238-af57-9c4f7096e704,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-75c121d1-010d-4059-abb5-27fdf183c035,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-0db75249-dafc-4fae-930c-289e6b7165cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-e4720b5e-d43b-4f44-8c61-ff6aee329d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-7f801ff7-91e3-4b88-a5bc-3bb1ff6e0eff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-251401528-172.17.0.4-1596015613613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36067,DS-d7caff5e-57df-407c-acb2-62f7fcba3fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-2dc2797a-aca5-4f55-9e1c-f3c3c1fb23ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46047,DS-51436f24-b889-4bbc-a460-93cc76fd13ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43908,DS-e02dbdb8-b459-4238-af57-9c4f7096e704,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-75c121d1-010d-4059-abb5-27fdf183c035,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-0db75249-dafc-4fae-930c-289e6b7165cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-e4720b5e-d43b-4f44-8c61-ff6aee329d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-7f801ff7-91e3-4b88-a5bc-3bb1ff6e0eff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1174849798-172.17.0.4-1596015771664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34935,DS-22a8a920-f237-4116-95e6-1db5d433d0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-a3b0ede4-9326-42af-8280-5216beaa16dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-576b752f-c931-4901-9d8b-582cfd7c75a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-309c084f-0fe0-4ec6-921e-3fbd4a6d736c,DISK], DatanodeInfoWithStorage[127.0.0.1:33533,DS-5e2d796d-fc2d-4e2e-86c2-756819165bee,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-ed1538d3-e2c6-486c-aa3f-2088a487e080,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-acfd62cf-7e9e-4463-9463-b5718091a4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-b29f0d36-6e17-4e6c-9e07-b5316befb721,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1174849798-172.17.0.4-1596015771664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34935,DS-22a8a920-f237-4116-95e6-1db5d433d0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-a3b0ede4-9326-42af-8280-5216beaa16dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-576b752f-c931-4901-9d8b-582cfd7c75a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-309c084f-0fe0-4ec6-921e-3fbd4a6d736c,DISK], DatanodeInfoWithStorage[127.0.0.1:33533,DS-5e2d796d-fc2d-4e2e-86c2-756819165bee,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-ed1538d3-e2c6-486c-aa3f-2088a487e080,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-acfd62cf-7e9e-4463-9463-b5718091a4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-b29f0d36-6e17-4e6c-9e07-b5316befb721,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1588794389-172.17.0.4-1596015897346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41081,DS-4016937b-8259-49c8-8e5a-4b9be50bf250,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-6b171343-67a7-44b5-b9e0-6c30a20cfa7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-135dd4aa-a971-4836-8c1c-74ffc7c77479,DISK], DatanodeInfoWithStorage[127.0.0.1:39335,DS-9070dd20-10b1-403e-802f-74074c2bbb47,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-34a8ea77-af18-4e57-93e3-3b1a0e04cece,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-e92cef3d-78dc-4fb8-8252-ea680b27c6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-5e996c0f-541b-43eb-b106-570169e00e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-189f91be-b69c-4bb8-be69-5fa83f7d7e68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1588794389-172.17.0.4-1596015897346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41081,DS-4016937b-8259-49c8-8e5a-4b9be50bf250,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-6b171343-67a7-44b5-b9e0-6c30a20cfa7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-135dd4aa-a971-4836-8c1c-74ffc7c77479,DISK], DatanodeInfoWithStorage[127.0.0.1:39335,DS-9070dd20-10b1-403e-802f-74074c2bbb47,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-34a8ea77-af18-4e57-93e3-3b1a0e04cece,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-e92cef3d-78dc-4fb8-8252-ea680b27c6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-5e996c0f-541b-43eb-b106-570169e00e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-189f91be-b69c-4bb8-be69-5fa83f7d7e68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879727399-172.17.0.4-1596016149859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42463,DS-5db7fdde-e2e0-4405-8d5b-1fa7eb981872,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-29c3d861-daeb-4f9f-88ba-133ce1f400c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35342,DS-f5884cd7-5989-497e-acba-f8e1b38fb6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45473,DS-a7ef2793-cdd2-49b4-b27f-28c60304e590,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-9b822115-0c5c-4314-ae15-8592bf464842,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-6ac8b7a6-2938-4751-9f52-015c7b0fb5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38781,DS-2844892a-ef43-438e-8b01-69f0e16ed692,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-052435dd-ee40-4d40-9830-60e1297dd35f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879727399-172.17.0.4-1596016149859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42463,DS-5db7fdde-e2e0-4405-8d5b-1fa7eb981872,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-29c3d861-daeb-4f9f-88ba-133ce1f400c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35342,DS-f5884cd7-5989-497e-acba-f8e1b38fb6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45473,DS-a7ef2793-cdd2-49b4-b27f-28c60304e590,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-9b822115-0c5c-4314-ae15-8592bf464842,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-6ac8b7a6-2938-4751-9f52-015c7b0fb5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38781,DS-2844892a-ef43-438e-8b01-69f0e16ed692,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-052435dd-ee40-4d40-9830-60e1297dd35f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2073780156-172.17.0.4-1596016403342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41313,DS-44ef541b-085a-49bd-8c3f-5f4ddc373692,DISK], DatanodeInfoWithStorage[127.0.0.1:37482,DS-723080fc-0a1a-43d7-913f-b6703047fae9,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-bb990516-1cad-48ec-9ca2-e7d34b9c693b,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-8de88664-93b3-4600-8aac-eaa952de8f17,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-4f36693d-9877-443e-880c-60ae1b7c4b49,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-691b425c-d139-4887-a4ab-4d1cc9b17ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-d4b314ed-e64f-4264-b9a6-b90fdb4957d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-1d78d6b9-ff18-445c-8978-00eac58bc325,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2073780156-172.17.0.4-1596016403342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41313,DS-44ef541b-085a-49bd-8c3f-5f4ddc373692,DISK], DatanodeInfoWithStorage[127.0.0.1:37482,DS-723080fc-0a1a-43d7-913f-b6703047fae9,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-bb990516-1cad-48ec-9ca2-e7d34b9c693b,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-8de88664-93b3-4600-8aac-eaa952de8f17,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-4f36693d-9877-443e-880c-60ae1b7c4b49,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-691b425c-d139-4887-a4ab-4d1cc9b17ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-d4b314ed-e64f-4264-b9a6-b90fdb4957d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-1d78d6b9-ff18-445c-8978-00eac58bc325,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-96164144-172.17.0.4-1596016636122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33791,DS-3274fb11-0085-4929-9998-ab2537e2b4da,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-beb28717-cbb1-4b2f-b7e9-7701bf72c85d,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-8a34e0e4-8341-4639-a237-007d12189bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-0a15bc65-65b1-4b06-90f2-9ae635abbf81,DISK], DatanodeInfoWithStorage[127.0.0.1:45243,DS-97735fcb-2d9a-4297-bb6e-cde08e5487ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36578,DS-8815b974-51c4-4a3d-9324-cfb61da56b58,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-6534c652-75e3-4b11-a610-d2fe590efe57,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-4f005fb7-f163-4c5c-b8fb-b4aba76273cc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-96164144-172.17.0.4-1596016636122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33791,DS-3274fb11-0085-4929-9998-ab2537e2b4da,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-beb28717-cbb1-4b2f-b7e9-7701bf72c85d,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-8a34e0e4-8341-4639-a237-007d12189bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-0a15bc65-65b1-4b06-90f2-9ae635abbf81,DISK], DatanodeInfoWithStorage[127.0.0.1:45243,DS-97735fcb-2d9a-4297-bb6e-cde08e5487ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36578,DS-8815b974-51c4-4a3d-9324-cfb61da56b58,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-6534c652-75e3-4b11-a610-d2fe590efe57,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-4f005fb7-f163-4c5c-b8fb-b4aba76273cc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1161134446-172.17.0.4-1596016806028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45988,DS-629a871f-151d-47dc-b25e-63b385312e13,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-da3a4130-0eb1-4818-971e-86737af2f668,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-d05148e5-f6a1-49ab-b171-1d40fab7c302,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-49fcd0da-fdf3-40df-b6c8-6282a285469a,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-5b109d2a-e20f-4a1d-b885-877f8a4bb8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-748722c9-8f65-4b8a-8bd5-4c85ac639804,DISK], DatanodeInfoWithStorage[127.0.0.1:36796,DS-dbab1fc8-7ee7-4b10-8f53-216de4c393f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43115,DS-e51686ad-3b7c-44f7-a564-97cd17ad12c6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1161134446-172.17.0.4-1596016806028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45988,DS-629a871f-151d-47dc-b25e-63b385312e13,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-da3a4130-0eb1-4818-971e-86737af2f668,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-d05148e5-f6a1-49ab-b171-1d40fab7c302,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-49fcd0da-fdf3-40df-b6c8-6282a285469a,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-5b109d2a-e20f-4a1d-b885-877f8a4bb8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-748722c9-8f65-4b8a-8bd5-4c85ac639804,DISK], DatanodeInfoWithStorage[127.0.0.1:36796,DS-dbab1fc8-7ee7-4b10-8f53-216de4c393f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43115,DS-e51686ad-3b7c-44f7-a564-97cd17ad12c6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-455739099-172.17.0.4-1596017168487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40905,DS-a2fc0f3f-9c38-4a16-805a-1196bccfba55,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-ff069c5b-9d9f-4ff7-811f-cf184b5797ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-3a2ae617-6ef3-4340-b64a-6d71a8f0fb8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-bc9728fe-953c-4d24-89e5-f95c0e2752a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-27ba1e57-338b-4eed-ae2a-52d74b237135,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-f310823a-7a0f-4c19-8f30-6fdea1745bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-b804b613-db99-4bb7-b805-296b2ca8c5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-01b689cf-2256-442c-a716-2ef764343ce8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-455739099-172.17.0.4-1596017168487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40905,DS-a2fc0f3f-9c38-4a16-805a-1196bccfba55,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-ff069c5b-9d9f-4ff7-811f-cf184b5797ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-3a2ae617-6ef3-4340-b64a-6d71a8f0fb8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-bc9728fe-953c-4d24-89e5-f95c0e2752a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-27ba1e57-338b-4eed-ae2a-52d74b237135,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-f310823a-7a0f-4c19-8f30-6fdea1745bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-b804b613-db99-4bb7-b805-296b2ca8c5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-01b689cf-2256-442c-a716-2ef764343ce8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-235852706-172.17.0.4-1596017256483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34539,DS-5989c2ce-f7ad-4876-b75e-04c747ad7ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-d3a326d6-384f-423e-b6c8-9525e1387a42,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-586dbaaf-247b-4790-b418-1dca1c0d3303,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-86ad9e01-2842-4bfa-b86b-17f0395550ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-bc492a17-f572-464d-b003-25e71832be0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-4862f2b9-f132-4330-846c-12f22e3b8d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-895a6d10-6077-40a3-bc46-e0be14ba7589,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-040b753d-37ae-4fe5-ab9b-f1b8c2f25256,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-235852706-172.17.0.4-1596017256483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34539,DS-5989c2ce-f7ad-4876-b75e-04c747ad7ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-d3a326d6-384f-423e-b6c8-9525e1387a42,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-586dbaaf-247b-4790-b418-1dca1c0d3303,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-86ad9e01-2842-4bfa-b86b-17f0395550ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-bc492a17-f572-464d-b003-25e71832be0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-4862f2b9-f132-4330-846c-12f22e3b8d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-895a6d10-6077-40a3-bc46-e0be14ba7589,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-040b753d-37ae-4fe5-ab9b-f1b8c2f25256,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1047600304-172.17.0.4-1596017390679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40077,DS-27357362-d73a-4d03-8f38-1face6b4f78c,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-1c6500f8-ccf4-47e8-9597-14cbe251e2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36477,DS-42118258-1b38-4a08-8141-431487372a06,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-facf9839-bbac-44bd-adea-426699e1a2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-38e45f7b-cf4c-4d66-b477-f42147ede780,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-8fc76853-f6ab-450e-8f9c-2ebdea9a3e59,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-5470b81a-f736-45e2-a09e-517155034aea,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-cebc57d1-7eb6-4ad2-bc5c-80332154409e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1047600304-172.17.0.4-1596017390679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40077,DS-27357362-d73a-4d03-8f38-1face6b4f78c,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-1c6500f8-ccf4-47e8-9597-14cbe251e2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36477,DS-42118258-1b38-4a08-8141-431487372a06,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-facf9839-bbac-44bd-adea-426699e1a2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-38e45f7b-cf4c-4d66-b477-f42147ede780,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-8fc76853-f6ab-450e-8f9c-2ebdea9a3e59,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-5470b81a-f736-45e2-a09e-517155034aea,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-cebc57d1-7eb6-4ad2-bc5c-80332154409e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-943762721-172.17.0.4-1596017471824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40207,DS-c3e675e0-f44e-4b9b-a2fe-b37908e1c8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-668b42a9-9c61-4439-9a41-930e4589c6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-f01c3997-61dc-4d30-a209-927206f4e2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-70d2f7b3-74dd-493f-9ae9-e9aeea292d19,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-be2ba818-848c-426d-af19-f53812e5d2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42167,DS-5705c492-766d-4858-8c1d-3f3fb8ca17ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-6aa9afa5-9e9a-4895-bbf8-ed21a588db50,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-e4a9611e-fd9d-4c5a-9f07-9bc7fb59a30d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-943762721-172.17.0.4-1596017471824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40207,DS-c3e675e0-f44e-4b9b-a2fe-b37908e1c8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-668b42a9-9c61-4439-9a41-930e4589c6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-f01c3997-61dc-4d30-a209-927206f4e2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-70d2f7b3-74dd-493f-9ae9-e9aeea292d19,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-be2ba818-848c-426d-af19-f53812e5d2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42167,DS-5705c492-766d-4858-8c1d-3f3fb8ca17ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-6aa9afa5-9e9a-4895-bbf8-ed21a588db50,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-e4a9611e-fd9d-4c5a-9f07-9bc7fb59a30d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1776707155-172.17.0.4-1596017566415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35705,DS-d8ef4833-09b0-4dfc-a03c-4b23c9b150c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43173,DS-07eda492-c591-41de-9ca4-7b29d2edf3db,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-1e33b730-4a64-422c-a7e9-6abe55444c53,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-1e500f21-6d90-45a0-95e9-ab6a37114ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-a453694b-dece-4bb2-bfc7-2643443dff66,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-f269bf25-dafe-4d86-806b-d213302d53d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-8e30d6bb-f2cc-4250-b993-d2871a289cde,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-fa4c9f30-b1de-419e-a440-46bdd2612291,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1776707155-172.17.0.4-1596017566415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35705,DS-d8ef4833-09b0-4dfc-a03c-4b23c9b150c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43173,DS-07eda492-c591-41de-9ca4-7b29d2edf3db,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-1e33b730-4a64-422c-a7e9-6abe55444c53,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-1e500f21-6d90-45a0-95e9-ab6a37114ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-a453694b-dece-4bb2-bfc7-2643443dff66,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-f269bf25-dafe-4d86-806b-d213302d53d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-8e30d6bb-f2cc-4250-b993-d2871a289cde,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-fa4c9f30-b1de-419e-a440-46bdd2612291,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1971090125-172.17.0.4-1596017691740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32936,DS-d4c472c7-4388-454d-b797-94547b83ffd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-bea362cf-3975-4327-a7f0-cd5aec21470f,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-579fa512-23f8-465e-a76b-7e28654ab7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-92cc5b1a-cf1f-4688-a241-1c1567ee2d72,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-eedefffe-ddec-4132-afbf-5d96c3971748,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-cc212722-a705-4337-b6d3-f5449136d3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-c3292fe1-4f54-412b-a6ff-f39a3bb24fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-6d095bf7-db7b-40af-aeb4-ec9e6a91a202,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1971090125-172.17.0.4-1596017691740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32936,DS-d4c472c7-4388-454d-b797-94547b83ffd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-bea362cf-3975-4327-a7f0-cd5aec21470f,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-579fa512-23f8-465e-a76b-7e28654ab7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-92cc5b1a-cf1f-4688-a241-1c1567ee2d72,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-eedefffe-ddec-4132-afbf-5d96c3971748,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-cc212722-a705-4337-b6d3-f5449136d3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-c3292fe1-4f54-412b-a6ff-f39a3bb24fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-6d095bf7-db7b-40af-aeb4-ec9e6a91a202,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-115431626-172.17.0.4-1596017825591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41879,DS-39358988-2f93-4b62-87db-3d1d162dd345,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-eefd4852-087e-467e-9fe3-41f3263662c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-5a75831e-479a-4032-a682-736184ab7799,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-a3a24275-1574-4782-b60c-3ba4c3bd3f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-63d2b192-d2a6-42d5-a9de-d48882017a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-5a6f0835-dbf6-482e-84d2-b7a78dbb8f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-d88fb4dd-1813-478b-8b6b-a60fdcefd14f,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-74f00992-6508-45c7-83cb-c5697cb4beeb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-115431626-172.17.0.4-1596017825591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41879,DS-39358988-2f93-4b62-87db-3d1d162dd345,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-eefd4852-087e-467e-9fe3-41f3263662c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-5a75831e-479a-4032-a682-736184ab7799,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-a3a24275-1574-4782-b60c-3ba4c3bd3f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-63d2b192-d2a6-42d5-a9de-d48882017a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-5a6f0835-dbf6-482e-84d2-b7a78dbb8f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-d88fb4dd-1813-478b-8b6b-a60fdcefd14f,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-74f00992-6508-45c7-83cb-c5697cb4beeb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1023602874-172.17.0.4-1596017907834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39382,DS-6286b2ac-c4f9-4e42-ba08-2379cd93b1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44036,DS-0eee6cd9-7100-415b-8743-f16eef7afbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:33022,DS-79e496f2-632c-46ed-8a7d-0859348a7244,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-8a3ce936-aa1f-4c6c-9278-cc9c00537c80,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-a82883c7-7c24-4daa-a738-66b8a931dbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-f0d008f3-acc9-43b5-828c-7d0b38af8f09,DISK], DatanodeInfoWithStorage[127.0.0.1:41012,DS-e4bce70f-1743-4294-ba04-8f3b24cd818e,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-e76a5ada-d72f-4d4e-8938-2a6a426e86d4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1023602874-172.17.0.4-1596017907834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39382,DS-6286b2ac-c4f9-4e42-ba08-2379cd93b1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44036,DS-0eee6cd9-7100-415b-8743-f16eef7afbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:33022,DS-79e496f2-632c-46ed-8a7d-0859348a7244,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-8a3ce936-aa1f-4c6c-9278-cc9c00537c80,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-a82883c7-7c24-4daa-a738-66b8a931dbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-f0d008f3-acc9-43b5-828c-7d0b38af8f09,DISK], DatanodeInfoWithStorage[127.0.0.1:41012,DS-e4bce70f-1743-4294-ba04-8f3b24cd818e,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-e76a5ada-d72f-4d4e-8938-2a6a426e86d4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-12329683-172.17.0.4-1596018035189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33944,DS-9336ea9f-59b0-42a8-989c-fe570257dc5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-9a5c099f-1c0a-4152-9a58-21dc12ae9797,DISK], DatanodeInfoWithStorage[127.0.0.1:35535,DS-a8cf28e8-6423-4fcc-811c-e5edc3a82088,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-3f57aeed-089d-4235-b992-f6fb7b12ac07,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-c9acbaa6-4275-4792-b132-ec0e13771e73,DISK], DatanodeInfoWithStorage[127.0.0.1:38948,DS-2e3d6f1b-31a0-4f6d-99b4-73e9896fe36b,DISK], DatanodeInfoWithStorage[127.0.0.1:34126,DS-379b4e19-5b21-41c0-ae94-cabe97da5b58,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-0c215962-ea66-471f-ba6b-1cc9e3558643,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-12329683-172.17.0.4-1596018035189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33944,DS-9336ea9f-59b0-42a8-989c-fe570257dc5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-9a5c099f-1c0a-4152-9a58-21dc12ae9797,DISK], DatanodeInfoWithStorage[127.0.0.1:35535,DS-a8cf28e8-6423-4fcc-811c-e5edc3a82088,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-3f57aeed-089d-4235-b992-f6fb7b12ac07,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-c9acbaa6-4275-4792-b132-ec0e13771e73,DISK], DatanodeInfoWithStorage[127.0.0.1:38948,DS-2e3d6f1b-31a0-4f6d-99b4-73e9896fe36b,DISK], DatanodeInfoWithStorage[127.0.0.1:34126,DS-379b4e19-5b21-41c0-ae94-cabe97da5b58,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-0c215962-ea66-471f-ba6b-1cc9e3558643,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2107392461-172.17.0.4-1596018550411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43569,DS-927ce4d2-b668-4dbe-9202-eb4e23f0d52b,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-3cc11cb4-c0ca-44f7-8971-c1844a1a1f74,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-33d91bff-280e-42eb-8c23-6af7b2877fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-c6cabe57-c63a-4f46-914c-c4d4a3e4794f,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-67101d89-bcb1-4696-9f31-a6ad64035aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-02f36202-4730-4615-ad35-57353f928753,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-efe61a32-8e63-4e15-bb9f-10795b1059e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-ff52e942-9e53-4ebf-ae1d-4afbbc634b5f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2107392461-172.17.0.4-1596018550411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43569,DS-927ce4d2-b668-4dbe-9202-eb4e23f0d52b,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-3cc11cb4-c0ca-44f7-8971-c1844a1a1f74,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-33d91bff-280e-42eb-8c23-6af7b2877fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-c6cabe57-c63a-4f46-914c-c4d4a3e4794f,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-67101d89-bcb1-4696-9f31-a6ad64035aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-02f36202-4730-4615-ad35-57353f928753,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-efe61a32-8e63-4e15-bb9f-10795b1059e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-ff52e942-9e53-4ebf-ae1d-4afbbc634b5f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2104519821-172.17.0.4-1596018595755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37590,DS-563510e7-72c1-4e3b-b4d3-e2798535f3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-0c03062f-583e-40c3-8430-e52a65faab25,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-26a1a24d-f51a-4b68-895e-f80bb8901ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-c55af301-3448-482b-a68e-36f1a236a94d,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-3e8317fd-ff68-444e-8953-2e252b66cc38,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-324acee2-f057-480a-911d-34d030328381,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-5a2d8b53-e86c-4d3b-99d2-897d03ed4e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46346,DS-47a9b7d9-7a0a-478a-8669-10e112cbedd6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2104519821-172.17.0.4-1596018595755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37590,DS-563510e7-72c1-4e3b-b4d3-e2798535f3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-0c03062f-583e-40c3-8430-e52a65faab25,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-26a1a24d-f51a-4b68-895e-f80bb8901ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-c55af301-3448-482b-a68e-36f1a236a94d,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-3e8317fd-ff68-444e-8953-2e252b66cc38,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-324acee2-f057-480a-911d-34d030328381,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-5a2d8b53-e86c-4d3b-99d2-897d03ed4e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46346,DS-47a9b7d9-7a0a-478a-8669-10e112cbedd6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-471019130-172.17.0.4-1596018726405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38514,DS-375c8419-e090-4a45-9056-f19785b06ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-dc3ceeaa-7389-45a4-ba83-6d75d885fe0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-1399060a-a942-4a9c-8693-22385ff02903,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-9f319d1a-8213-4f42-a50a-dbe42e534a80,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-6a4634e2-df83-4278-94fe-154606f9cad5,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-ea9c1bc3-69f0-4b0a-bfd3-b89e4c650f15,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-86b4a2c1-ce8e-451c-bb99-e58208ec87ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-da75d09c-ec47-4ea5-9e08-7ded37bbe993,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-471019130-172.17.0.4-1596018726405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38514,DS-375c8419-e090-4a45-9056-f19785b06ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-dc3ceeaa-7389-45a4-ba83-6d75d885fe0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-1399060a-a942-4a9c-8693-22385ff02903,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-9f319d1a-8213-4f42-a50a-dbe42e534a80,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-6a4634e2-df83-4278-94fe-154606f9cad5,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-ea9c1bc3-69f0-4b0a-bfd3-b89e4c650f15,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-86b4a2c1-ce8e-451c-bb99-e58208ec87ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-da75d09c-ec47-4ea5-9e08-7ded37bbe993,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-15265924-172.17.0.4-1596019184184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40582,DS-473bb4ae-70fd-4f6d-a309-bb6586de0948,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-59cf3696-0a31-4801-83d1-e74178d7af7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41166,DS-3948269b-7f9f-4f6f-bcf3-ca1b4370e98d,DISK], DatanodeInfoWithStorage[127.0.0.1:40854,DS-6647ba98-bc33-47c5-9522-d62886f307ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-75b7a493-5539-438c-8bb7-23da1859f936,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-d405b9c3-6393-432f-bfa6-78ff98465627,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-ed5f03d7-2153-4f22-8213-c0824399b760,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-4633014c-c3c3-48c6-ba94-ecc28229d70c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-15265924-172.17.0.4-1596019184184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40582,DS-473bb4ae-70fd-4f6d-a309-bb6586de0948,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-59cf3696-0a31-4801-83d1-e74178d7af7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41166,DS-3948269b-7f9f-4f6f-bcf3-ca1b4370e98d,DISK], DatanodeInfoWithStorage[127.0.0.1:40854,DS-6647ba98-bc33-47c5-9522-d62886f307ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-75b7a493-5539-438c-8bb7-23da1859f936,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-d405b9c3-6393-432f-bfa6-78ff98465627,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-ed5f03d7-2153-4f22-8213-c0824399b760,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-4633014c-c3c3-48c6-ba94-ecc28229d70c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1891934093-172.17.0.4-1596019313723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35328,DS-81a78db0-5eb5-4b79-b959-fa580bcddfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-380ffb9b-bb03-4ea8-b953-8c57f9f3c5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-b608f661-5fb1-4d7e-aaa6-47c14876f180,DISK], DatanodeInfoWithStorage[127.0.0.1:43179,DS-66a8ffd3-73d2-4d6f-94f9-604e6ee4a04a,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-01d01452-b513-4674-b383-95ea8857b359,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-4c1c4f7b-feac-41fe-b0c3-0db7d8962c96,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-a9366bc4-d569-4595-85a5-5e0e7f0a02c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-4637b1dd-4759-42ec-9ff9-0c11796d21e7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1891934093-172.17.0.4-1596019313723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35328,DS-81a78db0-5eb5-4b79-b959-fa580bcddfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-380ffb9b-bb03-4ea8-b953-8c57f9f3c5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-b608f661-5fb1-4d7e-aaa6-47c14876f180,DISK], DatanodeInfoWithStorage[127.0.0.1:43179,DS-66a8ffd3-73d2-4d6f-94f9-604e6ee4a04a,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-01d01452-b513-4674-b383-95ea8857b359,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-4c1c4f7b-feac-41fe-b0c3-0db7d8962c96,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-a9366bc4-d569-4595-85a5-5e0e7f0a02c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-4637b1dd-4759-42ec-9ff9-0c11796d21e7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1176544903-172.17.0.4-1596019412927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40916,DS-c1d6dc1b-5a19-4c41-a27a-4db51e9fdfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-8d7480a2-8889-43ac-889a-b7927daa0267,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-697680c4-8e8b-4890-85da-d309875262f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39352,DS-8057bb43-113c-4fa8-bd76-092fb4ac2485,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-23dbd868-3e1e-439e-8c97-bf1873a2f500,DISK], DatanodeInfoWithStorage[127.0.0.1:43386,DS-34407f21-306f-48d1-bb6c-76a387199e06,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-426e00d1-a347-44dc-9352-6810776aab48,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-c5e91d68-7fb2-4e6d-92b1-8cc138f7d474,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1176544903-172.17.0.4-1596019412927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40916,DS-c1d6dc1b-5a19-4c41-a27a-4db51e9fdfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-8d7480a2-8889-43ac-889a-b7927daa0267,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-697680c4-8e8b-4890-85da-d309875262f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39352,DS-8057bb43-113c-4fa8-bd76-092fb4ac2485,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-23dbd868-3e1e-439e-8c97-bf1873a2f500,DISK], DatanodeInfoWithStorage[127.0.0.1:43386,DS-34407f21-306f-48d1-bb6c-76a387199e06,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-426e00d1-a347-44dc-9352-6810776aab48,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-c5e91d68-7fb2-4e6d-92b1-8cc138f7d474,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061937559-172.17.0.4-1596019697805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42013,DS-0e690a7e-0639-4bde-9e13-8f48e73f7592,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-94f26f81-a077-46d5-ba31-cb26eb94abc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-ce440a7d-69a4-4f55-9ead-fee8493ad38f,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-2aec13dc-7067-4f60-8c27-fec15664cfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-593d8349-9e2a-4009-8213-d422cfcb3b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35121,DS-c2c55b83-4ea9-4c82-b590-0a13426acd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-b2f2d64d-96a6-44a1-85ea-31075f2b123a,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-d322afa3-d429-4fc9-9541-3a0f34f049d1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061937559-172.17.0.4-1596019697805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42013,DS-0e690a7e-0639-4bde-9e13-8f48e73f7592,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-94f26f81-a077-46d5-ba31-cb26eb94abc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-ce440a7d-69a4-4f55-9ead-fee8493ad38f,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-2aec13dc-7067-4f60-8c27-fec15664cfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-593d8349-9e2a-4009-8213-d422cfcb3b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35121,DS-c2c55b83-4ea9-4c82-b590-0a13426acd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-b2f2d64d-96a6-44a1-85ea-31075f2b123a,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-d322afa3-d429-4fc9-9541-3a0f34f049d1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 16 out of 50
v1v1v2v2 failed with probability 25 out of 50
result: false positive !!!
Total execution time in seconds : 6499
