reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-574756241-172.17.0.11-1596060997055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38672,DS-ae37e3fa-1776-4f76-a3e4-3df3948dbf10,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-15d8e50e-ecd4-41e9-b6eb-627e5d8d9c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-38c99150-3b1a-4a91-9bb8-9fce3f81226d,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-833160c4-cc16-494c-8b8b-98901a89c555,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-46716f90-c54a-4fe3-8414-111a28bbace8,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-014752af-e13a-4806-9793-eec09dac5ada,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-6a1d7901-d0fe-4f39-b9f6-da08cf014ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-1ca3b8ac-8fd2-495c-adcf-b01f049d7b24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-574756241-172.17.0.11-1596060997055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38672,DS-ae37e3fa-1776-4f76-a3e4-3df3948dbf10,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-15d8e50e-ecd4-41e9-b6eb-627e5d8d9c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-38c99150-3b1a-4a91-9bb8-9fce3f81226d,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-833160c4-cc16-494c-8b8b-98901a89c555,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-46716f90-c54a-4fe3-8414-111a28bbace8,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-014752af-e13a-4806-9793-eec09dac5ada,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-6a1d7901-d0fe-4f39-b9f6-da08cf014ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-1ca3b8ac-8fd2-495c-adcf-b01f049d7b24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-422173210-172.17.0.11-1596062429082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43448,DS-9a525379-1998-4ab5-aa94-2f73ed57e84d,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-6d499bb9-65f8-4d11-9db8-8e6079537090,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-e0d7922a-e56f-4af6-8b0e-5e5b6d984c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-0f0b5229-b116-4c53-b4e1-a6f626f65b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-e2a8b586-933d-44f9-8dbc-77506b6a7f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-9be2ac86-3916-426c-ac06-ba1339fbef85,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-b04a1c5e-9370-43e1-b2bc-d06f7ad75c04,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-532b50d2-2c8c-446e-9b76-968094142c5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-422173210-172.17.0.11-1596062429082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43448,DS-9a525379-1998-4ab5-aa94-2f73ed57e84d,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-6d499bb9-65f8-4d11-9db8-8e6079537090,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-e0d7922a-e56f-4af6-8b0e-5e5b6d984c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-0f0b5229-b116-4c53-b4e1-a6f626f65b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-e2a8b586-933d-44f9-8dbc-77506b6a7f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-9be2ac86-3916-426c-ac06-ba1339fbef85,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-b04a1c5e-9370-43e1-b2bc-d06f7ad75c04,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-532b50d2-2c8c-446e-9b76-968094142c5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1552117080-172.17.0.11-1596062607907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39320,DS-8d5e70eb-8001-4ab4-80d6-ab1f672dd215,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-72339189-61f0-4d88-a6fe-82e81d989c87,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-d5c68cb2-9086-4c32-9be0-02ca13147081,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-e6e81714-1f59-48c1-b6a0-f414502116e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-36a044fd-ec57-48b1-8cc7-5cc12bd52aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-cb380ec5-2042-4e4d-9f40-838686f167e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45997,DS-995c2a5f-c59f-4dd4-bc06-00cf60dd7e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-996d65be-f806-446f-bfb5-044267b736b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1552117080-172.17.0.11-1596062607907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39320,DS-8d5e70eb-8001-4ab4-80d6-ab1f672dd215,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-72339189-61f0-4d88-a6fe-82e81d989c87,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-d5c68cb2-9086-4c32-9be0-02ca13147081,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-e6e81714-1f59-48c1-b6a0-f414502116e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-36a044fd-ec57-48b1-8cc7-5cc12bd52aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-cb380ec5-2042-4e4d-9f40-838686f167e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45997,DS-995c2a5f-c59f-4dd4-bc06-00cf60dd7e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-996d65be-f806-446f-bfb5-044267b736b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1823986461-172.17.0.11-1596063111765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43846,DS-74f6e5d3-2ff4-45e4-9689-ffce8bc743dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-7931c4bf-fc97-4a94-bbc6-808da3444345,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-fa946181-7165-4ce3-b483-654eb56eb757,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-6b04bd58-25ba-49af-93c2-17749b433868,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-912d3127-9462-45e6-86b3-8225f12898ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-061422fe-8c71-4035-a803-d81260cd038a,DISK], DatanodeInfoWithStorage[127.0.0.1:44636,DS-7ec8cdb4-3fdc-496d-870d-94b738c6a82b,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-586e3682-88ab-4baa-8aa2-1093a2bb4abd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1823986461-172.17.0.11-1596063111765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43846,DS-74f6e5d3-2ff4-45e4-9689-ffce8bc743dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-7931c4bf-fc97-4a94-bbc6-808da3444345,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-fa946181-7165-4ce3-b483-654eb56eb757,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-6b04bd58-25ba-49af-93c2-17749b433868,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-912d3127-9462-45e6-86b3-8225f12898ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-061422fe-8c71-4035-a803-d81260cd038a,DISK], DatanodeInfoWithStorage[127.0.0.1:44636,DS-7ec8cdb4-3fdc-496d-870d-94b738c6a82b,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-586e3682-88ab-4baa-8aa2-1093a2bb4abd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1321655184-172.17.0.11-1596063510773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34453,DS-e202e78e-05e4-43b5-8c21-11b6a21af52f,DISK], DatanodeInfoWithStorage[127.0.0.1:42534,DS-c3422190-c8b4-4706-b7a6-30647a8d4e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-79031eb7-14d7-42f7-9779-30fec61ec43d,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-6038ebce-36df-450b-8f02-64f80b5b6877,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-a2980ceb-6c3e-4392-a7dd-52616d427a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45973,DS-cffb04bc-7557-43aa-b8f6-11c9df6931ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-db667c29-c590-4a41-be55-5c7f915e2017,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-3118f9a7-bef8-4f82-869b-d0d2139abc0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1321655184-172.17.0.11-1596063510773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34453,DS-e202e78e-05e4-43b5-8c21-11b6a21af52f,DISK], DatanodeInfoWithStorage[127.0.0.1:42534,DS-c3422190-c8b4-4706-b7a6-30647a8d4e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-79031eb7-14d7-42f7-9779-30fec61ec43d,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-6038ebce-36df-450b-8f02-64f80b5b6877,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-a2980ceb-6c3e-4392-a7dd-52616d427a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45973,DS-cffb04bc-7557-43aa-b8f6-11c9df6931ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-db667c29-c590-4a41-be55-5c7f915e2017,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-3118f9a7-bef8-4f82-869b-d0d2139abc0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2047040014-172.17.0.11-1596063847668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45320,DS-3ea19d7d-b988-487d-a81f-73bea533fc70,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-d246b1d1-5e91-4272-8201-12c3d3396dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-f6b4ee7f-cb39-4496-a58e-1160a5d06c80,DISK], DatanodeInfoWithStorage[127.0.0.1:44422,DS-a3039a31-3212-4776-8462-a2744fa19387,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-fe03c5e7-0f8a-4aa7-9904-0ce16256b196,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-ca5ba65c-2dcf-4c08-8034-049cda328e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-ce9a6ce6-51a0-4684-a65c-603956d34325,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-3783b804-b12a-4284-bd33-4fc3f164fd4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2047040014-172.17.0.11-1596063847668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45320,DS-3ea19d7d-b988-487d-a81f-73bea533fc70,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-d246b1d1-5e91-4272-8201-12c3d3396dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-f6b4ee7f-cb39-4496-a58e-1160a5d06c80,DISK], DatanodeInfoWithStorage[127.0.0.1:44422,DS-a3039a31-3212-4776-8462-a2744fa19387,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-fe03c5e7-0f8a-4aa7-9904-0ce16256b196,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-ca5ba65c-2dcf-4c08-8034-049cda328e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-ce9a6ce6-51a0-4684-a65c-603956d34325,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-3783b804-b12a-4284-bd33-4fc3f164fd4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1522324889-172.17.0.11-1596064501228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46130,DS-cf98d129-3a1a-40d8-95b0-9b6342b04424,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-6f5db648-6d2b-46f5-9287-46b68a0b02a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35755,DS-450e550f-0a54-4cce-a820-424bf1b294a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-04cacca0-a4bc-48d2-a778-ec53b0c552fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-291eaa6a-db5c-4c94-ab24-8e6ee20145bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-d1449176-a441-47ae-8b24-50ca41e8fec3,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-3f6f502f-bf11-4c4a-8aac-320cef60d7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-ffb18e9e-29a9-46ab-a9cd-7be625a23709,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1522324889-172.17.0.11-1596064501228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46130,DS-cf98d129-3a1a-40d8-95b0-9b6342b04424,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-6f5db648-6d2b-46f5-9287-46b68a0b02a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35755,DS-450e550f-0a54-4cce-a820-424bf1b294a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-04cacca0-a4bc-48d2-a778-ec53b0c552fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-291eaa6a-db5c-4c94-ab24-8e6ee20145bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-d1449176-a441-47ae-8b24-50ca41e8fec3,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-3f6f502f-bf11-4c4a-8aac-320cef60d7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-ffb18e9e-29a9-46ab-a9cd-7be625a23709,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-849350612-172.17.0.11-1596064586865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37773,DS-7216745c-7c7b-4cba-9c9b-297cbd0c98c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-7ff61aa0-88fb-48bd-b83c-c97570b40c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-a128a564-0f2a-4618-a39f-473a418cbfeb,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-3b667946-b2cd-4fc3-8b19-21692eee3284,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-07a87a86-3001-4faf-bc3d-2a0f9335d1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38597,DS-3300725a-f196-4fd1-8c6e-b49b9e60fd5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-5da36144-2c7b-40fa-9d3c-dc651c69921e,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-ae81334b-3e33-4f5b-81d3-14852153c82e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-849350612-172.17.0.11-1596064586865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37773,DS-7216745c-7c7b-4cba-9c9b-297cbd0c98c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-7ff61aa0-88fb-48bd-b83c-c97570b40c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-a128a564-0f2a-4618-a39f-473a418cbfeb,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-3b667946-b2cd-4fc3-8b19-21692eee3284,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-07a87a86-3001-4faf-bc3d-2a0f9335d1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38597,DS-3300725a-f196-4fd1-8c6e-b49b9e60fd5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-5da36144-2c7b-40fa-9d3c-dc651c69921e,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-ae81334b-3e33-4f5b-81d3-14852153c82e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1578699968-172.17.0.11-1596064668732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39959,DS-acf06b57-0239-4ccc-9641-84a1f4b80050,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-847f28e2-1ea7-4d3a-b550-e3bd8488ff4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44473,DS-c2043217-2fcf-4608-9873-775840578ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-8c472484-159c-4414-ab0e-e31619871087,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-9614e6e0-7458-4b4a-88e5-a639f0fdbcbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36082,DS-e7c7c706-c576-4705-ac9c-6d7f6873d650,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-34d50105-48d5-4c4a-a0c4-e13c1fcf8f40,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-634b3b00-b03c-4392-a23b-f5a8d8fa0166,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1578699968-172.17.0.11-1596064668732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39959,DS-acf06b57-0239-4ccc-9641-84a1f4b80050,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-847f28e2-1ea7-4d3a-b550-e3bd8488ff4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44473,DS-c2043217-2fcf-4608-9873-775840578ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-8c472484-159c-4414-ab0e-e31619871087,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-9614e6e0-7458-4b4a-88e5-a639f0fdbcbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36082,DS-e7c7c706-c576-4705-ac9c-6d7f6873d650,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-34d50105-48d5-4c4a-a0c4-e13c1fcf8f40,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-634b3b00-b03c-4392-a23b-f5a8d8fa0166,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1475627593-172.17.0.11-1596064970238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34940,DS-47e118da-be41-4a7e-8d73-a633fdec3fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-1fb24162-e4a2-47bc-92ef-f4b36dace37d,DISK], DatanodeInfoWithStorage[127.0.0.1:39621,DS-2c3a88d2-be10-498a-8dc2-53381f114bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-87fdbc20-d3f8-466e-8377-a7865903a638,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-96ebaef6-5b68-475c-aa5a-c284d861d947,DISK], DatanodeInfoWithStorage[127.0.0.1:35370,DS-0e1aadb3-9413-4385-854f-c783bec575e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-c3e54573-d108-42a6-b299-6d3507946bca,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-3ed11695-2b52-43f3-a774-400ce0aa32ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1475627593-172.17.0.11-1596064970238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34940,DS-47e118da-be41-4a7e-8d73-a633fdec3fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-1fb24162-e4a2-47bc-92ef-f4b36dace37d,DISK], DatanodeInfoWithStorage[127.0.0.1:39621,DS-2c3a88d2-be10-498a-8dc2-53381f114bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-87fdbc20-d3f8-466e-8377-a7865903a638,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-96ebaef6-5b68-475c-aa5a-c284d861d947,DISK], DatanodeInfoWithStorage[127.0.0.1:35370,DS-0e1aadb3-9413-4385-854f-c783bec575e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-c3e54573-d108-42a6-b299-6d3507946bca,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-3ed11695-2b52-43f3-a774-400ce0aa32ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879787355-172.17.0.11-1596065138569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44848,DS-7a28e448-7bde-415d-b154-de1b25ff7ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:41664,DS-fb792a0b-7758-4e03-967a-ac5a501a4bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-35355428-d66b-4305-97ad-90d2d2398a80,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-a023c832-5668-4654-b372-16c8e31078e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-a294604d-ed75-4e9c-87d3-e9206c230704,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-325ce9f8-af9d-48b3-aec6-0ee19b2178ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-a43c5548-2367-4d86-804b-91f3db118564,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-5423c46d-056f-4067-aaa3-f42c7fd3c991,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879787355-172.17.0.11-1596065138569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44848,DS-7a28e448-7bde-415d-b154-de1b25ff7ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:41664,DS-fb792a0b-7758-4e03-967a-ac5a501a4bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-35355428-d66b-4305-97ad-90d2d2398a80,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-a023c832-5668-4654-b372-16c8e31078e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-a294604d-ed75-4e9c-87d3-e9206c230704,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-325ce9f8-af9d-48b3-aec6-0ee19b2178ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-a43c5548-2367-4d86-804b-91f3db118564,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-5423c46d-056f-4067-aaa3-f42c7fd3c991,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-732017693-172.17.0.11-1596065574382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45122,DS-48136b0c-15c8-4b94-9026-7ef7902ddaa3,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-65b611eb-30ea-4ab0-b912-b25c9b84521c,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-a9194783-4c47-4bd6-9a52-ebbef8e2fe46,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-05611023-6f25-4991-b309-1f2d6fd48e71,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-f9b97d57-4602-4d3d-bc9a-5b29e905a657,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-f905c79d-69bf-43ad-9d53-8e985b9225a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41693,DS-92b45daf-7b15-455d-8c33-d2e820ec40ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-03d15cf3-29dc-44cd-94b1-a25d6a73e9d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-732017693-172.17.0.11-1596065574382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45122,DS-48136b0c-15c8-4b94-9026-7ef7902ddaa3,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-65b611eb-30ea-4ab0-b912-b25c9b84521c,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-a9194783-4c47-4bd6-9a52-ebbef8e2fe46,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-05611023-6f25-4991-b309-1f2d6fd48e71,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-f9b97d57-4602-4d3d-bc9a-5b29e905a657,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-f905c79d-69bf-43ad-9d53-8e985b9225a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41693,DS-92b45daf-7b15-455d-8c33-d2e820ec40ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-03d15cf3-29dc-44cd-94b1-a25d6a73e9d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-799088711-172.17.0.11-1596065767686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46314,DS-61b7c300-e163-4a10-aa26-f60dd642055a,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-e18e52bd-4c32-4ed1-94e9-c9a22c9187a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-dbc4a276-224f-43f6-8b9a-2496aad9cde7,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-5ab72af3-4bca-46f6-b4ef-c96a07cef44d,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-ff4926fc-aeef-433f-8e8e-170069d8888a,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-b9688e5c-84ca-464f-8fc6-6e11d675f4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-d00585ec-16e2-4573-8194-eb893530cfb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-54edaa3f-c4dc-4309-a2fb-c349c01de5e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-799088711-172.17.0.11-1596065767686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46314,DS-61b7c300-e163-4a10-aa26-f60dd642055a,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-e18e52bd-4c32-4ed1-94e9-c9a22c9187a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-dbc4a276-224f-43f6-8b9a-2496aad9cde7,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-5ab72af3-4bca-46f6-b4ef-c96a07cef44d,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-ff4926fc-aeef-433f-8e8e-170069d8888a,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-b9688e5c-84ca-464f-8fc6-6e11d675f4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-d00585ec-16e2-4573-8194-eb893530cfb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-54edaa3f-c4dc-4309-a2fb-c349c01de5e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-796493066-172.17.0.11-1596065789631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41818,DS-33afe61f-a60a-4b95-b57a-c730ce051e76,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-28ab811d-8b03-4cce-9f8e-3ca0c6d17708,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-1cdb25f1-701a-4e3c-8d2a-996f76332d52,DISK], DatanodeInfoWithStorage[127.0.0.1:34113,DS-a629eac2-376b-4549-8a51-ef26e728f412,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-c2c93f67-599b-40ba-984f-094be16a5e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-a6e280a3-93b3-4708-830f-25306400490d,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-467c12ce-250e-4e8c-8204-c1f9ccd7bda9,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-9a59b594-b546-48a3-a720-4353b850749e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-796493066-172.17.0.11-1596065789631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41818,DS-33afe61f-a60a-4b95-b57a-c730ce051e76,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-28ab811d-8b03-4cce-9f8e-3ca0c6d17708,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-1cdb25f1-701a-4e3c-8d2a-996f76332d52,DISK], DatanodeInfoWithStorage[127.0.0.1:34113,DS-a629eac2-376b-4549-8a51-ef26e728f412,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-c2c93f67-599b-40ba-984f-094be16a5e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-a6e280a3-93b3-4708-830f-25306400490d,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-467c12ce-250e-4e8c-8204-c1f9ccd7bda9,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-9a59b594-b546-48a3-a720-4353b850749e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-107612229-172.17.0.11-1596065832730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46228,DS-5772ae09-3487-4fda-a5a0-f30657d9022a,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-240bc0f7-5b23-4c9c-838d-bb61bf1f23cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-6bf58b3a-ee0d-49f0-8d69-7f6671a0cc38,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-5189e823-9504-444b-8e61-aa562986d5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-53ef2925-e3da-4733-bcac-85ea37ce429e,DISK], DatanodeInfoWithStorage[127.0.0.1:44191,DS-2a842418-20dc-406f-9d9b-30b0c149383c,DISK], DatanodeInfoWithStorage[127.0.0.1:34651,DS-8c465629-8490-4cfa-b55a-3cd851057be1,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-a3969527-6f88-4def-84b5-706707c4a8a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-107612229-172.17.0.11-1596065832730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46228,DS-5772ae09-3487-4fda-a5a0-f30657d9022a,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-240bc0f7-5b23-4c9c-838d-bb61bf1f23cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-6bf58b3a-ee0d-49f0-8d69-7f6671a0cc38,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-5189e823-9504-444b-8e61-aa562986d5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-53ef2925-e3da-4733-bcac-85ea37ce429e,DISK], DatanodeInfoWithStorage[127.0.0.1:44191,DS-2a842418-20dc-406f-9d9b-30b0c149383c,DISK], DatanodeInfoWithStorage[127.0.0.1:34651,DS-8c465629-8490-4cfa-b55a-3cd851057be1,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-a3969527-6f88-4def-84b5-706707c4a8a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-442321557-172.17.0.11-1596065873471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41848,DS-75b1827d-b1a7-4c0c-93b8-ce8fb8b31ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-e242c674-35bc-449c-b998-ab0826c19b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-9411d38b-aa0a-4da1-8355-69f9c5740f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-5fdd8462-a018-4d52-bb36-80ff244a09e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-9e84e324-ed3a-4e34-9bc9-b4fed8b742f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-cf119c17-f176-45c8-9ec6-3098376655c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-6441d8d7-966a-44a3-9e88-dd11372024c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-94e0130a-bae3-4236-a123-15ab744ee76e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-442321557-172.17.0.11-1596065873471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41848,DS-75b1827d-b1a7-4c0c-93b8-ce8fb8b31ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-e242c674-35bc-449c-b998-ab0826c19b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-9411d38b-aa0a-4da1-8355-69f9c5740f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-5fdd8462-a018-4d52-bb36-80ff244a09e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-9e84e324-ed3a-4e34-9bc9-b4fed8b742f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-cf119c17-f176-45c8-9ec6-3098376655c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-6441d8d7-966a-44a3-9e88-dd11372024c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-94e0130a-bae3-4236-a123-15ab744ee76e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5461
