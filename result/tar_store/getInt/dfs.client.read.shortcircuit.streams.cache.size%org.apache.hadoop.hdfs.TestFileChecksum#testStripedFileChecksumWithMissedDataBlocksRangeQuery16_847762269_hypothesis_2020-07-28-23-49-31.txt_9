reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1790531562-172.17.0.9-1595980302123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36555,DS-6b772593-abc3-4dc2-8cfd-5235554dfebf,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-efd1f786-d4bc-43ef-9734-b0e1109c6dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-03457958-c397-43ad-a90f-4de990b5e66f,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-ad4edfa8-bebb-4f54-9358-6117b927048e,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-2cf856e0-8ab9-44b0-a86c-392657c366a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-d62d4925-04dd-4416-9c17-407d29259b93,DISK], DatanodeInfoWithStorage[127.0.0.1:34158,DS-be30ce33-c87e-4aff-b71d-c8d686e97525,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-2e39c273-2d39-41c9-9d6e-460e66c14331,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1790531562-172.17.0.9-1595980302123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36555,DS-6b772593-abc3-4dc2-8cfd-5235554dfebf,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-efd1f786-d4bc-43ef-9734-b0e1109c6dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-03457958-c397-43ad-a90f-4de990b5e66f,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-ad4edfa8-bebb-4f54-9358-6117b927048e,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-2cf856e0-8ab9-44b0-a86c-392657c366a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-d62d4925-04dd-4416-9c17-407d29259b93,DISK], DatanodeInfoWithStorage[127.0.0.1:34158,DS-be30ce33-c87e-4aff-b71d-c8d686e97525,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-2e39c273-2d39-41c9-9d6e-460e66c14331,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1739775654-172.17.0.9-1595980505496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43465,DS-40245e22-fcb2-4178-8890-9c3f61c15db9,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-b9390acb-1a76-45ca-aeea-c4197b1786d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-565cbc12-cb08-4550-ba6f-d55f18e29664,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-92daeb21-ef23-46c7-aac5-bcb338741479,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-e54e86a2-75a6-43cd-ab2d-6582b6ca3394,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-7061d00c-c98d-4800-8edc-95bf909cb1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38026,DS-f666799f-e28a-497b-b656-4d7f01978c45,DISK], DatanodeInfoWithStorage[127.0.0.1:41635,DS-c4873c3f-cb41-4b32-b784-18a3b356334e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1739775654-172.17.0.9-1595980505496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43465,DS-40245e22-fcb2-4178-8890-9c3f61c15db9,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-b9390acb-1a76-45ca-aeea-c4197b1786d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-565cbc12-cb08-4550-ba6f-d55f18e29664,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-92daeb21-ef23-46c7-aac5-bcb338741479,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-e54e86a2-75a6-43cd-ab2d-6582b6ca3394,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-7061d00c-c98d-4800-8edc-95bf909cb1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38026,DS-f666799f-e28a-497b-b656-4d7f01978c45,DISK], DatanodeInfoWithStorage[127.0.0.1:41635,DS-c4873c3f-cb41-4b32-b784-18a3b356334e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-945042172-172.17.0.9-1595980619691:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38930,DS-52562aa2-d826-4554-a9de-0da721832c36,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-7742c752-2406-404e-a3b4-abb9e903c256,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-0f2b673d-b430-4bff-af7d-4958549ed8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-801d4594-22a7-4abe-b8bc-7391c2a44224,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-0435f995-119f-406a-bfe1-b6c9d8bcc36d,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-68536229-273a-4721-9bee-67601507f0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-ae5369a3-86ae-4e00-b5f4-8c629fc66d52,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-d503694d-4104-41b0-b13a-61b947b4f3f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-945042172-172.17.0.9-1595980619691:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38930,DS-52562aa2-d826-4554-a9de-0da721832c36,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-7742c752-2406-404e-a3b4-abb9e903c256,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-0f2b673d-b430-4bff-af7d-4958549ed8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-801d4594-22a7-4abe-b8bc-7391c2a44224,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-0435f995-119f-406a-bfe1-b6c9d8bcc36d,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-68536229-273a-4721-9bee-67601507f0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-ae5369a3-86ae-4e00-b5f4-8c629fc66d52,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-d503694d-4104-41b0-b13a-61b947b4f3f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1800151140-172.17.0.9-1595980889756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42686,DS-e1beb34f-4136-4110-b6be-9f1244680527,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-860ace89-bf2c-4622-b048-6b13406b0d94,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-9960f947-79d5-49b8-8e3d-903ed73287cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-5592333a-9b63-4e55-9009-5f377d2d0b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-3e1c32c6-578f-462d-b280-9c5f14a06480,DISK], DatanodeInfoWithStorage[127.0.0.1:44550,DS-e9ac333d-372b-4f3a-8e85-945aabc47a49,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-3a4697ef-5dbe-4017-ae6f-2c4a302e1b85,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-e5342ec0-9fc8-475f-9e3c-2a331308ad11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1800151140-172.17.0.9-1595980889756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42686,DS-e1beb34f-4136-4110-b6be-9f1244680527,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-860ace89-bf2c-4622-b048-6b13406b0d94,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-9960f947-79d5-49b8-8e3d-903ed73287cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-5592333a-9b63-4e55-9009-5f377d2d0b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-3e1c32c6-578f-462d-b280-9c5f14a06480,DISK], DatanodeInfoWithStorage[127.0.0.1:44550,DS-e9ac333d-372b-4f3a-8e85-945aabc47a49,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-3a4697ef-5dbe-4017-ae6f-2c4a302e1b85,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-e5342ec0-9fc8-475f-9e3c-2a331308ad11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-961290946-172.17.0.9-1595981068367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42500,DS-47e83f7c-ddad-4df2-addf-209a0f8a8c33,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-2b038965-6a21-4e23-ac0d-ff2fbdd728dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38868,DS-456f2f7f-1684-4f95-8f9a-be7053e39230,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-7cf26425-e709-417f-877d-62e81a226364,DISK], DatanodeInfoWithStorage[127.0.0.1:33092,DS-d645227d-1c08-449b-aa1c-63f846ebb3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-52058ed5-b305-478d-a2da-e87680c406ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-48a911ee-3e8a-4eb8-8426-17f43ea81030,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-5a2d35bd-ca29-4fe1-919a-1386602f9c05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-961290946-172.17.0.9-1595981068367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42500,DS-47e83f7c-ddad-4df2-addf-209a0f8a8c33,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-2b038965-6a21-4e23-ac0d-ff2fbdd728dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38868,DS-456f2f7f-1684-4f95-8f9a-be7053e39230,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-7cf26425-e709-417f-877d-62e81a226364,DISK], DatanodeInfoWithStorage[127.0.0.1:33092,DS-d645227d-1c08-449b-aa1c-63f846ebb3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-52058ed5-b305-478d-a2da-e87680c406ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-48a911ee-3e8a-4eb8-8426-17f43ea81030,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-5a2d35bd-ca29-4fe1-919a-1386602f9c05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-181213130-172.17.0.9-1595981565818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44557,DS-31757996-8045-4e08-b172-ce02f3692878,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-a5959337-836d-4499-a2a6-f706ffa72ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-7604ecb6-869b-420c-a0b9-084e7ea10dab,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-70c1ccfb-9f67-40e1-8978-1ec3d16fec52,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-fbd8e24d-999e-41b1-a287-4847c90ddd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-59fbf2f5-f5bc-44b9-8460-dacea783dd19,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-1d2fe18c-5767-4a29-bc31-105a80b8fe36,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-6c8663da-e229-41eb-aeab-2a4e31395f28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-181213130-172.17.0.9-1595981565818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44557,DS-31757996-8045-4e08-b172-ce02f3692878,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-a5959337-836d-4499-a2a6-f706ffa72ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-7604ecb6-869b-420c-a0b9-084e7ea10dab,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-70c1ccfb-9f67-40e1-8978-1ec3d16fec52,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-fbd8e24d-999e-41b1-a287-4847c90ddd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-59fbf2f5-f5bc-44b9-8460-dacea783dd19,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-1d2fe18c-5767-4a29-bc31-105a80b8fe36,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-6c8663da-e229-41eb-aeab-2a4e31395f28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1932696272-172.17.0.9-1595981725039:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40245,DS-e27e7138-eec3-4250-b45c-6f3e6446c6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-3d9f7f69-676b-4d65-99c7-57d6a2d7c834,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-41efc608-38d1-4bb3-99b1-74785feb97ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-632b4d3b-dadb-4d13-95e3-4b9b006589de,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-0bb84eac-146c-48c4-b45e-5423dc6deb71,DISK], DatanodeInfoWithStorage[127.0.0.1:33902,DS-22096cd4-e0ae-41ee-a26d-1bc52e2ad715,DISK], DatanodeInfoWithStorage[127.0.0.1:45798,DS-cbcf97d2-d9ef-408a-97c3-a6e257283859,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-47db833a-7a5f-438b-87c3-381eb2308bd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1932696272-172.17.0.9-1595981725039:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40245,DS-e27e7138-eec3-4250-b45c-6f3e6446c6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-3d9f7f69-676b-4d65-99c7-57d6a2d7c834,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-41efc608-38d1-4bb3-99b1-74785feb97ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-632b4d3b-dadb-4d13-95e3-4b9b006589de,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-0bb84eac-146c-48c4-b45e-5423dc6deb71,DISK], DatanodeInfoWithStorage[127.0.0.1:33902,DS-22096cd4-e0ae-41ee-a26d-1bc52e2ad715,DISK], DatanodeInfoWithStorage[127.0.0.1:45798,DS-cbcf97d2-d9ef-408a-97c3-a6e257283859,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-47db833a-7a5f-438b-87c3-381eb2308bd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1875699090-172.17.0.9-1595981797591:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35418,DS-6239e00b-c0cc-4296-82b5-7694fc96c173,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-d18acb6f-8672-42dc-b369-4c54b29668fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34138,DS-06f411d1-1c18-4971-b73d-bc51061a5367,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-94bcfb4a-154c-49e2-8660-add1b443244c,DISK], DatanodeInfoWithStorage[127.0.0.1:41048,DS-0d866b52-0594-4e8c-961b-607e23fd8833,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-191fee3e-6c39-47f6-9268-28c2cb3766e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-fabf6f8e-4d84-495a-95b3-e3aeaa270c09,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-6f78efb5-ac24-485f-bcce-373a3d8e598e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1875699090-172.17.0.9-1595981797591:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35418,DS-6239e00b-c0cc-4296-82b5-7694fc96c173,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-d18acb6f-8672-42dc-b369-4c54b29668fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34138,DS-06f411d1-1c18-4971-b73d-bc51061a5367,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-94bcfb4a-154c-49e2-8660-add1b443244c,DISK], DatanodeInfoWithStorage[127.0.0.1:41048,DS-0d866b52-0594-4e8c-961b-607e23fd8833,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-191fee3e-6c39-47f6-9268-28c2cb3766e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-fabf6f8e-4d84-495a-95b3-e3aeaa270c09,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-6f78efb5-ac24-485f-bcce-373a3d8e598e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-531423940-172.17.0.9-1595983330936:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40439,DS-90cda9df-9652-4356-94e4-29b0ae9c22ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-d9872a09-e490-4f34-8f7d-275ed8556f27,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-37e1ba60-c383-43da-bbac-de0ab9ab1a35,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-8abb9b97-066a-4e01-be84-877a18aea074,DISK], DatanodeInfoWithStorage[127.0.0.1:46881,DS-ea7d3fd8-c7f8-4fc0-b0b2-fe0279ffc1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41172,DS-45fafd1e-7873-4481-a1ff-af8126eb8598,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-20bc9f8f-b3e8-4350-a516-cf7e45344b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-719e63dc-809c-4c07-9123-6b19f36fbeb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-531423940-172.17.0.9-1595983330936:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40439,DS-90cda9df-9652-4356-94e4-29b0ae9c22ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-d9872a09-e490-4f34-8f7d-275ed8556f27,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-37e1ba60-c383-43da-bbac-de0ab9ab1a35,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-8abb9b97-066a-4e01-be84-877a18aea074,DISK], DatanodeInfoWithStorage[127.0.0.1:46881,DS-ea7d3fd8-c7f8-4fc0-b0b2-fe0279ffc1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41172,DS-45fafd1e-7873-4481-a1ff-af8126eb8598,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-20bc9f8f-b3e8-4350-a516-cf7e45344b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-719e63dc-809c-4c07-9123-6b19f36fbeb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-234215514-172.17.0.9-1595983412276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33741,DS-3317dcc4-82fc-4a68-aa30-721e759b665a,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-529a51af-be85-485a-bf92-6aaf80f74efc,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-a2aff42f-9151-4c4d-868e-9ffe01bcecd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-60d00e5a-0ec8-4b1c-990c-6b5f47ff5f77,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-e756c260-9329-4ad3-8caa-db795735f5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-efb3f59c-a315-4105-91b8-4848779ea027,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-eb2da10b-3ce2-4adf-b73f-6e5890729ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-8a77feab-2860-4778-ae38-ca533312b18e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-234215514-172.17.0.9-1595983412276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33741,DS-3317dcc4-82fc-4a68-aa30-721e759b665a,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-529a51af-be85-485a-bf92-6aaf80f74efc,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-a2aff42f-9151-4c4d-868e-9ffe01bcecd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-60d00e5a-0ec8-4b1c-990c-6b5f47ff5f77,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-e756c260-9329-4ad3-8caa-db795735f5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-efb3f59c-a315-4105-91b8-4848779ea027,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-eb2da10b-3ce2-4adf-b73f-6e5890729ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-8a77feab-2860-4778-ae38-ca533312b18e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1795851760-172.17.0.9-1595983554053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38374,DS-79c06c64-211a-46e5-8403-8048b58af3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-ae4ff22d-a0f6-4ca3-afe4-72cce3c91fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-c09f4abe-4391-40ec-88cb-10d249442205,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-02106e3f-a5ce-45f1-b3fa-8024bd513596,DISK], DatanodeInfoWithStorage[127.0.0.1:42457,DS-e279488a-813b-4298-89b0-3fbe541e5630,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-23118f85-a7d1-43ed-9673-c4aa99abb772,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-576f4003-236e-4387-8a3d-f7905727d698,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-11722e1d-5991-4588-9774-3637046ba09a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1795851760-172.17.0.9-1595983554053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38374,DS-79c06c64-211a-46e5-8403-8048b58af3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-ae4ff22d-a0f6-4ca3-afe4-72cce3c91fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-c09f4abe-4391-40ec-88cb-10d249442205,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-02106e3f-a5ce-45f1-b3fa-8024bd513596,DISK], DatanodeInfoWithStorage[127.0.0.1:42457,DS-e279488a-813b-4298-89b0-3fbe541e5630,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-23118f85-a7d1-43ed-9673-c4aa99abb772,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-576f4003-236e-4387-8a3d-f7905727d698,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-11722e1d-5991-4588-9774-3637046ba09a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-113210652-172.17.0.9-1595983686534:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36284,DS-21021e0b-c538-4e7f-8058-7633c6f84edf,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-9e90c74a-5849-4a9a-b451-2113e0918253,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-e9907143-ca42-4291-b949-0339a489774c,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-2aa66e94-4fc2-4ca5-b3f8-0e87baa48667,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-d2e4a7a3-bd29-48e1-bfd9-b1aee9069dde,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-07570637-e447-46cc-bfbe-9cb1b7f8ea9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-57ad7c08-e0e7-4770-9510-2e0247e8480d,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-eb149b2a-3091-4f75-8650-b57691ded5ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-113210652-172.17.0.9-1595983686534:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36284,DS-21021e0b-c538-4e7f-8058-7633c6f84edf,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-9e90c74a-5849-4a9a-b451-2113e0918253,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-e9907143-ca42-4291-b949-0339a489774c,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-2aa66e94-4fc2-4ca5-b3f8-0e87baa48667,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-d2e4a7a3-bd29-48e1-bfd9-b1aee9069dde,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-07570637-e447-46cc-bfbe-9cb1b7f8ea9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-57ad7c08-e0e7-4770-9510-2e0247e8480d,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-eb149b2a-3091-4f75-8650-b57691ded5ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2089321769-172.17.0.9-1595984041520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45335,DS-504f58f4-f6ba-429a-b61c-5248992826b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-a4359787-fb59-49b5-acf2-662aa8252ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-39a715c0-f62a-45e4-a652-99ff5f902e95,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-98e56aae-2993-4f6a-913c-97d2557ef2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-5dc07ded-e2e1-4a91-80f6-0d84756b3410,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-acdca799-0b25-419f-88b5-9222305c6926,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-82eb1267-b959-4522-943f-118ecef323d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-889d38c0-53d3-4a08-a7a9-312cf32e649a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2089321769-172.17.0.9-1595984041520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45335,DS-504f58f4-f6ba-429a-b61c-5248992826b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-a4359787-fb59-49b5-acf2-662aa8252ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-39a715c0-f62a-45e4-a652-99ff5f902e95,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-98e56aae-2993-4f6a-913c-97d2557ef2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-5dc07ded-e2e1-4a91-80f6-0d84756b3410,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-acdca799-0b25-419f-88b5-9222305c6926,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-82eb1267-b959-4522-943f-118ecef323d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-889d38c0-53d3-4a08-a7a9-312cf32e649a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2063660479-172.17.0.9-1595984724175:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35221,DS-84bb67e5-19d9-4524-afe0-110f7f0c603f,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-3b6b6bf6-fe49-4c4d-ab99-9aae87a538c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-a59a7400-5ccf-4eaf-824e-5f8f8ec74901,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-e7b09866-a0f8-49cb-83e9-30a93766513b,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-76767004-b41c-4edb-bbcf-dc2ca3e5c607,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-df4b061c-ae37-44be-ac27-75d1a133949b,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-83e087b1-93ff-466d-a473-dda258b633cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-d1898c0d-c75c-4075-8592-fb433cda7f02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2063660479-172.17.0.9-1595984724175:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35221,DS-84bb67e5-19d9-4524-afe0-110f7f0c603f,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-3b6b6bf6-fe49-4c4d-ab99-9aae87a538c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-a59a7400-5ccf-4eaf-824e-5f8f8ec74901,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-e7b09866-a0f8-49cb-83e9-30a93766513b,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-76767004-b41c-4edb-bbcf-dc2ca3e5c607,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-df4b061c-ae37-44be-ac27-75d1a133949b,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-83e087b1-93ff-466d-a473-dda258b633cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-d1898c0d-c75c-4075-8592-fb433cda7f02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-352459313-172.17.0.9-1595984876129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35869,DS-c671d9a7-24a1-45d5-9162-434af71c76bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-65c0dd25-6815-422f-af03-d04886549319,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-720f5b9c-512b-49e7-a334-2b6104b28989,DISK], DatanodeInfoWithStorage[127.0.0.1:42670,DS-69eecce5-41f4-4cc0-9ce3-1883ef9ff442,DISK], DatanodeInfoWithStorage[127.0.0.1:39474,DS-726ac546-3959-4556-b598-f0b5461d9af8,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-99671415-bd5d-47ee-8e9a-cb9541ac2e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43678,DS-b6492c56-feaf-47f0-88c0-f35783808fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-89997f55-c0cb-43a9-92ee-245ef8978e86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-352459313-172.17.0.9-1595984876129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35869,DS-c671d9a7-24a1-45d5-9162-434af71c76bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-65c0dd25-6815-422f-af03-d04886549319,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-720f5b9c-512b-49e7-a334-2b6104b28989,DISK], DatanodeInfoWithStorage[127.0.0.1:42670,DS-69eecce5-41f4-4cc0-9ce3-1883ef9ff442,DISK], DatanodeInfoWithStorage[127.0.0.1:39474,DS-726ac546-3959-4556-b598-f0b5461d9af8,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-99671415-bd5d-47ee-8e9a-cb9541ac2e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43678,DS-b6492c56-feaf-47f0-88c0-f35783808fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-89997f55-c0cb-43a9-92ee-245ef8978e86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1299553943-172.17.0.9-1595985436577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43535,DS-34173fc8-e9fa-44dc-ba04-194e845fe2da,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-04241150-a9eb-40a4-9fa4-5f5f0f2082f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41849,DS-91169ad7-ae92-4bdd-82f9-de98c8226da4,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-d4608fc5-513f-42c8-8709-1524bb389cab,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-962f5231-1e24-481d-a1ce-0cb20d6387d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-b361202d-9b02-479a-8c4d-db6cf3a3a853,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-85388f26-2e84-46c0-975c-2fd3789a4a06,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-4d435038-2893-4342-bf75-fe776bfdf6ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1299553943-172.17.0.9-1595985436577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43535,DS-34173fc8-e9fa-44dc-ba04-194e845fe2da,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-04241150-a9eb-40a4-9fa4-5f5f0f2082f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41849,DS-91169ad7-ae92-4bdd-82f9-de98c8226da4,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-d4608fc5-513f-42c8-8709-1524bb389cab,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-962f5231-1e24-481d-a1ce-0cb20d6387d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-b361202d-9b02-479a-8c4d-db6cf3a3a853,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-85388f26-2e84-46c0-975c-2fd3789a4a06,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-4d435038-2893-4342-bf75-fe776bfdf6ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5614
