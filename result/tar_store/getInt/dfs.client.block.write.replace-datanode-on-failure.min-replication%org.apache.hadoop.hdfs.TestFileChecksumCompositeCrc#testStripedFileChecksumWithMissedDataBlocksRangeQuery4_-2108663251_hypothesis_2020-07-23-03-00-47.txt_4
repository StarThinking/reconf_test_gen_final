reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-337672602-172.17.0.17-1595473694238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42777,DS-9549fd43-887f-47e3-bfe3-0862d921d878,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-69caa0c1-19ee-428c-97fe-8b36952ea68f,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-d98f9b11-fe40-4775-8838-e953050c67a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-0d50276f-e4c8-4d5b-8091-94f242e4adaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-df2e3f7c-1eae-4281-9607-98917d34b94e,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-984081ed-5d9a-40d5-a2d8-220eb52b3aed,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-45c45049-83dc-4ad2-b945-62e83a17d582,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-42ce3b3a-1af8-413d-8681-4c8e92aa6afb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-337672602-172.17.0.17-1595473694238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42777,DS-9549fd43-887f-47e3-bfe3-0862d921d878,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-69caa0c1-19ee-428c-97fe-8b36952ea68f,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-d98f9b11-fe40-4775-8838-e953050c67a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-0d50276f-e4c8-4d5b-8091-94f242e4adaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-df2e3f7c-1eae-4281-9607-98917d34b94e,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-984081ed-5d9a-40d5-a2d8-220eb52b3aed,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-45c45049-83dc-4ad2-b945-62e83a17d582,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-42ce3b3a-1af8-413d-8681-4c8e92aa6afb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948434835-172.17.0.17-1595473962080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45054,DS-e6d08f15-0b86-44bd-8292-70f7e899a704,DISK], DatanodeInfoWithStorage[127.0.0.1:42622,DS-f3d3e7b6-58ae-4756-8241-a3304d33312b,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-e158c5c1-fa87-4460-9d0a-738831f038cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-ff61ae16-68fe-4379-b6c3-e83317cae87a,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-ff1495d3-0391-4be1-bb80-e374928093a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-a1be3046-bd3e-4cbc-bbe8-09b94d6e04f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-5564caed-4e20-4c0d-9748-fdfe3a10f762,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-7a808b8b-0092-42f3-922b-553c175b1596,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948434835-172.17.0.17-1595473962080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45054,DS-e6d08f15-0b86-44bd-8292-70f7e899a704,DISK], DatanodeInfoWithStorage[127.0.0.1:42622,DS-f3d3e7b6-58ae-4756-8241-a3304d33312b,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-e158c5c1-fa87-4460-9d0a-738831f038cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-ff61ae16-68fe-4379-b6c3-e83317cae87a,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-ff1495d3-0391-4be1-bb80-e374928093a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-a1be3046-bd3e-4cbc-bbe8-09b94d6e04f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-5564caed-4e20-4c0d-9748-fdfe3a10f762,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-7a808b8b-0092-42f3-922b-553c175b1596,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2103560065-172.17.0.17-1595474141780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40540,DS-2d90a260-780a-493d-b114-bf53209c8489,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-a2bb322a-fd5d-4e2a-9f43-43909f394a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-6c9de3fb-0331-4a95-9baa-2ced81180a81,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-f35ac953-de72-4486-9106-e91f5db5dc10,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-1337d037-2515-4de7-93d1-9b22721b1a96,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-beda90e6-5d24-421f-b413-d8faa78675a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40229,DS-62a4d0f3-805d-4020-bce8-97521582cb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-c0e39a48-8c82-4983-8af3-b5f2f032bee4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2103560065-172.17.0.17-1595474141780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40540,DS-2d90a260-780a-493d-b114-bf53209c8489,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-a2bb322a-fd5d-4e2a-9f43-43909f394a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-6c9de3fb-0331-4a95-9baa-2ced81180a81,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-f35ac953-de72-4486-9106-e91f5db5dc10,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-1337d037-2515-4de7-93d1-9b22721b1a96,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-beda90e6-5d24-421f-b413-d8faa78675a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40229,DS-62a4d0f3-805d-4020-bce8-97521582cb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-c0e39a48-8c82-4983-8af3-b5f2f032bee4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1076966195-172.17.0.17-1595474463135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41840,DS-db5e062d-e9f1-4b9d-915d-79ebad9cb37d,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-0ff8a6fb-3f2d-4fef-a9b9-1ca6c6f98771,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-d5cb1dd3-58e3-4003-8cba-be2704af324d,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-2baaaecb-27a4-452b-a384-f9f5b7bd8ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-865d079b-30fd-4515-9765-d482c960c93b,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-515c2b50-2038-4bd2-aebf-7e2d9030d87c,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-c8a8e91d-8d6b-4320-9f96-afc63075244c,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-59dcdf76-7230-4ce1-85de-e9fa7d2a9cd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1076966195-172.17.0.17-1595474463135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41840,DS-db5e062d-e9f1-4b9d-915d-79ebad9cb37d,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-0ff8a6fb-3f2d-4fef-a9b9-1ca6c6f98771,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-d5cb1dd3-58e3-4003-8cba-be2704af324d,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-2baaaecb-27a4-452b-a384-f9f5b7bd8ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-865d079b-30fd-4515-9765-d482c960c93b,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-515c2b50-2038-4bd2-aebf-7e2d9030d87c,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-c8a8e91d-8d6b-4320-9f96-afc63075244c,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-59dcdf76-7230-4ce1-85de-e9fa7d2a9cd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1078209516-172.17.0.17-1595474503765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37586,DS-c87e9cd7-5c17-4f83-ab66-6b68cfc58e86,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-87a51138-3076-40ee-9fdc-e54a00c1f5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-d3c488f3-64cb-4d5a-b7db-aab0c9c47bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-450263d0-10f3-455f-a256-fd5948bed4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-76976215-d6a9-470b-9a11-5b8d8ee824b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-2b29cec7-f19e-44ea-9b0f-2c7d96aa91f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-f54c38dd-7974-4904-82e3-5f221f4da910,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-acb9b72b-294b-457c-b495-9a14e9218182,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1078209516-172.17.0.17-1595474503765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37586,DS-c87e9cd7-5c17-4f83-ab66-6b68cfc58e86,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-87a51138-3076-40ee-9fdc-e54a00c1f5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-d3c488f3-64cb-4d5a-b7db-aab0c9c47bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-450263d0-10f3-455f-a256-fd5948bed4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-76976215-d6a9-470b-9a11-5b8d8ee824b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-2b29cec7-f19e-44ea-9b0f-2c7d96aa91f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-f54c38dd-7974-4904-82e3-5f221f4da910,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-acb9b72b-294b-457c-b495-9a14e9218182,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-29006685-172.17.0.17-1595474542439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44067,DS-a50e13c6-0296-4075-83ea-1289ebf67479,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-c8ddabaa-7072-4e88-a796-c1fe14739495,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-229d09a4-cb5f-466e-9534-299836c4f4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43347,DS-3d1f6b93-2b7a-4f56-b786-30c531d9602e,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-624f2f6b-a3d5-494e-898e-de5a00e8a94c,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-0b643f86-8451-4d78-a223-6c28b148ef51,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-aedefd30-1d95-4349-96ea-445c94166aba,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-20dc9ff6-4251-4e4f-bc58-2e181e8410c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-29006685-172.17.0.17-1595474542439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44067,DS-a50e13c6-0296-4075-83ea-1289ebf67479,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-c8ddabaa-7072-4e88-a796-c1fe14739495,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-229d09a4-cb5f-466e-9534-299836c4f4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43347,DS-3d1f6b93-2b7a-4f56-b786-30c531d9602e,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-624f2f6b-a3d5-494e-898e-de5a00e8a94c,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-0b643f86-8451-4d78-a223-6c28b148ef51,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-aedefd30-1d95-4349-96ea-445c94166aba,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-20dc9ff6-4251-4e4f-bc58-2e181e8410c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951009327-172.17.0.17-1595475048066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37755,DS-e7ec8d1e-f38a-4820-a322-e840b2e41684,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-7b3f3596-8d1e-4520-803e-73f6f95fb49f,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-20224498-1710-4e58-84d8-aa3367a6d0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-59c30dd3-045b-4316-a8b9-e13774696f96,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-e34fc6c4-948b-49b5-8fd9-5710d4a8d448,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-d36b1ab3-eaee-4bbd-8058-0ed6df90f426,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-76d3c9c8-83bb-4bbb-b620-df5c1bbb12af,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-654ed82e-32b3-4a42-b1aa-17af44ed6352,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951009327-172.17.0.17-1595475048066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37755,DS-e7ec8d1e-f38a-4820-a322-e840b2e41684,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-7b3f3596-8d1e-4520-803e-73f6f95fb49f,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-20224498-1710-4e58-84d8-aa3367a6d0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-59c30dd3-045b-4316-a8b9-e13774696f96,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-e34fc6c4-948b-49b5-8fd9-5710d4a8d448,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-d36b1ab3-eaee-4bbd-8058-0ed6df90f426,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-76d3c9c8-83bb-4bbb-b620-df5c1bbb12af,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-654ed82e-32b3-4a42-b1aa-17af44ed6352,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1989620217-172.17.0.17-1595475437753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45557,DS-71466289-537d-4a45-ae26-8b85d8b4d4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38165,DS-9bde6fc9-1026-4ba6-a32b-e86a31adc2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-6e6f541f-4d92-485c-9e95-eef167ce9723,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-761fda8b-256b-41d4-8010-ee2a2351bb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-2d9fdb5b-5009-4f39-a92c-a31f199fed71,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-8f1fdb12-41f4-4b86-81b4-c67ec15e5379,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-d80e77fe-6777-4ac3-bdb4-fe2d52f491a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-93bfd3ff-df5b-4275-97a2-59f95b6adf01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1989620217-172.17.0.17-1595475437753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45557,DS-71466289-537d-4a45-ae26-8b85d8b4d4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38165,DS-9bde6fc9-1026-4ba6-a32b-e86a31adc2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-6e6f541f-4d92-485c-9e95-eef167ce9723,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-761fda8b-256b-41d4-8010-ee2a2351bb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-2d9fdb5b-5009-4f39-a92c-a31f199fed71,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-8f1fdb12-41f4-4b86-81b4-c67ec15e5379,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-d80e77fe-6777-4ac3-bdb4-fe2d52f491a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-93bfd3ff-df5b-4275-97a2-59f95b6adf01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1955309172-172.17.0.17-1595475761536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38810,DS-d0bbb431-e6e9-4193-8107-b703a696f5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-f9bc778b-e61e-4e8d-830d-8374fac9670f,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-b76557d0-b487-4d83-9c31-a0d946f0ac96,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-2bcfdec1-099c-4202-954d-a67156d85361,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-31d4d24f-708e-4a43-bc93-d1a2bff2bdcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42907,DS-fe93fbd5-2225-479b-8834-0138820aa273,DISK], DatanodeInfoWithStorage[127.0.0.1:36345,DS-3e555945-3114-4794-9fa2-076959df6079,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-c555410e-e527-4a9d-84d5-1656296655c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1955309172-172.17.0.17-1595475761536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38810,DS-d0bbb431-e6e9-4193-8107-b703a696f5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-f9bc778b-e61e-4e8d-830d-8374fac9670f,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-b76557d0-b487-4d83-9c31-a0d946f0ac96,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-2bcfdec1-099c-4202-954d-a67156d85361,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-31d4d24f-708e-4a43-bc93-d1a2bff2bdcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42907,DS-fe93fbd5-2225-479b-8834-0138820aa273,DISK], DatanodeInfoWithStorage[127.0.0.1:36345,DS-3e555945-3114-4794-9fa2-076959df6079,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-c555410e-e527-4a9d-84d5-1656296655c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-876677971-172.17.0.17-1595475828126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43707,DS-b5abe11e-c2a3-41f6-b755-6cf42da5faf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-fe645665-988f-4143-b119-9ec7993af266,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-eb668e37-d146-41f2-8111-2e0043f40120,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-91414939-637f-4d5a-8eb4-a3f5706a7c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-138eb59f-45ad-41af-b8eb-2a7d51f45b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38293,DS-f548a5d7-abac-4055-93ba-afcd9c94d48b,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-caa800ea-9a97-4952-b656-3e953c6a08e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-88fe26b9-7f79-4937-aee0-36d78b614323,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-876677971-172.17.0.17-1595475828126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43707,DS-b5abe11e-c2a3-41f6-b755-6cf42da5faf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-fe645665-988f-4143-b119-9ec7993af266,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-eb668e37-d146-41f2-8111-2e0043f40120,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-91414939-637f-4d5a-8eb4-a3f5706a7c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-138eb59f-45ad-41af-b8eb-2a7d51f45b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38293,DS-f548a5d7-abac-4055-93ba-afcd9c94d48b,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-caa800ea-9a97-4952-b656-3e953c6a08e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-88fe26b9-7f79-4937-aee0-36d78b614323,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-388662333-172.17.0.17-1595476212724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38487,DS-f5f16b4c-e376-442c-9f29-ce9d974ec82d,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-65b28292-7a07-40af-ac2a-ff432c996706,DISK], DatanodeInfoWithStorage[127.0.0.1:42856,DS-b8660a82-2f7c-4a04-acdd-c3e14f861b99,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-3df8b7b6-bc3f-4c5b-851d-f98b028d6a30,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-c871734f-a486-4da4-9560-f5180e5755d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-21a2e0c5-20ca-4c6a-aac8-f0d5ed263811,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-d3814f54-11ae-4d46-a619-10a03c8ee152,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-2e4774ab-495d-42c9-af98-e68a3ef37562,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-388662333-172.17.0.17-1595476212724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38487,DS-f5f16b4c-e376-442c-9f29-ce9d974ec82d,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-65b28292-7a07-40af-ac2a-ff432c996706,DISK], DatanodeInfoWithStorage[127.0.0.1:42856,DS-b8660a82-2f7c-4a04-acdd-c3e14f861b99,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-3df8b7b6-bc3f-4c5b-851d-f98b028d6a30,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-c871734f-a486-4da4-9560-f5180e5755d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-21a2e0c5-20ca-4c6a-aac8-f0d5ed263811,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-d3814f54-11ae-4d46-a619-10a03c8ee152,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-2e4774ab-495d-42c9-af98-e68a3ef37562,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1995071007-172.17.0.17-1595476326974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40862,DS-eddf74e5-cd01-4205-b02b-d539178abbdb,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-a4db6db2-1581-4669-afa5-331aa5d77d74,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-fe31261b-1a07-42a4-868e-7b26a74ce174,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-d0566633-0229-4366-ae26-d43b5a7a34d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-e133597c-d3fd-461c-81d3-cca3327a2317,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-d436b194-a4cf-40d8-8d55-a8a08a8ccf67,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-7af36d25-0d01-4d06-91a5-c44f2f4d26d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38041,DS-1f043150-104f-4a16-8e73-94096aa3bb07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1995071007-172.17.0.17-1595476326974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40862,DS-eddf74e5-cd01-4205-b02b-d539178abbdb,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-a4db6db2-1581-4669-afa5-331aa5d77d74,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-fe31261b-1a07-42a4-868e-7b26a74ce174,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-d0566633-0229-4366-ae26-d43b5a7a34d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-e133597c-d3fd-461c-81d3-cca3327a2317,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-d436b194-a4cf-40d8-8d55-a8a08a8ccf67,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-7af36d25-0d01-4d06-91a5-c44f2f4d26d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38041,DS-1f043150-104f-4a16-8e73-94096aa3bb07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1804814640-172.17.0.17-1595476523871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42020,DS-f870d78d-e17c-447f-a2b1-7a497bda9326,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-99f3c839-752e-4bda-a722-cdb9f61c8385,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-b6831973-8ff8-4865-ad23-efa5b01bdfcd,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-e89f215f-e23e-482f-bd0b-4a4cf86c4797,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-978d9985-38ff-4a94-84b4-b6ffc14be9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-984f524c-62af-48db-bc8a-5ca903a3682e,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-9461c721-494e-4367-958c-1371961bb702,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-b14628df-51fd-45d6-8d12-e54e20e73a0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1804814640-172.17.0.17-1595476523871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42020,DS-f870d78d-e17c-447f-a2b1-7a497bda9326,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-99f3c839-752e-4bda-a722-cdb9f61c8385,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-b6831973-8ff8-4865-ad23-efa5b01bdfcd,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-e89f215f-e23e-482f-bd0b-4a4cf86c4797,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-978d9985-38ff-4a94-84b4-b6ffc14be9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-984f524c-62af-48db-bc8a-5ca903a3682e,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-9461c721-494e-4367-958c-1371961bb702,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-b14628df-51fd-45d6-8d12-e54e20e73a0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1477406247-172.17.0.17-1595476614399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42782,DS-6684f242-6e16-4e70-b2c8-8d1962ce8b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-ec77427d-b9e9-49a9-a9b5-461d7807746b,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-a28d2820-6f99-44ef-9991-56d0d60a9354,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-36b26c04-1ada-4c2e-8e69-46923e02327c,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-72b3e643-fbb4-410e-8714-1242dcc89e94,DISK], DatanodeInfoWithStorage[127.0.0.1:34291,DS-9f2b4ca4-20da-4ef4-bb31-60d6ec7f4128,DISK], DatanodeInfoWithStorage[127.0.0.1:39785,DS-b3d4227c-4c89-406d-9e34-456738ab559d,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-079586ed-2e02-420c-9e29-80ca437adb3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1477406247-172.17.0.17-1595476614399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42782,DS-6684f242-6e16-4e70-b2c8-8d1962ce8b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-ec77427d-b9e9-49a9-a9b5-461d7807746b,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-a28d2820-6f99-44ef-9991-56d0d60a9354,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-36b26c04-1ada-4c2e-8e69-46923e02327c,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-72b3e643-fbb4-410e-8714-1242dcc89e94,DISK], DatanodeInfoWithStorage[127.0.0.1:34291,DS-9f2b4ca4-20da-4ef4-bb31-60d6ec7f4128,DISK], DatanodeInfoWithStorage[127.0.0.1:39785,DS-b3d4227c-4c89-406d-9e34-456738ab559d,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-079586ed-2e02-420c-9e29-80ca437adb3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-647110814-172.17.0.17-1595476848423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39539,DS-b36a8f0d-da04-4be2-9123-5bd02921b0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-3bfd167f-199a-4107-bd91-77faefa9cfdf,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-56981122-1c5f-4036-b7e2-cf4e3ec70b61,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-1c863550-d6f1-4668-be64-1187bbaf19e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-ed5d6e10-ac91-42f3-8850-9c43c689d143,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-1232eb11-bcba-4c7e-bc0e-b29fa1add6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34598,DS-533ea46b-5156-424b-8873-c58a990d85c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-73ad5fc1-5ec1-44e4-b18c-67727d0e370b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-647110814-172.17.0.17-1595476848423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39539,DS-b36a8f0d-da04-4be2-9123-5bd02921b0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-3bfd167f-199a-4107-bd91-77faefa9cfdf,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-56981122-1c5f-4036-b7e2-cf4e3ec70b61,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-1c863550-d6f1-4668-be64-1187bbaf19e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-ed5d6e10-ac91-42f3-8850-9c43c689d143,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-1232eb11-bcba-4c7e-bc0e-b29fa1add6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34598,DS-533ea46b-5156-424b-8873-c58a990d85c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-73ad5fc1-5ec1-44e4-b18c-67727d0e370b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-358787252-172.17.0.17-1595476889131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33066,DS-f69a9988-b759-4dd6-9f3c-34aca8196c53,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-795af514-1832-4170-8b2b-da0fdacae1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-a2b00b3d-8e25-4dea-9fe6-446f4a76e0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-79179daf-63ae-4c6c-a3a3-cb8dfab8970d,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-c0ab7ad3-a56b-4feb-9a15-476df7935179,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-44bd20a1-7eb7-4d05-9ed2-0047460f34ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-43fee59f-19b1-4e5f-acf3-64d980d04c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-50e506f6-209f-44d7-bcca-4805a79a25b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-358787252-172.17.0.17-1595476889131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33066,DS-f69a9988-b759-4dd6-9f3c-34aca8196c53,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-795af514-1832-4170-8b2b-da0fdacae1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-a2b00b3d-8e25-4dea-9fe6-446f4a76e0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-79179daf-63ae-4c6c-a3a3-cb8dfab8970d,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-c0ab7ad3-a56b-4feb-9a15-476df7935179,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-44bd20a1-7eb7-4d05-9ed2-0047460f34ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-43fee59f-19b1-4e5f-acf3-64d980d04c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-50e506f6-209f-44d7-bcca-4805a79a25b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1747078663-172.17.0.17-1595477050247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44471,DS-dca69e60-e506-4883-b469-aa7cfa07aa63,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-108103e8-d7d7-49e1-9e0a-822f851a5a77,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-b6c285a0-1bac-4042-9020-1cb1fe0dbe42,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-d6179002-e214-42fc-a2d6-efd59db29e47,DISK], DatanodeInfoWithStorage[127.0.0.1:36783,DS-71400fbe-9254-41bb-ad38-bf7699e83ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-9dd7b6a4-cc52-4693-8057-3c8c49bac343,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-42647b38-57af-440b-99aa-5be380bed42c,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-85c656fe-7b01-4b4b-8a23-de5bf28bb5d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1747078663-172.17.0.17-1595477050247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44471,DS-dca69e60-e506-4883-b469-aa7cfa07aa63,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-108103e8-d7d7-49e1-9e0a-822f851a5a77,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-b6c285a0-1bac-4042-9020-1cb1fe0dbe42,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-d6179002-e214-42fc-a2d6-efd59db29e47,DISK], DatanodeInfoWithStorage[127.0.0.1:36783,DS-71400fbe-9254-41bb-ad38-bf7699e83ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-9dd7b6a4-cc52-4693-8057-3c8c49bac343,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-42647b38-57af-440b-99aa-5be380bed42c,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-85c656fe-7b01-4b4b-8a23-de5bf28bb5d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-245519679-172.17.0.17-1595477438133:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36066,DS-63516355-71c0-47d7-807c-f96a360c8acb,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-700b91be-6c3d-4edb-a320-04c830981c28,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-39be29b9-52cb-446d-8312-3f6cace67396,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-ab64c3d5-80e8-4962-b6ac-c30502c8c025,DISK], DatanodeInfoWithStorage[127.0.0.1:44170,DS-aae9b719-efc1-4ef8-877e-1acb8f757b90,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-cff48624-c78f-440f-9420-76e1539d6c61,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-9e83ab5b-e2e2-4ab3-b980-f6def2f14b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45790,DS-9547ed07-803a-4be5-a626-d82a4b2d0e8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-245519679-172.17.0.17-1595477438133:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36066,DS-63516355-71c0-47d7-807c-f96a360c8acb,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-700b91be-6c3d-4edb-a320-04c830981c28,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-39be29b9-52cb-446d-8312-3f6cace67396,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-ab64c3d5-80e8-4962-b6ac-c30502c8c025,DISK], DatanodeInfoWithStorage[127.0.0.1:44170,DS-aae9b719-efc1-4ef8-877e-1acb8f757b90,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-cff48624-c78f-440f-9420-76e1539d6c61,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-9e83ab5b-e2e2-4ab3-b980-f6def2f14b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45790,DS-9547ed07-803a-4be5-a626-d82a4b2d0e8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1020918859-172.17.0.17-1595478211679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42281,DS-f6446b8e-e279-40dc-8cb9-ef47c2700844,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-ad843b0f-fa72-40ac-b79b-7cdfa87e2cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-a7b1ce2a-d857-4ecf-8192-4bf9732e094d,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-1683050f-00bf-449a-b69e-033eb9d4274d,DISK], DatanodeInfoWithStorage[127.0.0.1:41330,DS-7dd9b1fe-0c5c-4a9d-9b4f-5c5840865dde,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-66d04572-c0b9-4908-8562-f743cd19f805,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-6f104823-cfe6-43d5-8738-0f955e8cdfec,DISK], DatanodeInfoWithStorage[127.0.0.1:34747,DS-dfde20b8-1095-475b-87f3-acf8cecaf976,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1020918859-172.17.0.17-1595478211679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42281,DS-f6446b8e-e279-40dc-8cb9-ef47c2700844,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-ad843b0f-fa72-40ac-b79b-7cdfa87e2cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-a7b1ce2a-d857-4ecf-8192-4bf9732e094d,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-1683050f-00bf-449a-b69e-033eb9d4274d,DISK], DatanodeInfoWithStorage[127.0.0.1:41330,DS-7dd9b1fe-0c5c-4a9d-9b4f-5c5840865dde,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-66d04572-c0b9-4908-8562-f743cd19f805,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-6f104823-cfe6-43d5-8738-0f955e8cdfec,DISK], DatanodeInfoWithStorage[127.0.0.1:34747,DS-dfde20b8-1095-475b-87f3-acf8cecaf976,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1437777494-172.17.0.17-1595478506628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45002,DS-e0877330-c2b3-41f2-8683-6abadb216bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-89227f24-6b7c-47bc-94a1-2cf58af423a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-925a6a9b-353c-4e80-bbf6-2a37e0191a58,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-d725c30d-6229-4408-8137-e0c06d9dd26f,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-59d06b09-8f08-467c-bc80-3f23b85be4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-7fa9913b-a981-45c0-b138-7c6203994555,DISK], DatanodeInfoWithStorage[127.0.0.1:38720,DS-2a8fab5b-4288-4762-b3a5-4cb0762322c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-11f666fd-1199-4f62-b7b8-5cf03e42298c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1437777494-172.17.0.17-1595478506628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45002,DS-e0877330-c2b3-41f2-8683-6abadb216bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-89227f24-6b7c-47bc-94a1-2cf58af423a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-925a6a9b-353c-4e80-bbf6-2a37e0191a58,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-d725c30d-6229-4408-8137-e0c06d9dd26f,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-59d06b09-8f08-467c-bc80-3f23b85be4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-7fa9913b-a981-45c0-b138-7c6203994555,DISK], DatanodeInfoWithStorage[127.0.0.1:38720,DS-2a8fab5b-4288-4762-b3a5-4cb0762322c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-11f666fd-1199-4f62-b7b8-5cf03e42298c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5280
