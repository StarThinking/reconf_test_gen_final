reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-200445347-172.17.0.17-1595848704262:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43913,DS-907185cf-76e6-4054-a632-6bb9586cd8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-db9bc5ed-1bfc-40ed-b27a-ddddc89e8f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-c1792051-8778-4bc9-a3d3-ac9c1438c062,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-21f5a375-8aac-4952-8088-8e9cd156e4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-a726b683-ebb1-41ab-b369-4c3ff82c478c,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-70dc9e06-4881-4076-a390-1934ad0d9bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-d943f538-12de-4396-8559-aa4472d24f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-cd2ec275-be22-4d2b-aa0a-68a8419a0874,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-200445347-172.17.0.17-1595848704262:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43913,DS-907185cf-76e6-4054-a632-6bb9586cd8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-db9bc5ed-1bfc-40ed-b27a-ddddc89e8f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-c1792051-8778-4bc9-a3d3-ac9c1438c062,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-21f5a375-8aac-4952-8088-8e9cd156e4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-a726b683-ebb1-41ab-b369-4c3ff82c478c,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-70dc9e06-4881-4076-a390-1934ad0d9bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-d943f538-12de-4396-8559-aa4472d24f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-cd2ec275-be22-4d2b-aa0a-68a8419a0874,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-247572880-172.17.0.17-1595848740248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43363,DS-10470f25-18b8-4fd2-8b45-7ebf50cfd84c,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-ca52b806-7ad7-4e33-b32a-263d5ec82f52,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-7bc32059-1115-4bf4-95aa-15dec0dc3ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-ee3ee266-d8f8-4d39-9942-ee23e5c43bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:46305,DS-f60e5a76-6f98-4832-b9db-f6248d07166a,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-ce746e41-f2a6-4bf0-af19-f49e4593eda1,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-923aee5c-37da-4e5e-b5ee-d22c47d1fd3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-9655d37e-21e1-4b39-b631-020f2ccbd0f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-247572880-172.17.0.17-1595848740248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43363,DS-10470f25-18b8-4fd2-8b45-7ebf50cfd84c,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-ca52b806-7ad7-4e33-b32a-263d5ec82f52,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-7bc32059-1115-4bf4-95aa-15dec0dc3ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-ee3ee266-d8f8-4d39-9942-ee23e5c43bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:46305,DS-f60e5a76-6f98-4832-b9db-f6248d07166a,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-ce746e41-f2a6-4bf0-af19-f49e4593eda1,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-923aee5c-37da-4e5e-b5ee-d22c47d1fd3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-9655d37e-21e1-4b39-b631-020f2ccbd0f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-308890440-172.17.0.17-1595848888180:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44678,DS-0e55622e-8e57-4da2-8f56-0a4929cb1bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-ea668d5d-0891-4ec9-aa26-40937adca992,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-f6aa2775-1dd5-46dc-82ce-f0c9fd8952f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-2185b4a6-f297-48a9-a7ad-d9696f6e769f,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-6bcf5d8d-2f2d-4757-a62a-ad0226c92bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-ed54fa03-5d60-4655-a547-1eafacce60ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-637390cb-9828-4f41-96a0-5e6272ccb6da,DISK], DatanodeInfoWithStorage[127.0.0.1:40541,DS-cda5f3cc-e545-46ee-912d-cdfeb28a17d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-308890440-172.17.0.17-1595848888180:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44678,DS-0e55622e-8e57-4da2-8f56-0a4929cb1bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-ea668d5d-0891-4ec9-aa26-40937adca992,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-f6aa2775-1dd5-46dc-82ce-f0c9fd8952f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-2185b4a6-f297-48a9-a7ad-d9696f6e769f,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-6bcf5d8d-2f2d-4757-a62a-ad0226c92bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-ed54fa03-5d60-4655-a547-1eafacce60ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-637390cb-9828-4f41-96a0-5e6272ccb6da,DISK], DatanodeInfoWithStorage[127.0.0.1:40541,DS-cda5f3cc-e545-46ee-912d-cdfeb28a17d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1389474936-172.17.0.17-1595849481003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42680,DS-8b789a5b-fff6-4572-b067-d1f7cbb53362,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-07743bb4-e61c-4a5b-a855-dafb1ff85065,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-ba72c65f-dc96-438e-acfb-99b63ceb8d78,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-b39c9d4f-eebc-4236-9d88-ad32246fb03f,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-8b83d656-f758-47a9-b2e6-0b4376a319ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-4712e340-2ca7-4d42-9937-6c6331e71728,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-60a9f79f-bdee-4c19-b54e-6d014e326bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-92b1219e-393a-458e-8718-fbb0e1b6bc42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1389474936-172.17.0.17-1595849481003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42680,DS-8b789a5b-fff6-4572-b067-d1f7cbb53362,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-07743bb4-e61c-4a5b-a855-dafb1ff85065,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-ba72c65f-dc96-438e-acfb-99b63ceb8d78,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-b39c9d4f-eebc-4236-9d88-ad32246fb03f,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-8b83d656-f758-47a9-b2e6-0b4376a319ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-4712e340-2ca7-4d42-9937-6c6331e71728,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-60a9f79f-bdee-4c19-b54e-6d014e326bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-92b1219e-393a-458e-8718-fbb0e1b6bc42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-468931582-172.17.0.17-1595849698901:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46080,DS-5a1a7055-66f6-4674-947e-39a3acde90e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44643,DS-6142ece4-64e9-4ff7-a643-e381a148795a,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-7bab2672-9446-45b0-b4a8-7e064469dbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39376,DS-ca854742-3e7e-4f6a-ba07-5d1ba50062a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-d7cef685-fc7e-4357-b155-f64f6a42390b,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-b05d6518-7c2d-4aab-b828-6d1e84de284a,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-96b90835-e09f-43fd-901c-c323ff52c538,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-f306cdff-24b2-4815-b59d-d5a4e2d3204f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-468931582-172.17.0.17-1595849698901:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46080,DS-5a1a7055-66f6-4674-947e-39a3acde90e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44643,DS-6142ece4-64e9-4ff7-a643-e381a148795a,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-7bab2672-9446-45b0-b4a8-7e064469dbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39376,DS-ca854742-3e7e-4f6a-ba07-5d1ba50062a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-d7cef685-fc7e-4357-b155-f64f6a42390b,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-b05d6518-7c2d-4aab-b828-6d1e84de284a,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-96b90835-e09f-43fd-901c-c323ff52c538,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-f306cdff-24b2-4815-b59d-d5a4e2d3204f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1981403971-172.17.0.17-1595850396347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43035,DS-b2375e40-d137-4be2-9927-6615758a10dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-8d205284-ad88-42af-a6b9-7a84e188fc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-4c0e0b27-7000-4f36-9553-bfcb26187443,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-6961a185-9aea-41d6-a12e-caf0528f6acf,DISK], DatanodeInfoWithStorage[127.0.0.1:36083,DS-cedce119-fa54-48fb-89d7-26ce1bf7d9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-219097e2-a202-43fe-98ab-2cf89bb50914,DISK], DatanodeInfoWithStorage[127.0.0.1:41257,DS-dd7d7ff3-7171-4279-b5b0-a0f91167ffe4,DISK], DatanodeInfoWithStorage[127.0.0.1:33382,DS-9557d98d-853d-4e29-ac5d-b7e2741c5c32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1981403971-172.17.0.17-1595850396347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43035,DS-b2375e40-d137-4be2-9927-6615758a10dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-8d205284-ad88-42af-a6b9-7a84e188fc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-4c0e0b27-7000-4f36-9553-bfcb26187443,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-6961a185-9aea-41d6-a12e-caf0528f6acf,DISK], DatanodeInfoWithStorage[127.0.0.1:36083,DS-cedce119-fa54-48fb-89d7-26ce1bf7d9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-219097e2-a202-43fe-98ab-2cf89bb50914,DISK], DatanodeInfoWithStorage[127.0.0.1:41257,DS-dd7d7ff3-7171-4279-b5b0-a0f91167ffe4,DISK], DatanodeInfoWithStorage[127.0.0.1:33382,DS-9557d98d-853d-4e29-ac5d-b7e2741c5c32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1844535677-172.17.0.17-1595850566863:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46087,DS-b834b18c-cd39-40e9-a076-732ee712aa6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-86aa5c68-f08a-4aa2-9e66-fdfe9ab2ab68,DISK], DatanodeInfoWithStorage[127.0.0.1:46539,DS-d7beab66-68c7-4495-b973-a4a542f9a155,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-c8e64c22-462a-4a96-ba12-0adea84875b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-83e3b0b3-0237-4071-bc13-2e45ecc08e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-fdf2eefe-1e59-4e47-a8c1-9945dc96bb90,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-22b0bf82-f118-42fb-a9b7-1d3ab34813f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-d3416b3d-086e-4e65-ab89-102816d003e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1844535677-172.17.0.17-1595850566863:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46087,DS-b834b18c-cd39-40e9-a076-732ee712aa6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-86aa5c68-f08a-4aa2-9e66-fdfe9ab2ab68,DISK], DatanodeInfoWithStorage[127.0.0.1:46539,DS-d7beab66-68c7-4495-b973-a4a542f9a155,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-c8e64c22-462a-4a96-ba12-0adea84875b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-83e3b0b3-0237-4071-bc13-2e45ecc08e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-fdf2eefe-1e59-4e47-a8c1-9945dc96bb90,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-22b0bf82-f118-42fb-a9b7-1d3ab34813f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-d3416b3d-086e-4e65-ab89-102816d003e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-981570037-172.17.0.17-1595850608861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35089,DS-2d102e78-aae7-4017-ba58-57ce5015995f,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-bcb32f76-d8f6-482b-b546-94a3d491148a,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-77c9dbac-6843-44fc-83b3-61546c9e361f,DISK], DatanodeInfoWithStorage[127.0.0.1:34393,DS-23b5ceba-2a6d-41b4-9f04-c3a4e352e534,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-e5e395b4-edfd-429c-9cfa-6e0a9799b4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36898,DS-639fc61d-c5e4-4bc1-9495-9bd090ed5d74,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-95f94285-a204-4f0f-830d-1c34eece5bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-8d9e7e0d-eb9d-4f83-8ef2-e6fa9f5274eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-981570037-172.17.0.17-1595850608861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35089,DS-2d102e78-aae7-4017-ba58-57ce5015995f,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-bcb32f76-d8f6-482b-b546-94a3d491148a,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-77c9dbac-6843-44fc-83b3-61546c9e361f,DISK], DatanodeInfoWithStorage[127.0.0.1:34393,DS-23b5ceba-2a6d-41b4-9f04-c3a4e352e534,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-e5e395b4-edfd-429c-9cfa-6e0a9799b4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36898,DS-639fc61d-c5e4-4bc1-9495-9bd090ed5d74,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-95f94285-a204-4f0f-830d-1c34eece5bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-8d9e7e0d-eb9d-4f83-8ef2-e6fa9f5274eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1615152962-172.17.0.17-1595850827524:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42866,DS-8d3effd6-9f2a-40b8-a0a6-0533721fda78,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-e48ecbbb-0d02-435f-a138-3183a9c27f50,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-b9dd9e4c-d871-474b-a324-b9b3d9231f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-17f5e777-fc78-4848-b690-c80f014c7d93,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-498b6efc-8f9c-4f0f-8f46-9534bac02e88,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-5f9d3069-9a8a-4e7d-9a18-c705bd369c13,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-6575c96a-e978-445b-bfe1-2e69776d56f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-9e5f278b-23c4-4711-a238-bf674da8eeb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1615152962-172.17.0.17-1595850827524:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42866,DS-8d3effd6-9f2a-40b8-a0a6-0533721fda78,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-e48ecbbb-0d02-435f-a138-3183a9c27f50,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-b9dd9e4c-d871-474b-a324-b9b3d9231f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-17f5e777-fc78-4848-b690-c80f014c7d93,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-498b6efc-8f9c-4f0f-8f46-9534bac02e88,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-5f9d3069-9a8a-4e7d-9a18-c705bd369c13,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-6575c96a-e978-445b-bfe1-2e69776d56f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-9e5f278b-23c4-4711-a238-bf674da8eeb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-331431272-172.17.0.17-1595851070506:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44673,DS-d978123c-07fe-4523-a0a3-047d1cab2a73,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-551e9e76-7a39-420e-b8d3-9b6d319d67e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-435a304d-ba41-4970-be38-8acc5566616f,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-8a6916b3-2e94-4ea5-a5b4-18b1c7c8604d,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-bbe7ecec-919d-4e13-a52d-f8bc7a665bae,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-8ca92b0a-422e-4ff1-ac2a-7afe6ba74332,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-025d528d-0ee2-42ef-a884-2671911d0831,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-75bc18e9-cc0e-4ef7-b636-30e91dd0c1d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-331431272-172.17.0.17-1595851070506:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44673,DS-d978123c-07fe-4523-a0a3-047d1cab2a73,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-551e9e76-7a39-420e-b8d3-9b6d319d67e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-435a304d-ba41-4970-be38-8acc5566616f,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-8a6916b3-2e94-4ea5-a5b4-18b1c7c8604d,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-bbe7ecec-919d-4e13-a52d-f8bc7a665bae,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-8ca92b0a-422e-4ff1-ac2a-7afe6ba74332,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-025d528d-0ee2-42ef-a884-2671911d0831,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-75bc18e9-cc0e-4ef7-b636-30e91dd0c1d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-99309639-172.17.0.17-1595852210858:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36076,DS-a7fd023b-78e9-4c50-9395-1b6b68e9249d,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-63c9a696-0d83-4687-95c3-675ae784efbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-5775a95e-de67-43cd-8ff4-d454cee512ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38860,DS-261afa5f-e9df-46bf-a277-e98356140f46,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-b3be8a38-1cd2-41a1-82eb-191f0e65bffd,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-4d40ab15-5877-4cd1-80da-82a0b2df51f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-3ba27f49-ea9e-48e4-bea7-2a632eea47c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-ea9a054b-4a47-4ec9-abeb-f170af5e74f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-99309639-172.17.0.17-1595852210858:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36076,DS-a7fd023b-78e9-4c50-9395-1b6b68e9249d,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-63c9a696-0d83-4687-95c3-675ae784efbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-5775a95e-de67-43cd-8ff4-d454cee512ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38860,DS-261afa5f-e9df-46bf-a277-e98356140f46,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-b3be8a38-1cd2-41a1-82eb-191f0e65bffd,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-4d40ab15-5877-4cd1-80da-82a0b2df51f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-3ba27f49-ea9e-48e4-bea7-2a632eea47c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-ea9a054b-4a47-4ec9-abeb-f170af5e74f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5180
