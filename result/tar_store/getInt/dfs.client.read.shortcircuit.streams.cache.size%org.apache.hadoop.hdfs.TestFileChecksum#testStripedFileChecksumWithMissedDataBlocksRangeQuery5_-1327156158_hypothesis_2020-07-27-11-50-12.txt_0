reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 1
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 1
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1493927397-172.17.0.10-1595850958699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41612,DS-6a564aa7-8141-47ab-a67b-603ccdabaccd,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-19d3ca5b-3da3-449f-adb3-fdaa733cc849,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-6bb9e40e-503e-44a5-aed6-ad7490484378,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-f92a68c6-f92e-467d-aa72-e6ca2467bb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-55e38a78-7d3a-4dcf-8db2-edc83914971b,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-a743521e-67bc-4e7f-a73f-039b2c10bc41,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-d9404625-56fd-4190-8735-3a98b5a8a8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-b5696abf-f202-486a-94b0-1a2befc06ec3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1493927397-172.17.0.10-1595850958699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41612,DS-6a564aa7-8141-47ab-a67b-603ccdabaccd,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-19d3ca5b-3da3-449f-adb3-fdaa733cc849,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-6bb9e40e-503e-44a5-aed6-ad7490484378,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-f92a68c6-f92e-467d-aa72-e6ca2467bb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-55e38a78-7d3a-4dcf-8db2-edc83914971b,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-a743521e-67bc-4e7f-a73f-039b2c10bc41,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-d9404625-56fd-4190-8735-3a98b5a8a8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-b5696abf-f202-486a-94b0-1a2befc06ec3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 1
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-924077228-172.17.0.10-1595851173471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39265,DS-6d85052c-a69e-46bc-831a-0468752fbe58,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-50332412-e7aa-4edc-9339-120e219e3d15,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-5416e613-359a-40e9-a2d9-cfcdd92c0ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-2c88136b-bdfd-4b2f-a401-821e12c63f04,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-4b948f95-1e6e-4d31-9010-d8bf801d049e,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-9083a278-acb7-4746-b188-f51a2c6480b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-34a55c48-9368-43e9-9c7b-3d8e83d1e9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-72910a38-1c75-4c53-8b2d-8ffa56a669ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-924077228-172.17.0.10-1595851173471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39265,DS-6d85052c-a69e-46bc-831a-0468752fbe58,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-50332412-e7aa-4edc-9339-120e219e3d15,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-5416e613-359a-40e9-a2d9-cfcdd92c0ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-2c88136b-bdfd-4b2f-a401-821e12c63f04,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-4b948f95-1e6e-4d31-9010-d8bf801d049e,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-9083a278-acb7-4746-b188-f51a2c6480b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-34a55c48-9368-43e9-9c7b-3d8e83d1e9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-72910a38-1c75-4c53-8b2d-8ffa56a669ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 1
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-291844643-172.17.0.10-1595851900940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33474,DS-84aabcc4-3737-42c4-9d78-4e98af017cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-3a5622d1-1876-4add-b5c8-81a1e960d543,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-b744044a-38fe-4904-9a78-f7dbae6a0ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-c8caf343-ceed-4e9e-89c0-eb104bf2be14,DISK], DatanodeInfoWithStorage[127.0.0.1:33081,DS-0b5a1dad-8730-4033-9509-dd488939f1e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39752,DS-59017ce9-974f-42d4-8bd2-0ac529c538ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-f4d7fcb0-6649-4fac-b5e6-6cd1caa7d432,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-aa22c3ff-0880-4e24-b95d-07e47f606e42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-291844643-172.17.0.10-1595851900940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33474,DS-84aabcc4-3737-42c4-9d78-4e98af017cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-3a5622d1-1876-4add-b5c8-81a1e960d543,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-b744044a-38fe-4904-9a78-f7dbae6a0ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-c8caf343-ceed-4e9e-89c0-eb104bf2be14,DISK], DatanodeInfoWithStorage[127.0.0.1:33081,DS-0b5a1dad-8730-4033-9509-dd488939f1e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39752,DS-59017ce9-974f-42d4-8bd2-0ac529c538ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-f4d7fcb0-6649-4fac-b5e6-6cd1caa7d432,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-aa22c3ff-0880-4e24-b95d-07e47f606e42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 1
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-679916635-172.17.0.10-1595852035367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40875,DS-93027cb7-68c9-4351-b3c9-00d0a5f51a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-68d1c526-ef58-4c2c-aae6-9029c843783c,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-563efb1b-d49d-436f-94c3-be76abe5fe8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42283,DS-ae418a58-8b40-4f8b-bfd7-d4b47e403128,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-6bf60c8b-7f3a-43ad-8460-b50f45e8d408,DISK], DatanodeInfoWithStorage[127.0.0.1:43240,DS-5ff73710-0c69-4e0d-a8d5-af6ec954af9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-183f1955-5d8d-425b-90e1-3963c2ad6686,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-55e03b92-4ff5-4c02-8b98-c9e116a13795,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-679916635-172.17.0.10-1595852035367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40875,DS-93027cb7-68c9-4351-b3c9-00d0a5f51a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-68d1c526-ef58-4c2c-aae6-9029c843783c,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-563efb1b-d49d-436f-94c3-be76abe5fe8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42283,DS-ae418a58-8b40-4f8b-bfd7-d4b47e403128,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-6bf60c8b-7f3a-43ad-8460-b50f45e8d408,DISK], DatanodeInfoWithStorage[127.0.0.1:43240,DS-5ff73710-0c69-4e0d-a8d5-af6ec954af9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-183f1955-5d8d-425b-90e1-3963c2ad6686,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-55e03b92-4ff5-4c02-8b98-c9e116a13795,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 1
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-137440551-172.17.0.10-1595852159236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43759,DS-5a95bb3f-2e8c-4473-88be-26413f329e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-17db6d26-514d-4e63-b02e-162eb3131eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-1e2b69dd-5208-45a2-bb0a-4d0c92124570,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-2713828d-6b4d-4ab5-9b88-83e44499d675,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-89a64c58-729b-431e-8e09-fbf187958815,DISK], DatanodeInfoWithStorage[127.0.0.1:43716,DS-b4c4c1ff-a4f1-4c48-82c8-2612c4eddddc,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-320e204c-2b7a-4d6e-957d-4826eb4308fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-bcb3c423-6b0e-4485-8bd3-a2e037ee6b30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-137440551-172.17.0.10-1595852159236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43759,DS-5a95bb3f-2e8c-4473-88be-26413f329e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-17db6d26-514d-4e63-b02e-162eb3131eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-1e2b69dd-5208-45a2-bb0a-4d0c92124570,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-2713828d-6b4d-4ab5-9b88-83e44499d675,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-89a64c58-729b-431e-8e09-fbf187958815,DISK], DatanodeInfoWithStorage[127.0.0.1:43716,DS-b4c4c1ff-a4f1-4c48-82c8-2612c4eddddc,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-320e204c-2b7a-4d6e-957d-4826eb4308fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-bcb3c423-6b0e-4485-8bd3-a2e037ee6b30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 1
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1138571062-172.17.0.10-1595852380973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43337,DS-63c558b9-9f11-43d6-9ab3-23afb16013ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-f54e9340-60f1-468d-b9a3-226f531fd704,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-42049a7e-cb09-4152-acd9-636e486d1b82,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-f3dad6d1-458e-4309-aacd-b48f19fbcae7,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-e10e52e2-4162-4b0a-8326-c3851c598cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45769,DS-626c1b34-0eae-4f3f-961d-c38d568c5d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-e1e5cb7c-25bc-46e0-bc26-690ceb009019,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-e9a031bd-239f-4bb8-b1d8-22c4982c1bce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1138571062-172.17.0.10-1595852380973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43337,DS-63c558b9-9f11-43d6-9ab3-23afb16013ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-f54e9340-60f1-468d-b9a3-226f531fd704,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-42049a7e-cb09-4152-acd9-636e486d1b82,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-f3dad6d1-458e-4309-aacd-b48f19fbcae7,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-e10e52e2-4162-4b0a-8326-c3851c598cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45769,DS-626c1b34-0eae-4f3f-961d-c38d568c5d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-e1e5cb7c-25bc-46e0-bc26-690ceb009019,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-e9a031bd-239f-4bb8-b1d8-22c4982c1bce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 1
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1069077034-172.17.0.10-1595852650019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45970,DS-4d8684e9-32c8-4bba-8275-39c48c94aacc,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-811099d8-3161-4f8e-b431-7008c05c04b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-4a683b3d-2465-42e6-bfed-73871bf63dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-8af6b4f8-2e18-49ef-a71b-7ed050055e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-4270151c-1193-4df2-b0a0-9b61ed86ae58,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-78ada3c6-683b-4bab-b7ba-4a538989c3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45354,DS-1dc1db7a-4cf8-4116-884e-6c5f4ec7706f,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-4896d155-cf77-49eb-8183-46f4f5a05335,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1069077034-172.17.0.10-1595852650019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45970,DS-4d8684e9-32c8-4bba-8275-39c48c94aacc,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-811099d8-3161-4f8e-b431-7008c05c04b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-4a683b3d-2465-42e6-bfed-73871bf63dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-8af6b4f8-2e18-49ef-a71b-7ed050055e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-4270151c-1193-4df2-b0a0-9b61ed86ae58,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-78ada3c6-683b-4bab-b7ba-4a538989c3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45354,DS-1dc1db7a-4cf8-4116-884e-6c5f4ec7706f,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-4896d155-cf77-49eb-8183-46f4f5a05335,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 1
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1437166805-172.17.0.10-1595852810213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41779,DS-53103b89-9e09-4e2d-b7a2-9d454328f6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-690f22d8-36f8-4848-88c9-ab00a551f91a,DISK], DatanodeInfoWithStorage[127.0.0.1:37247,DS-e8d7c219-96f0-4fe5-8832-50d273ac14ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-48bfa6a0-8e55-4e8e-a88f-9ab64ca49720,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-a4621d98-96ca-418f-8ec9-e935ee222756,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-115a278c-ff47-4202-bb16-0dde6f6d6be1,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-c378b6a2-517c-4787-8ede-311df3b7d614,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-2adb7872-fe2c-4650-a9b4-f7b4e233ec84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1437166805-172.17.0.10-1595852810213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41779,DS-53103b89-9e09-4e2d-b7a2-9d454328f6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-690f22d8-36f8-4848-88c9-ab00a551f91a,DISK], DatanodeInfoWithStorage[127.0.0.1:37247,DS-e8d7c219-96f0-4fe5-8832-50d273ac14ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-48bfa6a0-8e55-4e8e-a88f-9ab64ca49720,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-a4621d98-96ca-418f-8ec9-e935ee222756,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-115a278c-ff47-4202-bb16-0dde6f6d6be1,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-c378b6a2-517c-4787-8ede-311df3b7d614,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-2adb7872-fe2c-4650-a9b4-f7b4e233ec84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 1
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-792258296-172.17.0.10-1595852856577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37447,DS-89edb52c-3ccc-4153-ba51-991b894add33,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-13ee5580-0aa0-43ff-a858-a2393898886f,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-96715930-9a06-4714-9c2b-5a3a8e3d1216,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-1c38b99f-51f5-4588-aace-9e28ff4097f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-a58d08fb-3a6e-406f-ac96-a7d0c5e9874d,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-a7b54060-d189-4710-84bf-3e486f1197a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-6440c816-c8ca-49e5-a61e-86a4c3f47bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-918cb51d-408a-4370-b1c4-8ace1b18b0ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-792258296-172.17.0.10-1595852856577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37447,DS-89edb52c-3ccc-4153-ba51-991b894add33,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-13ee5580-0aa0-43ff-a858-a2393898886f,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-96715930-9a06-4714-9c2b-5a3a8e3d1216,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-1c38b99f-51f5-4588-aace-9e28ff4097f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-a58d08fb-3a6e-406f-ac96-a7d0c5e9874d,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-a7b54060-d189-4710-84bf-3e486f1197a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-6440c816-c8ca-49e5-a61e-86a4c3f47bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-918cb51d-408a-4370-b1c4-8ace1b18b0ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 1
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1152774096-172.17.0.10-1595853324753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33102,DS-3c6fbedc-4552-4e05-a43e-82420cf5ef06,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-f32506b5-e73b-46e5-a7d0-a5e1e4e2888e,DISK], DatanodeInfoWithStorage[127.0.0.1:35621,DS-b140ed44-2a0d-4405-b4b2-51e7ce16b41d,DISK], DatanodeInfoWithStorage[127.0.0.1:33073,DS-b0cb6a5e-e4c1-46ec-9726-ef95462da13c,DISK], DatanodeInfoWithStorage[127.0.0.1:40405,DS-5e38a8b4-e26f-4e17-8bd1-c5bdff5c1e85,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-aafc2879-241f-47e7-991e-65bce36636fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-e761664d-589c-44c2-a25f-7de4173af0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-61a3f55a-b834-4cb3-86a6-289c89ffd0c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1152774096-172.17.0.10-1595853324753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33102,DS-3c6fbedc-4552-4e05-a43e-82420cf5ef06,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-f32506b5-e73b-46e5-a7d0-a5e1e4e2888e,DISK], DatanodeInfoWithStorage[127.0.0.1:35621,DS-b140ed44-2a0d-4405-b4b2-51e7ce16b41d,DISK], DatanodeInfoWithStorage[127.0.0.1:33073,DS-b0cb6a5e-e4c1-46ec-9726-ef95462da13c,DISK], DatanodeInfoWithStorage[127.0.0.1:40405,DS-5e38a8b4-e26f-4e17-8bd1-c5bdff5c1e85,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-aafc2879-241f-47e7-991e-65bce36636fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-e761664d-589c-44c2-a25f-7de4173af0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-61a3f55a-b834-4cb3-86a6-289c89ffd0c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 1
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337199710-172.17.0.10-1595853789546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42730,DS-a2c0855b-43f3-44ee-bc58-c091dc0ab43a,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-812658bb-d7f7-4289-a72f-551191275102,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-f030e3b1-b0f1-48d5-a769-2c0ae76dab49,DISK], DatanodeInfoWithStorage[127.0.0.1:34734,DS-f388119c-97f8-4b12-af1a-be7e07dd2a35,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-a0eed192-b2ad-49b9-af78-c2eb54fb158e,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-2d778a42-1426-4a42-8fbd-ee075179cf65,DISK], DatanodeInfoWithStorage[127.0.0.1:39888,DS-994646e5-5550-4cf0-b454-55893723b683,DISK], DatanodeInfoWithStorage[127.0.0.1:43538,DS-1a0fe762-f713-43cf-9063-856188da6b70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337199710-172.17.0.10-1595853789546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42730,DS-a2c0855b-43f3-44ee-bc58-c091dc0ab43a,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-812658bb-d7f7-4289-a72f-551191275102,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-f030e3b1-b0f1-48d5-a769-2c0ae76dab49,DISK], DatanodeInfoWithStorage[127.0.0.1:34734,DS-f388119c-97f8-4b12-af1a-be7e07dd2a35,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-a0eed192-b2ad-49b9-af78-c2eb54fb158e,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-2d778a42-1426-4a42-8fbd-ee075179cf65,DISK], DatanodeInfoWithStorage[127.0.0.1:39888,DS-994646e5-5550-4cf0-b454-55893723b683,DISK], DatanodeInfoWithStorage[127.0.0.1:43538,DS-1a0fe762-f713-43cf-9063-856188da6b70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 1
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-230311316-172.17.0.10-1595854122979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35281,DS-ad2641c6-77c4-498e-8e69-a70d6c0e685d,DISK], DatanodeInfoWithStorage[127.0.0.1:34925,DS-e5e2e4b6-2098-4328-865a-8d9a94f7bb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-4f26f6b6-a33d-432c-9b3b-7c165244fe44,DISK], DatanodeInfoWithStorage[127.0.0.1:39166,DS-b8ad54ad-ba45-492f-9caa-e7e83f67d973,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-3e3ee7ec-2e0b-4fe5-b562-6a074739ca2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-44c75a17-f2b2-44cb-b384-d4d25a3c3f36,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-fe8baec3-6702-4320-937b-712e7d89fa31,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-e5c42ea4-c30a-4c52-b95c-2c98869a4850,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-230311316-172.17.0.10-1595854122979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35281,DS-ad2641c6-77c4-498e-8e69-a70d6c0e685d,DISK], DatanodeInfoWithStorage[127.0.0.1:34925,DS-e5e2e4b6-2098-4328-865a-8d9a94f7bb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-4f26f6b6-a33d-432c-9b3b-7c165244fe44,DISK], DatanodeInfoWithStorage[127.0.0.1:39166,DS-b8ad54ad-ba45-492f-9caa-e7e83f67d973,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-3e3ee7ec-2e0b-4fe5-b562-6a074739ca2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-44c75a17-f2b2-44cb-b384-d4d25a3c3f36,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-fe8baec3-6702-4320-937b-712e7d89fa31,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-e5c42ea4-c30a-4c52-b95c-2c98869a4850,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 1
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2053233867-172.17.0.10-1595854861929:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37528,DS-918b905d-936f-46f5-8568-95a48c2117d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-aa119605-a18f-43d0-bc85-45c2a2c7794f,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-62900b98-6a50-46a4-9ac8-6b877ea9e41b,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-c78bca80-a38c-4302-b824-afe36a3e2620,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-ec726a50-cc81-4bc2-b1e3-24742991478c,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-d8d0201f-056a-416c-a150-ae717ed84707,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-7a3fa8dd-9060-439c-9fc4-5c79e6b5055d,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-56f5672c-a8b9-44dd-9b7d-211c27c8b825,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2053233867-172.17.0.10-1595854861929:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37528,DS-918b905d-936f-46f5-8568-95a48c2117d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-aa119605-a18f-43d0-bc85-45c2a2c7794f,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-62900b98-6a50-46a4-9ac8-6b877ea9e41b,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-c78bca80-a38c-4302-b824-afe36a3e2620,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-ec726a50-cc81-4bc2-b1e3-24742991478c,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-d8d0201f-056a-416c-a150-ae717ed84707,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-7a3fa8dd-9060-439c-9fc4-5c79e6b5055d,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-56f5672c-a8b9-44dd-9b7d-211c27c8b825,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 1
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1958847982-172.17.0.10-1595855108763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38998,DS-0e130ed6-ff08-4a96-8e32-84be8f479576,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-90851039-da7c-4279-b5f9-de3b01f652b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-cd77668d-e514-4419-87ef-09b53440d844,DISK], DatanodeInfoWithStorage[127.0.0.1:44444,DS-a77cf46b-e9ce-4304-bd95-8956956473a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-a739116b-eeb6-484c-a208-e76528df08bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-422841c3-d7d3-484e-ad4f-4fbdad5f0851,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-c9c931fa-9110-4b98-9479-5c944a363559,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-ab4033ea-bdf0-43f2-bebb-96b336dd54ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1958847982-172.17.0.10-1595855108763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38998,DS-0e130ed6-ff08-4a96-8e32-84be8f479576,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-90851039-da7c-4279-b5f9-de3b01f652b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-cd77668d-e514-4419-87ef-09b53440d844,DISK], DatanodeInfoWithStorage[127.0.0.1:44444,DS-a77cf46b-e9ce-4304-bd95-8956956473a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-a739116b-eeb6-484c-a208-e76528df08bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-422841c3-d7d3-484e-ad4f-4fbdad5f0851,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-c9c931fa-9110-4b98-9479-5c944a363559,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-ab4033ea-bdf0-43f2-bebb-96b336dd54ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 1
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1875237846-172.17.0.10-1595855493608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33467,DS-eb1657e5-1911-48d2-813f-9728ac272e44,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-e2da8b76-a57e-4ee7-9d3e-feaf02267160,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-bf842456-70df-4e4b-8983-2f0cdac795be,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-111a90be-07a9-4c58-8114-4463d5740a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-268cb918-2d7f-4dbd-a096-5177765761ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-50c033b8-99e8-4b3f-845f-ba27a98fb00e,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-43c9c471-3a69-4075-a208-d66855df1b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-e1e06bd8-572a-454a-a6c0-227eba4900b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1875237846-172.17.0.10-1595855493608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33467,DS-eb1657e5-1911-48d2-813f-9728ac272e44,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-e2da8b76-a57e-4ee7-9d3e-feaf02267160,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-bf842456-70df-4e4b-8983-2f0cdac795be,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-111a90be-07a9-4c58-8114-4463d5740a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-268cb918-2d7f-4dbd-a096-5177765761ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-50c033b8-99e8-4b3f-845f-ba27a98fb00e,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-43c9c471-3a69-4075-a208-d66855df1b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-e1e06bd8-572a-454a-a6c0-227eba4900b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 1
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1864673598-172.17.0.10-1595855712191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45390,DS-8110b3df-028e-4035-b3d6-d34e81ebe05e,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-42cf717d-d4e7-4566-a879-478c412bd6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-dca4da5c-0306-4aa0-b55a-756461e419f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-8c6aeae8-998e-4ff3-9931-32945173cd5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43173,DS-42ae6272-a404-4080-9664-3c984f0c40d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-54baf504-1dae-4af9-bf0e-71ea73001419,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-c685162f-f082-44ee-8102-145d8c447698,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-fb80ca5f-7912-40a2-9c59-a3e0d6d6b952,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1864673598-172.17.0.10-1595855712191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45390,DS-8110b3df-028e-4035-b3d6-d34e81ebe05e,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-42cf717d-d4e7-4566-a879-478c412bd6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-dca4da5c-0306-4aa0-b55a-756461e419f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-8c6aeae8-998e-4ff3-9931-32945173cd5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43173,DS-42ae6272-a404-4080-9664-3c984f0c40d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-54baf504-1dae-4af9-bf0e-71ea73001419,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-c685162f-f082-44ee-8102-145d8c447698,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-fb80ca5f-7912-40a2-9c59-a3e0d6d6b952,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 1
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1140549593-172.17.0.10-1595856518600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40515,DS-4bf9de1c-86cf-4ae8-85a8-206f2cc0cc11,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-2858a6c9-d15b-44f1-aaef-19d4ad5d3328,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-873df9e5-9adf-4d79-8c58-245437d9ca6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42505,DS-236a6516-4a6f-43db-a6e6-711e00502352,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-edddf8cc-3289-4518-a3e1-415704a3dc66,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-f81c0daf-d0a2-45ed-957d-9a4efd4baf0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-9b5a6b10-40b5-4a52-b8a5-50e8152a7c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-1d58f24d-dda5-4dc1-900b-8352be1b5deb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1140549593-172.17.0.10-1595856518600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40515,DS-4bf9de1c-86cf-4ae8-85a8-206f2cc0cc11,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-2858a6c9-d15b-44f1-aaef-19d4ad5d3328,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-873df9e5-9adf-4d79-8c58-245437d9ca6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42505,DS-236a6516-4a6f-43db-a6e6-711e00502352,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-edddf8cc-3289-4518-a3e1-415704a3dc66,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-f81c0daf-d0a2-45ed-957d-9a4efd4baf0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-9b5a6b10-40b5-4a52-b8a5-50e8152a7c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-1d58f24d-dda5-4dc1-900b-8352be1b5deb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 1
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056490192-172.17.0.10-1595856608985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39649,DS-7e50a1d4-4dbe-4d28-8e42-2fec8b4fa84d,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-9975107a-7c98-4074-bc1a-deda76f3ef17,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-2e1a65e4-c785-4f57-b43f-9b503fecd6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-50ccb934-0d54-42f1-8395-717cfe5fcd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-389633d0-d780-4581-a1c5-928a3efd8943,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-d6c741f9-2953-4abb-89c2-2df447f5c50e,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-4f2be404-e1a6-47f5-9f3d-bbb10202ccb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34788,DS-7283f3cc-3b9d-428f-8418-202e486409af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056490192-172.17.0.10-1595856608985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39649,DS-7e50a1d4-4dbe-4d28-8e42-2fec8b4fa84d,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-9975107a-7c98-4074-bc1a-deda76f3ef17,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-2e1a65e4-c785-4f57-b43f-9b503fecd6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-50ccb934-0d54-42f1-8395-717cfe5fcd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-389633d0-d780-4581-a1c5-928a3efd8943,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-d6c741f9-2953-4abb-89c2-2df447f5c50e,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-4f2be404-e1a6-47f5-9f3d-bbb10202ccb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34788,DS-7283f3cc-3b9d-428f-8418-202e486409af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 1
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-886474820-172.17.0.10-1595856736042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44466,DS-019e2b46-eac7-40df-b2be-fd5df6bdfabc,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-a6b44706-2c92-4732-a8ce-06cc331fa424,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-443f1b0c-438f-4079-a3cd-916819e32642,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-f7107351-f86a-43d9-9512-948263de65c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-792815e5-9097-466a-ace9-2292ca9008b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-7ffd616d-f2e7-4e0d-8cc1-957e923c572c,DISK], DatanodeInfoWithStorage[127.0.0.1:46681,DS-2649a525-e111-4e6b-af06-c68afaf2f552,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-8752b558-9fbf-4773-af1a-d33af6569b62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-886474820-172.17.0.10-1595856736042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44466,DS-019e2b46-eac7-40df-b2be-fd5df6bdfabc,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-a6b44706-2c92-4732-a8ce-06cc331fa424,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-443f1b0c-438f-4079-a3cd-916819e32642,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-f7107351-f86a-43d9-9512-948263de65c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-792815e5-9097-466a-ace9-2292ca9008b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-7ffd616d-f2e7-4e0d-8cc1-957e923c572c,DISK], DatanodeInfoWithStorage[127.0.0.1:46681,DS-2649a525-e111-4e6b-af06-c68afaf2f552,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-8752b558-9fbf-4773-af1a-d33af6569b62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 1
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1812672882-172.17.0.10-1595857260043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37089,DS-c575be15-1c13-442a-96c6-9fb06a2bf486,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-7799112a-78e8-4a85-a759-b2507a7bcf01,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-a5f453a1-6df6-4534-bba6-446731c45b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-131bd662-c71d-4041-81c0-b1f467785bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38732,DS-fd89e514-252a-4951-a977-3bc9de845664,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-b20c23e5-e19a-4bc2-8512-d21b75d0c841,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-9e9c5880-059e-44ab-a241-31fc6c490784,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-e85769bb-a82d-4762-9107-0b7f359989e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1812672882-172.17.0.10-1595857260043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37089,DS-c575be15-1c13-442a-96c6-9fb06a2bf486,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-7799112a-78e8-4a85-a759-b2507a7bcf01,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-a5f453a1-6df6-4534-bba6-446731c45b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-131bd662-c71d-4041-81c0-b1f467785bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38732,DS-fd89e514-252a-4951-a977-3bc9de845664,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-b20c23e5-e19a-4bc2-8512-d21b75d0c841,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-9e9c5880-059e-44ab-a241-31fc6c490784,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-e85769bb-a82d-4762-9107-0b7f359989e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 1
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-138586320-172.17.0.10-1595857484270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42126,DS-24adff5a-d2e4-422d-8073-b3fc38b123ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-f0b45d83-3e76-4a07-99b4-d4eb1660a99d,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-b5482a9c-3ee7-4148-a895-d6b13d049297,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-c356d26d-229c-41b2-9c3d-ea07802bcde6,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-29080e98-2791-4b35-8d36-0c9a9b0182b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-e36e3c1f-751e-44c5-a845-15fd832c918d,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-cca2ba6a-802b-40b3-8760-a73f975444be,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-94ac1bd0-3763-4e97-93be-617809423a1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-138586320-172.17.0.10-1595857484270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42126,DS-24adff5a-d2e4-422d-8073-b3fc38b123ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-f0b45d83-3e76-4a07-99b4-d4eb1660a99d,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-b5482a9c-3ee7-4148-a895-d6b13d049297,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-c356d26d-229c-41b2-9c3d-ea07802bcde6,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-29080e98-2791-4b35-8d36-0c9a9b0182b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-e36e3c1f-751e-44c5-a845-15fd832c918d,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-cca2ba6a-802b-40b3-8760-a73f975444be,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-94ac1bd0-3763-4e97-93be-617809423a1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6932
