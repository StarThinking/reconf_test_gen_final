reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-744040956-172.17.0.10-1595514573914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35985,DS-8a55c40e-4648-4f2e-a86f-1d1b2f0dd665,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-1d3d72b9-06e9-4c29-a0c0-3d8120942d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-7292205c-87da-467e-bb61-78dcea61b671,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-c418e4cf-b2d5-4085-82e4-0decb30f5897,DISK], DatanodeInfoWithStorage[127.0.0.1:45624,DS-51e01c1a-c256-4917-b463-8259b85e194f,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-0aaede02-9e97-4de4-98f7-5697c5673d16,DISK], DatanodeInfoWithStorage[127.0.0.1:44669,DS-813289c2-d83e-4b84-ba24-695226b4ac68,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-204037ed-3719-477f-b745-cd8fcd5f1678,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-744040956-172.17.0.10-1595514573914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35985,DS-8a55c40e-4648-4f2e-a86f-1d1b2f0dd665,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-1d3d72b9-06e9-4c29-a0c0-3d8120942d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-7292205c-87da-467e-bb61-78dcea61b671,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-c418e4cf-b2d5-4085-82e4-0decb30f5897,DISK], DatanodeInfoWithStorage[127.0.0.1:45624,DS-51e01c1a-c256-4917-b463-8259b85e194f,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-0aaede02-9e97-4de4-98f7-5697c5673d16,DISK], DatanodeInfoWithStorage[127.0.0.1:44669,DS-813289c2-d83e-4b84-ba24-695226b4ac68,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-204037ed-3719-477f-b745-cd8fcd5f1678,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-625369978-172.17.0.10-1595515190698:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40509,DS-7dd9fb4d-79c6-4987-a9d4-55f874d48e21,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-930d85af-138d-4bc7-8fdf-4411145e1ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-e7260f31-89f4-4a34-b37f-c0f822ecf367,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-0df609e0-2227-4c94-a4bd-61d72094093b,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-f457240e-3796-4d5a-bbd0-bbc527958123,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-0945fcad-b0c6-4cc0-bff1-6e8d2c1dfec3,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-05803e21-5da2-48e4-bcfd-3e095113f533,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-32d1a92e-a6d8-488e-bcb6-446826f5443d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-625369978-172.17.0.10-1595515190698:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40509,DS-7dd9fb4d-79c6-4987-a9d4-55f874d48e21,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-930d85af-138d-4bc7-8fdf-4411145e1ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-e7260f31-89f4-4a34-b37f-c0f822ecf367,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-0df609e0-2227-4c94-a4bd-61d72094093b,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-f457240e-3796-4d5a-bbd0-bbc527958123,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-0945fcad-b0c6-4cc0-bff1-6e8d2c1dfec3,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-05803e21-5da2-48e4-bcfd-3e095113f533,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-32d1a92e-a6d8-488e-bcb6-446826f5443d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1383966427-172.17.0.10-1595515265724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40433,DS-c30a2849-e591-48e0-8b56-1094907591c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-e19d3e84-6c95-4cbf-8f73-104ea18a0c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34561,DS-033f302a-6884-4e6c-abde-d50558b48bba,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-b14733bb-9716-41be-aaab-39c6909a3f49,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-21bce3fb-9e46-4ec0-a869-63a6c7095c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-b450b88f-550e-49e1-a84c-530bee43e6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-06c8019c-d3e0-481b-8490-d368ea64715e,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-00ad2aa4-13f7-4e29-a737-d5c163b499f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1383966427-172.17.0.10-1595515265724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40433,DS-c30a2849-e591-48e0-8b56-1094907591c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-e19d3e84-6c95-4cbf-8f73-104ea18a0c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34561,DS-033f302a-6884-4e6c-abde-d50558b48bba,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-b14733bb-9716-41be-aaab-39c6909a3f49,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-21bce3fb-9e46-4ec0-a869-63a6c7095c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-b450b88f-550e-49e1-a84c-530bee43e6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-06c8019c-d3e0-481b-8490-d368ea64715e,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-00ad2aa4-13f7-4e29-a737-d5c163b499f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1173587483-172.17.0.10-1595515481877:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43595,DS-19e700c8-79d5-43c2-a5a7-d5aa5c3b580f,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-39cf8b0c-76b0-4c13-854f-13550367a696,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-986c6a6f-7801-469f-b946-8dd07c886ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-57f2cdf8-ceaa-43cc-81d4-df8b9d3444e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-7d3bb028-b81b-4d27-bf7c-ff0579642e83,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-1bcf10fe-ea31-4203-b006-9cf76bb0b13e,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-b3d65c9a-13ce-4f7f-8a47-a59513fe609e,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-c9c62a33-a3ec-4b59-b5a0-0870c6aedd62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1173587483-172.17.0.10-1595515481877:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43595,DS-19e700c8-79d5-43c2-a5a7-d5aa5c3b580f,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-39cf8b0c-76b0-4c13-854f-13550367a696,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-986c6a6f-7801-469f-b946-8dd07c886ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-57f2cdf8-ceaa-43cc-81d4-df8b9d3444e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-7d3bb028-b81b-4d27-bf7c-ff0579642e83,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-1bcf10fe-ea31-4203-b006-9cf76bb0b13e,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-b3d65c9a-13ce-4f7f-8a47-a59513fe609e,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-c9c62a33-a3ec-4b59-b5a0-0870c6aedd62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-293422664-172.17.0.10-1595515848666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38024,DS-bf910a60-8029-4116-aaf6-6ce19b2d9691,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-4b320891-30bd-4bf3-9b0c-fc0844edf120,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-fd9d528c-54a1-4b2c-91c4-ca2497793442,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-3d915b92-9ff1-4a95-90c5-7d35f84931f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-ed4a5c4d-39d8-44d0-9aca-f53660d688c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36262,DS-e0b91b3f-2089-4c56-8493-b45594d17ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-cdb47c24-b62f-44ca-837a-c86cfc7c5e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-08aa983f-ed42-452a-9ce9-16e9402356b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-293422664-172.17.0.10-1595515848666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38024,DS-bf910a60-8029-4116-aaf6-6ce19b2d9691,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-4b320891-30bd-4bf3-9b0c-fc0844edf120,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-fd9d528c-54a1-4b2c-91c4-ca2497793442,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-3d915b92-9ff1-4a95-90c5-7d35f84931f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-ed4a5c4d-39d8-44d0-9aca-f53660d688c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36262,DS-e0b91b3f-2089-4c56-8493-b45594d17ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-cdb47c24-b62f-44ca-837a-c86cfc7c5e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-08aa983f-ed42-452a-9ce9-16e9402356b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1617170689-172.17.0.10-1595516117732:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41038,DS-7308e322-ae34-4fb0-8817-c05cea322e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-f7167bb1-efc7-4085-960b-3149e46640e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45012,DS-058543d7-f679-445b-b7aa-3ae1c9375baa,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-443a5f75-b185-46cc-b7be-d1a2ca9b982f,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-316f2f2b-11dd-4142-814b-be1bc538e2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-e09f5d01-b81d-4f89-86f4-dc253faa471a,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-a8ce8cae-d614-44ff-80c5-9318282e7a83,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-47731532-abd1-40eb-a97b-8437e3e15a08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1617170689-172.17.0.10-1595516117732:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41038,DS-7308e322-ae34-4fb0-8817-c05cea322e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-f7167bb1-efc7-4085-960b-3149e46640e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45012,DS-058543d7-f679-445b-b7aa-3ae1c9375baa,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-443a5f75-b185-46cc-b7be-d1a2ca9b982f,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-316f2f2b-11dd-4142-814b-be1bc538e2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-e09f5d01-b81d-4f89-86f4-dc253faa471a,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-a8ce8cae-d614-44ff-80c5-9318282e7a83,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-47731532-abd1-40eb-a97b-8437e3e15a08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1685492411-172.17.0.10-1595517413102:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45060,DS-83977feb-20bf-48c4-9370-c412780e7a19,DISK], DatanodeInfoWithStorage[127.0.0.1:43639,DS-771e0bec-698b-4c7b-96f8-0186619e8c45,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-6b43d70d-87e6-4362-8dd9-0451f7108c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-82cfc613-2578-4b92-9a41-a21735bb617e,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-1f4a00a6-0682-417d-bbf2-3bf745baa7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-c5d3f706-f4d1-45c0-b0d2-fdb9be1aa300,DISK], DatanodeInfoWithStorage[127.0.0.1:42113,DS-6df80b6f-b851-45b8-b994-e3820ce59a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-1e1f8387-2ee1-42ee-95eb-5be8ee53ef43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1685492411-172.17.0.10-1595517413102:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45060,DS-83977feb-20bf-48c4-9370-c412780e7a19,DISK], DatanodeInfoWithStorage[127.0.0.1:43639,DS-771e0bec-698b-4c7b-96f8-0186619e8c45,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-6b43d70d-87e6-4362-8dd9-0451f7108c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-82cfc613-2578-4b92-9a41-a21735bb617e,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-1f4a00a6-0682-417d-bbf2-3bf745baa7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-c5d3f706-f4d1-45c0-b0d2-fdb9be1aa300,DISK], DatanodeInfoWithStorage[127.0.0.1:42113,DS-6df80b6f-b851-45b8-b994-e3820ce59a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-1e1f8387-2ee1-42ee-95eb-5be8ee53ef43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-45368710-172.17.0.10-1595518131193:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40423,DS-3bfa927b-0b82-4439-886e-51aacd1fcd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-9b60f01e-4b16-404f-b526-3551c3110bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-f7e25adb-c45a-4374-9cbb-d351db617505,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-1f2f106e-38c6-4319-a9f9-2c4ccbecf334,DISK], DatanodeInfoWithStorage[127.0.0.1:37536,DS-b20b8086-3a2a-4d95-b741-133af250e052,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-d5035497-b8cc-4001-80aa-0d79021aadc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-7faf80aa-b88b-4b94-829f-ae3accd0bdca,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-fdb13cb2-91a1-497b-bdc9-cd5af4920fb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-45368710-172.17.0.10-1595518131193:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40423,DS-3bfa927b-0b82-4439-886e-51aacd1fcd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-9b60f01e-4b16-404f-b526-3551c3110bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-f7e25adb-c45a-4374-9cbb-d351db617505,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-1f2f106e-38c6-4319-a9f9-2c4ccbecf334,DISK], DatanodeInfoWithStorage[127.0.0.1:37536,DS-b20b8086-3a2a-4d95-b741-133af250e052,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-d5035497-b8cc-4001-80aa-0d79021aadc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-7faf80aa-b88b-4b94-829f-ae3accd0bdca,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-fdb13cb2-91a1-497b-bdc9-cd5af4920fb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-949165162-172.17.0.10-1595518421531:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44962,DS-06f5076f-22e2-4bf3-bd93-c34a9719b216,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-731efacb-149d-4a5a-ac4b-ee77c60cf408,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-3d4fc7d9-e83b-49d8-84fc-a49a81d2bb60,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-6580e2c7-e97f-462f-923d-b6ae3964728f,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-26a9eff2-6ef8-45df-98eb-721837828e54,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-ed8da8cc-4ffd-44fc-a913-621577b8b87f,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-2450fcb0-3343-4f74-9003-a0f569cff5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39727,DS-99bf799c-c97c-49fa-abd9-5486aa66230c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-949165162-172.17.0.10-1595518421531:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44962,DS-06f5076f-22e2-4bf3-bd93-c34a9719b216,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-731efacb-149d-4a5a-ac4b-ee77c60cf408,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-3d4fc7d9-e83b-49d8-84fc-a49a81d2bb60,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-6580e2c7-e97f-462f-923d-b6ae3964728f,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-26a9eff2-6ef8-45df-98eb-721837828e54,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-ed8da8cc-4ffd-44fc-a913-621577b8b87f,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-2450fcb0-3343-4f74-9003-a0f569cff5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39727,DS-99bf799c-c97c-49fa-abd9-5486aa66230c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-872751522-172.17.0.10-1595518460600:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35240,DS-297a2321-a64c-49f6-8e40-7add66d79ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-742ec1d0-8ae4-4d45-b50e-81d173b7ed3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-1beea804-33dc-4a0a-814e-7a4881e985af,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-ed60fe38-39e4-438b-becd-edb8c0df31de,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-8222499d-b380-45fc-9a42-698c96a1952c,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-5def7107-1bc5-4fcf-a43e-0a7b624a0764,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-dc11246d-65a4-4cd7-b00f-c2d5aa0377ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-083a3d12-6095-4ee9-8e0a-56137462fa2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-872751522-172.17.0.10-1595518460600:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35240,DS-297a2321-a64c-49f6-8e40-7add66d79ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-742ec1d0-8ae4-4d45-b50e-81d173b7ed3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-1beea804-33dc-4a0a-814e-7a4881e985af,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-ed60fe38-39e4-438b-becd-edb8c0df31de,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-8222499d-b380-45fc-9a42-698c96a1952c,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-5def7107-1bc5-4fcf-a43e-0a7b624a0764,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-dc11246d-65a4-4cd7-b00f-c2d5aa0377ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-083a3d12-6095-4ee9-8e0a-56137462fa2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1507793770-172.17.0.10-1595518865785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45554,DS-c2f101ff-3f7e-40e0-afa9-5611be240e27,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-60b7830f-88c2-4bd4-8515-383cd28655b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-7dcec2a6-f92f-48e9-bcf5-e7c387c9d576,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-9a4a6a43-074a-40d5-9f67-52b314c9691c,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-935c7c7c-61ce-4901-b6d7-6e57b839d2d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-d4dfae19-8533-4881-bb21-e18b3b6aad4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-8e52b95d-5f77-4fd8-8b94-5e2e8cba8987,DISK], DatanodeInfoWithStorage[127.0.0.1:40862,DS-fd67c708-76ec-4d01-a7d8-8141013529c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1507793770-172.17.0.10-1595518865785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45554,DS-c2f101ff-3f7e-40e0-afa9-5611be240e27,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-60b7830f-88c2-4bd4-8515-383cd28655b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-7dcec2a6-f92f-48e9-bcf5-e7c387c9d576,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-9a4a6a43-074a-40d5-9f67-52b314c9691c,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-935c7c7c-61ce-4901-b6d7-6e57b839d2d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-d4dfae19-8533-4881-bb21-e18b3b6aad4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-8e52b95d-5f77-4fd8-8b94-5e2e8cba8987,DISK], DatanodeInfoWithStorage[127.0.0.1:40862,DS-fd67c708-76ec-4d01-a7d8-8141013529c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1909239647-172.17.0.10-1595519448658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35694,DS-3d31a59e-d1c7-4a37-af7a-466cd2293a40,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-7ebf4a9c-1f8d-41f1-a17d-3f4f86eac251,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-0ef04564-31cf-4131-9bcb-1fdceb970729,DISK], DatanodeInfoWithStorage[127.0.0.1:39463,DS-af53965a-efc5-4b3a-8802-a8b746da7381,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-fc260a61-929f-4f82-aa8f-d99f572dce99,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-27d5bc50-33db-4224-ba11-7647d8c91b32,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-9f244ec3-a9dc-47d9-a02c-4b5a49331579,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-7193e43a-7454-4da5-937f-71d1270430e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1909239647-172.17.0.10-1595519448658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35694,DS-3d31a59e-d1c7-4a37-af7a-466cd2293a40,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-7ebf4a9c-1f8d-41f1-a17d-3f4f86eac251,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-0ef04564-31cf-4131-9bcb-1fdceb970729,DISK], DatanodeInfoWithStorage[127.0.0.1:39463,DS-af53965a-efc5-4b3a-8802-a8b746da7381,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-fc260a61-929f-4f82-aa8f-d99f572dce99,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-27d5bc50-33db-4224-ba11-7647d8c91b32,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-9f244ec3-a9dc-47d9-a02c-4b5a49331579,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-7193e43a-7454-4da5-937f-71d1270430e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-859963514-172.17.0.10-1595519579531:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33209,DS-605c9a52-b374-4da3-8d3a-e732797efade,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-081fb041-3794-4b62-b369-6572eebfdfbb,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-ed6bd13f-ad08-43cf-a0a8-75829fed1fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-797c74e9-1b32-497d-b4f8-de71fa09e3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-c4efefc9-313b-4fb3-8ab0-7bd3025b3bff,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-dfefbc3d-eaa4-427b-942b-769b279fa1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-852306df-0e11-406f-9b7e-a9edac3e42fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-3de7c8bf-cced-423f-a1fd-de19fad3d42b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-859963514-172.17.0.10-1595519579531:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33209,DS-605c9a52-b374-4da3-8d3a-e732797efade,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-081fb041-3794-4b62-b369-6572eebfdfbb,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-ed6bd13f-ad08-43cf-a0a8-75829fed1fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-797c74e9-1b32-497d-b4f8-de71fa09e3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-c4efefc9-313b-4fb3-8ab0-7bd3025b3bff,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-dfefbc3d-eaa4-427b-942b-769b279fa1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-852306df-0e11-406f-9b7e-a9edac3e42fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-3de7c8bf-cced-423f-a1fd-de19fad3d42b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-518568805-172.17.0.10-1595519644260:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41562,DS-d07d53f3-4fed-4af9-97e3-526371f2e052,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-19d31359-f88a-45b7-ac08-86285701ab46,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-52861650-9200-4b26-a95d-e14d1e854875,DISK], DatanodeInfoWithStorage[127.0.0.1:40892,DS-4b621506-40c1-432a-a38b-e7724803cc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-071be84e-27bc-4664-9560-248bbdf21869,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-a96f69e1-a262-42e6-9b79-11b45c8446b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46070,DS-5d2cd4fe-568a-4c6a-9af1-33ec29a7fc36,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-38ea911c-f256-442d-b011-cf7371b42bda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-518568805-172.17.0.10-1595519644260:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41562,DS-d07d53f3-4fed-4af9-97e3-526371f2e052,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-19d31359-f88a-45b7-ac08-86285701ab46,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-52861650-9200-4b26-a95d-e14d1e854875,DISK], DatanodeInfoWithStorage[127.0.0.1:40892,DS-4b621506-40c1-432a-a38b-e7724803cc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-071be84e-27bc-4664-9560-248bbdf21869,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-a96f69e1-a262-42e6-9b79-11b45c8446b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46070,DS-5d2cd4fe-568a-4c6a-9af1-33ec29a7fc36,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-38ea911c-f256-442d-b011-cf7371b42bda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1551297411-172.17.0.10-1595519758915:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46214,DS-da638617-55d0-4672-bcb0-a97207c197bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-8c6afe46-ef83-4fd8-80f0-35f2e4872c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-ee0a1cea-c165-4c0e-a8c9-0209af3edf02,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-ea7b7b9c-04ac-4fbc-85f9-4ba07201d396,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-af969e5d-b43c-46d5-b9fe-bf56b019e442,DISK], DatanodeInfoWithStorage[127.0.0.1:37285,DS-4cecd959-cd62-4837-9d74-0c1b03e0c8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-70f8627b-9c9c-4b61-919c-157406c87dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-f6b87987-0274-4feb-a49c-6f03e7fc8fb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1551297411-172.17.0.10-1595519758915:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46214,DS-da638617-55d0-4672-bcb0-a97207c197bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-8c6afe46-ef83-4fd8-80f0-35f2e4872c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-ee0a1cea-c165-4c0e-a8c9-0209af3edf02,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-ea7b7b9c-04ac-4fbc-85f9-4ba07201d396,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-af969e5d-b43c-46d5-b9fe-bf56b019e442,DISK], DatanodeInfoWithStorage[127.0.0.1:37285,DS-4cecd959-cd62-4837-9d74-0c1b03e0c8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-70f8627b-9c9c-4b61-919c-157406c87dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-f6b87987-0274-4feb-a49c-6f03e7fc8fb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5291
