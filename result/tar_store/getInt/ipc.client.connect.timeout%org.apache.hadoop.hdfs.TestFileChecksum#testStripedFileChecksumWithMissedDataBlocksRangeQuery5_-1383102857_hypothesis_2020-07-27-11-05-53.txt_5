reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 30000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 30000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-111680998-172.17.0.18-1595848206440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45319,DS-ed88f1ed-8dae-421b-9bf1-00fcad189b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40229,DS-b873e251-18ff-43bd-8acb-d9f0c99fa166,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-a7d3b22c-abcf-494e-8b7a-877abbebf90b,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-7cbe15cc-b331-40d0-9ab1-c05b63dbcd09,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-8117e298-38d9-4687-a661-59c2d622f14e,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-8fa5f39e-a6b8-4a7f-8d24-e653f17d8d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-a7eeb150-b62d-4079-bdd0-a56142a1069a,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-87637523-2c0b-44cf-8b5d-4cf5f0acd74e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-111680998-172.17.0.18-1595848206440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45319,DS-ed88f1ed-8dae-421b-9bf1-00fcad189b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40229,DS-b873e251-18ff-43bd-8acb-d9f0c99fa166,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-a7d3b22c-abcf-494e-8b7a-877abbebf90b,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-7cbe15cc-b331-40d0-9ab1-c05b63dbcd09,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-8117e298-38d9-4687-a661-59c2d622f14e,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-8fa5f39e-a6b8-4a7f-8d24-e653f17d8d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-a7eeb150-b62d-4079-bdd0-a56142a1069a,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-87637523-2c0b-44cf-8b5d-4cf5f0acd74e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 30000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1575811196-172.17.0.18-1595848656291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36593,DS-0d9c0206-eaa7-4e14-b033-99af89e8592c,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-8bea5a3d-50ea-4ef1-90c2-dc5ddd338031,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-32ff9b33-5ac3-4ecc-97a7-0e494d94a96d,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-2304f543-99e2-48ca-8937-573f0b29a82f,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-3c609fca-aa66-4fc5-bc5e-9fe27eec7818,DISK], DatanodeInfoWithStorage[127.0.0.1:40648,DS-1e33516c-c99e-4020-b01c-d12286cd1339,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-fcc82431-d88f-47af-aec6-1cb07438edd3,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-63047f7f-e0e0-4285-8bc3-2ac5a0f27b76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1575811196-172.17.0.18-1595848656291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36593,DS-0d9c0206-eaa7-4e14-b033-99af89e8592c,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-8bea5a3d-50ea-4ef1-90c2-dc5ddd338031,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-32ff9b33-5ac3-4ecc-97a7-0e494d94a96d,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-2304f543-99e2-48ca-8937-573f0b29a82f,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-3c609fca-aa66-4fc5-bc5e-9fe27eec7818,DISK], DatanodeInfoWithStorage[127.0.0.1:40648,DS-1e33516c-c99e-4020-b01c-d12286cd1339,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-fcc82431-d88f-47af-aec6-1cb07438edd3,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-63047f7f-e0e0-4285-8bc3-2ac5a0f27b76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 30000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1323091920-172.17.0.18-1595849791410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38103,DS-756d4d70-9990-4d84-9018-1447cd7c34f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-4268d74f-17a2-41ab-bed5-628e1c8f6013,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-825288e8-c60b-4142-8b58-224be75340ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-4c07a803-a959-488e-be8e-837b36ac4cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-a50b30c5-c037-41fe-895b-54d12242d458,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-bd5e8ac2-8201-428a-9d8f-d38f7c97ad45,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-a367ad01-814c-4906-970c-05b879235fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38242,DS-b9e03e90-6d30-4c26-8a21-f6b8f913af15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1323091920-172.17.0.18-1595849791410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38103,DS-756d4d70-9990-4d84-9018-1447cd7c34f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-4268d74f-17a2-41ab-bed5-628e1c8f6013,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-825288e8-c60b-4142-8b58-224be75340ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-4c07a803-a959-488e-be8e-837b36ac4cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-a50b30c5-c037-41fe-895b-54d12242d458,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-bd5e8ac2-8201-428a-9d8f-d38f7c97ad45,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-a367ad01-814c-4906-970c-05b879235fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38242,DS-b9e03e90-6d30-4c26-8a21-f6b8f913af15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 30000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-444992136-172.17.0.18-1595850795439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33557,DS-4f30cad6-429a-47db-947f-aa280f1b22ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-64398108-dfc0-45c6-b02a-071b72670c31,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-567af89a-1b48-4cf7-af34-84ca9cbafde4,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-800dc346-edf0-40b9-a0ce-19e229730d41,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-15e52a76-a270-48ce-ad6b-b210023da115,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-519dfb47-ef03-4c8d-afb7-cc6e923058e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-a032b5a8-f148-4a37-a755-323805a586b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-e36e55e1-4103-4b31-bcbb-cb2adb88cec2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-444992136-172.17.0.18-1595850795439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33557,DS-4f30cad6-429a-47db-947f-aa280f1b22ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-64398108-dfc0-45c6-b02a-071b72670c31,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-567af89a-1b48-4cf7-af34-84ca9cbafde4,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-800dc346-edf0-40b9-a0ce-19e229730d41,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-15e52a76-a270-48ce-ad6b-b210023da115,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-519dfb47-ef03-4c8d-afb7-cc6e923058e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-a032b5a8-f148-4a37-a755-323805a586b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-e36e55e1-4103-4b31-bcbb-cb2adb88cec2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 30000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-564712095-172.17.0.18-1595851136317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44530,DS-8d5f868b-e055-4b48-ab1f-70601440b616,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-27294db7-6798-41bd-8c61-c8436564f8da,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-6be46c4e-25d6-4baf-aef5-afc9fa40413b,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-972ae9c3-b5d6-44af-ad36-093a875d2903,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-1b325e58-ab4a-49f3-9c90-f7329c4c9e97,DISK], DatanodeInfoWithStorage[127.0.0.1:45012,DS-76bf3ec1-5e21-412f-8a2a-33d19afc644c,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-672611cf-5810-4974-8e4b-bec5ac3aae28,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-05054383-a517-4e10-8929-3f59fa6cb508,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-564712095-172.17.0.18-1595851136317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44530,DS-8d5f868b-e055-4b48-ab1f-70601440b616,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-27294db7-6798-41bd-8c61-c8436564f8da,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-6be46c4e-25d6-4baf-aef5-afc9fa40413b,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-972ae9c3-b5d6-44af-ad36-093a875d2903,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-1b325e58-ab4a-49f3-9c90-f7329c4c9e97,DISK], DatanodeInfoWithStorage[127.0.0.1:45012,DS-76bf3ec1-5e21-412f-8a2a-33d19afc644c,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-672611cf-5810-4974-8e4b-bec5ac3aae28,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-05054383-a517-4e10-8929-3f59fa6cb508,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 30000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-898956296-172.17.0.18-1595851362318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41481,DS-d9d1d4e4-6a77-4212-9101-b375288d68d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-f0721dd5-78b0-41b6-b531-79b5b7b0135c,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-c82174fb-0954-41f1-978b-bb87f7ca6163,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-5d801805-8361-4638-aabc-fde8338b6cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-caaf4dc7-369f-4c1d-bace-8f2f38165578,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-b3bc8012-9b0d-4bed-81d4-09be12f0a5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-e9b10825-5ea8-4646-bda8-8f79d93b9c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-79f0a2ce-e7ee-444a-9a07-ec30d6215351,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-898956296-172.17.0.18-1595851362318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41481,DS-d9d1d4e4-6a77-4212-9101-b375288d68d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-f0721dd5-78b0-41b6-b531-79b5b7b0135c,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-c82174fb-0954-41f1-978b-bb87f7ca6163,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-5d801805-8361-4638-aabc-fde8338b6cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-caaf4dc7-369f-4c1d-bace-8f2f38165578,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-b3bc8012-9b0d-4bed-81d4-09be12f0a5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-e9b10825-5ea8-4646-bda8-8f79d93b9c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-79f0a2ce-e7ee-444a-9a07-ec30d6215351,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 30000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1962761839-172.17.0.18-1595851402066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46322,DS-fff3617a-8f71-4fe9-95d8-46d173c44f14,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-041bad28-65b1-4150-a36b-561bfc0d9035,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-f43fef89-378b-4509-9672-e2a2e141590d,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-0ca970a6-bf62-483c-8fbc-5378b54d9ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-d3a5d94f-7b05-4bb0-b828-ab3d950465dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-ad9e87bc-62fe-4078-9f2d-6f7c89103ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-30b973ad-6bb5-4623-aa92-51499fb7ebaa,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-22094a46-82b5-4ab2-9384-491b6df6d27b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1962761839-172.17.0.18-1595851402066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46322,DS-fff3617a-8f71-4fe9-95d8-46d173c44f14,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-041bad28-65b1-4150-a36b-561bfc0d9035,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-f43fef89-378b-4509-9672-e2a2e141590d,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-0ca970a6-bf62-483c-8fbc-5378b54d9ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-d3a5d94f-7b05-4bb0-b828-ab3d950465dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-ad9e87bc-62fe-4078-9f2d-6f7c89103ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-30b973ad-6bb5-4623-aa92-51499fb7ebaa,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-22094a46-82b5-4ab2-9384-491b6df6d27b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 30000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1059339560-172.17.0.18-1595851662986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45422,DS-5b5e425d-ace6-4adf-a91e-d4a3b815d1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-e62e341b-cb87-4a61-8a1a-81707827d300,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-b8804483-ad44-476a-bb73-5e19ebe7407d,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-13aede14-6c1e-40f2-bc94-aca43e59e720,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-83cc03dc-2af0-4ea8-9529-611c53d1c4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-afccbf4a-d5f7-4396-898b-61d9a34e9183,DISK], DatanodeInfoWithStorage[127.0.0.1:44417,DS-bdaac9f7-8127-4677-af12-2df23b0795a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-90f2529c-d3d8-4c05-8979-63eea9f7bf29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1059339560-172.17.0.18-1595851662986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45422,DS-5b5e425d-ace6-4adf-a91e-d4a3b815d1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-e62e341b-cb87-4a61-8a1a-81707827d300,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-b8804483-ad44-476a-bb73-5e19ebe7407d,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-13aede14-6c1e-40f2-bc94-aca43e59e720,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-83cc03dc-2af0-4ea8-9529-611c53d1c4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-afccbf4a-d5f7-4396-898b-61d9a34e9183,DISK], DatanodeInfoWithStorage[127.0.0.1:44417,DS-bdaac9f7-8127-4677-af12-2df23b0795a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-90f2529c-d3d8-4c05-8979-63eea9f7bf29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 30000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2032089110-172.17.0.18-1595851848385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40901,DS-27c03ac9-aaf4-4a1e-9645-02f2c43f966e,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-1a848da8-cd69-456b-9f55-090c280a5e25,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-796ef99b-9248-4233-a4b8-00280d4fe446,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-a2429238-c02c-4d59-af72-ca663e149d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-7294d256-d285-4c62-98f9-5ab59262f8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-45d98f6c-881c-48ff-b001-a79e34dedcbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-a9fbf817-6406-4260-93c8-10e9243771b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-f728ef09-f8da-41fd-b9b5-a5fdf38fa9ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2032089110-172.17.0.18-1595851848385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40901,DS-27c03ac9-aaf4-4a1e-9645-02f2c43f966e,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-1a848da8-cd69-456b-9f55-090c280a5e25,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-796ef99b-9248-4233-a4b8-00280d4fe446,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-a2429238-c02c-4d59-af72-ca663e149d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-7294d256-d285-4c62-98f9-5ab59262f8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-45d98f6c-881c-48ff-b001-a79e34dedcbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-a9fbf817-6406-4260-93c8-10e9243771b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-f728ef09-f8da-41fd-b9b5-a5fdf38fa9ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 30000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1039225799-172.17.0.18-1595852742365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36575,DS-cc1248fa-85df-4c3b-b3c6-c5b34b28dca6,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-789a4523-0dc2-4809-98f6-f6c7f4238f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-f6b82984-05b3-49b5-b27b-82ca6a0ace10,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-7d3bbe83-daf1-45af-b6b0-71e091e6f894,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-33429cee-188b-4fe4-9455-e69b156e0257,DISK], DatanodeInfoWithStorage[127.0.0.1:41344,DS-76f425e4-074e-441e-a74a-a4d4cd4aa5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-40fe421f-f8b3-49f9-8cfb-5b2e67710173,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-860d1e52-5c1a-424d-8e08-12a1fdb103ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1039225799-172.17.0.18-1595852742365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36575,DS-cc1248fa-85df-4c3b-b3c6-c5b34b28dca6,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-789a4523-0dc2-4809-98f6-f6c7f4238f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-f6b82984-05b3-49b5-b27b-82ca6a0ace10,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-7d3bbe83-daf1-45af-b6b0-71e091e6f894,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-33429cee-188b-4fe4-9455-e69b156e0257,DISK], DatanodeInfoWithStorage[127.0.0.1:41344,DS-76f425e4-074e-441e-a74a-a4d4cd4aa5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-40fe421f-f8b3-49f9-8cfb-5b2e67710173,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-860d1e52-5c1a-424d-8e08-12a1fdb103ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 30000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1842449410-172.17.0.18-1595853078337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40119,DS-b4c8b94b-63d6-4163-ba3c-95e0628a944c,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-792b5d22-b8c0-43ae-95df-7df735c0d436,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-ce415c6c-759e-4640-84db-83247e6ed6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-a608b6ac-a956-4ea2-a1fa-36fe2f8924d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46309,DS-be2bf8e7-7cfa-4af1-a981-f0d256a5c5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-87612016-75ed-4cf8-b8eb-97dd419da129,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-b93462e3-2990-4975-b65f-e50d17ed1531,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-92cbb00b-5091-4b30-a8c1-4cfbd011e9f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1842449410-172.17.0.18-1595853078337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40119,DS-b4c8b94b-63d6-4163-ba3c-95e0628a944c,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-792b5d22-b8c0-43ae-95df-7df735c0d436,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-ce415c6c-759e-4640-84db-83247e6ed6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-a608b6ac-a956-4ea2-a1fa-36fe2f8924d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46309,DS-be2bf8e7-7cfa-4af1-a981-f0d256a5c5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-87612016-75ed-4cf8-b8eb-97dd419da129,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-b93462e3-2990-4975-b65f-e50d17ed1531,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-92cbb00b-5091-4b30-a8c1-4cfbd011e9f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 30000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1782421903-172.17.0.18-1595853334272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37797,DS-35db86d4-0bb9-4d06-8e49-9707fbacfe43,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-4e9eb241-3e67-4ada-8dcf-010815cca604,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-f411f22a-17df-4be1-b308-8e53ce38877e,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-a18278f4-feb9-4409-97d7-34d90fe00fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-649395be-11be-4008-ba5a-e2fea179c7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-53fd327f-b9fc-46f2-b31d-dcfa3d00c176,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-a749776f-89cb-47ed-91c0-8e2df19955dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45528,DS-28d06143-ec22-451e-a2d8-4720ef648fa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1782421903-172.17.0.18-1595853334272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37797,DS-35db86d4-0bb9-4d06-8e49-9707fbacfe43,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-4e9eb241-3e67-4ada-8dcf-010815cca604,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-f411f22a-17df-4be1-b308-8e53ce38877e,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-a18278f4-feb9-4409-97d7-34d90fe00fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-649395be-11be-4008-ba5a-e2fea179c7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-53fd327f-b9fc-46f2-b31d-dcfa3d00c176,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-a749776f-89cb-47ed-91c0-8e2df19955dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45528,DS-28d06143-ec22-451e-a2d8-4720ef648fa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5475
