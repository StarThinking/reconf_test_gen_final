reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-959076850-172.17.0.2-1595959112620:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46627,DS-71c2e4f7-1686-4055-b0f4-33c50869ec0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-4c070fad-1eb8-47af-8fe2-4eaa0551dad4,DISK], DatanodeInfoWithStorage[127.0.0.1:36419,DS-0c4d9275-3786-4a51-86c1-e8cb47e7325d,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-76cb4f68-6e7a-4575-9d58-1ffd2f0efc50,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-3accbddc-6ff3-4911-a9d3-a966d7a4c846,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-ace54199-9b10-495b-b9f7-32c4ed738117,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-853cd21a-74f5-4b5d-8418-e87853795e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45119,DS-370c00d2-6ea1-47a1-8218-2f0f4182b80f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-959076850-172.17.0.2-1595959112620:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46627,DS-71c2e4f7-1686-4055-b0f4-33c50869ec0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-4c070fad-1eb8-47af-8fe2-4eaa0551dad4,DISK], DatanodeInfoWithStorage[127.0.0.1:36419,DS-0c4d9275-3786-4a51-86c1-e8cb47e7325d,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-76cb4f68-6e7a-4575-9d58-1ffd2f0efc50,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-3accbddc-6ff3-4911-a9d3-a966d7a4c846,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-ace54199-9b10-495b-b9f7-32c4ed738117,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-853cd21a-74f5-4b5d-8418-e87853795e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45119,DS-370c00d2-6ea1-47a1-8218-2f0f4182b80f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1583124687-172.17.0.2-1595959794977:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38899,DS-a11e46c9-f166-4339-9062-db338405a56c,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-ba9434ff-8d6d-4cf8-9775-26f81f9d791c,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-9e4f83c9-9a84-4ed1-bee1-c6649c2ea5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-7428ddce-cb9c-44c2-84b8-d3a4dd1a4750,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-cc4cd947-7de2-4370-8012-11a93fd05c67,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-827d691e-6ca6-42bb-8dd4-7f5410a4648a,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-a31f6f87-bf8c-46f0-8a1a-b55ed4e303f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-38367d8a-ca3c-4f55-a9c9-014139bad996,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1583124687-172.17.0.2-1595959794977:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38899,DS-a11e46c9-f166-4339-9062-db338405a56c,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-ba9434ff-8d6d-4cf8-9775-26f81f9d791c,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-9e4f83c9-9a84-4ed1-bee1-c6649c2ea5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-7428ddce-cb9c-44c2-84b8-d3a4dd1a4750,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-cc4cd947-7de2-4370-8012-11a93fd05c67,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-827d691e-6ca6-42bb-8dd4-7f5410a4648a,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-a31f6f87-bf8c-46f0-8a1a-b55ed4e303f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-38367d8a-ca3c-4f55-a9c9-014139bad996,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-19213014-172.17.0.2-1595960014499:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32927,DS-af866914-e4d4-49e4-b48d-5509460de863,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-ec85703e-0bcf-493f-b7ef-b5467231f359,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-8598837b-9b2c-4a3d-9cd2-753541eb6ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-1225eed3-f810-47be-9ba6-b0a27af50451,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-dee32370-2b46-474d-bbe5-8032afea6146,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-3a67dcf0-5b7f-43d6-8b63-77078a3a13a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-3560f5f6-0906-41b6-ab20-e209a26852d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-94349d74-0bf4-4c8d-adc4-727ae6bbd69d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-19213014-172.17.0.2-1595960014499:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32927,DS-af866914-e4d4-49e4-b48d-5509460de863,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-ec85703e-0bcf-493f-b7ef-b5467231f359,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-8598837b-9b2c-4a3d-9cd2-753541eb6ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-1225eed3-f810-47be-9ba6-b0a27af50451,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-dee32370-2b46-474d-bbe5-8032afea6146,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-3a67dcf0-5b7f-43d6-8b63-77078a3a13a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-3560f5f6-0906-41b6-ab20-e209a26852d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-94349d74-0bf4-4c8d-adc4-727ae6bbd69d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-762356211-172.17.0.2-1595960153771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34871,DS-9b1fe594-4637-4aaa-aa76-317d1d97fa8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39432,DS-23530e70-b731-4d60-9ffb-8f53a187b67b,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-56271f47-389e-4d8e-9fb5-4874d63f9206,DISK], DatanodeInfoWithStorage[127.0.0.1:38155,DS-be8cc6e7-2161-4e31-9dfe-23c5960fc508,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-521bee96-55b9-4bee-a967-febf99a81e88,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-2b9f1840-5f61-4979-a8a4-2a7077d61786,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-e93ae292-b144-47ff-8ea1-f45d8d8b8510,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-0e69d74d-66c4-4ed3-b99a-df55a7ba47df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-762356211-172.17.0.2-1595960153771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34871,DS-9b1fe594-4637-4aaa-aa76-317d1d97fa8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39432,DS-23530e70-b731-4d60-9ffb-8f53a187b67b,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-56271f47-389e-4d8e-9fb5-4874d63f9206,DISK], DatanodeInfoWithStorage[127.0.0.1:38155,DS-be8cc6e7-2161-4e31-9dfe-23c5960fc508,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-521bee96-55b9-4bee-a967-febf99a81e88,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-2b9f1840-5f61-4979-a8a4-2a7077d61786,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-e93ae292-b144-47ff-8ea1-f45d8d8b8510,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-0e69d74d-66c4-4ed3-b99a-df55a7ba47df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-434364905-172.17.0.2-1595960247404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40709,DS-aeba09b8-48e7-4bc7-a669-bcc2386a3683,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-966d79bc-9f39-483f-8352-a4a1cbc6813a,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-ee2eea69-fcb8-40bf-b30a-fd8fe87eca5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-780ae1ec-601b-4008-b34d-9f51146fb81d,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-662242c7-b1b3-46bf-9f85-84a1258463a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-84f3aa31-7cb3-4739-bed8-163a41761095,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-e8d8464a-f366-4efb-a701-fb66dbc5d067,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-31dd996c-b5ad-4272-9f1c-218eb6a7b2e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-434364905-172.17.0.2-1595960247404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40709,DS-aeba09b8-48e7-4bc7-a669-bcc2386a3683,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-966d79bc-9f39-483f-8352-a4a1cbc6813a,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-ee2eea69-fcb8-40bf-b30a-fd8fe87eca5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-780ae1ec-601b-4008-b34d-9f51146fb81d,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-662242c7-b1b3-46bf-9f85-84a1258463a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-84f3aa31-7cb3-4739-bed8-163a41761095,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-e8d8464a-f366-4efb-a701-fb66dbc5d067,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-31dd996c-b5ad-4272-9f1c-218eb6a7b2e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1732964642-172.17.0.2-1595960342907:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44682,DS-b6b4cbbe-37f0-4cb9-a486-102fff7c15de,DISK], DatanodeInfoWithStorage[127.0.0.1:38523,DS-86f9ff7e-ff9f-48e0-ae03-736b053bc3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46590,DS-29b7ea82-8888-4124-baf4-267685299b41,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-b6758705-f1aa-416a-9984-89a9f777a2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-fac7aa19-1890-4ce9-9615-c06109465e82,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-0613ff57-e254-4fe0-a504-eac6f4651ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-9a897b20-0e29-43aa-b03f-531678b70588,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-033a5803-dc2e-44dd-99b7-51243248f0aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1732964642-172.17.0.2-1595960342907:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44682,DS-b6b4cbbe-37f0-4cb9-a486-102fff7c15de,DISK], DatanodeInfoWithStorage[127.0.0.1:38523,DS-86f9ff7e-ff9f-48e0-ae03-736b053bc3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46590,DS-29b7ea82-8888-4124-baf4-267685299b41,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-b6758705-f1aa-416a-9984-89a9f777a2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-fac7aa19-1890-4ce9-9615-c06109465e82,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-0613ff57-e254-4fe0-a504-eac6f4651ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-9a897b20-0e29-43aa-b03f-531678b70588,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-033a5803-dc2e-44dd-99b7-51243248f0aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-121418976-172.17.0.2-1595960445323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43419,DS-8dec71a7-e646-425b-8b8a-843dcb7705e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33603,DS-e633ff25-9b6d-4320-94b6-53773d22f3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-71509880-e067-4099-8bfe-7f4abcd3f68d,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-c7cae383-e9c3-4929-9ea0-2936c35e0d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36926,DS-f36d2178-a5f7-4d8b-813b-59fb7ec3a9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-9668955c-fc6a-421e-a265-a997dbc68f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-ca089c81-8757-42ad-8d52-e4f97ebe1b19,DISK], DatanodeInfoWithStorage[127.0.0.1:42123,DS-d8650119-8198-414d-98af-3ea78a09074e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-121418976-172.17.0.2-1595960445323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43419,DS-8dec71a7-e646-425b-8b8a-843dcb7705e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33603,DS-e633ff25-9b6d-4320-94b6-53773d22f3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-71509880-e067-4099-8bfe-7f4abcd3f68d,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-c7cae383-e9c3-4929-9ea0-2936c35e0d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36926,DS-f36d2178-a5f7-4d8b-813b-59fb7ec3a9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-9668955c-fc6a-421e-a265-a997dbc68f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-ca089c81-8757-42ad-8d52-e4f97ebe1b19,DISK], DatanodeInfoWithStorage[127.0.0.1:42123,DS-d8650119-8198-414d-98af-3ea78a09074e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-719800726-172.17.0.2-1595961148197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38094,DS-2a9a3a61-638d-444a-bb65-364ce5f81f23,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-3bad71fe-c4fc-4ccb-a251-636cab951a29,DISK], DatanodeInfoWithStorage[127.0.0.1:46426,DS-e1aaf592-1b24-41e9-b32d-d695667a7025,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-76bc9fe5-1a94-454a-b199-892978f03c45,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-e6fb4a37-5c16-4ce9-9ac9-e1efb597e78b,DISK], DatanodeInfoWithStorage[127.0.0.1:33959,DS-ecdd0fcf-026a-4e0d-b548-9a2f5d1d53ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-1828e3a9-4604-4e4f-88c0-4d645705c75f,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-6cd7c26c-07e3-47ff-b08e-03f6d3b9555f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-719800726-172.17.0.2-1595961148197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38094,DS-2a9a3a61-638d-444a-bb65-364ce5f81f23,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-3bad71fe-c4fc-4ccb-a251-636cab951a29,DISK], DatanodeInfoWithStorage[127.0.0.1:46426,DS-e1aaf592-1b24-41e9-b32d-d695667a7025,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-76bc9fe5-1a94-454a-b199-892978f03c45,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-e6fb4a37-5c16-4ce9-9ac9-e1efb597e78b,DISK], DatanodeInfoWithStorage[127.0.0.1:33959,DS-ecdd0fcf-026a-4e0d-b548-9a2f5d1d53ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-1828e3a9-4604-4e4f-88c0-4d645705c75f,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-6cd7c26c-07e3-47ff-b08e-03f6d3b9555f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1336505366-172.17.0.2-1595961299580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45816,DS-d5b91e4d-02ee-4c45-a86f-a8400ca3a887,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-4d5aae8b-cb29-4a91-aa8e-2e051defdc79,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-cfb36ba0-7edc-4eba-901c-422467eee63a,DISK], DatanodeInfoWithStorage[127.0.0.1:32793,DS-67858768-50bb-46e9-a374-809b80a44447,DISK], DatanodeInfoWithStorage[127.0.0.1:38589,DS-1e174a02-2ed6-4352-8b5d-6101da70233a,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-584ddef4-240d-464f-88f3-5a622e68aa00,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-98f41830-f86e-4716-b2bb-d1bbcebf83d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-2a957ac1-9551-4852-8c20-700f7d283a60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1336505366-172.17.0.2-1595961299580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45816,DS-d5b91e4d-02ee-4c45-a86f-a8400ca3a887,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-4d5aae8b-cb29-4a91-aa8e-2e051defdc79,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-cfb36ba0-7edc-4eba-901c-422467eee63a,DISK], DatanodeInfoWithStorage[127.0.0.1:32793,DS-67858768-50bb-46e9-a374-809b80a44447,DISK], DatanodeInfoWithStorage[127.0.0.1:38589,DS-1e174a02-2ed6-4352-8b5d-6101da70233a,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-584ddef4-240d-464f-88f3-5a622e68aa00,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-98f41830-f86e-4716-b2bb-d1bbcebf83d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-2a957ac1-9551-4852-8c20-700f7d283a60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-910148242-172.17.0.2-1595961468523:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41426,DS-28c19b63-8b2d-432b-8298-1b65d95e8043,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-eab404a0-89d1-4905-8d1e-61f7e7f4bfca,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-759e8267-c638-44bd-bba4-302766001340,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-0add6dfd-89ac-4511-9888-9eb8375ae286,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-f0c13fc3-a3c6-4a60-bca0-34a1ad24e466,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-7a1f14e4-55cf-4264-ba11-d18947e96875,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-f7a9990b-08f0-4fc3-9b10-38471366b72e,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-57d53544-3cbf-4229-b593-d3a4e54690b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-910148242-172.17.0.2-1595961468523:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41426,DS-28c19b63-8b2d-432b-8298-1b65d95e8043,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-eab404a0-89d1-4905-8d1e-61f7e7f4bfca,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-759e8267-c638-44bd-bba4-302766001340,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-0add6dfd-89ac-4511-9888-9eb8375ae286,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-f0c13fc3-a3c6-4a60-bca0-34a1ad24e466,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-7a1f14e4-55cf-4264-ba11-d18947e96875,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-f7a9990b-08f0-4fc3-9b10-38471366b72e,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-57d53544-3cbf-4229-b593-d3a4e54690b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-79691642-172.17.0.2-1595961575513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41122,DS-9b31c53f-ca56-4d74-99ae-e6cc746b9f07,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-7928178e-39b1-43d4-ab3c-65b65f42623e,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-bc724c17-b9d5-42d3-83ce-2d413c79faeb,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-59a96bc2-4962-448d-b485-2c264c753bec,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-41de9561-0f23-41cd-8381-fe459f563cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-dd02b07d-046d-4bcc-abca-c727220d0800,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-6ae98fa1-f651-4e39-a460-1b3f45d8c43d,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-f21ce038-2a9f-4ab4-84be-31d19a8b4719,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-79691642-172.17.0.2-1595961575513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41122,DS-9b31c53f-ca56-4d74-99ae-e6cc746b9f07,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-7928178e-39b1-43d4-ab3c-65b65f42623e,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-bc724c17-b9d5-42d3-83ce-2d413c79faeb,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-59a96bc2-4962-448d-b485-2c264c753bec,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-41de9561-0f23-41cd-8381-fe459f563cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-dd02b07d-046d-4bcc-abca-c727220d0800,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-6ae98fa1-f651-4e39-a460-1b3f45d8c43d,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-f21ce038-2a9f-4ab4-84be-31d19a8b4719,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1111688614-172.17.0.2-1595961671149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35656,DS-1d101861-cdc2-496d-b6e1-00d375f36795,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-8630221a-5532-4be2-becb-8711b3d4fb17,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-1c40358a-4e00-47f7-ab62-a9ceadd2bf10,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-29214944-d684-4845-bde1-24c0590c0553,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-7959b4b2-9b21-4a89-9e45-e65bed7e56d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-a9392e9b-be93-4262-8e3a-73f775d42ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-12bbfcf8-45bd-4038-b48b-bbe845d2fcd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-75469cb3-0954-4ed6-b0c5-137b1fb8ecfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1111688614-172.17.0.2-1595961671149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35656,DS-1d101861-cdc2-496d-b6e1-00d375f36795,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-8630221a-5532-4be2-becb-8711b3d4fb17,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-1c40358a-4e00-47f7-ab62-a9ceadd2bf10,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-29214944-d684-4845-bde1-24c0590c0553,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-7959b4b2-9b21-4a89-9e45-e65bed7e56d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-a9392e9b-be93-4262-8e3a-73f775d42ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-12bbfcf8-45bd-4038-b48b-bbe845d2fcd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-75469cb3-0954-4ed6-b0c5-137b1fb8ecfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1863783925-172.17.0.2-1595962365141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46776,DS-99f89a36-7e67-427f-88e5-d9db13831396,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-9cc7140a-c0da-42a8-99fa-b35edbe11ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-3f7d795a-d381-450c-b0dd-dd84b5075d62,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-8fc25681-f170-416e-a5d6-39c7598c5718,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-7dc711dd-00d7-4888-8d11-349747821bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-6421feaa-49ce-4db5-bd6e-f1e00a5ff228,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-2ea53f82-fbe1-482c-9a09-058350115bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-eec3d33a-fc4d-48ae-8e93-88e27deef0ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1863783925-172.17.0.2-1595962365141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46776,DS-99f89a36-7e67-427f-88e5-d9db13831396,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-9cc7140a-c0da-42a8-99fa-b35edbe11ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-3f7d795a-d381-450c-b0dd-dd84b5075d62,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-8fc25681-f170-416e-a5d6-39c7598c5718,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-7dc711dd-00d7-4888-8d11-349747821bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-6421feaa-49ce-4db5-bd6e-f1e00a5ff228,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-2ea53f82-fbe1-482c-9a09-058350115bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-eec3d33a-fc4d-48ae-8e93-88e27deef0ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1155685965-172.17.0.2-1595963029263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40183,DS-96e30ac1-8ec6-424c-b550-13b8ca252526,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-91f1ab06-cca3-4f4e-b318-04844f098540,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-17eecd45-1260-45cb-ab3b-2b8e15ee0fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-76d39f04-0f80-4f74-96d8-0ab4cb091027,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-2178d294-8a31-4818-aaac-d4aae7f6150e,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-8a6bc0a8-8e5c-4a30-a139-b866bf549715,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-854e11b4-a9ab-44ee-9495-704744c470ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-9edaadbe-237c-401f-8fa1-2628e04427d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1155685965-172.17.0.2-1595963029263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40183,DS-96e30ac1-8ec6-424c-b550-13b8ca252526,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-91f1ab06-cca3-4f4e-b318-04844f098540,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-17eecd45-1260-45cb-ab3b-2b8e15ee0fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-76d39f04-0f80-4f74-96d8-0ab4cb091027,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-2178d294-8a31-4818-aaac-d4aae7f6150e,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-8a6bc0a8-8e5c-4a30-a139-b866bf549715,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-854e11b4-a9ab-44ee-9495-704744c470ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-9edaadbe-237c-401f-8fa1-2628e04427d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-684596240-172.17.0.2-1595963357374:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45719,DS-0478c2ad-ac6e-45ae-bf96-8abcb291acdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36919,DS-6ceea3af-c489-4755-837d-323556c08d29,DISK], DatanodeInfoWithStorage[127.0.0.1:36519,DS-6a052a38-dec1-40c8-81f7-a3a1ec0778df,DISK], DatanodeInfoWithStorage[127.0.0.1:34751,DS-b2f541aa-c376-468c-a275-be8f0be2fa92,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-7b12f679-585b-4897-88bd-05b59373389a,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-2af46536-9561-4e7b-ab6e-20afdf4dd055,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-bc7b107c-ba2c-4a3b-96a2-39783743ae14,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-f321352f-c234-41d4-83d3-0818506c22d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-684596240-172.17.0.2-1595963357374:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45719,DS-0478c2ad-ac6e-45ae-bf96-8abcb291acdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36919,DS-6ceea3af-c489-4755-837d-323556c08d29,DISK], DatanodeInfoWithStorage[127.0.0.1:36519,DS-6a052a38-dec1-40c8-81f7-a3a1ec0778df,DISK], DatanodeInfoWithStorage[127.0.0.1:34751,DS-b2f541aa-c376-468c-a275-be8f0be2fa92,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-7b12f679-585b-4897-88bd-05b59373389a,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-2af46536-9561-4e7b-ab6e-20afdf4dd055,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-bc7b107c-ba2c-4a3b-96a2-39783743ae14,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-f321352f-c234-41d4-83d3-0818506c22d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5151
