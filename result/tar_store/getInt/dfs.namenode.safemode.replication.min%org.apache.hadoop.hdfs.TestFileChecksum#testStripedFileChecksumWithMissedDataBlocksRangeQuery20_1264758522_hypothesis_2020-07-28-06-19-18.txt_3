reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1860058931-172.17.0.2-1595918483256:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39098,DS-09fd5541-974d-48d6-9c42-4885fd8e4d94,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-9232c05b-4b49-4f72-8eb4-18d519fdcddc,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-d75ce6dd-a37a-4cd2-82d4-2670499ab4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-2ec4e008-49ac-43f7-908e-677f5ecdaa49,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-512a15a5-e489-480e-978a-2d051547c2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-eb857cbc-47e7-43fb-a89c-4dc2a31d774e,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-26e6880a-96f0-4993-a015-eccede92fa07,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-d753eb8c-3cff-4801-b7f6-2481672d5fb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1860058931-172.17.0.2-1595918483256:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39098,DS-09fd5541-974d-48d6-9c42-4885fd8e4d94,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-9232c05b-4b49-4f72-8eb4-18d519fdcddc,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-d75ce6dd-a37a-4cd2-82d4-2670499ab4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-2ec4e008-49ac-43f7-908e-677f5ecdaa49,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-512a15a5-e489-480e-978a-2d051547c2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-eb857cbc-47e7-43fb-a89c-4dc2a31d774e,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-26e6880a-96f0-4993-a015-eccede92fa07,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-d753eb8c-3cff-4801-b7f6-2481672d5fb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1799322917-172.17.0.2-1595918535646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36949,DS-2943c3d9-33a7-4f77-96c0-05f4e60cb3dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-783bc9d1-36fb-4479-a4df-17b8d5e8281d,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-fdc6ca05-02b7-4202-ba2e-5b659c62ec71,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-9e8b7b4f-ffd3-4be4-afd2-bd3f6d6c7b14,DISK], DatanodeInfoWithStorage[127.0.0.1:38183,DS-8a325919-bf8b-49c0-8d7b-bf4fc5363f77,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-abb5fa54-7bcf-4ebb-a117-fd72c9e6ca7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-0cef0ddb-b78e-4672-b1f3-9afc7bff908c,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-dc6e1557-24de-4a80-866b-92074407edd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1799322917-172.17.0.2-1595918535646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36949,DS-2943c3d9-33a7-4f77-96c0-05f4e60cb3dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-783bc9d1-36fb-4479-a4df-17b8d5e8281d,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-fdc6ca05-02b7-4202-ba2e-5b659c62ec71,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-9e8b7b4f-ffd3-4be4-afd2-bd3f6d6c7b14,DISK], DatanodeInfoWithStorage[127.0.0.1:38183,DS-8a325919-bf8b-49c0-8d7b-bf4fc5363f77,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-abb5fa54-7bcf-4ebb-a117-fd72c9e6ca7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-0cef0ddb-b78e-4672-b1f3-9afc7bff908c,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-dc6e1557-24de-4a80-866b-92074407edd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1573662282-172.17.0.2-1595918699836:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36043,DS-e7a06cb4-3616-4655-8a9c-21a14c39631e,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-5ecc7813-4aac-48ee-ae42-9db8bb7accb7,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-0d485a06-9a9b-46cb-8504-4c52dbd70fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-66e238dc-f8a6-496b-ad7d-c92606e8b25a,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-5630a51f-8f7f-4bb9-bb2d-72d3cf547267,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-2eb69b5a-a11c-4829-b2dc-908ffe600ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-e546f064-a9a4-4be8-b608-b50113107cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-4a6dbd48-15f7-4071-8d99-3626fea8e529,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1573662282-172.17.0.2-1595918699836:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36043,DS-e7a06cb4-3616-4655-8a9c-21a14c39631e,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-5ecc7813-4aac-48ee-ae42-9db8bb7accb7,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-0d485a06-9a9b-46cb-8504-4c52dbd70fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-66e238dc-f8a6-496b-ad7d-c92606e8b25a,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-5630a51f-8f7f-4bb9-bb2d-72d3cf547267,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-2eb69b5a-a11c-4829-b2dc-908ffe600ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-e546f064-a9a4-4be8-b608-b50113107cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-4a6dbd48-15f7-4071-8d99-3626fea8e529,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-335347252-172.17.0.2-1595919461131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36764,DS-c089cc72-db63-4f01-8b4a-041ae3676c22,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-8cdf944c-2702-4651-9c11-6973d01f7845,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-80107921-7e15-45e0-95be-3d4b47d32867,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-148d6497-4711-42c3-8379-062754e9ba3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-0afd7e8d-10e0-4617-8f35-f0282fd96151,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-fb673de1-4b53-4883-a765-9ab60917bd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-41fa2a3a-e937-48b0-acfc-10237f190f57,DISK], DatanodeInfoWithStorage[127.0.0.1:38419,DS-677f88d1-258e-4be7-af75-59088b08139b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-335347252-172.17.0.2-1595919461131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36764,DS-c089cc72-db63-4f01-8b4a-041ae3676c22,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-8cdf944c-2702-4651-9c11-6973d01f7845,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-80107921-7e15-45e0-95be-3d4b47d32867,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-148d6497-4711-42c3-8379-062754e9ba3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-0afd7e8d-10e0-4617-8f35-f0282fd96151,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-fb673de1-4b53-4883-a765-9ab60917bd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-41fa2a3a-e937-48b0-acfc-10237f190f57,DISK], DatanodeInfoWithStorage[127.0.0.1:38419,DS-677f88d1-258e-4be7-af75-59088b08139b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-825691371-172.17.0.2-1595919609487:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32837,DS-6f20312b-1060-48a2-97d5-40c8dddc8745,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-fcf73e53-a770-4829-a88b-ba4faa309226,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-ef2d078c-ff99-4a6c-a326-ac91358642f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-282223b4-ff6d-47f7-86a8-24dc48037c56,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-a536dd9d-4d96-4cdc-8d21-b069704b7c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40906,DS-b9442ed2-20ae-457d-90d5-cbca92ffc5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-18a6ba39-9915-4df2-ae7e-6f3e6fd6c22b,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-c0d8a062-76ae-4aa2-bf2c-b10414f8b5f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-825691371-172.17.0.2-1595919609487:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32837,DS-6f20312b-1060-48a2-97d5-40c8dddc8745,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-fcf73e53-a770-4829-a88b-ba4faa309226,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-ef2d078c-ff99-4a6c-a326-ac91358642f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-282223b4-ff6d-47f7-86a8-24dc48037c56,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-a536dd9d-4d96-4cdc-8d21-b069704b7c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40906,DS-b9442ed2-20ae-457d-90d5-cbca92ffc5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-18a6ba39-9915-4df2-ae7e-6f3e6fd6c22b,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-c0d8a062-76ae-4aa2-bf2c-b10414f8b5f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1810634166-172.17.0.2-1595919864053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38691,DS-cc84fca2-15a9-4311-8531-21bcdc5135f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-c8b3de0c-335e-4ac4-9cbd-45c7e9ee6882,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-17b23894-e33e-430b-aeb0-5deadc8ed453,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-c3338300-4186-44d8-8f65-95985a09435d,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-65c08b27-b4ca-4175-961a-fe7c7fb389ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-fb576a75-6769-4881-a758-a41a7b85567e,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-4b8d23c1-f1cd-4200-9823-a81aee73dbee,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-5d4a10ab-ba61-496a-a46d-fc82f5a09671,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1810634166-172.17.0.2-1595919864053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38691,DS-cc84fca2-15a9-4311-8531-21bcdc5135f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-c8b3de0c-335e-4ac4-9cbd-45c7e9ee6882,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-17b23894-e33e-430b-aeb0-5deadc8ed453,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-c3338300-4186-44d8-8f65-95985a09435d,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-65c08b27-b4ca-4175-961a-fe7c7fb389ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-fb576a75-6769-4881-a758-a41a7b85567e,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-4b8d23c1-f1cd-4200-9823-a81aee73dbee,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-5d4a10ab-ba61-496a-a46d-fc82f5a09671,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-241111975-172.17.0.2-1595920137830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39201,DS-de4baa10-5d93-4bcf-8040-adda37c311df,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-ca6bfb93-b417-4d31-af55-a5e565029209,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-dfe9b1b5-aa9c-42ba-bf3b-0516e1111697,DISK], DatanodeInfoWithStorage[127.0.0.1:33635,DS-0d581a77-8aaa-496d-b450-90f3f19d221e,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-6a0a293c-caa0-4b3d-8bef-b74eb2c32d98,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-51f62161-cb72-4156-a310-097885cfd784,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-bae6c37f-3d50-4488-8f6a-0ac020d0b829,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-acbe0711-05cd-4a35-b6ed-d8527c4c7075,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-241111975-172.17.0.2-1595920137830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39201,DS-de4baa10-5d93-4bcf-8040-adda37c311df,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-ca6bfb93-b417-4d31-af55-a5e565029209,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-dfe9b1b5-aa9c-42ba-bf3b-0516e1111697,DISK], DatanodeInfoWithStorage[127.0.0.1:33635,DS-0d581a77-8aaa-496d-b450-90f3f19d221e,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-6a0a293c-caa0-4b3d-8bef-b74eb2c32d98,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-51f62161-cb72-4156-a310-097885cfd784,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-bae6c37f-3d50-4488-8f6a-0ac020d0b829,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-acbe0711-05cd-4a35-b6ed-d8527c4c7075,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-344753203-172.17.0.2-1595920316218:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40513,DS-416b4e49-615b-4ee5-8365-bae0890a4d55,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-e3b4f1bf-dc1f-4832-9361-31139af4b622,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-b348ff2c-7a02-490f-962b-82c7f627f826,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-63120924-e488-43d2-8d85-e45f115c3198,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-d35eb6e9-f045-4aa2-9e4b-382c78646127,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-39cf3bc6-c75c-41c0-bd0e-32b7060fa683,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-06949968-58fe-4ddd-9011-a076c784dddd,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-19990cd8-8977-41e0-8532-9708553a3707,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-344753203-172.17.0.2-1595920316218:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40513,DS-416b4e49-615b-4ee5-8365-bae0890a4d55,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-e3b4f1bf-dc1f-4832-9361-31139af4b622,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-b348ff2c-7a02-490f-962b-82c7f627f826,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-63120924-e488-43d2-8d85-e45f115c3198,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-d35eb6e9-f045-4aa2-9e4b-382c78646127,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-39cf3bc6-c75c-41c0-bd0e-32b7060fa683,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-06949968-58fe-4ddd-9011-a076c784dddd,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-19990cd8-8977-41e0-8532-9708553a3707,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-581270683-172.17.0.2-1595920582205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41827,DS-ed418f47-c9da-4f21-8d97-0386b252838a,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-c7c1a0de-caed-4457-9e4e-1adb80d31c59,DISK], DatanodeInfoWithStorage[127.0.0.1:36345,DS-194cedaf-9685-47f0-ab2f-f0c36cc7275d,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-5b7af970-b27c-4e31-b250-284b73b05bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-5e6c7eac-fd69-44a1-9e01-29a0c7ec026f,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-d4d68c6e-1434-43d1-8e53-cd96f71c9d35,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-aaa8fa07-3ed1-4450-97e5-0947b9998f96,DISK], DatanodeInfoWithStorage[127.0.0.1:38843,DS-aef6c388-d69e-4f4d-8cd8-387892efd6b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-581270683-172.17.0.2-1595920582205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41827,DS-ed418f47-c9da-4f21-8d97-0386b252838a,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-c7c1a0de-caed-4457-9e4e-1adb80d31c59,DISK], DatanodeInfoWithStorage[127.0.0.1:36345,DS-194cedaf-9685-47f0-ab2f-f0c36cc7275d,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-5b7af970-b27c-4e31-b250-284b73b05bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-5e6c7eac-fd69-44a1-9e01-29a0c7ec026f,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-d4d68c6e-1434-43d1-8e53-cd96f71c9d35,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-aaa8fa07-3ed1-4450-97e5-0947b9998f96,DISK], DatanodeInfoWithStorage[127.0.0.1:38843,DS-aef6c388-d69e-4f4d-8cd8-387892efd6b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-438707810-172.17.0.2-1595920751404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33862,DS-1ac83adb-5785-467f-b7fe-17a156f5f949,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-cfc33ae4-c499-4592-a560-51fc40c6c1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35541,DS-fefd58e6-370d-414b-94a1-6d6ad201b263,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-d45a1154-bddc-45b0-bdd0-3c2b82329c17,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-038cd0eb-0e02-4c9e-963b-b382f1e0fcf8,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-3b001722-5a23-4e0c-8b8d-7fe7a5dbb9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-6dcf9b2b-df45-40ba-aa26-6fba750e6606,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-4b885938-5b69-42d0-9bb1-de1c47173294,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-438707810-172.17.0.2-1595920751404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33862,DS-1ac83adb-5785-467f-b7fe-17a156f5f949,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-cfc33ae4-c499-4592-a560-51fc40c6c1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35541,DS-fefd58e6-370d-414b-94a1-6d6ad201b263,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-d45a1154-bddc-45b0-bdd0-3c2b82329c17,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-038cd0eb-0e02-4c9e-963b-b382f1e0fcf8,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-3b001722-5a23-4e0c-8b8d-7fe7a5dbb9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-6dcf9b2b-df45-40ba-aa26-6fba750e6606,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-4b885938-5b69-42d0-9bb1-de1c47173294,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-338707571-172.17.0.2-1595921136406:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36470,DS-4a608e8e-a132-48fc-a286-9f056b9339c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-1225c325-0ab5-4a36-a4ba-48a726a35eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-66c3d4f9-d759-4d68-81b0-19a063c78a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-4d4fd890-7fb8-454a-a8b1-8f57e3010d53,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-0cb44c19-5403-466d-8c8c-473957db4298,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-dc04deea-3ad2-4e8c-a256-c6ce4f6efc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-952ecfa4-088f-4331-9791-503733d05ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-b1619a4d-8f4c-40dc-95c1-8e29afb038ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-338707571-172.17.0.2-1595921136406:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36470,DS-4a608e8e-a132-48fc-a286-9f056b9339c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-1225c325-0ab5-4a36-a4ba-48a726a35eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-66c3d4f9-d759-4d68-81b0-19a063c78a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-4d4fd890-7fb8-454a-a8b1-8f57e3010d53,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-0cb44c19-5403-466d-8c8c-473957db4298,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-dc04deea-3ad2-4e8c-a256-c6ce4f6efc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-952ecfa4-088f-4331-9791-503733d05ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-b1619a4d-8f4c-40dc-95c1-8e29afb038ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1344480773-172.17.0.2-1595921927809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34729,DS-fc965f80-1afb-4ff9-bc33-a7bae764f5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33605,DS-042bb031-374f-41db-a462-635588aff383,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-4e166f8e-eba6-45d9-8700-6901b1b3b6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-b4b31b79-7252-402f-9c87-f2f0d3ff40c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-d512d01d-d760-4252-b594-bb4639e80a28,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-be96a6e7-5ddd-4a7c-a91a-01640d011334,DISK], DatanodeInfoWithStorage[127.0.0.1:40648,DS-ee05ba40-aaf9-4c60-b7e0-52305202c7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-4f4db41f-7539-406c-87bc-993bf6ff074a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1344480773-172.17.0.2-1595921927809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34729,DS-fc965f80-1afb-4ff9-bc33-a7bae764f5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33605,DS-042bb031-374f-41db-a462-635588aff383,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-4e166f8e-eba6-45d9-8700-6901b1b3b6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-b4b31b79-7252-402f-9c87-f2f0d3ff40c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-d512d01d-d760-4252-b594-bb4639e80a28,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-be96a6e7-5ddd-4a7c-a91a-01640d011334,DISK], DatanodeInfoWithStorage[127.0.0.1:40648,DS-ee05ba40-aaf9-4c60-b7e0-52305202c7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-4f4db41f-7539-406c-87bc-993bf6ff074a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2039359599-172.17.0.2-1595922055582:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36300,DS-46dfaa7a-9417-4119-8e8f-cb80ffd635a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-d6857e0e-d353-4363-b005-743139bf6c43,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-a6725c54-e90e-4cd0-b1a5-fa8a9e0aa49e,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-78562f0b-ae4c-4b07-861a-bd9187aeb61c,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-ee29be2a-08c6-402e-a8a1-076854baf98d,DISK], DatanodeInfoWithStorage[127.0.0.1:35891,DS-bcc196e9-7b8b-4b75-91b8-a42b1931bd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-86975379-faef-4115-8386-5bb36ebdf4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-ac100b6f-95d9-49be-a831-bece81e0dcd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2039359599-172.17.0.2-1595922055582:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36300,DS-46dfaa7a-9417-4119-8e8f-cb80ffd635a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-d6857e0e-d353-4363-b005-743139bf6c43,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-a6725c54-e90e-4cd0-b1a5-fa8a9e0aa49e,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-78562f0b-ae4c-4b07-861a-bd9187aeb61c,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-ee29be2a-08c6-402e-a8a1-076854baf98d,DISK], DatanodeInfoWithStorage[127.0.0.1:35891,DS-bcc196e9-7b8b-4b75-91b8-a42b1931bd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-86975379-faef-4115-8386-5bb36ebdf4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-ac100b6f-95d9-49be-a831-bece81e0dcd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-446856622-172.17.0.2-1595922093101:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39577,DS-a4e61923-7fb7-4e95-8e83-3730556c4a64,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-25de7962-772f-4876-9037-6a5eaa4628c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-da022a5f-dab1-474d-aba0-f44df91f7f57,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-4a2fb433-3854-44fd-b2b2-76e7b50c96a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-6fe37f7b-622a-4144-a1cd-ecb74dc6bd6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-dbba3c8d-d5ab-41e1-ae7f-89a3610f5085,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-2b6364ed-1432-4c64-ac23-f4b7e3932800,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-a2e0f899-1a34-4856-94cb-8bcacc59e185,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-446856622-172.17.0.2-1595922093101:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39577,DS-a4e61923-7fb7-4e95-8e83-3730556c4a64,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-25de7962-772f-4876-9037-6a5eaa4628c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-da022a5f-dab1-474d-aba0-f44df91f7f57,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-4a2fb433-3854-44fd-b2b2-76e7b50c96a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-6fe37f7b-622a-4144-a1cd-ecb74dc6bd6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-dbba3c8d-d5ab-41e1-ae7f-89a3610f5085,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-2b6364ed-1432-4c64-ac23-f4b7e3932800,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-a2e0f899-1a34-4856-94cb-8bcacc59e185,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1465193528-172.17.0.2-1595922259588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37390,DS-92e0cafa-88c9-4fb4-88dd-578afaad2bed,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-4159c928-b412-47bb-a33a-76ec29339a12,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-d8d56f43-3b0e-42a6-b780-b86ac9465073,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-cd1917aa-2e2c-4db3-b8b7-55a3b2265c05,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-9e9f5e7b-7884-4e33-97cd-e8834a613c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36635,DS-d2ded708-7016-4213-b5e9-a54f0d606e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-3cfe12bd-01ac-444c-a225-36fe8ab10558,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-d69781bb-de8d-4227-a9c9-aceeff1b23db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1465193528-172.17.0.2-1595922259588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37390,DS-92e0cafa-88c9-4fb4-88dd-578afaad2bed,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-4159c928-b412-47bb-a33a-76ec29339a12,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-d8d56f43-3b0e-42a6-b780-b86ac9465073,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-cd1917aa-2e2c-4db3-b8b7-55a3b2265c05,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-9e9f5e7b-7884-4e33-97cd-e8834a613c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36635,DS-d2ded708-7016-4213-b5e9-a54f0d606e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-3cfe12bd-01ac-444c-a225-36fe8ab10558,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-d69781bb-de8d-4227-a9c9-aceeff1b23db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-697314144-172.17.0.2-1595922522553:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42527,DS-ec0472ed-26d3-4fac-b6e3-516aeb2c74f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-6a70713e-8c76-45cc-a118-d99d96f17d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-4398827f-75f8-4584-af11-b9627ec5849e,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-3da8b964-9ce3-4eed-9eb9-ed6ceae824eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-354e1d0e-4a1b-4385-8e11-1b919585d7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-87e9db8b-e4d0-4b12-accd-39cb72e21d34,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-674b80c8-9620-48fa-9479-7405e3ffbde2,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-a07d0235-75d7-4934-9f38-5714b9f5f83f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-697314144-172.17.0.2-1595922522553:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42527,DS-ec0472ed-26d3-4fac-b6e3-516aeb2c74f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-6a70713e-8c76-45cc-a118-d99d96f17d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-4398827f-75f8-4584-af11-b9627ec5849e,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-3da8b964-9ce3-4eed-9eb9-ed6ceae824eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-354e1d0e-4a1b-4385-8e11-1b919585d7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-87e9db8b-e4d0-4b12-accd-39cb72e21d34,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-674b80c8-9620-48fa-9479-7405e3ffbde2,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-a07d0235-75d7-4934-9f38-5714b9f5f83f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-252669134-172.17.0.2-1595922789306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43350,DS-ae861ec5-0c66-49ad-9d9f-b82a2d321907,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-cfe2bdda-496f-4608-826c-54f2dc6023f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-1dc90f73-6055-4854-9e7e-7f66c9f84d45,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-22ca4de0-117b-4306-8a6a-bf0e1ad3425a,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-1937fb19-73f0-48c5-ac41-bdc5958247a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-13808466-347f-4fb2-97ac-8d411a7c0573,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-6121a73b-521d-464c-8ba2-18150743340c,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-4250ffbf-61ef-47f9-b416-cd4736252ed2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-252669134-172.17.0.2-1595922789306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43350,DS-ae861ec5-0c66-49ad-9d9f-b82a2d321907,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-cfe2bdda-496f-4608-826c-54f2dc6023f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-1dc90f73-6055-4854-9e7e-7f66c9f84d45,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-22ca4de0-117b-4306-8a6a-bf0e1ad3425a,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-1937fb19-73f0-48c5-ac41-bdc5958247a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-13808466-347f-4fb2-97ac-8d411a7c0573,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-6121a73b-521d-464c-8ba2-18150743340c,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-4250ffbf-61ef-47f9-b416-cd4736252ed2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-171351529-172.17.0.2-1595923277225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43598,DS-e00dc32c-96e5-4daf-9e9e-cf69fda317fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-a320a8a9-b54c-4e29-9cf2-e0c724174a19,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-700b8287-f3bf-4765-9506-5d5f48b2f4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-5fd694db-4af7-4f51-a579-2a4a9354a096,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-db7d98a9-a2a3-4105-9301-68a93265a84c,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-2ebc6441-7a5c-47cc-bcd3-233fbb71a305,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-882ca29f-0872-4f99-a483-b4170f0a341a,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-d778c5c2-e32a-42af-aca6-27d325f9c43a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-171351529-172.17.0.2-1595923277225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43598,DS-e00dc32c-96e5-4daf-9e9e-cf69fda317fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-a320a8a9-b54c-4e29-9cf2-e0c724174a19,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-700b8287-f3bf-4765-9506-5d5f48b2f4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-5fd694db-4af7-4f51-a579-2a4a9354a096,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-db7d98a9-a2a3-4105-9301-68a93265a84c,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-2ebc6441-7a5c-47cc-bcd3-233fbb71a305,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-882ca29f-0872-4f99-a483-b4170f0a341a,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-d778c5c2-e32a-42af-aca6-27d325f9c43a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1065249679-172.17.0.2-1595923514348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44877,DS-2571f3a2-a1a2-41a8-962d-435ff58f82e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-8fb834d6-eac5-45cd-97e8-bae4e4fef732,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-1d29bff3-ec79-4799-89a0-cab06a011f87,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-0d9fdb09-7ee9-4791-8a64-79548ce126d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-a139fa7f-d39b-4e91-a019-43af843375ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-8a15fc55-0608-4077-89da-4e9d141e7e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-b7cfd6c0-9605-4203-b9e4-24a8c73a4ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-d809aa7f-2378-4309-acc6-a346dfaaabf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1065249679-172.17.0.2-1595923514348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44877,DS-2571f3a2-a1a2-41a8-962d-435ff58f82e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-8fb834d6-eac5-45cd-97e8-bae4e4fef732,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-1d29bff3-ec79-4799-89a0-cab06a011f87,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-0d9fdb09-7ee9-4791-8a64-79548ce126d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-a139fa7f-d39b-4e91-a019-43af843375ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-8a15fc55-0608-4077-89da-4e9d141e7e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-b7cfd6c0-9605-4203-b9e4-24a8c73a4ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-d809aa7f-2378-4309-acc6-a346dfaaabf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6587
