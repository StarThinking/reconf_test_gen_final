reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-66595924-172.17.0.20-1596039148771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42029,DS-870a837c-cfc2-469b-a5e6-ca597a279e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-f0cea0dd-142c-4d50-b22d-4b39e2767c83,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-874e294a-ab16-43fe-8347-b1bad44f1b14,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-5bc0f068-8fb5-49cb-a2bc-90598e2c08f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-8a0e48cc-14f9-4af9-89e6-6fe4af6d5aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-ba680c9c-4b49-494f-8a23-c35fe37e3010,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-96a035d9-0240-4665-8c25-8407a7966c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-bf1808b1-09dd-4f42-a752-abeb9b50ccc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-66595924-172.17.0.20-1596039148771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42029,DS-870a837c-cfc2-469b-a5e6-ca597a279e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-f0cea0dd-142c-4d50-b22d-4b39e2767c83,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-874e294a-ab16-43fe-8347-b1bad44f1b14,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-5bc0f068-8fb5-49cb-a2bc-90598e2c08f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-8a0e48cc-14f9-4af9-89e6-6fe4af6d5aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-ba680c9c-4b49-494f-8a23-c35fe37e3010,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-96a035d9-0240-4665-8c25-8407a7966c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-bf1808b1-09dd-4f42-a752-abeb9b50ccc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-320706055-172.17.0.20-1596039374058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38193,DS-6f503dc2-c52a-495f-9170-0f5100b6c431,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-4b79ff6d-bc5b-4c39-b55a-4f864023a047,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-c36423a8-f85d-4855-a24a-1fa66318f58b,DISK], DatanodeInfoWithStorage[127.0.0.1:41388,DS-e266f70f-5450-456f-9e19-b1861992e4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-41a8a66a-fa4d-4924-9788-1d4795daca9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41932,DS-f926b009-61d5-40f0-bb48-13dc1c693c48,DISK], DatanodeInfoWithStorage[127.0.0.1:38643,DS-ad14e790-2395-4756-a5a8-58b23f08a3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-4a7d3696-4f5b-42e8-8b0c-ab3b08090e1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-320706055-172.17.0.20-1596039374058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38193,DS-6f503dc2-c52a-495f-9170-0f5100b6c431,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-4b79ff6d-bc5b-4c39-b55a-4f864023a047,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-c36423a8-f85d-4855-a24a-1fa66318f58b,DISK], DatanodeInfoWithStorage[127.0.0.1:41388,DS-e266f70f-5450-456f-9e19-b1861992e4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-41a8a66a-fa4d-4924-9788-1d4795daca9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41932,DS-f926b009-61d5-40f0-bb48-13dc1c693c48,DISK], DatanodeInfoWithStorage[127.0.0.1:38643,DS-ad14e790-2395-4756-a5a8-58b23f08a3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-4a7d3696-4f5b-42e8-8b0c-ab3b08090e1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-415535255-172.17.0.20-1596039458054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42739,DS-fbd72dff-f347-4de2-9476-843b1ddd8911,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-12730c4e-4e77-41f9-b3f4-91d8c7603831,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-187cec5c-aced-49cf-8969-5f07c3e3a7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-0c4056e0-9033-40d5-8c8a-5d43e2480f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36122,DS-60240a50-e692-493b-9193-dfbc7a9034b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-7b0747fd-ecd5-45d5-8ae3-0bc424488029,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-3d0d2818-3a42-41a2-b7bd-cc498ab27cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-68c0ea87-fa15-4873-8777-ea1165573f0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-415535255-172.17.0.20-1596039458054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42739,DS-fbd72dff-f347-4de2-9476-843b1ddd8911,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-12730c4e-4e77-41f9-b3f4-91d8c7603831,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-187cec5c-aced-49cf-8969-5f07c3e3a7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-0c4056e0-9033-40d5-8c8a-5d43e2480f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36122,DS-60240a50-e692-493b-9193-dfbc7a9034b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-7b0747fd-ecd5-45d5-8ae3-0bc424488029,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-3d0d2818-3a42-41a2-b7bd-cc498ab27cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-68c0ea87-fa15-4873-8777-ea1165573f0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-508350403-172.17.0.20-1596039766328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43296,DS-6e919b34-0b8c-46dc-84b6-53c38176f162,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-c56eaf04-2044-40fe-b123-dedbca671d52,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-4d3d8a62-14d9-475e-8bcf-8b6385a8b752,DISK], DatanodeInfoWithStorage[127.0.0.1:39538,DS-0e655d8c-f436-470d-8bd1-959c2b5029d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-06e8c35f-de3b-4f13-914f-692172bd3ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-a1311bab-d779-4d87-85df-108f76afa4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-19df9bc9-4d54-4dcc-9825-caee6ce55f68,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-3534f527-0341-4357-8c6e-b6625c04122f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-508350403-172.17.0.20-1596039766328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43296,DS-6e919b34-0b8c-46dc-84b6-53c38176f162,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-c56eaf04-2044-40fe-b123-dedbca671d52,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-4d3d8a62-14d9-475e-8bcf-8b6385a8b752,DISK], DatanodeInfoWithStorage[127.0.0.1:39538,DS-0e655d8c-f436-470d-8bd1-959c2b5029d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-06e8c35f-de3b-4f13-914f-692172bd3ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-a1311bab-d779-4d87-85df-108f76afa4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-19df9bc9-4d54-4dcc-9825-caee6ce55f68,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-3534f527-0341-4357-8c6e-b6625c04122f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2118522786-172.17.0.20-1596039847605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34446,DS-b7cde0d9-dcb3-441a-aba5-bfa9b5ffd33e,DISK], DatanodeInfoWithStorage[127.0.0.1:34227,DS-0a0a17eb-0588-432f-b5a0-7a72e9b3dbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-3e7a4ba6-138d-4b0d-ba54-46451bf51a74,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-ad3b3b7d-b61e-44f7-abbd-a475aa2ccff8,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-ae979b4d-be86-4f76-92d7-8c26a8b7258f,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-49b558bd-2091-48b0-9c36-836e01cffe30,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-d8cd05d4-1bea-4e2c-88bf-50dda0917c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-93124bb6-b18f-4518-8e20-cf9d6f10f5c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2118522786-172.17.0.20-1596039847605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34446,DS-b7cde0d9-dcb3-441a-aba5-bfa9b5ffd33e,DISK], DatanodeInfoWithStorage[127.0.0.1:34227,DS-0a0a17eb-0588-432f-b5a0-7a72e9b3dbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-3e7a4ba6-138d-4b0d-ba54-46451bf51a74,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-ad3b3b7d-b61e-44f7-abbd-a475aa2ccff8,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-ae979b4d-be86-4f76-92d7-8c26a8b7258f,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-49b558bd-2091-48b0-9c36-836e01cffe30,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-d8cd05d4-1bea-4e2c-88bf-50dda0917c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-93124bb6-b18f-4518-8e20-cf9d6f10f5c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-86259176-172.17.0.20-1596040033540:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41548,DS-a972fd35-5e5c-4940-8e36-2a21d8be387f,DISK], DatanodeInfoWithStorage[127.0.0.1:38126,DS-0e6bafa0-a4cd-4680-ba1c-aff0a0fb455e,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-c6cb0f95-1487-4b53-9637-6cb3488a870e,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-544e407f-f89c-4928-a8bd-c665bc1c80f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-31dbe211-2312-4ae1-ab86-5ad519bb7e37,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-14231bf4-a4a3-49c0-bb3b-931968c36888,DISK], DatanodeInfoWithStorage[127.0.0.1:37732,DS-7de775bc-f694-48ed-b1c2-6da112f39106,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-d4b0f190-daa7-44f5-adbe-2c45bd54b2b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-86259176-172.17.0.20-1596040033540:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41548,DS-a972fd35-5e5c-4940-8e36-2a21d8be387f,DISK], DatanodeInfoWithStorage[127.0.0.1:38126,DS-0e6bafa0-a4cd-4680-ba1c-aff0a0fb455e,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-c6cb0f95-1487-4b53-9637-6cb3488a870e,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-544e407f-f89c-4928-a8bd-c665bc1c80f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-31dbe211-2312-4ae1-ab86-5ad519bb7e37,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-14231bf4-a4a3-49c0-bb3b-931968c36888,DISK], DatanodeInfoWithStorage[127.0.0.1:37732,DS-7de775bc-f694-48ed-b1c2-6da112f39106,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-d4b0f190-daa7-44f5-adbe-2c45bd54b2b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-517268435-172.17.0.20-1596040075227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36009,DS-d5961330-5193-4de0-ae4f-e7c00e09f935,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-57ae526d-2c44-4dd0-ae83-9712367205ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-22d6551d-b7b0-4bc7-bfd7-42d4e493bab9,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-f95680d5-ea86-486a-821b-5ff0f1be40c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38694,DS-41d9e33b-d57e-4599-af94-5b0366b11bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-7ecacf5e-5460-4e43-a3ee-286d054f9618,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-c52d0d32-a955-4d86-88a5-c711f7b448a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-bf29371b-5747-417e-a1b3-ff70486cb8ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-517268435-172.17.0.20-1596040075227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36009,DS-d5961330-5193-4de0-ae4f-e7c00e09f935,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-57ae526d-2c44-4dd0-ae83-9712367205ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-22d6551d-b7b0-4bc7-bfd7-42d4e493bab9,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-f95680d5-ea86-486a-821b-5ff0f1be40c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38694,DS-41d9e33b-d57e-4599-af94-5b0366b11bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-7ecacf5e-5460-4e43-a3ee-286d054f9618,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-c52d0d32-a955-4d86-88a5-c711f7b448a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-bf29371b-5747-417e-a1b3-ff70486cb8ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1904230697-172.17.0.20-1596040258939:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44537,DS-e43094a5-0f46-4bbf-9ae7-7570967b8813,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-4f0edf34-36e5-4a57-ba70-9c6c7147c834,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-71e60165-11bd-49a8-9a95-c45156076cac,DISK], DatanodeInfoWithStorage[127.0.0.1:41071,DS-66803747-1a4c-49a4-9f82-5cdaf32a29ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-35d9352b-c0dc-43b7-99db-fbd22bdc9301,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-c6734139-36b4-4e89-82fa-534aa0cddce0,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-a137f271-63cb-4fd9-8ada-dea5d339bd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-d3e2bd03-4b5d-4a52-b58a-a90e936d4989,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1904230697-172.17.0.20-1596040258939:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44537,DS-e43094a5-0f46-4bbf-9ae7-7570967b8813,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-4f0edf34-36e5-4a57-ba70-9c6c7147c834,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-71e60165-11bd-49a8-9a95-c45156076cac,DISK], DatanodeInfoWithStorage[127.0.0.1:41071,DS-66803747-1a4c-49a4-9f82-5cdaf32a29ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-35d9352b-c0dc-43b7-99db-fbd22bdc9301,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-c6734139-36b4-4e89-82fa-534aa0cddce0,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-a137f271-63cb-4fd9-8ada-dea5d339bd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-d3e2bd03-4b5d-4a52-b58a-a90e936d4989,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1860922932-172.17.0.20-1596040278880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41229,DS-d1a85772-d821-4690-b103-bdc574484f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-4e4e5e65-9729-4af5-9efa-a4df4507fc84,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-300755a1-5464-4b4c-9af5-87a0f602a7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-9a1cdc8a-62ae-41c8-9933-f45cffa64108,DISK], DatanodeInfoWithStorage[127.0.0.1:46046,DS-6138342c-fc9f-439c-b3c0-a4c244cb634b,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-f3332722-813c-4521-ba30-fcdb83f01172,DISK], DatanodeInfoWithStorage[127.0.0.1:34046,DS-a6ed7182-7400-40c9-b5e1-4844ac6774ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-e3c7d251-d968-4428-add9-49c7da05263f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1860922932-172.17.0.20-1596040278880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41229,DS-d1a85772-d821-4690-b103-bdc574484f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-4e4e5e65-9729-4af5-9efa-a4df4507fc84,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-300755a1-5464-4b4c-9af5-87a0f602a7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-9a1cdc8a-62ae-41c8-9933-f45cffa64108,DISK], DatanodeInfoWithStorage[127.0.0.1:46046,DS-6138342c-fc9f-439c-b3c0-a4c244cb634b,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-f3332722-813c-4521-ba30-fcdb83f01172,DISK], DatanodeInfoWithStorage[127.0.0.1:34046,DS-a6ed7182-7400-40c9-b5e1-4844ac6774ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-e3c7d251-d968-4428-add9-49c7da05263f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-17487293-172.17.0.20-1596040400864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41946,DS-1e662179-e64c-42e6-b59a-66466a57f9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-26bcbdf9-d591-44b0-9b27-eb18a6bb51e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-8e694ede-13a0-4905-aae5-63e355841fab,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-e1ff8072-622b-40d7-84b9-f055d9232a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-591af9ca-c09a-40b9-836e-849babfed9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41127,DS-abc9952e-fcff-4ec4-9fe7-3b325ab9d1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42549,DS-50a06308-9b85-4525-a505-49f324e1d125,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-82be520b-915d-4484-86d9-06defa2f92fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-17487293-172.17.0.20-1596040400864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41946,DS-1e662179-e64c-42e6-b59a-66466a57f9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-26bcbdf9-d591-44b0-9b27-eb18a6bb51e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-8e694ede-13a0-4905-aae5-63e355841fab,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-e1ff8072-622b-40d7-84b9-f055d9232a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-591af9ca-c09a-40b9-836e-849babfed9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41127,DS-abc9952e-fcff-4ec4-9fe7-3b325ab9d1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42549,DS-50a06308-9b85-4525-a505-49f324e1d125,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-82be520b-915d-4484-86d9-06defa2f92fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-576347459-172.17.0.20-1596040482297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34017,DS-0482ba6d-cafe-469d-8002-edcbd62e0254,DISK], DatanodeInfoWithStorage[127.0.0.1:40746,DS-7af8953a-2d7e-42d4-943a-534aad1a79d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-76b00c2d-693b-40d1-bca2-554c892d7318,DISK], DatanodeInfoWithStorage[127.0.0.1:42164,DS-7a5e98b0-e0bd-46f6-a4b7-0d3b52ec65d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-898ddc80-3d07-455c-b355-30415b167b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-4fa88f3c-06d7-4926-8dca-50864ebfa1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-21c71ece-65c4-472c-b158-c1b584e15c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-20b4a199-de17-43ba-addc-9d6e3120fb02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-576347459-172.17.0.20-1596040482297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34017,DS-0482ba6d-cafe-469d-8002-edcbd62e0254,DISK], DatanodeInfoWithStorage[127.0.0.1:40746,DS-7af8953a-2d7e-42d4-943a-534aad1a79d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-76b00c2d-693b-40d1-bca2-554c892d7318,DISK], DatanodeInfoWithStorage[127.0.0.1:42164,DS-7a5e98b0-e0bd-46f6-a4b7-0d3b52ec65d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-898ddc80-3d07-455c-b355-30415b167b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-4fa88f3c-06d7-4926-8dca-50864ebfa1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-21c71ece-65c4-472c-b158-c1b584e15c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-20b4a199-de17-43ba-addc-9d6e3120fb02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-24298737-172.17.0.20-1596040669941:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45430,DS-1ac17dca-e742-4d3c-9582-d5cf62c7979b,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-3e89eec5-1f26-4dd8-9d0d-ddedb0536099,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-6f09490c-6cc5-4fa3-94ac-91114fbad15a,DISK], DatanodeInfoWithStorage[127.0.0.1:33696,DS-fb02732b-17a7-449c-be22-6771aba499f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-af708dad-4162-4607-bbaf-6a4ff938a66d,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-ec8021f6-e2da-4eff-a46c-f1580a88699d,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-e30cb031-ce93-44ef-b33c-ca7e0bbac836,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-f78c857f-2e89-44f9-85f1-8ac05160b1bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-24298737-172.17.0.20-1596040669941:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45430,DS-1ac17dca-e742-4d3c-9582-d5cf62c7979b,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-3e89eec5-1f26-4dd8-9d0d-ddedb0536099,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-6f09490c-6cc5-4fa3-94ac-91114fbad15a,DISK], DatanodeInfoWithStorage[127.0.0.1:33696,DS-fb02732b-17a7-449c-be22-6771aba499f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-af708dad-4162-4607-bbaf-6a4ff938a66d,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-ec8021f6-e2da-4eff-a46c-f1580a88699d,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-e30cb031-ce93-44ef-b33c-ca7e0bbac836,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-f78c857f-2e89-44f9-85f1-8ac05160b1bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-934320764-172.17.0.20-1596040711263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40319,DS-872430a3-816f-44ce-859e-c066724f1305,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-ef6fc876-2aaa-48f4-9020-754929fec635,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-9aab2763-376f-4d60-afbb-772977dc7301,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-59060a3c-5a82-4d01-893f-ff19a5de57d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36074,DS-18adb37f-60dc-408a-a2d4-f62aef038497,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-2c2ee68a-688e-4f2e-a3b8-1a3fca1ba224,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-32f16b66-d091-4040-afd6-cb80b2bdd4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-b0a49a16-eb04-4764-ba75-cc421b178642,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-934320764-172.17.0.20-1596040711263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40319,DS-872430a3-816f-44ce-859e-c066724f1305,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-ef6fc876-2aaa-48f4-9020-754929fec635,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-9aab2763-376f-4d60-afbb-772977dc7301,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-59060a3c-5a82-4d01-893f-ff19a5de57d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36074,DS-18adb37f-60dc-408a-a2d4-f62aef038497,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-2c2ee68a-688e-4f2e-a3b8-1a3fca1ba224,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-32f16b66-d091-4040-afd6-cb80b2bdd4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-b0a49a16-eb04-4764-ba75-cc421b178642,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-71809025-172.17.0.20-1596040979590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45186,DS-1748f4d4-c1d5-4cb8-b87b-053f409f61f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-ef06c22e-2f56-41d7-b22f-504fb15dd0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-9dd43669-e75a-4c55-a75d-fadbcb3dcbad,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-f80e52d9-2eb2-4471-b3f6-079b049f019d,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-ff095642-a513-49df-82d5-c030ee64a116,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-ebcda6dc-32d0-4ba9-abda-6e5585ee05aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-b3702f9e-6530-409f-83ad-72e49b14c307,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-f9de412a-bf9c-42a6-86b7-57df3f08b497,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-71809025-172.17.0.20-1596040979590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45186,DS-1748f4d4-c1d5-4cb8-b87b-053f409f61f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-ef06c22e-2f56-41d7-b22f-504fb15dd0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-9dd43669-e75a-4c55-a75d-fadbcb3dcbad,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-f80e52d9-2eb2-4471-b3f6-079b049f019d,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-ff095642-a513-49df-82d5-c030ee64a116,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-ebcda6dc-32d0-4ba9-abda-6e5585ee05aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-b3702f9e-6530-409f-83ad-72e49b14c307,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-f9de412a-bf9c-42a6-86b7-57df3f08b497,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1350536081-172.17.0.20-1596041184792:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43514,DS-b18ecc7a-27e5-4b27-b650-793e78c5851a,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-bf1266ab-daa6-4369-b23b-c6f779b1b597,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-6b80f6fb-680e-4314-8e73-68876b59015e,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-776ba863-2ef2-44b0-acdf-0fece99421ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-2be0da29-9397-4b1e-89ee-3b177ddad849,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-e0da7f88-e164-41dc-bfbc-55ca47dde134,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-e7f0b61b-5c2c-4ea0-aca8-c9f1884a97e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-19b8a85d-0c2c-4a71-9706-41ded06826d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1350536081-172.17.0.20-1596041184792:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43514,DS-b18ecc7a-27e5-4b27-b650-793e78c5851a,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-bf1266ab-daa6-4369-b23b-c6f779b1b597,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-6b80f6fb-680e-4314-8e73-68876b59015e,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-776ba863-2ef2-44b0-acdf-0fece99421ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-2be0da29-9397-4b1e-89ee-3b177ddad849,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-e0da7f88-e164-41dc-bfbc-55ca47dde134,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-e7f0b61b-5c2c-4ea0-aca8-c9f1884a97e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-19b8a85d-0c2c-4a71-9706-41ded06826d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1744983378-172.17.0.20-1596041204822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46405,DS-39dbdee5-11b0-4602-aabb-732e72140f22,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-74c5b38d-7272-4ed2-8c99-f85b1c9e5349,DISK], DatanodeInfoWithStorage[127.0.0.1:38915,DS-9e4ab350-192b-43fa-adad-b1deb3aeb1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-a93d4e13-62bb-4f71-b884-a10ec8dd2919,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-01dd0008-3a7c-4018-985f-333d9cd50e51,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-d443803e-1353-4b8e-9cb4-ceb2d7ea0898,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-652ef116-cfa6-4bc7-a51d-a1c2eaa60f82,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-11aa7326-a96d-461e-8090-fb7cdbcf4a3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1744983378-172.17.0.20-1596041204822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46405,DS-39dbdee5-11b0-4602-aabb-732e72140f22,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-74c5b38d-7272-4ed2-8c99-f85b1c9e5349,DISK], DatanodeInfoWithStorage[127.0.0.1:38915,DS-9e4ab350-192b-43fa-adad-b1deb3aeb1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-a93d4e13-62bb-4f71-b884-a10ec8dd2919,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-01dd0008-3a7c-4018-985f-333d9cd50e51,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-d443803e-1353-4b8e-9cb4-ceb2d7ea0898,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-652ef116-cfa6-4bc7-a51d-a1c2eaa60f82,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-11aa7326-a96d-461e-8090-fb7cdbcf4a3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1686360353-172.17.0.20-1596041471006:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40039,DS-399719d9-d578-4b7a-b520-af089629a8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-da8afa27-66b0-4342-9c09-ec903300b907,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-3c3be208-2b82-4f0e-8443-09bcf76de552,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-16c0910c-a0a9-4047-a3f3-8ecc7f46e613,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-29958143-c054-4da9-b15c-672ee8076277,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-85736e32-ea9c-46e6-9040-3d7aecd2bf13,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-aee6c738-3f5b-4d92-96ca-29a7d1450fef,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-c81191ef-a6d4-438b-b4e2-db7eaebfca88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1686360353-172.17.0.20-1596041471006:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40039,DS-399719d9-d578-4b7a-b520-af089629a8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-da8afa27-66b0-4342-9c09-ec903300b907,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-3c3be208-2b82-4f0e-8443-09bcf76de552,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-16c0910c-a0a9-4047-a3f3-8ecc7f46e613,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-29958143-c054-4da9-b15c-672ee8076277,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-85736e32-ea9c-46e6-9040-3d7aecd2bf13,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-aee6c738-3f5b-4d92-96ca-29a7d1450fef,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-c81191ef-a6d4-438b-b4e2-db7eaebfca88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-595463172-172.17.0.20-1596041513106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33319,DS-4e7e2ff3-034c-44d1-9624-ff4201a87813,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-47052ef2-fbbe-49b6-80d7-b7ccf396910c,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-60be1498-c5c6-4534-8061-7bec56ca44fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-53d5635c-8515-493f-a1bc-09196977ccbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-7a21d218-f740-4f80-a6e4-00aeb0875b73,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-55f48674-28c3-422b-8546-72f38c63031d,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-0c5cdf95-4511-4c7c-8b9e-af8005c2780a,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-1b5d77b8-707f-4f3e-8c91-3c3bfbdc2de8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-595463172-172.17.0.20-1596041513106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33319,DS-4e7e2ff3-034c-44d1-9624-ff4201a87813,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-47052ef2-fbbe-49b6-80d7-b7ccf396910c,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-60be1498-c5c6-4534-8061-7bec56ca44fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-53d5635c-8515-493f-a1bc-09196977ccbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-7a21d218-f740-4f80-a6e4-00aeb0875b73,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-55f48674-28c3-422b-8546-72f38c63031d,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-0c5cdf95-4511-4c7c-8b9e-af8005c2780a,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-1b5d77b8-707f-4f3e-8c91-3c3bfbdc2de8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1814745093-172.17.0.20-1596041718050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46077,DS-4a71672e-cf71-464b-a2cc-dcfa062ee6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-9f3c22b7-ebba-4dad-a04f-0248eaee15f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39533,DS-e029b517-8d50-4202-8824-1680a666764b,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-0840df55-aa7e-4905-91d1-00d55dc5df8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-e0606fd9-651a-43b7-b581-bf1f16246d17,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-5878f4f8-9444-4030-b0ff-50f6af94d916,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-842bad8d-8aa6-4584-a3d2-5d576c15f3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-60c1292f-0830-4169-a110-f19df240b626,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1814745093-172.17.0.20-1596041718050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46077,DS-4a71672e-cf71-464b-a2cc-dcfa062ee6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-9f3c22b7-ebba-4dad-a04f-0248eaee15f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39533,DS-e029b517-8d50-4202-8824-1680a666764b,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-0840df55-aa7e-4905-91d1-00d55dc5df8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-e0606fd9-651a-43b7-b581-bf1f16246d17,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-5878f4f8-9444-4030-b0ff-50f6af94d916,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-842bad8d-8aa6-4584-a3d2-5d576c15f3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-60c1292f-0830-4169-a110-f19df240b626,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1122536262-172.17.0.20-1596041738230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39288,DS-bd61928d-73c5-48d0-8579-04a4a4ff5dda,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-a7f5d340-3be7-487f-9b4f-6bc018f13856,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-0f7caeff-d268-4ead-aa43-5ae0bffa4a96,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-310ba8e7-6fdc-4659-9bc2-6d38c5356bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-1e5c265d-5b5a-47c1-9301-fa9b242619cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-c604c0a8-9840-432e-b9b7-98996f716384,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-b961e80e-686c-4db3-a81b-d908cdaf6de8,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-9550c2ea-93f8-4771-a0fe-e873feadacbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1122536262-172.17.0.20-1596041738230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39288,DS-bd61928d-73c5-48d0-8579-04a4a4ff5dda,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-a7f5d340-3be7-487f-9b4f-6bc018f13856,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-0f7caeff-d268-4ead-aa43-5ae0bffa4a96,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-310ba8e7-6fdc-4659-9bc2-6d38c5356bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-1e5c265d-5b5a-47c1-9301-fa9b242619cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-c604c0a8-9840-432e-b9b7-98996f716384,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-b961e80e-686c-4db3-a81b-d908cdaf6de8,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-9550c2ea-93f8-4771-a0fe-e873feadacbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-723930806-172.17.0.20-1596041819853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34237,DS-b4468760-dbed-4449-ad99-da61de61ed14,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-f7b76092-e212-48b5-a970-c50a20b3c135,DISK], DatanodeInfoWithStorage[127.0.0.1:45963,DS-42f10be4-e249-4e3d-9d1b-51a8b19de448,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-fbe283ed-96c6-458c-9464-440ec5c8ab71,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-500ae9ee-a613-41cc-8532-a133b89a76cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-c69649dc-1d91-4477-a2bd-511b1c34899d,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-5724f7b2-9446-4708-b697-274d01f51d28,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-ce31bf25-249b-418c-a15c-760ed85758f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-723930806-172.17.0.20-1596041819853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34237,DS-b4468760-dbed-4449-ad99-da61de61ed14,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-f7b76092-e212-48b5-a970-c50a20b3c135,DISK], DatanodeInfoWithStorage[127.0.0.1:45963,DS-42f10be4-e249-4e3d-9d1b-51a8b19de448,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-fbe283ed-96c6-458c-9464-440ec5c8ab71,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-500ae9ee-a613-41cc-8532-a133b89a76cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-c69649dc-1d91-4477-a2bd-511b1c34899d,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-5724f7b2-9446-4708-b697-274d01f51d28,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-ce31bf25-249b-418c-a15c-760ed85758f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 3089
