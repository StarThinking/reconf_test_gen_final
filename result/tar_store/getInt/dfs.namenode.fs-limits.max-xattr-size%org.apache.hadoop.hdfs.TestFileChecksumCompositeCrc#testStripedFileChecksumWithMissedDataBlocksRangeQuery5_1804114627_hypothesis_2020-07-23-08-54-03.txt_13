reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-301337993-172.17.0.20-1595494849379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35460,DS-0f77b367-4ee4-46e0-9289-2ccb1872eba0,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-99690b8f-097a-4d52-a1b4-d776270a3c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-c47c7779-ce9e-4b3c-93d3-210e6d701ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-84a8e79c-6b15-4130-aa0a-8356a365153f,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-fb77ea4d-196c-4c95-bb72-9637f6bc5e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-00051711-58f6-40b8-bd18-64d7c5f0769a,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-c7d39c7a-3057-4910-98d5-76577fa649ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-49eef778-f1fe-48c9-ac94-b355ac43ce04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-301337993-172.17.0.20-1595494849379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35460,DS-0f77b367-4ee4-46e0-9289-2ccb1872eba0,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-99690b8f-097a-4d52-a1b4-d776270a3c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-c47c7779-ce9e-4b3c-93d3-210e6d701ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-84a8e79c-6b15-4130-aa0a-8356a365153f,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-fb77ea4d-196c-4c95-bb72-9637f6bc5e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-00051711-58f6-40b8-bd18-64d7c5f0769a,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-c7d39c7a-3057-4910-98d5-76577fa649ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-49eef778-f1fe-48c9-ac94-b355ac43ce04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1396208383-172.17.0.20-1595495710687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43419,DS-9ebe4d74-d91e-4f7f-bec9-7c82d3df5fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-e7be6d16-a657-48d7-ad53-907ce4625cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-6682383e-bf49-4274-bd8f-f3ea3f6ebca2,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-22ac4f68-5d7a-443d-95bb-d843b041fa6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-5e773179-ae78-4d35-bb64-0f6a94cc3154,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-95ce85fa-28fa-472c-bf39-242d7df7ffba,DISK], DatanodeInfoWithStorage[127.0.0.1:44660,DS-2a234274-5a88-4148-a3fa-137e2a9980ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-d658be48-9944-43e8-bc01-af76b75d3071,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1396208383-172.17.0.20-1595495710687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43419,DS-9ebe4d74-d91e-4f7f-bec9-7c82d3df5fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-e7be6d16-a657-48d7-ad53-907ce4625cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-6682383e-bf49-4274-bd8f-f3ea3f6ebca2,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-22ac4f68-5d7a-443d-95bb-d843b041fa6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-5e773179-ae78-4d35-bb64-0f6a94cc3154,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-95ce85fa-28fa-472c-bf39-242d7df7ffba,DISK], DatanodeInfoWithStorage[127.0.0.1:44660,DS-2a234274-5a88-4148-a3fa-137e2a9980ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-d658be48-9944-43e8-bc01-af76b75d3071,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1970524719-172.17.0.20-1595495903899:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34943,DS-604309c5-280b-42ae-b2c7-d6eb7c33c31e,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-8ae3d399-b63c-4442-80b4-5d5e42026173,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-a7d7f557-68f5-4b9e-9e77-0a6b332e2a63,DISK], DatanodeInfoWithStorage[127.0.0.1:38241,DS-a2291719-f93f-4f12-b7da-c0dfc312a962,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-0d75be62-7561-4886-9c9f-bd201137fd18,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-2b117827-6c3e-46a9-8d32-d6596160e047,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-31b124c3-02d9-49b4-adcd-e7705a91ca04,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-52f10a77-430d-4024-ada8-b54137fa2639,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1970524719-172.17.0.20-1595495903899:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34943,DS-604309c5-280b-42ae-b2c7-d6eb7c33c31e,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-8ae3d399-b63c-4442-80b4-5d5e42026173,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-a7d7f557-68f5-4b9e-9e77-0a6b332e2a63,DISK], DatanodeInfoWithStorage[127.0.0.1:38241,DS-a2291719-f93f-4f12-b7da-c0dfc312a962,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-0d75be62-7561-4886-9c9f-bd201137fd18,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-2b117827-6c3e-46a9-8d32-d6596160e047,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-31b124c3-02d9-49b4-adcd-e7705a91ca04,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-52f10a77-430d-4024-ada8-b54137fa2639,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1892587896-172.17.0.20-1595496442275:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39316,DS-16fb7b1e-6971-4d51-9a2c-0eb63e4da115,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-c1ebb1fc-d047-4e6c-beab-14eae4225d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-ec389a6c-4762-443a-91a1-16f01a4be177,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-4c4b4c34-3fcc-49b5-bf19-42928a6ded60,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-b7052573-7003-4c66-b5eb-446d777eab2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-9460bc9f-86d7-4bb1-a108-fb5682fbd6de,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-f3690425-4cc9-4495-93de-cb881fe4d66b,DISK], DatanodeInfoWithStorage[127.0.0.1:46799,DS-45d3861a-357b-4172-9aae-37e9b190e754,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1892587896-172.17.0.20-1595496442275:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39316,DS-16fb7b1e-6971-4d51-9a2c-0eb63e4da115,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-c1ebb1fc-d047-4e6c-beab-14eae4225d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-ec389a6c-4762-443a-91a1-16f01a4be177,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-4c4b4c34-3fcc-49b5-bf19-42928a6ded60,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-b7052573-7003-4c66-b5eb-446d777eab2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-9460bc9f-86d7-4bb1-a108-fb5682fbd6de,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-f3690425-4cc9-4495-93de-cb881fe4d66b,DISK], DatanodeInfoWithStorage[127.0.0.1:46799,DS-45d3861a-357b-4172-9aae-37e9b190e754,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1362500093-172.17.0.20-1595496608233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43956,DS-8a0f10c3-0c11-450b-84df-a86213aaa1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-d62b4bbf-ec0a-46e2-9b90-1e2e9a6a6dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-94177fad-32fe-490a-878e-d2a007121cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-d4c5f0f2-902a-4f04-8562-c6f3b9f99984,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-b3681941-874c-418a-b364-9b457778cbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-c7b8de7d-fc3a-4363-aa0a-9e784dcd67b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-5759b956-a489-4dcb-9f32-72e8a050bacb,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-88ee17e2-f9ff-49a6-8c45-d844973b3ede,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1362500093-172.17.0.20-1595496608233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43956,DS-8a0f10c3-0c11-450b-84df-a86213aaa1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-d62b4bbf-ec0a-46e2-9b90-1e2e9a6a6dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-94177fad-32fe-490a-878e-d2a007121cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-d4c5f0f2-902a-4f04-8562-c6f3b9f99984,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-b3681941-874c-418a-b364-9b457778cbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-c7b8de7d-fc3a-4363-aa0a-9e784dcd67b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-5759b956-a489-4dcb-9f32-72e8a050bacb,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-88ee17e2-f9ff-49a6-8c45-d844973b3ede,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2007173316-172.17.0.20-1595496852058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41972,DS-160fe91f-bece-4bf8-aab4-55c0a6d27594,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-7d47f9d3-3a74-4108-9d6a-e6770d2c3c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-c36fba9f-e4a2-4d08-86a4-9496e00443ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-327ece83-3abe-45ea-bb07-a9ff9893a944,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-49b6ac84-85fd-4eaa-93fa-7bb2438615a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-aa8f2275-2692-47e0-be70-b30075fe13c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-66f7d603-64ca-48b7-9be9-ee973fece229,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-c7d13fc2-7f41-4e32-a0e7-282e58d37496,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2007173316-172.17.0.20-1595496852058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41972,DS-160fe91f-bece-4bf8-aab4-55c0a6d27594,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-7d47f9d3-3a74-4108-9d6a-e6770d2c3c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-c36fba9f-e4a2-4d08-86a4-9496e00443ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-327ece83-3abe-45ea-bb07-a9ff9893a944,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-49b6ac84-85fd-4eaa-93fa-7bb2438615a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-aa8f2275-2692-47e0-be70-b30075fe13c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-66f7d603-64ca-48b7-9be9-ee973fece229,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-c7d13fc2-7f41-4e32-a0e7-282e58d37496,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1952622628-172.17.0.20-1595496955820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34153,DS-b5b39d14-306d-4fd3-91e6-cee258902f08,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-03c4d805-f46c-417b-8db6-7a2fea7fbdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-ba706be6-30cf-4028-9fb2-d3a8496b201a,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-e5a9b2bd-eb5e-4e5e-80c7-09d177a1272b,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-6e2d728d-d0e1-4190-8e76-52b50ef3354d,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-ebd3a65b-f4ec-4e20-9a53-5f3561e65290,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-9b275444-6318-4a5a-a819-7b33f7e042e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-61289954-3b61-4d01-9e5e-1f4f96029f83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1952622628-172.17.0.20-1595496955820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34153,DS-b5b39d14-306d-4fd3-91e6-cee258902f08,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-03c4d805-f46c-417b-8db6-7a2fea7fbdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-ba706be6-30cf-4028-9fb2-d3a8496b201a,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-e5a9b2bd-eb5e-4e5e-80c7-09d177a1272b,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-6e2d728d-d0e1-4190-8e76-52b50ef3354d,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-ebd3a65b-f4ec-4e20-9a53-5f3561e65290,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-9b275444-6318-4a5a-a819-7b33f7e042e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-61289954-3b61-4d01-9e5e-1f4f96029f83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-761990570-172.17.0.20-1595497014183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46845,DS-76a3352a-5de5-4e0e-a5cf-a338cb41792e,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-3ad0f61b-c2a6-46e9-8217-068c1f19e035,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-f05f5ed6-a6fa-497f-a087-f38fc3e1deb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-4d5bd38f-6e1a-47ed-a43d-ab8ca861f918,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-7d3694f5-94ef-4cde-9aea-6bb7be3112ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39217,DS-8a36429f-ff5a-4dd3-9adc-78e82755be84,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-2c1a3110-bb7f-46a6-adc0-d9abd20a4778,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-cc9b4516-55a4-4491-be7e-2ef1028ffb61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-761990570-172.17.0.20-1595497014183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46845,DS-76a3352a-5de5-4e0e-a5cf-a338cb41792e,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-3ad0f61b-c2a6-46e9-8217-068c1f19e035,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-f05f5ed6-a6fa-497f-a087-f38fc3e1deb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-4d5bd38f-6e1a-47ed-a43d-ab8ca861f918,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-7d3694f5-94ef-4cde-9aea-6bb7be3112ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39217,DS-8a36429f-ff5a-4dd3-9adc-78e82755be84,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-2c1a3110-bb7f-46a6-adc0-d9abd20a4778,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-cc9b4516-55a4-4491-be7e-2ef1028ffb61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-272825737-172.17.0.20-1595497354923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34648,DS-bfd595d6-b1c3-4b7c-a733-013e26e4b837,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-80e5fa51-38fd-49c1-9539-27b5583c20ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-fbb768e4-e72f-497f-9bcf-888a13bae769,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-2cf7559b-2106-4cb5-84b8-674adae63ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-b80290a1-d7bf-454f-a476-4ac4aeec83d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-fcdb13a3-9e7e-4bf7-8485-0ee863ccc1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-d212574e-cbb6-47f8-a255-b8b938944bce,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-9372276c-b956-4709-9c9d-1000da7d3da7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-272825737-172.17.0.20-1595497354923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34648,DS-bfd595d6-b1c3-4b7c-a733-013e26e4b837,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-80e5fa51-38fd-49c1-9539-27b5583c20ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-fbb768e4-e72f-497f-9bcf-888a13bae769,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-2cf7559b-2106-4cb5-84b8-674adae63ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-b80290a1-d7bf-454f-a476-4ac4aeec83d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-fcdb13a3-9e7e-4bf7-8485-0ee863ccc1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-d212574e-cbb6-47f8-a255-b8b938944bce,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-9372276c-b956-4709-9c9d-1000da7d3da7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2014476818-172.17.0.20-1595497518217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40082,DS-4c0d4554-f5be-4bd2-a6d8-6c2d1c0e3de2,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-792c167c-2617-42a3-b055-eb79e6a3645b,DISK], DatanodeInfoWithStorage[127.0.0.1:40989,DS-e0278013-b193-434f-ae8a-801a1beb90cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-9cbb5a18-c575-45b7-a568-6912a9114fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-b2a3482b-6d03-41e7-b073-4c0a25237bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-7ffa2f0d-41f1-4926-bf0b-f566a745dc98,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-9985b693-4f92-4117-8449-cf5fe2ad1d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38165,DS-4e540da5-cdbc-4f58-b7db-6578e9bf2c1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2014476818-172.17.0.20-1595497518217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40082,DS-4c0d4554-f5be-4bd2-a6d8-6c2d1c0e3de2,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-792c167c-2617-42a3-b055-eb79e6a3645b,DISK], DatanodeInfoWithStorage[127.0.0.1:40989,DS-e0278013-b193-434f-ae8a-801a1beb90cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-9cbb5a18-c575-45b7-a568-6912a9114fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-b2a3482b-6d03-41e7-b073-4c0a25237bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-7ffa2f0d-41f1-4926-bf0b-f566a745dc98,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-9985b693-4f92-4117-8449-cf5fe2ad1d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38165,DS-4e540da5-cdbc-4f58-b7db-6578e9bf2c1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-694401064-172.17.0.20-1595497759566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41672,DS-09e87175-b80e-43a5-90a1-2b0a8395d50d,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-cda4f668-376e-40f8-aec9-dddbc8b7d743,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-d6c87864-643c-4b21-a95b-14d051a33c57,DISK], DatanodeInfoWithStorage[127.0.0.1:46416,DS-e31fcb95-71be-4488-a66b-9707de9f2a69,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-41dd8fa7-902e-4514-bd1e-6cae91391096,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-c5841dc7-68ab-4413-989b-53c87d3b88ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-da35213b-6c43-4f38-806a-a9d089ff7baf,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-9b744320-5df5-4fad-958f-e94723279b99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-694401064-172.17.0.20-1595497759566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41672,DS-09e87175-b80e-43a5-90a1-2b0a8395d50d,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-cda4f668-376e-40f8-aec9-dddbc8b7d743,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-d6c87864-643c-4b21-a95b-14d051a33c57,DISK], DatanodeInfoWithStorage[127.0.0.1:46416,DS-e31fcb95-71be-4488-a66b-9707de9f2a69,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-41dd8fa7-902e-4514-bd1e-6cae91391096,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-c5841dc7-68ab-4413-989b-53c87d3b88ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-da35213b-6c43-4f38-806a-a9d089ff7baf,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-9b744320-5df5-4fad-958f-e94723279b99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-781899482-172.17.0.20-1595497855052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42897,DS-f0e09e6b-2d86-4636-96c4-b390f91e84ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-2446147f-01cf-425e-80e6-a346e080c144,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-70a3bd99-13a0-443c-a110-fee92172343e,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-60888c98-e0ab-4d10-bfc8-d4e15c2b93eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-eb223dae-6309-4516-9cb4-764edd38d011,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-da21611c-dfb8-48d4-89e9-b8179d9ea4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-795f98c6-69ba-45f0-bbc9-a61e19d1a38e,DISK], DatanodeInfoWithStorage[127.0.0.1:43379,DS-84ffcc83-0921-424b-a616-066d03c9428e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-781899482-172.17.0.20-1595497855052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42897,DS-f0e09e6b-2d86-4636-96c4-b390f91e84ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-2446147f-01cf-425e-80e6-a346e080c144,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-70a3bd99-13a0-443c-a110-fee92172343e,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-60888c98-e0ab-4d10-bfc8-d4e15c2b93eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-eb223dae-6309-4516-9cb4-764edd38d011,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-da21611c-dfb8-48d4-89e9-b8179d9ea4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-795f98c6-69ba-45f0-bbc9-a61e19d1a38e,DISK], DatanodeInfoWithStorage[127.0.0.1:43379,DS-84ffcc83-0921-424b-a616-066d03c9428e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1844136632-172.17.0.20-1595498606957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41974,DS-f669906d-94af-4f8b-ac96-1c3e26f010b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-ee41d42a-a1ae-46b2-ba6c-2f22db56d231,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-9b9541d6-c79f-4557-8aed-11fee78788c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-c1f33a10-e809-4d8f-b969-6630b37e0e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-08d0a0c6-8426-4875-b2da-6726653d219a,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-64d13910-d6ac-4227-9636-76e82748c91f,DISK], DatanodeInfoWithStorage[127.0.0.1:45707,DS-99358005-3ff2-4c8d-ac71-229d49363f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44525,DS-97e83780-39dc-4230-ae12-fb64240192e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1844136632-172.17.0.20-1595498606957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41974,DS-f669906d-94af-4f8b-ac96-1c3e26f010b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-ee41d42a-a1ae-46b2-ba6c-2f22db56d231,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-9b9541d6-c79f-4557-8aed-11fee78788c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-c1f33a10-e809-4d8f-b969-6630b37e0e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-08d0a0c6-8426-4875-b2da-6726653d219a,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-64d13910-d6ac-4227-9636-76e82748c91f,DISK], DatanodeInfoWithStorage[127.0.0.1:45707,DS-99358005-3ff2-4c8d-ac71-229d49363f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44525,DS-97e83780-39dc-4230-ae12-fb64240192e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-324890502-172.17.0.20-1595498687595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41880,DS-0fc93b0a-381d-475c-a50f-0e9c8e4079c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-57fbdca6-12e2-4ce7-baf1-2f6b42472681,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-f9324bc1-484e-4599-bb98-2574907b2ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-bdecaeb8-3697-4471-a8af-479d287404ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-284f679e-d861-4467-9e35-c96779ab100d,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-501b0e73-095a-4371-b0de-580e5b49286f,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-4aa9976c-0090-42fe-b382-ce9deb847cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-e52d6c83-54f8-451c-b619-fae3fed226e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-324890502-172.17.0.20-1595498687595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41880,DS-0fc93b0a-381d-475c-a50f-0e9c8e4079c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-57fbdca6-12e2-4ce7-baf1-2f6b42472681,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-f9324bc1-484e-4599-bb98-2574907b2ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-bdecaeb8-3697-4471-a8af-479d287404ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-284f679e-d861-4467-9e35-c96779ab100d,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-501b0e73-095a-4371-b0de-580e5b49286f,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-4aa9976c-0090-42fe-b382-ce9deb847cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-e52d6c83-54f8-451c-b619-fae3fed226e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1325892557-172.17.0.20-1595498762762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46140,DS-99a073f0-a708-4ab0-97e6-cbc2fba7f7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-15aa6d90-a20a-4a1d-b233-6c537e73914b,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-8c300791-ab7d-493f-b854-8ee8bc4128f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-f67129b6-bfdd-4342-9f60-1af1be64e2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-f344c229-0f77-4910-87e7-170c83f35155,DISK], DatanodeInfoWithStorage[127.0.0.1:42391,DS-39060e27-7c62-4224-8ad0-0996a298e6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-92251788-3f59-40d0-ae15-dabb4ca9f536,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-a09b9da4-736a-4afa-9909-ca62c0770e55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1325892557-172.17.0.20-1595498762762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46140,DS-99a073f0-a708-4ab0-97e6-cbc2fba7f7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-15aa6d90-a20a-4a1d-b233-6c537e73914b,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-8c300791-ab7d-493f-b854-8ee8bc4128f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-f67129b6-bfdd-4342-9f60-1af1be64e2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-f344c229-0f77-4910-87e7-170c83f35155,DISK], DatanodeInfoWithStorage[127.0.0.1:42391,DS-39060e27-7c62-4224-8ad0-0996a298e6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-92251788-3f59-40d0-ae15-dabb4ca9f536,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-a09b9da4-736a-4afa-9909-ca62c0770e55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1261594011-172.17.0.20-1595499075008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36640,DS-bb10ffde-8741-4f0f-8f40-d7cc2794cc55,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-41441e1c-6d36-45da-9ca7-70af63b348dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-5d4ed269-58c4-4aba-8dbc-22b8b8d4d7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35379,DS-02e172ef-b326-4baf-ae31-f03649906187,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-04b6d045-f2f6-42fc-896e-801a2f20e8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-cd743951-9873-4ad7-ba70-128f753da2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-c0da563c-d724-4576-ba53-b66eb5161918,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-9a64c704-c3ed-40ae-a1b6-d6fa9ef20445,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1261594011-172.17.0.20-1595499075008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36640,DS-bb10ffde-8741-4f0f-8f40-d7cc2794cc55,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-41441e1c-6d36-45da-9ca7-70af63b348dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-5d4ed269-58c4-4aba-8dbc-22b8b8d4d7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35379,DS-02e172ef-b326-4baf-ae31-f03649906187,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-04b6d045-f2f6-42fc-896e-801a2f20e8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-cd743951-9873-4ad7-ba70-128f753da2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-c0da563c-d724-4576-ba53-b66eb5161918,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-9a64c704-c3ed-40ae-a1b6-d6fa9ef20445,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-237073332-172.17.0.20-1595499346524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44668,DS-eaae41c8-1081-435b-bfe1-a0f8571aeae5,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-c8af78ab-f8aa-47af-8e30-176430dc5c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42565,DS-87ebb0f3-5e23-4d25-99f1-cb33e9e4cfd9,DISK], DatanodeInfoWithStorage[127.0.0.1:45023,DS-5dcf653e-2a3e-428e-a23e-7c865f045f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38797,DS-f5db345d-bc45-4366-a050-785bc3151d96,DISK], DatanodeInfoWithStorage[127.0.0.1:44272,DS-c00f8ffb-ceb6-43fa-9d8f-4c91ebda1d88,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-2939a533-6894-48af-856e-7c816af2f8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-e8f6bb84-20e7-41fe-a31b-b17f56c17462,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-237073332-172.17.0.20-1595499346524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44668,DS-eaae41c8-1081-435b-bfe1-a0f8571aeae5,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-c8af78ab-f8aa-47af-8e30-176430dc5c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42565,DS-87ebb0f3-5e23-4d25-99f1-cb33e9e4cfd9,DISK], DatanodeInfoWithStorage[127.0.0.1:45023,DS-5dcf653e-2a3e-428e-a23e-7c865f045f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38797,DS-f5db345d-bc45-4366-a050-785bc3151d96,DISK], DatanodeInfoWithStorage[127.0.0.1:44272,DS-c00f8ffb-ceb6-43fa-9d8f-4c91ebda1d88,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-2939a533-6894-48af-856e-7c816af2f8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-e8f6bb84-20e7-41fe-a31b-b17f56c17462,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-316264501-172.17.0.20-1595499619734:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45013,DS-0cf46154-8613-4a0a-8a9c-d44bbeb5623d,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-29a684ff-808c-4565-be5b-33fedd410db5,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-2c9ff9d4-c76d-4a61-a779-1aafe84c70bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-4df82834-b823-41f8-843f-f57aa1e3a7de,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-ac22beea-8b1a-45b5-98e9-1021ee27555d,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-56b79259-b3c5-459f-9470-618fd5e2ce96,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-4811250d-d32b-4efa-8f4c-ab6d78dbf70e,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-fc4e959b-6741-4a53-9146-d4911d1022a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-316264501-172.17.0.20-1595499619734:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45013,DS-0cf46154-8613-4a0a-8a9c-d44bbeb5623d,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-29a684ff-808c-4565-be5b-33fedd410db5,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-2c9ff9d4-c76d-4a61-a779-1aafe84c70bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-4df82834-b823-41f8-843f-f57aa1e3a7de,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-ac22beea-8b1a-45b5-98e9-1021ee27555d,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-56b79259-b3c5-459f-9470-618fd5e2ce96,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-4811250d-d32b-4efa-8f4c-ab6d78dbf70e,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-fc4e959b-6741-4a53-9146-d4911d1022a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5475
