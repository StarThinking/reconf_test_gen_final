reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1887633250-172.17.0.16-1595810542076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45438,DS-98e41e3f-a39e-44ae-9744-2bc1dd554dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-67017743-1318-405b-bf76-34ed3fa4982e,DISK], DatanodeInfoWithStorage[127.0.0.1:42247,DS-5e30c476-c9a5-44e9-9204-25681c9092d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-065b3c7a-c4ca-46ee-aa9d-1f812b1b1b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-2597aba0-7eaa-492f-9069-0c387ff6795d,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-3efdb239-c6c6-4c93-9144-d61eb4e8969b,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-15b43815-686e-4a49-a6d6-fe3bb2a2fc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-2202654a-6966-4f0f-9e87-c8dccf4bd831,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1887633250-172.17.0.16-1595810542076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45438,DS-98e41e3f-a39e-44ae-9744-2bc1dd554dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-67017743-1318-405b-bf76-34ed3fa4982e,DISK], DatanodeInfoWithStorage[127.0.0.1:42247,DS-5e30c476-c9a5-44e9-9204-25681c9092d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-065b3c7a-c4ca-46ee-aa9d-1f812b1b1b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-2597aba0-7eaa-492f-9069-0c387ff6795d,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-3efdb239-c6c6-4c93-9144-d61eb4e8969b,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-15b43815-686e-4a49-a6d6-fe3bb2a2fc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-2202654a-6966-4f0f-9e87-c8dccf4bd831,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1683587892-172.17.0.16-1595810611821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40615,DS-8d9b35df-0c40-4114-8539-6c5283a24fef,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-be0c4c49-5377-419d-a791-eaa9c37ecfd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-16d19f54-c3b6-4bf5-99bc-5e5a42783568,DISK], DatanodeInfoWithStorage[127.0.0.1:38377,DS-0b3430be-0a13-4b67-b804-1aea57b360d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-bfe3b74f-d711-4f07-ab2f-aa6c0bda8a32,DISK], DatanodeInfoWithStorage[127.0.0.1:35167,DS-d93dd53b-a950-47e3-9761-2cdd6a9ce868,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-a62378da-a39e-43d4-9a39-829fc14a0ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-3b961c52-bdaa-431f-b8d7-bad9eba93286,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1683587892-172.17.0.16-1595810611821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40615,DS-8d9b35df-0c40-4114-8539-6c5283a24fef,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-be0c4c49-5377-419d-a791-eaa9c37ecfd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-16d19f54-c3b6-4bf5-99bc-5e5a42783568,DISK], DatanodeInfoWithStorage[127.0.0.1:38377,DS-0b3430be-0a13-4b67-b804-1aea57b360d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-bfe3b74f-d711-4f07-ab2f-aa6c0bda8a32,DISK], DatanodeInfoWithStorage[127.0.0.1:35167,DS-d93dd53b-a950-47e3-9761-2cdd6a9ce868,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-a62378da-a39e-43d4-9a39-829fc14a0ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-3b961c52-bdaa-431f-b8d7-bad9eba93286,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-172817063-172.17.0.16-1595810734142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38036,DS-912a0ca2-251f-45f8-8394-fec5fc3536ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42280,DS-a92f388d-bfb7-453f-8619-b7ece75e26f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37440,DS-9ddc8bb0-709d-43f6-b88b-cfa5dee64775,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-a4794905-ed8a-4bea-b436-4eb18a16e9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-441fc42a-3246-42a7-a135-855aacb84121,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-0f54be0e-bbf2-4c5b-b936-99238e5b04e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-b6b03c09-f238-49ff-b7e2-d2c6f452c60a,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-6753450b-8178-4820-8f80-d038a57b5cea,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-172817063-172.17.0.16-1595810734142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38036,DS-912a0ca2-251f-45f8-8394-fec5fc3536ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42280,DS-a92f388d-bfb7-453f-8619-b7ece75e26f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37440,DS-9ddc8bb0-709d-43f6-b88b-cfa5dee64775,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-a4794905-ed8a-4bea-b436-4eb18a16e9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-441fc42a-3246-42a7-a135-855aacb84121,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-0f54be0e-bbf2-4c5b-b936-99238e5b04e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-b6b03c09-f238-49ff-b7e2-d2c6f452c60a,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-6753450b-8178-4820-8f80-d038a57b5cea,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-358741389-172.17.0.16-1595811036010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41812,DS-4dc15b91-6161-4ce3-b102-0e450a36df4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39621,DS-d3747ab8-d235-4bc0-b5d3-c0f9e51ec0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-4d5657c7-00f6-4de7-b5b8-577ebb1a788e,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-62525b65-4ef9-43bf-926d-f71d0ed29c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-2bbf135d-586b-480d-bbd3-b67c0261de6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-d34476ca-66e4-4922-9847-03a56969d575,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-3ab33585-7f8a-4ac2-9b69-ac137203de17,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-386d9f92-524d-4a49-bcd4-5868891c6b05,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-358741389-172.17.0.16-1595811036010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41812,DS-4dc15b91-6161-4ce3-b102-0e450a36df4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39621,DS-d3747ab8-d235-4bc0-b5d3-c0f9e51ec0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-4d5657c7-00f6-4de7-b5b8-577ebb1a788e,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-62525b65-4ef9-43bf-926d-f71d0ed29c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-2bbf135d-586b-480d-bbd3-b67c0261de6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-d34476ca-66e4-4922-9847-03a56969d575,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-3ab33585-7f8a-4ac2-9b69-ac137203de17,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-386d9f92-524d-4a49-bcd4-5868891c6b05,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-636974212-172.17.0.16-1595811101715:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36911,DS-2df15075-ea6c-4e2f-8a66-75ec44d4ef2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-edf1d9e1-1180-4152-a584-f35e02639410,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-a3349622-07df-4e03-98fb-8a34e8d001ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-3f84f12e-c94d-47bb-b4b2-e77e8f6623cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-6236e529-5a28-4db7-a2e2-66754e46ada6,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-18459750-094a-49fb-b83d-a2dfb12acd29,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-ee3a5992-2b05-47c7-bc7a-be0d49534383,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-b4c744f6-a6f4-49fb-9efb-eead40f7ca16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-636974212-172.17.0.16-1595811101715:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36911,DS-2df15075-ea6c-4e2f-8a66-75ec44d4ef2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-edf1d9e1-1180-4152-a584-f35e02639410,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-a3349622-07df-4e03-98fb-8a34e8d001ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-3f84f12e-c94d-47bb-b4b2-e77e8f6623cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-6236e529-5a28-4db7-a2e2-66754e46ada6,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-18459750-094a-49fb-b83d-a2dfb12acd29,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-ee3a5992-2b05-47c7-bc7a-be0d49534383,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-b4c744f6-a6f4-49fb-9efb-eead40f7ca16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-416370201-172.17.0.16-1595811172164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35754,DS-0cbb0677-878f-49b9-a488-edc4ef1b573a,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-2cd0943f-f09e-4c36-9a6f-e69ba48574bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-033c5bfd-ab95-4e4b-8ab0-6ce9eaf2edcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-c87cc6b8-877f-4aac-b68e-4b74db372a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-9084b506-cc8c-4234-90b2-fc0d2cb29f76,DISK], DatanodeInfoWithStorage[127.0.0.1:44376,DS-9acfcc97-6a71-4f77-aa2e-00d9081183f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37673,DS-fa86f464-a317-4e52-8205-47732bb6f9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40506,DS-8edbe7cb-c7de-4a2e-bd09-e9eabf60b526,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-416370201-172.17.0.16-1595811172164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35754,DS-0cbb0677-878f-49b9-a488-edc4ef1b573a,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-2cd0943f-f09e-4c36-9a6f-e69ba48574bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-033c5bfd-ab95-4e4b-8ab0-6ce9eaf2edcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-c87cc6b8-877f-4aac-b68e-4b74db372a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-9084b506-cc8c-4234-90b2-fc0d2cb29f76,DISK], DatanodeInfoWithStorage[127.0.0.1:44376,DS-9acfcc97-6a71-4f77-aa2e-00d9081183f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37673,DS-fa86f464-a317-4e52-8205-47732bb6f9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40506,DS-8edbe7cb-c7de-4a2e-bd09-e9eabf60b526,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-119350601-172.17.0.16-1595811386523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35834,DS-9ba78748-b0aa-4979-9cb6-4694eb7688b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-83f36b6a-728b-4eee-848a-0c18d16358ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-ab573113-3a8b-448a-829f-39f661e32780,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-5028ef4a-47a6-4628-b7d8-49a6c82a504b,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-b8ed9a80-6fc4-463c-b354-369ed5a87112,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-e48b5227-8775-4e9c-8711-e53cd4b393eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34329,DS-6bbb3d4e-3e00-4d27-8b8b-7f6da69685a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-5bbc5189-87a7-410b-85c6-a5792bda411b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-119350601-172.17.0.16-1595811386523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35834,DS-9ba78748-b0aa-4979-9cb6-4694eb7688b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-83f36b6a-728b-4eee-848a-0c18d16358ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-ab573113-3a8b-448a-829f-39f661e32780,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-5028ef4a-47a6-4628-b7d8-49a6c82a504b,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-b8ed9a80-6fc4-463c-b354-369ed5a87112,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-e48b5227-8775-4e9c-8711-e53cd4b393eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34329,DS-6bbb3d4e-3e00-4d27-8b8b-7f6da69685a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-5bbc5189-87a7-410b-85c6-a5792bda411b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-81220581-172.17.0.16-1595811673849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44802,DS-ec5b58fc-4ccf-487b-93c4-38994b70d326,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-c332af52-7702-48b9-b4ae-73667c349123,DISK], DatanodeInfoWithStorage[127.0.0.1:37862,DS-564a1e18-9754-4ce0-b2d9-cef895cd0630,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-1cd1915a-d101-4ce4-a4e0-57cca9d5b986,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-ea92a68a-66e3-49a9-bf13-26f3347d4ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-71161948-45b6-4660-99e8-df4a31881bea,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-54a044e6-c559-40ec-bdff-1e726fc1bffa,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-51e1bd25-f053-47a9-adf6-9754577d9817,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-81220581-172.17.0.16-1595811673849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44802,DS-ec5b58fc-4ccf-487b-93c4-38994b70d326,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-c332af52-7702-48b9-b4ae-73667c349123,DISK], DatanodeInfoWithStorage[127.0.0.1:37862,DS-564a1e18-9754-4ce0-b2d9-cef895cd0630,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-1cd1915a-d101-4ce4-a4e0-57cca9d5b986,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-ea92a68a-66e3-49a9-bf13-26f3347d4ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-71161948-45b6-4660-99e8-df4a31881bea,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-54a044e6-c559-40ec-bdff-1e726fc1bffa,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-51e1bd25-f053-47a9-adf6-9754577d9817,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1585903515-172.17.0.16-1595812101127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45075,DS-fb8405e5-76ac-4bce-b5f4-abdb5c741e05,DISK], DatanodeInfoWithStorage[127.0.0.1:44155,DS-9aefbbdb-9be2-483d-b71f-f3a55818f0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-71963482-2668-4fd7-96d4-4bd783c470bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39541,DS-8de139ff-998e-4c28-aa11-3bc4ea8f0ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-0df5b19a-8e35-488a-b69b-f7c17607d464,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-363fa4b3-b37c-485b-97a1-3ea4bb3e1297,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-a3acae17-16fd-4af7-8684-b0fcd0724445,DISK], DatanodeInfoWithStorage[127.0.0.1:37729,DS-ae8c3e76-f3da-4206-aaab-e2489edf191c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1585903515-172.17.0.16-1595812101127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45075,DS-fb8405e5-76ac-4bce-b5f4-abdb5c741e05,DISK], DatanodeInfoWithStorage[127.0.0.1:44155,DS-9aefbbdb-9be2-483d-b71f-f3a55818f0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-71963482-2668-4fd7-96d4-4bd783c470bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39541,DS-8de139ff-998e-4c28-aa11-3bc4ea8f0ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-0df5b19a-8e35-488a-b69b-f7c17607d464,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-363fa4b3-b37c-485b-97a1-3ea4bb3e1297,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-a3acae17-16fd-4af7-8684-b0fcd0724445,DISK], DatanodeInfoWithStorage[127.0.0.1:37729,DS-ae8c3e76-f3da-4206-aaab-e2489edf191c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1529692908-172.17.0.16-1595812522573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36464,DS-e15d3e61-59f2-4c22-b766-b634687aa49b,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-bc3deed5-3da9-4722-8b55-007c95b7e601,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-4367b490-53cf-421f-84a8-eed9bf43ce78,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-525ca5ef-bb81-4c67-bfab-e0ff7f416f13,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-7717cc7e-07ed-4387-968f-311557bb56fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-1685c21b-52da-48ed-9b0d-4d9405ac46e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35777,DS-786a1339-6290-48ad-adc8-4fb9fd705e28,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-5b65a4e3-66e7-43cc-8c66-1ac6bac851ef,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1529692908-172.17.0.16-1595812522573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36464,DS-e15d3e61-59f2-4c22-b766-b634687aa49b,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-bc3deed5-3da9-4722-8b55-007c95b7e601,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-4367b490-53cf-421f-84a8-eed9bf43ce78,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-525ca5ef-bb81-4c67-bfab-e0ff7f416f13,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-7717cc7e-07ed-4387-968f-311557bb56fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-1685c21b-52da-48ed-9b0d-4d9405ac46e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35777,DS-786a1339-6290-48ad-adc8-4fb9fd705e28,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-5b65a4e3-66e7-43cc-8c66-1ac6bac851ef,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2118818892-172.17.0.16-1595812769807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38088,DS-5703eb63-f956-48ed-9b5f-2e8bde7256f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-b5aa0537-ccaa-4836-b108-879419ad2b70,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-3a455b47-24a6-48c4-85e9-8e5967d7fd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-30b73b22-1a78-44e4-a986-fa0272415aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-abf48acb-789c-4b85-ac06-45bb04664138,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-45c64b0d-0cc7-49b6-9af2-fb7cf9cfa01e,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-7e59221f-8e53-4a5c-8cec-855481c17745,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-2424dc70-731d-4108-bd65-d3239475a61b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2118818892-172.17.0.16-1595812769807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38088,DS-5703eb63-f956-48ed-9b5f-2e8bde7256f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-b5aa0537-ccaa-4836-b108-879419ad2b70,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-3a455b47-24a6-48c4-85e9-8e5967d7fd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-30b73b22-1a78-44e4-a986-fa0272415aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-abf48acb-789c-4b85-ac06-45bb04664138,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-45c64b0d-0cc7-49b6-9af2-fb7cf9cfa01e,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-7e59221f-8e53-4a5c-8cec-855481c17745,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-2424dc70-731d-4108-bd65-d3239475a61b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-395712531-172.17.0.16-1595812956016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46209,DS-392171e9-c7cd-4dd7-97b3-7d2892f0368f,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-1c3fcea7-33e6-41f2-a4e8-da97ee33e2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43183,DS-6fcecdb7-5c33-4a2d-905c-2e0193d60289,DISK], DatanodeInfoWithStorage[127.0.0.1:46405,DS-8c43aaa9-3226-44e4-9439-dc0b3aba6dee,DISK], DatanodeInfoWithStorage[127.0.0.1:46395,DS-9382a231-37b2-43a7-97bf-5d68434861f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-4d265012-8524-4226-9bfb-7db9a2201c62,DISK], DatanodeInfoWithStorage[127.0.0.1:44643,DS-5db283de-870b-4c94-958d-b37504350703,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-f4557346-26f1-4b73-9164-9545f2b46933,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-395712531-172.17.0.16-1595812956016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46209,DS-392171e9-c7cd-4dd7-97b3-7d2892f0368f,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-1c3fcea7-33e6-41f2-a4e8-da97ee33e2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43183,DS-6fcecdb7-5c33-4a2d-905c-2e0193d60289,DISK], DatanodeInfoWithStorage[127.0.0.1:46405,DS-8c43aaa9-3226-44e4-9439-dc0b3aba6dee,DISK], DatanodeInfoWithStorage[127.0.0.1:46395,DS-9382a231-37b2-43a7-97bf-5d68434861f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-4d265012-8524-4226-9bfb-7db9a2201c62,DISK], DatanodeInfoWithStorage[127.0.0.1:44643,DS-5db283de-870b-4c94-958d-b37504350703,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-f4557346-26f1-4b73-9164-9545f2b46933,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-567646409-172.17.0.16-1595813020352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37488,DS-4389fe3e-cd5a-4b87-9e95-844e5d34cd48,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-567e1883-a451-484e-86d9-0feb71b502fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-f65685e8-2f9b-4a1b-8e3c-1071cb628477,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-d3c76b88-22e9-4581-bff2-57c18c98c84d,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-3efe8c8b-2c77-4b14-b191-1b43cc1ce885,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-e0746e4d-33f8-46d4-8f35-215b10fb147c,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-e1fa9f3f-8182-4ba4-888f-8e07ce3546df,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-ff2bd00a-17b8-4358-b2d6-cdac38998e98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-567646409-172.17.0.16-1595813020352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37488,DS-4389fe3e-cd5a-4b87-9e95-844e5d34cd48,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-567e1883-a451-484e-86d9-0feb71b502fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-f65685e8-2f9b-4a1b-8e3c-1071cb628477,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-d3c76b88-22e9-4581-bff2-57c18c98c84d,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-3efe8c8b-2c77-4b14-b191-1b43cc1ce885,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-e0746e4d-33f8-46d4-8f35-215b10fb147c,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-e1fa9f3f-8182-4ba4-888f-8e07ce3546df,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-ff2bd00a-17b8-4358-b2d6-cdac38998e98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1076901577-172.17.0.16-1595813129230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38271,DS-c98365af-56d5-4f32-9ea7-c61de76c71dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-66ede7c0-c5eb-4522-a422-6f01869aa319,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-e9f6c90a-1fa7-4dc5-af98-d2c2f26c2e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-80129fbe-17d0-4815-904d-d5c997bf6414,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-8eef10aa-ad0a-4c88-82ae-8366c46b72b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-f2edbc8b-acf5-410f-a728-29e6bba0d0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-0bd8df13-576f-4535-a2a1-165335e1e405,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-fc3a835e-756d-4650-8083-c79fd85bdc7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1076901577-172.17.0.16-1595813129230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38271,DS-c98365af-56d5-4f32-9ea7-c61de76c71dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-66ede7c0-c5eb-4522-a422-6f01869aa319,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-e9f6c90a-1fa7-4dc5-af98-d2c2f26c2e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-80129fbe-17d0-4815-904d-d5c997bf6414,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-8eef10aa-ad0a-4c88-82ae-8366c46b72b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-f2edbc8b-acf5-410f-a728-29e6bba0d0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-0bd8df13-576f-4535-a2a1-165335e1e405,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-fc3a835e-756d-4650-8083-c79fd85bdc7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-740091504-172.17.0.16-1595813274038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33122,DS-356dbc7f-c3e0-403b-ad09-e420a0cb6037,DISK], DatanodeInfoWithStorage[127.0.0.1:39839,DS-46d9c947-fd88-4820-9187-a84a132b197d,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-e4790979-6070-46d1-ba98-8cc7c10bf219,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-45d5ad67-56f3-4a44-97df-c174fefae940,DISK], DatanodeInfoWithStorage[127.0.0.1:36501,DS-19b30765-cf65-4c6b-ac44-a168c9880ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-424a24e3-e5e1-4309-a9eb-0bb38714763d,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-291a47be-d4af-43ea-b5c4-89f184a77426,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-f56b0201-273a-4e41-bfbd-2ee4d82e3ddc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-740091504-172.17.0.16-1595813274038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33122,DS-356dbc7f-c3e0-403b-ad09-e420a0cb6037,DISK], DatanodeInfoWithStorage[127.0.0.1:39839,DS-46d9c947-fd88-4820-9187-a84a132b197d,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-e4790979-6070-46d1-ba98-8cc7c10bf219,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-45d5ad67-56f3-4a44-97df-c174fefae940,DISK], DatanodeInfoWithStorage[127.0.0.1:36501,DS-19b30765-cf65-4c6b-ac44-a168c9880ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-424a24e3-e5e1-4309-a9eb-0bb38714763d,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-291a47be-d4af-43ea-b5c4-89f184a77426,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-f56b0201-273a-4e41-bfbd-2ee4d82e3ddc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1819636667-172.17.0.16-1595813493647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42716,DS-c29316c7-a53e-46ff-963c-47f8fe86fe43,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-ebcbbfb2-81b9-48bb-8e15-fd898798db89,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-3054d349-2d94-4136-8c8b-5b8c4705c746,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-f44229ae-f644-4f5f-99f8-6ad4cadbd317,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-317156a1-1c02-4de0-8aa4-bf38ff0711c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-5db70c3b-191f-469d-80fe-bc95b47f69a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-7328fbc8-685c-42bf-8081-7b3059bea8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34928,DS-b26405b5-de0a-43f8-b70e-c777b326b52d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1819636667-172.17.0.16-1595813493647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42716,DS-c29316c7-a53e-46ff-963c-47f8fe86fe43,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-ebcbbfb2-81b9-48bb-8e15-fd898798db89,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-3054d349-2d94-4136-8c8b-5b8c4705c746,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-f44229ae-f644-4f5f-99f8-6ad4cadbd317,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-317156a1-1c02-4de0-8aa4-bf38ff0711c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-5db70c3b-191f-469d-80fe-bc95b47f69a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-7328fbc8-685c-42bf-8081-7b3059bea8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34928,DS-b26405b5-de0a-43f8-b70e-c777b326b52d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-171874158-172.17.0.16-1595814010916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39329,DS-464a3ef5-6efa-4f72-8549-54273b9f817f,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-2a71e66b-926f-4370-b35b-565c3ef66834,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-399931bf-26fe-40bf-8b26-5eb44c89adef,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-f9e77ed1-c670-462b-bb47-13f1648bfc71,DISK], DatanodeInfoWithStorage[127.0.0.1:46807,DS-7067c190-2ca1-4e24-bdfe-e8e26ff7e915,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-12e6d07d-0395-4f6a-bd86-6d65dcbee270,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-a327a4bc-ca1e-4c88-8580-c809e8ad6f25,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-bd3d283f-fa20-480b-8193-5521be8d085b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-171874158-172.17.0.16-1595814010916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39329,DS-464a3ef5-6efa-4f72-8549-54273b9f817f,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-2a71e66b-926f-4370-b35b-565c3ef66834,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-399931bf-26fe-40bf-8b26-5eb44c89adef,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-f9e77ed1-c670-462b-bb47-13f1648bfc71,DISK], DatanodeInfoWithStorage[127.0.0.1:46807,DS-7067c190-2ca1-4e24-bdfe-e8e26ff7e915,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-12e6d07d-0395-4f6a-bd86-6d65dcbee270,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-a327a4bc-ca1e-4c88-8580-c809e8ad6f25,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-bd3d283f-fa20-480b-8193-5521be8d085b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-345536904-172.17.0.16-1595814153160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40038,DS-a8e9c279-c908-4653-96f1-2ff68784694e,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-73273f0b-2b1f-4f45-8845-c8f2d541ebed,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-2a2f3e15-7401-4d85-bc45-173491ad37fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39844,DS-a06a41c4-8da7-4775-b6a5-b5ca758ef331,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-8bac8e2b-ab87-4700-8cc0-34e089731345,DISK], DatanodeInfoWithStorage[127.0.0.1:38630,DS-b886f8cb-a1d1-4b6a-98f3-29bf09899355,DISK], DatanodeInfoWithStorage[127.0.0.1:39221,DS-d89d3d30-a030-4d2d-8305-864eced0040f,DISK], DatanodeInfoWithStorage[127.0.0.1:37951,DS-8791d250-ea1d-4e51-961e-43219db584c2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-345536904-172.17.0.16-1595814153160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40038,DS-a8e9c279-c908-4653-96f1-2ff68784694e,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-73273f0b-2b1f-4f45-8845-c8f2d541ebed,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-2a2f3e15-7401-4d85-bc45-173491ad37fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39844,DS-a06a41c4-8da7-4775-b6a5-b5ca758ef331,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-8bac8e2b-ab87-4700-8cc0-34e089731345,DISK], DatanodeInfoWithStorage[127.0.0.1:38630,DS-b886f8cb-a1d1-4b6a-98f3-29bf09899355,DISK], DatanodeInfoWithStorage[127.0.0.1:39221,DS-d89d3d30-a030-4d2d-8305-864eced0040f,DISK], DatanodeInfoWithStorage[127.0.0.1:37951,DS-8791d250-ea1d-4e51-961e-43219db584c2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1911556381-172.17.0.16-1595814187866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44767,DS-e2be5166-612d-47fe-b598-563bb27adeea,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-9affdc96-9e75-4c0c-8efa-18e0c4794c09,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-b3a35fd5-485e-4c0d-87bf-59fafca834f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-99b830aa-9036-42b5-9022-0f4b1ce25a43,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-a6fb9e0b-4175-4f15-b015-879413370b27,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-24c56ad2-3ebc-4de7-9e80-68a3cb34f24c,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-519cddd9-c926-401b-8ac2-0b084cecfe73,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-663f2a37-9c70-48c9-b754-5c8b4ea2dc86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1911556381-172.17.0.16-1595814187866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44767,DS-e2be5166-612d-47fe-b598-563bb27adeea,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-9affdc96-9e75-4c0c-8efa-18e0c4794c09,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-b3a35fd5-485e-4c0d-87bf-59fafca834f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-99b830aa-9036-42b5-9022-0f4b1ce25a43,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-a6fb9e0b-4175-4f15-b015-879413370b27,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-24c56ad2-3ebc-4de7-9e80-68a3cb34f24c,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-519cddd9-c926-401b-8ac2-0b084cecfe73,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-663f2a37-9c70-48c9-b754-5c8b4ea2dc86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1641289105-172.17.0.16-1595814673949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40722,DS-9644f58d-e424-48ce-be1d-e2c9035d8c35,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-2fe7b470-bce5-46e4-bb1b-1501a44c2a42,DISK], DatanodeInfoWithStorage[127.0.0.1:45617,DS-b61cd8e3-d67c-4ca8-8506-01e9e0b00ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-6761b952-34f7-48d2-b536-1ff7a3c55199,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-5b5e854a-9ab0-4849-8dc8-735b99c4df9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-1279a4f1-0f11-4ff3-a34f-6eca6bff641b,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-b6c8706d-2949-4898-9212-bdc4ba45252e,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-0e5bed98-987d-41ef-98de-bed2c61cda43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1641289105-172.17.0.16-1595814673949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40722,DS-9644f58d-e424-48ce-be1d-e2c9035d8c35,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-2fe7b470-bce5-46e4-bb1b-1501a44c2a42,DISK], DatanodeInfoWithStorage[127.0.0.1:45617,DS-b61cd8e3-d67c-4ca8-8506-01e9e0b00ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-6761b952-34f7-48d2-b536-1ff7a3c55199,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-5b5e854a-9ab0-4849-8dc8-735b99c4df9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-1279a4f1-0f11-4ff3-a34f-6eca6bff641b,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-b6c8706d-2949-4898-9212-bdc4ba45252e,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-0e5bed98-987d-41ef-98de-bed2c61cda43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-158480393-172.17.0.16-1595815242542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46821,DS-f4dee182-57de-4ee6-9156-e2abb3948560,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-2b6df269-9ef4-4602-9ca8-c6e810463b80,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-b04b9046-1c42-4998-9543-5560bf2b395b,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-81736ad6-dad5-47e2-a9c7-e59b5e2ba6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-766b32cc-b968-4733-8ffc-e2e3527077f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-41cffbe1-406c-41d2-b0d1-faeccb906b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-1d601cd4-855d-4252-a648-a7b50cba6e40,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-0985c4e2-da50-4da2-b351-f924bb012b96,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-158480393-172.17.0.16-1595815242542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46821,DS-f4dee182-57de-4ee6-9156-e2abb3948560,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-2b6df269-9ef4-4602-9ca8-c6e810463b80,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-b04b9046-1c42-4998-9543-5560bf2b395b,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-81736ad6-dad5-47e2-a9c7-e59b5e2ba6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-766b32cc-b968-4733-8ffc-e2e3527077f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-41cffbe1-406c-41d2-b0d1-faeccb906b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-1d601cd4-855d-4252-a648-a7b50cba6e40,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-0985c4e2-da50-4da2-b351-f924bb012b96,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1783206175-172.17.0.16-1595815424787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34765,DS-e8f32862-57a2-4d4f-bd9c-0998ddee3bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-52bc146f-6617-4bcd-bdc5-7a644d9048fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-fd241a21-6ab6-4c4d-a634-dd7919bde556,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-f75f9dca-fb12-4e01-9f43-6ca966acdd53,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-73075231-1230-4c43-bbeb-0add61ebbc4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-27004fa1-40bc-4b16-a843-2feb3c8fcd9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-42b35226-ed8f-4261-a43c-0b449bb18eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-3656a683-4f5b-4279-a00c-afaa365ef90f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1783206175-172.17.0.16-1595815424787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34765,DS-e8f32862-57a2-4d4f-bd9c-0998ddee3bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-52bc146f-6617-4bcd-bdc5-7a644d9048fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-fd241a21-6ab6-4c4d-a634-dd7919bde556,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-f75f9dca-fb12-4e01-9f43-6ca966acdd53,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-73075231-1230-4c43-bbeb-0add61ebbc4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-27004fa1-40bc-4b16-a843-2feb3c8fcd9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-42b35226-ed8f-4261-a43c-0b449bb18eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-3656a683-4f5b-4279-a00c-afaa365ef90f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-580700069-172.17.0.16-1595815655561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42555,DS-3beb9b96-9638-4782-a0e8-df852d3a7d55,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-83952639-5b72-4212-ba65-57b8874bde14,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-0e7fe83e-fdec-4e5d-87fc-6510ed53ee12,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-7cae4f23-b207-486c-8ab4-9e05a2067adb,DISK], DatanodeInfoWithStorage[127.0.0.1:37146,DS-11f06a9b-c458-48e1-817f-c82a5b45847c,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-2b2e8841-e25d-4838-90b1-007b20942ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-6589ad55-71fd-475b-9706-a0441c904e58,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-5942b767-ca6b-46f8-ab67-06928098f42e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-580700069-172.17.0.16-1595815655561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42555,DS-3beb9b96-9638-4782-a0e8-df852d3a7d55,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-83952639-5b72-4212-ba65-57b8874bde14,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-0e7fe83e-fdec-4e5d-87fc-6510ed53ee12,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-7cae4f23-b207-486c-8ab4-9e05a2067adb,DISK], DatanodeInfoWithStorage[127.0.0.1:37146,DS-11f06a9b-c458-48e1-817f-c82a5b45847c,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-2b2e8841-e25d-4838-90b1-007b20942ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-6589ad55-71fd-475b-9706-a0441c904e58,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-5942b767-ca6b-46f8-ab67-06928098f42e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1749959220-172.17.0.16-1595815769626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45295,DS-14b6d56b-745e-43d1-834f-f1f3fa89b894,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-a43b4592-92f4-4da2-8d76-81ff9fdbcf04,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-3699a198-c7ae-47dc-934a-a082e17a5fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-353dbfbb-446e-45b2-a6cd-2debd7bcd59f,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-c633d93f-f122-4fed-95e7-e9e33fd2ac9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-9a636cd1-a7ab-4c5e-95ea-e886edada8de,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-ee7a13bd-8cfd-44ee-a9cb-781b5e9c4d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-10aa32c9-eb5b-4836-81f6-968a8fdb8702,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1749959220-172.17.0.16-1595815769626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45295,DS-14b6d56b-745e-43d1-834f-f1f3fa89b894,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-a43b4592-92f4-4da2-8d76-81ff9fdbcf04,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-3699a198-c7ae-47dc-934a-a082e17a5fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-353dbfbb-446e-45b2-a6cd-2debd7bcd59f,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-c633d93f-f122-4fed-95e7-e9e33fd2ac9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-9a636cd1-a7ab-4c5e-95ea-e886edada8de,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-ee7a13bd-8cfd-44ee-a9cb-781b5e9c4d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-10aa32c9-eb5b-4836-81f6-968a8fdb8702,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5383
