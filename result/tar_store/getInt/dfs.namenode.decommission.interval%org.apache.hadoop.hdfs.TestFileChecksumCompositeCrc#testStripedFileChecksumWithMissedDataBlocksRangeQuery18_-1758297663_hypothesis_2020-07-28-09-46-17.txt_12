reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2140185006-172.17.0.4-1595929591906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42406,DS-37ba1e02-2f9e-4af0-a5e3-eb81343d13a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-cabb10af-d70a-4574-ae56-35ec9a18c67e,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-e0404649-b8c2-4120-8bdd-ad6c7db29b96,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-b23ee4b3-56d6-439a-bf36-7a94c39d28e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33697,DS-663b2304-154a-4ceb-a233-3acca08a157e,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-0a143c11-9859-415c-973e-4852158987a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34467,DS-6cab948c-e05f-4d63-8d1e-bf1c5d974934,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-396a6cc6-d5a7-448e-97dd-d12860612c24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2140185006-172.17.0.4-1595929591906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42406,DS-37ba1e02-2f9e-4af0-a5e3-eb81343d13a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-cabb10af-d70a-4574-ae56-35ec9a18c67e,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-e0404649-b8c2-4120-8bdd-ad6c7db29b96,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-b23ee4b3-56d6-439a-bf36-7a94c39d28e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33697,DS-663b2304-154a-4ceb-a233-3acca08a157e,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-0a143c11-9859-415c-973e-4852158987a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34467,DS-6cab948c-e05f-4d63-8d1e-bf1c5d974934,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-396a6cc6-d5a7-448e-97dd-d12860612c24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-296957729-172.17.0.4-1595930099221:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45537,DS-248eb7be-b525-48af-b1a5-069c0ec82f81,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-67132507-3127-4666-8472-2034afe1e2de,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-80312041-c3f3-4464-bae4-b381cf471fec,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-ca67fd48-28dd-45de-85c8-1a1d7ceb23a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-2ae7856c-e44e-4ccf-9322-6b3d111c5aca,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-01427785-729a-4688-a8c1-653ac75b388a,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-640c3583-ab9c-49f9-8a3d-7417ec53d593,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-f9431bbd-7c7f-44bb-8669-bd20e273064f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-296957729-172.17.0.4-1595930099221:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45537,DS-248eb7be-b525-48af-b1a5-069c0ec82f81,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-67132507-3127-4666-8472-2034afe1e2de,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-80312041-c3f3-4464-bae4-b381cf471fec,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-ca67fd48-28dd-45de-85c8-1a1d7ceb23a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-2ae7856c-e44e-4ccf-9322-6b3d111c5aca,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-01427785-729a-4688-a8c1-653ac75b388a,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-640c3583-ab9c-49f9-8a3d-7417ec53d593,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-f9431bbd-7c7f-44bb-8669-bd20e273064f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1347323796-172.17.0.4-1595930484997:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44084,DS-166cebba-e745-437a-bd45-2b133ef341eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40719,DS-1afdf513-5a22-4359-9653-b346f28a2cce,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-9f7a64fd-5a9b-40c4-a237-02c6ccfebcde,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-a8db78a6-2b7d-488e-a56d-54fd31b2dc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-84376a3e-15ed-48b0-a73d-c5b44204cdf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-5aebfac4-c54e-4ed0-a1a5-b110dde4e65f,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-97a77793-ebf1-43f5-9966-0033ab7aa06b,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-3bdcd60f-6523-42f9-981d-3330a2a0ea29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1347323796-172.17.0.4-1595930484997:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44084,DS-166cebba-e745-437a-bd45-2b133ef341eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40719,DS-1afdf513-5a22-4359-9653-b346f28a2cce,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-9f7a64fd-5a9b-40c4-a237-02c6ccfebcde,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-a8db78a6-2b7d-488e-a56d-54fd31b2dc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-84376a3e-15ed-48b0-a73d-c5b44204cdf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-5aebfac4-c54e-4ed0-a1a5-b110dde4e65f,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-97a77793-ebf1-43f5-9966-0033ab7aa06b,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-3bdcd60f-6523-42f9-981d-3330a2a0ea29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-193921712-172.17.0.4-1595930576803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45073,DS-d09052a7-ee56-4ba1-a6cc-47ca55efd823,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-c6d2fa60-c3f0-4cd2-879b-3e4fe249ffd5,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-f89f620c-8ed8-4f26-95fa-b3ea4cd5f485,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-dce756e0-2112-4926-9b5a-91a1b9e4cacd,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-4bac543c-820d-484b-9bfd-5dd1f11cb5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41055,DS-1ff80aaa-b0b1-46a3-ae01-6e8a49790424,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-769b03f4-b6df-483e-950c-9f0bffb054db,DISK], DatanodeInfoWithStorage[127.0.0.1:36454,DS-a3fc5d34-005a-4a63-8568-8fc30c1f6a89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-193921712-172.17.0.4-1595930576803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45073,DS-d09052a7-ee56-4ba1-a6cc-47ca55efd823,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-c6d2fa60-c3f0-4cd2-879b-3e4fe249ffd5,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-f89f620c-8ed8-4f26-95fa-b3ea4cd5f485,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-dce756e0-2112-4926-9b5a-91a1b9e4cacd,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-4bac543c-820d-484b-9bfd-5dd1f11cb5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41055,DS-1ff80aaa-b0b1-46a3-ae01-6e8a49790424,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-769b03f4-b6df-483e-950c-9f0bffb054db,DISK], DatanodeInfoWithStorage[127.0.0.1:36454,DS-a3fc5d34-005a-4a63-8568-8fc30c1f6a89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1907525439-172.17.0.4-1595930713941:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43636,DS-7ae633a2-8ae0-4cdf-99b7-fe533e8d4ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-12bafb48-23ed-4f58-89df-219735d08aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-1055ab1d-cd7e-45f9-bea8-83985169204a,DISK], DatanodeInfoWithStorage[127.0.0.1:37132,DS-bedf3b6d-9c1d-483f-abd9-dcb79009c7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-65758aee-a4e4-4f95-b517-4b936da0b134,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-63886217-ef56-4e1f-83d6-e63e32fe06ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35530,DS-d16419d0-6c90-4949-a3b8-6a795d6caf17,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-ea63d2ae-bb0a-411d-ade1-9290e998ca10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1907525439-172.17.0.4-1595930713941:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43636,DS-7ae633a2-8ae0-4cdf-99b7-fe533e8d4ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-12bafb48-23ed-4f58-89df-219735d08aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-1055ab1d-cd7e-45f9-bea8-83985169204a,DISK], DatanodeInfoWithStorage[127.0.0.1:37132,DS-bedf3b6d-9c1d-483f-abd9-dcb79009c7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-65758aee-a4e4-4f95-b517-4b936da0b134,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-63886217-ef56-4e1f-83d6-e63e32fe06ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35530,DS-d16419d0-6c90-4949-a3b8-6a795d6caf17,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-ea63d2ae-bb0a-411d-ade1-9290e998ca10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-901110760-172.17.0.4-1595931011774:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46118,DS-e5563cde-cc0a-45ef-a831-1ec1675900a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-ceff28e1-654e-4309-b904-ba4c39e9ab08,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-3d7b00b5-2fbb-41a7-91cf-dc1d6e3e86a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-ff02b2d2-b2a0-4f60-bc2c-3c5b5630006b,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-83afdee1-bfe1-4847-a81a-fa6903841ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-b031a368-bf44-439f-b069-050b7e8b6826,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-3c4ebda2-11eb-46fb-aa35-25cb787d1bef,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-15d48673-6f7c-4a7a-815c-d72a9449025d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-901110760-172.17.0.4-1595931011774:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46118,DS-e5563cde-cc0a-45ef-a831-1ec1675900a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-ceff28e1-654e-4309-b904-ba4c39e9ab08,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-3d7b00b5-2fbb-41a7-91cf-dc1d6e3e86a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-ff02b2d2-b2a0-4f60-bc2c-3c5b5630006b,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-83afdee1-bfe1-4847-a81a-fa6903841ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-b031a368-bf44-439f-b069-050b7e8b6826,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-3c4ebda2-11eb-46fb-aa35-25cb787d1bef,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-15d48673-6f7c-4a7a-815c-d72a9449025d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-764317090-172.17.0.4-1595931078935:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44428,DS-6eb340a7-b15c-4be5-90d7-bd0d1eb73b90,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-1706cf3b-e4aa-451a-94fc-7dd7ce97dfc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-5737b025-7f3a-4f57-b1d8-78bb1b8fb6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-72fb08bd-2be9-4fca-ab2e-04e60ffa96e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46523,DS-ddcec5ac-7078-4d7f-b5b9-1996e220c055,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-2960ec37-4793-4922-81b9-794095a7a570,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-3cf7945a-ab66-4cab-927c-56abb63b3b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-d6bd1645-a386-4fdb-81b3-36c9bc03ca26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-764317090-172.17.0.4-1595931078935:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44428,DS-6eb340a7-b15c-4be5-90d7-bd0d1eb73b90,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-1706cf3b-e4aa-451a-94fc-7dd7ce97dfc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-5737b025-7f3a-4f57-b1d8-78bb1b8fb6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-72fb08bd-2be9-4fca-ab2e-04e60ffa96e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46523,DS-ddcec5ac-7078-4d7f-b5b9-1996e220c055,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-2960ec37-4793-4922-81b9-794095a7a570,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-3cf7945a-ab66-4cab-927c-56abb63b3b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-d6bd1645-a386-4fdb-81b3-36c9bc03ca26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-527295703-172.17.0.4-1595931481970:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34232,DS-30c77248-165c-4699-8ed3-6e3dcabb58a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-7eaa9454-72ca-4f94-aafa-fd92e072aa31,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-8eebc203-e803-4058-9c5d-e38f887f35ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41148,DS-e46873ee-d0c8-463e-93f6-757c32c2153d,DISK], DatanodeInfoWithStorage[127.0.0.1:45743,DS-83200c1e-54a9-442e-8f1b-0a90757398f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-0687ef74-2ecf-4426-9308-59dcb06eedb5,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-0c33ff1f-267f-4577-bef0-669e968b38fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-7138eea1-fb31-4d4a-9702-f20e22fce0c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-527295703-172.17.0.4-1595931481970:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34232,DS-30c77248-165c-4699-8ed3-6e3dcabb58a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-7eaa9454-72ca-4f94-aafa-fd92e072aa31,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-8eebc203-e803-4058-9c5d-e38f887f35ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41148,DS-e46873ee-d0c8-463e-93f6-757c32c2153d,DISK], DatanodeInfoWithStorage[127.0.0.1:45743,DS-83200c1e-54a9-442e-8f1b-0a90757398f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-0687ef74-2ecf-4426-9308-59dcb06eedb5,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-0c33ff1f-267f-4577-bef0-669e968b38fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-7138eea1-fb31-4d4a-9702-f20e22fce0c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1170787557-172.17.0.4-1595931704915:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36556,DS-e75903cf-a81c-4338-b4bb-15e2ed5577f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-9a644112-9898-43f0-a579-e6db7a132dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-8e9dbc25-693b-4774-9ea6-a86f3afb6727,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-66885038-c81b-43c2-bb8f-ce33077c81ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-1c4092c3-773b-460a-81a3-208de43265ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-478e932d-f7ee-4afd-96d8-94b8f6dc2044,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-23a020be-0f7c-47d9-ae63-dacf9210d0b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-0949e5fc-e25b-4d65-8032-ffc36dbae665,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1170787557-172.17.0.4-1595931704915:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36556,DS-e75903cf-a81c-4338-b4bb-15e2ed5577f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-9a644112-9898-43f0-a579-e6db7a132dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-8e9dbc25-693b-4774-9ea6-a86f3afb6727,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-66885038-c81b-43c2-bb8f-ce33077c81ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-1c4092c3-773b-460a-81a3-208de43265ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-478e932d-f7ee-4afd-96d8-94b8f6dc2044,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-23a020be-0f7c-47d9-ae63-dacf9210d0b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-0949e5fc-e25b-4d65-8032-ffc36dbae665,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-128373754-172.17.0.4-1595932027806:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37734,DS-d96b7736-4951-44eb-ae59-baed234168f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-cd25de44-ead6-44ac-9b85-d14a5f38c284,DISK], DatanodeInfoWithStorage[127.0.0.1:40909,DS-0a38a3fb-c686-424c-8cdf-d56cf6dabf5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-22ec4e5c-8349-4e55-bd11-3860bb40df91,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-163b35d4-a1c2-40c5-a1c3-e3e998e99e22,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-231cf325-0036-4b32-9709-ac95fef697d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-5a7ca1f9-f1c1-46f4-bde8-dadbaefbcae6,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-fbd186c8-47d5-4f2b-90fb-288cacfec383,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-128373754-172.17.0.4-1595932027806:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37734,DS-d96b7736-4951-44eb-ae59-baed234168f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-cd25de44-ead6-44ac-9b85-d14a5f38c284,DISK], DatanodeInfoWithStorage[127.0.0.1:40909,DS-0a38a3fb-c686-424c-8cdf-d56cf6dabf5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-22ec4e5c-8349-4e55-bd11-3860bb40df91,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-163b35d4-a1c2-40c5-a1c3-e3e998e99e22,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-231cf325-0036-4b32-9709-ac95fef697d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-5a7ca1f9-f1c1-46f4-bde8-dadbaefbcae6,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-fbd186c8-47d5-4f2b-90fb-288cacfec383,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-159860642-172.17.0.4-1595932406825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39036,DS-1cc014df-b128-4a1b-b7b7-ab43024c2f04,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-d91194f8-818d-457c-b37c-c9701b738d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-d1b96174-adca-4c4c-9595-dd641a1cf58a,DISK], DatanodeInfoWithStorage[127.0.0.1:36748,DS-ca4f43d4-2225-4d9d-a62a-3fc194c71aed,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-70054af9-0932-4a13-97e3-29bf0939b56f,DISK], DatanodeInfoWithStorage[127.0.0.1:44749,DS-c8de20a8-bcba-4270-8554-aa8f85ddd32b,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-dcf237e9-d3c8-4ef4-90de-09133204ac78,DISK], DatanodeInfoWithStorage[127.0.0.1:44202,DS-eadadd08-f167-475c-b70d-8b027c075205,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-159860642-172.17.0.4-1595932406825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39036,DS-1cc014df-b128-4a1b-b7b7-ab43024c2f04,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-d91194f8-818d-457c-b37c-c9701b738d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-d1b96174-adca-4c4c-9595-dd641a1cf58a,DISK], DatanodeInfoWithStorage[127.0.0.1:36748,DS-ca4f43d4-2225-4d9d-a62a-3fc194c71aed,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-70054af9-0932-4a13-97e3-29bf0939b56f,DISK], DatanodeInfoWithStorage[127.0.0.1:44749,DS-c8de20a8-bcba-4270-8554-aa8f85ddd32b,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-dcf237e9-d3c8-4ef4-90de-09133204ac78,DISK], DatanodeInfoWithStorage[127.0.0.1:44202,DS-eadadd08-f167-475c-b70d-8b027c075205,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1254563419-172.17.0.4-1595932513261:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46488,DS-558947cf-a453-4680-b89d-38748fd45a78,DISK], DatanodeInfoWithStorage[127.0.0.1:45790,DS-a10afd78-ef8f-4620-adcb-67e1038c09d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-14c5b7ff-8b26-4ee4-ae6b-101e3ffaf95a,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-db9dd20f-31c5-48bd-843c-6fbe49cad807,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-a449a736-0b75-44b3-b6a6-44762cbf04d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-8db54e4b-34a8-4c5c-bda3-4ed7f5e8c5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-74b67c01-7041-4580-b907-658f9df90a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-62078adf-e722-43da-99d1-ebb42546cd36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1254563419-172.17.0.4-1595932513261:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46488,DS-558947cf-a453-4680-b89d-38748fd45a78,DISK], DatanodeInfoWithStorage[127.0.0.1:45790,DS-a10afd78-ef8f-4620-adcb-67e1038c09d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-14c5b7ff-8b26-4ee4-ae6b-101e3ffaf95a,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-db9dd20f-31c5-48bd-843c-6fbe49cad807,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-a449a736-0b75-44b3-b6a6-44762cbf04d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-8db54e4b-34a8-4c5c-bda3-4ed7f5e8c5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-74b67c01-7041-4580-b907-658f9df90a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-62078adf-e722-43da-99d1-ebb42546cd36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-983383479-172.17.0.4-1595933800320:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41436,DS-282b59e8-21c7-4fdb-8c57-2f8c711a4831,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-82583eb2-d0e9-4f7c-bc4f-b9e52d2df5da,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-cbb80bfd-7428-470c-902f-d6c99e4665dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-ea160685-6152-4ae6-9193-19802fabf184,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-3753a212-fed3-4aaa-ab53-329b89f89f95,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-41667d90-f22e-4e3f-99d0-a408ba488492,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-be916eaa-8b0a-48ae-9207-9d47f1892ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-a654deb5-b6b2-44f2-8db4-fd5a2d70b677,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-983383479-172.17.0.4-1595933800320:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41436,DS-282b59e8-21c7-4fdb-8c57-2f8c711a4831,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-82583eb2-d0e9-4f7c-bc4f-b9e52d2df5da,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-cbb80bfd-7428-470c-902f-d6c99e4665dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-ea160685-6152-4ae6-9193-19802fabf184,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-3753a212-fed3-4aaa-ab53-329b89f89f95,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-41667d90-f22e-4e3f-99d0-a408ba488492,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-be916eaa-8b0a-48ae-9207-9d47f1892ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-a654deb5-b6b2-44f2-8db4-fd5a2d70b677,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1642451310-172.17.0.4-1595933868052:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33748,DS-2297d2a3-caf6-4f9c-8bb4-3d0292683cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-98f28566-64d5-44a3-88b3-a9c0aedbf518,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-e77337ac-a2a8-4a4a-802b-022ac2644b19,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-134a0736-b57d-4420-9a06-69864aa61fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45224,DS-18e1d66d-3df0-4e72-a12e-dc63b9696385,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-f59d0f68-b3a3-478e-a7d8-3975febb1bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-f48f965a-0c76-40ed-a998-f9cf8b055c17,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-15951153-5cd5-4c32-a9dc-55dbb5749645,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1642451310-172.17.0.4-1595933868052:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33748,DS-2297d2a3-caf6-4f9c-8bb4-3d0292683cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-98f28566-64d5-44a3-88b3-a9c0aedbf518,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-e77337ac-a2a8-4a4a-802b-022ac2644b19,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-134a0736-b57d-4420-9a06-69864aa61fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45224,DS-18e1d66d-3df0-4e72-a12e-dc63b9696385,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-f59d0f68-b3a3-478e-a7d8-3975febb1bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-f48f965a-0c76-40ed-a998-f9cf8b055c17,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-15951153-5cd5-4c32-a9dc-55dbb5749645,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1957972675-172.17.0.4-1595933899052:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39936,DS-b6a4ff85-4797-425b-be67-3f2f0c72a5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-01179f27-ddb8-4e62-8e09-ad29f631844c,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-8c3a9d9b-5926-4f27-b1ad-86fd86cba68f,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-3359f859-5321-485b-ab11-ea72675cd405,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-62567c45-f842-4b81-82b2-9bd5ac2595a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-f64db65e-d038-4127-97a1-ab56d1466385,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-f5921059-8bdc-43eb-b890-677000246cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-a52cb163-7c90-4715-a348-8a3144051680,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1957972675-172.17.0.4-1595933899052:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39936,DS-b6a4ff85-4797-425b-be67-3f2f0c72a5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-01179f27-ddb8-4e62-8e09-ad29f631844c,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-8c3a9d9b-5926-4f27-b1ad-86fd86cba68f,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-3359f859-5321-485b-ab11-ea72675cd405,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-62567c45-f842-4b81-82b2-9bd5ac2595a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-f64db65e-d038-4127-97a1-ab56d1466385,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-f5921059-8bdc-43eb-b890-677000246cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-a52cb163-7c90-4715-a348-8a3144051680,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1755725838-172.17.0.4-1595934269203:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44167,DS-34079378-3e2a-4faa-a984-92076cb900f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-ec466536-03d0-43b0-8472-1fefacb2b95c,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-e8d0549f-926f-4239-bdb3-ba878228be24,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-68e6e9c7-8316-4a5b-bafb-853a88c2f3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-59912ae0-ee88-461f-b7e4-fcb619792795,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-8d49fffd-c870-41e1-84d9-cfd472dfd345,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-28457a37-9a90-4bf0-8d42-11342797ac51,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-99ceaa00-bcf5-48b6-ade9-13273d8482dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1755725838-172.17.0.4-1595934269203:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44167,DS-34079378-3e2a-4faa-a984-92076cb900f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-ec466536-03d0-43b0-8472-1fefacb2b95c,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-e8d0549f-926f-4239-bdb3-ba878228be24,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-68e6e9c7-8316-4a5b-bafb-853a88c2f3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-59912ae0-ee88-461f-b7e4-fcb619792795,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-8d49fffd-c870-41e1-84d9-cfd472dfd345,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-28457a37-9a90-4bf0-8d42-11342797ac51,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-99ceaa00-bcf5-48b6-ade9-13273d8482dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 4941
