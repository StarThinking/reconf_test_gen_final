reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-973486096-172.17.0.18-1595972957886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41664,DS-41ecb031-24ad-4e26-a659-1fa53726a7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-b34fb58a-ccc7-47d0-a62f-b80eb232c404,DISK], DatanodeInfoWithStorage[127.0.0.1:42713,DS-881ef3f9-af59-4603-8060-82444b2f6435,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-8413ac73-a958-4594-8034-c5f1f744dbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-24d374a9-6f1f-4aba-8fb0-71857614ea77,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-b1f72e70-9cfc-4df9-8324-b3f0b6ac14a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-5c97c24a-1b1c-429c-9594-84e5a9ead573,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-2f9e2b04-2ee4-47a7-81c5-ea505b2fe2b8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-973486096-172.17.0.18-1595972957886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41664,DS-41ecb031-24ad-4e26-a659-1fa53726a7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-b34fb58a-ccc7-47d0-a62f-b80eb232c404,DISK], DatanodeInfoWithStorage[127.0.0.1:42713,DS-881ef3f9-af59-4603-8060-82444b2f6435,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-8413ac73-a958-4594-8034-c5f1f744dbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-24d374a9-6f1f-4aba-8fb0-71857614ea77,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-b1f72e70-9cfc-4df9-8324-b3f0b6ac14a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-5c97c24a-1b1c-429c-9594-84e5a9ead573,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-2f9e2b04-2ee4-47a7-81c5-ea505b2fe2b8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-127745036-172.17.0.18-1595973034543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43825,DS-8959aff2-f173-48ad-b649-6aa8c81758c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-0fc48f7f-5588-452e-8052-61584aee2990,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-622b5429-9909-4874-827a-3cb640c4de21,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-c96a1aea-708c-4ea7-bef6-0a41f2ebac69,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-d2585bc2-933c-4acc-974d-da483ca7db13,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-2e070426-e9ea-46af-8cf0-892919730862,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-d8a18729-5afd-412a-a073-20e7c342196f,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-140a6023-c60f-45b9-ba46-55d458be2ced,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-127745036-172.17.0.18-1595973034543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43825,DS-8959aff2-f173-48ad-b649-6aa8c81758c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-0fc48f7f-5588-452e-8052-61584aee2990,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-622b5429-9909-4874-827a-3cb640c4de21,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-c96a1aea-708c-4ea7-bef6-0a41f2ebac69,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-d2585bc2-933c-4acc-974d-da483ca7db13,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-2e070426-e9ea-46af-8cf0-892919730862,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-d8a18729-5afd-412a-a073-20e7c342196f,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-140a6023-c60f-45b9-ba46-55d458be2ced,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1228682099-172.17.0.18-1595973100241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44500,DS-b6870f41-6f88-41df-a7a7-c7a94a592477,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-ddba3f1d-c38e-4875-a10a-4acaee8db605,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-06fe7543-0773-46f0-8e33-be5dd0529bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-e2ea98e4-7f0d-4a9a-8c4e-97497bc6e6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-b28ac769-c146-4169-b6c8-e58c3b926544,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-b37359bb-1784-4925-b269-db07dce2e345,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-ac088f95-a67e-4198-981c-ebc3329f0cde,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-01ece75d-9316-4a79-9786-00582c8549b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1228682099-172.17.0.18-1595973100241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44500,DS-b6870f41-6f88-41df-a7a7-c7a94a592477,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-ddba3f1d-c38e-4875-a10a-4acaee8db605,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-06fe7543-0773-46f0-8e33-be5dd0529bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-e2ea98e4-7f0d-4a9a-8c4e-97497bc6e6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-b28ac769-c146-4169-b6c8-e58c3b926544,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-b37359bb-1784-4925-b269-db07dce2e345,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-ac088f95-a67e-4198-981c-ebc3329f0cde,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-01ece75d-9316-4a79-9786-00582c8549b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1757504314-172.17.0.18-1595973136552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35910,DS-c77c6a59-a8d5-4e84-96b6-1937c7cec88c,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-dcdafbf8-3b91-4ffa-a993-f145155cd953,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-cea71dcc-cc4a-4ba0-9010-380fd64d41cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35648,DS-19222a6f-d212-419c-b82a-fd794a6917b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-42d1f641-14e4-4681-8db2-5a0e295cc872,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-ed2c7b5d-d2ed-4e69-8126-c2efb07509e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-4c64d3a7-1388-45c8-bf8b-a6666224c45d,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-3c67d4b5-025a-4bc3-b8c9-addf3f45253b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1757504314-172.17.0.18-1595973136552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35910,DS-c77c6a59-a8d5-4e84-96b6-1937c7cec88c,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-dcdafbf8-3b91-4ffa-a993-f145155cd953,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-cea71dcc-cc4a-4ba0-9010-380fd64d41cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35648,DS-19222a6f-d212-419c-b82a-fd794a6917b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-42d1f641-14e4-4681-8db2-5a0e295cc872,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-ed2c7b5d-d2ed-4e69-8126-c2efb07509e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-4c64d3a7-1388-45c8-bf8b-a6666224c45d,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-3c67d4b5-025a-4bc3-b8c9-addf3f45253b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1664837983-172.17.0.18-1595973171861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37340,DS-9981b4e3-1ca7-44d3-83b9-83ccb00edd4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-c35a9bc0-d01d-46f7-9e9e-3a79bef79dff,DISK], DatanodeInfoWithStorage[127.0.0.1:39780,DS-4a018c79-458a-4c8e-a4b0-7b9e867eef1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44514,DS-9c02b2c3-62e5-4740-9ee8-a1c78863703a,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-42ec9927-ec39-4d66-b2a9-83dea9fc9840,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-34cf99c1-847f-4e4a-a4da-54181551cb09,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-0f90dd54-a4e7-49ff-aad4-206436b49be3,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-3983999e-dd32-4560-8d28-60cd13c5cfc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1664837983-172.17.0.18-1595973171861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37340,DS-9981b4e3-1ca7-44d3-83b9-83ccb00edd4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-c35a9bc0-d01d-46f7-9e9e-3a79bef79dff,DISK], DatanodeInfoWithStorage[127.0.0.1:39780,DS-4a018c79-458a-4c8e-a4b0-7b9e867eef1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44514,DS-9c02b2c3-62e5-4740-9ee8-a1c78863703a,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-42ec9927-ec39-4d66-b2a9-83dea9fc9840,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-34cf99c1-847f-4e4a-a4da-54181551cb09,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-0f90dd54-a4e7-49ff-aad4-206436b49be3,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-3983999e-dd32-4560-8d28-60cd13c5cfc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-782964773-172.17.0.18-1595973474366:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40447,DS-b654238b-5bd8-4953-8687-94faf5d5d68c,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-5065d474-b4f4-47c9-8d73-af9b938901df,DISK], DatanodeInfoWithStorage[127.0.0.1:39913,DS-b8fd03f7-bbb4-4bfe-864f-2bd6715ecf1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-4e8bfeb6-c193-4f7f-9baa-4130e07f0dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-0afdf0fc-6587-416e-b07d-e86baa3e2aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:33199,DS-b13b5531-c392-445f-8fd2-b736717f4fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-b1135407-05e8-417c-bd36-a979d6b5eb99,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-16993e69-a5bf-4f3b-a466-bfb65840d0a1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-782964773-172.17.0.18-1595973474366:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40447,DS-b654238b-5bd8-4953-8687-94faf5d5d68c,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-5065d474-b4f4-47c9-8d73-af9b938901df,DISK], DatanodeInfoWithStorage[127.0.0.1:39913,DS-b8fd03f7-bbb4-4bfe-864f-2bd6715ecf1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-4e8bfeb6-c193-4f7f-9baa-4130e07f0dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-0afdf0fc-6587-416e-b07d-e86baa3e2aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:33199,DS-b13b5531-c392-445f-8fd2-b736717f4fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-b1135407-05e8-417c-bd36-a979d6b5eb99,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-16993e69-a5bf-4f3b-a466-bfb65840d0a1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1113141754-172.17.0.18-1595973506244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35857,DS-9a4ed0db-3cad-4637-ba71-721289e68005,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-e02ae65b-792b-413a-aa17-89d5e55a0163,DISK], DatanodeInfoWithStorage[127.0.0.1:33682,DS-28accc89-d063-4959-a74f-c83bf0a13fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-c80d0c9f-b6af-4b13-b7c6-9cb45acaba8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-9f75d0a2-8e44-4ec6-a0c7-d2eae23e9f54,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-3e784342-f99f-43c8-a5d4-805082545019,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-1deb9e0e-2b28-4ccd-bfdb-c2f83100a1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-644d1451-0761-4343-98f4-e11716ffd609,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1113141754-172.17.0.18-1595973506244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35857,DS-9a4ed0db-3cad-4637-ba71-721289e68005,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-e02ae65b-792b-413a-aa17-89d5e55a0163,DISK], DatanodeInfoWithStorage[127.0.0.1:33682,DS-28accc89-d063-4959-a74f-c83bf0a13fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-c80d0c9f-b6af-4b13-b7c6-9cb45acaba8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-9f75d0a2-8e44-4ec6-a0c7-d2eae23e9f54,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-3e784342-f99f-43c8-a5d4-805082545019,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-1deb9e0e-2b28-4ccd-bfdb-c2f83100a1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-644d1451-0761-4343-98f4-e11716ffd609,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-635348014-172.17.0.18-1595973585655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38651,DS-15a2ed9a-e602-43ec-b479-419113ee867d,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-ab621078-f4de-45bd-aa6f-7039c5abd41d,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-4972cded-f48d-4dfc-bd66-e5e3666bfdb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-c3f5248d-32d6-4dbb-b480-7a393f2f77e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-c630ed1e-b51e-4044-b64e-a47adf90bf3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-5b67623b-d6dd-49be-89aa-ed4adaea1c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-91c53f54-7349-492a-bf65-d8ded11a049a,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-a563619a-40b0-4519-8b2f-500ea2b1ded3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-635348014-172.17.0.18-1595973585655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38651,DS-15a2ed9a-e602-43ec-b479-419113ee867d,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-ab621078-f4de-45bd-aa6f-7039c5abd41d,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-4972cded-f48d-4dfc-bd66-e5e3666bfdb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-c3f5248d-32d6-4dbb-b480-7a393f2f77e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-c630ed1e-b51e-4044-b64e-a47adf90bf3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-5b67623b-d6dd-49be-89aa-ed4adaea1c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-91c53f54-7349-492a-bf65-d8ded11a049a,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-a563619a-40b0-4519-8b2f-500ea2b1ded3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2089736790-172.17.0.18-1595973810507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41756,DS-b0bb5dbe-5caa-487f-8e2a-184cd0013c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-bb39971c-5b2d-452a-a590-75e6ca18cd3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-f68bf7d3-9293-4f6c-8c9a-9683e632e8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-8062ef95-572e-4d19-8a73-ae681d21bfef,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-e564f7cd-cf08-48ed-b2d0-2ab7c2cde35f,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-0d7e0ca1-85dc-4a47-a244-dda7a8a886be,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-0b8d7d09-e086-422f-96df-f1f3243d174c,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-944f5450-d9cf-437b-8908-491444a2d2cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2089736790-172.17.0.18-1595973810507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41756,DS-b0bb5dbe-5caa-487f-8e2a-184cd0013c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-bb39971c-5b2d-452a-a590-75e6ca18cd3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-f68bf7d3-9293-4f6c-8c9a-9683e632e8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-8062ef95-572e-4d19-8a73-ae681d21bfef,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-e564f7cd-cf08-48ed-b2d0-2ab7c2cde35f,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-0d7e0ca1-85dc-4a47-a244-dda7a8a886be,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-0b8d7d09-e086-422f-96df-f1f3243d174c,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-944f5450-d9cf-437b-8908-491444a2d2cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1955006046-172.17.0.18-1595973855596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44621,DS-18776f58-089e-4556-9352-d644cad24091,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-8165a263-d38c-478d-8a41-34e6c4740486,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-79d2d5e4-4151-42ed-9bfa-f72a383d706f,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-e2699841-7af5-4404-a9e0-50a353b28d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-7aabf778-b897-4d02-8f31-c83059693cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-8619088e-f9c8-4161-ae73-f079f8280b65,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-24c9742c-08d6-4556-9d2c-d75bd8cc0ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-84f247fe-b014-4ba7-840f-07c7177aba19,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1955006046-172.17.0.18-1595973855596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44621,DS-18776f58-089e-4556-9352-d644cad24091,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-8165a263-d38c-478d-8a41-34e6c4740486,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-79d2d5e4-4151-42ed-9bfa-f72a383d706f,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-e2699841-7af5-4404-a9e0-50a353b28d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-7aabf778-b897-4d02-8f31-c83059693cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-8619088e-f9c8-4161-ae73-f079f8280b65,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-24c9742c-08d6-4556-9d2c-d75bd8cc0ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-84f247fe-b014-4ba7-840f-07c7177aba19,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1774120515-172.17.0.18-1595973970593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45228,DS-b91cb699-1e2a-464e-acef-ce0b39db13a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-a1c4795f-a63a-45cb-b6a8-beb70175eb8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-3ed4e144-9192-4f33-ad10-0fdc87de211c,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-ddef6769-e0ec-48a3-9027-9501fd07d308,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-bda48065-0228-452a-83a9-8a21580da701,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-1cb05e33-e9b5-4f8b-b447-8a17ac9a0b94,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-2f08fce4-c95d-48e8-a0ba-948ea4e1cd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-7146c2aa-2116-4ae9-aaf6-9892047ce284,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1774120515-172.17.0.18-1595973970593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45228,DS-b91cb699-1e2a-464e-acef-ce0b39db13a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-a1c4795f-a63a-45cb-b6a8-beb70175eb8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-3ed4e144-9192-4f33-ad10-0fdc87de211c,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-ddef6769-e0ec-48a3-9027-9501fd07d308,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-bda48065-0228-452a-83a9-8a21580da701,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-1cb05e33-e9b5-4f8b-b447-8a17ac9a0b94,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-2f08fce4-c95d-48e8-a0ba-948ea4e1cd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-7146c2aa-2116-4ae9-aaf6-9892047ce284,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-672382836-172.17.0.18-1595974247785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46342,DS-e43df5d1-608e-49b8-adc8-a552083a03a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-b740a430-0b3c-44fd-b333-ba8ded392096,DISK], DatanodeInfoWithStorage[127.0.0.1:36122,DS-f2fc7bd3-73fa-41f6-8a44-848746571618,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-340aebbe-df06-4611-b8d2-5a81fa4502f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-8b947241-a7d1-444b-b18d-280d5fc4f757,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-541c3837-7c78-4081-b372-a9e1c9c5e373,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-6169c5d0-ecf3-4bd0-b0c5-8ddeb2549758,DISK], DatanodeInfoWithStorage[127.0.0.1:39790,DS-757a4d8d-4183-48e7-a505-77ac93172f92,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-672382836-172.17.0.18-1595974247785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46342,DS-e43df5d1-608e-49b8-adc8-a552083a03a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-b740a430-0b3c-44fd-b333-ba8ded392096,DISK], DatanodeInfoWithStorage[127.0.0.1:36122,DS-f2fc7bd3-73fa-41f6-8a44-848746571618,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-340aebbe-df06-4611-b8d2-5a81fa4502f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-8b947241-a7d1-444b-b18d-280d5fc4f757,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-541c3837-7c78-4081-b372-a9e1c9c5e373,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-6169c5d0-ecf3-4bd0-b0c5-8ddeb2549758,DISK], DatanodeInfoWithStorage[127.0.0.1:39790,DS-757a4d8d-4183-48e7-a505-77ac93172f92,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1080602991-172.17.0.18-1595974671833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39014,DS-4f6f42d6-5cdc-4340-afde-d35f07be1266,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-334a2b07-19f1-4c41-b88e-3e7474a8e059,DISK], DatanodeInfoWithStorage[127.0.0.1:36671,DS-92c22a2f-13eb-4dda-8082-34e13332a8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-28430bb6-c0c5-415f-898d-d8e66a70638c,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-cd092850-deed-4046-876d-96840a7679d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-62e135e2-bf8e-4fe9-bcd9-8fd3bf007a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-a5dc714b-26a2-46c8-b22c-ab1633da326b,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-0cef7dec-ee7e-449c-ad81-e79f00ac9782,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1080602991-172.17.0.18-1595974671833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39014,DS-4f6f42d6-5cdc-4340-afde-d35f07be1266,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-334a2b07-19f1-4c41-b88e-3e7474a8e059,DISK], DatanodeInfoWithStorage[127.0.0.1:36671,DS-92c22a2f-13eb-4dda-8082-34e13332a8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-28430bb6-c0c5-415f-898d-d8e66a70638c,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-cd092850-deed-4046-876d-96840a7679d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-62e135e2-bf8e-4fe9-bcd9-8fd3bf007a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-a5dc714b-26a2-46c8-b22c-ab1633da326b,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-0cef7dec-ee7e-449c-ad81-e79f00ac9782,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1772080264-172.17.0.18-1595974746214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37564,DS-653fef6f-f6c8-45b5-86f7-d5505edd25d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-24b3159d-0dc5-46e8-bded-3d876c1e2135,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-e0d9607b-5c1c-44b8-8bb8-107eaff51533,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-b484ac4c-ecd3-4ba2-b366-18a2b9dc88d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-25dbaedf-368e-45e4-9401-c60a820ed22b,DISK], DatanodeInfoWithStorage[127.0.0.1:42796,DS-f8775af0-71bd-4331-9acf-19df043834f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-af083346-d46a-45c9-97a6-239b59a60598,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-662858b9-e340-40f6-bbec-7c629dddbaf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1772080264-172.17.0.18-1595974746214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37564,DS-653fef6f-f6c8-45b5-86f7-d5505edd25d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-24b3159d-0dc5-46e8-bded-3d876c1e2135,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-e0d9607b-5c1c-44b8-8bb8-107eaff51533,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-b484ac4c-ecd3-4ba2-b366-18a2b9dc88d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-25dbaedf-368e-45e4-9401-c60a820ed22b,DISK], DatanodeInfoWithStorage[127.0.0.1:42796,DS-f8775af0-71bd-4331-9acf-19df043834f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-af083346-d46a-45c9-97a6-239b59a60598,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-662858b9-e340-40f6-bbec-7c629dddbaf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-470633705-172.17.0.18-1595974786804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39779,DS-34a7317b-b434-44ca-8772-f492e1fb452e,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-20e66369-14e0-4f53-8a06-0c3e7948663c,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-0bb921fe-595e-4aca-902a-ef66b53e25d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-7b332754-848b-4203-9865-d1f2734a71e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-198cd353-4aa1-4094-aac9-f648462fc3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-16e5cc32-5f27-4861-82a3-b1e47b38db8f,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-17104600-1abc-405c-bac9-741d84b05bba,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-4bf93ee7-37b6-4a58-8449-36c723fd035c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-470633705-172.17.0.18-1595974786804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39779,DS-34a7317b-b434-44ca-8772-f492e1fb452e,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-20e66369-14e0-4f53-8a06-0c3e7948663c,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-0bb921fe-595e-4aca-902a-ef66b53e25d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-7b332754-848b-4203-9865-d1f2734a71e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-198cd353-4aa1-4094-aac9-f648462fc3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-16e5cc32-5f27-4861-82a3-b1e47b38db8f,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-17104600-1abc-405c-bac9-741d84b05bba,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-4bf93ee7-37b6-4a58-8449-36c723fd035c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-312900541-172.17.0.18-1595974819276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39210,DS-60e8bcd6-1e36-4635-b4f2-f0970a8c23ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46616,DS-9c56f089-b9b9-48d8-a202-a0321e34c99c,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-2150d290-6130-4049-9c31-5a5a7a0b0bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-6696c68f-b1d8-48a4-9483-e14ac4d867fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-77726f1e-f967-4cec-92bc-ed5b38e6611d,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-1aa8188d-8124-463d-ae0d-36c6606d8083,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-fb80034e-376d-439f-b2c8-fe87248389c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-9ae3f93e-16dc-4446-8281-46947e195833,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-312900541-172.17.0.18-1595974819276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39210,DS-60e8bcd6-1e36-4635-b4f2-f0970a8c23ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46616,DS-9c56f089-b9b9-48d8-a202-a0321e34c99c,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-2150d290-6130-4049-9c31-5a5a7a0b0bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-6696c68f-b1d8-48a4-9483-e14ac4d867fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-77726f1e-f967-4cec-92bc-ed5b38e6611d,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-1aa8188d-8124-463d-ae0d-36c6606d8083,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-fb80034e-376d-439f-b2c8-fe87248389c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-9ae3f93e-16dc-4446-8281-46947e195833,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1808629774-172.17.0.18-1595974864180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35153,DS-f553fe6d-ca13-4b0e-b596-c0bafdcf044b,DISK], DatanodeInfoWithStorage[127.0.0.1:33949,DS-04fbaadb-fcfc-41f7-a029-035987cc8164,DISK], DatanodeInfoWithStorage[127.0.0.1:45528,DS-22d02a31-f503-4eae-b59d-dd51a30fa8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-8c329a56-4e17-4dd9-89d2-848482ad93ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-e2674287-4433-4723-8fa1-3c0851c1f505,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-a8d4b339-a910-4f23-a8f4-b7e34c8e3dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40072,DS-c888caa5-938c-4758-9643-38d1b8b6a866,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-86ddfeb6-39b6-4576-86e2-7570d06c872a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1808629774-172.17.0.18-1595974864180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35153,DS-f553fe6d-ca13-4b0e-b596-c0bafdcf044b,DISK], DatanodeInfoWithStorage[127.0.0.1:33949,DS-04fbaadb-fcfc-41f7-a029-035987cc8164,DISK], DatanodeInfoWithStorage[127.0.0.1:45528,DS-22d02a31-f503-4eae-b59d-dd51a30fa8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-8c329a56-4e17-4dd9-89d2-848482ad93ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-e2674287-4433-4723-8fa1-3c0851c1f505,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-a8d4b339-a910-4f23-a8f4-b7e34c8e3dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40072,DS-c888caa5-938c-4758-9643-38d1b8b6a866,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-86ddfeb6-39b6-4576-86e2-7570d06c872a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1887193277-172.17.0.18-1595975269402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41229,DS-afefa07c-d82d-4960-a0a2-974ed745710a,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-825ef126-1234-4513-ac2a-1e5c8c0a9a48,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-7aa8d645-9a83-42d9-9b10-5b432a8d380f,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-4d02fe25-600b-4d35-8f04-3850dfb0ddc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-c20329bd-0708-46ca-9ff1-d01d4705b8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-30e8b4d7-42e4-4255-b0bd-36625131d0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-c750811e-bb98-4223-8d93-165f51fcde47,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-5a5f2237-593a-47ba-8d53-86ca5430e4e9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1887193277-172.17.0.18-1595975269402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41229,DS-afefa07c-d82d-4960-a0a2-974ed745710a,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-825ef126-1234-4513-ac2a-1e5c8c0a9a48,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-7aa8d645-9a83-42d9-9b10-5b432a8d380f,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-4d02fe25-600b-4d35-8f04-3850dfb0ddc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-c20329bd-0708-46ca-9ff1-d01d4705b8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-30e8b4d7-42e4-4255-b0bd-36625131d0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-c750811e-bb98-4223-8d93-165f51fcde47,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-5a5f2237-593a-47ba-8d53-86ca5430e4e9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1332804228-172.17.0.18-1595975478683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38458,DS-cd9923ba-34fa-48d5-a1e3-1ddaab5aeb52,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-5580dd13-5c17-4bde-937c-ea15cc2faec0,DISK], DatanodeInfoWithStorage[127.0.0.1:39170,DS-ef1240b7-4499-499e-8f2f-6127a7953833,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-a716f015-3016-4abc-8b61-6b7e28dcd6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-3e35dc35-b920-4dc3-ae68-f4e1c267eeb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38907,DS-da5c6e72-14ad-4dcd-9554-cada27d7e636,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-082724b8-74bc-4969-a399-d98efae2449b,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-2effb210-0404-41cc-899a-1d555bdd4a7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1332804228-172.17.0.18-1595975478683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38458,DS-cd9923ba-34fa-48d5-a1e3-1ddaab5aeb52,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-5580dd13-5c17-4bde-937c-ea15cc2faec0,DISK], DatanodeInfoWithStorage[127.0.0.1:39170,DS-ef1240b7-4499-499e-8f2f-6127a7953833,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-a716f015-3016-4abc-8b61-6b7e28dcd6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-3e35dc35-b920-4dc3-ae68-f4e1c267eeb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38907,DS-da5c6e72-14ad-4dcd-9554-cada27d7e636,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-082724b8-74bc-4969-a399-d98efae2449b,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-2effb210-0404-41cc-899a-1d555bdd4a7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1302617361-172.17.0.18-1595975562153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34216,DS-88f2a2c7-4001-4b2e-94cd-dca720ad51cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-e63b0f31-eac9-4d82-915f-53dcfef91445,DISK], DatanodeInfoWithStorage[127.0.0.1:37784,DS-d43db07d-1b05-4cf7-919c-3b5725aa5fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-2e42b788-33ff-4cce-aeb3-4e78682c6e77,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-61cdf57a-3fa8-4689-924a-87a3a4362c61,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-04629ef4-1657-46d9-b60f-c136f5a68e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34302,DS-fc4b7131-eab5-468e-9217-4e3f0bb81166,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-d3777199-5c76-4e65-8117-82b597ae8691,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1302617361-172.17.0.18-1595975562153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34216,DS-88f2a2c7-4001-4b2e-94cd-dca720ad51cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-e63b0f31-eac9-4d82-915f-53dcfef91445,DISK], DatanodeInfoWithStorage[127.0.0.1:37784,DS-d43db07d-1b05-4cf7-919c-3b5725aa5fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-2e42b788-33ff-4cce-aeb3-4e78682c6e77,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-61cdf57a-3fa8-4689-924a-87a3a4362c61,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-04629ef4-1657-46d9-b60f-c136f5a68e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34302,DS-fc4b7131-eab5-468e-9217-4e3f0bb81166,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-d3777199-5c76-4e65-8117-82b597ae8691,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2058298252-172.17.0.18-1595975640164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40803,DS-cc93168a-4635-4254-9d50-83aada4dd213,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-dda3a2ff-dfd6-4762-a47e-657e521a1eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-eeac6d8b-7011-4d95-a549-49de25f7229b,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-81d21b78-12ed-4b0a-a094-7143d092c6be,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-0a9ee44f-e16f-4f95-a928-b7a4b49e28a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-481ec138-e295-4aa7-99b2-0a940896671e,DISK], DatanodeInfoWithStorage[127.0.0.1:33229,DS-e77e3232-b23f-48ce-bc9b-7dee23039fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-8497265a-43a4-4e17-a868-bf73509e7fe6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2058298252-172.17.0.18-1595975640164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40803,DS-cc93168a-4635-4254-9d50-83aada4dd213,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-dda3a2ff-dfd6-4762-a47e-657e521a1eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-eeac6d8b-7011-4d95-a549-49de25f7229b,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-81d21b78-12ed-4b0a-a094-7143d092c6be,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-0a9ee44f-e16f-4f95-a928-b7a4b49e28a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-481ec138-e295-4aa7-99b2-0a940896671e,DISK], DatanodeInfoWithStorage[127.0.0.1:33229,DS-e77e3232-b23f-48ce-bc9b-7dee23039fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-8497265a-43a4-4e17-a868-bf73509e7fe6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1999371548-172.17.0.18-1595975719051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39126,DS-8991744b-3d06-4ed7-abec-5eae14a3f62f,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-c272ef0e-bcb0-46a8-8fe4-9936836677e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-8968356a-2c75-467c-8ca7-3b79a851fb32,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-32a1671a-7149-4233-8941-c015d606fc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-f08a0416-6bf7-483a-847b-a9b5e92c46ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-a7201c41-e986-48cc-bf5e-d1bb5c9679bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-ecea1562-e660-460c-b39f-2f537e69eda9,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-3accea01-55c4-4ad6-86a9-7a03cf17e01c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1999371548-172.17.0.18-1595975719051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39126,DS-8991744b-3d06-4ed7-abec-5eae14a3f62f,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-c272ef0e-bcb0-46a8-8fe4-9936836677e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-8968356a-2c75-467c-8ca7-3b79a851fb32,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-32a1671a-7149-4233-8941-c015d606fc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-f08a0416-6bf7-483a-847b-a9b5e92c46ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-a7201c41-e986-48cc-bf5e-d1bb5c9679bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-ecea1562-e660-460c-b39f-2f537e69eda9,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-3accea01-55c4-4ad6-86a9-7a03cf17e01c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1560850364-172.17.0.18-1595975757133:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46162,DS-f5f96e08-e1dd-49f3-8741-20aea3dc087e,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-0970a268-c7e2-4ef0-86c6-80ecc87d95f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-5cb518d8-c332-42cb-bde4-d137c8e5b807,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-c6cf0b58-c1cf-4acc-a2ba-65633ce60628,DISK], DatanodeInfoWithStorage[127.0.0.1:42337,DS-adb0d809-6cdf-45db-9b07-fe60e668779a,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-5937aa4e-904c-46fa-b314-aba4a5c45f31,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-6849ac62-9317-41d6-86d9-469194887440,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-5dd2768c-2baf-4187-b85a-96fabab82eca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1560850364-172.17.0.18-1595975757133:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46162,DS-f5f96e08-e1dd-49f3-8741-20aea3dc087e,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-0970a268-c7e2-4ef0-86c6-80ecc87d95f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-5cb518d8-c332-42cb-bde4-d137c8e5b807,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-c6cf0b58-c1cf-4acc-a2ba-65633ce60628,DISK], DatanodeInfoWithStorage[127.0.0.1:42337,DS-adb0d809-6cdf-45db-9b07-fe60e668779a,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-5937aa4e-904c-46fa-b314-aba4a5c45f31,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-6849ac62-9317-41d6-86d9-469194887440,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-5dd2768c-2baf-4187-b85a-96fabab82eca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1941294394-172.17.0.18-1595975834981:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46473,DS-ec1a144b-b993-4602-829e-a3875164688b,DISK], DatanodeInfoWithStorage[127.0.0.1:46860,DS-e38a3f4f-e31b-4803-a551-67cc5628e78a,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-85f14143-f882-49f8-8865-308ae4132e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-d9186fa4-6b6d-4cff-8472-f1aeab58960b,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-2ffaa357-d6ab-49f1-990b-89478b351b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-d382f1c7-b174-46cb-8776-d4e20fd8c2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-2c37e748-b56a-4f02-b48f-2a23c4cbafa5,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-87ab4621-e6cf-43a5-a799-ccb8f300c1ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1941294394-172.17.0.18-1595975834981:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46473,DS-ec1a144b-b993-4602-829e-a3875164688b,DISK], DatanodeInfoWithStorage[127.0.0.1:46860,DS-e38a3f4f-e31b-4803-a551-67cc5628e78a,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-85f14143-f882-49f8-8865-308ae4132e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-d9186fa4-6b6d-4cff-8472-f1aeab58960b,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-2ffaa357-d6ab-49f1-990b-89478b351b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-d382f1c7-b174-46cb-8776-d4e20fd8c2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-2c37e748-b56a-4f02-b48f-2a23c4cbafa5,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-87ab4621-e6cf-43a5-a799-ccb8f300c1ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-206385417-172.17.0.18-1595975874431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44590,DS-0d232390-c778-45b5-aa3a-027be69c3e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-7f9b1871-5557-4455-8ef9-4882e4118b86,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-e038ca8e-5ee1-4a93-9574-f74026adadea,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-77c91609-4e89-4048-972e-ef2b1869c109,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-2c225822-ed3e-47f2-87c0-33e665596a33,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-1a392dc4-213d-4c7d-981c-5740c5c5c5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-aa571489-ffea-4502-9ddd-bd6fcf668b73,DISK], DatanodeInfoWithStorage[127.0.0.1:43240,DS-255f356c-005c-4908-ba12-c6ba7c3267fa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-206385417-172.17.0.18-1595975874431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44590,DS-0d232390-c778-45b5-aa3a-027be69c3e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-7f9b1871-5557-4455-8ef9-4882e4118b86,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-e038ca8e-5ee1-4a93-9574-f74026adadea,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-77c91609-4e89-4048-972e-ef2b1869c109,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-2c225822-ed3e-47f2-87c0-33e665596a33,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-1a392dc4-213d-4c7d-981c-5740c5c5c5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-aa571489-ffea-4502-9ddd-bd6fcf668b73,DISK], DatanodeInfoWithStorage[127.0.0.1:43240,DS-255f356c-005c-4908-ba12-c6ba7c3267fa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1680808729-172.17.0.18-1595975911616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37171,DS-bcb7a714-3e58-4b02-ad29-989c39344451,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-9fc25194-95e3-46b6-abab-4f1782c1c8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43863,DS-a086301f-867a-49e1-a971-02149492cd03,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-a5134b93-8a47-4ba5-867b-752b07a2aee3,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-01e89970-32e4-45fb-b5d1-b71fbe0b516c,DISK], DatanodeInfoWithStorage[127.0.0.1:40254,DS-25831a3b-9e45-452c-92e3-67e4f6558612,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-d957d100-77a3-4d08-be55-fe63ccd97e23,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-cd9f4706-f3aa-451f-bdf5-60ac3c9f83ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1680808729-172.17.0.18-1595975911616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37171,DS-bcb7a714-3e58-4b02-ad29-989c39344451,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-9fc25194-95e3-46b6-abab-4f1782c1c8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43863,DS-a086301f-867a-49e1-a971-02149492cd03,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-a5134b93-8a47-4ba5-867b-752b07a2aee3,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-01e89970-32e4-45fb-b5d1-b71fbe0b516c,DISK], DatanodeInfoWithStorage[127.0.0.1:40254,DS-25831a3b-9e45-452c-92e3-67e4f6558612,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-d957d100-77a3-4d08-be55-fe63ccd97e23,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-cd9f4706-f3aa-451f-bdf5-60ac3c9f83ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1100363387-172.17.0.18-1595976053147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46199,DS-ee407189-3cb9-478d-86f0-36515169e278,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-c5123e21-bf4d-4e00-b3c9-48452329bd60,DISK], DatanodeInfoWithStorage[127.0.0.1:44997,DS-a0ed0d57-3afe-4379-940a-b727754855e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-41798ad1-83bd-4b05-9549-5813948c373b,DISK], DatanodeInfoWithStorage[127.0.0.1:42387,DS-e32e465a-4287-410d-8e6a-99e46cc47a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-d4b6b452-54b7-4135-9405-8cca8dfaaa88,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-b0a86d66-9ec8-4a49-8ea6-574062d82329,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-5bb60154-c5b0-4213-bbf2-20b6962d0a18,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1100363387-172.17.0.18-1595976053147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46199,DS-ee407189-3cb9-478d-86f0-36515169e278,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-c5123e21-bf4d-4e00-b3c9-48452329bd60,DISK], DatanodeInfoWithStorage[127.0.0.1:44997,DS-a0ed0d57-3afe-4379-940a-b727754855e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-41798ad1-83bd-4b05-9549-5813948c373b,DISK], DatanodeInfoWithStorage[127.0.0.1:42387,DS-e32e465a-4287-410d-8e6a-99e46cc47a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-d4b6b452-54b7-4135-9405-8cca8dfaaa88,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-b0a86d66-9ec8-4a49-8ea6-574062d82329,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-5bb60154-c5b0-4213-bbf2-20b6962d0a18,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1474823797-172.17.0.18-1595976154833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46511,DS-f8b0d2f5-bb32-4439-b85a-e2da368ad6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-181a7174-3ce8-4a4b-9252-06d2ed747474,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-696b698f-69d8-4d73-8514-30f9a7b00d39,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-2d7f174d-6e45-43b6-8a1b-f26e082fd85a,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-762f9020-2aa2-4157-a00c-2eeb55c0f7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-aa829b86-19a0-4d24-88fc-f784fed3b063,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-7f178870-d8bc-4e1b-a6f1-ac38332b1833,DISK], DatanodeInfoWithStorage[127.0.0.1:33738,DS-6b485909-9539-4450-a3f2-a2d7c29aa71a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1474823797-172.17.0.18-1595976154833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46511,DS-f8b0d2f5-bb32-4439-b85a-e2da368ad6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-181a7174-3ce8-4a4b-9252-06d2ed747474,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-696b698f-69d8-4d73-8514-30f9a7b00d39,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-2d7f174d-6e45-43b6-8a1b-f26e082fd85a,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-762f9020-2aa2-4157-a00c-2eeb55c0f7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-aa829b86-19a0-4d24-88fc-f784fed3b063,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-7f178870-d8bc-4e1b-a6f1-ac38332b1833,DISK], DatanodeInfoWithStorage[127.0.0.1:33738,DS-6b485909-9539-4450-a3f2-a2d7c29aa71a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1510413170-172.17.0.18-1595976257564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34870,DS-02c3d6e8-89b7-49cd-9a57-8d1ea9b1b211,DISK], DatanodeInfoWithStorage[127.0.0.1:45820,DS-34827b79-9782-455d-bda6-612d5855cd35,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-7cf64bdf-4017-42fe-8da4-7661684f288f,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-82f8afb4-9607-44e0-8b7b-76dacc3d67ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-a39056ca-0268-432d-ab06-921a39bf0eea,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-97102e60-df8a-4cc6-ba71-76479ac988f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-8fcb6c35-85a0-4d77-8b0a-a16089108db6,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-64815b2a-9586-4799-89ea-c4a673a7b62e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1510413170-172.17.0.18-1595976257564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34870,DS-02c3d6e8-89b7-49cd-9a57-8d1ea9b1b211,DISK], DatanodeInfoWithStorage[127.0.0.1:45820,DS-34827b79-9782-455d-bda6-612d5855cd35,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-7cf64bdf-4017-42fe-8da4-7661684f288f,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-82f8afb4-9607-44e0-8b7b-76dacc3d67ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-a39056ca-0268-432d-ab06-921a39bf0eea,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-97102e60-df8a-4cc6-ba71-76479ac988f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-8fcb6c35-85a0-4d77-8b0a-a16089108db6,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-64815b2a-9586-4799-89ea-c4a673a7b62e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-526129586-172.17.0.18-1595976288113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35368,DS-52b7b17a-4bc6-4480-bef2-268fe9fe2a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-7f1d3bb5-c0f5-44c0-a5a2-928c6a536548,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-dd61964b-a59e-4cc0-bbb2-134397ff5123,DISK], DatanodeInfoWithStorage[127.0.0.1:42549,DS-ff200f10-7005-4e17-8fe2-f157f7e86a22,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-f7f3f0d4-3e1e-4252-9604-d8af9fe73c99,DISK], DatanodeInfoWithStorage[127.0.0.1:37142,DS-9adb92e0-ee54-4018-ad18-39d22a726297,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-d86000a9-9c47-46a2-83c0-e158f1c77716,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-128c54f3-dc8a-4442-a8f5-fc6c18e0189f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-526129586-172.17.0.18-1595976288113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35368,DS-52b7b17a-4bc6-4480-bef2-268fe9fe2a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-7f1d3bb5-c0f5-44c0-a5a2-928c6a536548,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-dd61964b-a59e-4cc0-bbb2-134397ff5123,DISK], DatanodeInfoWithStorage[127.0.0.1:42549,DS-ff200f10-7005-4e17-8fe2-f157f7e86a22,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-f7f3f0d4-3e1e-4252-9604-d8af9fe73c99,DISK], DatanodeInfoWithStorage[127.0.0.1:37142,DS-9adb92e0-ee54-4018-ad18-39d22a726297,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-d86000a9-9c47-46a2-83c0-e158f1c77716,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-128c54f3-dc8a-4442-a8f5-fc6c18e0189f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1964402128-172.17.0.18-1595976400050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45089,DS-9a5c6bff-aacf-467a-b6da-87dd6e280e69,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-13ffc26a-61d1-4709-954e-cab98d315bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-3de603e5-f376-494a-a376-acdd770116c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-9b882388-00c1-421e-b27a-dc815b9baeda,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-f5631379-8dcb-4732-968e-c8a0e03f7c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-c8b6026e-37af-4ca8-beb8-c34195380a37,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-0a84b9d7-dbfb-434a-a4be-6a51978a2512,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-5cc7319f-55bd-4872-8610-cf9bce6c6927,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1964402128-172.17.0.18-1595976400050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45089,DS-9a5c6bff-aacf-467a-b6da-87dd6e280e69,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-13ffc26a-61d1-4709-954e-cab98d315bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-3de603e5-f376-494a-a376-acdd770116c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-9b882388-00c1-421e-b27a-dc815b9baeda,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-f5631379-8dcb-4732-968e-c8a0e03f7c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-c8b6026e-37af-4ca8-beb8-c34195380a37,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-0a84b9d7-dbfb-434a-a4be-6a51978a2512,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-5cc7319f-55bd-4872-8610-cf9bce6c6927,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1151941869-172.17.0.18-1595976544702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38901,DS-37621433-dd55-47d9-a6d7-b27576a2cfe8,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-59cdfce8-9663-415d-98b2-5389524dc9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-f4ec50c1-dbcf-498d-9d95-3c668d22092a,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-6c25f6b4-daee-4c68-87d9-d510034a58db,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-5e4f72c5-1d51-4b83-9097-61cac23332ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-0a6b8c8c-dfc6-4f57-94b9-261a17de4cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-4f39b6a3-1d49-4d9d-8076-d4d9fadff595,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-a43f7b2e-985c-49d8-b9fd-ac8668975814,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1151941869-172.17.0.18-1595976544702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38901,DS-37621433-dd55-47d9-a6d7-b27576a2cfe8,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-59cdfce8-9663-415d-98b2-5389524dc9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-f4ec50c1-dbcf-498d-9d95-3c668d22092a,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-6c25f6b4-daee-4c68-87d9-d510034a58db,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-5e4f72c5-1d51-4b83-9097-61cac23332ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-0a6b8c8c-dfc6-4f57-94b9-261a17de4cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-4f39b6a3-1d49-4d9d-8076-d4d9fadff595,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-a43f7b2e-985c-49d8-b9fd-ac8668975814,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-393247556-172.17.0.18-1595976617462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38575,DS-139720a0-4a2c-45a9-acfc-96837b78f4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39911,DS-1e9f47c0-760a-47f1-9c4b-3920a7bb7938,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-655266d7-3d70-4e7d-9f3b-c680ec5a141c,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-2f1e56e2-f26d-408c-9667-761390529232,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-11b7afa1-2467-425d-aa33-3b20f10f33ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-b6513e28-b24e-4f59-8e4e-729cedcfd4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-fe009bfb-0ed9-4e1b-a0ba-af41c67a5350,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-52a5e1a7-dd1f-4046-a0e1-959d372fa4e3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-393247556-172.17.0.18-1595976617462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38575,DS-139720a0-4a2c-45a9-acfc-96837b78f4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39911,DS-1e9f47c0-760a-47f1-9c4b-3920a7bb7938,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-655266d7-3d70-4e7d-9f3b-c680ec5a141c,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-2f1e56e2-f26d-408c-9667-761390529232,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-11b7afa1-2467-425d-aa33-3b20f10f33ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-b6513e28-b24e-4f59-8e4e-729cedcfd4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-fe009bfb-0ed9-4e1b-a0ba-af41c67a5350,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-52a5e1a7-dd1f-4046-a0e1-959d372fa4e3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-180840868-172.17.0.18-1595976800742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41135,DS-ea1ef328-5e4c-4026-bd5a-f9356a6da822,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-74ab8232-d9a0-40fb-bbe4-cf42894acdb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-e9dbd5a4-6f1a-4333-bb77-a6a45eedf080,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-dc81a819-4092-4107-9461-31c7dce6f177,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-40c30813-0cdd-4980-8c93-530657a01337,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-5e0d744e-7046-4d76-839e-2468fcae7942,DISK], DatanodeInfoWithStorage[127.0.0.1:38672,DS-35699eab-8572-40ca-85ec-06fc964f865a,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-5a882b86-d757-4cb9-80b5-50fae68c0487,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-180840868-172.17.0.18-1595976800742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41135,DS-ea1ef328-5e4c-4026-bd5a-f9356a6da822,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-74ab8232-d9a0-40fb-bbe4-cf42894acdb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-e9dbd5a4-6f1a-4333-bb77-a6a45eedf080,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-dc81a819-4092-4107-9461-31c7dce6f177,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-40c30813-0cdd-4980-8c93-530657a01337,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-5e0d744e-7046-4d76-839e-2468fcae7942,DISK], DatanodeInfoWithStorage[127.0.0.1:38672,DS-35699eab-8572-40ca-85ec-06fc964f865a,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-5a882b86-d757-4cb9-80b5-50fae68c0487,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-532344124-172.17.0.18-1595976904531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46561,DS-35583a2e-946a-4ead-958f-425f9e1be3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-2b14bf7d-a7ac-4c46-8814-b96591d767ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-cd1f324c-254e-41b4-b0d5-33dc291bc1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-0c7d96cd-e4ec-47ca-af3a-a3bf50bee9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-6403d581-00b6-462c-8621-81f883bb09bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-f6ef0acf-30c1-41a7-8339-33c635f67df7,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-7c49ade9-832d-420c-9925-0d9f9e651b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45471,DS-8dbb6112-b679-449b-a7cf-0ed1dd564035,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-532344124-172.17.0.18-1595976904531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46561,DS-35583a2e-946a-4ead-958f-425f9e1be3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-2b14bf7d-a7ac-4c46-8814-b96591d767ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-cd1f324c-254e-41b4-b0d5-33dc291bc1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-0c7d96cd-e4ec-47ca-af3a-a3bf50bee9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-6403d581-00b6-462c-8621-81f883bb09bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-f6ef0acf-30c1-41a7-8339-33c635f67df7,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-7c49ade9-832d-420c-9925-0d9f9e651b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45471,DS-8dbb6112-b679-449b-a7cf-0ed1dd564035,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1776301780-172.17.0.18-1595977088521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43935,DS-e291d726-e553-4884-bed9-c41d7492cbca,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-ce4cf760-0691-4186-a69b-c1c77e43d24d,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-248dd92d-9ed4-470c-bf35-779be6af4724,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-aaa8253b-3521-4bf9-9ce6-20f4afe7a175,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-81db9605-9c49-438b-bdf9-a29277ec6d88,DISK], DatanodeInfoWithStorage[127.0.0.1:42927,DS-520cf5d3-e027-4d89-9b24-132b8f2e2a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-c6c41c55-b496-429b-8693-885ad59151ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-0ba67642-9257-4168-aaa2-41407f5b9baf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1776301780-172.17.0.18-1595977088521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43935,DS-e291d726-e553-4884-bed9-c41d7492cbca,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-ce4cf760-0691-4186-a69b-c1c77e43d24d,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-248dd92d-9ed4-470c-bf35-779be6af4724,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-aaa8253b-3521-4bf9-9ce6-20f4afe7a175,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-81db9605-9c49-438b-bdf9-a29277ec6d88,DISK], DatanodeInfoWithStorage[127.0.0.1:42927,DS-520cf5d3-e027-4d89-9b24-132b8f2e2a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-c6c41c55-b496-429b-8693-885ad59151ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-0ba67642-9257-4168-aaa2-41407f5b9baf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-920620419-172.17.0.18-1595977122647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36065,DS-10648367-58d7-4653-8870-17907fe24027,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-6d7c2884-fa71-40eb-9502-6c45be11e088,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-f8a9a0ff-9ba7-485a-b8a0-84442f518c59,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-b66d5356-d0ff-4e53-8233-1d00e3d5e1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-4aaf2b47-31b8-4897-8c73-c6baccde1cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-cf45d6f1-2f43-493c-a2eb-8a55206f3255,DISK], DatanodeInfoWithStorage[127.0.0.1:33734,DS-80bbc3c6-000e-42d8-bb12-fc5383472bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-09008370-0343-4fe5-a58e-a494d73dd245,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-920620419-172.17.0.18-1595977122647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36065,DS-10648367-58d7-4653-8870-17907fe24027,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-6d7c2884-fa71-40eb-9502-6c45be11e088,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-f8a9a0ff-9ba7-485a-b8a0-84442f518c59,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-b66d5356-d0ff-4e53-8233-1d00e3d5e1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-4aaf2b47-31b8-4897-8c73-c6baccde1cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-cf45d6f1-2f43-493c-a2eb-8a55206f3255,DISK], DatanodeInfoWithStorage[127.0.0.1:33734,DS-80bbc3c6-000e-42d8-bb12-fc5383472bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-09008370-0343-4fe5-a58e-a494d73dd245,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1599188093-172.17.0.18-1595977163891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44343,DS-5bcee163-f628-469d-90eb-b3aac19d18b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-0d721ce2-0e5d-4902-bfa4-42129be008ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-8213ecf5-eb72-4332-a2ba-cf4fbafc8689,DISK], DatanodeInfoWithStorage[127.0.0.1:36796,DS-a66f135f-8d47-442a-9e7d-060159645bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:33612,DS-ff4f7bf4-f7fe-4290-9855-721ded121d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41297,DS-5d65d738-c04f-4d50-abe3-76a37b62fdfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-f327662a-103b-4ab9-9faa-9af70cb340db,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-3f64291f-ab70-461c-a22d-d3171276c9ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1599188093-172.17.0.18-1595977163891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44343,DS-5bcee163-f628-469d-90eb-b3aac19d18b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-0d721ce2-0e5d-4902-bfa4-42129be008ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-8213ecf5-eb72-4332-a2ba-cf4fbafc8689,DISK], DatanodeInfoWithStorage[127.0.0.1:36796,DS-a66f135f-8d47-442a-9e7d-060159645bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:33612,DS-ff4f7bf4-f7fe-4290-9855-721ded121d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41297,DS-5d65d738-c04f-4d50-abe3-76a37b62fdfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-f327662a-103b-4ab9-9faa-9af70cb340db,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-3f64291f-ab70-461c-a22d-d3171276c9ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1331598907-172.17.0.18-1595977362144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37734,DS-bec465c1-61e2-407a-8958-2b6a4a41e6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-049ac0fe-7ef0-40ea-9efb-22bb6f2fc3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-348d9fc7-2627-46f4-b1d4-fa1c0ab99a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-c41e82a3-61f1-4417-8e54-0e2e5b024f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-9dcd44ea-f3ed-4ec4-a390-93f444ff3586,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-55230591-e303-4c16-a9df-565abc36d95d,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-5819b346-c5fe-4948-81d1-f224316a8b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34948,DS-7e1b1149-53e4-4c7c-a538-1bce36518d67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1331598907-172.17.0.18-1595977362144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37734,DS-bec465c1-61e2-407a-8958-2b6a4a41e6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-049ac0fe-7ef0-40ea-9efb-22bb6f2fc3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-348d9fc7-2627-46f4-b1d4-fa1c0ab99a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-c41e82a3-61f1-4417-8e54-0e2e5b024f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-9dcd44ea-f3ed-4ec4-a390-93f444ff3586,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-55230591-e303-4c16-a9df-565abc36d95d,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-5819b346-c5fe-4948-81d1-f224316a8b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34948,DS-7e1b1149-53e4-4c7c-a538-1bce36518d67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346731628-172.17.0.18-1595977535645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35829,DS-ab394bff-0aa5-46da-8fd5-5a69915bb098,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-a1c15cae-0768-4b3c-a368-4131116774b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-290a13b8-c2ab-4032-bb6b-551b2f8b2907,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-e2cd0f71-5649-48f5-9f3d-dc1c879fb8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-6bf782fc-2577-4198-9bc3-f46167a2760f,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-e2b7a723-7c6a-4fe8-8b89-e621a41a098f,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-47616d65-981f-496b-a483-9b2fe3b280ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-df2d26b9-3aa3-424e-af86-2ecd8e005a12,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346731628-172.17.0.18-1595977535645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35829,DS-ab394bff-0aa5-46da-8fd5-5a69915bb098,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-a1c15cae-0768-4b3c-a368-4131116774b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-290a13b8-c2ab-4032-bb6b-551b2f8b2907,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-e2cd0f71-5649-48f5-9f3d-dc1c879fb8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-6bf782fc-2577-4198-9bc3-f46167a2760f,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-e2b7a723-7c6a-4fe8-8b89-e621a41a098f,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-47616d65-981f-496b-a483-9b2fe3b280ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-df2d26b9-3aa3-424e-af86-2ecd8e005a12,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-182394154-172.17.0.18-1595977672212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41693,DS-178e5c7a-0d3f-4a09-9aa9-df5d4c1abc47,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-dc1d6319-2352-4928-9c2e-c284a017d6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-6032f080-ae87-4f69-8c42-5cdbf8fb4abf,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-abb200d5-aff5-4f56-8d4f-c00547f8480f,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-a5406335-7f25-4cc5-ac2b-2ef289f07838,DISK], DatanodeInfoWithStorage[127.0.0.1:34781,DS-2d16577a-a29e-4e06-8c7f-d96bae7abb10,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-b712c971-c306-4c8e-8e31-f5fc5a76a576,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-05359bff-5f92-48bf-be07-1d1f673aaa1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-182394154-172.17.0.18-1595977672212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41693,DS-178e5c7a-0d3f-4a09-9aa9-df5d4c1abc47,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-dc1d6319-2352-4928-9c2e-c284a017d6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-6032f080-ae87-4f69-8c42-5cdbf8fb4abf,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-abb200d5-aff5-4f56-8d4f-c00547f8480f,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-a5406335-7f25-4cc5-ac2b-2ef289f07838,DISK], DatanodeInfoWithStorage[127.0.0.1:34781,DS-2d16577a-a29e-4e06-8c7f-d96bae7abb10,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-b712c971-c306-4c8e-8e31-f5fc5a76a576,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-05359bff-5f92-48bf-be07-1d1f673aaa1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-358340341-172.17.0.18-1595977901190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46806,DS-175c8b40-3b9a-468e-aeec-7baa78674a86,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-8df4e97b-b47a-4816-9824-3aff36a08be7,DISK], DatanodeInfoWithStorage[127.0.0.1:38043,DS-60879fa4-227d-43d7-8915-d166308f81b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-e1db5c99-c0dd-4e73-a77a-e99320dc82eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-2dfae9d5-127c-4ddb-95dc-b7625fec6330,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-b9db4373-aa29-4b7a-a09d-e9e0aa02b5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-09ac74fc-6dcb-47f3-aa6f-efb3fd9b4888,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-5becfd37-8337-4792-86a5-0df1af04b75e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-358340341-172.17.0.18-1595977901190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46806,DS-175c8b40-3b9a-468e-aeec-7baa78674a86,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-8df4e97b-b47a-4816-9824-3aff36a08be7,DISK], DatanodeInfoWithStorage[127.0.0.1:38043,DS-60879fa4-227d-43d7-8915-d166308f81b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-e1db5c99-c0dd-4e73-a77a-e99320dc82eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-2dfae9d5-127c-4ddb-95dc-b7625fec6330,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-b9db4373-aa29-4b7a-a09d-e9e0aa02b5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-09ac74fc-6dcb-47f3-aa6f-efb3fd9b4888,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-5becfd37-8337-4792-86a5-0df1af04b75e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948760082-172.17.0.18-1595977968443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43769,DS-974f32e7-cdfa-40f9-a130-569fe0188027,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-22053894-a3bf-4197-8337-2e8434215282,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-8de8f30c-bf54-44b8-8ee9-51e5581fd23f,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-b7a6053a-caa4-44bb-aaea-4e6e622ba59c,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-4d236607-5aa2-4660-8065-54cf36e30dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-3633a4c7-9d3f-4628-a77b-0a245d394708,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-51d6ef00-0a44-469e-a978-62fcc1e23885,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-d58c0a8b-9fad-43e1-b6cd-a6aba4fdbf6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948760082-172.17.0.18-1595977968443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43769,DS-974f32e7-cdfa-40f9-a130-569fe0188027,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-22053894-a3bf-4197-8337-2e8434215282,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-8de8f30c-bf54-44b8-8ee9-51e5581fd23f,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-b7a6053a-caa4-44bb-aaea-4e6e622ba59c,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-4d236607-5aa2-4660-8065-54cf36e30dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-3633a4c7-9d3f-4628-a77b-0a245d394708,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-51d6ef00-0a44-469e-a978-62fcc1e23885,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-d58c0a8b-9fad-43e1-b6cd-a6aba4fdbf6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-366316088-172.17.0.18-1595978184460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43755,DS-1c3e951f-1efc-47c4-bdfb-27e53bd9d9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-65aff5f7-0cd4-4cac-bc99-2f6a0ffbe00b,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-f141782d-678a-47c8-a637-bf761c1db417,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-a209e91e-7bd1-4a5c-83a7-aaa0497a3a28,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-671cf079-e8ee-4dc3-859e-ed3455690eee,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-0b16f2bd-7a5e-42ab-88df-49c97ff98b99,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-89d836d0-1a7e-4bac-8b9c-55372ac8197b,DISK], DatanodeInfoWithStorage[127.0.0.1:44170,DS-6e90919c-bde4-4a02-a5d6-65960d4234ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-366316088-172.17.0.18-1595978184460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43755,DS-1c3e951f-1efc-47c4-bdfb-27e53bd9d9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-65aff5f7-0cd4-4cac-bc99-2f6a0ffbe00b,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-f141782d-678a-47c8-a637-bf761c1db417,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-a209e91e-7bd1-4a5c-83a7-aaa0497a3a28,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-671cf079-e8ee-4dc3-859e-ed3455690eee,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-0b16f2bd-7a5e-42ab-88df-49c97ff98b99,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-89d836d0-1a7e-4bac-8b9c-55372ac8197b,DISK], DatanodeInfoWithStorage[127.0.0.1:44170,DS-6e90919c-bde4-4a02-a5d6-65960d4234ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-19698293-172.17.0.18-1595978359717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41015,DS-d2f94bd6-7541-4fa8-934f-dc4f8c9560da,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-c1f1acb6-7824-476b-9772-c66bf19ffc5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-1efe741f-cbb5-418d-8571-2bb08360f6a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-a916ddfa-ddf1-496a-8f0f-a2675d5119cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-240b4a54-2af9-4d6d-ae2d-ff8b7bbe5f57,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-dce71af8-b6ca-4e7b-8daf-b27d3b4ba41f,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-34418112-a956-4052-8c0b-0a482edfa04e,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-f57e9c70-ad72-44aa-8ae1-1af68b68c3bc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-19698293-172.17.0.18-1595978359717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41015,DS-d2f94bd6-7541-4fa8-934f-dc4f8c9560da,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-c1f1acb6-7824-476b-9772-c66bf19ffc5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-1efe741f-cbb5-418d-8571-2bb08360f6a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-a916ddfa-ddf1-496a-8f0f-a2675d5119cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-240b4a54-2af9-4d6d-ae2d-ff8b7bbe5f57,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-dce71af8-b6ca-4e7b-8daf-b27d3b4ba41f,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-34418112-a956-4052-8c0b-0a482edfa04e,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-f57e9c70-ad72-44aa-8ae1-1af68b68c3bc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1786737229-172.17.0.18-1595978428828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37305,DS-cdb0c427-619e-4ab6-805d-e72ac3a22371,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-402f7351-fa6d-4721-b656-e1b54fc02d70,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-8e5bf344-8f78-429d-9540-656fe87f3e23,DISK], DatanodeInfoWithStorage[127.0.0.1:35741,DS-58daa721-1855-4541-b750-4ebc5ec495d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-8c011b24-c2ad-4268-81ac-abb1a59541ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-241cdd2a-26fd-4003-ac55-70f55f206cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36108,DS-e4235afe-6649-410a-9a5f-e60d48c3b24b,DISK], DatanodeInfoWithStorage[127.0.0.1:39006,DS-b37ac865-e2f6-42a3-9d27-8b93a2e84e88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1786737229-172.17.0.18-1595978428828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37305,DS-cdb0c427-619e-4ab6-805d-e72ac3a22371,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-402f7351-fa6d-4721-b656-e1b54fc02d70,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-8e5bf344-8f78-429d-9540-656fe87f3e23,DISK], DatanodeInfoWithStorage[127.0.0.1:35741,DS-58daa721-1855-4541-b750-4ebc5ec495d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-8c011b24-c2ad-4268-81ac-abb1a59541ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-241cdd2a-26fd-4003-ac55-70f55f206cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36108,DS-e4235afe-6649-410a-9a5f-e60d48c3b24b,DISK], DatanodeInfoWithStorage[127.0.0.1:39006,DS-b37ac865-e2f6-42a3-9d27-8b93a2e84e88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 14 out of 50
v1v1v2v2 failed with probability 26 out of 50
result: false positive !!!
Total execution time in seconds : 5542
