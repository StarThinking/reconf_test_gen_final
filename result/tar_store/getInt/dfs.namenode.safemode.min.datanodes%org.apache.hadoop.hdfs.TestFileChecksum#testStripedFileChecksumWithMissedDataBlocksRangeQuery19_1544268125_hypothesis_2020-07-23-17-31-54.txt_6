reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-558139540-172.17.0.6-1595525598568:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32972,DS-785055f8-82ec-4202-a386-1c0de7c97847,DISK], DatanodeInfoWithStorage[127.0.0.1:34888,DS-933dd179-0d40-4226-954f-212539d9d69b,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-ab4623b4-6d22-4147-9ec8-7940f15defaa,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-c8fcb824-428f-4f48-954a-3a897449cd95,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-93ce134d-4fe6-4961-a14e-a52090c54dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-5a861a85-2d0c-49f8-a233-d38b0ea65ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-9c8d76bc-4185-4ea4-9ef6-3a0c8e36d619,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-b4ad7755-0582-492a-be40-95436d66962c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-558139540-172.17.0.6-1595525598568:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32972,DS-785055f8-82ec-4202-a386-1c0de7c97847,DISK], DatanodeInfoWithStorage[127.0.0.1:34888,DS-933dd179-0d40-4226-954f-212539d9d69b,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-ab4623b4-6d22-4147-9ec8-7940f15defaa,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-c8fcb824-428f-4f48-954a-3a897449cd95,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-93ce134d-4fe6-4961-a14e-a52090c54dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-5a861a85-2d0c-49f8-a233-d38b0ea65ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-9c8d76bc-4185-4ea4-9ef6-3a0c8e36d619,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-b4ad7755-0582-492a-be40-95436d66962c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1329351292-172.17.0.6-1595526348303:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45409,DS-0ea02e2f-720e-4e75-a4fc-cc9cf5fb4996,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-652a7fd4-b24b-4bcb-9acf-e46d1958fce9,DISK], DatanodeInfoWithStorage[127.0.0.1:39651,DS-4e64e561-4cee-4a30-b491-1d96729863d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36233,DS-a0a88780-ef8a-4a82-9770-551baaadef31,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-9a45e793-a26d-4ff2-840d-ce8b873cbee4,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-077471e9-64b7-4795-97c8-4d2d255df259,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-ea04d4a0-7289-48e0-a86f-15505f10a5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-b5760860-8843-435e-b4b6-6fa52ee3b661,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1329351292-172.17.0.6-1595526348303:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45409,DS-0ea02e2f-720e-4e75-a4fc-cc9cf5fb4996,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-652a7fd4-b24b-4bcb-9acf-e46d1958fce9,DISK], DatanodeInfoWithStorage[127.0.0.1:39651,DS-4e64e561-4cee-4a30-b491-1d96729863d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36233,DS-a0a88780-ef8a-4a82-9770-551baaadef31,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-9a45e793-a26d-4ff2-840d-ce8b873cbee4,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-077471e9-64b7-4795-97c8-4d2d255df259,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-ea04d4a0-7289-48e0-a86f-15505f10a5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-b5760860-8843-435e-b4b6-6fa52ee3b661,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-518422917-172.17.0.6-1595526549707:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41919,DS-42dd7da3-4685-4c21-8d14-4e4031fa7ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:39818,DS-fa446421-4145-4615-9026-76daccbe83c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-6f6044a1-d4e9-4026-9bb7-c28a9fe4f1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45485,DS-c5959877-782c-4ae1-912a-7b1c32479415,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-989d8cd3-7e4e-48dd-aec1-2a0ff57bfbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-7d12758a-0fda-443c-8c1c-7e5daf1c5c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34439,DS-6bb9a055-5a88-4ef9-9dca-ada27c94b180,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-7ccdf8ad-0f55-48fe-856a-db8e46248169,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-518422917-172.17.0.6-1595526549707:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41919,DS-42dd7da3-4685-4c21-8d14-4e4031fa7ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:39818,DS-fa446421-4145-4615-9026-76daccbe83c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-6f6044a1-d4e9-4026-9bb7-c28a9fe4f1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45485,DS-c5959877-782c-4ae1-912a-7b1c32479415,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-989d8cd3-7e4e-48dd-aec1-2a0ff57bfbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-7d12758a-0fda-443c-8c1c-7e5daf1c5c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34439,DS-6bb9a055-5a88-4ef9-9dca-ada27c94b180,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-7ccdf8ad-0f55-48fe-856a-db8e46248169,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1027118932-172.17.0.6-1595526724650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37921,DS-018aa849-35a7-44c3-bf0f-8d2152a9e619,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-eb5d9a49-888c-4cb3-9b8f-fb61aa78be30,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-9a8b9fd9-82e4-4650-b538-50ec077b833b,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-af520409-7bf1-436f-a23d-f5c3928f5330,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-71d8bde2-2492-4f10-888d-710ae2fea94c,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-a6c15c4c-5a82-4d21-83e8-9e140c2ae906,DISK], DatanodeInfoWithStorage[127.0.0.1:39667,DS-5a3a4923-b756-4d3f-a012-b76e34af5c67,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-411f0aea-609d-4cef-a999-2ecb3178ca98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1027118932-172.17.0.6-1595526724650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37921,DS-018aa849-35a7-44c3-bf0f-8d2152a9e619,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-eb5d9a49-888c-4cb3-9b8f-fb61aa78be30,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-9a8b9fd9-82e4-4650-b538-50ec077b833b,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-af520409-7bf1-436f-a23d-f5c3928f5330,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-71d8bde2-2492-4f10-888d-710ae2fea94c,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-a6c15c4c-5a82-4d21-83e8-9e140c2ae906,DISK], DatanodeInfoWithStorage[127.0.0.1:39667,DS-5a3a4923-b756-4d3f-a012-b76e34af5c67,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-411f0aea-609d-4cef-a999-2ecb3178ca98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1341127354-172.17.0.6-1595527006377:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44052,DS-62022646-5a25-405a-91aa-dabc2f55bde6,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-5239b6bf-16bc-4fd0-88ba-1ca1ea45c75a,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-97064aea-eeb0-4fdb-9a8f-6e2b804b5302,DISK], DatanodeInfoWithStorage[127.0.0.1:42255,DS-5e93f6eb-63d4-4a0f-b0d9-362c4efee095,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-4a8fe36b-f1a1-4e93-9f7b-03070aac3daf,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-8015d98d-92fc-47cf-8830-6da8e425be4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-36dd38ec-1067-4172-9862-ad0d899568b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-6e10091e-3c44-4dd0-8665-12879d40402a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1341127354-172.17.0.6-1595527006377:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44052,DS-62022646-5a25-405a-91aa-dabc2f55bde6,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-5239b6bf-16bc-4fd0-88ba-1ca1ea45c75a,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-97064aea-eeb0-4fdb-9a8f-6e2b804b5302,DISK], DatanodeInfoWithStorage[127.0.0.1:42255,DS-5e93f6eb-63d4-4a0f-b0d9-362c4efee095,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-4a8fe36b-f1a1-4e93-9f7b-03070aac3daf,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-8015d98d-92fc-47cf-8830-6da8e425be4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-36dd38ec-1067-4172-9862-ad0d899568b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-6e10091e-3c44-4dd0-8665-12879d40402a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-313417462-172.17.0.6-1595528378951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45655,DS-6cfa9bf5-e5c3-461e-bb5d-0d8b48d23da0,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-703eecda-3051-47c0-9bd9-4306b5d51525,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-94b6e707-6096-4eec-ab47-7077e690ad18,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-0f4a9811-0b36-4c27-b552-07c00efc29b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-0f32abfe-833b-4466-a62c-06db4c24283d,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-7c4f848c-681b-4437-970b-a3a3710f73fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-5d67678c-07dd-4233-95ba-05476f208a25,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-bc261924-6d3b-463a-840d-7db61e066ace,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-313417462-172.17.0.6-1595528378951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45655,DS-6cfa9bf5-e5c3-461e-bb5d-0d8b48d23da0,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-703eecda-3051-47c0-9bd9-4306b5d51525,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-94b6e707-6096-4eec-ab47-7077e690ad18,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-0f4a9811-0b36-4c27-b552-07c00efc29b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-0f32abfe-833b-4466-a62c-06db4c24283d,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-7c4f848c-681b-4437-970b-a3a3710f73fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-5d67678c-07dd-4233-95ba-05476f208a25,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-bc261924-6d3b-463a-840d-7db61e066ace,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1617892257-172.17.0.6-1595528524162:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38402,DS-ea671c68-c40f-400f-bedc-f59659232c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-aa3c7850-08ae-4009-accc-771eee56d5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-705add9f-f670-4164-bdbf-bf67b463e565,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-52e60ea6-2c45-4509-aa65-b4226699699c,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-69cd8a53-155a-4002-bf25-b6b4e2b14cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:42152,DS-54c6c037-78d8-4d4f-9731-96451d975ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-49992fa2-2abb-44f2-9a1b-4ed2be465599,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-c5c17747-b770-4b0b-b085-298bd9413c1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1617892257-172.17.0.6-1595528524162:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38402,DS-ea671c68-c40f-400f-bedc-f59659232c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-aa3c7850-08ae-4009-accc-771eee56d5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-705add9f-f670-4164-bdbf-bf67b463e565,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-52e60ea6-2c45-4509-aa65-b4226699699c,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-69cd8a53-155a-4002-bf25-b6b4e2b14cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:42152,DS-54c6c037-78d8-4d4f-9731-96451d975ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-49992fa2-2abb-44f2-9a1b-4ed2be465599,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-c5c17747-b770-4b0b-b085-298bd9413c1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1694860357-172.17.0.6-1595528660986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37343,DS-74ac026f-9b00-442b-9d6b-4d85d95e32b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-3bb4cdc2-75a8-491f-bf16-6e59f901c807,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-154e3390-82db-46b5-89b7-eb56a3dac33b,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-59db100c-2e2e-4a95-a7de-9dcb0bdfa400,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-b1b61fca-7d11-4942-a942-5339af26c7df,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-10d430f1-3397-4050-8fc7-4d3f61af5a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-edb1d4f1-756a-48d7-8269-964ac3ce37bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-7be6e183-afa4-4251-9a92-87666efb0620,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1694860357-172.17.0.6-1595528660986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37343,DS-74ac026f-9b00-442b-9d6b-4d85d95e32b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-3bb4cdc2-75a8-491f-bf16-6e59f901c807,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-154e3390-82db-46b5-89b7-eb56a3dac33b,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-59db100c-2e2e-4a95-a7de-9dcb0bdfa400,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-b1b61fca-7d11-4942-a942-5339af26c7df,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-10d430f1-3397-4050-8fc7-4d3f61af5a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-edb1d4f1-756a-48d7-8269-964ac3ce37bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-7be6e183-afa4-4251-9a92-87666efb0620,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1664482148-172.17.0.6-1595528728451:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42620,DS-e9b80a33-dc74-4ff3-bf5e-c5673324ab34,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-4bfcb7b1-2690-4dc5-94d7-4062c64935e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-934e4fac-96a0-4239-933b-3f44d5c44985,DISK], DatanodeInfoWithStorage[127.0.0.1:44514,DS-c4513472-18ce-456d-8bfe-e3415fde0077,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-5d58f826-0107-4365-8402-6d770c3ec0be,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-d5a06982-6bfc-49eb-95f3-8c4030d1faa2,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-85d5f72e-6d30-4dc8-9744-7f0bd0417698,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-b8eece42-b3bf-465f-bfe4-e9b2ef72d3b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1664482148-172.17.0.6-1595528728451:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42620,DS-e9b80a33-dc74-4ff3-bf5e-c5673324ab34,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-4bfcb7b1-2690-4dc5-94d7-4062c64935e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-934e4fac-96a0-4239-933b-3f44d5c44985,DISK], DatanodeInfoWithStorage[127.0.0.1:44514,DS-c4513472-18ce-456d-8bfe-e3415fde0077,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-5d58f826-0107-4365-8402-6d770c3ec0be,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-d5a06982-6bfc-49eb-95f3-8c4030d1faa2,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-85d5f72e-6d30-4dc8-9744-7f0bd0417698,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-b8eece42-b3bf-465f-bfe4-e9b2ef72d3b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1762270100-172.17.0.6-1595529005770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36096,DS-e55b0eb2-560b-4c9c-9fe9-2a333bdcdf1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44008,DS-9bc291f9-8f0d-4ddc-8d5b-7f495135489b,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-9a9e1ea0-26b5-4cda-bacf-a240eabd5b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-958a3968-3662-4f21-9613-02791822c049,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-9655e7a7-f123-4c47-8e3b-dc3d568aed17,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-0e94d7a2-3fd0-41c7-9768-5e420289daee,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-6188c9e4-0c4f-4847-bccc-9c99b11c2f49,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-bbf7817e-a9f0-42c4-8090-19c67232b8fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1762270100-172.17.0.6-1595529005770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36096,DS-e55b0eb2-560b-4c9c-9fe9-2a333bdcdf1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44008,DS-9bc291f9-8f0d-4ddc-8d5b-7f495135489b,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-9a9e1ea0-26b5-4cda-bacf-a240eabd5b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-958a3968-3662-4f21-9613-02791822c049,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-9655e7a7-f123-4c47-8e3b-dc3d568aed17,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-0e94d7a2-3fd0-41c7-9768-5e420289daee,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-6188c9e4-0c4f-4847-bccc-9c99b11c2f49,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-bbf7817e-a9f0-42c4-8090-19c67232b8fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1799839766-172.17.0.6-1595529799971:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39130,DS-bc07a8ae-b29b-48d4-87d4-f85b916250c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35823,DS-0ae88c54-109f-431e-987f-c48801ed0ced,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-34e53bf3-0a04-4633-be1b-58182b35b252,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-48af1de3-98cd-489d-9d5e-241fd066434d,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-16703f69-e7e2-4fcd-a194-6bec01940b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-67f03ade-d312-471d-8348-89e93388535a,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-d62955ad-53ea-4df1-8522-dbb091c32763,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-d39801ed-775c-47f9-8bff-a7325e64c293,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1799839766-172.17.0.6-1595529799971:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39130,DS-bc07a8ae-b29b-48d4-87d4-f85b916250c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35823,DS-0ae88c54-109f-431e-987f-c48801ed0ced,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-34e53bf3-0a04-4633-be1b-58182b35b252,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-48af1de3-98cd-489d-9d5e-241fd066434d,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-16703f69-e7e2-4fcd-a194-6bec01940b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-67f03ade-d312-471d-8348-89e93388535a,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-d62955ad-53ea-4df1-8522-dbb091c32763,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-d39801ed-775c-47f9-8bff-a7325e64c293,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-404616056-172.17.0.6-1595529983785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39552,DS-3de29617-5b95-4367-9251-deda81a0ee49,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-5b158bc3-c605-47ad-8b82-082903061eab,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-6418c26a-82d1-4115-bc20-1be25ab40852,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-24a659be-3ee8-48e5-953d-3738c01dc05a,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-d514c16b-87b1-4c7a-aae2-38b0e62e5374,DISK], DatanodeInfoWithStorage[127.0.0.1:41803,DS-391a9b31-70fe-41cc-b288-f48e5a8a8e40,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-3de82c3d-351a-4d9b-a62b-5d65bc92420e,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-1462b37b-0713-421f-befb-b32371afe273,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-404616056-172.17.0.6-1595529983785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39552,DS-3de29617-5b95-4367-9251-deda81a0ee49,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-5b158bc3-c605-47ad-8b82-082903061eab,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-6418c26a-82d1-4115-bc20-1be25ab40852,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-24a659be-3ee8-48e5-953d-3738c01dc05a,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-d514c16b-87b1-4c7a-aae2-38b0e62e5374,DISK], DatanodeInfoWithStorage[127.0.0.1:41803,DS-391a9b31-70fe-41cc-b288-f48e5a8a8e40,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-3de82c3d-351a-4d9b-a62b-5d65bc92420e,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-1462b37b-0713-421f-befb-b32371afe273,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1466663474-172.17.0.6-1595530742006:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45625,DS-90c8da1f-f944-40b7-a8cb-4aa988570de8,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-de4ec8ed-e2d4-4b49-b484-e32ea2a37d05,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-527990fd-8434-4609-b656-27698d9be69d,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-fa50227f-0bdb-432d-bd49-41178c25be47,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-2c3cb58a-37fc-48e5-a008-adc29174a660,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-10c82a5b-48e4-4e42-875b-a610a8990cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-d0a4a27b-c716-47e9-9e08-0421e7868fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-28d98457-3059-44a5-899c-09d9e38bb7cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1466663474-172.17.0.6-1595530742006:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45625,DS-90c8da1f-f944-40b7-a8cb-4aa988570de8,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-de4ec8ed-e2d4-4b49-b484-e32ea2a37d05,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-527990fd-8434-4609-b656-27698d9be69d,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-fa50227f-0bdb-432d-bd49-41178c25be47,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-2c3cb58a-37fc-48e5-a008-adc29174a660,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-10c82a5b-48e4-4e42-875b-a610a8990cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-d0a4a27b-c716-47e9-9e08-0421e7868fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-28d98457-3059-44a5-899c-09d9e38bb7cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1139976391-172.17.0.6-1595530779789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44919,DS-88796ba1-b571-47d0-ade6-b63249c4d5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-8fee5232-6ea2-4164-ab61-e5c57a64aee9,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-c745ae5a-e444-4da3-8ee3-59184da69ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-e0a5b881-b5d9-4241-95ca-fdb92223afe8,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-76df16c0-539c-4710-86d9-fcf3cdc08042,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-b82a69d6-d075-48ba-98c8-ec3eaba944f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34816,DS-249f07db-cb69-46c4-b2c9-c4e8e135d083,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-a5f6b18b-b224-4b1a-89cf-ad8f764c0466,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1139976391-172.17.0.6-1595530779789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44919,DS-88796ba1-b571-47d0-ade6-b63249c4d5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-8fee5232-6ea2-4164-ab61-e5c57a64aee9,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-c745ae5a-e444-4da3-8ee3-59184da69ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-e0a5b881-b5d9-4241-95ca-fdb92223afe8,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-76df16c0-539c-4710-86d9-fcf3cdc08042,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-b82a69d6-d075-48ba-98c8-ec3eaba944f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34816,DS-249f07db-cb69-46c4-b2c9-c4e8e135d083,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-a5f6b18b-b224-4b1a-89cf-ad8f764c0466,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5285
