reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1452969202-172.17.0.17-1595941893190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43686,DS-6ced45fa-6654-4c20-a561-1698500068d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-02ac59e2-e51d-4104-98b9-6271bc7e1a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-f8367bc9-b9e0-4367-93f5-657c58298168,DISK], DatanodeInfoWithStorage[127.0.0.1:34561,DS-277f6af6-acde-4a0e-9dbc-77c555bb4c30,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-02f7427e-6ec1-4dab-9770-8de6c2466974,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-04160b0f-02d6-4c22-8079-3bcfc4cb9698,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-530af7ce-bcb6-4999-8381-ba373ce2a744,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-b2f1a49d-6c93-4276-9f2e-57c3b5dbda58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1452969202-172.17.0.17-1595941893190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43686,DS-6ced45fa-6654-4c20-a561-1698500068d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-02ac59e2-e51d-4104-98b9-6271bc7e1a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-f8367bc9-b9e0-4367-93f5-657c58298168,DISK], DatanodeInfoWithStorage[127.0.0.1:34561,DS-277f6af6-acde-4a0e-9dbc-77c555bb4c30,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-02f7427e-6ec1-4dab-9770-8de6c2466974,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-04160b0f-02d6-4c22-8079-3bcfc4cb9698,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-530af7ce-bcb6-4999-8381-ba373ce2a744,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-b2f1a49d-6c93-4276-9f2e-57c3b5dbda58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-877298352-172.17.0.17-1595942119420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38247,DS-cc561dbf-edab-4731-a134-ebd678fad4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-532726fd-d1de-4d75-8136-9b66d4a9a53a,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-cc91fe66-ad5d-4bf5-b5f3-cf02237b3766,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-8d56399b-ad16-4069-b26e-6f51f7018e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-16449d2e-29f0-4a44-98da-6ade5000b323,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-4b0c4dfa-f702-4311-b1ac-4f0dffb77dde,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-102cff03-89a8-4f3f-ab79-6cef5ccbb5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-7cdc5d60-3af4-41b0-a284-8b14aaf46260,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-877298352-172.17.0.17-1595942119420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38247,DS-cc561dbf-edab-4731-a134-ebd678fad4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-532726fd-d1de-4d75-8136-9b66d4a9a53a,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-cc91fe66-ad5d-4bf5-b5f3-cf02237b3766,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-8d56399b-ad16-4069-b26e-6f51f7018e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-16449d2e-29f0-4a44-98da-6ade5000b323,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-4b0c4dfa-f702-4311-b1ac-4f0dffb77dde,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-102cff03-89a8-4f3f-ab79-6cef5ccbb5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-7cdc5d60-3af4-41b0-a284-8b14aaf46260,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1470230587-172.17.0.17-1595942190712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41140,DS-56199a2b-9ba2-4c1a-9b11-29f2cb4780df,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-1184e6eb-4936-41f6-a7ad-c9efec43c037,DISK], DatanodeInfoWithStorage[127.0.0.1:39356,DS-6d462558-5878-44df-8594-f61b21d20c72,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-6dc90182-71b1-4c9b-9ac6-4909a8ae3404,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-aa5a053a-15d1-44f5-9760-8da9ace9848b,DISK], DatanodeInfoWithStorage[127.0.0.1:36347,DS-bc7ba941-b1df-45ee-965d-2c9399749c57,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-305b6d46-49f6-4a61-bf1b-4b9db2d1d7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46456,DS-1907e500-db8f-4b93-bf66-812f953dca69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1470230587-172.17.0.17-1595942190712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41140,DS-56199a2b-9ba2-4c1a-9b11-29f2cb4780df,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-1184e6eb-4936-41f6-a7ad-c9efec43c037,DISK], DatanodeInfoWithStorage[127.0.0.1:39356,DS-6d462558-5878-44df-8594-f61b21d20c72,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-6dc90182-71b1-4c9b-9ac6-4909a8ae3404,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-aa5a053a-15d1-44f5-9760-8da9ace9848b,DISK], DatanodeInfoWithStorage[127.0.0.1:36347,DS-bc7ba941-b1df-45ee-965d-2c9399749c57,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-305b6d46-49f6-4a61-bf1b-4b9db2d1d7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46456,DS-1907e500-db8f-4b93-bf66-812f953dca69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1754319756-172.17.0.17-1595942223797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46714,DS-e1fa37f1-6996-48eb-b175-975f9cc7a5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-ab879106-fa59-4a17-8d47-5142d6763415,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-834c9644-2d81-4d89-a2d1-e2f9a66441f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-8372391f-6d8a-4339-84cf-5b6fe503bb70,DISK], DatanodeInfoWithStorage[127.0.0.1:36099,DS-3f5e2746-0cc8-462b-a45d-f1c9b3a23624,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-52de1da9-cce7-479a-b473-932d16ff388d,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-944d9a0d-5ef4-4bcb-9d66-a41eb5574af2,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-4aefdffc-868d-42ca-8b4a-801c5b6026e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1754319756-172.17.0.17-1595942223797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46714,DS-e1fa37f1-6996-48eb-b175-975f9cc7a5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-ab879106-fa59-4a17-8d47-5142d6763415,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-834c9644-2d81-4d89-a2d1-e2f9a66441f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-8372391f-6d8a-4339-84cf-5b6fe503bb70,DISK], DatanodeInfoWithStorage[127.0.0.1:36099,DS-3f5e2746-0cc8-462b-a45d-f1c9b3a23624,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-52de1da9-cce7-479a-b473-932d16ff388d,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-944d9a0d-5ef4-4bcb-9d66-a41eb5574af2,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-4aefdffc-868d-42ca-8b4a-801c5b6026e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1615156001-172.17.0.17-1595942411037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45752,DS-4d91fa8c-25e3-4e5d-99a0-3e6c0483e9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-5582341b-eaa9-4356-a3b7-101ec0af25ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-cd15dada-4bac-467a-9bb4-923d432366df,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-ff08c49a-3b00-4f44-8ebb-fbc6908e70aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-806cbee7-ded5-457c-bd49-3267af6312f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-206da4f3-fd37-4853-bbe0-a7845c4c9076,DISK], DatanodeInfoWithStorage[127.0.0.1:35777,DS-b7e065de-7ceb-4180-b644-539e15a03fad,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-82642abe-c376-4b57-86ea-49cc7a61cf52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1615156001-172.17.0.17-1595942411037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45752,DS-4d91fa8c-25e3-4e5d-99a0-3e6c0483e9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-5582341b-eaa9-4356-a3b7-101ec0af25ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-cd15dada-4bac-467a-9bb4-923d432366df,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-ff08c49a-3b00-4f44-8ebb-fbc6908e70aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-806cbee7-ded5-457c-bd49-3267af6312f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-206da4f3-fd37-4853-bbe0-a7845c4c9076,DISK], DatanodeInfoWithStorage[127.0.0.1:35777,DS-b7e065de-7ceb-4180-b644-539e15a03fad,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-82642abe-c376-4b57-86ea-49cc7a61cf52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2052944688-172.17.0.17-1595942709691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35721,DS-8f8371d3-5b2c-4b77-b277-109ce415175b,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-c27e17f6-b6ac-442a-b87f-49a47dcd6f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-87956f57-943c-4ea9-8c3c-f8b4344535eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-a958a797-b43f-47ff-9919-aea0b896cbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-b1a15eeb-971f-4094-9059-2dd1a073a22a,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-bc76c2ba-a7da-446e-b53b-7889e79f4655,DISK], DatanodeInfoWithStorage[127.0.0.1:42056,DS-72886588-09ce-4551-9d89-43db0a7de10f,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-c05fbb49-5305-4c98-a518-ecd97e494332,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2052944688-172.17.0.17-1595942709691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35721,DS-8f8371d3-5b2c-4b77-b277-109ce415175b,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-c27e17f6-b6ac-442a-b87f-49a47dcd6f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-87956f57-943c-4ea9-8c3c-f8b4344535eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-a958a797-b43f-47ff-9919-aea0b896cbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-b1a15eeb-971f-4094-9059-2dd1a073a22a,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-bc76c2ba-a7da-446e-b53b-7889e79f4655,DISK], DatanodeInfoWithStorage[127.0.0.1:42056,DS-72886588-09ce-4551-9d89-43db0a7de10f,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-c05fbb49-5305-4c98-a518-ecd97e494332,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2046890356-172.17.0.17-1595943571890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44768,DS-151746a6-b423-49f9-ac21-aeef854e162f,DISK], DatanodeInfoWithStorage[127.0.0.1:38187,DS-2f2cb7be-1c75-4563-bd88-a5331a462c35,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-cb8cfb00-519f-4dc7-a01e-472ed4a87023,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-02e6f988-0d3c-457d-91d2-e705470a33c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33272,DS-53b4c5ee-89c4-4e84-ace4-29871e1271ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-67608e7b-e13a-4f2f-ab79-fb390058202f,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-7b2aaad4-4f8c-4eef-8359-ad947f837f74,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-c0322c59-aef9-4893-9120-1ecaaab73d7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2046890356-172.17.0.17-1595943571890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44768,DS-151746a6-b423-49f9-ac21-aeef854e162f,DISK], DatanodeInfoWithStorage[127.0.0.1:38187,DS-2f2cb7be-1c75-4563-bd88-a5331a462c35,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-cb8cfb00-519f-4dc7-a01e-472ed4a87023,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-02e6f988-0d3c-457d-91d2-e705470a33c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33272,DS-53b4c5ee-89c4-4e84-ace4-29871e1271ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-67608e7b-e13a-4f2f-ab79-fb390058202f,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-7b2aaad4-4f8c-4eef-8359-ad947f837f74,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-c0322c59-aef9-4893-9120-1ecaaab73d7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-676233544-172.17.0.17-1595944066592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33620,DS-34a2ab6d-e5f1-4d68-a561-f969767cea88,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-d8093f71-34eb-4d03-8daf-190ec7e2a7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-b4135122-a63f-4b49-89b0-5888a3e339e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-c134a3cd-cfe4-4331-ae77-18680c2f79d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-ec48d158-7c62-4aad-bf3b-955c25fc18fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-a0fbb920-fb2f-441a-b3ba-6846f8a56514,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-ad17ac3a-4151-4716-9f76-da4989e94bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-a89c1999-8fa8-48b7-b1a7-bd13f463ce9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-676233544-172.17.0.17-1595944066592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33620,DS-34a2ab6d-e5f1-4d68-a561-f969767cea88,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-d8093f71-34eb-4d03-8daf-190ec7e2a7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-b4135122-a63f-4b49-89b0-5888a3e339e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-c134a3cd-cfe4-4331-ae77-18680c2f79d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-ec48d158-7c62-4aad-bf3b-955c25fc18fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-a0fbb920-fb2f-441a-b3ba-6846f8a56514,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-ad17ac3a-4151-4716-9f76-da4989e94bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-a89c1999-8fa8-48b7-b1a7-bd13f463ce9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-272717711-172.17.0.17-1595944290703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43425,DS-962b0761-0a37-4c87-9d86-a8d3301210c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-5a6fb618-be12-428c-8a79-09c409d727a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-9d9c95c1-eb1a-4f05-bb45-52867603b404,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-3e613639-4e11-4bb5-a4b0-ed4fb0adc374,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-5460dfec-ab8b-4366-ba5b-d52786d0a151,DISK], DatanodeInfoWithStorage[127.0.0.1:45610,DS-83c1c095-5f70-4e1c-a5d0-03488e7ccc38,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-aff816fe-b557-434e-97cb-63f9d71e10b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-0e51d078-59b2-4df7-9e0d-4bee1074305f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-272717711-172.17.0.17-1595944290703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43425,DS-962b0761-0a37-4c87-9d86-a8d3301210c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-5a6fb618-be12-428c-8a79-09c409d727a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-9d9c95c1-eb1a-4f05-bb45-52867603b404,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-3e613639-4e11-4bb5-a4b0-ed4fb0adc374,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-5460dfec-ab8b-4366-ba5b-d52786d0a151,DISK], DatanodeInfoWithStorage[127.0.0.1:45610,DS-83c1c095-5f70-4e1c-a5d0-03488e7ccc38,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-aff816fe-b557-434e-97cb-63f9d71e10b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-0e51d078-59b2-4df7-9e0d-4bee1074305f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1610190718-172.17.0.17-1595944362108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41540,DS-5a26af17-bd82-45e3-818b-38a6ec3a0a52,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-03cefe5f-085e-43fc-a516-7cacd1b16e25,DISK], DatanodeInfoWithStorage[127.0.0.1:33455,DS-190eefd1-357e-4644-adf4-a06fad67d4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-b11226f4-5cee-4cc3-b331-ba648a91ab0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-ba6c08ac-dda6-45b0-b167-914444a74a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-0a371dcd-063f-454d-bd98-1f36bb85d61d,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-aa98a873-4267-4a06-a7a8-2f090910ec49,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-b86d56d3-9414-4170-b89f-1c29274e8d0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1610190718-172.17.0.17-1595944362108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41540,DS-5a26af17-bd82-45e3-818b-38a6ec3a0a52,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-03cefe5f-085e-43fc-a516-7cacd1b16e25,DISK], DatanodeInfoWithStorage[127.0.0.1:33455,DS-190eefd1-357e-4644-adf4-a06fad67d4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-b11226f4-5cee-4cc3-b331-ba648a91ab0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-ba6c08ac-dda6-45b0-b167-914444a74a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-0a371dcd-063f-454d-bd98-1f36bb85d61d,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-aa98a873-4267-4a06-a7a8-2f090910ec49,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-b86d56d3-9414-4170-b89f-1c29274e8d0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-761380260-172.17.0.17-1595944590356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42451,DS-4c744ae9-29ce-47fd-b221-7390e25d4121,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-173d27d5-c702-4d9f-ab11-fd184ff01dec,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-070e40b9-d062-4ad0-bcaa-6eeaceacfff0,DISK], DatanodeInfoWithStorage[127.0.0.1:44132,DS-76413c9e-eff5-493b-bf51-2650243742e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45199,DS-84a08611-1066-48c6-bed7-f051c346ee56,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-1b62f983-ebe2-4825-b7f4-12b7a862fbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40059,DS-0732f1e5-f8aa-485c-8c73-43c326cf5535,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-a63f120c-d88c-4dce-ad33-f03619d10e88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-761380260-172.17.0.17-1595944590356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42451,DS-4c744ae9-29ce-47fd-b221-7390e25d4121,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-173d27d5-c702-4d9f-ab11-fd184ff01dec,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-070e40b9-d062-4ad0-bcaa-6eeaceacfff0,DISK], DatanodeInfoWithStorage[127.0.0.1:44132,DS-76413c9e-eff5-493b-bf51-2650243742e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45199,DS-84a08611-1066-48c6-bed7-f051c346ee56,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-1b62f983-ebe2-4825-b7f4-12b7a862fbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40059,DS-0732f1e5-f8aa-485c-8c73-43c326cf5535,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-a63f120c-d88c-4dce-ad33-f03619d10e88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2054265137-172.17.0.17-1595944989713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36210,DS-61d23981-e8f6-4755-8daa-4897878aa769,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-b01d5947-b5d6-4100-b0c8-d00e2a0a17e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-c4e86ff1-8193-4d2e-ae42-84732e3b80f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-5f8481a5-cfd0-4de5-b0bd-3214f43eccae,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-5561924a-5931-4b05-8552-7d415fb971d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-994a30b9-5845-4431-88c2-2fabb98406d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-b1d6d918-1284-4e41-8b53-0a8d3e8d3944,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-5ce0bdd2-e9d3-4d5c-ab9c-5872086b45c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2054265137-172.17.0.17-1595944989713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36210,DS-61d23981-e8f6-4755-8daa-4897878aa769,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-b01d5947-b5d6-4100-b0c8-d00e2a0a17e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-c4e86ff1-8193-4d2e-ae42-84732e3b80f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-5f8481a5-cfd0-4de5-b0bd-3214f43eccae,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-5561924a-5931-4b05-8552-7d415fb971d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-994a30b9-5845-4431-88c2-2fabb98406d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-b1d6d918-1284-4e41-8b53-0a8d3e8d3944,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-5ce0bdd2-e9d3-4d5c-ab9c-5872086b45c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-749737770-172.17.0.17-1595945089674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37922,DS-28223799-6934-4684-8e35-b2eb89c1d890,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-26a4e150-1fed-4457-9f32-51df98145128,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-e9ecc1b5-c1ab-48c1-a432-68fec95c11ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-55ed33a9-3c24-4aab-b962-28f28826b8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-7dac3b89-95bf-436a-86f7-5ac4a089379c,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-5e1b6fad-6bb8-4f47-a40d-83a26529c1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-78c32d8f-1f5d-4e0e-af00-1b2c80c62692,DISK], DatanodeInfoWithStorage[127.0.0.1:46284,DS-b43e6ee3-28d4-4b15-bd2f-968ba2b3a0f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-749737770-172.17.0.17-1595945089674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37922,DS-28223799-6934-4684-8e35-b2eb89c1d890,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-26a4e150-1fed-4457-9f32-51df98145128,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-e9ecc1b5-c1ab-48c1-a432-68fec95c11ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-55ed33a9-3c24-4aab-b962-28f28826b8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-7dac3b89-95bf-436a-86f7-5ac4a089379c,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-5e1b6fad-6bb8-4f47-a40d-83a26529c1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-78c32d8f-1f5d-4e0e-af00-1b2c80c62692,DISK], DatanodeInfoWithStorage[127.0.0.1:46284,DS-b43e6ee3-28d4-4b15-bd2f-968ba2b3a0f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1880006799-172.17.0.17-1595945491318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34398,DS-3dbf1d45-25a4-44aa-8d3a-5abac1b767de,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-f8481f8f-08ae-4f51-9797-1c1731d8c92d,DISK], DatanodeInfoWithStorage[127.0.0.1:40831,DS-32f19d7d-b8f3-4cc6-99a9-b253eca322c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-734e635f-0fe3-4ef8-abf9-5170555debda,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-56956032-02b6-4ac1-a176-5002f0c42c45,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-d05062e4-c0d1-4d84-9e7d-c8cc299ff098,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-5de68cd5-a610-4f0d-8e04-0f0477424c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-8ce73511-a5bc-4741-ac5c-a71c24c44896,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1880006799-172.17.0.17-1595945491318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34398,DS-3dbf1d45-25a4-44aa-8d3a-5abac1b767de,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-f8481f8f-08ae-4f51-9797-1c1731d8c92d,DISK], DatanodeInfoWithStorage[127.0.0.1:40831,DS-32f19d7d-b8f3-4cc6-99a9-b253eca322c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-734e635f-0fe3-4ef8-abf9-5170555debda,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-56956032-02b6-4ac1-a176-5002f0c42c45,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-d05062e4-c0d1-4d84-9e7d-c8cc299ff098,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-5de68cd5-a610-4f0d-8e04-0f0477424c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-8ce73511-a5bc-4741-ac5c-a71c24c44896,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1652472693-172.17.0.17-1595946046610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39352,DS-d6b5f094-d3ce-4221-bbe4-3f42961487d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34128,DS-5bae1875-4108-4b17-a346-43a0b15e0a21,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-2600dce1-62a7-458b-ac63-0cab7fa52a02,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-9139e30a-530f-4701-bee6-a64d619f5f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-371e5d11-eb72-4d6c-9e0e-eb5506a72445,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-9f0754e9-c870-44a5-a085-18afd576d2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-8569e4ea-a4a6-4b24-a534-678be5d49e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-783a6dda-c959-464d-b34d-8dec8e2409c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1652472693-172.17.0.17-1595946046610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39352,DS-d6b5f094-d3ce-4221-bbe4-3f42961487d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34128,DS-5bae1875-4108-4b17-a346-43a0b15e0a21,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-2600dce1-62a7-458b-ac63-0cab7fa52a02,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-9139e30a-530f-4701-bee6-a64d619f5f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-371e5d11-eb72-4d6c-9e0e-eb5506a72445,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-9f0754e9-c870-44a5-a085-18afd576d2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-8569e4ea-a4a6-4b24-a534-678be5d49e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-783a6dda-c959-464d-b34d-8dec8e2409c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-34589421-172.17.0.17-1595946154220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33214,DS-d6d212bd-7575-4763-9b4e-12df9d5fb22a,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-4b855713-f031-4127-9550-cb6554339020,DISK], DatanodeInfoWithStorage[127.0.0.1:46284,DS-442fc0d8-2dda-423b-9087-57d15ff2784a,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-6eacb33a-e867-4c53-9bb8-33d1f48dff22,DISK], DatanodeInfoWithStorage[127.0.0.1:45146,DS-ad7623ac-6208-4880-9c1c-b8e018990201,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-3600fc66-106a-4237-9ed5-38eaba2ecda5,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-64cfd2f2-f2c8-4b00-8a65-ca58f95d3156,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-caaae0c2-9d3c-48f6-96f5-2e9999faaca1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-34589421-172.17.0.17-1595946154220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33214,DS-d6d212bd-7575-4763-9b4e-12df9d5fb22a,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-4b855713-f031-4127-9550-cb6554339020,DISK], DatanodeInfoWithStorage[127.0.0.1:46284,DS-442fc0d8-2dda-423b-9087-57d15ff2784a,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-6eacb33a-e867-4c53-9bb8-33d1f48dff22,DISK], DatanodeInfoWithStorage[127.0.0.1:45146,DS-ad7623ac-6208-4880-9c1c-b8e018990201,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-3600fc66-106a-4237-9ed5-38eaba2ecda5,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-64cfd2f2-f2c8-4b00-8a65-ca58f95d3156,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-caaae0c2-9d3c-48f6-96f5-2e9999faaca1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-509611487-172.17.0.17-1595946686991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33946,DS-31648805-411f-4588-9856-546beaeb469b,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-cbe929ee-4704-4893-96f9-913a0de55321,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-6c07b050-10d2-412d-a4f0-cc08bf903ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:35399,DS-5da5c3bc-1add-4b75-a442-2313a9f515b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-99f0c5d9-c50b-46ba-bec6-c74c7ab324de,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-b5aa09cf-df33-4ca8-b6d2-8e78379b0c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-757eac3e-b87b-45bd-b8d5-9c3c9fb3da5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-a6294a08-114f-48e5-a85d-f609e0250c74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-509611487-172.17.0.17-1595946686991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33946,DS-31648805-411f-4588-9856-546beaeb469b,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-cbe929ee-4704-4893-96f9-913a0de55321,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-6c07b050-10d2-412d-a4f0-cc08bf903ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:35399,DS-5da5c3bc-1add-4b75-a442-2313a9f515b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-99f0c5d9-c50b-46ba-bec6-c74c7ab324de,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-b5aa09cf-df33-4ca8-b6d2-8e78379b0c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-757eac3e-b87b-45bd-b8d5-9c3c9fb3da5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-a6294a08-114f-48e5-a85d-f609e0250c74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1458215041-172.17.0.17-1595946722968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40647,DS-aa3a5450-9e0c-461f-96ce-2aba43c35fed,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-4212b9d9-d37a-4c1b-aaf6-e8151c1fe1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-b62f27df-5147-4c1d-984a-8e288e599b65,DISK], DatanodeInfoWithStorage[127.0.0.1:43603,DS-f60e6221-5b7f-4676-89df-b924bc64f54f,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-069af63d-0084-4b96-aae7-b1803fb54dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-ecd87b2e-a768-458a-b8bc-327cd93aec62,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-a7c21432-7604-4084-8501-6a783180d5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35585,DS-f36377e9-d656-4e72-b6a6-816f5711b71a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1458215041-172.17.0.17-1595946722968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40647,DS-aa3a5450-9e0c-461f-96ce-2aba43c35fed,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-4212b9d9-d37a-4c1b-aaf6-e8151c1fe1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-b62f27df-5147-4c1d-984a-8e288e599b65,DISK], DatanodeInfoWithStorage[127.0.0.1:43603,DS-f60e6221-5b7f-4676-89df-b924bc64f54f,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-069af63d-0084-4b96-aae7-b1803fb54dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-ecd87b2e-a768-458a-b8bc-327cd93aec62,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-a7c21432-7604-4084-8501-6a783180d5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35585,DS-f36377e9-d656-4e72-b6a6-816f5711b71a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061533620-172.17.0.17-1595947013879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35189,DS-6bcfb9e0-f4cf-40b9-9ffc-698ab992cf88,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-5c2f4e4e-fe87-4e6a-a48f-7ca0d9ee73d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34126,DS-40100086-d792-45aa-a2c3-4b279966d6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-fb6327a8-4954-4869-bc06-6d59ee7bf367,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-e253c122-95a8-47fb-ada9-3b784e50af68,DISK], DatanodeInfoWithStorage[127.0.0.1:37952,DS-af7e4029-e92a-4278-a4e7-9afe1023e5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33455,DS-28b3c9cd-8855-4e41-a0a0-e5af0975b5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-92ccbf2b-ca25-4374-8944-8b2e073c9266,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061533620-172.17.0.17-1595947013879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35189,DS-6bcfb9e0-f4cf-40b9-9ffc-698ab992cf88,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-5c2f4e4e-fe87-4e6a-a48f-7ca0d9ee73d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34126,DS-40100086-d792-45aa-a2c3-4b279966d6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-fb6327a8-4954-4869-bc06-6d59ee7bf367,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-e253c122-95a8-47fb-ada9-3b784e50af68,DISK], DatanodeInfoWithStorage[127.0.0.1:37952,DS-af7e4029-e92a-4278-a4e7-9afe1023e5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33455,DS-28b3c9cd-8855-4e41-a0a0-e5af0975b5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-92ccbf2b-ca25-4374-8944-8b2e073c9266,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-756722026-172.17.0.17-1595947119250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36567,DS-92fe8ddf-ea34-4868-8696-20d7e849060d,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-fba20810-3ba5-481a-880a-da712eda4a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-d2449079-2c05-41ce-b6cd-d69fa3380d82,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-a01d9e27-5ea4-454f-a516-6e1c1d3decda,DISK], DatanodeInfoWithStorage[127.0.0.1:44906,DS-1c00d763-8a93-42c1-92c8-a48a2f8ad36c,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-fff6ed2c-2892-4bb6-b56a-94d80d417711,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-17491e74-81f0-4988-9ec5-e309cafc84f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-499c0cbb-0ada-4a09-9d36-e0fcf7283599,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-756722026-172.17.0.17-1595947119250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36567,DS-92fe8ddf-ea34-4868-8696-20d7e849060d,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-fba20810-3ba5-481a-880a-da712eda4a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-d2449079-2c05-41ce-b6cd-d69fa3380d82,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-a01d9e27-5ea4-454f-a516-6e1c1d3decda,DISK], DatanodeInfoWithStorage[127.0.0.1:44906,DS-1c00d763-8a93-42c1-92c8-a48a2f8ad36c,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-fff6ed2c-2892-4bb6-b56a-94d80d417711,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-17491e74-81f0-4988-9ec5-e309cafc84f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-499c0cbb-0ada-4a09-9d36-e0fcf7283599,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: might be true error
Total execution time in seconds : 5440
