reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688648035-172.17.0.17-1595989914569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32795,DS-c732da75-2a52-460d-bbb8-9b2dfa006619,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-f8edbb39-7ec4-4798-862e-41cc585246fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-99442f60-4cd8-4ed6-8dae-cc13556139f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43303,DS-2a29d05b-c58a-44a7-a5e6-c5dcaf8868e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-ac56823a-acfe-47f0-8fd5-ac831b36a47e,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-90d3b2f9-8ab6-4f81-bf3d-5671c78e7553,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-66fad1d8-a845-43ce-a829-d94e91cf32bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-2133fdba-7839-4852-93b8-e4392ed325cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688648035-172.17.0.17-1595989914569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32795,DS-c732da75-2a52-460d-bbb8-9b2dfa006619,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-f8edbb39-7ec4-4798-862e-41cc585246fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-99442f60-4cd8-4ed6-8dae-cc13556139f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43303,DS-2a29d05b-c58a-44a7-a5e6-c5dcaf8868e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-ac56823a-acfe-47f0-8fd5-ac831b36a47e,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-90d3b2f9-8ab6-4f81-bf3d-5671c78e7553,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-66fad1d8-a845-43ce-a829-d94e91cf32bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-2133fdba-7839-4852-93b8-e4392ed325cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-327036284-172.17.0.17-1595990127155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34913,DS-19f9b61f-056a-41af-b88b-b86522ef8cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-6c7ea1ec-bb8d-47fd-bc67-1f69f90fba9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-9a8473d9-6caf-40be-a605-79ffd8c06cad,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-3923e316-3cf8-4514-b43d-2af1e17233c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-ca965dff-2f47-4776-b3bd-b9b192917424,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-750dc309-5583-4e11-9214-e1721e3ad192,DISK], DatanodeInfoWithStorage[127.0.0.1:40249,DS-918030f3-1f4a-4750-83e3-9a5a42c31794,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-00880ca9-1a7a-4bf2-ac2b-a741c3e7a1cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-327036284-172.17.0.17-1595990127155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34913,DS-19f9b61f-056a-41af-b88b-b86522ef8cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-6c7ea1ec-bb8d-47fd-bc67-1f69f90fba9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-9a8473d9-6caf-40be-a605-79ffd8c06cad,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-3923e316-3cf8-4514-b43d-2af1e17233c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-ca965dff-2f47-4776-b3bd-b9b192917424,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-750dc309-5583-4e11-9214-e1721e3ad192,DISK], DatanodeInfoWithStorage[127.0.0.1:40249,DS-918030f3-1f4a-4750-83e3-9a5a42c31794,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-00880ca9-1a7a-4bf2-ac2b-a741c3e7a1cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1452677868-172.17.0.17-1595991279474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39052,DS-9dc2b008-292a-4c5f-9235-8f5ca673931b,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-46ca612c-a8c7-4c07-af66-16a4b9b2fb71,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-c1ffd512-14e2-46ca-99d4-51c0f1c98163,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-46ebbe76-3c1a-43a5-8a80-654126b6bd84,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-a73e6dcb-faa7-4716-96ce-d5e4fe75d48b,DISK], DatanodeInfoWithStorage[127.0.0.1:35890,DS-56a05c93-e922-4d3f-a506-5242a5d01587,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-def14f72-a148-4142-b8d9-c122177f383d,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-c8b8909c-0307-40d1-9ccd-64bd4e092e06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1452677868-172.17.0.17-1595991279474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39052,DS-9dc2b008-292a-4c5f-9235-8f5ca673931b,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-46ca612c-a8c7-4c07-af66-16a4b9b2fb71,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-c1ffd512-14e2-46ca-99d4-51c0f1c98163,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-46ebbe76-3c1a-43a5-8a80-654126b6bd84,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-a73e6dcb-faa7-4716-96ce-d5e4fe75d48b,DISK], DatanodeInfoWithStorage[127.0.0.1:35890,DS-56a05c93-e922-4d3f-a506-5242a5d01587,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-def14f72-a148-4142-b8d9-c122177f383d,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-c8b8909c-0307-40d1-9ccd-64bd4e092e06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-119421103-172.17.0.17-1595991387977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34095,DS-da78285e-73f5-44cd-8bd8-7d19c9b4c89b,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-a8e5e9b2-3565-4a2c-8e6b-0de2f24883ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-da07a003-16ce-4982-a901-8b0f5c702b32,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-c2f0494e-4619-427c-8cc1-6cab137b1384,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-17f67b92-b5d3-4eeb-8536-43b249337340,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-7e405d64-410a-4822-a14d-221e9e7929b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-89194717-1aad-4746-8587-9932ee53d9da,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-99f98e59-f014-4a8a-9b8d-f56043756395,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-119421103-172.17.0.17-1595991387977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34095,DS-da78285e-73f5-44cd-8bd8-7d19c9b4c89b,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-a8e5e9b2-3565-4a2c-8e6b-0de2f24883ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-da07a003-16ce-4982-a901-8b0f5c702b32,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-c2f0494e-4619-427c-8cc1-6cab137b1384,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-17f67b92-b5d3-4eeb-8536-43b249337340,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-7e405d64-410a-4822-a14d-221e9e7929b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-89194717-1aad-4746-8587-9932ee53d9da,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-99f98e59-f014-4a8a-9b8d-f56043756395,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1275825359-172.17.0.17-1595992109386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34140,DS-de0990cf-afe9-4ec9-a435-f1bfb3a37a28,DISK], DatanodeInfoWithStorage[127.0.0.1:46071,DS-4d3d8e54-9614-4f1a-84d5-dd4d31fcfa64,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-7837ed90-409f-448e-8e1a-85c6126faafa,DISK], DatanodeInfoWithStorage[127.0.0.1:42549,DS-389a1a7b-7c51-45e0-b36b-b689d23104bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-94740e20-f014-488d-9cb2-6335dd7138dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45973,DS-6ad7e3e9-3ba7-4750-89db-632d4129d074,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-ac0c622e-797f-4572-89ca-674a5ff891af,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-42b2fa92-a1e6-4af5-9eef-b0a55c9ebe03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1275825359-172.17.0.17-1595992109386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34140,DS-de0990cf-afe9-4ec9-a435-f1bfb3a37a28,DISK], DatanodeInfoWithStorage[127.0.0.1:46071,DS-4d3d8e54-9614-4f1a-84d5-dd4d31fcfa64,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-7837ed90-409f-448e-8e1a-85c6126faafa,DISK], DatanodeInfoWithStorage[127.0.0.1:42549,DS-389a1a7b-7c51-45e0-b36b-b689d23104bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-94740e20-f014-488d-9cb2-6335dd7138dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45973,DS-6ad7e3e9-3ba7-4750-89db-632d4129d074,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-ac0c622e-797f-4572-89ca-674a5ff891af,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-42b2fa92-a1e6-4af5-9eef-b0a55c9ebe03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1396695651-172.17.0.17-1595992146637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33359,DS-d78f6907-d7f6-40ef-89bd-376d323198c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-5d77c6bb-cf2e-4ce0-9f2f-851c650d5b40,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-f19971e0-05ef-42c7-848e-418eefc398e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-b2ed7257-9a80-475c-b8d5-2e76aad7e069,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-0f1bf28a-2485-4eda-94d5-229f54503ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-ce43e80e-f834-4b30-a402-b1a667a1517b,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-c076781a-723c-446b-826b-7b1851cdddcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-1032d766-a09f-4a44-9e20-0af26eb7d14b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1396695651-172.17.0.17-1595992146637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33359,DS-d78f6907-d7f6-40ef-89bd-376d323198c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-5d77c6bb-cf2e-4ce0-9f2f-851c650d5b40,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-f19971e0-05ef-42c7-848e-418eefc398e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-b2ed7257-9a80-475c-b8d5-2e76aad7e069,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-0f1bf28a-2485-4eda-94d5-229f54503ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-ce43e80e-f834-4b30-a402-b1a667a1517b,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-c076781a-723c-446b-826b-7b1851cdddcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-1032d766-a09f-4a44-9e20-0af26eb7d14b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1035112854-172.17.0.17-1595992370491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37934,DS-1e61cb5e-7c69-48d5-8543-85b48683214b,DISK], DatanodeInfoWithStorage[127.0.0.1:40508,DS-794d07ab-0811-4b46-88ad-ec1f033c921e,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-72b16cd7-dc6a-4fd7-b2c2-372dd1cf1db6,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-ef704e59-2d53-41e6-88b8-dde90a981860,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-e35634e9-78a9-462a-9dfa-925647dcd001,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-831ca15a-5b3e-4c52-85ec-0e82b72c72c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-66528b13-f730-4bbe-a10b-02dbd05a972e,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-56a6a485-1a86-4fc6-83a0-79a7dd7c7246,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1035112854-172.17.0.17-1595992370491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37934,DS-1e61cb5e-7c69-48d5-8543-85b48683214b,DISK], DatanodeInfoWithStorage[127.0.0.1:40508,DS-794d07ab-0811-4b46-88ad-ec1f033c921e,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-72b16cd7-dc6a-4fd7-b2c2-372dd1cf1db6,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-ef704e59-2d53-41e6-88b8-dde90a981860,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-e35634e9-78a9-462a-9dfa-925647dcd001,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-831ca15a-5b3e-4c52-85ec-0e82b72c72c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-66528b13-f730-4bbe-a10b-02dbd05a972e,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-56a6a485-1a86-4fc6-83a0-79a7dd7c7246,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1106916739-172.17.0.17-1595992951139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40023,DS-a651adec-7ab7-4976-8a70-92ada233e25d,DISK], DatanodeInfoWithStorage[127.0.0.1:45528,DS-7e58f18b-b1ed-498b-8566-86ef1986abde,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-a55eeb18-e0b2-4abc-9989-009b219e8ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:38775,DS-b3727038-f0fc-40c4-bbd2-44baacd80c97,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-afe3d926-a6c0-4ed6-9499-198d73d6b030,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-a4bfa001-4f44-426a-84db-55ff9f2d13a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36692,DS-d5d50e17-4741-4129-8c84-30679278e645,DISK], DatanodeInfoWithStorage[127.0.0.1:43310,DS-6508687f-a2fc-48dc-ad96-1d25d9e2fe6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1106916739-172.17.0.17-1595992951139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40023,DS-a651adec-7ab7-4976-8a70-92ada233e25d,DISK], DatanodeInfoWithStorage[127.0.0.1:45528,DS-7e58f18b-b1ed-498b-8566-86ef1986abde,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-a55eeb18-e0b2-4abc-9989-009b219e8ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:38775,DS-b3727038-f0fc-40c4-bbd2-44baacd80c97,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-afe3d926-a6c0-4ed6-9499-198d73d6b030,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-a4bfa001-4f44-426a-84db-55ff9f2d13a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36692,DS-d5d50e17-4741-4129-8c84-30679278e645,DISK], DatanodeInfoWithStorage[127.0.0.1:43310,DS-6508687f-a2fc-48dc-ad96-1d25d9e2fe6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1351683914-172.17.0.17-1595993470216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37279,DS-a48ac249-57ed-4015-81fa-d047cf85dee3,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-cb91e141-cdcf-47e3-96f3-7321aac65fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-b5b00eef-1e7f-4654-ab93-f37da4a5d8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-b339e1b5-3141-4784-a18a-16481c0ab37b,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-e3a8c8f4-099e-43f1-9b46-d0b8c59218ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-aad9d399-626d-4249-91ed-7aaf5dd1cb93,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-b12fcbb0-557b-41aa-b5b1-6be6bf145396,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-42f75d80-2b03-480f-9f94-7114a90671dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1351683914-172.17.0.17-1595993470216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37279,DS-a48ac249-57ed-4015-81fa-d047cf85dee3,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-cb91e141-cdcf-47e3-96f3-7321aac65fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-b5b00eef-1e7f-4654-ab93-f37da4a5d8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-b339e1b5-3141-4784-a18a-16481c0ab37b,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-e3a8c8f4-099e-43f1-9b46-d0b8c59218ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-aad9d399-626d-4249-91ed-7aaf5dd1cb93,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-b12fcbb0-557b-41aa-b5b1-6be6bf145396,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-42f75d80-2b03-480f-9f94-7114a90671dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1987156698-172.17.0.17-1595994455247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37281,DS-36212158-5eca-42ef-95f0-a0fdfdd7b81f,DISK], DatanodeInfoWithStorage[127.0.0.1:41187,DS-8a3c6c73-4072-41f5-bce2-4be5c2dad76f,DISK], DatanodeInfoWithStorage[127.0.0.1:40506,DS-11405c68-ee10-4325-aa70-4f10fdb49eef,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-0bfde5bb-c121-470b-9d7b-d3f06afea651,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-f87a5ea0-5374-4345-aaab-a77765e274b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-9b031db5-d81c-4411-b775-d8b289689960,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-e0564849-7d25-4b63-9c20-c391c0276246,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-b7aa11f2-3474-448b-952a-4cf3b7d9dbe0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1987156698-172.17.0.17-1595994455247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37281,DS-36212158-5eca-42ef-95f0-a0fdfdd7b81f,DISK], DatanodeInfoWithStorage[127.0.0.1:41187,DS-8a3c6c73-4072-41f5-bce2-4be5c2dad76f,DISK], DatanodeInfoWithStorage[127.0.0.1:40506,DS-11405c68-ee10-4325-aa70-4f10fdb49eef,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-0bfde5bb-c121-470b-9d7b-d3f06afea651,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-f87a5ea0-5374-4345-aaab-a77765e274b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-9b031db5-d81c-4411-b775-d8b289689960,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-e0564849-7d25-4b63-9c20-c391c0276246,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-b7aa11f2-3474-448b-952a-4cf3b7d9dbe0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1173048944-172.17.0.17-1595994800024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43808,DS-71f325f5-f66d-43e3-a058-239e362ff976,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-7672a6f8-c7f5-40a0-8406-2e02da600863,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-e8d51c13-f1b5-4abc-b77d-64789f232597,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-7cf14f52-4ffa-4356-b447-93e8ce6bf063,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-d811335b-7413-4440-973c-326466abc718,DISK], DatanodeInfoWithStorage[127.0.0.1:38144,DS-e17eab46-5bd8-4f6f-bdfa-e0e14afbcf13,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-4223b376-e7be-41e5-bd9f-12c519dc6b47,DISK], DatanodeInfoWithStorage[127.0.0.1:33229,DS-bcc5ae3c-8466-46d0-b75d-bedbb918daab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1173048944-172.17.0.17-1595994800024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43808,DS-71f325f5-f66d-43e3-a058-239e362ff976,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-7672a6f8-c7f5-40a0-8406-2e02da600863,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-e8d51c13-f1b5-4abc-b77d-64789f232597,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-7cf14f52-4ffa-4356-b447-93e8ce6bf063,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-d811335b-7413-4440-973c-326466abc718,DISK], DatanodeInfoWithStorage[127.0.0.1:38144,DS-e17eab46-5bd8-4f6f-bdfa-e0e14afbcf13,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-4223b376-e7be-41e5-bd9f-12c519dc6b47,DISK], DatanodeInfoWithStorage[127.0.0.1:33229,DS-bcc5ae3c-8466-46d0-b75d-bedbb918daab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-27269184-172.17.0.17-1595995158897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38289,DS-56d9a9f5-9393-4c25-9e3b-5a155135dbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-3bef5507-2e86-42ca-9e51-bc42887fe4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-b7959333-1b69-42bb-8de9-872230bfe98f,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-d7848e9b-91bd-4135-9b9c-f7b70b1163f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-85b3ba75-fba5-4cd4-b58b-026b9cb30788,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-e2020766-8337-4642-a8cc-c109a9059448,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-cfc98006-f2b9-4131-a61d-aa6a335547df,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-29021dbf-84ee-41f4-81ff-46a589483331,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-27269184-172.17.0.17-1595995158897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38289,DS-56d9a9f5-9393-4c25-9e3b-5a155135dbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-3bef5507-2e86-42ca-9e51-bc42887fe4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-b7959333-1b69-42bb-8de9-872230bfe98f,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-d7848e9b-91bd-4135-9b9c-f7b70b1163f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-85b3ba75-fba5-4cd4-b58b-026b9cb30788,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-e2020766-8337-4642-a8cc-c109a9059448,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-cfc98006-f2b9-4131-a61d-aa6a335547df,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-29021dbf-84ee-41f4-81ff-46a589483331,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5722
