reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2096936477-172.17.0.21-1595845069667:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38482,DS-520eb226-4918-47d7-b9a2-58c2b5f3b5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-2bae5e97-0e97-4a6d-b17d-2c0d5b51fe57,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-0ac7ab4e-089d-4491-b0bf-3713fb61c425,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-6efae40d-0dff-4552-9022-f4e0f729ad1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-195d8e66-a887-4b3c-a751-1b114e000852,DISK], DatanodeInfoWithStorage[127.0.0.1:37067,DS-0b66a734-3078-4044-9900-1ffb817fab16,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-12f8a4b3-d463-41fa-9e64-5d6961047548,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-0422be7f-16cd-4445-ae16-d163a22e66a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2096936477-172.17.0.21-1595845069667:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38482,DS-520eb226-4918-47d7-b9a2-58c2b5f3b5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-2bae5e97-0e97-4a6d-b17d-2c0d5b51fe57,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-0ac7ab4e-089d-4491-b0bf-3713fb61c425,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-6efae40d-0dff-4552-9022-f4e0f729ad1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-195d8e66-a887-4b3c-a751-1b114e000852,DISK], DatanodeInfoWithStorage[127.0.0.1:37067,DS-0b66a734-3078-4044-9900-1ffb817fab16,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-12f8a4b3-d463-41fa-9e64-5d6961047548,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-0422be7f-16cd-4445-ae16-d163a22e66a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-919701390-172.17.0.21-1595845683732:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39143,DS-7f766f4e-86f5-4508-bda1-dbfeeeae34b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37040,DS-80d3ae7e-e821-4960-98d1-d70c9193ec6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-c1019c4b-0ce9-45d8-852f-f9de5d0c2972,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-5d82230c-cc65-4605-a979-c545ccc88392,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-da8a0c45-54d5-4114-a0dd-2956cd364f98,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-902a2791-d434-436c-bfe6-a36984cf946b,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-ae6ba9be-bb61-4d91-a9b3-c52ba257a8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-4ec3835b-5a82-4c4c-8a84-d660ab4f3c14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-919701390-172.17.0.21-1595845683732:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39143,DS-7f766f4e-86f5-4508-bda1-dbfeeeae34b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37040,DS-80d3ae7e-e821-4960-98d1-d70c9193ec6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-c1019c4b-0ce9-45d8-852f-f9de5d0c2972,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-5d82230c-cc65-4605-a979-c545ccc88392,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-da8a0c45-54d5-4114-a0dd-2956cd364f98,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-902a2791-d434-436c-bfe6-a36984cf946b,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-ae6ba9be-bb61-4d91-a9b3-c52ba257a8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-4ec3835b-5a82-4c4c-8a84-d660ab4f3c14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1285063621-172.17.0.21-1595845721655:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37359,DS-beb00060-bbce-423f-aec6-a88b051ec357,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-49959683-f074-40cc-82ec-a963b0a7dd82,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-6c6fa074-0db2-4b35-afd3-7dfcb8c43989,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-8c3b54b2-d419-49b5-9e9f-be3886606d93,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-57190067-f3a0-4878-bed1-43499b9432e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-b2468d26-03c0-48cc-b898-12a9bbb23f09,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-efe7d899-6c48-4a77-827f-e8060e4f6b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-abe1aa67-d88d-42b8-b4dd-f63105e297f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1285063621-172.17.0.21-1595845721655:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37359,DS-beb00060-bbce-423f-aec6-a88b051ec357,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-49959683-f074-40cc-82ec-a963b0a7dd82,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-6c6fa074-0db2-4b35-afd3-7dfcb8c43989,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-8c3b54b2-d419-49b5-9e9f-be3886606d93,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-57190067-f3a0-4878-bed1-43499b9432e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-b2468d26-03c0-48cc-b898-12a9bbb23f09,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-efe7d899-6c48-4a77-827f-e8060e4f6b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-abe1aa67-d88d-42b8-b4dd-f63105e297f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1919978157-172.17.0.21-1595845849188:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36599,DS-bcae2c56-cbfb-4424-8d49-2778abfea249,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-e91d1c46-b289-4467-a80a-a75a84841e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-21de6230-f9db-4743-85ff-8a45968d5d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46004,DS-609e820e-b437-424e-93e6-b1e11547baa0,DISK], DatanodeInfoWithStorage[127.0.0.1:42523,DS-b7cf59d7-9ed8-4811-9817-7b45c4abfba2,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-8e0a7c83-7447-4108-87f0-1a6e241d27b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-321c2b0c-8083-4437-b63a-48871d77f5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-16fe17bf-bf64-4145-a697-fe45e7821535,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1919978157-172.17.0.21-1595845849188:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36599,DS-bcae2c56-cbfb-4424-8d49-2778abfea249,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-e91d1c46-b289-4467-a80a-a75a84841e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-21de6230-f9db-4743-85ff-8a45968d5d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46004,DS-609e820e-b437-424e-93e6-b1e11547baa0,DISK], DatanodeInfoWithStorage[127.0.0.1:42523,DS-b7cf59d7-9ed8-4811-9817-7b45c4abfba2,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-8e0a7c83-7447-4108-87f0-1a6e241d27b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-321c2b0c-8083-4437-b63a-48871d77f5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-16fe17bf-bf64-4145-a697-fe45e7821535,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1491406583-172.17.0.21-1595846129441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37113,DS-d68914ae-6cd6-4619-8b48-9aca411993fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-de667ddd-a53f-478d-994e-59ad6ecd8a46,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-690752e4-d9ef-4ce2-9698-23d99cf06353,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-a2934d06-3766-4e71-be6d-9c9dcb7a9dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-2a14a2a9-d744-48ca-98f0-cb793a18e4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-d37b3904-d1ff-4867-b0fd-51ad2b022821,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-af26aff0-004e-4fcd-9e9f-e1952149d2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-35b1bac7-8160-405f-a747-fbe6ebe68a74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1491406583-172.17.0.21-1595846129441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37113,DS-d68914ae-6cd6-4619-8b48-9aca411993fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-de667ddd-a53f-478d-994e-59ad6ecd8a46,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-690752e4-d9ef-4ce2-9698-23d99cf06353,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-a2934d06-3766-4e71-be6d-9c9dcb7a9dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-2a14a2a9-d744-48ca-98f0-cb793a18e4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-d37b3904-d1ff-4867-b0fd-51ad2b022821,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-af26aff0-004e-4fcd-9e9f-e1952149d2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-35b1bac7-8160-405f-a747-fbe6ebe68a74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-809622316-172.17.0.21-1595846729903:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44758,DS-5d2cc19d-62c1-4dfc-99e9-22c9e041d052,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-14c6d43d-f0d8-407c-b9fc-5c53f77ad790,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-5e25309f-042a-4df3-910f-5fca4b2de57e,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-cc36f29a-a9c8-46f7-af02-560322a01f49,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-9fbdcaf9-5dfe-44e9-97ba-40d6847ac0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37958,DS-034fa93b-b421-4e32-a895-1c6670223909,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-a4833e7f-0a29-4077-ae63-8b0c9dae4478,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-a24e2b2e-a63a-45ed-a7d6-ca7025915629,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-809622316-172.17.0.21-1595846729903:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44758,DS-5d2cc19d-62c1-4dfc-99e9-22c9e041d052,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-14c6d43d-f0d8-407c-b9fc-5c53f77ad790,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-5e25309f-042a-4df3-910f-5fca4b2de57e,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-cc36f29a-a9c8-46f7-af02-560322a01f49,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-9fbdcaf9-5dfe-44e9-97ba-40d6847ac0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37958,DS-034fa93b-b421-4e32-a895-1c6670223909,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-a4833e7f-0a29-4077-ae63-8b0c9dae4478,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-a24e2b2e-a63a-45ed-a7d6-ca7025915629,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1788899519-172.17.0.21-1595846867217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34484,DS-1d351147-ce90-417b-bc50-6f99d7500b99,DISK], DatanodeInfoWithStorage[127.0.0.1:32990,DS-3f62d805-9700-4bc5-9108-13a4d0adf2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41508,DS-f869b73c-bb62-40fa-9aa2-b742158c3d15,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-3ed02abd-8d27-4bb5-ab49-00c48244f0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-f86fbf36-c1e6-4f1f-af1b-45b2eb190ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-96b508c6-99b1-47c5-a97a-165c27480a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-416cb382-4f02-4db3-9151-ed0554dfc92b,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-da126405-86a9-47e1-9cb4-2bc62250404c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1788899519-172.17.0.21-1595846867217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34484,DS-1d351147-ce90-417b-bc50-6f99d7500b99,DISK], DatanodeInfoWithStorage[127.0.0.1:32990,DS-3f62d805-9700-4bc5-9108-13a4d0adf2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41508,DS-f869b73c-bb62-40fa-9aa2-b742158c3d15,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-3ed02abd-8d27-4bb5-ab49-00c48244f0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-f86fbf36-c1e6-4f1f-af1b-45b2eb190ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-96b508c6-99b1-47c5-a97a-165c27480a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-416cb382-4f02-4db3-9151-ed0554dfc92b,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-da126405-86a9-47e1-9cb4-2bc62250404c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1977042620-172.17.0.21-1595848201925:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35188,DS-e80436df-7e81-4cb9-90e4-300abb6bbfe9,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-b7868ff0-d915-4f26-b325-b156e0e95638,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-2d999f32-5376-4b99-8377-670c6080e21e,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-d5efdf38-1a30-4944-91b0-e1e383a3df8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-0b814e72-8c94-436d-b2cb-c6d41deeaff0,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-5b31a280-aaaf-489e-8d37-0cada6cbdb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-7f202455-164a-42f0-837b-e24b7b3600bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-dce8eac4-ad3d-4002-8122-ee30caacdb00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1977042620-172.17.0.21-1595848201925:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35188,DS-e80436df-7e81-4cb9-90e4-300abb6bbfe9,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-b7868ff0-d915-4f26-b325-b156e0e95638,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-2d999f32-5376-4b99-8377-670c6080e21e,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-d5efdf38-1a30-4944-91b0-e1e383a3df8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-0b814e72-8c94-436d-b2cb-c6d41deeaff0,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-5b31a280-aaaf-489e-8d37-0cada6cbdb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-7f202455-164a-42f0-837b-e24b7b3600bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-dce8eac4-ad3d-4002-8122-ee30caacdb00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-653438434-172.17.0.21-1595849013919:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41475,DS-7dcb6a9d-918d-49e7-a6a9-273e3715188c,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-0e81295b-d7f9-4e3c-a177-e24592d92045,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-a3e7fe7e-da8b-4bc8-9efe-e98ce1594bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46430,DS-c0b4704d-4c26-4b21-9e8a-873d5b5a5a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37338,DS-0ee82522-d27d-477a-8bf1-1df2252c3636,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-adc21dad-ce9a-4f89-9789-e1199ba5f951,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-304363c2-ddd4-421e-9061-a44da347d498,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-f337ed0c-e5b0-4f05-9166-74fa641a84fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-653438434-172.17.0.21-1595849013919:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41475,DS-7dcb6a9d-918d-49e7-a6a9-273e3715188c,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-0e81295b-d7f9-4e3c-a177-e24592d92045,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-a3e7fe7e-da8b-4bc8-9efe-e98ce1594bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46430,DS-c0b4704d-4c26-4b21-9e8a-873d5b5a5a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37338,DS-0ee82522-d27d-477a-8bf1-1df2252c3636,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-adc21dad-ce9a-4f89-9789-e1199ba5f951,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-304363c2-ddd4-421e-9061-a44da347d498,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-f337ed0c-e5b0-4f05-9166-74fa641a84fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-166501563-172.17.0.21-1595849330699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38119,DS-e698a5a4-2ecb-4cab-8055-ae04e56383ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-d0bb3d56-6e5b-4d0a-86aa-4837830906a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-1d368d74-3005-4326-9d8f-d104c8982ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:39059,DS-e0fb7665-e5b8-450f-8526-f7e789cbef95,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-fbf1a5ea-c62b-4f61-bc23-ffdc3fdccc5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-610881ba-cacf-4d0a-b6d8-4fc5629a683a,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-ae28cfbb-9a6f-4a58-aafc-57f81a77b66a,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-a0d5994b-8ce4-4eb0-83f7-66faadc47dc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-166501563-172.17.0.21-1595849330699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38119,DS-e698a5a4-2ecb-4cab-8055-ae04e56383ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-d0bb3d56-6e5b-4d0a-86aa-4837830906a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-1d368d74-3005-4326-9d8f-d104c8982ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:39059,DS-e0fb7665-e5b8-450f-8526-f7e789cbef95,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-fbf1a5ea-c62b-4f61-bc23-ffdc3fdccc5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-610881ba-cacf-4d0a-b6d8-4fc5629a683a,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-ae28cfbb-9a6f-4a58-aafc-57f81a77b66a,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-a0d5994b-8ce4-4eb0-83f7-66faadc47dc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1251879099-172.17.0.21-1595849697294:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35506,DS-bd3d50db-cbde-4b35-9b51-a47faa11c380,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-d02972b7-c15b-4788-9acc-2db48c766348,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-d9cd646a-db0d-4b76-82d4-25cc55324d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-37df8c99-47f6-4de7-9062-9a3e7e914425,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-42ad47a0-4b1a-478e-9dd1-000e92e034a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-7d4f6871-e970-4642-8264-41a9323262d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-e91c0430-fab6-4163-ae71-a42d0f868621,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-53155be2-04c4-4adf-b7ab-567b3631b1af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1251879099-172.17.0.21-1595849697294:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35506,DS-bd3d50db-cbde-4b35-9b51-a47faa11c380,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-d02972b7-c15b-4788-9acc-2db48c766348,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-d9cd646a-db0d-4b76-82d4-25cc55324d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-37df8c99-47f6-4de7-9062-9a3e7e914425,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-42ad47a0-4b1a-478e-9dd1-000e92e034a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-7d4f6871-e970-4642-8264-41a9323262d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-e91c0430-fab6-4163-ae71-a42d0f868621,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-53155be2-04c4-4adf-b7ab-567b3631b1af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-373328246-172.17.0.21-1595849938266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33839,DS-132e81fe-171e-454a-a551-6dded531247e,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-ba21a580-5cec-4b1a-b714-5a1d6833c5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:32778,DS-c573e4ab-6868-495d-aa05-39c6226aec10,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-e9079360-6ecb-40a1-ad38-cdfc033f3af2,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-6126ba64-50d9-4bd1-80cc-96f5f4808ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-08ae18b4-5cb0-49fe-b256-ba51e9b85a58,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-3e2e145e-281e-4933-a68b-b6ea3bcd2970,DISK], DatanodeInfoWithStorage[127.0.0.1:35348,DS-248b8452-7dfa-4494-a0a9-9759dbf0968d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-373328246-172.17.0.21-1595849938266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33839,DS-132e81fe-171e-454a-a551-6dded531247e,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-ba21a580-5cec-4b1a-b714-5a1d6833c5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:32778,DS-c573e4ab-6868-495d-aa05-39c6226aec10,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-e9079360-6ecb-40a1-ad38-cdfc033f3af2,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-6126ba64-50d9-4bd1-80cc-96f5f4808ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-08ae18b4-5cb0-49fe-b256-ba51e9b85a58,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-3e2e145e-281e-4933-a68b-b6ea3bcd2970,DISK], DatanodeInfoWithStorage[127.0.0.1:35348,DS-248b8452-7dfa-4494-a0a9-9759dbf0968d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: might be true error
Total execution time in seconds : 4902
