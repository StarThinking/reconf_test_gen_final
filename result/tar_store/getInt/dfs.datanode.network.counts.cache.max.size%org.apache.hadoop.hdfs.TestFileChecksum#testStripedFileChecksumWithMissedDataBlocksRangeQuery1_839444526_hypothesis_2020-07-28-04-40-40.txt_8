reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-151251362-172.17.0.13-1595911590836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35613,DS-f4645213-68b4-46ff-855c-2d940e9415dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-2a405c24-5f3a-4e48-93b2-fd6a937e57b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-1185c21b-3da5-4cef-be93-37cfc24d7228,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-03674f52-5003-4ec7-b3b6-c9f8c8a47cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-99f7829b-43c5-4c96-9911-440d7cefdae5,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-9584923f-574a-47c9-a82c-7e380cb0d6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-a3a07436-2f06-4828-a175-72cba885c638,DISK], DatanodeInfoWithStorage[127.0.0.1:33084,DS-9a99f675-3c26-4d90-b40f-0abc48229fe4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-151251362-172.17.0.13-1595911590836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35613,DS-f4645213-68b4-46ff-855c-2d940e9415dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-2a405c24-5f3a-4e48-93b2-fd6a937e57b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-1185c21b-3da5-4cef-be93-37cfc24d7228,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-03674f52-5003-4ec7-b3b6-c9f8c8a47cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-99f7829b-43c5-4c96-9911-440d7cefdae5,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-9584923f-574a-47c9-a82c-7e380cb0d6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-a3a07436-2f06-4828-a175-72cba885c638,DISK], DatanodeInfoWithStorage[127.0.0.1:33084,DS-9a99f675-3c26-4d90-b40f-0abc48229fe4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-811905464-172.17.0.13-1595911768626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35454,DS-6d97c3d5-2895-4274-8967-10eaae89007f,DISK], DatanodeInfoWithStorage[127.0.0.1:36516,DS-b47c51a7-aaea-4951-ae47-9b4d4364e1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-cf917d9e-07e8-4245-909d-82e4a23d86dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-15eadda1-9033-42f4-8480-03ee8f7eebe5,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-d45e48fb-7e34-43dd-bf4d-22441c2d6a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-196008bb-c872-40ea-b294-63506f585b47,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-f2337359-de34-4700-81a0-73b9640e7027,DISK], DatanodeInfoWithStorage[127.0.0.1:37656,DS-d08380b0-30e3-441d-94a1-f361252d55e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-811905464-172.17.0.13-1595911768626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35454,DS-6d97c3d5-2895-4274-8967-10eaae89007f,DISK], DatanodeInfoWithStorage[127.0.0.1:36516,DS-b47c51a7-aaea-4951-ae47-9b4d4364e1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-cf917d9e-07e8-4245-909d-82e4a23d86dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-15eadda1-9033-42f4-8480-03ee8f7eebe5,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-d45e48fb-7e34-43dd-bf4d-22441c2d6a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-196008bb-c872-40ea-b294-63506f585b47,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-f2337359-de34-4700-81a0-73b9640e7027,DISK], DatanodeInfoWithStorage[127.0.0.1:37656,DS-d08380b0-30e3-441d-94a1-f361252d55e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1798089041-172.17.0.13-1595911838515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41080,DS-50419767-8f3c-4c9e-b0f9-c4db17e01505,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-06cb436e-050f-4f0e-bdf4-1911b964edb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-ec54cb3e-a300-47f5-ac23-bed9e2dc56fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-41f23662-4316-4beb-b1e9-54092eb11276,DISK], DatanodeInfoWithStorage[127.0.0.1:41379,DS-c0ffae93-b3ff-42a3-afc6-b8fc237efbfb,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-bc14a5b9-b808-42c5-9691-f7d25be224ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37082,DS-00c28c04-3422-4fcf-a160-fa868b129f20,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-83a6cd83-e4ce-484e-8d2e-16774389d4da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1798089041-172.17.0.13-1595911838515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41080,DS-50419767-8f3c-4c9e-b0f9-c4db17e01505,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-06cb436e-050f-4f0e-bdf4-1911b964edb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-ec54cb3e-a300-47f5-ac23-bed9e2dc56fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-41f23662-4316-4beb-b1e9-54092eb11276,DISK], DatanodeInfoWithStorage[127.0.0.1:41379,DS-c0ffae93-b3ff-42a3-afc6-b8fc237efbfb,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-bc14a5b9-b808-42c5-9691-f7d25be224ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37082,DS-00c28c04-3422-4fcf-a160-fa868b129f20,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-83a6cd83-e4ce-484e-8d2e-16774389d4da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1692989802-172.17.0.13-1595912201470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40983,DS-3ac4bad8-eac1-4951-b009-475256c7d375,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-4dc7bb67-9469-4fd6-97f3-7ced2bad12fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-bc144800-209c-4227-8d12-83cf2ba1ef50,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-f2a251c3-79b5-42dd-8661-90e6ab2f38aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46181,DS-234448b1-7f64-419c-9ff1-5436aa9dbc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-b1a95977-ba9c-44f3-ad49-18a2efe2a9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-4400fc42-177c-43d1-9bf4-0ea0f608cb15,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-ba785ca3-28dd-4561-948c-1b80131f0ce8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1692989802-172.17.0.13-1595912201470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40983,DS-3ac4bad8-eac1-4951-b009-475256c7d375,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-4dc7bb67-9469-4fd6-97f3-7ced2bad12fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-bc144800-209c-4227-8d12-83cf2ba1ef50,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-f2a251c3-79b5-42dd-8661-90e6ab2f38aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46181,DS-234448b1-7f64-419c-9ff1-5436aa9dbc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-b1a95977-ba9c-44f3-ad49-18a2efe2a9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-4400fc42-177c-43d1-9bf4-0ea0f608cb15,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-ba785ca3-28dd-4561-948c-1b80131f0ce8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1904163578-172.17.0.13-1595912238430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39498,DS-ed8332fe-7cd3-4a4a-a63d-04f158bd578a,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-8cc1e812-c10d-4015-9c27-6e8ce06c76e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-75cdb027-7328-4f53-991f-e07917940e99,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-ad783f1d-feed-4cb1-a6c9-32c7c50ac0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-28af11f4-e067-4879-a275-606550b7d888,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-8b4f8aa0-abed-4a9e-8acd-a83397d1d353,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-d582c70c-8bbe-49af-90fb-6b6631c347f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39231,DS-058eaa55-e84f-4243-9d39-4cdbc7030f64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1904163578-172.17.0.13-1595912238430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39498,DS-ed8332fe-7cd3-4a4a-a63d-04f158bd578a,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-8cc1e812-c10d-4015-9c27-6e8ce06c76e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-75cdb027-7328-4f53-991f-e07917940e99,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-ad783f1d-feed-4cb1-a6c9-32c7c50ac0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-28af11f4-e067-4879-a275-606550b7d888,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-8b4f8aa0-abed-4a9e-8acd-a83397d1d353,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-d582c70c-8bbe-49af-90fb-6b6631c347f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39231,DS-058eaa55-e84f-4243-9d39-4cdbc7030f64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-323333291-172.17.0.13-1595912607793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40228,DS-65227a93-5e79-4179-91fe-2f7e719ef408,DISK], DatanodeInfoWithStorage[127.0.0.1:33455,DS-9ec756bc-3032-4267-9008-e163d281c16c,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-1a2445b3-4acf-4b6e-93c4-16e041ed9083,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-bddd8449-171d-4386-b414-9f2a08030fac,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-df709314-96e8-4c91-bb96-90793311fc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33624,DS-abe34342-9edc-441e-9ae8-016684be6383,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-68dfc9b7-9228-490e-84da-da5c5afbb649,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-dcd1c045-c194-4b5d-a03b-f4a2e45c8a6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-323333291-172.17.0.13-1595912607793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40228,DS-65227a93-5e79-4179-91fe-2f7e719ef408,DISK], DatanodeInfoWithStorage[127.0.0.1:33455,DS-9ec756bc-3032-4267-9008-e163d281c16c,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-1a2445b3-4acf-4b6e-93c4-16e041ed9083,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-bddd8449-171d-4386-b414-9f2a08030fac,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-df709314-96e8-4c91-bb96-90793311fc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33624,DS-abe34342-9edc-441e-9ae8-016684be6383,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-68dfc9b7-9228-490e-84da-da5c5afbb649,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-dcd1c045-c194-4b5d-a03b-f4a2e45c8a6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109161509-172.17.0.13-1595913415212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33893,DS-9ac67cd2-5d6d-49dd-86ca-3be3f97eaf67,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-10ee471f-afdd-4a9a-826f-a6ce36ce5916,DISK], DatanodeInfoWithStorage[127.0.0.1:33476,DS-f549ef7e-4e54-4aea-a1a0-84b403c8b0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37048,DS-d0c89a58-fde0-436c-919a-0d99ad682a07,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-223c7cb7-f2f2-45c1-9548-104c132627ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-ecd1f45d-a66d-40c0-9b6d-c8bfe39a6460,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-28aa84a9-8677-45f7-9f35-5dab2fa5863b,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-6329bd8d-42b2-4ca4-86cd-9e78e70c3ff6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109161509-172.17.0.13-1595913415212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33893,DS-9ac67cd2-5d6d-49dd-86ca-3be3f97eaf67,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-10ee471f-afdd-4a9a-826f-a6ce36ce5916,DISK], DatanodeInfoWithStorage[127.0.0.1:33476,DS-f549ef7e-4e54-4aea-a1a0-84b403c8b0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37048,DS-d0c89a58-fde0-436c-919a-0d99ad682a07,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-223c7cb7-f2f2-45c1-9548-104c132627ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-ecd1f45d-a66d-40c0-9b6d-c8bfe39a6460,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-28aa84a9-8677-45f7-9f35-5dab2fa5863b,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-6329bd8d-42b2-4ca4-86cd-9e78e70c3ff6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-978932007-172.17.0.13-1595913963171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39464,DS-ebe12ae7-e43a-49f7-8361-8870165313a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37972,DS-08659126-7415-4217-ab46-c01a38c297c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-84002524-f995-4b15-bc23-cb51343fb8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-f4942494-b8e9-4f1b-9d75-3006815c213a,DISK], DatanodeInfoWithStorage[127.0.0.1:42396,DS-d2012706-fa8b-4431-a7e9-3d4243cc29e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-097a3773-2b2a-44ca-b574-c56ac6afc371,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-fde43d79-6759-4f7b-874b-7d844ce496ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33734,DS-10120412-061d-4778-b1a4-bd1425c00db2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-978932007-172.17.0.13-1595913963171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39464,DS-ebe12ae7-e43a-49f7-8361-8870165313a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37972,DS-08659126-7415-4217-ab46-c01a38c297c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-84002524-f995-4b15-bc23-cb51343fb8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-f4942494-b8e9-4f1b-9d75-3006815c213a,DISK], DatanodeInfoWithStorage[127.0.0.1:42396,DS-d2012706-fa8b-4431-a7e9-3d4243cc29e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-097a3773-2b2a-44ca-b574-c56ac6afc371,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-fde43d79-6759-4f7b-874b-7d844ce496ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33734,DS-10120412-061d-4778-b1a4-bd1425c00db2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183495984-172.17.0.13-1595914840359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38085,DS-d784e311-154a-44d1-9649-037406677718,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-46ab5696-7183-4f6a-bf37-d219bb215134,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-08e009f8-af01-4dad-9f69-5e21cf9dfcf7,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-d5d3be34-93ee-4011-8bbf-4777bd82aad9,DISK], DatanodeInfoWithStorage[127.0.0.1:41438,DS-480bb140-4467-4bba-b2dc-af0abb7acfb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-3473d2e0-6535-4462-846f-dcf5c8cfaef9,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-0266bcd1-3fab-422c-b7db-7cebf942d245,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-8923ff3d-9453-4816-b81d-82ec95a6919a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183495984-172.17.0.13-1595914840359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38085,DS-d784e311-154a-44d1-9649-037406677718,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-46ab5696-7183-4f6a-bf37-d219bb215134,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-08e009f8-af01-4dad-9f69-5e21cf9dfcf7,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-d5d3be34-93ee-4011-8bbf-4777bd82aad9,DISK], DatanodeInfoWithStorage[127.0.0.1:41438,DS-480bb140-4467-4bba-b2dc-af0abb7acfb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-3473d2e0-6535-4462-846f-dcf5c8cfaef9,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-0266bcd1-3fab-422c-b7db-7cebf942d245,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-8923ff3d-9453-4816-b81d-82ec95a6919a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-464060237-172.17.0.13-1595914886936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33713,DS-df6d8e15-d43e-42e2-93f4-3b12c85bcbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-340e7d17-a2dd-4425-aece-e886b2408b43,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-cc5c73e3-baba-4b9a-be22-490ea9b7cb67,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-c3ee6fbe-410c-49d0-bcea-2580512e77f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44110,DS-6196e03b-163c-4872-b4d7-9f5e88446141,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-fbdbb037-d4b5-4d00-8ebd-ea51ca386961,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-3bfe43db-1bb9-4dba-8688-b38308828e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-64cdbaf6-ccb7-4132-969a-ef3d2506a0c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-464060237-172.17.0.13-1595914886936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33713,DS-df6d8e15-d43e-42e2-93f4-3b12c85bcbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-340e7d17-a2dd-4425-aece-e886b2408b43,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-cc5c73e3-baba-4b9a-be22-490ea9b7cb67,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-c3ee6fbe-410c-49d0-bcea-2580512e77f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44110,DS-6196e03b-163c-4872-b4d7-9f5e88446141,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-fbdbb037-d4b5-4d00-8ebd-ea51ca386961,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-3bfe43db-1bb9-4dba-8688-b38308828e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-64cdbaf6-ccb7-4132-969a-ef3d2506a0c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1451155918-172.17.0.13-1595915078626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37077,DS-39e51335-6f5a-4ebc-85a3-d14c354ac32e,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-314105a3-4a06-4ec2-8380-a54ac5b9f4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-1285399f-b9e6-44e7-903f-6d64c2ee5146,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-14da4faa-a12c-43d3-8f26-c927a4273c14,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-4be32f34-53f5-431f-8110-43b10dcc222a,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-a12b7f1c-b04e-4e7a-b691-d58d308ac1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-1e3fe8ae-7123-4ae5-b00f-3e11f4c6fac0,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-7d966399-e358-4951-af2c-bf453d885d3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1451155918-172.17.0.13-1595915078626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37077,DS-39e51335-6f5a-4ebc-85a3-d14c354ac32e,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-314105a3-4a06-4ec2-8380-a54ac5b9f4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-1285399f-b9e6-44e7-903f-6d64c2ee5146,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-14da4faa-a12c-43d3-8f26-c927a4273c14,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-4be32f34-53f5-431f-8110-43b10dcc222a,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-a12b7f1c-b04e-4e7a-b691-d58d308ac1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-1e3fe8ae-7123-4ae5-b00f-3e11f4c6fac0,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-7d966399-e358-4951-af2c-bf453d885d3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1172923250-172.17.0.13-1595915116632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39079,DS-b0f5d6f3-04b7-4c2e-bd12-ebc1602c656e,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-ac670be0-f940-4418-9d61-ba8f4413d674,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-d7ff75b2-98b7-4646-a3bc-98e1bbfd3f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:32952,DS-1259b171-0252-45d9-a6ea-524b16f0cee7,DISK], DatanodeInfoWithStorage[127.0.0.1:33243,DS-9e0bd430-adb1-4017-b877-91fafb4f5e45,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-15ae09fb-37c2-41af-991a-a7273f7a0015,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-b9085068-0f92-4874-b68d-7d5f68c2b87b,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-14df4d08-d0b4-4e16-ab47-018afb2ad4fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1172923250-172.17.0.13-1595915116632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39079,DS-b0f5d6f3-04b7-4c2e-bd12-ebc1602c656e,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-ac670be0-f940-4418-9d61-ba8f4413d674,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-d7ff75b2-98b7-4646-a3bc-98e1bbfd3f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:32952,DS-1259b171-0252-45d9-a6ea-524b16f0cee7,DISK], DatanodeInfoWithStorage[127.0.0.1:33243,DS-9e0bd430-adb1-4017-b877-91fafb4f5e45,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-15ae09fb-37c2-41af-991a-a7273f7a0015,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-b9085068-0f92-4874-b68d-7d5f68c2b87b,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-14df4d08-d0b4-4e16-ab47-018afb2ad4fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-100281687-172.17.0.13-1595915314757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42349,DS-d458d1f9-d27c-4547-ade8-9b97d2520f35,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-f123f9d3-0af9-490d-9b76-4a64897c5870,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-87556e63-9be4-45f2-b41a-4cfa734a0e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-e42a955f-9de1-4439-bf6d-a28b7b77d325,DISK], DatanodeInfoWithStorage[127.0.0.1:35309,DS-ed96208d-161a-420d-80df-f70e63b1c47f,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-ca58e7fc-8982-430c-9b68-400bf47dae20,DISK], DatanodeInfoWithStorage[127.0.0.1:40884,DS-c9d9ba9e-11b5-43c7-9a36-25457afce058,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-8a23f4a1-93a3-4496-9382-01a1c40a2973,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-100281687-172.17.0.13-1595915314757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42349,DS-d458d1f9-d27c-4547-ade8-9b97d2520f35,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-f123f9d3-0af9-490d-9b76-4a64897c5870,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-87556e63-9be4-45f2-b41a-4cfa734a0e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-e42a955f-9de1-4439-bf6d-a28b7b77d325,DISK], DatanodeInfoWithStorage[127.0.0.1:35309,DS-ed96208d-161a-420d-80df-f70e63b1c47f,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-ca58e7fc-8982-430c-9b68-400bf47dae20,DISK], DatanodeInfoWithStorage[127.0.0.1:40884,DS-c9d9ba9e-11b5-43c7-9a36-25457afce058,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-8a23f4a1-93a3-4496-9382-01a1c40a2973,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951789945-172.17.0.13-1595915721767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44679,DS-ec59bcac-adff-4190-95b6-eaa7237a35ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-822fcf43-62e7-405c-bbf3-bb90223d3621,DISK], DatanodeInfoWithStorage[127.0.0.1:44963,DS-4895320d-7263-4f21-935a-cdc7f0476058,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-65c19df6-f2d3-4fc9-975d-dbbb38b5f9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-8a73e9bc-9099-4064-9694-2e8fe6ac7382,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-aa7d800a-2508-4234-a269-bd62c4ea7c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-1c9cf042-72dd-44f9-8805-5b757988236c,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-f0339237-6986-4611-a43e-958f06c350ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951789945-172.17.0.13-1595915721767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44679,DS-ec59bcac-adff-4190-95b6-eaa7237a35ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-822fcf43-62e7-405c-bbf3-bb90223d3621,DISK], DatanodeInfoWithStorage[127.0.0.1:44963,DS-4895320d-7263-4f21-935a-cdc7f0476058,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-65c19df6-f2d3-4fc9-975d-dbbb38b5f9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-8a73e9bc-9099-4064-9694-2e8fe6ac7382,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-aa7d800a-2508-4234-a269-bd62c4ea7c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-1c9cf042-72dd-44f9-8805-5b757988236c,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-f0339237-6986-4611-a43e-958f06c350ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1538849912-172.17.0.13-1595916008047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35636,DS-3fe64e66-c0d8-4736-a647-117d570155ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-9306b422-b1ea-4eb4-823f-18342fe3e797,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-f0a9613f-7c33-4219-b795-36af3ed47215,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-71be5bd2-ddb3-4583-bffe-977ba38d0d07,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-504fb5a2-0afd-485a-86da-80937c3cbd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-86b6974e-e22a-41fd-b07a-4fab15ac99ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41000,DS-d4c15f22-8381-4730-9b84-1345248512d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-ecdb3157-d423-4844-b306-407000e22ef3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1538849912-172.17.0.13-1595916008047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35636,DS-3fe64e66-c0d8-4736-a647-117d570155ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-9306b422-b1ea-4eb4-823f-18342fe3e797,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-f0a9613f-7c33-4219-b795-36af3ed47215,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-71be5bd2-ddb3-4583-bffe-977ba38d0d07,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-504fb5a2-0afd-485a-86da-80937c3cbd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-86b6974e-e22a-41fd-b07a-4fab15ac99ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41000,DS-d4c15f22-8381-4730-9b84-1345248512d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-ecdb3157-d423-4844-b306-407000e22ef3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851524215-172.17.0.13-1595916352892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41730,DS-58153e6b-9065-4ead-9ac2-eb498a9f8203,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-c75f6051-34c2-403b-998a-afad89337462,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-37636a85-1261-49a6-baef-3971bd7f0660,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-3eb64618-490c-4f9a-97ab-e70010470195,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-d790e122-8e39-4e96-ab19-84b130854de2,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-361809d2-912d-4b1b-8c47-d8c4c90d2b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-811f9f87-b998-4ed0-afab-91b5187aac5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-2b80cbae-fa86-417b-a881-1ee4c01f9cc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851524215-172.17.0.13-1595916352892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41730,DS-58153e6b-9065-4ead-9ac2-eb498a9f8203,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-c75f6051-34c2-403b-998a-afad89337462,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-37636a85-1261-49a6-baef-3971bd7f0660,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-3eb64618-490c-4f9a-97ab-e70010470195,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-d790e122-8e39-4e96-ab19-84b130854de2,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-361809d2-912d-4b1b-8c47-d8c4c90d2b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-811f9f87-b998-4ed0-afab-91b5187aac5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-2b80cbae-fa86-417b-a881-1ee4c01f9cc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-289204610-172.17.0.13-1595916696018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46054,DS-d6a0f40d-b7e6-48a1-9849-de28f1c98107,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-0544c268-ae4b-4688-ab03-70bf42ed76e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-1f4dba00-b13e-493c-a79e-eac107757a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-000e1338-4fff-4550-bd3d-4cd480af2f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-362ff8d7-7677-40dd-b872-0d47451b00d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-ee6ec7fb-a0cc-4778-9cac-c1650593b117,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-d0efc2e3-31a4-42b7-b782-39d04a919294,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-4c9faa2b-342f-4643-baa8-9311d894640b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-289204610-172.17.0.13-1595916696018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46054,DS-d6a0f40d-b7e6-48a1-9849-de28f1c98107,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-0544c268-ae4b-4688-ab03-70bf42ed76e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-1f4dba00-b13e-493c-a79e-eac107757a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-000e1338-4fff-4550-bd3d-4cd480af2f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-362ff8d7-7677-40dd-b872-0d47451b00d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-ee6ec7fb-a0cc-4778-9cac-c1650593b117,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-d0efc2e3-31a4-42b7-b782-39d04a919294,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-4c9faa2b-342f-4643-baa8-9311d894640b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2088993101-172.17.0.13-1595916798814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46115,DS-0a37f7b5-f80d-4b6f-970b-101c0c38dcc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-0a2ec1d9-96cf-48e4-a02d-40d7c98b0c30,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-d90a54c3-37a6-4770-9e9e-951e258adbca,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-e8808d21-d564-44a1-8486-8c7e7cb4404d,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-0e991268-4a12-487f-9270-041c7db35523,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-1b3e2392-5f30-4260-8de5-1247fcb9e000,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-68c33e03-fc71-410f-8454-c048a448aee7,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-032f2ef4-22b9-4f5b-b7d7-f2741c90fe01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2088993101-172.17.0.13-1595916798814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46115,DS-0a37f7b5-f80d-4b6f-970b-101c0c38dcc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-0a2ec1d9-96cf-48e4-a02d-40d7c98b0c30,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-d90a54c3-37a6-4770-9e9e-951e258adbca,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-e8808d21-d564-44a1-8486-8c7e7cb4404d,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-0e991268-4a12-487f-9270-041c7db35523,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-1b3e2392-5f30-4260-8de5-1247fcb9e000,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-68c33e03-fc71-410f-8454-c048a448aee7,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-032f2ef4-22b9-4f5b-b7d7-f2741c90fe01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5579
