reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-434925320-172.17.0.17-1595819628242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37791,DS-97e87172-f330-4a1c-a9da-8498b245a77c,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-7d5a3888-59c9-4ac5-9259-8082794e9f63,DISK], DatanodeInfoWithStorage[127.0.0.1:33467,DS-fd211e5f-b850-4987-b022-157b55023a49,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-250948ba-579b-4768-9bbd-2ebe4aad9007,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-72029a3c-5ed4-48f6-bd85-79df7076223a,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-3348dad0-da17-4aab-a083-1ed23870c241,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-e780c782-b1eb-46ac-a656-f33843a2dfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-453c69ee-f12d-4415-8b95-dba512b694c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-434925320-172.17.0.17-1595819628242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37791,DS-97e87172-f330-4a1c-a9da-8498b245a77c,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-7d5a3888-59c9-4ac5-9259-8082794e9f63,DISK], DatanodeInfoWithStorage[127.0.0.1:33467,DS-fd211e5f-b850-4987-b022-157b55023a49,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-250948ba-579b-4768-9bbd-2ebe4aad9007,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-72029a3c-5ed4-48f6-bd85-79df7076223a,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-3348dad0-da17-4aab-a083-1ed23870c241,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-e780c782-b1eb-46ac-a656-f33843a2dfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-453c69ee-f12d-4415-8b95-dba512b694c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1921912118-172.17.0.17-1595820011197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45691,DS-ec07fd2f-2e0f-4842-92d4-cd8e3aca42a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-c4bfdc80-885e-486a-96b0-a6966690f11a,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-c5840852-a52c-4d4a-8821-33cacdcc901b,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-3fbc2f1d-e3d4-4f9d-a777-5642ed3b3402,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-ed40cceb-c5d4-4d86-80d9-aa6c3bb11980,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-05feb9d6-0b5c-4950-b6ee-2c52986ef8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-2a450dbd-efae-4640-9362-b58a084e9e39,DISK], DatanodeInfoWithStorage[127.0.0.1:41974,DS-ed56be2d-8668-4b06-b64e-8a89e2fd4201,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1921912118-172.17.0.17-1595820011197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45691,DS-ec07fd2f-2e0f-4842-92d4-cd8e3aca42a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-c4bfdc80-885e-486a-96b0-a6966690f11a,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-c5840852-a52c-4d4a-8821-33cacdcc901b,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-3fbc2f1d-e3d4-4f9d-a777-5642ed3b3402,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-ed40cceb-c5d4-4d86-80d9-aa6c3bb11980,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-05feb9d6-0b5c-4950-b6ee-2c52986ef8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-2a450dbd-efae-4640-9362-b58a084e9e39,DISK], DatanodeInfoWithStorage[127.0.0.1:41974,DS-ed56be2d-8668-4b06-b64e-8a89e2fd4201,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-235203454-172.17.0.17-1595820425919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33246,DS-a2847d4d-7867-4300-98b8-6a0010b62fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:33303,DS-9bbfc718-cf70-431f-8e81-e51e0f3a6802,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-3acb7ff3-2f89-431b-8626-cfd781d88c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37480,DS-e7f94ce9-1b53-4442-b259-09d2db3f316a,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-54b36395-72e9-4e8b-b9e8-de2a9bdb12b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-dc0f8acc-7a63-4821-9f10-fbd33c8675b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-530e0f2b-279e-4c6f-b35d-8a21cda7196c,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-49c40f73-05db-46b0-826f-1b9c85ec8b0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-235203454-172.17.0.17-1595820425919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33246,DS-a2847d4d-7867-4300-98b8-6a0010b62fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:33303,DS-9bbfc718-cf70-431f-8e81-e51e0f3a6802,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-3acb7ff3-2f89-431b-8626-cfd781d88c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37480,DS-e7f94ce9-1b53-4442-b259-09d2db3f316a,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-54b36395-72e9-4e8b-b9e8-de2a9bdb12b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-dc0f8acc-7a63-4821-9f10-fbd33c8675b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-530e0f2b-279e-4c6f-b35d-8a21cda7196c,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-49c40f73-05db-46b0-826f-1b9c85ec8b0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-434465945-172.17.0.17-1595820486937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36145,DS-3d666fc7-8c24-4316-b878-4360b3a41523,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-cd58d0be-a1ce-4779-bc06-d6097d76ccbc,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-2c7ef996-9ac8-4d9e-ab97-1eb454759526,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-1cc745a2-b4d1-46f0-b8a9-e813b03a39c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-f9750577-659d-4466-921f-df7ef2ff7f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-340e827d-63d1-4b00-aef4-a748c8341f32,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-6c859596-5720-496a-b976-df172e977681,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-40726b9f-79e1-411b-be37-8096c3357d76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-434465945-172.17.0.17-1595820486937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36145,DS-3d666fc7-8c24-4316-b878-4360b3a41523,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-cd58d0be-a1ce-4779-bc06-d6097d76ccbc,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-2c7ef996-9ac8-4d9e-ab97-1eb454759526,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-1cc745a2-b4d1-46f0-b8a9-e813b03a39c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-f9750577-659d-4466-921f-df7ef2ff7f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-340e827d-63d1-4b00-aef4-a748c8341f32,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-6c859596-5720-496a-b976-df172e977681,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-40726b9f-79e1-411b-be37-8096c3357d76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1833207507-172.17.0.17-1595822060052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41448,DS-bc081789-1850-4e00-a5d5-945978b86de0,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-5862c35c-570e-4251-881c-a286c117d398,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-c5b8dc64-e89a-4ab1-b2b6-f95f52a00dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-e1f917e3-7512-423c-a562-1f61ef1cf90a,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-44291ea2-f1d5-4a63-bbf0-e8a28bfead3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-c31e449c-8e07-4c14-8358-6b369f303690,DISK], DatanodeInfoWithStorage[127.0.0.1:40791,DS-7657c684-1d6b-465a-8f16-4c1bab6bf836,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-63815463-da84-4c04-8685-9963ba68b32d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1833207507-172.17.0.17-1595822060052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41448,DS-bc081789-1850-4e00-a5d5-945978b86de0,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-5862c35c-570e-4251-881c-a286c117d398,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-c5b8dc64-e89a-4ab1-b2b6-f95f52a00dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-e1f917e3-7512-423c-a562-1f61ef1cf90a,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-44291ea2-f1d5-4a63-bbf0-e8a28bfead3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-c31e449c-8e07-4c14-8358-6b369f303690,DISK], DatanodeInfoWithStorage[127.0.0.1:40791,DS-7657c684-1d6b-465a-8f16-4c1bab6bf836,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-63815463-da84-4c04-8685-9963ba68b32d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1099353304-172.17.0.17-1595822311295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33136,DS-b396638c-88e2-4f1b-b487-d5a372b2d091,DISK], DatanodeInfoWithStorage[127.0.0.1:43765,DS-48a6fa99-d57a-416a-8260-c6e77bb7afdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-4f86e8b4-3e2a-47e0-bd85-9a02773579c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-aefb2480-ba9c-4b18-815d-2eddb61fd1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-8047ed52-f6ad-44fc-9cc1-e928a211885c,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-f6ff2836-ae41-49e3-b475-c155adc57eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-3066f5bc-4762-4b2f-9c0b-c4d6b3c9b23d,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-2fb3849c-6eaa-4c6a-a15d-00280cd0f94d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1099353304-172.17.0.17-1595822311295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33136,DS-b396638c-88e2-4f1b-b487-d5a372b2d091,DISK], DatanodeInfoWithStorage[127.0.0.1:43765,DS-48a6fa99-d57a-416a-8260-c6e77bb7afdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-4f86e8b4-3e2a-47e0-bd85-9a02773579c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-aefb2480-ba9c-4b18-815d-2eddb61fd1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-8047ed52-f6ad-44fc-9cc1-e928a211885c,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-f6ff2836-ae41-49e3-b475-c155adc57eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-3066f5bc-4762-4b2f-9c0b-c4d6b3c9b23d,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-2fb3849c-6eaa-4c6a-a15d-00280cd0f94d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1234319225-172.17.0.17-1595822669864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37342,DS-6e00bcc1-9ad0-4476-84ad-43ce4a4e955b,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-e68c1be5-f404-4dcb-8a5b-457ffa41d338,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-65af5638-72fc-4281-a23f-4cfd45f3c120,DISK], DatanodeInfoWithStorage[127.0.0.1:45141,DS-12d98331-2e69-41f0-968f-ca939c086576,DISK], DatanodeInfoWithStorage[127.0.0.1:40181,DS-6a1f95b0-dc1a-49b4-8c44-5908d5d5b2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45266,DS-03b0d839-829a-4a96-b9e1-17d99e619d60,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-02b65e1b-3e5b-4053-9c94-02535522d879,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-27a02da3-ae7a-43c6-a7a5-661242f27555,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1234319225-172.17.0.17-1595822669864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37342,DS-6e00bcc1-9ad0-4476-84ad-43ce4a4e955b,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-e68c1be5-f404-4dcb-8a5b-457ffa41d338,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-65af5638-72fc-4281-a23f-4cfd45f3c120,DISK], DatanodeInfoWithStorage[127.0.0.1:45141,DS-12d98331-2e69-41f0-968f-ca939c086576,DISK], DatanodeInfoWithStorage[127.0.0.1:40181,DS-6a1f95b0-dc1a-49b4-8c44-5908d5d5b2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45266,DS-03b0d839-829a-4a96-b9e1-17d99e619d60,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-02b65e1b-3e5b-4053-9c94-02535522d879,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-27a02da3-ae7a-43c6-a7a5-661242f27555,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-587103333-172.17.0.17-1595822800973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34390,DS-0d267ba5-4f4e-4bde-998c-c1e0a92fab76,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-afd8c00a-1bdd-48b3-b08c-df9d19a1c6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-9e1a3c0d-0ac6-4b27-9890-26426ec65462,DISK], DatanodeInfoWithStorage[127.0.0.1:33409,DS-e5685b15-0d22-4779-8627-6621b2059ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-9b0c9742-3570-4b0a-a428-797716cb8b43,DISK], DatanodeInfoWithStorage[127.0.0.1:45471,DS-8493f21e-1641-4389-92d7-193ea883eabb,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-27e17e42-c314-4020-8b62-7ab33af5a5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-f9da9b67-b614-4dec-9858-3886a76faca5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-587103333-172.17.0.17-1595822800973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34390,DS-0d267ba5-4f4e-4bde-998c-c1e0a92fab76,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-afd8c00a-1bdd-48b3-b08c-df9d19a1c6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-9e1a3c0d-0ac6-4b27-9890-26426ec65462,DISK], DatanodeInfoWithStorage[127.0.0.1:33409,DS-e5685b15-0d22-4779-8627-6621b2059ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-9b0c9742-3570-4b0a-a428-797716cb8b43,DISK], DatanodeInfoWithStorage[127.0.0.1:45471,DS-8493f21e-1641-4389-92d7-193ea883eabb,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-27e17e42-c314-4020-8b62-7ab33af5a5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-f9da9b67-b614-4dec-9858-3886a76faca5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-640972091-172.17.0.17-1595823173709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40595,DS-34eb2eff-5464-4992-9aa2-4cc74d053a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46653,DS-1ec1c37b-d007-4963-929c-6ba3b7d32aae,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-cbd42c72-0549-4abd-81e4-80adf0fafcb4,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-1cb97524-1e11-4f3a-8af1-0ed30736a453,DISK], DatanodeInfoWithStorage[127.0.0.1:40210,DS-b2cf194e-2359-425f-9201-74ca5ac4dcea,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-81b15df6-a06c-4951-b209-ac9d572608e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-2a37ca43-0db8-4053-888e-f31904e7fe2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-d5128cd3-0b55-4efc-9bf3-49cf6e948631,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-640972091-172.17.0.17-1595823173709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40595,DS-34eb2eff-5464-4992-9aa2-4cc74d053a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46653,DS-1ec1c37b-d007-4963-929c-6ba3b7d32aae,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-cbd42c72-0549-4abd-81e4-80adf0fafcb4,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-1cb97524-1e11-4f3a-8af1-0ed30736a453,DISK], DatanodeInfoWithStorage[127.0.0.1:40210,DS-b2cf194e-2359-425f-9201-74ca5ac4dcea,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-81b15df6-a06c-4951-b209-ac9d572608e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-2a37ca43-0db8-4053-888e-f31904e7fe2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-d5128cd3-0b55-4efc-9bf3-49cf6e948631,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-759218347-172.17.0.17-1595823300778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37921,DS-c033f309-6b5e-4088-9f5d-31120c2bd768,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-0c88d64f-290e-42e5-9b62-1e4aed86d32e,DISK], DatanodeInfoWithStorage[127.0.0.1:40181,DS-c2d0fbc8-84bf-4214-b275-21cb8ed144ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-c4ee25b7-9eff-4cff-a805-ecf18519f474,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-8350f333-2c99-4166-af8c-f0c6f7292115,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-945c268f-d21a-4b02-8863-4f5126168e40,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-03db79b0-b79b-4627-b240-e21dca993811,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-974e379b-50b1-4398-bdf6-86407118c113,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-759218347-172.17.0.17-1595823300778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37921,DS-c033f309-6b5e-4088-9f5d-31120c2bd768,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-0c88d64f-290e-42e5-9b62-1e4aed86d32e,DISK], DatanodeInfoWithStorage[127.0.0.1:40181,DS-c2d0fbc8-84bf-4214-b275-21cb8ed144ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-c4ee25b7-9eff-4cff-a805-ecf18519f474,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-8350f333-2c99-4166-af8c-f0c6f7292115,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-945c268f-d21a-4b02-8863-4f5126168e40,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-03db79b0-b79b-4627-b240-e21dca993811,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-974e379b-50b1-4398-bdf6-86407118c113,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144655231-172.17.0.17-1595823342030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36206,DS-48119176-6c18-42f9-a095-56ea392289c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-1d210d4a-6a27-4579-872c-630e73f78221,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-212f80e4-8fb3-485d-869a-e14180d603a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-c53a8e43-478f-4fd1-a3bb-a385eab91416,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-75c2fb55-f51b-491b-b142-e87c617c227c,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-c45b9db4-6bf8-440c-bd93-d5f55c7fb113,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-aaa8e430-22a2-48d6-9bc1-57af660412f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-0ffad7dc-80b1-4e7c-87ae-0f9ec8aed3e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144655231-172.17.0.17-1595823342030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36206,DS-48119176-6c18-42f9-a095-56ea392289c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-1d210d4a-6a27-4579-872c-630e73f78221,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-212f80e4-8fb3-485d-869a-e14180d603a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-c53a8e43-478f-4fd1-a3bb-a385eab91416,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-75c2fb55-f51b-491b-b142-e87c617c227c,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-c45b9db4-6bf8-440c-bd93-d5f55c7fb113,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-aaa8e430-22a2-48d6-9bc1-57af660412f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-0ffad7dc-80b1-4e7c-87ae-0f9ec8aed3e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1977231949-172.17.0.17-1595823521801:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35681,DS-09f46888-59ff-4f44-90fa-6b152f5bc7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-f9406930-17e6-4cbb-a7c7-51519e2c70c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-924e3185-8b4d-4322-90c8-25043a4a6758,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-a7aa5372-9717-468c-8c4b-318b7a7a880d,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-34625a16-add0-4dde-b434-9ce49a9b4c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-bfb5730a-b561-42e3-a822-d1d1275a824a,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-f854fa1f-0ec9-4589-a427-fbe101d6a730,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-77cfa3be-2471-4aa5-b357-11622c4e9e0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1977231949-172.17.0.17-1595823521801:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35681,DS-09f46888-59ff-4f44-90fa-6b152f5bc7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-f9406930-17e6-4cbb-a7c7-51519e2c70c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-924e3185-8b4d-4322-90c8-25043a4a6758,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-a7aa5372-9717-468c-8c4b-318b7a7a880d,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-34625a16-add0-4dde-b434-9ce49a9b4c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-bfb5730a-b561-42e3-a822-d1d1275a824a,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-f854fa1f-0ec9-4589-a427-fbe101d6a730,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-77cfa3be-2471-4aa5-b357-11622c4e9e0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1597727314-172.17.0.17-1595824163101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33031,DS-061fb7e8-d302-427d-b461-dbd72c9f6f60,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-72b2ffbf-f6e4-4021-8ab0-18224102d0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-b52d946a-c007-4f12-89cd-b9717ef8d884,DISK], DatanodeInfoWithStorage[127.0.0.1:46539,DS-e6cda487-f61e-4aca-b50b-edccd266334b,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-28ec889e-69dc-4bf6-a6a6-6932715feca9,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-32d51f15-245c-41d9-b23e-625b514bbaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-bc54f56c-d8f9-445c-b320-e1bd60f4d6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-2886ce2b-d2bf-456f-950b-a4c2436f106c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1597727314-172.17.0.17-1595824163101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33031,DS-061fb7e8-d302-427d-b461-dbd72c9f6f60,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-72b2ffbf-f6e4-4021-8ab0-18224102d0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-b52d946a-c007-4f12-89cd-b9717ef8d884,DISK], DatanodeInfoWithStorage[127.0.0.1:46539,DS-e6cda487-f61e-4aca-b50b-edccd266334b,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-28ec889e-69dc-4bf6-a6a6-6932715feca9,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-32d51f15-245c-41d9-b23e-625b514bbaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-bc54f56c-d8f9-445c-b320-e1bd60f4d6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-2886ce2b-d2bf-456f-950b-a4c2436f106c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1029028802-172.17.0.17-1595824571238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36039,DS-0a1e239c-769c-4466-ac3d-c131f5633e34,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-5aac4bc1-2f20-4a36-b527-6c5cd935f50a,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-0962f2c5-06e0-4263-b2ea-f96c8ed3bc30,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-e43b4dfb-8da0-4110-8745-9736bdf9a8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-67804c0a-2fdd-443a-80bd-9926800713de,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-252356e0-db65-49e0-9406-2b2611f28ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-a46ec477-98b3-4083-b875-a9af13d0614f,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-de653739-b5fa-4b83-98bf-62a5bab28468,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1029028802-172.17.0.17-1595824571238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36039,DS-0a1e239c-769c-4466-ac3d-c131f5633e34,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-5aac4bc1-2f20-4a36-b527-6c5cd935f50a,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-0962f2c5-06e0-4263-b2ea-f96c8ed3bc30,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-e43b4dfb-8da0-4110-8745-9736bdf9a8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-67804c0a-2fdd-443a-80bd-9926800713de,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-252356e0-db65-49e0-9406-2b2611f28ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-a46ec477-98b3-4083-b875-a9af13d0614f,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-de653739-b5fa-4b83-98bf-62a5bab28468,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1675602101-172.17.0.17-1595824635739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42490,DS-a5eb8a79-753c-4103-80f1-3fe625464e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-0e06f48c-44b4-4262-850e-dd01118f8900,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-66bcc156-a6e7-4b3c-ad19-49aca479fd32,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-d809c2e9-0bf0-4e59-be08-43a36366bae3,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-ff73c443-8323-4d23-b8cb-08c0fd408cec,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-6fa75ab3-f6e3-4ce4-96e0-beba00fca595,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-a87dddee-0bd0-4682-9660-756063b0e221,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-5793abd3-0a95-4d97-a906-5f56dbf878eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1675602101-172.17.0.17-1595824635739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42490,DS-a5eb8a79-753c-4103-80f1-3fe625464e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-0e06f48c-44b4-4262-850e-dd01118f8900,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-66bcc156-a6e7-4b3c-ad19-49aca479fd32,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-d809c2e9-0bf0-4e59-be08-43a36366bae3,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-ff73c443-8323-4d23-b8cb-08c0fd408cec,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-6fa75ab3-f6e3-4ce4-96e0-beba00fca595,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-a87dddee-0bd0-4682-9660-756063b0e221,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-5793abd3-0a95-4d97-a906-5f56dbf878eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5384
