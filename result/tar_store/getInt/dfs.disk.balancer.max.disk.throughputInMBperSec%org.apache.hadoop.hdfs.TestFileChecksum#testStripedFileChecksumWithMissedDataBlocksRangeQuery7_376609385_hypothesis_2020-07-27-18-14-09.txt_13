reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712606971-172.17.0.5-1595873704936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33999,DS-36165591-e725-41aa-8581-55458476681f,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-a84aea86-6bf0-47cc-b620-a70b9f8e4f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-0c7fd395-5530-4226-8b2f-9757f5dd036a,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-a57eed9b-7e9e-4c06-92d6-473ca63dab79,DISK], DatanodeInfoWithStorage[127.0.0.1:42072,DS-2e563d05-12dc-45bc-ba22-2ad379f6cb96,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-8e03ba42-905a-4e43-afde-3306a1eaf7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-07de9ba1-f773-4004-8b12-cbb91b6e719e,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-f20923b2-e04b-41bd-ba8d-24d126d0b2b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712606971-172.17.0.5-1595873704936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33999,DS-36165591-e725-41aa-8581-55458476681f,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-a84aea86-6bf0-47cc-b620-a70b9f8e4f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-0c7fd395-5530-4226-8b2f-9757f5dd036a,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-a57eed9b-7e9e-4c06-92d6-473ca63dab79,DISK], DatanodeInfoWithStorage[127.0.0.1:42072,DS-2e563d05-12dc-45bc-ba22-2ad379f6cb96,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-8e03ba42-905a-4e43-afde-3306a1eaf7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-07de9ba1-f773-4004-8b12-cbb91b6e719e,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-f20923b2-e04b-41bd-ba8d-24d126d0b2b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-370264629-172.17.0.5-1595873918469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41194,DS-d99b66c0-5b7a-4b6d-9a71-a54f22df5f80,DISK], DatanodeInfoWithStorage[127.0.0.1:39578,DS-ae679220-8462-4f45-85d4-aea59268124d,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-9a30282c-1f19-49c9-ad09-be2e5c60d32a,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-6b205606-6e3e-45ab-81d1-097f943c6404,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-4189ab77-19db-477d-ad54-eb17aecbe7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-09b45dfc-abb2-480e-a588-94a94a94fedf,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-482910f0-922b-45ce-b3fc-0461f2d57be9,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-83b490f8-082d-4d08-a170-ffcb012c917d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-370264629-172.17.0.5-1595873918469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41194,DS-d99b66c0-5b7a-4b6d-9a71-a54f22df5f80,DISK], DatanodeInfoWithStorage[127.0.0.1:39578,DS-ae679220-8462-4f45-85d4-aea59268124d,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-9a30282c-1f19-49c9-ad09-be2e5c60d32a,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-6b205606-6e3e-45ab-81d1-097f943c6404,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-4189ab77-19db-477d-ad54-eb17aecbe7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-09b45dfc-abb2-480e-a588-94a94a94fedf,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-482910f0-922b-45ce-b3fc-0461f2d57be9,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-83b490f8-082d-4d08-a170-ffcb012c917d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-50029524-172.17.0.5-1595874088285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46755,DS-46901c29-a261-4224-a964-c760ac1b5092,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-25e8f6a0-06bb-4f90-a2e5-28866d733eff,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-39126075-6874-42ab-bd90-5ea5a0684c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-3915ead1-1ab1-44a8-a3ae-fa0471f5d4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35539,DS-29f5122c-9504-442d-bef4-be4589ecf04f,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-f3dcfacd-6e3c-4d99-810b-63785ea57ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-fa28d180-8b4f-458c-a70e-6725fbe0001c,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-43283bfc-a48a-4e54-8d0f-e0865755e9ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-50029524-172.17.0.5-1595874088285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46755,DS-46901c29-a261-4224-a964-c760ac1b5092,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-25e8f6a0-06bb-4f90-a2e5-28866d733eff,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-39126075-6874-42ab-bd90-5ea5a0684c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-3915ead1-1ab1-44a8-a3ae-fa0471f5d4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35539,DS-29f5122c-9504-442d-bef4-be4589ecf04f,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-f3dcfacd-6e3c-4d99-810b-63785ea57ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-fa28d180-8b4f-458c-a70e-6725fbe0001c,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-43283bfc-a48a-4e54-8d0f-e0865755e9ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-901744847-172.17.0.5-1595874741852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36042,DS-be7cc1fa-7915-45c0-9ff9-b44824926672,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-3f103c08-dcdc-4d07-80ea-909157d0379d,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-147fc42d-e29c-4c6d-a49e-6a03babbbae1,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-24a1c0c1-0803-41af-9085-d6af3fe27ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-6a946340-d527-4404-ab5f-70a0e04dde47,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-7114ac67-e711-45fa-8a30-16b04ba2a556,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-ca54c896-7b4e-4b06-abc1-a608723f8ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-f05788a6-78dd-4960-85dd-f20b7c33682c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-901744847-172.17.0.5-1595874741852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36042,DS-be7cc1fa-7915-45c0-9ff9-b44824926672,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-3f103c08-dcdc-4d07-80ea-909157d0379d,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-147fc42d-e29c-4c6d-a49e-6a03babbbae1,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-24a1c0c1-0803-41af-9085-d6af3fe27ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-6a946340-d527-4404-ab5f-70a0e04dde47,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-7114ac67-e711-45fa-8a30-16b04ba2a556,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-ca54c896-7b4e-4b06-abc1-a608723f8ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-f05788a6-78dd-4960-85dd-f20b7c33682c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1208855900-172.17.0.5-1595874961638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38324,DS-61bf1ddc-d8fa-4422-ad25-2d78efe41922,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-1af8dd35-bc09-4ca9-96b2-038c8a8078ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-a64082b2-a8f7-463f-9165-b1eef1582d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-0d7fbbe0-0666-42ba-bbdb-a6c5ad4a2410,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-14f9cce5-884f-40a9-9871-9d32c4793298,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-93edeadf-a593-4aba-bd0f-4dae91953e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44787,DS-ed90f03a-79c0-42ee-944b-785f82e329f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-0d0f46be-e486-45c5-9421-196a5b8637c6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1208855900-172.17.0.5-1595874961638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38324,DS-61bf1ddc-d8fa-4422-ad25-2d78efe41922,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-1af8dd35-bc09-4ca9-96b2-038c8a8078ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-a64082b2-a8f7-463f-9165-b1eef1582d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-0d7fbbe0-0666-42ba-bbdb-a6c5ad4a2410,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-14f9cce5-884f-40a9-9871-9d32c4793298,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-93edeadf-a593-4aba-bd0f-4dae91953e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44787,DS-ed90f03a-79c0-42ee-944b-785f82e329f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-0d0f46be-e486-45c5-9421-196a5b8637c6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-802438032-172.17.0.5-1595875025921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37008,DS-74a3c50d-84e2-430e-bf8d-8a6c1fb6b525,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-579f87a4-698a-49fa-b606-1b9c0232d70f,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-73f695a5-7a5c-4e65-a306-76dfb0f00cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-c62340fb-e009-4245-bcfb-0ba4e92b7de0,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-4aa10ec5-84be-4e6e-a32b-230f5cb11825,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-3da0f4c1-ac3b-4787-b40e-adf65717cbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-25162c80-6085-4faf-b0d3-6763af43048d,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-d4ebc0dc-8b3e-473c-bdc9-3180f1204da9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-802438032-172.17.0.5-1595875025921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37008,DS-74a3c50d-84e2-430e-bf8d-8a6c1fb6b525,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-579f87a4-698a-49fa-b606-1b9c0232d70f,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-73f695a5-7a5c-4e65-a306-76dfb0f00cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-c62340fb-e009-4245-bcfb-0ba4e92b7de0,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-4aa10ec5-84be-4e6e-a32b-230f5cb11825,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-3da0f4c1-ac3b-4787-b40e-adf65717cbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-25162c80-6085-4faf-b0d3-6763af43048d,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-d4ebc0dc-8b3e-473c-bdc9-3180f1204da9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1868025239-172.17.0.5-1595875174372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36831,DS-d633463d-8dcc-486f-a0b4-ac297dca6348,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-682e4f6f-81bd-4eff-806a-8c70898cf03d,DISK], DatanodeInfoWithStorage[127.0.0.1:38217,DS-9009b543-8446-49da-a304-8f98b3c36b84,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-cff1c537-07bc-482e-89bb-07291bfa08f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-c037e165-4ed0-411d-b956-8c79ce4ce17e,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-ff150ba7-99d6-49f3-b672-20b1d6f88d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-d18a4bf8-9955-4292-93b9-09f730c8588f,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-334495d8-0377-4a84-9013-0a4fc88ef92a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1868025239-172.17.0.5-1595875174372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36831,DS-d633463d-8dcc-486f-a0b4-ac297dca6348,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-682e4f6f-81bd-4eff-806a-8c70898cf03d,DISK], DatanodeInfoWithStorage[127.0.0.1:38217,DS-9009b543-8446-49da-a304-8f98b3c36b84,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-cff1c537-07bc-482e-89bb-07291bfa08f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-c037e165-4ed0-411d-b956-8c79ce4ce17e,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-ff150ba7-99d6-49f3-b672-20b1d6f88d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-d18a4bf8-9955-4292-93b9-09f730c8588f,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-334495d8-0377-4a84-9013-0a4fc88ef92a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2116602801-172.17.0.5-1595875243243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34891,DS-926dd850-d5bb-46a3-9d2d-68d6d74d12e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-f530f287-15fc-48e7-aee2-1ed0dce9c01b,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-6e66fceb-1a6e-409f-9f9d-256dd32db42e,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-4ada2642-43a9-4222-bff9-fc101ca6abb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-b4025a01-0051-40e0-9e52-d5c9645463f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-cedba992-7a67-4af3-acc2-aabe1feebbda,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-224fde4f-a4e5-41a1-8652-1748233ccc30,DISK], DatanodeInfoWithStorage[127.0.0.1:42183,DS-36e437e6-be83-4a6c-840d-d62865a6f0a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2116602801-172.17.0.5-1595875243243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34891,DS-926dd850-d5bb-46a3-9d2d-68d6d74d12e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-f530f287-15fc-48e7-aee2-1ed0dce9c01b,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-6e66fceb-1a6e-409f-9f9d-256dd32db42e,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-4ada2642-43a9-4222-bff9-fc101ca6abb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-b4025a01-0051-40e0-9e52-d5c9645463f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-cedba992-7a67-4af3-acc2-aabe1feebbda,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-224fde4f-a4e5-41a1-8652-1748233ccc30,DISK], DatanodeInfoWithStorage[127.0.0.1:42183,DS-36e437e6-be83-4a6c-840d-d62865a6f0a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1832286805-172.17.0.5-1595875345288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34044,DS-1420a5ff-341e-4807-9f63-c1d72055eaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-0a7c331c-fa3e-4bfe-a1ac-c171df351773,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-7b5af80e-a69c-441b-8180-02246836f12e,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-246290cf-4e98-4ff7-bb3a-5d05313d7a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-d2f40fcd-cba6-4be0-bb42-28497469c485,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-568a324a-e07c-437e-9d65-13752938f2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-b6e85246-8a8d-4fdd-b550-2a291284dc56,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-02fedd42-4097-41e3-b421-94ff8f2ee874,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1832286805-172.17.0.5-1595875345288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34044,DS-1420a5ff-341e-4807-9f63-c1d72055eaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-0a7c331c-fa3e-4bfe-a1ac-c171df351773,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-7b5af80e-a69c-441b-8180-02246836f12e,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-246290cf-4e98-4ff7-bb3a-5d05313d7a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-d2f40fcd-cba6-4be0-bb42-28497469c485,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-568a324a-e07c-437e-9d65-13752938f2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-b6e85246-8a8d-4fdd-b550-2a291284dc56,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-02fedd42-4097-41e3-b421-94ff8f2ee874,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1498146287-172.17.0.5-1595875440145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36460,DS-bbfe6c5d-73f9-427b-88a0-6c65e1185852,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-b9dfe576-f105-441b-b14c-93707c9d9613,DISK], DatanodeInfoWithStorage[127.0.0.1:42152,DS-2f6ab3ec-b794-470a-bc46-baffc68c9767,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-cf823a8a-2464-4a6b-993c-4d75512522f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-66f47be2-1fa2-472b-b766-19468a9ea307,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-32a2a92e-9402-4a69-8c47-06b7e1a8d5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-23181eb9-5ccc-4ddc-887d-a50f64b1cee9,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-90641c2f-ddcd-46d3-b747-cba35fb54b31,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1498146287-172.17.0.5-1595875440145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36460,DS-bbfe6c5d-73f9-427b-88a0-6c65e1185852,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-b9dfe576-f105-441b-b14c-93707c9d9613,DISK], DatanodeInfoWithStorage[127.0.0.1:42152,DS-2f6ab3ec-b794-470a-bc46-baffc68c9767,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-cf823a8a-2464-4a6b-993c-4d75512522f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-66f47be2-1fa2-472b-b766-19468a9ea307,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-32a2a92e-9402-4a69-8c47-06b7e1a8d5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-23181eb9-5ccc-4ddc-887d-a50f64b1cee9,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-90641c2f-ddcd-46d3-b747-cba35fb54b31,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1675484263-172.17.0.5-1595875629867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40005,DS-37e701a5-5dc7-4c5d-9c1c-a260b158cb98,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-70b6cabb-6a85-44ee-aa03-c0c49a77ba2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-ffb3c0fe-4c96-4aaf-9e53-2fbc70ac99f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-219879f4-9257-4e4d-bce7-83981e06171f,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-30b5ca76-6837-4259-a057-53fd44b79939,DISK], DatanodeInfoWithStorage[127.0.0.1:46590,DS-817a1ca9-8e49-4bea-8815-c6b8b94044e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-0efcb25d-d5ba-4e3e-91f1-8564a26e351b,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-1fe50e4a-dd3a-419c-bb57-07125b387f36,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1675484263-172.17.0.5-1595875629867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40005,DS-37e701a5-5dc7-4c5d-9c1c-a260b158cb98,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-70b6cabb-6a85-44ee-aa03-c0c49a77ba2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-ffb3c0fe-4c96-4aaf-9e53-2fbc70ac99f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-219879f4-9257-4e4d-bce7-83981e06171f,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-30b5ca76-6837-4259-a057-53fd44b79939,DISK], DatanodeInfoWithStorage[127.0.0.1:46590,DS-817a1ca9-8e49-4bea-8815-c6b8b94044e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-0efcb25d-d5ba-4e3e-91f1-8564a26e351b,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-1fe50e4a-dd3a-419c-bb57-07125b387f36,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-747963568-172.17.0.5-1595875707748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38567,DS-1d97fb77-df3f-45f7-a201-18d97dc5e96c,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-b152602c-7ca6-426d-ba59-574fdbda534b,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-2c342158-2883-4632-9a8b-f40a567ac7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-82af209b-c543-402d-a5d0-ddccc20d5b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-d050aa8c-0747-4882-8642-cb7b0df14008,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-1bf6dcb2-5234-4edb-ad32-5b59fa56627a,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-07074a76-a985-4e3b-87c7-5415bf33759d,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-970f2856-6ebf-4ab5-89d8-5fc980c9a109,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-747963568-172.17.0.5-1595875707748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38567,DS-1d97fb77-df3f-45f7-a201-18d97dc5e96c,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-b152602c-7ca6-426d-ba59-574fdbda534b,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-2c342158-2883-4632-9a8b-f40a567ac7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-82af209b-c543-402d-a5d0-ddccc20d5b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-d050aa8c-0747-4882-8642-cb7b0df14008,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-1bf6dcb2-5234-4edb-ad32-5b59fa56627a,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-07074a76-a985-4e3b-87c7-5415bf33759d,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-970f2856-6ebf-4ab5-89d8-5fc980c9a109,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-437469836-172.17.0.5-1595875960056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36815,DS-7008ad4b-1cb9-4a39-9afa-b979d4497688,DISK], DatanodeInfoWithStorage[127.0.0.1:43885,DS-f899db89-8d35-4786-97ef-2fbf8edb1557,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-d520c526-b422-436d-ae55-dfb2f5285bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-b8166d52-050f-41ad-a6b7-3744d5eb835b,DISK], DatanodeInfoWithStorage[127.0.0.1:33755,DS-2a40a322-bec0-4910-827a-a06d176914e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-605ec6ba-133e-48bf-849d-ea77476b5fda,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-6990988d-a7c2-4701-8f6c-aed396a4f6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-c35950dc-52f9-4b09-880c-f84f747404a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-437469836-172.17.0.5-1595875960056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36815,DS-7008ad4b-1cb9-4a39-9afa-b979d4497688,DISK], DatanodeInfoWithStorage[127.0.0.1:43885,DS-f899db89-8d35-4786-97ef-2fbf8edb1557,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-d520c526-b422-436d-ae55-dfb2f5285bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-b8166d52-050f-41ad-a6b7-3744d5eb835b,DISK], DatanodeInfoWithStorage[127.0.0.1:33755,DS-2a40a322-bec0-4910-827a-a06d176914e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-605ec6ba-133e-48bf-849d-ea77476b5fda,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-6990988d-a7c2-4701-8f6c-aed396a4f6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-c35950dc-52f9-4b09-880c-f84f747404a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-388050037-172.17.0.5-1595876127851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35988,DS-0a242813-e5f0-4d74-b02d-625ac02ef313,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-aa67b9e1-5fb6-4eb3-8ecd-4c3ce8f2d83b,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-71613c8d-cf6f-4729-8591-a7dbcdd4c549,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-6e0fe8aa-f3b2-4768-9c14-fe43d10e75df,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-e875459f-2116-4009-ae85-573ca03790ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-a3dae1d4-303e-4814-9719-cb7ba670d35f,DISK], DatanodeInfoWithStorage[127.0.0.1:33022,DS-bff3c8eb-4c88-4178-9b03-be434309121d,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-f3b2c084-ab82-4fe1-81e6-3ea0b3a8f474,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-388050037-172.17.0.5-1595876127851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35988,DS-0a242813-e5f0-4d74-b02d-625ac02ef313,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-aa67b9e1-5fb6-4eb3-8ecd-4c3ce8f2d83b,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-71613c8d-cf6f-4729-8591-a7dbcdd4c549,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-6e0fe8aa-f3b2-4768-9c14-fe43d10e75df,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-e875459f-2116-4009-ae85-573ca03790ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-a3dae1d4-303e-4814-9719-cb7ba670d35f,DISK], DatanodeInfoWithStorage[127.0.0.1:33022,DS-bff3c8eb-4c88-4178-9b03-be434309121d,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-f3b2c084-ab82-4fe1-81e6-3ea0b3a8f474,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391852653-172.17.0.5-1595876397740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44638,DS-1ac173bd-b45d-4cb5-8c08-373eacb2b112,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-048e3acf-7046-4d00-b6a1-b44a913f894b,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-470be9b8-74e6-49d2-92cf-e62ee34b8ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:41046,DS-7cb1c146-66fd-4547-8493-cd27f24fbd14,DISK], DatanodeInfoWithStorage[127.0.0.1:37579,DS-33a572d5-2e35-47c2-a170-f4a9a3454a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-9cc8e9da-af39-4fcf-bee2-f9169255b4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35618,DS-47e83642-9b9b-4a42-b6f4-f795b4988944,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-9d6ae338-8363-4a52-9644-66c3d5a4da52,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391852653-172.17.0.5-1595876397740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44638,DS-1ac173bd-b45d-4cb5-8c08-373eacb2b112,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-048e3acf-7046-4d00-b6a1-b44a913f894b,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-470be9b8-74e6-49d2-92cf-e62ee34b8ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:41046,DS-7cb1c146-66fd-4547-8493-cd27f24fbd14,DISK], DatanodeInfoWithStorage[127.0.0.1:37579,DS-33a572d5-2e35-47c2-a170-f4a9a3454a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-9cc8e9da-af39-4fcf-bee2-f9169255b4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35618,DS-47e83642-9b9b-4a42-b6f4-f795b4988944,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-9d6ae338-8363-4a52-9644-66c3d5a4da52,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1121390551-172.17.0.5-1595876465019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35295,DS-50449663-99af-4f31-9e11-33685f46c5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-6524aa7a-dfcf-47ac-99e7-ab625261fe00,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-3d725c0b-f6cb-4590-891a-01efbaefe99c,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-fe05c5af-7a45-47ef-82bb-cdb833e00bde,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-83d98a11-ccee-4834-a989-be1ad9c391ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-646e5490-ed8d-42ef-aa92-f00e5b831bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-0706ca34-b715-455d-9e33-236121e1b6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-8f6c4353-a5c1-4d4c-962b-8416b6c86918,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1121390551-172.17.0.5-1595876465019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35295,DS-50449663-99af-4f31-9e11-33685f46c5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-6524aa7a-dfcf-47ac-99e7-ab625261fe00,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-3d725c0b-f6cb-4590-891a-01efbaefe99c,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-fe05c5af-7a45-47ef-82bb-cdb833e00bde,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-83d98a11-ccee-4834-a989-be1ad9c391ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-646e5490-ed8d-42ef-aa92-f00e5b831bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-0706ca34-b715-455d-9e33-236121e1b6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-8f6c4353-a5c1-4d4c-962b-8416b6c86918,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-903870666-172.17.0.5-1595876661372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41664,DS-ef5709fa-e0f2-468d-ba71-c5f34187dc2f,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-8db49aa0-05f3-4052-b9c4-a52ed9551418,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-b32917a4-c370-4266-b3d6-c7d42853f2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-ae48ae90-d161-4209-a03f-30d3971298b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-cb7ddb06-d2f3-4f23-904d-ce791ce0e51c,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-917405ac-d512-41b4-9ab4-73526e0f03be,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-20bc0dbd-8a07-4fb6-8e90-9d1d15d7d258,DISK], DatanodeInfoWithStorage[127.0.0.1:32977,DS-d6b64933-4e17-4d76-b724-6861ecba48c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-903870666-172.17.0.5-1595876661372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41664,DS-ef5709fa-e0f2-468d-ba71-c5f34187dc2f,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-8db49aa0-05f3-4052-b9c4-a52ed9551418,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-b32917a4-c370-4266-b3d6-c7d42853f2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-ae48ae90-d161-4209-a03f-30d3971298b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-cb7ddb06-d2f3-4f23-904d-ce791ce0e51c,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-917405ac-d512-41b4-9ab4-73526e0f03be,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-20bc0dbd-8a07-4fb6-8e90-9d1d15d7d258,DISK], DatanodeInfoWithStorage[127.0.0.1:32977,DS-d6b64933-4e17-4d76-b724-6861ecba48c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1713472769-172.17.0.5-1595876697699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45254,DS-bfc2efe9-14b0-4693-8f30-43b21368494c,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-f9402c0e-21fd-4ceb-ac53-b7878bff13e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-79389580-d298-48dd-becc-56f8fc635942,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-f633dbb8-6419-43cb-b43a-9fc1c3fde033,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-8a218bb6-2604-46f8-961d-ec254c452dac,DISK], DatanodeInfoWithStorage[127.0.0.1:40526,DS-e2134c5e-a1f3-4ce0-8777-6c101c0dd116,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-f7e13584-75d1-4497-be57-788b0749479f,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-e8283d35-445f-4146-898a-7c56cc8b4552,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1713472769-172.17.0.5-1595876697699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45254,DS-bfc2efe9-14b0-4693-8f30-43b21368494c,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-f9402c0e-21fd-4ceb-ac53-b7878bff13e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-79389580-d298-48dd-becc-56f8fc635942,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-f633dbb8-6419-43cb-b43a-9fc1c3fde033,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-8a218bb6-2604-46f8-961d-ec254c452dac,DISK], DatanodeInfoWithStorage[127.0.0.1:40526,DS-e2134c5e-a1f3-4ce0-8777-6c101c0dd116,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-f7e13584-75d1-4497-be57-788b0749479f,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-e8283d35-445f-4146-898a-7c56cc8b4552,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2124649748-172.17.0.5-1595876768095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42796,DS-b3dde04c-7d84-4e68-8a3c-e2e578d11728,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-c1f49f8a-336e-4498-9f44-3a9463b6c455,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-5f67219c-107e-4158-82ee-3e76a4550a91,DISK], DatanodeInfoWithStorage[127.0.0.1:32773,DS-8e32f8c7-7f1c-4bc7-b5ea-44135153ac04,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-896468ea-4e42-4b11-8c36-449bed3ec905,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-d5a1663d-6e41-4873-b8c3-4d39ac96d6db,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-1b1ca481-fb75-45da-9936-8d03fb98202f,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-b27a156a-f511-497f-b8c1-5103c5d36ea3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2124649748-172.17.0.5-1595876768095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42796,DS-b3dde04c-7d84-4e68-8a3c-e2e578d11728,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-c1f49f8a-336e-4498-9f44-3a9463b6c455,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-5f67219c-107e-4158-82ee-3e76a4550a91,DISK], DatanodeInfoWithStorage[127.0.0.1:32773,DS-8e32f8c7-7f1c-4bc7-b5ea-44135153ac04,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-896468ea-4e42-4b11-8c36-449bed3ec905,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-d5a1663d-6e41-4873-b8c3-4d39ac96d6db,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-1b1ca481-fb75-45da-9936-8d03fb98202f,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-b27a156a-f511-497f-b8c1-5103c5d36ea3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-87006686-172.17.0.5-1595877245841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41531,DS-c4dfa269-bc31-453d-9413-88e026be2188,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-631b219f-d109-4129-a078-1d8626068549,DISK], DatanodeInfoWithStorage[127.0.0.1:41300,DS-09cb1059-fecf-4f26-9a72-cd50c5ae266d,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-594dce21-e3b1-4bd5-b005-429123ac1ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-bbe2da3d-a5ec-4501-917e-0800d5632ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-054dc619-c2e5-4fa0-8edb-997c3f3bb8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-dccec774-ba2b-4072-a7dc-c7682a9706ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-9bfe790a-4d4b-43c2-a82a-8e1d4cddc166,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-87006686-172.17.0.5-1595877245841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41531,DS-c4dfa269-bc31-453d-9413-88e026be2188,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-631b219f-d109-4129-a078-1d8626068549,DISK], DatanodeInfoWithStorage[127.0.0.1:41300,DS-09cb1059-fecf-4f26-9a72-cd50c5ae266d,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-594dce21-e3b1-4bd5-b005-429123ac1ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-bbe2da3d-a5ec-4501-917e-0800d5632ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-054dc619-c2e5-4fa0-8edb-997c3f3bb8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-dccec774-ba2b-4072-a7dc-c7682a9706ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-9bfe790a-4d4b-43c2-a82a-8e1d4cddc166,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-132337040-172.17.0.5-1595877437601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34584,DS-1ddc9ec1-37c3-4856-8e52-188c07e81397,DISK], DatanodeInfoWithStorage[127.0.0.1:42123,DS-7a0d33fb-2d46-47a5-87c8-16be94e7f710,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-dbef309a-9dd6-4cf3-bae8-b61639cc0c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38859,DS-b1ab3c59-94bc-4883-aaa4-c589675ae685,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-0c4aef24-84c4-4284-b9d8-a0697719030e,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-53f90641-79e5-4285-911c-49754c00ea84,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-1472dd61-1cdd-4cbf-bf7c-3ab0eedb8a44,DISK], DatanodeInfoWithStorage[127.0.0.1:42247,DS-b365ff74-51eb-42c4-ba18-d846a2274722,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-132337040-172.17.0.5-1595877437601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34584,DS-1ddc9ec1-37c3-4856-8e52-188c07e81397,DISK], DatanodeInfoWithStorage[127.0.0.1:42123,DS-7a0d33fb-2d46-47a5-87c8-16be94e7f710,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-dbef309a-9dd6-4cf3-bae8-b61639cc0c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38859,DS-b1ab3c59-94bc-4883-aaa4-c589675ae685,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-0c4aef24-84c4-4284-b9d8-a0697719030e,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-53f90641-79e5-4285-911c-49754c00ea84,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-1472dd61-1cdd-4cbf-bf7c-3ab0eedb8a44,DISK], DatanodeInfoWithStorage[127.0.0.1:42247,DS-b365ff74-51eb-42c4-ba18-d846a2274722,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1473699446-172.17.0.5-1595877672651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35046,DS-e5aa3d89-e2de-4c0a-a5d8-ae5882ff5bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42951,DS-e6963ebd-e7a9-450b-b9ba-ff0a293d8a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-82a233fb-f6a1-4538-ad85-57c2244be1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-ae481b6f-5355-40c5-8239-3e06c11eebdd,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-7eac733c-6482-410a-ba02-a6295a7f2928,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-06398cc4-6742-49a6-b6c7-ba65238f9f20,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-4ce392c2-7101-4a7f-8bd7-63d9934c41b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-bfaa0637-577f-4fb7-85fd-68aa29b415a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1473699446-172.17.0.5-1595877672651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35046,DS-e5aa3d89-e2de-4c0a-a5d8-ae5882ff5bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42951,DS-e6963ebd-e7a9-450b-b9ba-ff0a293d8a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-82a233fb-f6a1-4538-ad85-57c2244be1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-ae481b6f-5355-40c5-8239-3e06c11eebdd,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-7eac733c-6482-410a-ba02-a6295a7f2928,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-06398cc4-6742-49a6-b6c7-ba65238f9f20,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-4ce392c2-7101-4a7f-8bd7-63d9934c41b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-bfaa0637-577f-4fb7-85fd-68aa29b415a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-982814404-172.17.0.5-1595877746493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41736,DS-9b32c60c-a61a-418d-9709-ee17952afece,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-e8f8c67c-2d35-4bb7-8beb-9135f6f4ef4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-904f8bca-60ab-4f4b-b9ef-fe02b5e374b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33682,DS-66673c58-a303-4a5d-8bbe-8b5eeaf6434c,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-c093e920-ac37-4606-8773-7d7897b4d060,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-f86dbfd3-fe17-4413-ab7e-88dca746d6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-d9c7305d-2135-4321-819a-89b1faa0a7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33312,DS-d8f5daaf-2879-45a1-96fc-ee89fb54cde8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-982814404-172.17.0.5-1595877746493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41736,DS-9b32c60c-a61a-418d-9709-ee17952afece,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-e8f8c67c-2d35-4bb7-8beb-9135f6f4ef4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-904f8bca-60ab-4f4b-b9ef-fe02b5e374b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33682,DS-66673c58-a303-4a5d-8bbe-8b5eeaf6434c,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-c093e920-ac37-4606-8773-7d7897b4d060,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-f86dbfd3-fe17-4413-ab7e-88dca746d6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-d9c7305d-2135-4321-819a-89b1faa0a7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33312,DS-d8f5daaf-2879-45a1-96fc-ee89fb54cde8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-798127546-172.17.0.5-1595877806884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40988,DS-67d07b28-2fe8-4c63-abd8-d62775d9df6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39204,DS-0c95b3c9-1bd5-4d64-b062-d2ce39b25170,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-0814ca4b-0a09-4d1c-88d5-486b7c6589b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-a97c5632-3b15-4fbf-aa6c-306be7263694,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-7a23819a-caa1-4249-a001-ae3953bf482f,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-af581c7d-96bc-4222-bf76-0329158e731c,DISK], DatanodeInfoWithStorage[127.0.0.1:45449,DS-f51c7da3-560c-4f45-a380-246b56670e98,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-ed931f8f-d015-4361-8955-f2a1bc457b9b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-798127546-172.17.0.5-1595877806884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40988,DS-67d07b28-2fe8-4c63-abd8-d62775d9df6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39204,DS-0c95b3c9-1bd5-4d64-b062-d2ce39b25170,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-0814ca4b-0a09-4d1c-88d5-486b7c6589b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-a97c5632-3b15-4fbf-aa6c-306be7263694,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-7a23819a-caa1-4249-a001-ae3953bf482f,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-af581c7d-96bc-4222-bf76-0329158e731c,DISK], DatanodeInfoWithStorage[127.0.0.1:45449,DS-f51c7da3-560c-4f45-a380-246b56670e98,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-ed931f8f-d015-4361-8955-f2a1bc457b9b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-885104303-172.17.0.5-1595877919157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45519,DS-afd6605c-a82f-4e7e-9a83-b502495b7bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-abee6f7d-1cf0-4159-8bba-8b8a8ee1d51f,DISK], DatanodeInfoWithStorage[127.0.0.1:36435,DS-eb523080-0ac3-43bb-add5-bc2ff2df37a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-61c9cb93-a8b2-49ac-9ebf-5cb3cef902c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-a7c90ad0-3d95-48d2-bbc7-0ffa33ac6674,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-2abf38b9-4ccb-4df6-82c0-f7d6c2b28afa,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-3e564dda-14c3-4a75-86c1-2dd46f18eca7,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-9c009d3d-4286-4688-becc-b62fb7299a3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-885104303-172.17.0.5-1595877919157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45519,DS-afd6605c-a82f-4e7e-9a83-b502495b7bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-abee6f7d-1cf0-4159-8bba-8b8a8ee1d51f,DISK], DatanodeInfoWithStorage[127.0.0.1:36435,DS-eb523080-0ac3-43bb-add5-bc2ff2df37a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-61c9cb93-a8b2-49ac-9ebf-5cb3cef902c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-a7c90ad0-3d95-48d2-bbc7-0ffa33ac6674,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-2abf38b9-4ccb-4df6-82c0-f7d6c2b28afa,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-3e564dda-14c3-4a75-86c1-2dd46f18eca7,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-9c009d3d-4286-4688-becc-b62fb7299a3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1150661235-172.17.0.5-1595878033624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42103,DS-3b707d69-e6f8-4939-8c9f-f80b7478d246,DISK], DatanodeInfoWithStorage[127.0.0.1:36596,DS-2b23fec6-0dc0-4b98-9a2a-f408ac921d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40882,DS-4667148b-ec4b-46ee-8bbb-317975a92880,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-849e82ea-a3f7-4fc3-ab21-6c8d08d93ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:44216,DS-09a0a2f4-ebb0-4bb7-b036-496658bf9a88,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-3a7ba842-b67f-43b4-8626-d7a781e899a2,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-da41ebe1-bdf1-46ef-ad22-e245b2ef0cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-5c65038d-d59b-424b-8bee-825d97c981ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1150661235-172.17.0.5-1595878033624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42103,DS-3b707d69-e6f8-4939-8c9f-f80b7478d246,DISK], DatanodeInfoWithStorage[127.0.0.1:36596,DS-2b23fec6-0dc0-4b98-9a2a-f408ac921d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40882,DS-4667148b-ec4b-46ee-8bbb-317975a92880,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-849e82ea-a3f7-4fc3-ab21-6c8d08d93ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:44216,DS-09a0a2f4-ebb0-4bb7-b036-496658bf9a88,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-3a7ba842-b67f-43b4-8626-d7a781e899a2,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-da41ebe1-bdf1-46ef-ad22-e245b2ef0cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-5c65038d-d59b-424b-8bee-825d97c981ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-267487162-172.17.0.5-1595878182912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37700,DS-6497c502-ab3c-4175-b69f-0835242d4ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-0a4f1dc9-ccf7-483b-8407-a5845b333689,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-c235515e-11be-44b7-a08f-cb4dd5733c60,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-60797dc5-7d8e-4d26-b6a4-c69af7b63b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-246b33f7-c568-454a-8daa-6fd7d8ecd45d,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-91994211-d1e5-42aa-8d8e-1af6a867f9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33723,DS-8123c9c8-4391-41b3-ac24-e6bc0af70b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-d220279b-c40f-4cad-8de3-0d6126ba3c2a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-267487162-172.17.0.5-1595878182912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37700,DS-6497c502-ab3c-4175-b69f-0835242d4ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-0a4f1dc9-ccf7-483b-8407-a5845b333689,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-c235515e-11be-44b7-a08f-cb4dd5733c60,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-60797dc5-7d8e-4d26-b6a4-c69af7b63b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-246b33f7-c568-454a-8daa-6fd7d8ecd45d,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-91994211-d1e5-42aa-8d8e-1af6a867f9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33723,DS-8123c9c8-4391-41b3-ac24-e6bc0af70b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-d220279b-c40f-4cad-8de3-0d6126ba3c2a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-903587465-172.17.0.5-1595878293423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33794,DS-0d3086e5-f893-427c-a7e6-f680ef92bf89,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-ba6503d1-10fc-4749-a1c6-182c9a79c950,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-097df043-2964-40d7-a9bb-b1667c2bf670,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-901c9cb3-4857-4d96-ab21-3b3ee1393525,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-baeb42e5-35df-4ad4-aab3-dad076867f53,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-eaa4adfd-5d6b-43f2-bb71-6b5cc28f3205,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-18f6da8a-6a1d-4cfb-bf70-9b3af5bacb32,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-17c18abb-83f9-44dc-8ee4-56d2eddb309c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-903587465-172.17.0.5-1595878293423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33794,DS-0d3086e5-f893-427c-a7e6-f680ef92bf89,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-ba6503d1-10fc-4749-a1c6-182c9a79c950,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-097df043-2964-40d7-a9bb-b1667c2bf670,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-901c9cb3-4857-4d96-ab21-3b3ee1393525,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-baeb42e5-35df-4ad4-aab3-dad076867f53,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-eaa4adfd-5d6b-43f2-bb71-6b5cc28f3205,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-18f6da8a-6a1d-4cfb-bf70-9b3af5bacb32,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-17c18abb-83f9-44dc-8ee4-56d2eddb309c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1079178324-172.17.0.5-1595878373705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37871,DS-94c4c1fa-6a26-4b8b-abe7-a9d70380b580,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-be0dbbe7-cbbc-48ef-a0b1-49b7b1f7cd38,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-86af5b62-2139-4508-b2dd-f618b193b40f,DISK], DatanodeInfoWithStorage[127.0.0.1:45218,DS-2d70b0d3-35a6-411f-9e0c-ac82233cad19,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-2f0e7c28-8f48-41d1-b5dc-647f546b5c76,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-0abcc22c-3a7f-4a1f-8a61-b520881427f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-7af69e34-cfa2-4732-917a-814ece27fe90,DISK], DatanodeInfoWithStorage[127.0.0.1:41254,DS-2494470d-df87-4557-ae01-5f8d6ea5c5e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1079178324-172.17.0.5-1595878373705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37871,DS-94c4c1fa-6a26-4b8b-abe7-a9d70380b580,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-be0dbbe7-cbbc-48ef-a0b1-49b7b1f7cd38,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-86af5b62-2139-4508-b2dd-f618b193b40f,DISK], DatanodeInfoWithStorage[127.0.0.1:45218,DS-2d70b0d3-35a6-411f-9e0c-ac82233cad19,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-2f0e7c28-8f48-41d1-b5dc-647f546b5c76,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-0abcc22c-3a7f-4a1f-8a61-b520881427f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-7af69e34-cfa2-4732-917a-814ece27fe90,DISK], DatanodeInfoWithStorage[127.0.0.1:41254,DS-2494470d-df87-4557-ae01-5f8d6ea5c5e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1111976261-172.17.0.5-1595878407048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42149,DS-bf7748fb-6725-444c-ae30-f785790c7d41,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-5975fcfe-591b-4dde-ad1d-34952d815cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-d2ce69dd-bb0a-451c-a413-30cb9f66c28a,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-5af0f178-7222-4bc7-a9ce-5660d7b1c0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-fe7bc666-24a4-47f7-86f6-1e1f87bf3b17,DISK], DatanodeInfoWithStorage[127.0.0.1:34243,DS-1c4c1ddf-b5a7-4bba-bf74-6121191dd717,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-a5408b54-3507-4203-a64f-c81b15577a61,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-2940bdd6-886e-4e08-ad1c-5474a1a40f1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1111976261-172.17.0.5-1595878407048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42149,DS-bf7748fb-6725-444c-ae30-f785790c7d41,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-5975fcfe-591b-4dde-ad1d-34952d815cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-d2ce69dd-bb0a-451c-a413-30cb9f66c28a,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-5af0f178-7222-4bc7-a9ce-5660d7b1c0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-fe7bc666-24a4-47f7-86f6-1e1f87bf3b17,DISK], DatanodeInfoWithStorage[127.0.0.1:34243,DS-1c4c1ddf-b5a7-4bba-bf74-6121191dd717,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-a5408b54-3507-4203-a64f-c81b15577a61,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-2940bdd6-886e-4e08-ad1c-5474a1a40f1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1618323996-172.17.0.5-1595878441278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37424,DS-daace020-47d7-4d33-9f6b-ee61f15185e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-647e14a3-f798-44de-8bc7-99dfff3680fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-5cf46738-269f-4a10-85af-391c88312849,DISK], DatanodeInfoWithStorage[127.0.0.1:44350,DS-c49dc46e-1bbd-4c12-9eaf-3e81b6468339,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-c5a6fbfb-bf88-4260-805c-a958f34fafcc,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-9a46b413-96fa-4b01-9083-921e4a5a33dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-c62b9c51-26f5-4288-bb0d-8fd906b44840,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-568d1a49-a810-445e-9db9-7afefd047764,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1618323996-172.17.0.5-1595878441278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37424,DS-daace020-47d7-4d33-9f6b-ee61f15185e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-647e14a3-f798-44de-8bc7-99dfff3680fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-5cf46738-269f-4a10-85af-391c88312849,DISK], DatanodeInfoWithStorage[127.0.0.1:44350,DS-c49dc46e-1bbd-4c12-9eaf-3e81b6468339,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-c5a6fbfb-bf88-4260-805c-a958f34fafcc,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-9a46b413-96fa-4b01-9083-921e4a5a33dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-c62b9c51-26f5-4288-bb0d-8fd906b44840,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-568d1a49-a810-445e-9db9-7afefd047764,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1467375158-172.17.0.5-1595878511770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34559,DS-18786200-dc59-428e-87ef-e750eceee8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-106a68ce-47de-434e-9542-ac3e70a72046,DISK], DatanodeInfoWithStorage[127.0.0.1:42541,DS-fdb76bf8-bbb6-4f30-9207-107de1497072,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-d54e2ce5-4a8d-425f-ac05-2927ade629fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-b3743ea0-9299-48ce-9156-4a7aa19d85c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-b2c61451-920b-4347-86ff-e15e5e33edc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-0e238f9b-5d20-44f7-8879-ff2528e28cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-dfc05317-124a-4c20-8f27-08af6153ac12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1467375158-172.17.0.5-1595878511770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34559,DS-18786200-dc59-428e-87ef-e750eceee8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-106a68ce-47de-434e-9542-ac3e70a72046,DISK], DatanodeInfoWithStorage[127.0.0.1:42541,DS-fdb76bf8-bbb6-4f30-9207-107de1497072,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-d54e2ce5-4a8d-425f-ac05-2927ade629fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-b3743ea0-9299-48ce-9156-4a7aa19d85c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-b2c61451-920b-4347-86ff-e15e5e33edc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-0e238f9b-5d20-44f7-8879-ff2528e28cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-dfc05317-124a-4c20-8f27-08af6153ac12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1885769241-172.17.0.5-1595878870359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33663,DS-aca3eda0-d708-4147-ba72-92ceb7cbc6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-209b1f4f-2399-4ffa-bde9-2b444746fa55,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-35a17f5d-99ce-43ac-bd2c-cd3f0e6a2e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-040443f3-3e42-46e9-a1ae-4550c4b34ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-04856d32-14ef-496e-8f74-01554bc19c14,DISK], DatanodeInfoWithStorage[127.0.0.1:34747,DS-8e743861-d097-4550-9759-adca014a5cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-c3f3d914-176f-4937-beec-012e4c4cc707,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-7bba11be-1110-4255-8fcb-cfe665fd7f1e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1885769241-172.17.0.5-1595878870359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33663,DS-aca3eda0-d708-4147-ba72-92ceb7cbc6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-209b1f4f-2399-4ffa-bde9-2b444746fa55,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-35a17f5d-99ce-43ac-bd2c-cd3f0e6a2e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-040443f3-3e42-46e9-a1ae-4550c4b34ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-04856d32-14ef-496e-8f74-01554bc19c14,DISK], DatanodeInfoWithStorage[127.0.0.1:34747,DS-8e743861-d097-4550-9759-adca014a5cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-c3f3d914-176f-4937-beec-012e4c4cc707,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-7bba11be-1110-4255-8fcb-cfe665fd7f1e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 16 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 5244
