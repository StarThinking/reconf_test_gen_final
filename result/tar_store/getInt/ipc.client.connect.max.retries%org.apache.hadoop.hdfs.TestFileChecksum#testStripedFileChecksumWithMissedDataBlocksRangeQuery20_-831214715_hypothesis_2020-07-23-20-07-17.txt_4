reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1169142860-172.17.0.9-1595534918264:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34386,DS-e058b51c-f541-4f2c-9e8b-1427cc536161,DISK], DatanodeInfoWithStorage[127.0.0.1:46205,DS-98cea6b1-1efc-4574-8b85-8130f1ae19ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-540c822e-d867-4c92-b630-a2dc6ec17e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34723,DS-9ed7b44c-c9d2-4fc9-9e8c-02906d26c5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-ad9d77e8-c89b-4571-9ae8-083ecd935233,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-5fcdd155-1a4f-4d42-9592-240b4a7fc36e,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-dbc1f8a3-e91b-491c-a59c-c506bbb83d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-0d1b2c3f-a5bb-4082-9add-ba6dc590dbf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1169142860-172.17.0.9-1595534918264:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34386,DS-e058b51c-f541-4f2c-9e8b-1427cc536161,DISK], DatanodeInfoWithStorage[127.0.0.1:46205,DS-98cea6b1-1efc-4574-8b85-8130f1ae19ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-540c822e-d867-4c92-b630-a2dc6ec17e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34723,DS-9ed7b44c-c9d2-4fc9-9e8c-02906d26c5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-ad9d77e8-c89b-4571-9ae8-083ecd935233,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-5fcdd155-1a4f-4d42-9592-240b4a7fc36e,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-dbc1f8a3-e91b-491c-a59c-c506bbb83d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-0d1b2c3f-a5bb-4082-9add-ba6dc590dbf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1911749360-172.17.0.9-1595535641163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36242,DS-2cb8f4d8-03f1-431c-bcef-ef054cd08635,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-20d9530c-2d45-4c65-b1d2-7103565e1a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-933ac355-49b5-43a3-888e-2bb76aabf440,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-837e040b-0b81-4df7-85e7-7d8cde01c6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-1115bb61-3bbf-4866-b4d1-493f743d85a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43120,DS-bff16464-d54e-4ffc-815d-05e9748328d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-ba2b12c7-d4dd-4194-bb83-db7f0f661445,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-59336ae9-6ed0-4307-9da6-fbea05c56cf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1911749360-172.17.0.9-1595535641163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36242,DS-2cb8f4d8-03f1-431c-bcef-ef054cd08635,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-20d9530c-2d45-4c65-b1d2-7103565e1a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-933ac355-49b5-43a3-888e-2bb76aabf440,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-837e040b-0b81-4df7-85e7-7d8cde01c6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-1115bb61-3bbf-4866-b4d1-493f743d85a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43120,DS-bff16464-d54e-4ffc-815d-05e9748328d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-ba2b12c7-d4dd-4194-bb83-db7f0f661445,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-59336ae9-6ed0-4307-9da6-fbea05c56cf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-812155006-172.17.0.9-1595536195633:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42428,DS-f35e8a87-b862-45cd-8437-dd03a6e8f877,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-c6f886fb-6d45-4c4e-b257-a525fd5a062a,DISK], DatanodeInfoWithStorage[127.0.0.1:41015,DS-1d8af695-6f65-4cdc-b06c-c1bbe1eab81d,DISK], DatanodeInfoWithStorage[127.0.0.1:43164,DS-0c7a8845-dd8d-48f9-bfa2-b0191499d8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-211eafb4-87b3-40dd-9697-a4f6ef23eda1,DISK], DatanodeInfoWithStorage[127.0.0.1:45871,DS-e60a2ca1-cbef-4f6d-8861-c4a33ac73119,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-bfde6b71-6037-441c-8861-92f57256e81b,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-d4a0f556-b25d-4e08-a588-8b668b5fba37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-812155006-172.17.0.9-1595536195633:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42428,DS-f35e8a87-b862-45cd-8437-dd03a6e8f877,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-c6f886fb-6d45-4c4e-b257-a525fd5a062a,DISK], DatanodeInfoWithStorage[127.0.0.1:41015,DS-1d8af695-6f65-4cdc-b06c-c1bbe1eab81d,DISK], DatanodeInfoWithStorage[127.0.0.1:43164,DS-0c7a8845-dd8d-48f9-bfa2-b0191499d8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-211eafb4-87b3-40dd-9697-a4f6ef23eda1,DISK], DatanodeInfoWithStorage[127.0.0.1:45871,DS-e60a2ca1-cbef-4f6d-8861-c4a33ac73119,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-bfde6b71-6037-441c-8861-92f57256e81b,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-d4a0f556-b25d-4e08-a588-8b668b5fba37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-610550171-172.17.0.9-1595536496799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35396,DS-77f91002-b4df-47fd-bae7-53d795e576ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41209,DS-d79a7e2b-aab7-43ab-9fc2-cab49c8ca7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-48c75d62-37c5-4d16-a0f0-ffd0c02d8ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-bb3ea1f4-8d38-4b9a-8edf-631654431088,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-7a0bd3f1-8bb5-4070-987e-4b2f39fa7359,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-4ae683ee-6647-4c18-b56a-ea5b1872c9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-595e3923-3204-4f13-8d3d-d813948e6de3,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-62205ff5-a83c-47bf-9981-bb7b925f5e7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-610550171-172.17.0.9-1595536496799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35396,DS-77f91002-b4df-47fd-bae7-53d795e576ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41209,DS-d79a7e2b-aab7-43ab-9fc2-cab49c8ca7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-48c75d62-37c5-4d16-a0f0-ffd0c02d8ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-bb3ea1f4-8d38-4b9a-8edf-631654431088,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-7a0bd3f1-8bb5-4070-987e-4b2f39fa7359,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-4ae683ee-6647-4c18-b56a-ea5b1872c9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-595e3923-3204-4f13-8d3d-d813948e6de3,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-62205ff5-a83c-47bf-9981-bb7b925f5e7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-637729219-172.17.0.9-1595536763836:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40208,DS-8a8bb4cc-5117-4cf2-8276-97d1fc62358c,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-7eb78ca7-13ba-47ab-8614-c59f05fb1674,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-c429c5ef-cae9-4d60-97d8-eb5141d04add,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-a3e7f3d2-3371-41f3-aa03-df20f10f085d,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-adb04829-d66c-43c8-bb81-24e8e658db40,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-0f27bc10-8c5e-498d-b9e5-581bca6ca7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-be1f165b-4f51-46fc-a681-34736ffda7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-ef2aa78d-1cf3-4b5c-b01d-86accbe55026,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-637729219-172.17.0.9-1595536763836:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40208,DS-8a8bb4cc-5117-4cf2-8276-97d1fc62358c,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-7eb78ca7-13ba-47ab-8614-c59f05fb1674,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-c429c5ef-cae9-4d60-97d8-eb5141d04add,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-a3e7f3d2-3371-41f3-aa03-df20f10f085d,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-adb04829-d66c-43c8-bb81-24e8e658db40,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-0f27bc10-8c5e-498d-b9e5-581bca6ca7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-be1f165b-4f51-46fc-a681-34736ffda7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-ef2aa78d-1cf3-4b5c-b01d-86accbe55026,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-939882842-172.17.0.9-1595537091545:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33934,DS-cb003a58-8fea-4c5b-a783-68b8cb27dae4,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-7452caa6-016d-4ed3-a122-8be3392ebe96,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-7e87035b-cae1-4e0f-abba-38f74fed894c,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-45a1ea2c-57aa-4be6-a27c-ef58a77ba50c,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-8bc4a014-0d0d-44c2-a3e9-3044f9060d16,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-d4eebf2f-68d6-4d19-9cdf-43e428623953,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-46b60823-9813-439b-b65a-7b47bfb1e387,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-aa195cb5-88a8-48f1-b923-f9f4f676b3a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-939882842-172.17.0.9-1595537091545:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33934,DS-cb003a58-8fea-4c5b-a783-68b8cb27dae4,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-7452caa6-016d-4ed3-a122-8be3392ebe96,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-7e87035b-cae1-4e0f-abba-38f74fed894c,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-45a1ea2c-57aa-4be6-a27c-ef58a77ba50c,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-8bc4a014-0d0d-44c2-a3e9-3044f9060d16,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-d4eebf2f-68d6-4d19-9cdf-43e428623953,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-46b60823-9813-439b-b65a-7b47bfb1e387,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-aa195cb5-88a8-48f1-b923-f9f4f676b3a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-999850514-172.17.0.9-1595538198092:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33968,DS-c5012018-c12e-44a4-b6c1-6aa7b8e28a74,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-5e894df8-84f7-48f9-a8d2-4dd08c9a22ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-08593aea-fd0c-42a2-b0f1-7b6772b57be7,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-c2ea0565-61a1-4be2-933b-5271c8494cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-c139f683-7833-45be-b553-9e385342bf72,DISK], DatanodeInfoWithStorage[127.0.0.1:34788,DS-45822f61-3f54-4800-a13b-d9cfc0069d52,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-554ee4e3-d493-4ff8-94a3-d1088f891475,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-03c50c67-a417-4f1b-bdb8-f0a3c0baa6ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-999850514-172.17.0.9-1595538198092:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33968,DS-c5012018-c12e-44a4-b6c1-6aa7b8e28a74,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-5e894df8-84f7-48f9-a8d2-4dd08c9a22ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-08593aea-fd0c-42a2-b0f1-7b6772b57be7,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-c2ea0565-61a1-4be2-933b-5271c8494cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-c139f683-7833-45be-b553-9e385342bf72,DISK], DatanodeInfoWithStorage[127.0.0.1:34788,DS-45822f61-3f54-4800-a13b-d9cfc0069d52,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-554ee4e3-d493-4ff8-94a3-d1088f891475,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-03c50c67-a417-4f1b-bdb8-f0a3c0baa6ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1301042183-172.17.0.9-1595538840222:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40809,DS-97de3a8a-43b0-4fc8-afc1-f557b53f909f,DISK], DatanodeInfoWithStorage[127.0.0.1:38256,DS-27cb7dc0-e083-4f63-9a3e-04ef2450c25b,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-3e1bc5e9-daa4-44d6-bbdf-61364ca451b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-dcc15d96-a04b-4125-a5ac-6d6ac3a3a3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-110067f4-2f5f-4225-8373-604a476e1913,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-1497e17d-f87b-4661-9640-9d9495ed10bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-1ea0efbd-b1f6-459d-8411-2c2509b8597b,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-e94ad2e4-cf25-4820-ae23-9f15215c81ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1301042183-172.17.0.9-1595538840222:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40809,DS-97de3a8a-43b0-4fc8-afc1-f557b53f909f,DISK], DatanodeInfoWithStorage[127.0.0.1:38256,DS-27cb7dc0-e083-4f63-9a3e-04ef2450c25b,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-3e1bc5e9-daa4-44d6-bbdf-61364ca451b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-dcc15d96-a04b-4125-a5ac-6d6ac3a3a3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-110067f4-2f5f-4225-8373-604a476e1913,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-1497e17d-f87b-4661-9640-9d9495ed10bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-1ea0efbd-b1f6-459d-8411-2c2509b8597b,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-e94ad2e4-cf25-4820-ae23-9f15215c81ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1690557804-172.17.0.9-1595538873644:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36243,DS-90aa2d1f-3869-4ad8-86a8-1d353e680895,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-6f95a45f-99ac-418c-a428-2c29759c7c96,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-875f22b2-b6b0-4092-a40f-7f222d442980,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-9d3c4f3f-dcd8-4237-ac71-729fa2e30d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45534,DS-7f2b5e64-501c-41b1-9803-85ff452eb78a,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-3a51b679-ebb2-44a1-af90-bc38d4eaa72f,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-804a13a4-e2e5-4f9e-af0f-7ab4a870ef9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-cecfc595-dccc-4608-a1de-82586588d667,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1690557804-172.17.0.9-1595538873644:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36243,DS-90aa2d1f-3869-4ad8-86a8-1d353e680895,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-6f95a45f-99ac-418c-a428-2c29759c7c96,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-875f22b2-b6b0-4092-a40f-7f222d442980,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-9d3c4f3f-dcd8-4237-ac71-729fa2e30d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45534,DS-7f2b5e64-501c-41b1-9803-85ff452eb78a,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-3a51b679-ebb2-44a1-af90-bc38d4eaa72f,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-804a13a4-e2e5-4f9e-af0f-7ab4a870ef9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-cecfc595-dccc-4608-a1de-82586588d667,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1946552074-172.17.0.9-1595539020578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33654,DS-978d78f2-d022-422a-9f3d-96eee2b9b788,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-27b7b1b9-1c03-4cc7-bc03-21cc2185debe,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-411a5a3c-83f9-4b7e-a2c9-be93b072a02a,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-db86f793-d4bd-4b3f-a15b-55f8920e389b,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-913a92a3-0ae1-4584-a362-2941ddf40013,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-4582d0c5-23ff-4078-9148-50fef43d3dad,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-c2ef614c-04a6-453b-8e17-65105ddce6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-903912a7-2be2-4571-998a-3c4b01f2b0c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1946552074-172.17.0.9-1595539020578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33654,DS-978d78f2-d022-422a-9f3d-96eee2b9b788,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-27b7b1b9-1c03-4cc7-bc03-21cc2185debe,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-411a5a3c-83f9-4b7e-a2c9-be93b072a02a,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-db86f793-d4bd-4b3f-a15b-55f8920e389b,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-913a92a3-0ae1-4584-a362-2941ddf40013,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-4582d0c5-23ff-4078-9148-50fef43d3dad,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-c2ef614c-04a6-453b-8e17-65105ddce6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-903912a7-2be2-4571-998a-3c4b01f2b0c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1326657362-172.17.0.9-1595539478163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40387,DS-8b02ffec-5f0a-4761-8c32-04a48031349a,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-a61f891f-410d-4fd6-9397-c2c8376e9bec,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-2d67a2e7-21f0-4760-ad01-704d8f09b88b,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-0d7fae77-0a46-4c5e-8a63-0a1c6faf06c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-3fce18e1-94aa-4a0e-9052-3c319f4897b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-0a54918c-38fc-4f83-ac0a-a4f4019aa557,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-2301be46-8375-4688-a517-383b8fcca543,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-41b1e4d5-8a1b-4902-9e03-917e87bbe6aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1326657362-172.17.0.9-1595539478163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40387,DS-8b02ffec-5f0a-4761-8c32-04a48031349a,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-a61f891f-410d-4fd6-9397-c2c8376e9bec,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-2d67a2e7-21f0-4760-ad01-704d8f09b88b,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-0d7fae77-0a46-4c5e-8a63-0a1c6faf06c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-3fce18e1-94aa-4a0e-9052-3c319f4897b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-0a54918c-38fc-4f83-ac0a-a4f4019aa557,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-2301be46-8375-4688-a517-383b8fcca543,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-41b1e4d5-8a1b-4902-9e03-917e87bbe6aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1659039263-172.17.0.9-1595539506449:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37493,DS-2bef3211-6f38-4df9-8fc6-a166244844d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-444cc3f6-7ab3-4e5c-8ad0-a4287fb6fae7,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-52ab4d49-07eb-4153-8033-06c234acfd59,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-4f1bcd97-2e7a-4c5a-a32d-ddb7a07768a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-d7dc5c1a-ec26-43c9-a81c-a3c58e610975,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-3ba12b2a-e0b6-4588-b263-ba0e6f7d7a94,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-a2971849-4429-44bb-a2d2-c42e69d99660,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-6e9b6e55-a4f1-4c74-83d5-28d21d07622e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1659039263-172.17.0.9-1595539506449:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37493,DS-2bef3211-6f38-4df9-8fc6-a166244844d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-444cc3f6-7ab3-4e5c-8ad0-a4287fb6fae7,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-52ab4d49-07eb-4153-8033-06c234acfd59,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-4f1bcd97-2e7a-4c5a-a32d-ddb7a07768a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-d7dc5c1a-ec26-43c9-a81c-a3c58e610975,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-3ba12b2a-e0b6-4588-b263-ba0e6f7d7a94,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-a2971849-4429-44bb-a2d2-c42e69d99660,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-6e9b6e55-a4f1-4c74-83d5-28d21d07622e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1354444578-172.17.0.9-1595539701276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41952,DS-0bd6079d-3503-4e40-9fe1-13eaf98a25fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-94f5a7af-875a-4c2b-9b3d-4277ee6b12b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-0402418a-ec42-4e3d-9345-5d1aa4dba8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-eb563abf-34e5-46d7-8075-07ac0d311989,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-274e0bc9-9299-4724-b49d-1eebd8b79a29,DISK], DatanodeInfoWithStorage[127.0.0.1:35427,DS-247efcbb-1ded-42b2-9dd4-3487e382ee70,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-b11e14c4-70c8-4913-885a-f38137d66308,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-14622527-47dd-4de0-8dc6-b59501bfdf71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1354444578-172.17.0.9-1595539701276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41952,DS-0bd6079d-3503-4e40-9fe1-13eaf98a25fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-94f5a7af-875a-4c2b-9b3d-4277ee6b12b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-0402418a-ec42-4e3d-9345-5d1aa4dba8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-eb563abf-34e5-46d7-8075-07ac0d311989,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-274e0bc9-9299-4724-b49d-1eebd8b79a29,DISK], DatanodeInfoWithStorage[127.0.0.1:35427,DS-247efcbb-1ded-42b2-9dd4-3487e382ee70,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-b11e14c4-70c8-4913-885a-f38137d66308,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-14622527-47dd-4de0-8dc6-b59501bfdf71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1291941474-172.17.0.9-1595540051754:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40535,DS-4aa09d10-7765-4d0f-8099-f19d8a5d5f59,DISK], DatanodeInfoWithStorage[127.0.0.1:40345,DS-82aacb2a-c5d2-46eb-9505-de949a7958ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-b295b31a-2100-4000-82ba-fb8b7e2c2799,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-62ee6010-1d2d-49cc-80f4-499813a3ff6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-46d9e1d2-9fb2-4ae3-9fa5-c881fbec16a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-6a822009-406d-40b2-8f01-1f78a7a788ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-8d178b7d-c380-48d1-8a02-f1e9ef88b0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-6477bb62-3e84-4bc8-b055-377cd8fbdaad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1291941474-172.17.0.9-1595540051754:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40535,DS-4aa09d10-7765-4d0f-8099-f19d8a5d5f59,DISK], DatanodeInfoWithStorage[127.0.0.1:40345,DS-82aacb2a-c5d2-46eb-9505-de949a7958ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-b295b31a-2100-4000-82ba-fb8b7e2c2799,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-62ee6010-1d2d-49cc-80f4-499813a3ff6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-46d9e1d2-9fb2-4ae3-9fa5-c881fbec16a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-6a822009-406d-40b2-8f01-1f78a7a788ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-8d178b7d-c380-48d1-8a02-f1e9ef88b0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-6477bb62-3e84-4bc8-b055-377cd8fbdaad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1797396827-172.17.0.9-1595540154340:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35743,DS-cf265f6d-ac5b-4f12-9f81-060f1f281757,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-e4e2228c-b3c4-4e40-b067-68671873485d,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-80b553f5-1341-4235-a2c4-0107d66fb7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-f02037d2-7b0d-40bb-8045-ef29d0729679,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-2c7789a0-cddd-45db-a671-d6a0e15d6be0,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-639d2b0f-b49d-4351-89ff-9feb354dd31f,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-d4cc2d5d-3a08-414c-a6ff-64404b1430b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-4ffe843a-0fbe-486a-b0fb-cba24736d57e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1797396827-172.17.0.9-1595540154340:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35743,DS-cf265f6d-ac5b-4f12-9f81-060f1f281757,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-e4e2228c-b3c4-4e40-b067-68671873485d,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-80b553f5-1341-4235-a2c4-0107d66fb7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-f02037d2-7b0d-40bb-8045-ef29d0729679,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-2c7789a0-cddd-45db-a671-d6a0e15d6be0,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-639d2b0f-b49d-4351-89ff-9feb354dd31f,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-d4cc2d5d-3a08-414c-a6ff-64404b1430b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-4ffe843a-0fbe-486a-b0fb-cba24736d57e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5374
