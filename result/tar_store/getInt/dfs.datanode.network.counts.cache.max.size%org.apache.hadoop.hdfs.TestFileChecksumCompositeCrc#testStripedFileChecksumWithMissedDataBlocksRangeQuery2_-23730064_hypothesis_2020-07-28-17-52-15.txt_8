reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-169842796-172.17.0.20-1595959180913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42982,DS-3864dedb-ea52-4b54-8d2f-14881cc22873,DISK], DatanodeInfoWithStorage[127.0.0.1:44355,DS-72ff5875-de59-4032-855b-3fde65f273e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-2d0fa37d-473f-4a3a-bf02-a1f1db11a552,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-8513e155-1625-4ead-8727-2b20ccee3058,DISK], DatanodeInfoWithStorage[127.0.0.1:36475,DS-8f57c332-6854-4711-a637-77a90564e5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-0e2d8c6d-709b-4694-a7bb-abb87cc68167,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-cebe4f4c-0f1c-4258-a724-d489d7adb09a,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-e8cf9cfa-9653-4a1f-b045-c509189cf425,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-169842796-172.17.0.20-1595959180913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42982,DS-3864dedb-ea52-4b54-8d2f-14881cc22873,DISK], DatanodeInfoWithStorage[127.0.0.1:44355,DS-72ff5875-de59-4032-855b-3fde65f273e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-2d0fa37d-473f-4a3a-bf02-a1f1db11a552,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-8513e155-1625-4ead-8727-2b20ccee3058,DISK], DatanodeInfoWithStorage[127.0.0.1:36475,DS-8f57c332-6854-4711-a637-77a90564e5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-0e2d8c6d-709b-4694-a7bb-abb87cc68167,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-cebe4f4c-0f1c-4258-a724-d489d7adb09a,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-e8cf9cfa-9653-4a1f-b045-c509189cf425,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1611298009-172.17.0.20-1595959318691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37207,DS-c58b22a8-28e1-4a53-a648-8ca6a9c8e88b,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-7fcda68a-e638-47a3-980d-b4a04d985081,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-5dd87f51-b992-4322-81ed-d276b8cf96dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-21936124-ccdb-4e35-ac43-d5c93f230e20,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-58dbf2e6-3c51-440e-b6f5-80b107cfbbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-8bcb5480-d1f8-42ed-bd3e-89a558b7df1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-3c200356-6a0e-4cc5-a84a-cd6820d0d822,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-d1906ea5-4334-4049-adc1-439531d940b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1611298009-172.17.0.20-1595959318691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37207,DS-c58b22a8-28e1-4a53-a648-8ca6a9c8e88b,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-7fcda68a-e638-47a3-980d-b4a04d985081,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-5dd87f51-b992-4322-81ed-d276b8cf96dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-21936124-ccdb-4e35-ac43-d5c93f230e20,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-58dbf2e6-3c51-440e-b6f5-80b107cfbbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-8bcb5480-d1f8-42ed-bd3e-89a558b7df1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-3c200356-6a0e-4cc5-a84a-cd6820d0d822,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-d1906ea5-4334-4049-adc1-439531d940b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1628192085-172.17.0.20-1595960192044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41648,DS-ef18a06c-8385-4db2-ae1a-581a6c563a28,DISK], DatanodeInfoWithStorage[127.0.0.1:43639,DS-6edeb161-262c-4c4e-8f31-8c945c536914,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-f909710d-6a37-4fc6-8ec6-22a9327dc0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-57885b81-9719-490a-910e-4fb292b8c417,DISK], DatanodeInfoWithStorage[127.0.0.1:45521,DS-0926c2e8-a697-45e3-bba8-3b87b9f01164,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-117d9e01-8a10-4e0b-9ad2-6f15df120585,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-f40adf5c-3209-4ba0-804d-1bb803558dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-ee7a8178-cfe0-4d93-8641-fdc4c9bb48e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1628192085-172.17.0.20-1595960192044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41648,DS-ef18a06c-8385-4db2-ae1a-581a6c563a28,DISK], DatanodeInfoWithStorage[127.0.0.1:43639,DS-6edeb161-262c-4c4e-8f31-8c945c536914,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-f909710d-6a37-4fc6-8ec6-22a9327dc0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-57885b81-9719-490a-910e-4fb292b8c417,DISK], DatanodeInfoWithStorage[127.0.0.1:45521,DS-0926c2e8-a697-45e3-bba8-3b87b9f01164,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-117d9e01-8a10-4e0b-9ad2-6f15df120585,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-f40adf5c-3209-4ba0-804d-1bb803558dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-ee7a8178-cfe0-4d93-8641-fdc4c9bb48e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2032741714-172.17.0.20-1595962079976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46578,DS-aee99607-5c5e-49a5-9b6d-e5261dd0ffee,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-e3b80bc5-c767-4a0d-ab7c-ba0f7fbbc6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-ba91e3b2-d4dd-4007-9a2c-7d12aa1c2af4,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-6b03edc3-5650-4938-baf5-0c7fd54931db,DISK], DatanodeInfoWithStorage[127.0.0.1:38350,DS-4d8cd0b2-85bc-4b67-938b-cb94292aa647,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-661c7927-7508-4639-931a-1348ed35ebd3,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-60bceafd-eccd-4013-8c64-f8e437517a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-ae7003ba-f777-4422-81d8-afd73eabbf3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2032741714-172.17.0.20-1595962079976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46578,DS-aee99607-5c5e-49a5-9b6d-e5261dd0ffee,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-e3b80bc5-c767-4a0d-ab7c-ba0f7fbbc6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-ba91e3b2-d4dd-4007-9a2c-7d12aa1c2af4,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-6b03edc3-5650-4938-baf5-0c7fd54931db,DISK], DatanodeInfoWithStorage[127.0.0.1:38350,DS-4d8cd0b2-85bc-4b67-938b-cb94292aa647,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-661c7927-7508-4639-931a-1348ed35ebd3,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-60bceafd-eccd-4013-8c64-f8e437517a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-ae7003ba-f777-4422-81d8-afd73eabbf3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1955545740-172.17.0.20-1595962152441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33733,DS-09320225-c534-4eda-bb52-6d188be73f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-49e8bbb5-252c-48a3-b0aa-670159e673d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-1d914eb2-1ccf-447f-8456-58209c0601eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-589d9507-ecfa-48b1-bd41-27d290179d99,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-43b0e76d-874c-47c3-ad3e-1de680fceff8,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-9ddf5eeb-16e0-4cd5-b391-d02cc5f08497,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-aad53f66-9808-4c11-a0b0-3261c7656df7,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-c5fb961c-90f9-4fed-a849-b3983046bdc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1955545740-172.17.0.20-1595962152441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33733,DS-09320225-c534-4eda-bb52-6d188be73f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-49e8bbb5-252c-48a3-b0aa-670159e673d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-1d914eb2-1ccf-447f-8456-58209c0601eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-589d9507-ecfa-48b1-bd41-27d290179d99,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-43b0e76d-874c-47c3-ad3e-1de680fceff8,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-9ddf5eeb-16e0-4cd5-b391-d02cc5f08497,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-aad53f66-9808-4c11-a0b0-3261c7656df7,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-c5fb961c-90f9-4fed-a849-b3983046bdc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1128326658-172.17.0.20-1595962221238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46126,DS-d589b827-ceb9-481c-bd0f-9459bd757ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:37608,DS-8cf8de0f-c175-48fa-b3fb-9a042f8c982c,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-82acb901-d5d0-4178-8f5b-6f9ec55a7b19,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-924543df-00fc-4d11-8394-88b17fab7a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-66351569-6a02-45c8-997d-0e0411e392e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37198,DS-821b092a-e5d1-4380-a7bd-e491f2f75e70,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-8b0003bf-d02e-4420-ab8c-c56fe9261a80,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-000020df-95c8-46f4-b264-ee87a9a33cab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1128326658-172.17.0.20-1595962221238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46126,DS-d589b827-ceb9-481c-bd0f-9459bd757ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:37608,DS-8cf8de0f-c175-48fa-b3fb-9a042f8c982c,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-82acb901-d5d0-4178-8f5b-6f9ec55a7b19,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-924543df-00fc-4d11-8394-88b17fab7a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-66351569-6a02-45c8-997d-0e0411e392e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37198,DS-821b092a-e5d1-4380-a7bd-e491f2f75e70,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-8b0003bf-d02e-4420-ab8c-c56fe9261a80,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-000020df-95c8-46f4-b264-ee87a9a33cab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1227981393-172.17.0.20-1595962390099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38026,DS-ddd7254c-6a9b-410f-89b8-9bf58063ec05,DISK], DatanodeInfoWithStorage[127.0.0.1:39067,DS-5a44f081-56ae-4ba5-b4b4-cf68a24ac274,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-5f22fa3e-a0f0-41fb-a12b-3391b237a94f,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-e5829891-0b2c-47aa-ae27-77feb9e6cd04,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-4e30bc07-5515-4455-a8b4-4fd80ea1acc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-908df4e9-8347-481d-a971-77295f07d6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-7acad3a4-90e7-4e84-97cc-05e369581699,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-ea6adb31-09f9-48bf-81ff-11959b86f26c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1227981393-172.17.0.20-1595962390099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38026,DS-ddd7254c-6a9b-410f-89b8-9bf58063ec05,DISK], DatanodeInfoWithStorage[127.0.0.1:39067,DS-5a44f081-56ae-4ba5-b4b4-cf68a24ac274,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-5f22fa3e-a0f0-41fb-a12b-3391b237a94f,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-e5829891-0b2c-47aa-ae27-77feb9e6cd04,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-4e30bc07-5515-4455-a8b4-4fd80ea1acc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-908df4e9-8347-481d-a971-77295f07d6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-7acad3a4-90e7-4e84-97cc-05e369581699,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-ea6adb31-09f9-48bf-81ff-11959b86f26c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1522305866-172.17.0.20-1595963001490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34200,DS-00eac30d-dd2d-4a70-9de3-9350fa5ede6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-78d72058-5746-4a30-9cc7-0bd1cd2a0c17,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-56683cbf-6e14-48de-a36d-5549c1c828d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-ce7cc856-edb0-4c1b-9e63-8a2d89da8507,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-a427f978-1b5e-41e1-b1be-63d8c078d36e,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-8ac0f654-fcbe-4e08-84a6-98a0afb4e69a,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-338c828b-0c34-42d5-a4e4-25a53506f127,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-6da028c2-c521-4153-99d4-c99bcb245bf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1522305866-172.17.0.20-1595963001490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34200,DS-00eac30d-dd2d-4a70-9de3-9350fa5ede6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-78d72058-5746-4a30-9cc7-0bd1cd2a0c17,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-56683cbf-6e14-48de-a36d-5549c1c828d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-ce7cc856-edb0-4c1b-9e63-8a2d89da8507,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-a427f978-1b5e-41e1-b1be-63d8c078d36e,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-8ac0f654-fcbe-4e08-84a6-98a0afb4e69a,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-338c828b-0c34-42d5-a4e4-25a53506f127,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-6da028c2-c521-4153-99d4-c99bcb245bf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1099911059-172.17.0.20-1595963079246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44329,DS-e594d0c4-d186-4486-9f2a-93a85449334c,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-f42a277b-8ee5-4323-9d85-11452535b5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-6406b51c-f735-4f90-8ef1-2c4ec53836ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-b293226c-60ff-4453-af80-6214cb78ead3,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-64fb1f6a-41a4-47cd-aa4d-35a334752df0,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-d87370e4-a322-450d-b5dd-b5d4fde07b50,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-fa4136e0-5336-44a2-b93d-0489bb2dca07,DISK], DatanodeInfoWithStorage[127.0.0.1:39059,DS-ae168a3e-832c-4202-9e20-d66c28f29067,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1099911059-172.17.0.20-1595963079246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44329,DS-e594d0c4-d186-4486-9f2a-93a85449334c,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-f42a277b-8ee5-4323-9d85-11452535b5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-6406b51c-f735-4f90-8ef1-2c4ec53836ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-b293226c-60ff-4453-af80-6214cb78ead3,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-64fb1f6a-41a4-47cd-aa4d-35a334752df0,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-d87370e4-a322-450d-b5dd-b5d4fde07b50,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-fa4136e0-5336-44a2-b93d-0489bb2dca07,DISK], DatanodeInfoWithStorage[127.0.0.1:39059,DS-ae168a3e-832c-4202-9e20-d66c28f29067,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2127338155-172.17.0.20-1595963231649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39762,DS-9606e7ea-d413-4940-bb8a-07990628fda5,DISK], DatanodeInfoWithStorage[127.0.0.1:34225,DS-b75a134e-1f7b-4d17-9694-4a1f839d5a33,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-6047ba3b-c1a4-4cb8-a815-9c80c9f367a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-b91b7e02-de3e-4651-ba4d-fc2e1983199f,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-e715113d-c1a8-490d-ad3d-1baf0d5a0de7,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-4eff60cc-3109-45bb-92fb-3eb115bbbc70,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-4324fe71-daf8-4e89-b232-c9306ce1f5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46082,DS-d97de18a-904c-421b-99ca-b56d9d3f1e27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2127338155-172.17.0.20-1595963231649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39762,DS-9606e7ea-d413-4940-bb8a-07990628fda5,DISK], DatanodeInfoWithStorage[127.0.0.1:34225,DS-b75a134e-1f7b-4d17-9694-4a1f839d5a33,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-6047ba3b-c1a4-4cb8-a815-9c80c9f367a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-b91b7e02-de3e-4651-ba4d-fc2e1983199f,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-e715113d-c1a8-490d-ad3d-1baf0d5a0de7,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-4eff60cc-3109-45bb-92fb-3eb115bbbc70,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-4324fe71-daf8-4e89-b232-c9306ce1f5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46082,DS-d97de18a-904c-421b-99ca-b56d9d3f1e27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1913567168-172.17.0.20-1595963493507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34934,DS-0ddc415a-77b4-4510-b5cf-47d19b3e007f,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-31fdc9c3-8256-4408-8478-48f6db7dede9,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-e0e2e589-7404-48ea-af80-d5c8a7d59098,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-bbaea5bc-94c3-4cf4-87ae-589ab95ecbf2,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-be31c22a-c83b-41aa-ae00-f4fdf2fff7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-9f960d33-4bc7-47bd-8334-f24f4969ec38,DISK], DatanodeInfoWithStorage[127.0.0.1:39847,DS-0fdff4e0-86a5-4ad2-b635-1f4dbd3d1319,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-7843a09e-a53d-43cd-9d2b-6b0940849df9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1913567168-172.17.0.20-1595963493507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34934,DS-0ddc415a-77b4-4510-b5cf-47d19b3e007f,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-31fdc9c3-8256-4408-8478-48f6db7dede9,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-e0e2e589-7404-48ea-af80-d5c8a7d59098,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-bbaea5bc-94c3-4cf4-87ae-589ab95ecbf2,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-be31c22a-c83b-41aa-ae00-f4fdf2fff7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-9f960d33-4bc7-47bd-8334-f24f4969ec38,DISK], DatanodeInfoWithStorage[127.0.0.1:39847,DS-0fdff4e0-86a5-4ad2-b635-1f4dbd3d1319,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-7843a09e-a53d-43cd-9d2b-6b0940849df9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1275509618-172.17.0.20-1595963996975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34176,DS-93190786-ec75-4fac-b34f-7e2bf5159a39,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-218254ca-cf38-40bc-9e13-b9f995a87f11,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-b4c41c7e-0971-4898-95d4-eb686dddc7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-678b7cdf-4eb2-42c0-a79f-3849b1ace5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-c55b1b78-21a7-487a-b5d2-94570f5f505f,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-ac4de4e3-5b76-4a37-a881-4f2b6c68121a,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-efe78be2-ff2e-427f-a402-f034fd9ba7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-ab1a6301-56ee-4f50-922c-1e49e0fa3f6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1275509618-172.17.0.20-1595963996975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34176,DS-93190786-ec75-4fac-b34f-7e2bf5159a39,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-218254ca-cf38-40bc-9e13-b9f995a87f11,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-b4c41c7e-0971-4898-95d4-eb686dddc7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-678b7cdf-4eb2-42c0-a79f-3849b1ace5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-c55b1b78-21a7-487a-b5d2-94570f5f505f,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-ac4de4e3-5b76-4a37-a881-4f2b6c68121a,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-efe78be2-ff2e-427f-a402-f034fd9ba7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-ab1a6301-56ee-4f50-922c-1e49e0fa3f6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-775722485-172.17.0.20-1595964271742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39994,DS-ca28fa39-ec1e-44c9-bd33-33f0d27278dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-2862dcdb-d7da-4d2d-b917-9ac0ce49c9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-f365d091-6602-4d8b-9701-f7207f486651,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-d7179f66-b496-4541-b784-5d9c364c00a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-703008c1-886f-4a1d-96b1-ffa25dadb6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40892,DS-c76b5ea8-1837-43e7-a9c0-befca32963ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-1c444548-c18e-46d2-a843-75fe9c11d748,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-864097b4-11a7-4581-a0b9-b6c3ecbb244f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-775722485-172.17.0.20-1595964271742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39994,DS-ca28fa39-ec1e-44c9-bd33-33f0d27278dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-2862dcdb-d7da-4d2d-b917-9ac0ce49c9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-f365d091-6602-4d8b-9701-f7207f486651,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-d7179f66-b496-4541-b784-5d9c364c00a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-703008c1-886f-4a1d-96b1-ffa25dadb6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40892,DS-c76b5ea8-1837-43e7-a9c0-befca32963ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-1c444548-c18e-46d2-a843-75fe9c11d748,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-864097b4-11a7-4581-a0b9-b6c3ecbb244f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5553
