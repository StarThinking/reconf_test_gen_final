reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 50
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 50
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-460661313-172.17.0.4-1595808296428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45196,DS-56d170a0-b289-439d-8400-41eaaabc5058,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-aa18b35d-27ac-4e2c-aa1e-0245d2e9623b,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-6bd544eb-d3af-4ba4-aa22-e2d34279424c,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-558feffd-e37a-4c11-8379-6b3764de57c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39489,DS-f5dc7f64-1ed3-4f31-8384-52cb998e58f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-ef696e28-9e06-4edd-960b-c2fb18fa4c40,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-b5447a66-0c0b-43d8-a9e7-6452342ba6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-661899ce-8c2c-4996-bb09-711ce2a25278,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-460661313-172.17.0.4-1595808296428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45196,DS-56d170a0-b289-439d-8400-41eaaabc5058,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-aa18b35d-27ac-4e2c-aa1e-0245d2e9623b,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-6bd544eb-d3af-4ba4-aa22-e2d34279424c,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-558feffd-e37a-4c11-8379-6b3764de57c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39489,DS-f5dc7f64-1ed3-4f31-8384-52cb998e58f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-ef696e28-9e06-4edd-960b-c2fb18fa4c40,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-b5447a66-0c0b-43d8-a9e7-6452342ba6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-661899ce-8c2c-4996-bb09-711ce2a25278,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 50
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1100150475-172.17.0.4-1595808675824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45718,DS-85c0f202-56ec-43c7-afb6-bb086b9bb2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-646a85eb-45f6-460a-9bcd-cf89753fbc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-6635ec61-8e11-45b0-9d33-7508a915a4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-c922f4ea-41b6-4127-8a30-88e7f351df2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-2b208276-c3a2-40c4-bc49-14615bca2a64,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-26a2fc0b-7ee9-41f6-8be4-7cf10bcf2edd,DISK], DatanodeInfoWithStorage[127.0.0.1:39011,DS-96b59a21-e23d-4827-bb7a-4fedee09bc13,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-62d57092-23de-4a68-9d5f-cad3aadd6fb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1100150475-172.17.0.4-1595808675824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45718,DS-85c0f202-56ec-43c7-afb6-bb086b9bb2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-646a85eb-45f6-460a-9bcd-cf89753fbc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-6635ec61-8e11-45b0-9d33-7508a915a4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-c922f4ea-41b6-4127-8a30-88e7f351df2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-2b208276-c3a2-40c4-bc49-14615bca2a64,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-26a2fc0b-7ee9-41f6-8be4-7cf10bcf2edd,DISK], DatanodeInfoWithStorage[127.0.0.1:39011,DS-96b59a21-e23d-4827-bb7a-4fedee09bc13,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-62d57092-23de-4a68-9d5f-cad3aadd6fb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 50
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-237499438-172.17.0.4-1595808774375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44799,DS-3d536421-3f23-4934-931e-e88fa3f99f82,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-f47ddae1-69be-4587-9118-1dcd2bebd5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-03a6d180-d61f-4619-8764-f7a4997448a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-fe7f8d1b-8bbd-4894-9efe-90ecf8087144,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-01939456-403c-4ef5-b48f-4ba9ea7dd715,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-000c5b3f-e484-4f04-8247-4907697b2132,DISK], DatanodeInfoWithStorage[127.0.0.1:42410,DS-e09c0d48-dee5-4894-a1ec-1179b3212daf,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-20e26e26-0997-45c2-8040-9999c1f63a2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-237499438-172.17.0.4-1595808774375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44799,DS-3d536421-3f23-4934-931e-e88fa3f99f82,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-f47ddae1-69be-4587-9118-1dcd2bebd5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-03a6d180-d61f-4619-8764-f7a4997448a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-fe7f8d1b-8bbd-4894-9efe-90ecf8087144,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-01939456-403c-4ef5-b48f-4ba9ea7dd715,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-000c5b3f-e484-4f04-8247-4907697b2132,DISK], DatanodeInfoWithStorage[127.0.0.1:42410,DS-e09c0d48-dee5-4894-a1ec-1179b3212daf,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-20e26e26-0997-45c2-8040-9999c1f63a2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 50
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-107773837-172.17.0.4-1595809119392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42398,DS-9bb7b8e8-8377-4eee-ae34-f12c77f3dd4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-a36ab069-8420-4cdd-8d51-edec0a1c2e52,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-7ebe9921-ddb5-4f72-a46b-d90789aa2515,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-6985809f-21a1-4f86-9daf-a87062a934e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-12f32177-b0c0-43b6-b53d-e995dae63730,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-945cd949-20c2-4493-af6e-d3ad25a30291,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-9f04b008-e2ce-44f6-9e8c-115ae2ac1437,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-476f834d-d36e-42d4-a378-09cce14b166b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-107773837-172.17.0.4-1595809119392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42398,DS-9bb7b8e8-8377-4eee-ae34-f12c77f3dd4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-a36ab069-8420-4cdd-8d51-edec0a1c2e52,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-7ebe9921-ddb5-4f72-a46b-d90789aa2515,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-6985809f-21a1-4f86-9daf-a87062a934e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-12f32177-b0c0-43b6-b53d-e995dae63730,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-945cd949-20c2-4493-af6e-d3ad25a30291,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-9f04b008-e2ce-44f6-9e8c-115ae2ac1437,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-476f834d-d36e-42d4-a378-09cce14b166b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 50
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1241853663-172.17.0.4-1595809632873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35475,DS-7c474d4b-7962-4d38-bf28-2fad9b739b76,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-c93f6d2e-a767-46ec-b9ae-fb5f465b8abe,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-936b7805-d86b-4070-9a6f-ac4bb2d896a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-126fc8c4-82c5-4b73-85e7-006d7f2d0e05,DISK], DatanodeInfoWithStorage[127.0.0.1:46323,DS-872af5fc-8862-48d1-97a9-3c5f4009bffe,DISK], DatanodeInfoWithStorage[127.0.0.1:36989,DS-c83c5c69-606b-42fc-a14a-2dab67950c37,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-999bde88-e128-4aff-902c-995af33de535,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-131145f6-6125-417e-8d3f-431e33215ab7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1241853663-172.17.0.4-1595809632873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35475,DS-7c474d4b-7962-4d38-bf28-2fad9b739b76,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-c93f6d2e-a767-46ec-b9ae-fb5f465b8abe,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-936b7805-d86b-4070-9a6f-ac4bb2d896a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-126fc8c4-82c5-4b73-85e7-006d7f2d0e05,DISK], DatanodeInfoWithStorage[127.0.0.1:46323,DS-872af5fc-8862-48d1-97a9-3c5f4009bffe,DISK], DatanodeInfoWithStorage[127.0.0.1:36989,DS-c83c5c69-606b-42fc-a14a-2dab67950c37,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-999bde88-e128-4aff-902c-995af33de535,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-131145f6-6125-417e-8d3f-431e33215ab7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 50
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-278729005-172.17.0.4-1595809980956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39655,DS-d3884a1f-f6d7-41d3-83bd-4dc78ea25823,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-cf8f5256-ada7-4676-9433-557775898abe,DISK], DatanodeInfoWithStorage[127.0.0.1:34890,DS-1c0d949b-c980-4c41-9878-de68376a7d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42354,DS-04b2b13c-c59d-41c3-baac-f08feaf1f803,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-a93b5ba3-d319-4791-8e97-df5394989d63,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-908c3e81-2317-4a88-ba3a-8d0ed6819e40,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-0392fedb-3da8-4ef3-a6b3-00f08234aa55,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-4c51210f-df16-408f-bd00-239a51852040,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-278729005-172.17.0.4-1595809980956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39655,DS-d3884a1f-f6d7-41d3-83bd-4dc78ea25823,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-cf8f5256-ada7-4676-9433-557775898abe,DISK], DatanodeInfoWithStorage[127.0.0.1:34890,DS-1c0d949b-c980-4c41-9878-de68376a7d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42354,DS-04b2b13c-c59d-41c3-baac-f08feaf1f803,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-a93b5ba3-d319-4791-8e97-df5394989d63,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-908c3e81-2317-4a88-ba3a-8d0ed6819e40,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-0392fedb-3da8-4ef3-a6b3-00f08234aa55,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-4c51210f-df16-408f-bd00-239a51852040,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 50
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-704880972-172.17.0.4-1595811165128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45538,DS-90c11455-aec4-4af9-8e05-de777d3eb13f,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-7a13f135-239e-4133-98f5-03d87516b19e,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-ad9bea4b-4094-40c0-bf0e-0623ba9994b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-1f2c4bcf-0c4e-4788-9b78-faac8b4bb062,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-76f3b941-4151-4cd9-ba41-09a9004c8c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-8a33f01e-60ae-4a6c-87c8-63ed05a27c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-937da688-adc2-4f6f-8ccf-cda05730e69d,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-878f9420-fe40-4971-820f-3c310a086ec7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-704880972-172.17.0.4-1595811165128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45538,DS-90c11455-aec4-4af9-8e05-de777d3eb13f,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-7a13f135-239e-4133-98f5-03d87516b19e,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-ad9bea4b-4094-40c0-bf0e-0623ba9994b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-1f2c4bcf-0c4e-4788-9b78-faac8b4bb062,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-76f3b941-4151-4cd9-ba41-09a9004c8c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-8a33f01e-60ae-4a6c-87c8-63ed05a27c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-937da688-adc2-4f6f-8ccf-cda05730e69d,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-878f9420-fe40-4971-820f-3c310a086ec7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 50
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-650638403-172.17.0.4-1595812043380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45250,DS-09ea06ef-70b8-41f3-9783-8756e8f9eca4,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-bd62dc3e-4894-4a96-9e8a-9d5d7181023d,DISK], DatanodeInfoWithStorage[127.0.0.1:33682,DS-d61c6290-7f6e-4f5b-8c33-c7da737b9846,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-2fa79931-8351-4902-b683-e2784c54f8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-fbe51b7b-a6cf-4b7a-9fa9-f51831f09211,DISK], DatanodeInfoWithStorage[127.0.0.1:43778,DS-4b39cea6-c1b6-4a69-995a-a7766cc27829,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-d429fda3-5731-4a7f-9780-016353074096,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-e46327f3-d532-46bf-912c-38b8e67a2f6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-650638403-172.17.0.4-1595812043380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45250,DS-09ea06ef-70b8-41f3-9783-8756e8f9eca4,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-bd62dc3e-4894-4a96-9e8a-9d5d7181023d,DISK], DatanodeInfoWithStorage[127.0.0.1:33682,DS-d61c6290-7f6e-4f5b-8c33-c7da737b9846,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-2fa79931-8351-4902-b683-e2784c54f8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-fbe51b7b-a6cf-4b7a-9fa9-f51831f09211,DISK], DatanodeInfoWithStorage[127.0.0.1:43778,DS-4b39cea6-c1b6-4a69-995a-a7766cc27829,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-d429fda3-5731-4a7f-9780-016353074096,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-e46327f3-d532-46bf-912c-38b8e67a2f6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 50
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-12225362-172.17.0.4-1595812184844:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41674,DS-944f3c68-33f2-4a2e-b92a-ca8af34be4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-5cb4f3f3-3dcd-415b-b758-d1652a9cbb2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-07fba198-907b-4eee-88ad-64d32d0d14c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-d38f359f-ebb3-40e2-9d0d-69b9d13319f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-85695179-f56c-4f2d-960e-e0e4c3b55092,DISK], DatanodeInfoWithStorage[127.0.0.1:42395,DS-d51347e0-533b-45e9-a9cf-95e15ff75b06,DISK], DatanodeInfoWithStorage[127.0.0.1:43618,DS-d15db99a-e302-4ef3-bc3c-83f38787f230,DISK], DatanodeInfoWithStorage[127.0.0.1:34437,DS-4a86cc9f-e91c-44f6-9b98-36290a09a0c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-12225362-172.17.0.4-1595812184844:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41674,DS-944f3c68-33f2-4a2e-b92a-ca8af34be4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-5cb4f3f3-3dcd-415b-b758-d1652a9cbb2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-07fba198-907b-4eee-88ad-64d32d0d14c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-d38f359f-ebb3-40e2-9d0d-69b9d13319f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-85695179-f56c-4f2d-960e-e0e4c3b55092,DISK], DatanodeInfoWithStorage[127.0.0.1:42395,DS-d51347e0-533b-45e9-a9cf-95e15ff75b06,DISK], DatanodeInfoWithStorage[127.0.0.1:43618,DS-d15db99a-e302-4ef3-bc3c-83f38787f230,DISK], DatanodeInfoWithStorage[127.0.0.1:34437,DS-4a86cc9f-e91c-44f6-9b98-36290a09a0c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 50
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1778810965-172.17.0.4-1595812643951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38287,DS-2b45dd33-f230-4ea1-b508-2941058bef79,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-1ef3954c-b341-43e0-9e96-694cef17bb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-186a9908-a6e2-4d57-948c-75d9b01b00e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-e42d4d8a-a048-499d-b646-447444c06644,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-22309005-dc1f-4140-941e-3c234709cc03,DISK], DatanodeInfoWithStorage[127.0.0.1:35584,DS-d9680d36-af8e-4cc4-9f4e-e5220c659ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-ea1803a0-8a68-4c0c-b0b6-816ebb068eee,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-411933fa-2742-4592-bce7-f116125b2737,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1778810965-172.17.0.4-1595812643951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38287,DS-2b45dd33-f230-4ea1-b508-2941058bef79,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-1ef3954c-b341-43e0-9e96-694cef17bb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-186a9908-a6e2-4d57-948c-75d9b01b00e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-e42d4d8a-a048-499d-b646-447444c06644,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-22309005-dc1f-4140-941e-3c234709cc03,DISK], DatanodeInfoWithStorage[127.0.0.1:35584,DS-d9680d36-af8e-4cc4-9f4e-e5220c659ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-ea1803a0-8a68-4c0c-b0b6-816ebb068eee,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-411933fa-2742-4592-bce7-f116125b2737,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 50
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1301195156-172.17.0.4-1595813044052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41409,DS-8e316291-4607-417c-9317-dc31fe0a5e43,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-00d89f2b-6e7c-416b-8ea0-ec9ef9783dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-988a6f99-8957-4a01-aa72-0c9f6b9d386e,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-e890633e-c3d6-4c03-9430-6f5f12b055c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-4fc76b84-f1c9-4f19-a2e4-64e79464f728,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-2c5d8f2f-665d-4bdf-b423-da967440b491,DISK], DatanodeInfoWithStorage[127.0.0.1:33476,DS-0a67cb3a-948b-4bf6-8f03-9417f1f5abe2,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-717983e3-b233-4174-8951-8003026abc68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1301195156-172.17.0.4-1595813044052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41409,DS-8e316291-4607-417c-9317-dc31fe0a5e43,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-00d89f2b-6e7c-416b-8ea0-ec9ef9783dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-988a6f99-8957-4a01-aa72-0c9f6b9d386e,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-e890633e-c3d6-4c03-9430-6f5f12b055c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-4fc76b84-f1c9-4f19-a2e4-64e79464f728,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-2c5d8f2f-665d-4bdf-b423-da967440b491,DISK], DatanodeInfoWithStorage[127.0.0.1:33476,DS-0a67cb3a-948b-4bf6-8f03-9417f1f5abe2,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-717983e3-b233-4174-8951-8003026abc68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 6671
