reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1445072846-172.17.0.18-1595830061855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43817,DS-127b51a7-0a4b-4861-95c2-afd5a6c41d98,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-e8e0383e-bd42-40e6-b881-22cbe9a2e308,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-873c9d24-d5ee-4369-aa90-bd3b0ea1c266,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-6f59383c-28ff-46e3-bdd6-415968bee237,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-a6d7b689-be14-48eb-89f4-b6b6860e232e,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-d3b83eb1-8098-4433-ac70-8d540ec65659,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-929635d4-c0c8-4da0-9704-3d640cac8cea,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-cbd18f46-ff1b-44e0-8b09-cafbf5701f79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1445072846-172.17.0.18-1595830061855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43817,DS-127b51a7-0a4b-4861-95c2-afd5a6c41d98,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-e8e0383e-bd42-40e6-b881-22cbe9a2e308,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-873c9d24-d5ee-4369-aa90-bd3b0ea1c266,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-6f59383c-28ff-46e3-bdd6-415968bee237,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-a6d7b689-be14-48eb-89f4-b6b6860e232e,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-d3b83eb1-8098-4433-ac70-8d540ec65659,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-929635d4-c0c8-4da0-9704-3d640cac8cea,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-cbd18f46-ff1b-44e0-8b09-cafbf5701f79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424795929-172.17.0.18-1595830375038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34630,DS-e34dd8ba-497a-43f8-953c-c73da3a1f8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-1c44258a-daf4-4549-9724-fe8ba94122b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-8e0c7cc8-913f-4920-956d-89ccac1a6be6,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-ba7f5f66-aa62-47f2-a117-a3a7a867c53e,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-acd6a3e3-5f74-40bd-bf2f-46c4739be96c,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-3eef23cb-d555-46b8-8319-14afca914114,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-6e7fb929-2f9f-466f-95d7-dd8baad52a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-3541378b-32a1-452d-a9f5-996f5808dd0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424795929-172.17.0.18-1595830375038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34630,DS-e34dd8ba-497a-43f8-953c-c73da3a1f8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-1c44258a-daf4-4549-9724-fe8ba94122b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-8e0c7cc8-913f-4920-956d-89ccac1a6be6,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-ba7f5f66-aa62-47f2-a117-a3a7a867c53e,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-acd6a3e3-5f74-40bd-bf2f-46c4739be96c,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-3eef23cb-d555-46b8-8319-14afca914114,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-6e7fb929-2f9f-466f-95d7-dd8baad52a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-3541378b-32a1-452d-a9f5-996f5808dd0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-757034025-172.17.0.18-1595830818905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39982,DS-c3da261e-103a-490a-84b7-3e3125bcf6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35092,DS-412663f8-29ff-4eea-924f-025069363110,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-5e1cf3d0-7cef-415f-96ef-c45026e0b3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-d663117d-e1ad-4ba5-8e67-46a876bd4b44,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-8e9feb8e-f7c8-4dc6-998a-3eec39b4ebd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-958cd4ac-22c9-4684-808e-694c54e9cf93,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-fbbacea4-b9cd-4e2a-9fb3-ca2f8e7ef745,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-d2788c63-4002-4492-8603-3aa8edf3072f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-757034025-172.17.0.18-1595830818905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39982,DS-c3da261e-103a-490a-84b7-3e3125bcf6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35092,DS-412663f8-29ff-4eea-924f-025069363110,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-5e1cf3d0-7cef-415f-96ef-c45026e0b3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-d663117d-e1ad-4ba5-8e67-46a876bd4b44,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-8e9feb8e-f7c8-4dc6-998a-3eec39b4ebd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-958cd4ac-22c9-4684-808e-694c54e9cf93,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-fbbacea4-b9cd-4e2a-9fb3-ca2f8e7ef745,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-d2788c63-4002-4492-8603-3aa8edf3072f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-352062957-172.17.0.18-1595831138576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40109,DS-6fb7852b-2e13-4e8e-a7e0-c1c695b7adfc,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-0559ccad-aa58-416c-a120-2b2319b6a433,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-47b09980-fb9e-4499-8ba1-7f615038b817,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-e239979c-ee96-4d29-bd1e-6ce4238fa9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33012,DS-1070e704-cb21-462b-ac49-4aac22aa09e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-1e7471dd-5e82-44be-8ded-142f1ba775fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-3b4396cb-d971-4aaa-bb52-7aa28bdcf176,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-c0e6b7d6-fb57-42c6-a398-8765a92ac270,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-352062957-172.17.0.18-1595831138576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40109,DS-6fb7852b-2e13-4e8e-a7e0-c1c695b7adfc,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-0559ccad-aa58-416c-a120-2b2319b6a433,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-47b09980-fb9e-4499-8ba1-7f615038b817,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-e239979c-ee96-4d29-bd1e-6ce4238fa9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33012,DS-1070e704-cb21-462b-ac49-4aac22aa09e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-1e7471dd-5e82-44be-8ded-142f1ba775fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-3b4396cb-d971-4aaa-bb52-7aa28bdcf176,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-c0e6b7d6-fb57-42c6-a398-8765a92ac270,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1445681096-172.17.0.18-1595831531140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35342,DS-330b3d91-c50d-4aba-8faf-17b7a91c1836,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-05dd1285-c291-47e1-a6ae-6bdacfdef9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-98160ebe-a50f-4e77-9a43-5453b247d34c,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-fff6e4bd-99c5-4660-a8cc-f0782d250582,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-e665c1f8-7aa7-4b53-8c48-e7d41d65ea23,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-8738f6d2-f69e-4e0d-a884-438e2130edf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35433,DS-07702b40-c753-430e-a5be-f41bbfa8b050,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-ae7148b9-e841-426e-8e31-271ad3dcdab9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1445681096-172.17.0.18-1595831531140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35342,DS-330b3d91-c50d-4aba-8faf-17b7a91c1836,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-05dd1285-c291-47e1-a6ae-6bdacfdef9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-98160ebe-a50f-4e77-9a43-5453b247d34c,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-fff6e4bd-99c5-4660-a8cc-f0782d250582,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-e665c1f8-7aa7-4b53-8c48-e7d41d65ea23,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-8738f6d2-f69e-4e0d-a884-438e2130edf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35433,DS-07702b40-c753-430e-a5be-f41bbfa8b050,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-ae7148b9-e841-426e-8e31-271ad3dcdab9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1581043862-172.17.0.18-1595832253971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35212,DS-ac1f16a3-8d20-4d9a-a861-3c1e947ef690,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-828a0c6c-dee6-42fd-af49-f578d5409f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44116,DS-e2f5d975-289a-4e33-8947-9c70ceb06a38,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-6daafa0e-6cd6-4de9-9247-0b4ae1634890,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-660c15b9-b59a-455a-bc6f-d961d9077b39,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-ccec2661-a52c-4944-aebc-f5649099e49a,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-661af2d5-c8ea-45b0-94e7-297f28b9f8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-1883818a-4ce8-4074-a576-feb866e8f7ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1581043862-172.17.0.18-1595832253971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35212,DS-ac1f16a3-8d20-4d9a-a861-3c1e947ef690,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-828a0c6c-dee6-42fd-af49-f578d5409f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44116,DS-e2f5d975-289a-4e33-8947-9c70ceb06a38,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-6daafa0e-6cd6-4de9-9247-0b4ae1634890,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-660c15b9-b59a-455a-bc6f-d961d9077b39,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-ccec2661-a52c-4944-aebc-f5649099e49a,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-661af2d5-c8ea-45b0-94e7-297f28b9f8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-1883818a-4ce8-4074-a576-feb866e8f7ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1601346033-172.17.0.18-1595832322927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45081,DS-91132f90-b57a-44b2-af7f-cd6e0352e082,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-f6929c6c-2033-4a55-a046-196dad51029a,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-52ead47e-a323-4e90-86a9-440d6d1ee420,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-0ce2b4f6-b08c-41e9-8799-4a0adcff0426,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-0d5ffa47-0853-498c-9511-00376beb8f68,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-db32fa28-7702-448b-b8f7-7956ed28ffe4,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-536f135e-0785-4213-a6d8-eedd2cdaa3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-204e84eb-b203-4b93-9a6a-a5c2503cf66e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1601346033-172.17.0.18-1595832322927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45081,DS-91132f90-b57a-44b2-af7f-cd6e0352e082,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-f6929c6c-2033-4a55-a046-196dad51029a,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-52ead47e-a323-4e90-86a9-440d6d1ee420,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-0ce2b4f6-b08c-41e9-8799-4a0adcff0426,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-0d5ffa47-0853-498c-9511-00376beb8f68,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-db32fa28-7702-448b-b8f7-7956ed28ffe4,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-536f135e-0785-4213-a6d8-eedd2cdaa3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-204e84eb-b203-4b93-9a6a-a5c2503cf66e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-597336359-172.17.0.18-1595832712359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46202,DS-c3610f68-9e26-4787-a79b-ca9b82e7f090,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-6237d37f-3df8-4ab7-85bf-25107ccdce99,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-94283618-2f56-420d-ae2d-802167b3d0db,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-2ac5190a-d325-4364-b6bd-409548b05d86,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-8669f69a-cd09-42f5-81d7-7a9f5f86c74e,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-7ce1dbe9-8e93-458d-94a7-1e35f358cbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42736,DS-4d12f4f1-6019-4759-8d54-b8313a485581,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-f710d8d7-48c1-4a69-83f1-0767e12bccbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-597336359-172.17.0.18-1595832712359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46202,DS-c3610f68-9e26-4787-a79b-ca9b82e7f090,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-6237d37f-3df8-4ab7-85bf-25107ccdce99,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-94283618-2f56-420d-ae2d-802167b3d0db,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-2ac5190a-d325-4364-b6bd-409548b05d86,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-8669f69a-cd09-42f5-81d7-7a9f5f86c74e,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-7ce1dbe9-8e93-458d-94a7-1e35f358cbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42736,DS-4d12f4f1-6019-4759-8d54-b8313a485581,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-f710d8d7-48c1-4a69-83f1-0767e12bccbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-246746632-172.17.0.18-1595832770289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35377,DS-d04ce437-a5ad-48da-93b4-5d4323dc2c19,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-83341b15-0972-4d6a-8928-d07d85ea7f15,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-be101ee2-946f-4bc0-8289-b22d344da82b,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-949682bb-7af7-465a-8197-cfa247bb9e52,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-4b129671-c0de-44e7-8c35-e0d218952662,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-58226838-8f4d-4f2e-80fc-14ebb2e99f60,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-4fdb9e33-4f75-429e-af1c-a0298d9aeab0,DISK], DatanodeInfoWithStorage[127.0.0.1:33854,DS-5171ba4a-bf30-4314-a232-d0efd0e821c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-246746632-172.17.0.18-1595832770289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35377,DS-d04ce437-a5ad-48da-93b4-5d4323dc2c19,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-83341b15-0972-4d6a-8928-d07d85ea7f15,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-be101ee2-946f-4bc0-8289-b22d344da82b,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-949682bb-7af7-465a-8197-cfa247bb9e52,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-4b129671-c0de-44e7-8c35-e0d218952662,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-58226838-8f4d-4f2e-80fc-14ebb2e99f60,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-4fdb9e33-4f75-429e-af1c-a0298d9aeab0,DISK], DatanodeInfoWithStorage[127.0.0.1:33854,DS-5171ba4a-bf30-4314-a232-d0efd0e821c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1566876823-172.17.0.18-1595832838460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35114,DS-b82973df-45c2-49c2-b9ba-288f74dcddc3,DISK], DatanodeInfoWithStorage[127.0.0.1:34282,DS-49f29f62-6a7b-439e-addc-740b5a612770,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-38413690-fea1-4af0-bc83-c27bb3b3a8be,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-64d925b2-6c54-4b22-84b5-de099291d0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-8181e34b-1497-49f5-a3bd-73619c99ef4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-dc5f05bc-5800-47cc-afde-1398b5e21802,DISK], DatanodeInfoWithStorage[127.0.0.1:40050,DS-c5057131-4381-4039-a2ef-073f70392dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-d3fe9b17-b024-4513-bdf2-9df523019782,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1566876823-172.17.0.18-1595832838460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35114,DS-b82973df-45c2-49c2-b9ba-288f74dcddc3,DISK], DatanodeInfoWithStorage[127.0.0.1:34282,DS-49f29f62-6a7b-439e-addc-740b5a612770,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-38413690-fea1-4af0-bc83-c27bb3b3a8be,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-64d925b2-6c54-4b22-84b5-de099291d0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-8181e34b-1497-49f5-a3bd-73619c99ef4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-dc5f05bc-5800-47cc-afde-1398b5e21802,DISK], DatanodeInfoWithStorage[127.0.0.1:40050,DS-c5057131-4381-4039-a2ef-073f70392dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-d3fe9b17-b024-4513-bdf2-9df523019782,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-821863008-172.17.0.18-1595832872765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33578,DS-6604eb79-9d33-4b7a-b67b-d46afb3e7466,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-7f4680e5-4f36-4332-9773-fceca782ad16,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-099489e3-88b7-42b2-9fea-d4fb374edb19,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-c3cd26bb-4276-40e7-9c2d-a88691e1b6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33508,DS-5ca8e2d8-f7dc-4bd8-a255-1627eb402727,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-fd649a90-2de1-4e63-b246-4f215b8a6150,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-60d4d7e0-5a68-41f9-9eb6-cba6ed69d2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-076dbd43-12f9-4a52-9e3a-4f3110c43903,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-821863008-172.17.0.18-1595832872765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33578,DS-6604eb79-9d33-4b7a-b67b-d46afb3e7466,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-7f4680e5-4f36-4332-9773-fceca782ad16,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-099489e3-88b7-42b2-9fea-d4fb374edb19,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-c3cd26bb-4276-40e7-9c2d-a88691e1b6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33508,DS-5ca8e2d8-f7dc-4bd8-a255-1627eb402727,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-fd649a90-2de1-4e63-b246-4f215b8a6150,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-60d4d7e0-5a68-41f9-9eb6-cba6ed69d2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-076dbd43-12f9-4a52-9e3a-4f3110c43903,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2130885897-172.17.0.18-1595832973971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37126,DS-9c14aaf7-cb95-479d-b331-1d899555d315,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-7e43bc21-d2ea-4f0f-8af0-b461e5a15893,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-cf9ccbaa-9dc8-451b-af6f-8c64eeba061d,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-caf1e9a3-b2cc-499e-adda-4899a2d893bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-9b56b820-1a1e-4d64-97e4-fcec51fbcd19,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-bc3bf508-5eea-4162-9fa1-2f9f8298f47c,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-3e03004d-4d80-48e1-9103-17fedae17ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-9d09c5f5-d767-4ed9-a8f8-ce01ef82cdb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2130885897-172.17.0.18-1595832973971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37126,DS-9c14aaf7-cb95-479d-b331-1d899555d315,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-7e43bc21-d2ea-4f0f-8af0-b461e5a15893,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-cf9ccbaa-9dc8-451b-af6f-8c64eeba061d,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-caf1e9a3-b2cc-499e-adda-4899a2d893bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-9b56b820-1a1e-4d64-97e4-fcec51fbcd19,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-bc3bf508-5eea-4162-9fa1-2f9f8298f47c,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-3e03004d-4d80-48e1-9103-17fedae17ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-9d09c5f5-d767-4ed9-a8f8-ce01ef82cdb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-736638539-172.17.0.18-1595833390950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44995,DS-10699952-e808-4e2e-ba5c-d0fe315fefd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-dddfbbef-6d7a-4192-a40e-aaeca27d48ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-2e8d4086-7642-412d-839e-be348af57cad,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-d0709cbd-8f54-4b87-a31d-33cb05aa1553,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-0b51b2d4-a6df-4c60-8f80-6e3c5da926f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-68f7a2cc-32a1-4fc3-9d4a-5b546d5c43f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-00dc8f29-20ad-4d52-82ba-b120d906f8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-11cdacd1-baf7-403b-8f74-05a59cea891d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-736638539-172.17.0.18-1595833390950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44995,DS-10699952-e808-4e2e-ba5c-d0fe315fefd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-dddfbbef-6d7a-4192-a40e-aaeca27d48ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-2e8d4086-7642-412d-839e-be348af57cad,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-d0709cbd-8f54-4b87-a31d-33cb05aa1553,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-0b51b2d4-a6df-4c60-8f80-6e3c5da926f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-68f7a2cc-32a1-4fc3-9d4a-5b546d5c43f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-00dc8f29-20ad-4d52-82ba-b120d906f8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-11cdacd1-baf7-403b-8f74-05a59cea891d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1358600523-172.17.0.18-1595833461761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34394,DS-0bf94959-5511-4b5c-980d-eb4aeebf5042,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-c0433ed1-b919-4596-a391-0551be3c03ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-28fe0c51-9fb7-4122-80a6-4c6683328e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-439c076c-be73-4f29-ab00-3e9328fb3c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46634,DS-461308b4-138e-45ca-b2d3-25306b524e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-03382696-579d-4fa3-a22b-7864cd019eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-a445a5d0-567f-443c-8b17-9b85656fb78e,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-d07f6b07-ca36-461b-8f49-a35c37b70682,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1358600523-172.17.0.18-1595833461761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34394,DS-0bf94959-5511-4b5c-980d-eb4aeebf5042,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-c0433ed1-b919-4596-a391-0551be3c03ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-28fe0c51-9fb7-4122-80a6-4c6683328e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-439c076c-be73-4f29-ab00-3e9328fb3c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46634,DS-461308b4-138e-45ca-b2d3-25306b524e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-03382696-579d-4fa3-a22b-7864cd019eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-a445a5d0-567f-443c-8b17-9b85656fb78e,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-d07f6b07-ca36-461b-8f49-a35c37b70682,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-965753582-172.17.0.18-1595833776980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35144,DS-0f039cde-a7b3-4190-867f-cc924def04d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-d267e4a0-8845-41e5-9363-4aa538551ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:34759,DS-de5f25d1-12b7-4455-b9b9-896ec0676f25,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-1cb51646-4853-42f7-98a8-22d75895b782,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-c67e1159-6bea-4562-9c44-259d9175e4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42742,DS-45e59eaf-b6f3-4401-81ee-a028a7240547,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-51638f5e-9573-4d88-ac05-52b65f819964,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-c7efdffb-738e-4d8e-bde9-215af3e4b02c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-965753582-172.17.0.18-1595833776980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35144,DS-0f039cde-a7b3-4190-867f-cc924def04d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-d267e4a0-8845-41e5-9363-4aa538551ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:34759,DS-de5f25d1-12b7-4455-b9b9-896ec0676f25,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-1cb51646-4853-42f7-98a8-22d75895b782,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-c67e1159-6bea-4562-9c44-259d9175e4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42742,DS-45e59eaf-b6f3-4401-81ee-a028a7240547,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-51638f5e-9573-4d88-ac05-52b65f819964,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-c7efdffb-738e-4d8e-bde9-215af3e4b02c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-687510721-172.17.0.18-1595834277759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38245,DS-7d9154d7-d600-4482-a978-713669c6b8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-4f290cb0-ebff-463e-bf64-f2a65da85a81,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-b7f8d6fe-8f10-4c4f-867e-21eda322c9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-0f18d5ee-3f9a-49a3-a936-5282193bcb27,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-f9cfeb9f-ee5e-4c5d-a374-4c192cc4ad56,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-78d66c5b-ca82-4506-a3f6-f31766bd4824,DISK], DatanodeInfoWithStorage[127.0.0.1:43677,DS-8d8317b2-1ee1-4295-a41c-3e113a4dbcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-91c7acbc-dccc-41ba-bb4a-71b194c8851c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-687510721-172.17.0.18-1595834277759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38245,DS-7d9154d7-d600-4482-a978-713669c6b8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-4f290cb0-ebff-463e-bf64-f2a65da85a81,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-b7f8d6fe-8f10-4c4f-867e-21eda322c9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-0f18d5ee-3f9a-49a3-a936-5282193bcb27,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-f9cfeb9f-ee5e-4c5d-a374-4c192cc4ad56,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-78d66c5b-ca82-4506-a3f6-f31766bd4824,DISK], DatanodeInfoWithStorage[127.0.0.1:43677,DS-8d8317b2-1ee1-4295-a41c-3e113a4dbcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-91c7acbc-dccc-41ba-bb4a-71b194c8851c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1458561049-172.17.0.18-1595834382157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39534,DS-ac980471-7940-41e3-a75f-b5d1ab1525ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-86a52324-4748-46a0-a5a5-e96aa89e4007,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-9eb5631b-df34-4ab4-bddf-2028c6b44cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-4872848d-0b51-4c2b-a2e6-4bfcd06dafc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-750855b3-a540-430b-af4c-7fc22b9b067d,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-b4a03b91-bf04-4b4a-ba93-b487a4f12380,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-47121c01-0f2e-4e2e-ad00-0812bf3e7760,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-3277bdf9-f2b0-4bec-a42a-15d2be6399af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1458561049-172.17.0.18-1595834382157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39534,DS-ac980471-7940-41e3-a75f-b5d1ab1525ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-86a52324-4748-46a0-a5a5-e96aa89e4007,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-9eb5631b-df34-4ab4-bddf-2028c6b44cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-4872848d-0b51-4c2b-a2e6-4bfcd06dafc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-750855b3-a540-430b-af4c-7fc22b9b067d,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-b4a03b91-bf04-4b4a-ba93-b487a4f12380,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-47121c01-0f2e-4e2e-ad00-0812bf3e7760,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-3277bdf9-f2b0-4bec-a42a-15d2be6399af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1296851311-172.17.0.18-1595834486152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33049,DS-d31242ed-04db-4ade-b562-b70190b24c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-ab4162aa-c337-4546-9e37-f286e3ecde8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-4adb812d-83f5-46b8-a059-0d0728cf47c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-79ec2c75-f01c-4cac-bac9-13df55d6d603,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-afa62e78-9a16-403b-b404-a8f8b526351a,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-c68c5305-fb25-4693-8559-5819aea2a160,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-c4b32f81-82ce-45e3-9857-6908793cc9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-94c6a3c0-3766-4aa0-a0aa-d869763721e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1296851311-172.17.0.18-1595834486152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33049,DS-d31242ed-04db-4ade-b562-b70190b24c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-ab4162aa-c337-4546-9e37-f286e3ecde8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-4adb812d-83f5-46b8-a059-0d0728cf47c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-79ec2c75-f01c-4cac-bac9-13df55d6d603,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-afa62e78-9a16-403b-b404-a8f8b526351a,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-c68c5305-fb25-4693-8559-5819aea2a160,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-c4b32f81-82ce-45e3-9857-6908793cc9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-94c6a3c0-3766-4aa0-a0aa-d869763721e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5229
