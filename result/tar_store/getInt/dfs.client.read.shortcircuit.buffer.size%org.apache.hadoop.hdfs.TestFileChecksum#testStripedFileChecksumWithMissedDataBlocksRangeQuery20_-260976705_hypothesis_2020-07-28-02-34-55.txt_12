reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-846311531-172.17.0.6-1595904395482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41522,DS-c18eca7a-7e3c-4eb9-a011-527053489347,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-4d5444c9-eca1-4dbe-9ab1-6487884e0051,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-9c0dc8de-e552-45c6-995a-310cb56ee2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-725053c5-ba09-4840-a12c-946d18f032a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-dd7d07a6-4eb6-4aed-9653-56a6bbef882f,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-6a5236ec-ec59-4774-beb8-6e6936384099,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-7c9a4350-da6d-4f48-92c4-5302b9c0417a,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-beeacd37-1fac-4d55-b024-1ea762db951f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-846311531-172.17.0.6-1595904395482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41522,DS-c18eca7a-7e3c-4eb9-a011-527053489347,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-4d5444c9-eca1-4dbe-9ab1-6487884e0051,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-9c0dc8de-e552-45c6-995a-310cb56ee2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-725053c5-ba09-4840-a12c-946d18f032a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-dd7d07a6-4eb6-4aed-9653-56a6bbef882f,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-6a5236ec-ec59-4774-beb8-6e6936384099,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-7c9a4350-da6d-4f48-92c4-5302b9c0417a,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-beeacd37-1fac-4d55-b024-1ea762db951f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-623224094-172.17.0.6-1595904860234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42468,DS-8086dc5c-74ff-47ce-8f36-e621d5289d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-ab2499ea-92fa-4e19-b0ab-5c6854b95f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-898b53a8-1104-4c2d-9692-201cc8c64e91,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-79a556ca-6c77-4ab0-88ac-7ba710c8ca12,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-0b78673e-d64d-43e9-ade0-f6a6a62e108b,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-8531c4e9-9ff8-486a-ad96-2c02e5881ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-f1b31224-c34a-43a8-8e6d-728d762e9ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-d873e765-9757-412c-9a9c-73e7d32ddd9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-623224094-172.17.0.6-1595904860234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42468,DS-8086dc5c-74ff-47ce-8f36-e621d5289d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-ab2499ea-92fa-4e19-b0ab-5c6854b95f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-898b53a8-1104-4c2d-9692-201cc8c64e91,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-79a556ca-6c77-4ab0-88ac-7ba710c8ca12,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-0b78673e-d64d-43e9-ade0-f6a6a62e108b,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-8531c4e9-9ff8-486a-ad96-2c02e5881ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-f1b31224-c34a-43a8-8e6d-728d762e9ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-d873e765-9757-412c-9a9c-73e7d32ddd9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1257716188-172.17.0.6-1595905715205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39647,DS-e9162fe3-f328-4737-85c9-4a97980c9b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-dca287a3-3617-4e03-98a2-3c43480e4b90,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-9813e89b-f657-48ed-a859-09e253f9e93b,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-bffc3045-40d8-4f18-a2e3-43b286214dde,DISK], DatanodeInfoWithStorage[127.0.0.1:32817,DS-a5f27e34-19b0-4af7-a029-9573d52f3893,DISK], DatanodeInfoWithStorage[127.0.0.1:39911,DS-7e464151-f376-4539-8270-d0297d214013,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-cd279f80-298b-4583-abd7-174a4edf33e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-28c3821f-1ab1-41f6-8083-524e47b567c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1257716188-172.17.0.6-1595905715205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39647,DS-e9162fe3-f328-4737-85c9-4a97980c9b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-dca287a3-3617-4e03-98a2-3c43480e4b90,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-9813e89b-f657-48ed-a859-09e253f9e93b,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-bffc3045-40d8-4f18-a2e3-43b286214dde,DISK], DatanodeInfoWithStorage[127.0.0.1:32817,DS-a5f27e34-19b0-4af7-a029-9573d52f3893,DISK], DatanodeInfoWithStorage[127.0.0.1:39911,DS-7e464151-f376-4539-8270-d0297d214013,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-cd279f80-298b-4583-abd7-174a4edf33e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-28c3821f-1ab1-41f6-8083-524e47b567c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-611162930-172.17.0.6-1595905839628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45622,DS-8c68090c-f72c-4e0a-9db2-a868072310ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-ab11a26d-d377-461c-a884-b0964a1f320a,DISK], DatanodeInfoWithStorage[127.0.0.1:33121,DS-2caf7c19-f492-4cc0-9b84-0c986677a1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36237,DS-f06da8c1-29df-4e6a-a581-554b223c5de4,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-a127fb98-7193-49ba-8a70-eafbc99bd3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-ebc2d90a-e1ab-4bbe-a4a3-3cfbd4a0e387,DISK], DatanodeInfoWithStorage[127.0.0.1:46010,DS-9f9bc593-dee5-4100-9f8c-4ee4c89f7943,DISK], DatanodeInfoWithStorage[127.0.0.1:45786,DS-4635ee4b-4947-4ebf-bc39-dc78f5b240c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-611162930-172.17.0.6-1595905839628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45622,DS-8c68090c-f72c-4e0a-9db2-a868072310ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-ab11a26d-d377-461c-a884-b0964a1f320a,DISK], DatanodeInfoWithStorage[127.0.0.1:33121,DS-2caf7c19-f492-4cc0-9b84-0c986677a1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36237,DS-f06da8c1-29df-4e6a-a581-554b223c5de4,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-a127fb98-7193-49ba-8a70-eafbc99bd3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-ebc2d90a-e1ab-4bbe-a4a3-3cfbd4a0e387,DISK], DatanodeInfoWithStorage[127.0.0.1:46010,DS-9f9bc593-dee5-4100-9f8c-4ee4c89f7943,DISK], DatanodeInfoWithStorage[127.0.0.1:45786,DS-4635ee4b-4947-4ebf-bc39-dc78f5b240c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2022087199-172.17.0.6-1595906399714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40729,DS-73204a30-b80c-488c-9339-e1f92db90e16,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-74595f52-ae98-44ef-b9f7-1ecc1eedcd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-94ac92ba-0a27-45f2-a7ba-cf57ba03bdc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-f59672d0-fb25-495e-9299-3e2b73249a75,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-d4076909-784d-4203-a3fc-184bd3ed9ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-3a1b9a79-77ea-47d8-89cf-6c9b2207522c,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-d818e182-6b3f-49b2-b81a-30329e87d6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39094,DS-38afb3fe-42e5-448d-9662-b504f4f2757d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2022087199-172.17.0.6-1595906399714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40729,DS-73204a30-b80c-488c-9339-e1f92db90e16,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-74595f52-ae98-44ef-b9f7-1ecc1eedcd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-94ac92ba-0a27-45f2-a7ba-cf57ba03bdc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-f59672d0-fb25-495e-9299-3e2b73249a75,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-d4076909-784d-4203-a3fc-184bd3ed9ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-3a1b9a79-77ea-47d8-89cf-6c9b2207522c,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-d818e182-6b3f-49b2-b81a-30329e87d6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39094,DS-38afb3fe-42e5-448d-9662-b504f4f2757d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1567510552-172.17.0.6-1595907564723:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46881,DS-be4de9f6-fb0f-453b-88f7-73167df7a43e,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-8027578b-4f84-467e-9f19-209fbbc25704,DISK], DatanodeInfoWithStorage[127.0.0.1:37469,DS-cefc459e-6745-4118-aaeb-b21cea0a8cce,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-6d61ac8a-1015-4ac4-97fa-9974efe25edb,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-d1463092-0e2a-40ef-bdac-91e50eb967dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-ca973e14-7c92-4a02-8ca3-905e15a46810,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-b2d0d3eb-3fde-4384-90a8-15d57a0a4a65,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-1c6eb250-239c-49f6-9298-289ef4d57d4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1567510552-172.17.0.6-1595907564723:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46881,DS-be4de9f6-fb0f-453b-88f7-73167df7a43e,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-8027578b-4f84-467e-9f19-209fbbc25704,DISK], DatanodeInfoWithStorage[127.0.0.1:37469,DS-cefc459e-6745-4118-aaeb-b21cea0a8cce,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-6d61ac8a-1015-4ac4-97fa-9974efe25edb,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-d1463092-0e2a-40ef-bdac-91e50eb967dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-ca973e14-7c92-4a02-8ca3-905e15a46810,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-b2d0d3eb-3fde-4384-90a8-15d57a0a4a65,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-1c6eb250-239c-49f6-9298-289ef4d57d4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1003499753-172.17.0.6-1595907631664:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34993,DS-8f4922b5-abe9-45a8-9d82-06d6028fcaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-e9b236a0-b098-4fc9-adf1-b58c539e6397,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-0cf90e9b-7807-41fa-9e44-63776417bf63,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-bee5f21e-8429-4b16-b11b-297d11f9bb6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-f41f5c8c-7454-446c-98c8-4bcd30923101,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-f10110f6-67fa-456f-8236-86b1c89275fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-a0bfdc1a-4f8f-44dc-b588-fdab83305283,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-b07092b0-cf6d-4909-b2ed-0fedc4a19854,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1003499753-172.17.0.6-1595907631664:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34993,DS-8f4922b5-abe9-45a8-9d82-06d6028fcaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-e9b236a0-b098-4fc9-adf1-b58c539e6397,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-0cf90e9b-7807-41fa-9e44-63776417bf63,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-bee5f21e-8429-4b16-b11b-297d11f9bb6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-f41f5c8c-7454-446c-98c8-4bcd30923101,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-f10110f6-67fa-456f-8236-86b1c89275fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-a0bfdc1a-4f8f-44dc-b588-fdab83305283,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-b07092b0-cf6d-4909-b2ed-0fedc4a19854,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-889424819-172.17.0.6-1595907898495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38433,DS-a32be978-adee-48bd-8d20-ce8cbdebed07,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-91d1ef1e-ee5b-4af5-af78-7c97c305995e,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-929640e2-25b9-424b-8c9d-be1613f92b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-ab122e8d-d976-494f-afeb-44afdf5b3433,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-9313de1e-8a72-47ad-926e-adb875f73bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-5bbb2d1c-aaa0-45f1-8379-3e205e1fd191,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-5dbf3441-f56e-4883-960a-ced984c4f561,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-4333c3fc-9741-435a-b3e5-a858b936b47b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-889424819-172.17.0.6-1595907898495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38433,DS-a32be978-adee-48bd-8d20-ce8cbdebed07,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-91d1ef1e-ee5b-4af5-af78-7c97c305995e,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-929640e2-25b9-424b-8c9d-be1613f92b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-ab122e8d-d976-494f-afeb-44afdf5b3433,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-9313de1e-8a72-47ad-926e-adb875f73bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-5bbb2d1c-aaa0-45f1-8379-3e205e1fd191,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-5dbf3441-f56e-4883-960a-ced984c4f561,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-4333c3fc-9741-435a-b3e5-a858b936b47b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1845779802-172.17.0.6-1595908078654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44027,DS-6bb4d348-251b-4a7a-be7b-2aea136b4e86,DISK], DatanodeInfoWithStorage[127.0.0.1:38915,DS-04872626-6578-47f6-99ea-cc17b1f0f672,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-2b07f28b-039c-4fc5-8c7d-ee52ccb8c7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-1e3f35d1-f369-437e-8344-b179d915f2da,DISK], DatanodeInfoWithStorage[127.0.0.1:40300,DS-7e280ad6-e589-4e15-9745-1031809f944d,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-8f152cfe-8ca9-4d08-b4b7-c2707194da39,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-66a2c597-89ce-44eb-a116-72c0e1188bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-4e949daf-a14c-4496-9394-66b9a31a2a94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1845779802-172.17.0.6-1595908078654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44027,DS-6bb4d348-251b-4a7a-be7b-2aea136b4e86,DISK], DatanodeInfoWithStorage[127.0.0.1:38915,DS-04872626-6578-47f6-99ea-cc17b1f0f672,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-2b07f28b-039c-4fc5-8c7d-ee52ccb8c7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-1e3f35d1-f369-437e-8344-b179d915f2da,DISK], DatanodeInfoWithStorage[127.0.0.1:40300,DS-7e280ad6-e589-4e15-9745-1031809f944d,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-8f152cfe-8ca9-4d08-b4b7-c2707194da39,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-66a2c597-89ce-44eb-a116-72c0e1188bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-4e949daf-a14c-4496-9394-66b9a31a2a94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-695903857-172.17.0.6-1595908392881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35090,DS-967e074f-8edc-4dd7-914e-9c21743ad170,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-271247e2-732b-4096-86be-80c17e03f054,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-d9072042-8a0d-4334-b63e-222c5608f7af,DISK], DatanodeInfoWithStorage[127.0.0.1:36475,DS-e8c0bacf-6f3d-4e98-8830-e1e4a5f69eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-f5fd11f6-fda5-4ea7-8267-f1745214ea9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-a2e4c25d-f0c6-4a39-9de8-70ec6689c6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-bcb2a8b8-7703-45f9-9360-8ab404d201d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-a18dd8f1-8c88-40f0-a606-bb32002e3819,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-695903857-172.17.0.6-1595908392881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35090,DS-967e074f-8edc-4dd7-914e-9c21743ad170,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-271247e2-732b-4096-86be-80c17e03f054,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-d9072042-8a0d-4334-b63e-222c5608f7af,DISK], DatanodeInfoWithStorage[127.0.0.1:36475,DS-e8c0bacf-6f3d-4e98-8830-e1e4a5f69eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-f5fd11f6-fda5-4ea7-8267-f1745214ea9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-a2e4c25d-f0c6-4a39-9de8-70ec6689c6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-bcb2a8b8-7703-45f9-9360-8ab404d201d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-a18dd8f1-8c88-40f0-a606-bb32002e3819,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-643745819-172.17.0.6-1595908435826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36709,DS-dfb959b3-7041-4da4-b4dd-c6f929b4a785,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-27a379c6-522e-43a2-bc5c-2e8382ae743e,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-298b10e8-ebae-4aa6-a694-0ca6b340ef2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44195,DS-019e4726-3499-480f-b6fa-1edfd0052cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-f0067b58-86e3-41a1-9bae-b902c763784c,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-da1b5bd9-f5fa-4244-b8f0-e8814faf7ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-bae635e9-63a7-42dd-9425-9dbe3addae8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-6e191b94-3172-4b31-a109-84df842fe883,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-643745819-172.17.0.6-1595908435826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36709,DS-dfb959b3-7041-4da4-b4dd-c6f929b4a785,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-27a379c6-522e-43a2-bc5c-2e8382ae743e,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-298b10e8-ebae-4aa6-a694-0ca6b340ef2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44195,DS-019e4726-3499-480f-b6fa-1edfd0052cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-f0067b58-86e3-41a1-9bae-b902c763784c,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-da1b5bd9-f5fa-4244-b8f0-e8814faf7ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-bae635e9-63a7-42dd-9425-9dbe3addae8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-6e191b94-3172-4b31-a109-84df842fe883,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-569960939-172.17.0.6-1595908536918:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44785,DS-5e7eac42-8336-4324-83b5-27540c87f43a,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-4f8d8353-5863-4f4b-9e4c-1d4f2a6bcd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-0ac72826-647f-4499-bea2-0356bbee34c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-8c39e009-ebd9-41cd-b903-100346dfce51,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-73b79e4c-3329-4941-968e-03cd1ee4b268,DISK], DatanodeInfoWithStorage[127.0.0.1:44419,DS-d96980de-b008-4a0e-ab00-a5ad793c7e96,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-baa985b4-438d-482b-9a89-2a4ece36e967,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-0b6345cc-c886-48fb-8771-779384d8be07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-569960939-172.17.0.6-1595908536918:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44785,DS-5e7eac42-8336-4324-83b5-27540c87f43a,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-4f8d8353-5863-4f4b-9e4c-1d4f2a6bcd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-0ac72826-647f-4499-bea2-0356bbee34c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-8c39e009-ebd9-41cd-b903-100346dfce51,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-73b79e4c-3329-4941-968e-03cd1ee4b268,DISK], DatanodeInfoWithStorage[127.0.0.1:44419,DS-d96980de-b008-4a0e-ab00-a5ad793c7e96,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-baa985b4-438d-482b-9a89-2a4ece36e967,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-0b6345cc-c886-48fb-8771-779384d8be07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5093
