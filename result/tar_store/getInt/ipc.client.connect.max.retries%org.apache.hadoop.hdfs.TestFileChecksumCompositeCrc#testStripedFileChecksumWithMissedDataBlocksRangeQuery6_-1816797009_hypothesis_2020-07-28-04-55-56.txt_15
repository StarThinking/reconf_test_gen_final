reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980916715-172.17.0.7-1595912171421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33734,DS-e9c319f3-80c8-42ed-b099-9c7d74d0813a,DISK], DatanodeInfoWithStorage[127.0.0.1:42631,DS-ae2109fa-b2e1-4d10-84b5-b8c360173dce,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-528174bd-2859-4cde-b657-ea0dd86492b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-2abf4cf6-9e4f-478c-ab58-3557b49ec4db,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-ac060402-a98b-4edd-b167-3214bfad463f,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-e26c1405-ec28-4d4b-8072-efa2ad78906b,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-525d3375-31d2-466d-bcad-237a3a06f9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-8d0f428f-72d7-4f63-ac81-c913830b6d9b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980916715-172.17.0.7-1595912171421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33734,DS-e9c319f3-80c8-42ed-b099-9c7d74d0813a,DISK], DatanodeInfoWithStorage[127.0.0.1:42631,DS-ae2109fa-b2e1-4d10-84b5-b8c360173dce,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-528174bd-2859-4cde-b657-ea0dd86492b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-2abf4cf6-9e4f-478c-ab58-3557b49ec4db,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-ac060402-a98b-4edd-b167-3214bfad463f,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-e26c1405-ec28-4d4b-8072-efa2ad78906b,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-525d3375-31d2-466d-bcad-237a3a06f9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-8d0f428f-72d7-4f63-ac81-c913830b6d9b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1145474462-172.17.0.7-1595912276640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37622,DS-8aedafdb-d669-44bb-8d90-6a866eef7f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-ad619abb-48f9-4c55-92b2-f5f6163cbb23,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-d218636f-dade-4cab-820f-3388347f2d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-f468fe38-d21c-4bdf-b7ae-0a3fc483d1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-37e85496-8162-4614-a0a6-07c65a48a8be,DISK], DatanodeInfoWithStorage[127.0.0.1:33590,DS-58b6d165-1d84-40c8-a0c7-aa481329048e,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-38434689-b981-4750-8436-87aab9db92cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-57506c22-7915-4f99-b169-3c6f3b020bb9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1145474462-172.17.0.7-1595912276640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37622,DS-8aedafdb-d669-44bb-8d90-6a866eef7f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-ad619abb-48f9-4c55-92b2-f5f6163cbb23,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-d218636f-dade-4cab-820f-3388347f2d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-f468fe38-d21c-4bdf-b7ae-0a3fc483d1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-37e85496-8162-4614-a0a6-07c65a48a8be,DISK], DatanodeInfoWithStorage[127.0.0.1:33590,DS-58b6d165-1d84-40c8-a0c7-aa481329048e,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-38434689-b981-4750-8436-87aab9db92cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-57506c22-7915-4f99-b169-3c6f3b020bb9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1162981505-172.17.0.7-1595912419594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45161,DS-8507c66d-a487-4094-b613-b733487f61a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-a5312bcf-1121-4935-8e2f-6fe0f1a7873f,DISK], DatanodeInfoWithStorage[127.0.0.1:36175,DS-461bc4f4-3132-4a98-a72c-fc8918448f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-d522474e-c409-4c79-83e6-c5a56725a819,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-5d6592f1-6f6b-4b52-8413-60268b783846,DISK], DatanodeInfoWithStorage[127.0.0.1:37159,DS-8af4446e-c622-4814-89d7-d6ae9d06a108,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-69ec533d-4b5a-4573-8d10-a972315eb04a,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-7a7bda0e-2b24-4dae-a1bf-3ca9cf34674b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1162981505-172.17.0.7-1595912419594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45161,DS-8507c66d-a487-4094-b613-b733487f61a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-a5312bcf-1121-4935-8e2f-6fe0f1a7873f,DISK], DatanodeInfoWithStorage[127.0.0.1:36175,DS-461bc4f4-3132-4a98-a72c-fc8918448f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-d522474e-c409-4c79-83e6-c5a56725a819,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-5d6592f1-6f6b-4b52-8413-60268b783846,DISK], DatanodeInfoWithStorage[127.0.0.1:37159,DS-8af4446e-c622-4814-89d7-d6ae9d06a108,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-69ec533d-4b5a-4573-8d10-a972315eb04a,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-7a7bda0e-2b24-4dae-a1bf-3ca9cf34674b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691825135-172.17.0.7-1595912586347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34934,DS-1db89941-35c2-412d-b59e-2fc92a4b2618,DISK], DatanodeInfoWithStorage[127.0.0.1:46099,DS-72c04ba4-2ba0-4b7a-b663-c072723a2654,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-d8aed130-3af7-4cbf-a987-9803f5a3addd,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-bfa83947-0e2d-4715-a0f9-35a7cb7d11c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-455d9882-ba3b-468b-be6e-6bcfa864f2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-cd2bc6d0-c649-47b4-beb3-6378aa557a40,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-a4977775-588f-4327-aadb-3bb08d1b9383,DISK], DatanodeInfoWithStorage[127.0.0.1:36477,DS-ac283754-c1ba-4102-b275-3d8e67532d5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691825135-172.17.0.7-1595912586347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34934,DS-1db89941-35c2-412d-b59e-2fc92a4b2618,DISK], DatanodeInfoWithStorage[127.0.0.1:46099,DS-72c04ba4-2ba0-4b7a-b663-c072723a2654,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-d8aed130-3af7-4cbf-a987-9803f5a3addd,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-bfa83947-0e2d-4715-a0f9-35a7cb7d11c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-455d9882-ba3b-468b-be6e-6bcfa864f2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-cd2bc6d0-c649-47b4-beb3-6378aa557a40,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-a4977775-588f-4327-aadb-3bb08d1b9383,DISK], DatanodeInfoWithStorage[127.0.0.1:36477,DS-ac283754-c1ba-4102-b275-3d8e67532d5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-221538090-172.17.0.7-1595912743487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35935,DS-9eb6ec19-e604-40ba-9c6d-154f7d1b72e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-ad66c2f9-a20f-4bf2-a538-bd57a9be78d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-5c3dbcc1-b0eb-4222-9974-459ee7a36f35,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-b26dc7fc-5ea7-4853-847b-8e43c174c944,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-4d0ea394-89f4-48f4-a2c9-f6bb9a69a87a,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-6887fe95-7b02-42ed-8171-06eba3734b78,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-0a734acf-f926-46a6-994d-5e9410bc23cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-94e840f8-5392-4e78-a045-7cf6f139e193,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-221538090-172.17.0.7-1595912743487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35935,DS-9eb6ec19-e604-40ba-9c6d-154f7d1b72e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-ad66c2f9-a20f-4bf2-a538-bd57a9be78d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-5c3dbcc1-b0eb-4222-9974-459ee7a36f35,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-b26dc7fc-5ea7-4853-847b-8e43c174c944,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-4d0ea394-89f4-48f4-a2c9-f6bb9a69a87a,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-6887fe95-7b02-42ed-8171-06eba3734b78,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-0a734acf-f926-46a6-994d-5e9410bc23cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-94e840f8-5392-4e78-a045-7cf6f139e193,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-399718702-172.17.0.7-1595912780189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42283,DS-c6cf0126-e734-4634-a007-faeb619c7b44,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-75302e9b-c59f-4090-b5c5-8960a2f5587a,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-b2ed72fd-fd11-4d91-b153-b4f3bc810d88,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-db05b7f4-68aa-44ef-ac58-05a90ebb0b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-7a33ea86-f326-4234-9dfb-c55a2671f9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43930,DS-434b0839-c98e-4c7f-935d-0fe29d6c8939,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-1f5102a5-1f23-494d-96af-88b6f07cfc86,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-5f2fcc26-49c2-4289-b938-213425901baf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-399718702-172.17.0.7-1595912780189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42283,DS-c6cf0126-e734-4634-a007-faeb619c7b44,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-75302e9b-c59f-4090-b5c5-8960a2f5587a,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-b2ed72fd-fd11-4d91-b153-b4f3bc810d88,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-db05b7f4-68aa-44ef-ac58-05a90ebb0b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-7a33ea86-f326-4234-9dfb-c55a2671f9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43930,DS-434b0839-c98e-4c7f-935d-0fe29d6c8939,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-1f5102a5-1f23-494d-96af-88b6f07cfc86,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-5f2fcc26-49c2-4289-b938-213425901baf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1614754143-172.17.0.7-1595913225039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42369,DS-4537af44-af73-401b-ae42-f3e746ba42de,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-b0d5f72d-550b-40e3-9c95-a7494ab956ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-03b72cc3-aac4-4d05-8286-230eef7df2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-d2f8fb22-f52b-4649-8a34-9782944daea4,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-42931b07-7d07-41b5-9e8d-d316cd23f0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-7484d49b-b7fe-4814-8442-fafc9296102f,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-bbfa95eb-71ed-4704-b176-2db1cf31502c,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-74a13e13-7f70-4936-a6eb-b96a2838437c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1614754143-172.17.0.7-1595913225039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42369,DS-4537af44-af73-401b-ae42-f3e746ba42de,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-b0d5f72d-550b-40e3-9c95-a7494ab956ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-03b72cc3-aac4-4d05-8286-230eef7df2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-d2f8fb22-f52b-4649-8a34-9782944daea4,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-42931b07-7d07-41b5-9e8d-d316cd23f0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-7484d49b-b7fe-4814-8442-fafc9296102f,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-bbfa95eb-71ed-4704-b176-2db1cf31502c,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-74a13e13-7f70-4936-a6eb-b96a2838437c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1410203745-172.17.0.7-1595913496440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44796,DS-c096cc00-42f9-4027-93a0-c5ea5b1f1d44,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-e376e8ff-f0a6-4d68-a804-b12108665f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-a83332ce-b9b5-48e4-b352-f013777becc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-64d02509-dd92-4069-90c5-560c7b565517,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-fbf914b9-b3ca-4e6e-b057-62ccb5c041bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-ae75d594-b074-4e49-8ca9-11f12a3f0edb,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-9fdd838c-1c68-4985-878c-61e7e3cdd09e,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-167c86ba-3bcd-4900-be13-9b7e434e2f9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1410203745-172.17.0.7-1595913496440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44796,DS-c096cc00-42f9-4027-93a0-c5ea5b1f1d44,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-e376e8ff-f0a6-4d68-a804-b12108665f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-a83332ce-b9b5-48e4-b352-f013777becc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-64d02509-dd92-4069-90c5-560c7b565517,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-fbf914b9-b3ca-4e6e-b057-62ccb5c041bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-ae75d594-b074-4e49-8ca9-11f12a3f0edb,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-9fdd838c-1c68-4985-878c-61e7e3cdd09e,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-167c86ba-3bcd-4900-be13-9b7e434e2f9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-206653750-172.17.0.7-1595913573182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36838,DS-cebee7e8-74cb-4508-a1b5-8335c582b874,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-38d7e3fc-e8ab-4c08-8f38-5331669168ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-f00a4047-855e-4f2a-a240-af226ee812fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-d960de11-7e72-4d06-8993-47e8e0c33ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-8f95716b-bd54-4870-af82-7d38070067a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-398a9e46-c478-4bdf-b088-1b159e8c6223,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-914817a5-9d66-4108-9a2c-179d8c4f650f,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-4b31a978-dc70-440b-855a-d0f52391d972,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-206653750-172.17.0.7-1595913573182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36838,DS-cebee7e8-74cb-4508-a1b5-8335c582b874,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-38d7e3fc-e8ab-4c08-8f38-5331669168ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-f00a4047-855e-4f2a-a240-af226ee812fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-d960de11-7e72-4d06-8993-47e8e0c33ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-8f95716b-bd54-4870-af82-7d38070067a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-398a9e46-c478-4bdf-b088-1b159e8c6223,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-914817a5-9d66-4108-9a2c-179d8c4f650f,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-4b31a978-dc70-440b-855a-d0f52391d972,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-90032271-172.17.0.7-1595913606802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45775,DS-bfde4813-92b8-4006-ae98-52d48465a6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-3e4353b3-934f-4a0a-8b08-c354c5b4e608,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-7dff1f73-e8db-438a-9af5-e10e964eb895,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-1bf3503c-906f-49af-98b3-e938c745f93e,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-b046d925-6a6f-4b2e-84e3-2cf3bef80b16,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-6f23ec27-d280-4d82-b852-b75f3e840ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-d14c635c-ca96-42fb-8151-4fefdaa8f8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-967bc3cf-2728-4974-a28a-41c8917e50ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-90032271-172.17.0.7-1595913606802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45775,DS-bfde4813-92b8-4006-ae98-52d48465a6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-3e4353b3-934f-4a0a-8b08-c354c5b4e608,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-7dff1f73-e8db-438a-9af5-e10e964eb895,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-1bf3503c-906f-49af-98b3-e938c745f93e,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-b046d925-6a6f-4b2e-84e3-2cf3bef80b16,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-6f23ec27-d280-4d82-b852-b75f3e840ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-d14c635c-ca96-42fb-8151-4fefdaa8f8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-967bc3cf-2728-4974-a28a-41c8917e50ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-222686802-172.17.0.7-1595914332139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46831,DS-8542a08a-da8e-4c52-92b7-3c8c9334cde2,DISK], DatanodeInfoWithStorage[127.0.0.1:46010,DS-764c960e-587b-466e-85ec-93bfb58a2f95,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-5ddd64ea-6527-4cb0-a5c6-c3a92fa4c2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-1fce9c69-5be9-41ac-a7d2-234d4d714367,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-288ffb9b-5113-4555-9482-996486bc84f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-f50c3326-a43e-4368-a5a9-ca660bbe2fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-3f46b2c3-e4ac-4f03-9e08-a12c276bc3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-58489095-cda5-4f08-af3a-89a1b3b0b8b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-222686802-172.17.0.7-1595914332139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46831,DS-8542a08a-da8e-4c52-92b7-3c8c9334cde2,DISK], DatanodeInfoWithStorage[127.0.0.1:46010,DS-764c960e-587b-466e-85ec-93bfb58a2f95,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-5ddd64ea-6527-4cb0-a5c6-c3a92fa4c2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-1fce9c69-5be9-41ac-a7d2-234d4d714367,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-288ffb9b-5113-4555-9482-996486bc84f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-f50c3326-a43e-4368-a5a9-ca660bbe2fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-3f46b2c3-e4ac-4f03-9e08-a12c276bc3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-58489095-cda5-4f08-af3a-89a1b3b0b8b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-412806789-172.17.0.7-1595914463213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38815,DS-ba0ed492-2788-458d-bec1-cbc3b5b6cc02,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-faf7c9c2-80df-45bc-a813-781d75be6f76,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-16ef8517-b226-4ce8-b2bf-24e6a37b6d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-21c4d831-5b7f-4e11-be0f-d468ce632b39,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-4a63ae29-a026-4eed-b0ee-0f47985e0862,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-4c01e984-b43d-4f1a-ae29-beb423d0137d,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-bdb3ba1d-c937-471b-a61c-3184db3cfb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-a8409d0c-6d59-4b2f-aee9-8d1038500ef4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-412806789-172.17.0.7-1595914463213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38815,DS-ba0ed492-2788-458d-bec1-cbc3b5b6cc02,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-faf7c9c2-80df-45bc-a813-781d75be6f76,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-16ef8517-b226-4ce8-b2bf-24e6a37b6d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-21c4d831-5b7f-4e11-be0f-d468ce632b39,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-4a63ae29-a026-4eed-b0ee-0f47985e0862,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-4c01e984-b43d-4f1a-ae29-beb423d0137d,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-bdb3ba1d-c937-471b-a61c-3184db3cfb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-a8409d0c-6d59-4b2f-aee9-8d1038500ef4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1669583866-172.17.0.7-1595914609481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45478,DS-d182ffb5-06be-43d7-a60b-95a6b85330be,DISK], DatanodeInfoWithStorage[127.0.0.1:46241,DS-6a2ab36a-9279-452b-b393-4c1df72f4d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-412528ec-371a-4d5b-a728-7d6bd251a56d,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-b0e8aaab-709a-4498-b127-30707d21c290,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-2760fbd4-14a3-40f5-980a-88f1373d6b31,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-58553395-3a00-4740-bdbf-360f34bb7979,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-8fdb0566-154e-422b-850f-ff859a2f433c,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-97dae29a-1f23-46e2-83c8-451374cd2765,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1669583866-172.17.0.7-1595914609481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45478,DS-d182ffb5-06be-43d7-a60b-95a6b85330be,DISK], DatanodeInfoWithStorage[127.0.0.1:46241,DS-6a2ab36a-9279-452b-b393-4c1df72f4d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-412528ec-371a-4d5b-a728-7d6bd251a56d,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-b0e8aaab-709a-4498-b127-30707d21c290,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-2760fbd4-14a3-40f5-980a-88f1373d6b31,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-58553395-3a00-4740-bdbf-360f34bb7979,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-8fdb0566-154e-422b-850f-ff859a2f433c,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-97dae29a-1f23-46e2-83c8-451374cd2765,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1880452354-172.17.0.7-1595915189053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34751,DS-aeec60ec-2ab9-40b2-8299-9e4ce9b05f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-15b7a753-fc9d-4095-8a54-cbfc52f3ff14,DISK], DatanodeInfoWithStorage[127.0.0.1:40314,DS-a62d9f06-ff36-4623-90d5-f651104877f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-a80f7c61-5b0c-4490-9b58-b07a1ede6941,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-4e8ba9da-5bda-446f-871e-97eb7c8a50a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-0ef84562-d974-4973-ac09-6a14ef76c4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-4ec85d80-f6d9-4088-8ebe-ed88e1f3a246,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-f693dc1e-265f-4f3a-aecf-e02bb6d32e90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1880452354-172.17.0.7-1595915189053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34751,DS-aeec60ec-2ab9-40b2-8299-9e4ce9b05f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-15b7a753-fc9d-4095-8a54-cbfc52f3ff14,DISK], DatanodeInfoWithStorage[127.0.0.1:40314,DS-a62d9f06-ff36-4623-90d5-f651104877f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-a80f7c61-5b0c-4490-9b58-b07a1ede6941,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-4e8ba9da-5bda-446f-871e-97eb7c8a50a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-0ef84562-d974-4973-ac09-6a14ef76c4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-4ec85d80-f6d9-4088-8ebe-ed88e1f3a246,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-f693dc1e-265f-4f3a-aecf-e02bb6d32e90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-204609208-172.17.0.7-1595915396652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40292,DS-c11b7802-a3f2-43a6-a2a5-010d75ee034d,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-4ea7a1e0-0555-498a-8fcc-84210af56e38,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-6d1976b6-9502-4c4e-97b2-3600757426d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-6a906d4d-2310-45c0-a6c6-3bd1b1cc8c23,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-67e495f6-e82e-4a7e-b844-86ee59486718,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-5e1240ad-42ec-4884-829e-19a5190249d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-6406bde6-fd7e-4a89-942f-24cd91258725,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-80ae0abf-876a-4294-9908-a3750a73c930,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-204609208-172.17.0.7-1595915396652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40292,DS-c11b7802-a3f2-43a6-a2a5-010d75ee034d,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-4ea7a1e0-0555-498a-8fcc-84210af56e38,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-6d1976b6-9502-4c4e-97b2-3600757426d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-6a906d4d-2310-45c0-a6c6-3bd1b1cc8c23,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-67e495f6-e82e-4a7e-b844-86ee59486718,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-5e1240ad-42ec-4884-829e-19a5190249d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-6406bde6-fd7e-4a89-942f-24cd91258725,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-80ae0abf-876a-4294-9908-a3750a73c930,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1767916389-172.17.0.7-1595915439068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43293,DS-f593a437-af34-4dcb-8839-da9b53f123a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-c8b67290-6b8b-4c9e-a466-4b905606c8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-f366f6d8-63d1-4ba5-883e-df3646798702,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-0a058049-85bf-4feb-b480-54edd9dd40b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-278d0faa-9f88-4b28-a462-1feb625c6840,DISK], DatanodeInfoWithStorage[127.0.0.1:34385,DS-fdf21684-4669-4d68-b867-15c1eb904121,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-8e6be5e1-0998-4ca0-b2fd-d11812ad0f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-183796d7-2127-48e2-b472-948bf18a8f7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1767916389-172.17.0.7-1595915439068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43293,DS-f593a437-af34-4dcb-8839-da9b53f123a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-c8b67290-6b8b-4c9e-a466-4b905606c8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-f366f6d8-63d1-4ba5-883e-df3646798702,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-0a058049-85bf-4feb-b480-54edd9dd40b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-278d0faa-9f88-4b28-a462-1feb625c6840,DISK], DatanodeInfoWithStorage[127.0.0.1:34385,DS-fdf21684-4669-4d68-b867-15c1eb904121,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-8e6be5e1-0998-4ca0-b2fd-d11812ad0f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-183796d7-2127-48e2-b472-948bf18a8f7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-240920111-172.17.0.7-1595915514792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39978,DS-e093c043-069d-4676-a119-7320aad132d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-1e7df42c-9842-4cb9-ac67-89d99be1693f,DISK], DatanodeInfoWithStorage[127.0.0.1:37173,DS-a59f1fca-f213-4869-b1a0-216a28dd4b73,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-c292cddd-2cf0-4d70-b021-99f21ece8196,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-140a6b14-6430-4f0a-8fc7-b5b6b062fb03,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-d4266195-765d-435f-abb8-68d8757400cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-6001caa6-b57f-4cae-94b4-7ddd0eb3a3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-c6e4b839-13b9-4e47-950a-653d01c3f26f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-240920111-172.17.0.7-1595915514792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39978,DS-e093c043-069d-4676-a119-7320aad132d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-1e7df42c-9842-4cb9-ac67-89d99be1693f,DISK], DatanodeInfoWithStorage[127.0.0.1:37173,DS-a59f1fca-f213-4869-b1a0-216a28dd4b73,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-c292cddd-2cf0-4d70-b021-99f21ece8196,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-140a6b14-6430-4f0a-8fc7-b5b6b062fb03,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-d4266195-765d-435f-abb8-68d8757400cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-6001caa6-b57f-4cae-94b4-7ddd0eb3a3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-c6e4b839-13b9-4e47-950a-653d01c3f26f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1071660503-172.17.0.7-1595915701105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40452,DS-54c81cf3-c058-4209-8e2c-a41101fc8db7,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-0a9d0cee-9af1-403a-a249-7405e2f1243a,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-bf07a4fc-1b7a-4270-a1d9-a3718f9b9a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-8c8a0119-ca75-44a0-9c8c-68f728f44521,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-aa64e8b6-4111-4a1e-9704-d42efcc8eb67,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-b4e3d58e-2f65-4eb2-b2ab-c0c61a2bc9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-e84c093c-a50c-4426-96d5-e588a802181d,DISK], DatanodeInfoWithStorage[127.0.0.1:41374,DS-40c80117-0b3a-4d8a-b179-afc8a88e1a11,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1071660503-172.17.0.7-1595915701105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40452,DS-54c81cf3-c058-4209-8e2c-a41101fc8db7,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-0a9d0cee-9af1-403a-a249-7405e2f1243a,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-bf07a4fc-1b7a-4270-a1d9-a3718f9b9a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-8c8a0119-ca75-44a0-9c8c-68f728f44521,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-aa64e8b6-4111-4a1e-9704-d42efcc8eb67,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-b4e3d58e-2f65-4eb2-b2ab-c0c61a2bc9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-e84c093c-a50c-4426-96d5-e588a802181d,DISK], DatanodeInfoWithStorage[127.0.0.1:41374,DS-40c80117-0b3a-4d8a-b179-afc8a88e1a11,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1173826417-172.17.0.7-1595915739473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35256,DS-d00f30cb-b985-46a2-897b-885a063c4822,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-8343455e-2b8e-40f1-88e0-2dc355253847,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-6d698690-70cd-4f85-90dd-6e5fd0e581be,DISK], DatanodeInfoWithStorage[127.0.0.1:35857,DS-f7db01fa-cbb7-4d80-8d85-3ef2bcbf1a74,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-49a69edb-385e-410c-8bed-8b84185c05ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-fe9e0534-533f-4c71-a456-de41edfa5ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-b7cbc84b-05f0-4663-997d-8686e5db5883,DISK], DatanodeInfoWithStorage[127.0.0.1:43686,DS-9d23577b-5f67-4670-a7a6-69026d3351a2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1173826417-172.17.0.7-1595915739473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35256,DS-d00f30cb-b985-46a2-897b-885a063c4822,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-8343455e-2b8e-40f1-88e0-2dc355253847,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-6d698690-70cd-4f85-90dd-6e5fd0e581be,DISK], DatanodeInfoWithStorage[127.0.0.1:35857,DS-f7db01fa-cbb7-4d80-8d85-3ef2bcbf1a74,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-49a69edb-385e-410c-8bed-8b84185c05ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-fe9e0534-533f-4c71-a456-de41edfa5ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-b7cbc84b-05f0-4663-997d-8686e5db5883,DISK], DatanodeInfoWithStorage[127.0.0.1:43686,DS-9d23577b-5f67-4670-a7a6-69026d3351a2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2116086624-172.17.0.7-1595915954643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35846,DS-7eaf6ca0-6002-41c5-92b0-d8fcc6a4580e,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-5aa30aa9-346e-447a-944e-e43a06d0ede8,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-8d9a05e9-ca7b-4f5c-b2b4-d304a981929d,DISK], DatanodeInfoWithStorage[127.0.0.1:35362,DS-2c1d11f2-ed42-48ee-9d37-0f5b4b2ef18b,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-aa7005fe-e877-47c8-8d43-c76288b109ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-102882eb-55fd-477d-a8c0-ebb50f3735bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-f327d5a5-db6a-4170-b4fa-92256469edbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38646,DS-be734429-e278-4611-9b80-5baec8bb594d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2116086624-172.17.0.7-1595915954643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35846,DS-7eaf6ca0-6002-41c5-92b0-d8fcc6a4580e,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-5aa30aa9-346e-447a-944e-e43a06d0ede8,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-8d9a05e9-ca7b-4f5c-b2b4-d304a981929d,DISK], DatanodeInfoWithStorage[127.0.0.1:35362,DS-2c1d11f2-ed42-48ee-9d37-0f5b4b2ef18b,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-aa7005fe-e877-47c8-8d43-c76288b109ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-102882eb-55fd-477d-a8c0-ebb50f3735bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-f327d5a5-db6a-4170-b4fa-92256469edbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38646,DS-be734429-e278-4611-9b80-5baec8bb594d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-593948474-172.17.0.7-1595916355649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46229,DS-12544eb2-d3cf-49cf-b710-482cfd3529d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-348b4a3c-5ca1-4ad3-a2ab-b96f724e913f,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-83d4f5fa-e3e9-4b3c-88b5-c2ce0559a10c,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-a071f97c-6b65-4c31-b988-44374fcbfc83,DISK], DatanodeInfoWithStorage[127.0.0.1:44525,DS-a697354b-0aaf-48e6-9321-dc6ab7052e20,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-56b379ee-6b8c-4eed-b11d-cb057c8e515c,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-437a85a5-173c-403e-b56f-d0342f05500f,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-604ac052-70de-426c-aac9-7237f1b68574,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-593948474-172.17.0.7-1595916355649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46229,DS-12544eb2-d3cf-49cf-b710-482cfd3529d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-348b4a3c-5ca1-4ad3-a2ab-b96f724e913f,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-83d4f5fa-e3e9-4b3c-88b5-c2ce0559a10c,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-a071f97c-6b65-4c31-b988-44374fcbfc83,DISK], DatanodeInfoWithStorage[127.0.0.1:44525,DS-a697354b-0aaf-48e6-9321-dc6ab7052e20,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-56b379ee-6b8c-4eed-b11d-cb057c8e515c,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-437a85a5-173c-403e-b56f-d0342f05500f,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-604ac052-70de-426c-aac9-7237f1b68574,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-21980427-172.17.0.7-1595916425826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41408,DS-c5c14d5b-1aae-40eb-82d3-6c77dbba6d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-5f102a07-f2a6-4df1-ac07-08d90b5e3de6,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-d6d96a99-ce1c-419a-bba9-6cfbe3b256d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35035,DS-3972483a-6868-482b-87bb-c8e76905dbcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43613,DS-29627fb7-a680-42ad-acb3-93107884fcdb,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-a363bb87-7e23-42fb-ab29-1ea880ed5170,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-4d95e983-0867-45ec-973d-881fa76f62ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-a0ccb43a-2782-4369-b986-96a0c31b7f44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-21980427-172.17.0.7-1595916425826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41408,DS-c5c14d5b-1aae-40eb-82d3-6c77dbba6d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-5f102a07-f2a6-4df1-ac07-08d90b5e3de6,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-d6d96a99-ce1c-419a-bba9-6cfbe3b256d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35035,DS-3972483a-6868-482b-87bb-c8e76905dbcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43613,DS-29627fb7-a680-42ad-acb3-93107884fcdb,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-a363bb87-7e23-42fb-ab29-1ea880ed5170,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-4d95e983-0867-45ec-973d-881fa76f62ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-a0ccb43a-2782-4369-b986-96a0c31b7f44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-352520814-172.17.0.7-1595916528794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39095,DS-d66f2960-26d7-4a41-86f5-69d00d8f1a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-93415f10-c6b8-479f-a290-30e7c99c3058,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-9920675d-b72e-43dd-a983-3b184a0862a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-20787b72-9057-4c79-9db7-1a7fd95568b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-c8a5017a-fcdd-400b-b632-c2622535e0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-bba25fa0-57cd-43d8-942e-80ed5663fef4,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-0c0d42c5-cc1d-45a8-af17-bbfa8dcd7f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-531a59f7-9b68-46bc-a745-1a83ec075391,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-352520814-172.17.0.7-1595916528794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39095,DS-d66f2960-26d7-4a41-86f5-69d00d8f1a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-93415f10-c6b8-479f-a290-30e7c99c3058,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-9920675d-b72e-43dd-a983-3b184a0862a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-20787b72-9057-4c79-9db7-1a7fd95568b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-c8a5017a-fcdd-400b-b632-c2622535e0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-bba25fa0-57cd-43d8-942e-80ed5663fef4,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-0c0d42c5-cc1d-45a8-af17-bbfa8dcd7f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-531a59f7-9b68-46bc-a745-1a83ec075391,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1573613352-172.17.0.7-1595917005781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33221,DS-28c675e8-336b-402b-8dfe-0aef2c444afb,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-a5c0da3c-73b1-4832-86f0-762f079c5bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36881,DS-6e1b5378-7a9d-4925-bdc5-c77403eb1e35,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-afc8525a-b6d5-4c19-bf7c-330e8cde7817,DISK], DatanodeInfoWithStorage[127.0.0.1:37759,DS-9ed5b88c-db33-4130-987d-c87327646bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-247de575-04de-4ccd-95ad-11aac63588e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-202f173d-4b6e-449b-be64-fa322d50baf5,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-96785281-0cc3-4118-bdad-6f1c013c041c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1573613352-172.17.0.7-1595917005781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33221,DS-28c675e8-336b-402b-8dfe-0aef2c444afb,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-a5c0da3c-73b1-4832-86f0-762f079c5bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36881,DS-6e1b5378-7a9d-4925-bdc5-c77403eb1e35,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-afc8525a-b6d5-4c19-bf7c-330e8cde7817,DISK], DatanodeInfoWithStorage[127.0.0.1:37759,DS-9ed5b88c-db33-4130-987d-c87327646bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-247de575-04de-4ccd-95ad-11aac63588e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-202f173d-4b6e-449b-be64-fa322d50baf5,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-96785281-0cc3-4118-bdad-6f1c013c041c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-999115147-172.17.0.7-1595917112610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44824,DS-cf61e292-d553-4284-96dd-3342af139f17,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-54bb20bb-6ccb-413d-9ecd-fea6a51413e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38974,DS-d48f9ace-d4ed-4edb-99d5-13f8f8ad3b48,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-6f5228df-cab5-49a5-8a3a-a71720b96857,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-504497b7-30fd-4e5b-be0c-65bb705afdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-fb15e9d3-c7ed-49b9-abed-0b1459fef24e,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-a872f105-5409-45a7-829d-9846c50f4da3,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-266bf098-3b77-4cba-9aaa-8d2a0dc358f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-999115147-172.17.0.7-1595917112610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44824,DS-cf61e292-d553-4284-96dd-3342af139f17,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-54bb20bb-6ccb-413d-9ecd-fea6a51413e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38974,DS-d48f9ace-d4ed-4edb-99d5-13f8f8ad3b48,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-6f5228df-cab5-49a5-8a3a-a71720b96857,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-504497b7-30fd-4e5b-be0c-65bb705afdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-fb15e9d3-c7ed-49b9-abed-0b1459fef24e,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-a872f105-5409-45a7-829d-9846c50f4da3,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-266bf098-3b77-4cba-9aaa-8d2a0dc358f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-474101334-172.17.0.7-1595917193371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42006,DS-93f9cae8-c158-4055-8351-b8ce6c41c2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-704c733d-3d0a-429c-a9c0-1f6b27a717b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-2512b794-3c1b-4a26-af98-1ff741c70834,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-cc867225-58d6-4f00-b15d-81ec51b6de2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-0ba919f0-df64-46d4-a38c-bf06a13ee22c,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-6a226490-e718-4554-94ec-5e85184bee47,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-b08f5ce1-61d8-4daa-9520-e9f0227de833,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-c20e0c2c-1d9d-4e1f-ba40-6df5d3b262d5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-474101334-172.17.0.7-1595917193371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42006,DS-93f9cae8-c158-4055-8351-b8ce6c41c2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-704c733d-3d0a-429c-a9c0-1f6b27a717b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-2512b794-3c1b-4a26-af98-1ff741c70834,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-cc867225-58d6-4f00-b15d-81ec51b6de2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-0ba919f0-df64-46d4-a38c-bf06a13ee22c,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-6a226490-e718-4554-94ec-5e85184bee47,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-b08f5ce1-61d8-4daa-9520-e9f0227de833,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-c20e0c2c-1d9d-4e1f-ba40-6df5d3b262d5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1303900596-172.17.0.7-1595917265817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37919,DS-80dc6a3a-990d-41ad-8442-4d05169068c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-b658b61f-972b-4775-83f7-b31a38d9ed42,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-3494a4a6-41b0-4534-b971-b1dd71a5b800,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-433772e6-167c-42f8-9565-e10c27897bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-0c069f8f-e58a-484b-942c-6823b2cab99d,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-5d624254-48a7-421a-acd9-cc6a1a76de5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40318,DS-839a6094-4a74-4638-b2ef-8e139c84dab7,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-c10e7a0c-d190-4a8a-82e3-f703a95c9237,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1303900596-172.17.0.7-1595917265817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37919,DS-80dc6a3a-990d-41ad-8442-4d05169068c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-b658b61f-972b-4775-83f7-b31a38d9ed42,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-3494a4a6-41b0-4534-b971-b1dd71a5b800,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-433772e6-167c-42f8-9565-e10c27897bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-0c069f8f-e58a-484b-942c-6823b2cab99d,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-5d624254-48a7-421a-acd9-cc6a1a76de5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40318,DS-839a6094-4a74-4638-b2ef-8e139c84dab7,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-c10e7a0c-d190-4a8a-82e3-f703a95c9237,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5301
