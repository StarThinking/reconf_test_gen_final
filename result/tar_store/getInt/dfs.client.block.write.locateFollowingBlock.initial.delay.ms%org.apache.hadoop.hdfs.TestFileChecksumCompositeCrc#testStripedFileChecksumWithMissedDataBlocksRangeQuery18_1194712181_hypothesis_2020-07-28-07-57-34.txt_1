reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-307695870-172.17.0.3-1595923318647:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39123,DS-7ac30762-d353-4996-b9bc-c8aa40584f44,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-59c44975-7b78-48b9-8764-ed279ea89675,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-e78831ae-2b9a-4843-a93a-6098cd320600,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-3fb6c6ff-6dc5-49fd-ac88-84b4214f5d05,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-af2efbd7-6131-42ef-b470-817e2c701b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-582e6e27-6aca-456d-8827-e714d48c3d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-810dc7cf-bbec-4b68-aad6-853848184251,DISK], DatanodeInfoWithStorage[127.0.0.1:44131,DS-c9b4edf0-1027-47ec-901e-b61fd71e053f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-307695870-172.17.0.3-1595923318647:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39123,DS-7ac30762-d353-4996-b9bc-c8aa40584f44,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-59c44975-7b78-48b9-8764-ed279ea89675,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-e78831ae-2b9a-4843-a93a-6098cd320600,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-3fb6c6ff-6dc5-49fd-ac88-84b4214f5d05,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-af2efbd7-6131-42ef-b470-817e2c701b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-582e6e27-6aca-456d-8827-e714d48c3d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-810dc7cf-bbec-4b68-aad6-853848184251,DISK], DatanodeInfoWithStorage[127.0.0.1:44131,DS-c9b4edf0-1027-47ec-901e-b61fd71e053f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: test timed out after 90000 milliseconds
stackTrace: java.lang.Exception: test timed out after 90000 milliseconds
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:967)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl(DFSStripedOutputStream.java:1218)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:866)
	at org.apache.hadoop.hdfs.TestFileChecksum.prepareTestFiles(TestFileChecksum.java:602)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:505)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-370823977-172.17.0.3-1595924631694:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34434,DS-a11b8571-7381-4008-8362-db3c82707ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-e5136c24-9477-4cbd-a6fd-73621bfebaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-73b312ae-6f27-4432-a212-20e67127ff26,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-4a95ba1a-beba-4bc4-832a-7f7f8525e3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-2f379b99-0674-40f1-8b16-6356c73b507d,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-10587941-9849-476a-91a7-fe55a1db23ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-1b611d5e-8bd5-49fc-b6f3-b8da08488be3,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-16ba166c-7da4-4a1a-b7a6-1fe6aeef0aee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-370823977-172.17.0.3-1595924631694:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34434,DS-a11b8571-7381-4008-8362-db3c82707ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-e5136c24-9477-4cbd-a6fd-73621bfebaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-73b312ae-6f27-4432-a212-20e67127ff26,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-4a95ba1a-beba-4bc4-832a-7f7f8525e3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-2f379b99-0674-40f1-8b16-6356c73b507d,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-10587941-9849-476a-91a7-fe55a1db23ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-1b611d5e-8bd5-49fc-b6f3-b8da08488be3,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-16ba166c-7da4-4a1a-b7a6-1fe6aeef0aee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: test timed out after 90000 milliseconds
stackTrace: java.lang.Exception: test timed out after 90000 milliseconds
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:967)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl(DFSStripedOutputStream.java:1218)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:866)
	at org.apache.hadoop.hdfs.TestFileChecksum.prepareTestFiles(TestFileChecksum.java:602)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:292)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-198788165-172.17.0.3-1595924959169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33066,DS-274bdd64-80cd-4a5f-bfa8-918c0f0f6edc,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-0df5f46f-02ac-4d6e-8939-850fb23c3145,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-50c505de-0351-4adc-8066-6cd3de9f5d61,DISK], DatanodeInfoWithStorage[127.0.0.1:46093,DS-934ccf50-5a7d-4655-a831-0a8a1725bbde,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-ccbe063e-33b3-403a-af17-e80434589897,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-01c1f933-ee28-475c-9bde-6289d208b5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-0bff7c53-149e-4264-ba07-3115260dbc5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-20d7b3c3-b208-4e86-beae-0a7f85a697ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-198788165-172.17.0.3-1595924959169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33066,DS-274bdd64-80cd-4a5f-bfa8-918c0f0f6edc,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-0df5f46f-02ac-4d6e-8939-850fb23c3145,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-50c505de-0351-4adc-8066-6cd3de9f5d61,DISK], DatanodeInfoWithStorage[127.0.0.1:46093,DS-934ccf50-5a7d-4655-a831-0a8a1725bbde,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-ccbe063e-33b3-403a-af17-e80434589897,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-01c1f933-ee28-475c-9bde-6289d208b5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-0bff7c53-149e-4264-ba07-3115260dbc5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-20d7b3c3-b208-4e86-beae-0a7f85a697ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: test timed out after 90000 milliseconds
stackTrace: java.lang.Exception: test timed out after 90000 milliseconds
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:967)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl(DFSStripedOutputStream.java:1218)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:866)
	at org.apache.hadoop.hdfs.TestFileChecksum.prepareTestFiles(TestFileChecksum.java:602)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:505)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-176208777-172.17.0.3-1595925501856:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40675,DS-e1060aa4-d13e-4307-8905-c168c35b7efe,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-bc6d2d7a-9f09-4325-ad10-c78ac627c5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-47bf1b56-3550-4dce-869c-7338ae749bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45602,DS-8fbd84ef-889b-4036-80f7-7e67359a6453,DISK], DatanodeInfoWithStorage[127.0.0.1:44194,DS-ecf00825-4bce-4ed8-bc07-99829f025c23,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-b7593810-1d98-4823-a5d1-ebb16e0678ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-31e8d8ce-e668-4a8a-aca9-d79cf0b56cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-85009b36-34eb-4932-8ade-75c852fa14bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-176208777-172.17.0.3-1595925501856:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40675,DS-e1060aa4-d13e-4307-8905-c168c35b7efe,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-bc6d2d7a-9f09-4325-ad10-c78ac627c5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-47bf1b56-3550-4dce-869c-7338ae749bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45602,DS-8fbd84ef-889b-4036-80f7-7e67359a6453,DISK], DatanodeInfoWithStorage[127.0.0.1:44194,DS-ecf00825-4bce-4ed8-bc07-99829f025c23,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-b7593810-1d98-4823-a5d1-ebb16e0678ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-31e8d8ce-e668-4a8a-aca9-d79cf0b56cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-85009b36-34eb-4932-8ade-75c852fa14bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1444133575-172.17.0.3-1595925541361:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39808,DS-0fc3b8c9-75a1-43fc-bb12-d4a83370c9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-26ce9e33-ec13-4365-a1e3-faa6d85a4bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-8ffb9856-0290-41b5-8f7b-2e0b62158853,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-b0c0ab61-2e18-4ea4-b74a-7ae2bc92d9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35888,DS-f2f3903f-311c-40a6-aa8d-b922f448e18d,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-42c4b745-5ee7-4eda-a42a-1d31c3fa4e25,DISK], DatanodeInfoWithStorage[127.0.0.1:34160,DS-bf67f6d7-3ceb-4b8c-b661-4ad4e58c3966,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-8f0bf417-295f-4e32-8aa6-10fba95624e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1444133575-172.17.0.3-1595925541361:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39808,DS-0fc3b8c9-75a1-43fc-bb12-d4a83370c9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-26ce9e33-ec13-4365-a1e3-faa6d85a4bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-8ffb9856-0290-41b5-8f7b-2e0b62158853,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-b0c0ab61-2e18-4ea4-b74a-7ae2bc92d9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35888,DS-f2f3903f-311c-40a6-aa8d-b922f448e18d,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-42c4b745-5ee7-4eda-a42a-1d31c3fa4e25,DISK], DatanodeInfoWithStorage[127.0.0.1:34160,DS-bf67f6d7-3ceb-4b8c-b661-4ad4e58c3966,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-8f0bf417-295f-4e32-8aa6-10fba95624e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1322028167-172.17.0.3-1595925819610:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33299,DS-81304ec4-8341-4f5d-ab5f-174e3531bbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-5425fb4e-bd15-4cac-ac80-7898a54f7886,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-7a492a45-9c70-4297-9521-c59ddb62f85e,DISK], DatanodeInfoWithStorage[127.0.0.1:38205,DS-c8f4fcd3-2774-43eb-abe8-37fff9f3e9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-13475265-376a-4c85-9c84-18c3f66930a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-cfa86741-a933-4d98-b3fc-a42592950415,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-e275fca5-d75f-4af5-b1d2-96d390816c74,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-254aa594-14f6-4998-b1c6-488b1414d2d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1322028167-172.17.0.3-1595925819610:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33299,DS-81304ec4-8341-4f5d-ab5f-174e3531bbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-5425fb4e-bd15-4cac-ac80-7898a54f7886,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-7a492a45-9c70-4297-9521-c59ddb62f85e,DISK], DatanodeInfoWithStorage[127.0.0.1:38205,DS-c8f4fcd3-2774-43eb-abe8-37fff9f3e9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-13475265-376a-4c85-9c84-18c3f66930a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-cfa86741-a933-4d98-b3fc-a42592950415,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-e275fca5-d75f-4af5-b1d2-96d390816c74,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-254aa594-14f6-4998-b1c6-488b1414d2d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: test timed out after 90000 milliseconds
stackTrace: java.lang.Exception: test timed out after 90000 milliseconds
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:967)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl(DFSStripedOutputStream.java:1218)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:866)
	at org.apache.hadoop.hdfs.TestFileChecksum.prepareTestFiles(TestFileChecksum.java:602)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:505)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2107439450-172.17.0.3-1595926143663:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41182,DS-e7ecd1f0-4485-4c3e-84df-ee581401f369,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-55496d0e-8be9-4771-838d-c150ff5edd43,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-5551ae7a-d6f1-4246-a971-1556b1b8f8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-27421ced-84bd-4576-b14c-470b54148968,DISK], DatanodeInfoWithStorage[127.0.0.1:40851,DS-c6caefc3-6520-4fda-85f7-f6cfea10f6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-f5498e0f-8302-4a8d-950e-928c3859ee32,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-af8b3254-da6d-4ddc-9bfd-7010b127adfe,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-396df330-142f-4d5f-8a3e-3eccac85f4d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2107439450-172.17.0.3-1595926143663:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41182,DS-e7ecd1f0-4485-4c3e-84df-ee581401f369,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-55496d0e-8be9-4771-838d-c150ff5edd43,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-5551ae7a-d6f1-4246-a971-1556b1b8f8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-27421ced-84bd-4576-b14c-470b54148968,DISK], DatanodeInfoWithStorage[127.0.0.1:40851,DS-c6caefc3-6520-4fda-85f7-f6cfea10f6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-f5498e0f-8302-4a8d-950e-928c3859ee32,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-af8b3254-da6d-4ddc-9bfd-7010b127adfe,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-396df330-142f-4d5f-8a3e-3eccac85f4d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2003143728-172.17.0.3-1595926212094:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32886,DS-b4d108b6-2367-4658-a823-88ce76ad346e,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-373ad603-66fb-4828-9f02-3a83709abcbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-b3d554fe-1f29-451a-913f-5f915e93e39b,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-7a38c354-4003-4dfe-b39e-062706a468a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-308b02ee-8c7b-4d66-8113-e558da949eac,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-8dd3707a-5c53-433a-9865-e54ddda4ba7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-1ad2218c-9cc9-4226-87c4-4d46aa1bf03c,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-775b956f-cdfc-409f-a5fc-5ac4a8abfb85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2003143728-172.17.0.3-1595926212094:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32886,DS-b4d108b6-2367-4658-a823-88ce76ad346e,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-373ad603-66fb-4828-9f02-3a83709abcbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-b3d554fe-1f29-451a-913f-5f915e93e39b,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-7a38c354-4003-4dfe-b39e-062706a468a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-308b02ee-8c7b-4d66-8113-e558da949eac,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-8dd3707a-5c53-433a-9865-e54ddda4ba7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-1ad2218c-9cc9-4226-87c4-4d46aa1bf03c,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-775b956f-cdfc-409f-a5fc-5ac4a8abfb85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-626355640-172.17.0.3-1595926569445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37286,DS-51d45e3e-c6b2-4996-bac4-3d33efbbe627,DISK], DatanodeInfoWithStorage[127.0.0.1:40627,DS-8556a43a-7114-4ffd-a780-d1890a652849,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-85efb0d1-db3e-47b7-b301-bb8305d00734,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-d64bba1c-4aa9-4d71-9cca-c1ce4b4d346d,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-1848978f-0ff3-4042-8a22-b51b73927a06,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-de953562-fbde-4bf5-a6ba-dfc62210fd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-a4d82b24-0a8d-48c2-af50-c2341886d19f,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-ddeec772-389d-48db-b21c-85b258af6478,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-626355640-172.17.0.3-1595926569445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37286,DS-51d45e3e-c6b2-4996-bac4-3d33efbbe627,DISK], DatanodeInfoWithStorage[127.0.0.1:40627,DS-8556a43a-7114-4ffd-a780-d1890a652849,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-85efb0d1-db3e-47b7-b301-bb8305d00734,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-d64bba1c-4aa9-4d71-9cca-c1ce4b4d346d,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-1848978f-0ff3-4042-8a22-b51b73927a06,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-de953562-fbde-4bf5-a6ba-dfc62210fd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-a4d82b24-0a8d-48c2-af50-c2341886d19f,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-ddeec772-389d-48db-b21c-85b258af6478,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1681573406-172.17.0.3-1595926698009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38741,DS-e989b2f5-0e6a-41b8-8d94-4edeb85be6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-3a6e40f3-d126-4295-8cb9-f961f5da24da,DISK], DatanodeInfoWithStorage[127.0.0.1:40270,DS-642f7c9e-5538-4abe-b91d-c89d3a0e27c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44550,DS-c22e2fc5-5fe5-49cb-a3d7-a521cb39b341,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-b9a4f359-a46e-464d-ad49-8c7ac85e435f,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-fe0a2369-dc4a-4896-b671-3c6b32c03e32,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-2fc7b2d8-c976-4b27-ba7a-44a9af47c389,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-c6d6f8b9-abc2-4383-98af-786384b18aed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1681573406-172.17.0.3-1595926698009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38741,DS-e989b2f5-0e6a-41b8-8d94-4edeb85be6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-3a6e40f3-d126-4295-8cb9-f961f5da24da,DISK], DatanodeInfoWithStorage[127.0.0.1:40270,DS-642f7c9e-5538-4abe-b91d-c89d3a0e27c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44550,DS-c22e2fc5-5fe5-49cb-a3d7-a521cb39b341,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-b9a4f359-a46e-464d-ad49-8c7ac85e435f,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-fe0a2369-dc4a-4896-b671-3c6b32c03e32,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-2fc7b2d8-c976-4b27-ba7a-44a9af47c389,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-c6d6f8b9-abc2-4383-98af-786384b18aed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1251645902-172.17.0.3-1595927088081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38639,DS-31a68e07-d1d7-432c-94be-74dbf56dadb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-79f4f8df-05d9-48b0-9829-b07fd908293c,DISK], DatanodeInfoWithStorage[127.0.0.1:42724,DS-d4a52470-156d-4387-a0f2-fd3ef88baba5,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-0c3289a5-c8bf-4d9f-a989-0d13852ae858,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-e3a2f4a8-bc1c-4c42-b896-90f4f43760f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-41690a04-06c8-4514-9d32-484fa4aca1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37775,DS-5b8f56b2-e5f1-4414-ba5d-e59f9a6e3f89,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-50aa1049-9b3b-4c54-ae0d-42e44aba7072,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1251645902-172.17.0.3-1595927088081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38639,DS-31a68e07-d1d7-432c-94be-74dbf56dadb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-79f4f8df-05d9-48b0-9829-b07fd908293c,DISK], DatanodeInfoWithStorage[127.0.0.1:42724,DS-d4a52470-156d-4387-a0f2-fd3ef88baba5,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-0c3289a5-c8bf-4d9f-a989-0d13852ae858,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-e3a2f4a8-bc1c-4c42-b896-90f4f43760f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-41690a04-06c8-4514-9d32-484fa4aca1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37775,DS-5b8f56b2-e5f1-4414-ba5d-e59f9a6e3f89,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-50aa1049-9b3b-4c54-ae0d-42e44aba7072,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-400574267-172.17.0.3-1595927162080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40307,DS-719ac9e7-4401-4f95-884f-272094b8e148,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-8e532c15-21fd-4b0a-ae6c-873014ef805c,DISK], DatanodeInfoWithStorage[127.0.0.1:41952,DS-3a62ca00-8fef-419d-aaf4-97b0e725177e,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-b5601371-726f-4ec9-bb62-5a5f2ac41215,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-f32c6439-140c-49fb-959c-d39331153404,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-52fb8d19-192b-418c-81f8-bd652dd7b2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-7d8e6d84-e854-42f3-8079-75aa44146995,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-551349be-0734-4cd8-a98f-a7f971bd8753,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-400574267-172.17.0.3-1595927162080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40307,DS-719ac9e7-4401-4f95-884f-272094b8e148,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-8e532c15-21fd-4b0a-ae6c-873014ef805c,DISK], DatanodeInfoWithStorage[127.0.0.1:41952,DS-3a62ca00-8fef-419d-aaf4-97b0e725177e,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-b5601371-726f-4ec9-bb62-5a5f2ac41215,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-f32c6439-140c-49fb-959c-d39331153404,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-52fb8d19-192b-418c-81f8-bd652dd7b2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-7d8e6d84-e854-42f3-8079-75aa44146995,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-551349be-0734-4cd8-a98f-a7f971bd8753,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-364882935-172.17.0.3-1595927652926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38698,DS-c6d05af9-d051-402f-a3af-e104c47c414f,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-4ddaa02a-8c3c-41c7-9251-267b4424a69b,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-238c3b74-5c4f-43a2-a7e7-92605fb49842,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-89d08978-5893-4d8d-b554-c59eb0f670f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-f0819054-8b68-4e92-885a-ffcd295cab3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-722cf9ba-af4d-4c33-bef1-776db8be2112,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-c0707069-65e6-472d-9d1a-b1a795531161,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-fe69e966-5933-4b7d-b31f-b538a36f5ad4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-364882935-172.17.0.3-1595927652926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38698,DS-c6d05af9-d051-402f-a3af-e104c47c414f,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-4ddaa02a-8c3c-41c7-9251-267b4424a69b,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-238c3b74-5c4f-43a2-a7e7-92605fb49842,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-89d08978-5893-4d8d-b554-c59eb0f670f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-f0819054-8b68-4e92-885a-ffcd295cab3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-722cf9ba-af4d-4c33-bef1-776db8be2112,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-c0707069-65e6-472d-9d1a-b1a795531161,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-fe69e966-5933-4b7d-b31f-b538a36f5ad4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1095853562-172.17.0.3-1595927685146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36194,DS-899e6d6f-2ac7-4c47-b0b6-c8d24cf38fea,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-aba09c07-be3a-4a3b-a442-0db25de2bea1,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-82e1a821-0e38-4062-b35e-9b6a5a957f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-c817128c-ad98-4f56-8245-eddff93ffcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-66d8c753-22ac-49c0-97c7-536bf60a74db,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-66aa702a-d2b8-4064-9c6c-7e584e8a9d25,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-0823f47f-67a6-4c27-b6ac-9959a8d7738b,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-9eb723f1-35df-491e-84f1-0305d3c96b4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1095853562-172.17.0.3-1595927685146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36194,DS-899e6d6f-2ac7-4c47-b0b6-c8d24cf38fea,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-aba09c07-be3a-4a3b-a442-0db25de2bea1,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-82e1a821-0e38-4062-b35e-9b6a5a957f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-c817128c-ad98-4f56-8245-eddff93ffcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-66d8c753-22ac-49c0-97c7-536bf60a74db,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-66aa702a-d2b8-4064-9c6c-7e584e8a9d25,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-0823f47f-67a6-4c27-b6ac-9959a8d7738b,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-9eb723f1-35df-491e-84f1-0305d3c96b4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5345
