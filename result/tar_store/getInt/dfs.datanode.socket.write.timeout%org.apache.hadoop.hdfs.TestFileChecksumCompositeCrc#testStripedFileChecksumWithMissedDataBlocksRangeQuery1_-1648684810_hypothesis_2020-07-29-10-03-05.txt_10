reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1162932598-172.17.0.5-1596017684681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45689,DS-ac7be7fd-64f3-48ca-9b98-e8bbb2c2e901,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-2b281e02-6663-444f-864d-8b7c376dd52d,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-c8e02839-dbb0-4eee-9301-876ee99b1b44,DISK], DatanodeInfoWithStorage[127.0.0.1:41192,DS-bc824baa-594e-4e63-9f70-9823c603b2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41727,DS-5dba9741-9c77-42c3-b29c-0c832e0eed18,DISK], DatanodeInfoWithStorage[127.0.0.1:41803,DS-c4fe6626-29b6-46e2-9b71-13e8ae4fca5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-796ebc48-5ac5-4c2a-be66-e0be5d80532e,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-dcbda347-aab6-4468-b465-3655e7424629,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1162932598-172.17.0.5-1596017684681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45689,DS-ac7be7fd-64f3-48ca-9b98-e8bbb2c2e901,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-2b281e02-6663-444f-864d-8b7c376dd52d,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-c8e02839-dbb0-4eee-9301-876ee99b1b44,DISK], DatanodeInfoWithStorage[127.0.0.1:41192,DS-bc824baa-594e-4e63-9f70-9823c603b2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41727,DS-5dba9741-9c77-42c3-b29c-0c832e0eed18,DISK], DatanodeInfoWithStorage[127.0.0.1:41803,DS-c4fe6626-29b6-46e2-9b71-13e8ae4fca5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-796ebc48-5ac5-4c2a-be66-e0be5d80532e,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-dcbda347-aab6-4468-b465-3655e7424629,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-18353241-172.17.0.5-1596017838763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34142,DS-b0ac9007-9341-4f72-ae20-7bc78bd5bbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-710a735b-588f-4b21-96de-26ac39817634,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-ea51dd15-366e-4378-9b69-f688e61e3633,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-a411ef75-f382-44dc-b834-b449570bda85,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-afa281e2-6ea8-455c-8777-7592b5f22762,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-f151a798-c7b7-45ed-b7e3-75cf6ea10d75,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-40b473d2-e1bf-4999-b10c-96cddf9f8e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-0cb1f99c-2b41-4a95-ba14-f0eb9a67b620,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-18353241-172.17.0.5-1596017838763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34142,DS-b0ac9007-9341-4f72-ae20-7bc78bd5bbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-710a735b-588f-4b21-96de-26ac39817634,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-ea51dd15-366e-4378-9b69-f688e61e3633,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-a411ef75-f382-44dc-b834-b449570bda85,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-afa281e2-6ea8-455c-8777-7592b5f22762,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-f151a798-c7b7-45ed-b7e3-75cf6ea10d75,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-40b473d2-e1bf-4999-b10c-96cddf9f8e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-0cb1f99c-2b41-4a95-ba14-f0eb9a67b620,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1444136545-172.17.0.5-1596017874065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41499,DS-d05afeb9-6345-4d3d-bdf1-28647a1b55ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-b7ac8490-e031-45c2-b3c7-e2262a7d8d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-a856c840-5eb0-4562-87f2-4d99f5f18841,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-b11db6c9-9ce9-44ad-b72b-e79657d1e29e,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-8abb1757-9c7d-4354-9df0-d6f6405f6310,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-b40630cf-ac52-4bda-bff3-6c7090e5ddd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-0e98f4b7-81c6-4c60-b258-b020c9cc3313,DISK], DatanodeInfoWithStorage[127.0.0.1:42876,DS-7cd78a56-991e-4fa4-8ed4-444268ab7715,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1444136545-172.17.0.5-1596017874065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41499,DS-d05afeb9-6345-4d3d-bdf1-28647a1b55ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-b7ac8490-e031-45c2-b3c7-e2262a7d8d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-a856c840-5eb0-4562-87f2-4d99f5f18841,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-b11db6c9-9ce9-44ad-b72b-e79657d1e29e,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-8abb1757-9c7d-4354-9df0-d6f6405f6310,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-b40630cf-ac52-4bda-bff3-6c7090e5ddd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-0e98f4b7-81c6-4c60-b258-b020c9cc3313,DISK], DatanodeInfoWithStorage[127.0.0.1:42876,DS-7cd78a56-991e-4fa4-8ed4-444268ab7715,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2030795121-172.17.0.5-1596018397329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35322,DS-2a96cb1f-d292-4066-af3c-95a1a5863bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-c1008bac-9fac-46de-9250-e734d3c1bb90,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-a19e3930-e95e-4599-a677-660361c2a104,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-251f500f-cf2a-405c-a1ab-b9a8664539fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45331,DS-e9514a3a-76fc-42cd-9292-fd977a34b4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-6a83907c-c960-485a-99c5-5d23d680b2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-512d0567-d029-4c19-8da8-db5056a94260,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-a43e5fb7-2847-4d8b-89c7-bbe5adb7894b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2030795121-172.17.0.5-1596018397329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35322,DS-2a96cb1f-d292-4066-af3c-95a1a5863bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-c1008bac-9fac-46de-9250-e734d3c1bb90,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-a19e3930-e95e-4599-a677-660361c2a104,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-251f500f-cf2a-405c-a1ab-b9a8664539fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45331,DS-e9514a3a-76fc-42cd-9292-fd977a34b4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-6a83907c-c960-485a-99c5-5d23d680b2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-512d0567-d029-4c19-8da8-db5056a94260,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-a43e5fb7-2847-4d8b-89c7-bbe5adb7894b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1573321051-172.17.0.5-1596018434154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40181,DS-c0ab658e-5882-48f9-b81f-cd2332f01621,DISK], DatanodeInfoWithStorage[127.0.0.1:39979,DS-8cc2e1a6-a265-4db6-9872-306c2c582ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:46495,DS-f4abe6df-5726-4c15-b1cb-9aeb8d4e2e61,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-47514ff7-3bb3-4ada-bf0e-9fed66c7651d,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-42f853a0-2006-4697-b77c-5c79e108a52b,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-311eb499-c28d-4bb6-90da-b81bac24c9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-55c31a6b-9ac2-4725-b1c0-079a7100a373,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-fa9bd09b-a357-4480-b306-e60816c0fd1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1573321051-172.17.0.5-1596018434154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40181,DS-c0ab658e-5882-48f9-b81f-cd2332f01621,DISK], DatanodeInfoWithStorage[127.0.0.1:39979,DS-8cc2e1a6-a265-4db6-9872-306c2c582ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:46495,DS-f4abe6df-5726-4c15-b1cb-9aeb8d4e2e61,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-47514ff7-3bb3-4ada-bf0e-9fed66c7651d,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-42f853a0-2006-4697-b77c-5c79e108a52b,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-311eb499-c28d-4bb6-90da-b81bac24c9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-55c31a6b-9ac2-4725-b1c0-079a7100a373,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-fa9bd09b-a357-4480-b306-e60816c0fd1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2075182348-172.17.0.5-1596018598277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33511,DS-9680c2d4-b7fd-4ec8-92c1-70eadeb1ec5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-1fe5860e-4a8d-40a7-9e5b-c4907928d3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-1575a2af-01bb-410e-be91-78063948c39d,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-c8d7efd4-4332-4f68-800f-a4af9c8a6996,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-adb1febc-2a14-4db3-b0f7-ac0b0ac61a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-f6875c2e-f8b6-479d-9485-9d9e06d29996,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-be681277-0281-4d80-a17f-30fd0f9eaa8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-9c792cb9-7c92-42af-a6c4-175d8c69f482,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2075182348-172.17.0.5-1596018598277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33511,DS-9680c2d4-b7fd-4ec8-92c1-70eadeb1ec5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-1fe5860e-4a8d-40a7-9e5b-c4907928d3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-1575a2af-01bb-410e-be91-78063948c39d,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-c8d7efd4-4332-4f68-800f-a4af9c8a6996,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-adb1febc-2a14-4db3-b0f7-ac0b0ac61a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-f6875c2e-f8b6-479d-9485-9d9e06d29996,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-be681277-0281-4d80-a17f-30fd0f9eaa8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-9c792cb9-7c92-42af-a6c4-175d8c69f482,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1777407630-172.17.0.5-1596018922959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44304,DS-732c894a-b7dd-412e-9881-60ea2c63443a,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-49042a3c-bd3e-456a-a641-f8eb4ec6bba7,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-95b41729-a976-43b6-af36-48d34c35b6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-a722cea1-7070-42c5-b963-78038aadd79a,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-9adf9c5f-1a16-46bc-b5e9-c5b6cbbdb486,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-e9a0f1e7-b585-4b8d-9ba7-c907534d0de0,DISK], DatanodeInfoWithStorage[127.0.0.1:37923,DS-919c0e9d-6977-4abf-8b74-79427ab2f701,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-d1664f1d-c003-4e60-9a77-bedfba1766f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1777407630-172.17.0.5-1596018922959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44304,DS-732c894a-b7dd-412e-9881-60ea2c63443a,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-49042a3c-bd3e-456a-a641-f8eb4ec6bba7,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-95b41729-a976-43b6-af36-48d34c35b6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-a722cea1-7070-42c5-b963-78038aadd79a,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-9adf9c5f-1a16-46bc-b5e9-c5b6cbbdb486,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-e9a0f1e7-b585-4b8d-9ba7-c907534d0de0,DISK], DatanodeInfoWithStorage[127.0.0.1:37923,DS-919c0e9d-6977-4abf-8b74-79427ab2f701,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-d1664f1d-c003-4e60-9a77-bedfba1766f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1000582629-172.17.0.5-1596019100726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37362,DS-988b15ad-11e2-43f7-8132-d3f411bd3a08,DISK], DatanodeInfoWithStorage[127.0.0.1:36684,DS-e7e2a604-c2bd-42bc-92fa-79a64d9ab8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-30fe015e-3f4d-4a60-9b77-e6da2e8e9fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-57251562-1d37-4096-a2ba-3e2c2ed8dd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-ee930bac-2095-409e-93ed-21684706f43b,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-5fcdac0c-9232-47c0-9b7d-e7d13be719fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-eac15a69-986d-4172-8ace-4356734e899f,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-f9ef6ab8-dab6-476c-ab82-8b6530da70fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1000582629-172.17.0.5-1596019100726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37362,DS-988b15ad-11e2-43f7-8132-d3f411bd3a08,DISK], DatanodeInfoWithStorage[127.0.0.1:36684,DS-e7e2a604-c2bd-42bc-92fa-79a64d9ab8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-30fe015e-3f4d-4a60-9b77-e6da2e8e9fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-57251562-1d37-4096-a2ba-3e2c2ed8dd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-ee930bac-2095-409e-93ed-21684706f43b,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-5fcdac0c-9232-47c0-9b7d-e7d13be719fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-eac15a69-986d-4172-8ace-4356734e899f,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-f9ef6ab8-dab6-476c-ab82-8b6530da70fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891114197-172.17.0.5-1596019388310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42295,DS-a0b0c76e-8f06-4631-aa28-679f281e2efc,DISK], DatanodeInfoWithStorage[127.0.0.1:35185,DS-d8314c8b-0993-471e-ab90-69b6fb01bb79,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-5a1f7de7-4a9d-4817-9e50-796fedb7a059,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-8d4dd212-8155-4cd9-a575-44673507c007,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-fcd7459c-91ce-4d41-b895-80ab27944da4,DISK], DatanodeInfoWithStorage[127.0.0.1:44716,DS-6164688c-8e97-4e98-a589-8fe8cffcdc36,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-848a77eb-f081-49a3-98f7-866fd6bdb9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42851,DS-6a704a88-bd74-4f20-86e2-3ad853c6941e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891114197-172.17.0.5-1596019388310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42295,DS-a0b0c76e-8f06-4631-aa28-679f281e2efc,DISK], DatanodeInfoWithStorage[127.0.0.1:35185,DS-d8314c8b-0993-471e-ab90-69b6fb01bb79,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-5a1f7de7-4a9d-4817-9e50-796fedb7a059,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-8d4dd212-8155-4cd9-a575-44673507c007,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-fcd7459c-91ce-4d41-b895-80ab27944da4,DISK], DatanodeInfoWithStorage[127.0.0.1:44716,DS-6164688c-8e97-4e98-a589-8fe8cffcdc36,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-848a77eb-f081-49a3-98f7-866fd6bdb9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42851,DS-6a704a88-bd74-4f20-86e2-3ad853c6941e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1836309207-172.17.0.5-1596019910695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40433,DS-a20deb92-e1e4-4778-9ea1-e862c7d9e9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39309,DS-499590c7-0b4f-45a9-acc1-081479defd3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46634,DS-8f7eab0b-b3c4-4ac4-a211-37923bfde1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-8d380f9b-ccfe-440d-8a90-679db7d7b298,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-e6b60daa-fe49-47af-9055-8ce4d36ab333,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-c8a79f2a-4c37-4d67-92a4-c5d00e2b4ada,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-d1d5558f-3c81-4e8b-9559-e64bdbe47c62,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-57cb1170-7e40-4d78-87a4-10a115a3e6b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1836309207-172.17.0.5-1596019910695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40433,DS-a20deb92-e1e4-4778-9ea1-e862c7d9e9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39309,DS-499590c7-0b4f-45a9-acc1-081479defd3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46634,DS-8f7eab0b-b3c4-4ac4-a211-37923bfde1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-8d380f9b-ccfe-440d-8a90-679db7d7b298,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-e6b60daa-fe49-47af-9055-8ce4d36ab333,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-c8a79f2a-4c37-4d67-92a4-c5d00e2b4ada,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-d1d5558f-3c81-4e8b-9559-e64bdbe47c62,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-57cb1170-7e40-4d78-87a4-10a115a3e6b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1025500348-172.17.0.5-1596020045307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44208,DS-2e72205c-ee1a-4b6d-aa41-f0eb1708f97b,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-8488959f-9072-41c4-a718-5f989b0a13c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-2fab4b82-e6d8-40aa-8154-26ba87d1ca91,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-4d3daef7-7c5b-4d60-8c62-da8d569dd30b,DISK], DatanodeInfoWithStorage[127.0.0.1:42801,DS-fa6b6b37-5eaa-4649-9998-6bbf4b92537f,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-95db289f-f001-4713-a595-a2e218f7b70a,DISK], DatanodeInfoWithStorage[127.0.0.1:34601,DS-8f898e14-8fb0-469f-8efe-b54e0df80763,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-bcd55195-7f83-46f0-881b-3a48a81eef22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1025500348-172.17.0.5-1596020045307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44208,DS-2e72205c-ee1a-4b6d-aa41-f0eb1708f97b,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-8488959f-9072-41c4-a718-5f989b0a13c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-2fab4b82-e6d8-40aa-8154-26ba87d1ca91,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-4d3daef7-7c5b-4d60-8c62-da8d569dd30b,DISK], DatanodeInfoWithStorage[127.0.0.1:42801,DS-fa6b6b37-5eaa-4649-9998-6bbf4b92537f,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-95db289f-f001-4713-a595-a2e218f7b70a,DISK], DatanodeInfoWithStorage[127.0.0.1:34601,DS-8f898e14-8fb0-469f-8efe-b54e0df80763,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-bcd55195-7f83-46f0-881b-3a48a81eef22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-340376087-172.17.0.5-1596020176189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34942,DS-6ac5e50b-79f5-4c4d-b363-0f619a31ce73,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-8aa833a2-76d6-4fad-ad15-bdc1a406711e,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-1859408e-8a5b-41f6-8372-24fc4d7cbb23,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-b73a246c-aee6-4499-a300-3fcd01342960,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-26d6ab2d-c5ec-4429-8505-1fee297495b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-7af1362e-0307-4ca0-a7ad-2387e8f555a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37392,DS-426c3204-4041-4cbd-b10b-c659a92ad5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-3e83dfa5-e874-4c4e-85d7-b075d03d4f98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-340376087-172.17.0.5-1596020176189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34942,DS-6ac5e50b-79f5-4c4d-b363-0f619a31ce73,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-8aa833a2-76d6-4fad-ad15-bdc1a406711e,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-1859408e-8a5b-41f6-8372-24fc4d7cbb23,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-b73a246c-aee6-4499-a300-3fcd01342960,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-26d6ab2d-c5ec-4429-8505-1fee297495b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-7af1362e-0307-4ca0-a7ad-2387e8f555a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37392,DS-426c3204-4041-4cbd-b10b-c659a92ad5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-3e83dfa5-e874-4c4e-85d7-b075d03d4f98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1171136355-172.17.0.5-1596020241851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37568,DS-4f388ba4-a2b9-4fbb-b313-83bd86ea5e93,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-d43115f9-b67e-408b-83f7-4f744956ec53,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-adde88e7-ba69-44bf-a466-8ac829728232,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-a5c89dfc-8f99-46ac-81fe-daafcabbb247,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-969f518d-1afb-4785-b68f-59316f2cff0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-4f349a59-a64a-4616-b62c-aee94bb3edc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-49eadaec-75f5-48d3-b497-49b99e46d775,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-d850f983-1895-4e6c-9667-24e1dd116d08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1171136355-172.17.0.5-1596020241851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37568,DS-4f388ba4-a2b9-4fbb-b313-83bd86ea5e93,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-d43115f9-b67e-408b-83f7-4f744956ec53,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-adde88e7-ba69-44bf-a466-8ac829728232,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-a5c89dfc-8f99-46ac-81fe-daafcabbb247,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-969f518d-1afb-4785-b68f-59316f2cff0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-4f349a59-a64a-4616-b62c-aee94bb3edc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-49eadaec-75f5-48d3-b497-49b99e46d775,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-d850f983-1895-4e6c-9667-24e1dd116d08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1594231688-172.17.0.5-1596020721474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43232,DS-73043728-ac6e-4438-9e36-0bc9cba01fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-8edcdeae-ffd9-4e55-8241-89a998ae3b34,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-c4082bbe-0747-4aba-ba8f-98d65cc94089,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-7dd5f1c6-119d-4b93-b8d2-6a0e7ccb0e63,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-d005dc12-40a9-4197-bf42-b966920e5965,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-ab07c33d-65ab-412d-adc2-c4cc0daf0e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-dc13fc50-227d-4f18-8ab5-65125c5be1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-e0ed48e0-d54c-436f-b393-100b62a6ed4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1594231688-172.17.0.5-1596020721474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43232,DS-73043728-ac6e-4438-9e36-0bc9cba01fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-8edcdeae-ffd9-4e55-8241-89a998ae3b34,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-c4082bbe-0747-4aba-ba8f-98d65cc94089,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-7dd5f1c6-119d-4b93-b8d2-6a0e7ccb0e63,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-d005dc12-40a9-4197-bf42-b966920e5965,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-ab07c33d-65ab-412d-adc2-c4cc0daf0e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-dc13fc50-227d-4f18-8ab5-65125c5be1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-e0ed48e0-d54c-436f-b393-100b62a6ed4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-523513028-172.17.0.5-1596021007744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35039,DS-2fa74989-bf39-48f5-a33c-fd78cfed982e,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-7aee9ca5-a054-498b-b888-81b1ac17a065,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-3d8527d7-5190-4cf2-a33d-18fb0c92efc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-393d5664-6106-472f-9f58-931583863a89,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-f4c00a51-02f9-48c7-bdd4-514e87538588,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-aee1a17e-b169-422b-8809-61e44fa6ee50,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-45395f8c-6363-4bbd-9c48-a7015493a0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-84eff796-2f96-4d23-b8c0-e6e9e1c42080,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-523513028-172.17.0.5-1596021007744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35039,DS-2fa74989-bf39-48f5-a33c-fd78cfed982e,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-7aee9ca5-a054-498b-b888-81b1ac17a065,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-3d8527d7-5190-4cf2-a33d-18fb0c92efc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-393d5664-6106-472f-9f58-931583863a89,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-f4c00a51-02f9-48c7-bdd4-514e87538588,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-aee1a17e-b169-422b-8809-61e44fa6ee50,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-45395f8c-6363-4bbd-9c48-a7015493a0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-84eff796-2f96-4d23-b8c0-e6e9e1c42080,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-217569846-172.17.0.5-1596021396524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42671,DS-7d0b4e77-aa76-421f-91c8-684caf295ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-a95b1817-9db3-431c-bf55-4921134baf2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-b63d981e-ff98-4591-983d-3b995d3efd30,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-c07be5ee-2a10-4396-bbac-a7fa3db0ef60,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-8bcf6ad9-e880-4e5e-8a8e-e0e338567299,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-04c49e14-9721-43bd-8677-84b874001daf,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-adfe7546-e543-4492-b96b-1e67f895d227,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-9b851392-d1cc-4575-8694-6d4199f2dfc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-217569846-172.17.0.5-1596021396524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42671,DS-7d0b4e77-aa76-421f-91c8-684caf295ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-a95b1817-9db3-431c-bf55-4921134baf2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-b63d981e-ff98-4591-983d-3b995d3efd30,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-c07be5ee-2a10-4396-bbac-a7fa3db0ef60,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-8bcf6ad9-e880-4e5e-8a8e-e0e338567299,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-04c49e14-9721-43bd-8677-84b874001daf,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-adfe7546-e543-4492-b96b-1e67f895d227,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-9b851392-d1cc-4575-8694-6d4199f2dfc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-696393899-172.17.0.5-1596021960627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38390,DS-759076cf-9ee7-448b-a394-e17fce0d43a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-2d206fb4-8ea5-446b-a2ea-6cde9905af5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41361,DS-5ec8eb3a-8973-4bdb-b887-01459cdf854c,DISK], DatanodeInfoWithStorage[127.0.0.1:41819,DS-c8dd8d5b-0958-4222-b432-0bc8d44f632f,DISK], DatanodeInfoWithStorage[127.0.0.1:32953,DS-92eeff4b-ab9d-4f29-82d6-b3eeba86d926,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-2b90baea-d42a-43dd-82ff-0284f9c0173e,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-6bd6ab99-f51e-46da-820f-ccd86c2abe19,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-6be938b1-5d8d-499c-99ef-19e58f98a2c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-696393899-172.17.0.5-1596021960627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38390,DS-759076cf-9ee7-448b-a394-e17fce0d43a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-2d206fb4-8ea5-446b-a2ea-6cde9905af5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41361,DS-5ec8eb3a-8973-4bdb-b887-01459cdf854c,DISK], DatanodeInfoWithStorage[127.0.0.1:41819,DS-c8dd8d5b-0958-4222-b432-0bc8d44f632f,DISK], DatanodeInfoWithStorage[127.0.0.1:32953,DS-92eeff4b-ab9d-4f29-82d6-b3eeba86d926,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-2b90baea-d42a-43dd-82ff-0284f9c0173e,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-6bd6ab99-f51e-46da-820f-ccd86c2abe19,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-6be938b1-5d8d-499c-99ef-19e58f98a2c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5213
