reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-376235351-172.17.0.19-1595874889878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34527,DS-52dd53d3-e1cf-457b-892d-336703634929,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-a49b13c0-1c3d-4082-86f7-c3ef967f8c91,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-7d5ce650-620b-4177-a433-1ad181b9eff2,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-740eb470-2b33-4863-a130-21065023ebd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-dcf4aeb4-d58b-4648-91be-f5e2b713ee32,DISK], DatanodeInfoWithStorage[127.0.0.1:34138,DS-59abb43b-e62c-4f4c-b3da-e663ef3357a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-8a4afccc-a5a1-4e1b-9467-74aece98635d,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-71a7fc54-b514-4aea-bac5-0a54e47643ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-376235351-172.17.0.19-1595874889878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34527,DS-52dd53d3-e1cf-457b-892d-336703634929,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-a49b13c0-1c3d-4082-86f7-c3ef967f8c91,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-7d5ce650-620b-4177-a433-1ad181b9eff2,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-740eb470-2b33-4863-a130-21065023ebd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-dcf4aeb4-d58b-4648-91be-f5e2b713ee32,DISK], DatanodeInfoWithStorage[127.0.0.1:34138,DS-59abb43b-e62c-4f4c-b3da-e663ef3357a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-8a4afccc-a5a1-4e1b-9467-74aece98635d,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-71a7fc54-b514-4aea-bac5-0a54e47643ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1908691956-172.17.0.19-1595875574527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45850,DS-ba5a797f-fc95-4e06-af44-b943c6d631b3,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-e7e04b49-d195-4212-a084-9ad2efe144cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40873,DS-71eb196a-5be7-4e4a-8f81-3e62d49506a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-ded86c65-1d10-4e61-921c-bb5db7c09746,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-acff8c3f-be7d-45e5-8fe3-f81af8c8b8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37940,DS-0ec14f7e-a84f-4c60-bcc8-c8d927a337f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-778b1625-1662-4b9d-8ad3-f04b2de7d7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-7fab97ef-c0f7-430a-86f7-f6e7207eb2c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1908691956-172.17.0.19-1595875574527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45850,DS-ba5a797f-fc95-4e06-af44-b943c6d631b3,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-e7e04b49-d195-4212-a084-9ad2efe144cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40873,DS-71eb196a-5be7-4e4a-8f81-3e62d49506a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-ded86c65-1d10-4e61-921c-bb5db7c09746,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-acff8c3f-be7d-45e5-8fe3-f81af8c8b8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37940,DS-0ec14f7e-a84f-4c60-bcc8-c8d927a337f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-778b1625-1662-4b9d-8ad3-f04b2de7d7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-7fab97ef-c0f7-430a-86f7-f6e7207eb2c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2039288781-172.17.0.19-1595875720668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33478,DS-bc129126-71e0-4663-b21e-b282f21c2a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46267,DS-a455cb64-fec1-4b92-9470-2ae747f3073c,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-595138dc-8133-43b2-b081-0e418b1edbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-831a01b0-8ad6-455b-ae43-8a66d54acf2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35441,DS-ea5af3b0-5ace-4549-86f5-a1ea90c08cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-4ab006ca-0c8c-47f9-afd7-e3d2b96c41d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-037929b5-412b-48ae-b6cd-c1b073ac8b84,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-46370e1a-ca1b-4fef-b53a-1828b508ca9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2039288781-172.17.0.19-1595875720668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33478,DS-bc129126-71e0-4663-b21e-b282f21c2a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46267,DS-a455cb64-fec1-4b92-9470-2ae747f3073c,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-595138dc-8133-43b2-b081-0e418b1edbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-831a01b0-8ad6-455b-ae43-8a66d54acf2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35441,DS-ea5af3b0-5ace-4549-86f5-a1ea90c08cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-4ab006ca-0c8c-47f9-afd7-e3d2b96c41d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-037929b5-412b-48ae-b6cd-c1b073ac8b84,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-46370e1a-ca1b-4fef-b53a-1828b508ca9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1890976295-172.17.0.19-1595875946488:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38635,DS-a5d8f169-2743-49f4-8b6d-f830261726f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-43e95eff-ba5a-48f7-bb69-4cd64e788107,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-581cabcb-f39d-4e22-b225-5352c94cf62b,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-5b4e0e17-cbf8-403c-bbcc-41c6d21912de,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-76bb485c-5fc3-4fb9-81e8-48ecfbcf9664,DISK], DatanodeInfoWithStorage[127.0.0.1:33546,DS-add2a01e-214b-486b-beed-f4d911154339,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-dbeadba4-560a-441e-a866-d141dc6c3735,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-ace3aaa5-400e-40d2-ae55-b545b1681398,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1890976295-172.17.0.19-1595875946488:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38635,DS-a5d8f169-2743-49f4-8b6d-f830261726f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-43e95eff-ba5a-48f7-bb69-4cd64e788107,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-581cabcb-f39d-4e22-b225-5352c94cf62b,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-5b4e0e17-cbf8-403c-bbcc-41c6d21912de,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-76bb485c-5fc3-4fb9-81e8-48ecfbcf9664,DISK], DatanodeInfoWithStorage[127.0.0.1:33546,DS-add2a01e-214b-486b-beed-f4d911154339,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-dbeadba4-560a-441e-a866-d141dc6c3735,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-ace3aaa5-400e-40d2-ae55-b545b1681398,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-528235422-172.17.0.19-1595876172973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42533,DS-02447c09-51f7-42cb-987c-57d887ff1652,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-6c8adc9c-452b-4406-8d00-9b1790a9c7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-c05c7ebe-97ce-4b0e-8a44-b4c73c58d33f,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-0f84f4cf-1b76-4c40-a239-701dc6b359ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-dd8ab7fc-2544-40f6-a243-6e5f1f46b1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-c5632b63-ffed-4046-9061-74008b83abb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-a8e6031d-9482-4af5-8ad9-e78cd8c2cba5,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-6320e106-4020-4ae6-afcf-a5985c71e7c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-528235422-172.17.0.19-1595876172973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42533,DS-02447c09-51f7-42cb-987c-57d887ff1652,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-6c8adc9c-452b-4406-8d00-9b1790a9c7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-c05c7ebe-97ce-4b0e-8a44-b4c73c58d33f,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-0f84f4cf-1b76-4c40-a239-701dc6b359ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-dd8ab7fc-2544-40f6-a243-6e5f1f46b1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-c5632b63-ffed-4046-9061-74008b83abb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-a8e6031d-9482-4af5-8ad9-e78cd8c2cba5,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-6320e106-4020-4ae6-afcf-a5985c71e7c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-41560572-172.17.0.19-1595876215161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45230,DS-035dd297-6cc2-4313-ad49-ffc2bc6fc92e,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-1ab8ab57-65e2-48a8-9595-bfae25ee59c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-fcca5a0b-93f0-4c13-b35b-0a8b56bdf71e,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-600fb61f-f722-4775-8ece-912407e25d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46266,DS-3f18bc9c-f7a9-46f1-aafa-0457ff4fb27e,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-225e4348-910c-43c5-bea1-ea4df14324db,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-9be9365e-b67b-41ea-91c6-482321e8a971,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-19cad9b8-434a-4129-a7d7-cc2fc20d75ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-41560572-172.17.0.19-1595876215161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45230,DS-035dd297-6cc2-4313-ad49-ffc2bc6fc92e,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-1ab8ab57-65e2-48a8-9595-bfae25ee59c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-fcca5a0b-93f0-4c13-b35b-0a8b56bdf71e,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-600fb61f-f722-4775-8ece-912407e25d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46266,DS-3f18bc9c-f7a9-46f1-aafa-0457ff4fb27e,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-225e4348-910c-43c5-bea1-ea4df14324db,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-9be9365e-b67b-41ea-91c6-482321e8a971,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-19cad9b8-434a-4129-a7d7-cc2fc20d75ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1724472229-172.17.0.19-1595876589658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35678,DS-9607bc3d-ea4b-495f-bb18-03309c6ccee7,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-334f4716-55b3-406a-b301-68faf4e9c46b,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-a13d1adc-2967-45e2-b38e-9bb42fc69b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-fd48bcb1-e4ca-481a-bf6c-ceef52b2a747,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-28a2de43-cf07-4849-ab77-5a653b4113b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-357614c0-e993-41e9-891a-28bdec520184,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-77b5b854-3581-40db-8f70-8e3b3f05b9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42296,DS-ab71cf10-be37-4353-90a2-7bb1ae70fe67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1724472229-172.17.0.19-1595876589658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35678,DS-9607bc3d-ea4b-495f-bb18-03309c6ccee7,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-334f4716-55b3-406a-b301-68faf4e9c46b,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-a13d1adc-2967-45e2-b38e-9bb42fc69b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-fd48bcb1-e4ca-481a-bf6c-ceef52b2a747,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-28a2de43-cf07-4849-ab77-5a653b4113b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-357614c0-e993-41e9-891a-28bdec520184,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-77b5b854-3581-40db-8f70-8e3b3f05b9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42296,DS-ab71cf10-be37-4353-90a2-7bb1ae70fe67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-543293704-172.17.0.19-1595876782350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43517,DS-873828f7-37db-4bc8-9334-b0614e610c74,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-a928f221-5037-46e5-a2fa-a868ff7ff17e,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-ac8f5c0b-3d74-41b2-9a06-402f8f026ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-e3cf230a-9f7d-4946-81a6-24c420e19624,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-cb1afb6c-c66e-47cf-b9f9-8de7cf33c091,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-7f365216-10c5-4f87-8b9c-29d1b9cd1860,DISK], DatanodeInfoWithStorage[127.0.0.1:35040,DS-b810453c-563e-4b7f-933d-fa9b6a0d6e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-e3ef98e8-543d-47c0-bba2-b1dd10f6baf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-543293704-172.17.0.19-1595876782350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43517,DS-873828f7-37db-4bc8-9334-b0614e610c74,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-a928f221-5037-46e5-a2fa-a868ff7ff17e,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-ac8f5c0b-3d74-41b2-9a06-402f8f026ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-e3cf230a-9f7d-4946-81a6-24c420e19624,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-cb1afb6c-c66e-47cf-b9f9-8de7cf33c091,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-7f365216-10c5-4f87-8b9c-29d1b9cd1860,DISK], DatanodeInfoWithStorage[127.0.0.1:35040,DS-b810453c-563e-4b7f-933d-fa9b6a0d6e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-e3ef98e8-543d-47c0-bba2-b1dd10f6baf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-863233831-172.17.0.19-1595876823473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33559,DS-015ff844-3b71-45f2-a97c-cb5807fcd4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45052,DS-16e9e3db-439e-4977-9a9d-630dffccfee4,DISK], DatanodeInfoWithStorage[127.0.0.1:35324,DS-0705bd70-82da-4cd8-8ef1-eac145cc468c,DISK], DatanodeInfoWithStorage[127.0.0.1:35148,DS-dbfe231f-df44-4114-9e42-df796147a47e,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-62857eb0-37ab-49c9-ad80-d35eef20a4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-599b6c70-08cc-4658-a169-a70bb84bc2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-c2b1270d-181e-43cd-bc6d-c079ad7f1c58,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-dcfea746-f6fa-4d6c-a7f8-4e381728ae3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-863233831-172.17.0.19-1595876823473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33559,DS-015ff844-3b71-45f2-a97c-cb5807fcd4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45052,DS-16e9e3db-439e-4977-9a9d-630dffccfee4,DISK], DatanodeInfoWithStorage[127.0.0.1:35324,DS-0705bd70-82da-4cd8-8ef1-eac145cc468c,DISK], DatanodeInfoWithStorage[127.0.0.1:35148,DS-dbfe231f-df44-4114-9e42-df796147a47e,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-62857eb0-37ab-49c9-ad80-d35eef20a4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-599b6c70-08cc-4658-a169-a70bb84bc2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-c2b1270d-181e-43cd-bc6d-c079ad7f1c58,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-dcfea746-f6fa-4d6c-a7f8-4e381728ae3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-492619643-172.17.0.19-1595877059397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36130,DS-2788d465-4620-4a20-9297-f7cb5b579c01,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-8df20707-82eb-4471-b694-7db71f2b718d,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-94044408-2e70-454c-9016-3daead31e4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-b3086201-7589-47df-9ac2-23eb8f98bad2,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-f0834a3d-8570-4b07-a702-2955a84eefe5,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-a69fb706-9ef5-4bcd-b366-3df11550360d,DISK], DatanodeInfoWithStorage[127.0.0.1:40472,DS-e3ffc486-22ab-4495-bef5-95dc743633c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-32ce6d57-aea1-4168-b53c-a7de97107baa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-492619643-172.17.0.19-1595877059397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36130,DS-2788d465-4620-4a20-9297-f7cb5b579c01,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-8df20707-82eb-4471-b694-7db71f2b718d,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-94044408-2e70-454c-9016-3daead31e4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-b3086201-7589-47df-9ac2-23eb8f98bad2,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-f0834a3d-8570-4b07-a702-2955a84eefe5,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-a69fb706-9ef5-4bcd-b366-3df11550360d,DISK], DatanodeInfoWithStorage[127.0.0.1:40472,DS-e3ffc486-22ab-4495-bef5-95dc743633c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-32ce6d57-aea1-4168-b53c-a7de97107baa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-937830001-172.17.0.19-1595877432330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32999,DS-62f9124e-581f-4474-8307-6346e7b1c621,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-f2c8a4b4-bef6-42e0-9b01-b706c752d919,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-6cc94e46-f7c2-4fa3-a731-d6b9deb725a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-07a4c227-6914-4d00-82ff-0413b33bd7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34668,DS-f30ef1a7-90dc-4efa-a032-3aa2ace041d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-43801781-a60e-4a45-b0bd-ae20eece5729,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-59257f3d-b853-4f3f-8455-9e0d134ded92,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-9abbd57b-7aec-4e7b-8a8f-dfd1c31f909c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-937830001-172.17.0.19-1595877432330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32999,DS-62f9124e-581f-4474-8307-6346e7b1c621,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-f2c8a4b4-bef6-42e0-9b01-b706c752d919,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-6cc94e46-f7c2-4fa3-a731-d6b9deb725a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-07a4c227-6914-4d00-82ff-0413b33bd7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34668,DS-f30ef1a7-90dc-4efa-a032-3aa2ace041d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-43801781-a60e-4a45-b0bd-ae20eece5729,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-59257f3d-b853-4f3f-8455-9e0d134ded92,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-9abbd57b-7aec-4e7b-8a8f-dfd1c31f909c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-71907271-172.17.0.19-1595877549611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46236,DS-dbb742d8-161b-433a-8c6e-5a1c439c81f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-b5886fe8-6276-443b-a3b2-8de191af24bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35774,DS-cc22c90d-6305-4974-a6ff-a5e5cf18f26c,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-5c80e274-bbd1-438f-95ec-19821b34f40e,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-ae4424ae-bdfa-4a48-b5a5-d03b22b9467e,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-3e8bd287-5d41-4c6e-b028-3479ea0370c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-678626ec-362b-463e-b656-069036b89269,DISK], DatanodeInfoWithStorage[127.0.0.1:41893,DS-63c9603d-80c3-4560-b12f-7307076bc0f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-71907271-172.17.0.19-1595877549611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46236,DS-dbb742d8-161b-433a-8c6e-5a1c439c81f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-b5886fe8-6276-443b-a3b2-8de191af24bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35774,DS-cc22c90d-6305-4974-a6ff-a5e5cf18f26c,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-5c80e274-bbd1-438f-95ec-19821b34f40e,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-ae4424ae-bdfa-4a48-b5a5-d03b22b9467e,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-3e8bd287-5d41-4c6e-b028-3479ea0370c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-678626ec-362b-463e-b656-069036b89269,DISK], DatanodeInfoWithStorage[127.0.0.1:41893,DS-63c9603d-80c3-4560-b12f-7307076bc0f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-724306864-172.17.0.19-1595877749124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35743,DS-dd9229e4-91dd-4373-8b7a-9001d2449a47,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-e20f66dd-279f-4efd-942d-03c8c2b47551,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-22308336-a25e-430f-bda4-f8c45f35f920,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-2e3a7903-afd6-4653-b140-79e6c7ea40b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-b99637fc-a938-4acd-85cd-1204b25f319a,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-dc61135f-acc2-4b52-b1fb-233648daa03d,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-35062e4d-c1db-4e29-b28a-34c7d5585caa,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-d89d682a-72c0-493e-acf7-a4090ee4088a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-724306864-172.17.0.19-1595877749124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35743,DS-dd9229e4-91dd-4373-8b7a-9001d2449a47,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-e20f66dd-279f-4efd-942d-03c8c2b47551,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-22308336-a25e-430f-bda4-f8c45f35f920,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-2e3a7903-afd6-4653-b140-79e6c7ea40b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-b99637fc-a938-4acd-85cd-1204b25f319a,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-dc61135f-acc2-4b52-b1fb-233648daa03d,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-35062e4d-c1db-4e29-b28a-34c7d5585caa,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-d89d682a-72c0-493e-acf7-a4090ee4088a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1978089917-172.17.0.19-1595878067744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37975,DS-182fa3f2-6ee8-406c-b91f-bf5d6158302c,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-0767a12f-b7e5-44b5-98e5-6a92ed306d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-b55b53df-9d1c-4a12-aeaf-482d0f835b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-10b506b7-e802-4743-a8e5-ba1ec859c00e,DISK], DatanodeInfoWithStorage[127.0.0.1:42534,DS-3d703668-5970-41e2-875a-afb5c2c1c1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-73de62e8-f94a-42db-bcc2-6266f9068f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-749d3794-5a31-4d8a-9d89-9c65b0d92a11,DISK], DatanodeInfoWithStorage[127.0.0.1:38901,DS-d2eb19a4-4517-4c6c-a6ed-19e9dd9a09bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1978089917-172.17.0.19-1595878067744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37975,DS-182fa3f2-6ee8-406c-b91f-bf5d6158302c,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-0767a12f-b7e5-44b5-98e5-6a92ed306d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-b55b53df-9d1c-4a12-aeaf-482d0f835b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-10b506b7-e802-4743-a8e5-ba1ec859c00e,DISK], DatanodeInfoWithStorage[127.0.0.1:42534,DS-3d703668-5970-41e2-875a-afb5c2c1c1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-73de62e8-f94a-42db-bcc2-6266f9068f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-749d3794-5a31-4d8a-9d89-9c65b0d92a11,DISK], DatanodeInfoWithStorage[127.0.0.1:38901,DS-d2eb19a4-4517-4c6c-a6ed-19e9dd9a09bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-908422698-172.17.0.19-1595879229731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44411,DS-b760bc76-ee68-480d-99eb-3d79e2939d29,DISK], DatanodeInfoWithStorage[127.0.0.1:35312,DS-2d519952-2ff3-4893-a780-d6a06703b577,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-84e05078-7e83-4586-a0a5-3e924201b844,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-48c9ebe7-2f49-434c-9d67-7d38256480ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-25b3e9e4-da9e-46bb-9fef-e07a9f6e5eac,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-ff8cd522-0dea-4459-8c0f-4c81741c0a94,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-9b7140a5-15cd-4884-b279-c728c5eedc4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45535,DS-03d0fcf6-88b6-43d6-b385-e72eeabe38e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-908422698-172.17.0.19-1595879229731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44411,DS-b760bc76-ee68-480d-99eb-3d79e2939d29,DISK], DatanodeInfoWithStorage[127.0.0.1:35312,DS-2d519952-2ff3-4893-a780-d6a06703b577,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-84e05078-7e83-4586-a0a5-3e924201b844,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-48c9ebe7-2f49-434c-9d67-7d38256480ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-25b3e9e4-da9e-46bb-9fef-e07a9f6e5eac,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-ff8cd522-0dea-4459-8c0f-4c81741c0a94,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-9b7140a5-15cd-4884-b279-c728c5eedc4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45535,DS-03d0fcf6-88b6-43d6-b385-e72eeabe38e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-909548094-172.17.0.19-1595879418230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40060,DS-07dc288e-6605-418d-b5ba-ce068b814569,DISK], DatanodeInfoWithStorage[127.0.0.1:34343,DS-ec1c0fa6-5998-45a9-8859-574acd246dca,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-50628d56-b115-46b8-be38-30a73bbb833a,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-43ceebd9-fac4-4b95-99a1-330991c1a44c,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-276952a3-489d-40a6-82a3-63864d6fc894,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-8aada8e2-2273-49c0-907e-3fbac5a1224b,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-df53b61a-40e3-4173-ac20-d72daaccee48,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-4ad00229-c8cb-4bda-af19-3c33b3032c2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-909548094-172.17.0.19-1595879418230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40060,DS-07dc288e-6605-418d-b5ba-ce068b814569,DISK], DatanodeInfoWithStorage[127.0.0.1:34343,DS-ec1c0fa6-5998-45a9-8859-574acd246dca,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-50628d56-b115-46b8-be38-30a73bbb833a,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-43ceebd9-fac4-4b95-99a1-330991c1a44c,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-276952a3-489d-40a6-82a3-63864d6fc894,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-8aada8e2-2273-49c0-907e-3fbac5a1224b,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-df53b61a-40e3-4173-ac20-d72daaccee48,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-4ad00229-c8cb-4bda-af19-3c33b3032c2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1569078734-172.17.0.19-1595879677988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33715,DS-32a7b78b-ad69-4392-91f3-5f5fc92e0852,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-dec42a1d-8673-442e-9ca6-31823946fea1,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-7d5f9834-c3fc-4061-94f3-803a9853051d,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-d675e2d2-da57-42c4-80d9-368e1fe5761f,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-f90dbb7a-38aa-4abe-8346-4940abda7746,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-bbe2cff9-63c7-47f6-81c7-7f84df21b7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39691,DS-3dc428a1-9d47-4e53-9394-9641d8e8f077,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-e2fcd838-a487-4139-bc81-30a86bbd1577,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1569078734-172.17.0.19-1595879677988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33715,DS-32a7b78b-ad69-4392-91f3-5f5fc92e0852,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-dec42a1d-8673-442e-9ca6-31823946fea1,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-7d5f9834-c3fc-4061-94f3-803a9853051d,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-d675e2d2-da57-42c4-80d9-368e1fe5761f,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-f90dbb7a-38aa-4abe-8346-4940abda7746,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-bbe2cff9-63c7-47f6-81c7-7f84df21b7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39691,DS-3dc428a1-9d47-4e53-9394-9641d8e8f077,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-e2fcd838-a487-4139-bc81-30a86bbd1577,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1402271642-172.17.0.19-1595879812114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41152,DS-12894a17-3597-4a79-a536-a84aa23c2580,DISK], DatanodeInfoWithStorage[127.0.0.1:33332,DS-cab40807-5994-4bd5-9150-870787404104,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-7939a1bc-04f3-4136-a02c-eea511250a11,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-bab74d34-75ea-410c-8683-c6930db0ef89,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-14b21a70-2ca7-4ed4-9233-dc6a142cacbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37952,DS-8c15e5c9-1ad3-413b-96fa-b8c9c29f3d29,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-6254072e-79d0-44ea-8b25-32052b720420,DISK], DatanodeInfoWithStorage[127.0.0.1:46495,DS-b1908e8c-7f14-468d-b085-ca802f00656f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1402271642-172.17.0.19-1595879812114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41152,DS-12894a17-3597-4a79-a536-a84aa23c2580,DISK], DatanodeInfoWithStorage[127.0.0.1:33332,DS-cab40807-5994-4bd5-9150-870787404104,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-7939a1bc-04f3-4136-a02c-eea511250a11,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-bab74d34-75ea-410c-8683-c6930db0ef89,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-14b21a70-2ca7-4ed4-9233-dc6a142cacbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37952,DS-8c15e5c9-1ad3-413b-96fa-b8c9c29f3d29,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-6254072e-79d0-44ea-8b25-32052b720420,DISK], DatanodeInfoWithStorage[127.0.0.1:46495,DS-b1908e8c-7f14-468d-b085-ca802f00656f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5659
