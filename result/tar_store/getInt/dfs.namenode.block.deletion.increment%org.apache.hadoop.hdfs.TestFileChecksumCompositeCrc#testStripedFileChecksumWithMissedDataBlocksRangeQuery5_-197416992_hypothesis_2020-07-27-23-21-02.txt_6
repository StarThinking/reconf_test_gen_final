reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319916592-172.17.0.14-1595892216234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33879,DS-cd74b121-631d-426c-aaaf-62cafaea610c,DISK], DatanodeInfoWithStorage[127.0.0.1:35379,DS-79faee79-e654-4207-8d09-1bbc397f51cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-60560fc1-5e9d-45f4-984c-1c45dcc2db5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-1d365dd0-f4fc-4880-a9d6-74d6d2ed78ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33278,DS-2b211986-76ac-409a-b572-6530dfc80be4,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-09ecf54d-aead-4cc4-8174-4260684322ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-c9942198-6b2d-4b72-ae51-ea084f2cbcc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-adef2a41-32b7-41c8-8bad-03fdd533ad8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319916592-172.17.0.14-1595892216234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33879,DS-cd74b121-631d-426c-aaaf-62cafaea610c,DISK], DatanodeInfoWithStorage[127.0.0.1:35379,DS-79faee79-e654-4207-8d09-1bbc397f51cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-60560fc1-5e9d-45f4-984c-1c45dcc2db5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-1d365dd0-f4fc-4880-a9d6-74d6d2ed78ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33278,DS-2b211986-76ac-409a-b572-6530dfc80be4,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-09ecf54d-aead-4cc4-8174-4260684322ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-c9942198-6b2d-4b72-ae51-ea084f2cbcc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-adef2a41-32b7-41c8-8bad-03fdd533ad8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-945237828-172.17.0.14-1595892324362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37618,DS-38264367-9ade-46a8-be57-504ef910c527,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-fd8275f8-b7a8-42cd-8fbc-b6149dd76766,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-ef16dc95-8e22-47b5-a723-6c2deb48b256,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-0964ad56-9c0d-428f-9267-8d0d891260ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-80d5bdb9-c933-4d40-9f71-f1138c286aea,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-1b0074d8-a451-4339-8ea1-e8f17415340a,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-f00199f1-b850-40da-a9fa-7e4b1a6a2605,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-4e978a90-1ce4-4481-9a3f-ae08e629cd33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-945237828-172.17.0.14-1595892324362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37618,DS-38264367-9ade-46a8-be57-504ef910c527,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-fd8275f8-b7a8-42cd-8fbc-b6149dd76766,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-ef16dc95-8e22-47b5-a723-6c2deb48b256,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-0964ad56-9c0d-428f-9267-8d0d891260ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-80d5bdb9-c933-4d40-9f71-f1138c286aea,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-1b0074d8-a451-4339-8ea1-e8f17415340a,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-f00199f1-b850-40da-a9fa-7e4b1a6a2605,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-4e978a90-1ce4-4481-9a3f-ae08e629cd33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-254778621-172.17.0.14-1595893075288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37676,DS-9afb7e99-2d2f-4106-a3b6-7711d3758d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-2bb15503-74d7-40b9-a73e-0827d8281eca,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-d7d89651-ede8-48a1-ae63-a7a7f8522ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-28ca9c2e-62cc-42b2-8660-d51cbc510be7,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-6e4dd71e-84c1-4de4-bd67-a5924388b9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-b2641889-42dc-47c8-9963-74f737dc5d99,DISK], DatanodeInfoWithStorage[127.0.0.1:41053,DS-f9ff9a0f-6a87-4250-a67f-a44dc8901dee,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-f9df04b6-0670-4c3e-bc3c-a272424e24ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-254778621-172.17.0.14-1595893075288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37676,DS-9afb7e99-2d2f-4106-a3b6-7711d3758d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-2bb15503-74d7-40b9-a73e-0827d8281eca,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-d7d89651-ede8-48a1-ae63-a7a7f8522ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-28ca9c2e-62cc-42b2-8660-d51cbc510be7,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-6e4dd71e-84c1-4de4-bd67-a5924388b9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-b2641889-42dc-47c8-9963-74f737dc5d99,DISK], DatanodeInfoWithStorage[127.0.0.1:41053,DS-f9ff9a0f-6a87-4250-a67f-a44dc8901dee,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-f9df04b6-0670-4c3e-bc3c-a272424e24ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614934722-172.17.0.14-1595893284376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42488,DS-a15800b3-831e-4d86-a98c-3d1031c8bd57,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-743479a9-3ff7-4afb-8ff7-3d0919cb6560,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-ec4c4be4-9510-4512-b1fb-960f87857e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-aa250a0f-7533-4bc4-9655-de2b4d786480,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-1ee9dc2b-544f-4897-9ea5-eb1fa3c44336,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-47e3b4d7-a45a-43c0-b6e7-7fafe7db0b61,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-655da648-1425-4a4b-95d0-0d08dc4fdeb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37747,DS-6622ed45-c763-45f5-81e7-57c6fb88d5bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614934722-172.17.0.14-1595893284376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42488,DS-a15800b3-831e-4d86-a98c-3d1031c8bd57,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-743479a9-3ff7-4afb-8ff7-3d0919cb6560,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-ec4c4be4-9510-4512-b1fb-960f87857e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-aa250a0f-7533-4bc4-9655-de2b4d786480,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-1ee9dc2b-544f-4897-9ea5-eb1fa3c44336,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-47e3b4d7-a45a-43c0-b6e7-7fafe7db0b61,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-655da648-1425-4a4b-95d0-0d08dc4fdeb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37747,DS-6622ed45-c763-45f5-81e7-57c6fb88d5bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-782855725-172.17.0.14-1595894456327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40792,DS-f41840f3-8fd0-4f7e-8fb5-166f2fedad96,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-26e52b67-5fe4-4229-8642-825e4c18ee85,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-442c0204-23a7-4890-9329-4e77012f5ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:43517,DS-9e98eba4-fa46-42c5-932e-8d937a94de51,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-4de8b434-65da-4003-b37f-aef48efd51b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-efd39b7d-dcf1-4612-8b46-190346cc720f,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-751dd4f9-aaac-4b56-9c5c-aed575fb1b38,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-79fb1874-7398-443e-ba57-50857f1d2025,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-782855725-172.17.0.14-1595894456327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40792,DS-f41840f3-8fd0-4f7e-8fb5-166f2fedad96,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-26e52b67-5fe4-4229-8642-825e4c18ee85,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-442c0204-23a7-4890-9329-4e77012f5ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:43517,DS-9e98eba4-fa46-42c5-932e-8d937a94de51,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-4de8b434-65da-4003-b37f-aef48efd51b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-efd39b7d-dcf1-4612-8b46-190346cc720f,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-751dd4f9-aaac-4b56-9c5c-aed575fb1b38,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-79fb1874-7398-443e-ba57-50857f1d2025,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-559206067-172.17.0.14-1595894751579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44862,DS-b0338965-07a4-40cb-b8e5-f673ecfe8806,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-7e4104d4-e891-4b64-bc0d-c75867b7e10e,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-074f96f1-0918-477c-a97d-6b485972b3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-0ea71b6b-ab94-4627-b007-55ccba1c8101,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-5134f210-68b7-4319-8160-b0d21d1ff68f,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-b64466a8-f186-4643-882b-844e138909c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-c2469d33-e293-41b6-91b7-a23f555a487d,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-d5540885-99bb-49d2-a912-444a5e8a6588,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-559206067-172.17.0.14-1595894751579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44862,DS-b0338965-07a4-40cb-b8e5-f673ecfe8806,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-7e4104d4-e891-4b64-bc0d-c75867b7e10e,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-074f96f1-0918-477c-a97d-6b485972b3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-0ea71b6b-ab94-4627-b007-55ccba1c8101,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-5134f210-68b7-4319-8160-b0d21d1ff68f,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-b64466a8-f186-4643-882b-844e138909c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-c2469d33-e293-41b6-91b7-a23f555a487d,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-d5540885-99bb-49d2-a912-444a5e8a6588,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1747002334-172.17.0.14-1595895439158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40800,DS-40226e08-e268-464c-8814-f17b94c8120a,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-707fee2b-049b-4c2c-aaf9-8ae09f4c2a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-5ef0821f-5bb1-4824-b41f-44106d95b4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-bc214e7b-960e-4aa8-8273-47a29ace2bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-9f45a021-5d16-4a95-84cb-7f94976d7792,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-c074b241-9030-41e9-9765-96af8d8c408d,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-63eb9df9-9702-4227-b8c2-51af5ed98c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-fc99c01c-999d-4a79-9e96-5c09941a0632,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1747002334-172.17.0.14-1595895439158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40800,DS-40226e08-e268-464c-8814-f17b94c8120a,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-707fee2b-049b-4c2c-aaf9-8ae09f4c2a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-5ef0821f-5bb1-4824-b41f-44106d95b4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-bc214e7b-960e-4aa8-8273-47a29ace2bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-9f45a021-5d16-4a95-84cb-7f94976d7792,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-c074b241-9030-41e9-9765-96af8d8c408d,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-63eb9df9-9702-4227-b8c2-51af5ed98c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-fc99c01c-999d-4a79-9e96-5c09941a0632,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1409351449-172.17.0.14-1595895688550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37466,DS-0dc7d3c2-4c10-41d4-91d0-65ced95582cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-1ff428cc-4e8e-4901-9738-59d66db11d75,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-583c501e-b9a0-4624-9305-6d24ec7c752f,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-1df3dae9-eec5-45a9-9e2d-8bad94f62f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41554,DS-6d4a290a-116f-4bc4-ba93-f9365145a89f,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-8b317490-bdba-4996-bdce-bc5ce61f69bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-7afdba18-db6e-4712-bce3-23f63202a8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-35bed13d-6c47-4b22-b295-8fd755558a0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1409351449-172.17.0.14-1595895688550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37466,DS-0dc7d3c2-4c10-41d4-91d0-65ced95582cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-1ff428cc-4e8e-4901-9738-59d66db11d75,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-583c501e-b9a0-4624-9305-6d24ec7c752f,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-1df3dae9-eec5-45a9-9e2d-8bad94f62f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41554,DS-6d4a290a-116f-4bc4-ba93-f9365145a89f,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-8b317490-bdba-4996-bdce-bc5ce61f69bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-7afdba18-db6e-4712-bce3-23f63202a8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-35bed13d-6c47-4b22-b295-8fd755558a0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2142525605-172.17.0.14-1595896318549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32807,DS-87635486-53a9-44ce-81a9-726060b72025,DISK], DatanodeInfoWithStorage[127.0.0.1:45007,DS-ddbc851d-d430-4fe7-87a1-6491932f701d,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-345f63bf-83ff-4d0b-afd4-5e1a7e1df687,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-761a2717-6d3d-4132-86b2-c9e24de3ef77,DISK], DatanodeInfoWithStorage[127.0.0.1:46505,DS-dc9af5b7-0c85-4687-bad8-790238e39822,DISK], DatanodeInfoWithStorage[127.0.0.1:35309,DS-be7af2b3-6dcd-478b-9a17-d9e9aa100b15,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-880182ad-369e-4cbe-bec8-1ac1f3d658ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-0129a8ea-6fd5-4be4-abe3-01eba61e5420,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2142525605-172.17.0.14-1595896318549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32807,DS-87635486-53a9-44ce-81a9-726060b72025,DISK], DatanodeInfoWithStorage[127.0.0.1:45007,DS-ddbc851d-d430-4fe7-87a1-6491932f701d,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-345f63bf-83ff-4d0b-afd4-5e1a7e1df687,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-761a2717-6d3d-4132-86b2-c9e24de3ef77,DISK], DatanodeInfoWithStorage[127.0.0.1:46505,DS-dc9af5b7-0c85-4687-bad8-790238e39822,DISK], DatanodeInfoWithStorage[127.0.0.1:35309,DS-be7af2b3-6dcd-478b-9a17-d9e9aa100b15,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-880182ad-369e-4cbe-bec8-1ac1f3d658ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-0129a8ea-6fd5-4be4-abe3-01eba61e5420,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-363862700-172.17.0.14-1595896437171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38724,DS-eefec5e0-ced8-4945-9af7-ed63746dacb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-6dfaf17e-551e-4cb7-b170-1bb7b7b35e01,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-f9e11f7d-43c6-4e8f-9634-e790a9706cec,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-1cd61492-67d8-4004-b886-d5463c23503c,DISK], DatanodeInfoWithStorage[127.0.0.1:45081,DS-8086197d-19e5-4c41-bc0f-0888cd056ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-3653e8a6-30c9-483c-b9de-893aedf966a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-fca650b6-e0bc-4657-9f4b-9bffc1a03444,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-678a0c25-e198-4f18-b0cf-526d0fd60020,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-363862700-172.17.0.14-1595896437171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38724,DS-eefec5e0-ced8-4945-9af7-ed63746dacb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-6dfaf17e-551e-4cb7-b170-1bb7b7b35e01,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-f9e11f7d-43c6-4e8f-9634-e790a9706cec,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-1cd61492-67d8-4004-b886-d5463c23503c,DISK], DatanodeInfoWithStorage[127.0.0.1:45081,DS-8086197d-19e5-4c41-bc0f-0888cd056ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-3653e8a6-30c9-483c-b9de-893aedf966a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-fca650b6-e0bc-4657-9f4b-9bffc1a03444,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-678a0c25-e198-4f18-b0cf-526d0fd60020,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2070398894-172.17.0.14-1595897106476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34687,DS-91ef61e7-2abe-4590-b1c1-90eb5e8836b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45493,DS-f125af17-737f-4d3d-8b7f-7b96bad7ff7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40873,DS-6f5d7fcf-1efc-446b-873d-07cfd34a30a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-356621b7-a213-469c-aba9-4d4be84deb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-0f2a6c69-680c-4205-8f9d-e00ff9b88c88,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-d1cdefee-4d39-4952-bfa4-3dcb243dadda,DISK], DatanodeInfoWithStorage[127.0.0.1:41412,DS-0b31df40-6d9c-40d2-b498-d117cf0ccd6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-b8bd1412-cdd1-4dc7-a5ae-aeb262c4b11b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2070398894-172.17.0.14-1595897106476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34687,DS-91ef61e7-2abe-4590-b1c1-90eb5e8836b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45493,DS-f125af17-737f-4d3d-8b7f-7b96bad7ff7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40873,DS-6f5d7fcf-1efc-446b-873d-07cfd34a30a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-356621b7-a213-469c-aba9-4d4be84deb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-0f2a6c69-680c-4205-8f9d-e00ff9b88c88,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-d1cdefee-4d39-4952-bfa4-3dcb243dadda,DISK], DatanodeInfoWithStorage[127.0.0.1:41412,DS-0b31df40-6d9c-40d2-b498-d117cf0ccd6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-b8bd1412-cdd1-4dc7-a5ae-aeb262c4b11b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-750164111-172.17.0.14-1595897179925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46866,DS-5614938f-ebb7-454a-af2f-af5e4fcf0efe,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-9bc48d4e-165e-45f6-a3ea-5e78eb0e4269,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-cb752939-bc6c-4c6a-a5c5-dfadb8103309,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-3e462d0f-b170-4928-9c7c-245fb67da84d,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-f62bd388-5077-4595-9190-870a7f83e678,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-968aa380-10e0-4584-8e0d-fd70c1ae0b22,DISK], DatanodeInfoWithStorage[127.0.0.1:38014,DS-2ff9a7b7-9017-4804-8b32-49c92af631c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35326,DS-e8a3f572-9f28-4d5b-8b2d-1cb722b77f7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-750164111-172.17.0.14-1595897179925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46866,DS-5614938f-ebb7-454a-af2f-af5e4fcf0efe,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-9bc48d4e-165e-45f6-a3ea-5e78eb0e4269,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-cb752939-bc6c-4c6a-a5c5-dfadb8103309,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-3e462d0f-b170-4928-9c7c-245fb67da84d,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-f62bd388-5077-4595-9190-870a7f83e678,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-968aa380-10e0-4584-8e0d-fd70c1ae0b22,DISK], DatanodeInfoWithStorage[127.0.0.1:38014,DS-2ff9a7b7-9017-4804-8b32-49c92af631c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35326,DS-e8a3f572-9f28-4d5b-8b2d-1cb722b77f7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1482478670-172.17.0.14-1595897261560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37869,DS-4a554391-5bb6-4395-8d26-a869ed7ee208,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-48f48011-2427-444c-90ca-e184ce5c5d71,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-4fb461f9-5984-4d11-ba63-a14ffaaf0355,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-f0f987a4-4f69-4474-8e5b-dabcc3eca4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-d9ed971f-dada-4015-ad1a-196edd91c022,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-41f020ee-a999-4725-a768-bff1554da1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-4b778d88-c0d5-4ab9-8aa1-e5163728918a,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-e40d57f9-995e-4c39-9428-bc1020d05c55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1482478670-172.17.0.14-1595897261560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37869,DS-4a554391-5bb6-4395-8d26-a869ed7ee208,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-48f48011-2427-444c-90ca-e184ce5c5d71,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-4fb461f9-5984-4d11-ba63-a14ffaaf0355,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-f0f987a4-4f69-4474-8e5b-dabcc3eca4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-d9ed971f-dada-4015-ad1a-196edd91c022,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-41f020ee-a999-4725-a768-bff1554da1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-4b778d88-c0d5-4ab9-8aa1-e5163728918a,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-e40d57f9-995e-4c39-9428-bc1020d05c55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1524007436-172.17.0.14-1595897439157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36699,DS-204be10e-10ec-4a4d-8244-bebb53c3968d,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-6249425f-eccc-4364-842a-a48b64f30444,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-f819b131-1daf-4aae-9bb6-d4886b74b0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-12c09155-4817-41d3-822a-1301a9ded9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-2795c209-1010-4bfe-864b-35c8a1f475f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-c8ad3e8f-e608-4e6e-89ae-0580dafd2df5,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-c741bcc9-6657-465a-b886-79d67ded712a,DISK], DatanodeInfoWithStorage[127.0.0.1:33106,DS-a05ba4ec-78ac-4737-ae1d-f63e461fcbe3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1524007436-172.17.0.14-1595897439157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36699,DS-204be10e-10ec-4a4d-8244-bebb53c3968d,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-6249425f-eccc-4364-842a-a48b64f30444,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-f819b131-1daf-4aae-9bb6-d4886b74b0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-12c09155-4817-41d3-822a-1301a9ded9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-2795c209-1010-4bfe-864b-35c8a1f475f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-c8ad3e8f-e608-4e6e-89ae-0580dafd2df5,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-c741bcc9-6657-465a-b886-79d67ded712a,DISK], DatanodeInfoWithStorage[127.0.0.1:33106,DS-a05ba4ec-78ac-4737-ae1d-f63e461fcbe3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5431
