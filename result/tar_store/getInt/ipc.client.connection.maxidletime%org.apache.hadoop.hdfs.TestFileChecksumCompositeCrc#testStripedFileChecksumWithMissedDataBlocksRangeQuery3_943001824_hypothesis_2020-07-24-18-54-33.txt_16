reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1509683524-172.17.0.12-1595617256178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34034,DS-1b9271c0-50c6-4ede-8e96-39a5b9977ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-96492611-6100-45a3-80b8-92f78a9c1a74,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-9f951c20-f764-42d9-a0e5-600ee6f97f63,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-066d71d6-14fa-40d1-b138-c1beb90f20c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-53b3a7bc-e0cc-4d5e-921c-b24b0af2caaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-ce311a98-cf60-481c-b72a-61b2f37ca307,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-23507c9f-a55c-4eb2-8cf2-00fd43561d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-35f383f3-4642-455a-8a87-42bf69df8094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1509683524-172.17.0.12-1595617256178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34034,DS-1b9271c0-50c6-4ede-8e96-39a5b9977ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-96492611-6100-45a3-80b8-92f78a9c1a74,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-9f951c20-f764-42d9-a0e5-600ee6f97f63,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-066d71d6-14fa-40d1-b138-c1beb90f20c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-53b3a7bc-e0cc-4d5e-921c-b24b0af2caaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-ce311a98-cf60-481c-b72a-61b2f37ca307,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-23507c9f-a55c-4eb2-8cf2-00fd43561d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-35f383f3-4642-455a-8a87-42bf69df8094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1471430503-172.17.0.12-1595617969618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37068,DS-a00b5353-e4f2-4bc4-92d9-ee32120e1441,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-a005d681-1fcb-4ce4-8eb7-2fd97a543a56,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-87b15350-8ea1-48e1-9e1b-fcedd2e01f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-5fb423bb-491e-41cc-a600-0718653058f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-fa9ddfbc-355e-427b-8888-2d50a614e489,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-3e753a0c-bd68-4d78-a76d-1536a0b87bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-3927f30f-ce93-4542-b6e0-b551d8ff1757,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-f81a6e3c-c85f-4667-9e7b-2a8d1384785c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1471430503-172.17.0.12-1595617969618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37068,DS-a00b5353-e4f2-4bc4-92d9-ee32120e1441,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-a005d681-1fcb-4ce4-8eb7-2fd97a543a56,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-87b15350-8ea1-48e1-9e1b-fcedd2e01f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-5fb423bb-491e-41cc-a600-0718653058f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-fa9ddfbc-355e-427b-8888-2d50a614e489,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-3e753a0c-bd68-4d78-a76d-1536a0b87bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-3927f30f-ce93-4542-b6e0-b551d8ff1757,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-f81a6e3c-c85f-4667-9e7b-2a8d1384785c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258763039-172.17.0.12-1595618059836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37931,DS-86e77987-7faa-4163-b72f-891645bf0fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-6f25c1a1-5124-46c8-a9e4-f52b2efa8175,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-f4538391-99be-432e-9e77-7095c7fda387,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-cb496e3a-fa0c-4055-a78c-db431dfae8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-af5e8f4e-a1fa-487d-ba87-65dcad5fa6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-c9cec473-4c56-4e8f-b5a9-6b6109b1839b,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-89709d12-049d-4fdb-97a2-fa308caf83f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-650656f4-6030-4229-8c03-44244d33c375,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258763039-172.17.0.12-1595618059836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37931,DS-86e77987-7faa-4163-b72f-891645bf0fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-6f25c1a1-5124-46c8-a9e4-f52b2efa8175,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-f4538391-99be-432e-9e77-7095c7fda387,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-cb496e3a-fa0c-4055-a78c-db431dfae8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-af5e8f4e-a1fa-487d-ba87-65dcad5fa6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-c9cec473-4c56-4e8f-b5a9-6b6109b1839b,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-89709d12-049d-4fdb-97a2-fa308caf83f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-650656f4-6030-4229-8c03-44244d33c375,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1370623547-172.17.0.12-1595618684921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38203,DS-47fcb9eb-23b8-43e5-9c2d-116ad57ca538,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-5fe4c1c2-8ead-4089-9e85-23c805738d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46368,DS-443db3b1-857b-4506-a42f-6996eac15426,DISK], DatanodeInfoWithStorage[127.0.0.1:45996,DS-cb084df1-becb-4ac6-82ea-5804b244e741,DISK], DatanodeInfoWithStorage[127.0.0.1:36936,DS-f50779f0-a622-49a0-a550-24d8d14e8e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-ee8fb028-58ba-41d4-9b0d-7ee402f3985c,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-33d17a11-abb6-490c-9e2d-6371a0ef8af6,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-efbc85ec-c965-4532-bd3d-75aa8185621e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1370623547-172.17.0.12-1595618684921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38203,DS-47fcb9eb-23b8-43e5-9c2d-116ad57ca538,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-5fe4c1c2-8ead-4089-9e85-23c805738d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46368,DS-443db3b1-857b-4506-a42f-6996eac15426,DISK], DatanodeInfoWithStorage[127.0.0.1:45996,DS-cb084df1-becb-4ac6-82ea-5804b244e741,DISK], DatanodeInfoWithStorage[127.0.0.1:36936,DS-f50779f0-a622-49a0-a550-24d8d14e8e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-ee8fb028-58ba-41d4-9b0d-7ee402f3985c,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-33d17a11-abb6-490c-9e2d-6371a0ef8af6,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-efbc85ec-c965-4532-bd3d-75aa8185621e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-73636298-172.17.0.12-1595618783073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36257,DS-c1f797a2-6ba7-4b1d-acd9-d28a257f4790,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-b4ffd2b4-c31e-4976-b3c4-b0d2cbdb6c06,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-578f8ce7-f01b-4409-90a5-32d6dccec487,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-26687061-c526-48da-bd11-967cfca699e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-298a8121-b626-44ca-a793-77179c4a92d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-f0ca9d90-bce3-4b1a-ab92-03eef11efaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-55df8cdd-6e76-43b2-8d2c-66608c15591a,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-cf03f9cb-eef7-42fe-8530-5cf06babc65d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-73636298-172.17.0.12-1595618783073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36257,DS-c1f797a2-6ba7-4b1d-acd9-d28a257f4790,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-b4ffd2b4-c31e-4976-b3c4-b0d2cbdb6c06,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-578f8ce7-f01b-4409-90a5-32d6dccec487,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-26687061-c526-48da-bd11-967cfca699e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-298a8121-b626-44ca-a793-77179c4a92d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-f0ca9d90-bce3-4b1a-ab92-03eef11efaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-55df8cdd-6e76-43b2-8d2c-66608c15591a,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-cf03f9cb-eef7-42fe-8530-5cf06babc65d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-385857535-172.17.0.12-1595619261653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40253,DS-4c53119f-150f-4a99-891e-1024629d1e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-e2f3886b-4b0f-454d-90a8-8cf844caaa12,DISK], DatanodeInfoWithStorage[127.0.0.1:34949,DS-f2798dbe-9d67-4242-af89-7b081b144cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-c22fe862-b844-48b2-908e-3ba8d6995cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-83f2f023-1ac9-4a40-bd6c-cee701895446,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-6e38661e-a0a8-4932-83d3-f21414ce7988,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-36c45217-5bec-4ebf-90b9-559ae170303a,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-719182db-5a7b-47a1-88b4-bee8076c8a71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-385857535-172.17.0.12-1595619261653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40253,DS-4c53119f-150f-4a99-891e-1024629d1e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-e2f3886b-4b0f-454d-90a8-8cf844caaa12,DISK], DatanodeInfoWithStorage[127.0.0.1:34949,DS-f2798dbe-9d67-4242-af89-7b081b144cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-c22fe862-b844-48b2-908e-3ba8d6995cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-83f2f023-1ac9-4a40-bd6c-cee701895446,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-6e38661e-a0a8-4932-83d3-f21414ce7988,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-36c45217-5bec-4ebf-90b9-559ae170303a,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-719182db-5a7b-47a1-88b4-bee8076c8a71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-403305809-172.17.0.12-1595619321553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41574,DS-d8a57d07-e783-4940-813f-51d44adcb82e,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-7aa4139a-8204-4bad-aa60-0516f37c4ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-167e8e5d-c3b8-45b6-af2b-3d0534f58da7,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-c2b44c17-4a79-419b-a820-63aad12cc5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-1006aa32-fb51-41c5-bd0b-237b225a73b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-4a7c663c-5696-4de2-a54e-f3e1f3cac3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-16beec9e-2318-4c6f-b868-e8f893d094da,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-8cc5d167-9724-4a44-b4b0-c03f287158f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-403305809-172.17.0.12-1595619321553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41574,DS-d8a57d07-e783-4940-813f-51d44adcb82e,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-7aa4139a-8204-4bad-aa60-0516f37c4ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-167e8e5d-c3b8-45b6-af2b-3d0534f58da7,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-c2b44c17-4a79-419b-a820-63aad12cc5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-1006aa32-fb51-41c5-bd0b-237b225a73b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-4a7c663c-5696-4de2-a54e-f3e1f3cac3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-16beec9e-2318-4c6f-b868-e8f893d094da,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-8cc5d167-9724-4a44-b4b0-c03f287158f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1629946736-172.17.0.12-1595620532315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42232,DS-df22a009-a72c-4d4b-bb08-d2172eb473d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-72cd7a7c-4dcf-4a83-9e1a-4fd5cb2e6360,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-f6d158fb-0f8b-47a9-9084-ccdb0866f25f,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-4c2ee1d6-ba9b-4342-a044-a5a61bb0d32b,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-c9f5d00e-0801-4f1e-8b24-e269f7e5e68e,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-66d42cc7-7459-4fc8-9bba-f5da58c0b84a,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-6a7badc2-a249-47c2-a194-21b356b46931,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-de556f3f-5d07-4ab0-b5f1-d14bdc1d1c03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1629946736-172.17.0.12-1595620532315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42232,DS-df22a009-a72c-4d4b-bb08-d2172eb473d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-72cd7a7c-4dcf-4a83-9e1a-4fd5cb2e6360,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-f6d158fb-0f8b-47a9-9084-ccdb0866f25f,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-4c2ee1d6-ba9b-4342-a044-a5a61bb0d32b,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-c9f5d00e-0801-4f1e-8b24-e269f7e5e68e,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-66d42cc7-7459-4fc8-9bba-f5da58c0b84a,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-6a7badc2-a249-47c2-a194-21b356b46931,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-de556f3f-5d07-4ab0-b5f1-d14bdc1d1c03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1432236304-172.17.0.12-1595620626371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44315,DS-d588531e-8351-4fd5-9115-efd0b2a17bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-2f980b70-ce63-4d22-884b-4c475ad0d528,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-9af0ca79-a107-4e6b-8ec6-d31a8f423a98,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-460a7b68-fe19-4d4a-aa9d-2bc927fcb3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-904220d2-cfac-4c03-9219-7d92800eae90,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-67f0ac55-ee75-4b73-aa45-24654afefecc,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-42d377c9-546c-4064-a07a-a9d29f19849b,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-d8e849b7-6730-46c0-b3be-894ae15cb153,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1432236304-172.17.0.12-1595620626371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44315,DS-d588531e-8351-4fd5-9115-efd0b2a17bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-2f980b70-ce63-4d22-884b-4c475ad0d528,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-9af0ca79-a107-4e6b-8ec6-d31a8f423a98,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-460a7b68-fe19-4d4a-aa9d-2bc927fcb3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-904220d2-cfac-4c03-9219-7d92800eae90,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-67f0ac55-ee75-4b73-aa45-24654afefecc,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-42d377c9-546c-4064-a07a-a9d29f19849b,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-d8e849b7-6730-46c0-b3be-894ae15cb153,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688160947-172.17.0.12-1595623033473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43933,DS-d9c4dd87-ceb5-42ec-a7b1-c7650110f5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-db0b6e16-c1fe-40ea-a82b-aab1c63e3f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-421c4911-e7e3-4531-a44f-1d121b1c90cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-29e3acaf-2bb6-4b70-ae44-26ee6069bba3,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-62a3f732-53b5-454e-88c8-9bcdb976488f,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-3b24e5d3-eb1b-4df4-83fb-de4e21927831,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-5e9e6f07-82f2-486a-b23c-88db23e03211,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-c1af6ebb-0e53-47d9-b094-400e67975a3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688160947-172.17.0.12-1595623033473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43933,DS-d9c4dd87-ceb5-42ec-a7b1-c7650110f5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-db0b6e16-c1fe-40ea-a82b-aab1c63e3f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-421c4911-e7e3-4531-a44f-1d121b1c90cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-29e3acaf-2bb6-4b70-ae44-26ee6069bba3,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-62a3f732-53b5-454e-88c8-9bcdb976488f,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-3b24e5d3-eb1b-4df4-83fb-de4e21927831,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-5e9e6f07-82f2-486a-b23c-88db23e03211,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-c1af6ebb-0e53-47d9-b094-400e67975a3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1227235846-172.17.0.12-1595623406277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40302,DS-66971b69-a77a-44f5-9e0b-05109ab0a36c,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-9806fbad-5b55-441a-a33d-1d6686c81402,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-ea8a13ce-34f8-419c-a24c-510bcd5bd80a,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-535579dc-1889-4eba-b879-81c90afd35f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-3494d114-a428-4096-abd3-77d5345192b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43962,DS-3beddc58-6e02-4e95-92fd-8ff1da9c085e,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-59e8883b-4660-47d6-a742-467134f3dc08,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-592c445c-4f2f-4cac-b680-a290d72a833b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1227235846-172.17.0.12-1595623406277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40302,DS-66971b69-a77a-44f5-9e0b-05109ab0a36c,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-9806fbad-5b55-441a-a33d-1d6686c81402,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-ea8a13ce-34f8-419c-a24c-510bcd5bd80a,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-535579dc-1889-4eba-b879-81c90afd35f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-3494d114-a428-4096-abd3-77d5345192b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43962,DS-3beddc58-6e02-4e95-92fd-8ff1da9c085e,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-59e8883b-4660-47d6-a742-467134f3dc08,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-592c445c-4f2f-4cac-b680-a290d72a833b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 6963
