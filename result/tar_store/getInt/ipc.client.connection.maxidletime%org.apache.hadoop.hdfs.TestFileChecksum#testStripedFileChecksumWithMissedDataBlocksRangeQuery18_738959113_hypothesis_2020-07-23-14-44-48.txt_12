reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2026887921-172.17.0.14-1595516133606:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43229,DS-43df4ef3-1669-427a-bb0a-0de609a902be,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-47759d53-1023-4012-ac12-71f4710bb53e,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-6cc66d69-a64a-4199-ba81-4602ef61eb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-621b59e1-c43e-48df-bfd4-c6bcd2bca5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-2861d271-ded4-43db-b406-2b724199bfef,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-c3250a79-aea9-46c3-bbec-f30c22119739,DISK], DatanodeInfoWithStorage[127.0.0.1:35811,DS-ccdb474d-0d49-4d95-a06e-f7065c7be1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-0e11d260-371d-47b8-b215-ea5451d0c382,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2026887921-172.17.0.14-1595516133606:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43229,DS-43df4ef3-1669-427a-bb0a-0de609a902be,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-47759d53-1023-4012-ac12-71f4710bb53e,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-6cc66d69-a64a-4199-ba81-4602ef61eb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-621b59e1-c43e-48df-bfd4-c6bcd2bca5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-2861d271-ded4-43db-b406-2b724199bfef,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-c3250a79-aea9-46c3-bbec-f30c22119739,DISK], DatanodeInfoWithStorage[127.0.0.1:35811,DS-ccdb474d-0d49-4d95-a06e-f7065c7be1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-0e11d260-371d-47b8-b215-ea5451d0c382,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1538692711-172.17.0.14-1595516340424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42302,DS-de784164-3614-4cbe-825e-042b30e5f673,DISK], DatanodeInfoWithStorage[127.0.0.1:45977,DS-74194fb8-961c-4417-8d43-13e04847dc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-7a3b8064-cb17-4f95-9dd4-73e617aac08c,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-15c132f9-b283-45f1-8ae6-6b5852ba1dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44863,DS-c569854c-361c-4e34-b5ed-65b4626c21b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42807,DS-3e79ab49-4cb0-4e39-8bec-fa274a094445,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-ffec238a-fec7-46d3-bf1b-573409cdb5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36453,DS-ae88a200-3e32-4eb3-a97a-d279fe6a9400,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1538692711-172.17.0.14-1595516340424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42302,DS-de784164-3614-4cbe-825e-042b30e5f673,DISK], DatanodeInfoWithStorage[127.0.0.1:45977,DS-74194fb8-961c-4417-8d43-13e04847dc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-7a3b8064-cb17-4f95-9dd4-73e617aac08c,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-15c132f9-b283-45f1-8ae6-6b5852ba1dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44863,DS-c569854c-361c-4e34-b5ed-65b4626c21b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42807,DS-3e79ab49-4cb0-4e39-8bec-fa274a094445,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-ffec238a-fec7-46d3-bf1b-573409cdb5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36453,DS-ae88a200-3e32-4eb3-a97a-d279fe6a9400,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-527009540-172.17.0.14-1595516609084:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39626,DS-606b3f76-aa1a-444b-bc21-6a74afeb8cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-d844437d-6a39-49c5-b3bf-c168c85c2dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-86e9184f-4fe6-4d22-8e20-7bd442cc9bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-8b9a6fa4-663f-4e42-89dd-6d7d4143ad88,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-cd3caa73-2942-496b-88fb-aa1e98729442,DISK], DatanodeInfoWithStorage[127.0.0.1:35341,DS-dccb1a5c-a1f8-4a51-82f6-431c20698afc,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-3632f98a-29e7-42df-9165-c241683c323d,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-079ef574-2650-4997-b2b3-69c86cbe2122,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-527009540-172.17.0.14-1595516609084:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39626,DS-606b3f76-aa1a-444b-bc21-6a74afeb8cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-d844437d-6a39-49c5-b3bf-c168c85c2dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-86e9184f-4fe6-4d22-8e20-7bd442cc9bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-8b9a6fa4-663f-4e42-89dd-6d7d4143ad88,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-cd3caa73-2942-496b-88fb-aa1e98729442,DISK], DatanodeInfoWithStorage[127.0.0.1:35341,DS-dccb1a5c-a1f8-4a51-82f6-431c20698afc,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-3632f98a-29e7-42df-9165-c241683c323d,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-079ef574-2650-4997-b2b3-69c86cbe2122,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-477453001-172.17.0.14-1595516851475:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33405,DS-2e0df02d-e8d0-4665-b558-ecd3c310a3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-f21b2b42-e3aa-4560-badd-588f8924171f,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-2323839b-19a3-4d49-8ab6-92b0c7763855,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-d1d7e6fb-cdc2-4040-9c9e-c0cc973fce62,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-9d2c333a-1ea7-4fa0-86db-7365381372fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45737,DS-b940c7e0-bb4c-4cc1-836f-af892e54dbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-20c7ab95-9e07-4cc7-8fec-91e92406e9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-ba8737b9-d650-49bb-9736-940cbb565b98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-477453001-172.17.0.14-1595516851475:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33405,DS-2e0df02d-e8d0-4665-b558-ecd3c310a3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-f21b2b42-e3aa-4560-badd-588f8924171f,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-2323839b-19a3-4d49-8ab6-92b0c7763855,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-d1d7e6fb-cdc2-4040-9c9e-c0cc973fce62,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-9d2c333a-1ea7-4fa0-86db-7365381372fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45737,DS-b940c7e0-bb4c-4cc1-836f-af892e54dbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-20c7ab95-9e07-4cc7-8fec-91e92406e9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-ba8737b9-d650-49bb-9736-940cbb565b98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-620542033-172.17.0.14-1595517004911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33676,DS-f4858d77-3a35-49b4-9c2c-bb1a053aa653,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-ff51e59f-9d77-49d3-aa90-0d9b3880be06,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-745c82f3-310d-4774-9675-737b427e206d,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-b08e07b4-76ea-4a56-9aeb-d3e199a268d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-4836696e-4f01-474a-a22b-a5e6ffecfb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-a244ecbd-3ce0-40cf-9339-59919d96293e,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-8702a517-210e-491d-8240-649b4e3a2413,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-877a171d-5095-4a25-863a-03ac06111f7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-620542033-172.17.0.14-1595517004911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33676,DS-f4858d77-3a35-49b4-9c2c-bb1a053aa653,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-ff51e59f-9d77-49d3-aa90-0d9b3880be06,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-745c82f3-310d-4774-9675-737b427e206d,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-b08e07b4-76ea-4a56-9aeb-d3e199a268d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-4836696e-4f01-474a-a22b-a5e6ffecfb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-a244ecbd-3ce0-40cf-9339-59919d96293e,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-8702a517-210e-491d-8240-649b4e3a2413,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-877a171d-5095-4a25-863a-03ac06111f7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-610861813-172.17.0.14-1595517320266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43706,DS-9c14f244-b448-46ac-8784-d03168e19a37,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-1012d9d8-ac57-4b77-8779-9ebb2117d3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-bb1711f9-3d28-4819-b7b1-cbe4f4328d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-c0a71d33-ace1-4600-94ed-1e3b2088c218,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-b8d8eb1d-5d18-4a3f-ba1d-afad6476b0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-2ceab666-eea5-4a6d-aba5-21199c1cdb38,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-9c75cf07-5201-499f-b7ca-1877f563bef3,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-f3957d27-ef83-433a-a360-527e0688d8ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-610861813-172.17.0.14-1595517320266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43706,DS-9c14f244-b448-46ac-8784-d03168e19a37,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-1012d9d8-ac57-4b77-8779-9ebb2117d3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-bb1711f9-3d28-4819-b7b1-cbe4f4328d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-c0a71d33-ace1-4600-94ed-1e3b2088c218,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-b8d8eb1d-5d18-4a3f-ba1d-afad6476b0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-2ceab666-eea5-4a6d-aba5-21199c1cdb38,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-9c75cf07-5201-499f-b7ca-1877f563bef3,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-f3957d27-ef83-433a-a360-527e0688d8ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-654932873-172.17.0.14-1595517861430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39132,DS-7bfe1852-a468-4896-a7a8-a0ad69390489,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-f759ba3c-f6d6-41bd-b9a9-fdc687dd61b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-66560206-966d-4e64-93c5-3ee5e5b1c751,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-b14c126f-d7a3-4320-9293-07f250a798d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-65f7f9a6-1df0-4ead-963f-3b65f399afb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-ac1e7743-b073-4fb2-8a38-14335180f8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-8bcbf02b-2196-4fb8-b823-424fc0d95b07,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-db1c34f7-f9ab-41bc-8c4f-e53ead77e6f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-654932873-172.17.0.14-1595517861430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39132,DS-7bfe1852-a468-4896-a7a8-a0ad69390489,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-f759ba3c-f6d6-41bd-b9a9-fdc687dd61b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-66560206-966d-4e64-93c5-3ee5e5b1c751,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-b14c126f-d7a3-4320-9293-07f250a798d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-65f7f9a6-1df0-4ead-963f-3b65f399afb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-ac1e7743-b073-4fb2-8a38-14335180f8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-8bcbf02b-2196-4fb8-b823-424fc0d95b07,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-db1c34f7-f9ab-41bc-8c4f-e53ead77e6f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-497093552-172.17.0.14-1595518395243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42542,DS-1b7e58c7-cfa9-4958-be81-fa87fe3a79b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-a106feb3-8597-4bd5-822c-75ac084c5fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-ccb92ef9-6dfc-4bbd-a4fb-ac68b30f1d75,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-9e3ebef7-d314-4451-8ca9-0620866461fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-8b25f724-7bb4-49b6-9d48-a3d964349633,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-b973d30b-2114-433c-86ab-70f9ffeaf99e,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-aba089e9-91f9-4675-9c1a-5ae1598b9ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-67f950ba-ad08-4409-bafe-f5f01f3182d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-497093552-172.17.0.14-1595518395243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42542,DS-1b7e58c7-cfa9-4958-be81-fa87fe3a79b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-a106feb3-8597-4bd5-822c-75ac084c5fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-ccb92ef9-6dfc-4bbd-a4fb-ac68b30f1d75,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-9e3ebef7-d314-4451-8ca9-0620866461fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-8b25f724-7bb4-49b6-9d48-a3d964349633,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-b973d30b-2114-433c-86ab-70f9ffeaf99e,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-aba089e9-91f9-4675-9c1a-5ae1598b9ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-67f950ba-ad08-4409-bafe-f5f01f3182d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1744725348-172.17.0.14-1595518749338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45734,DS-66fcbbc4-775d-443d-949d-53a16f9c9125,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-ad799a5b-9e91-4e4f-b7c1-7623c91b86b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-a81f393a-4dfa-442e-b527-0f17c25419fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-5af96d39-8419-4e32-aeb6-277157094095,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-ee25a853-41b6-4304-9cb5-e054cf606a33,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-1c1f50de-d07a-446b-ad9e-f992a92eda34,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-b3165ad2-e227-4781-8976-34d67e3e6607,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-9433e956-812c-4be4-b8d7-d3e46f2893bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1744725348-172.17.0.14-1595518749338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45734,DS-66fcbbc4-775d-443d-949d-53a16f9c9125,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-ad799a5b-9e91-4e4f-b7c1-7623c91b86b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-a81f393a-4dfa-442e-b527-0f17c25419fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-5af96d39-8419-4e32-aeb6-277157094095,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-ee25a853-41b6-4304-9cb5-e054cf606a33,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-1c1f50de-d07a-446b-ad9e-f992a92eda34,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-b3165ad2-e227-4781-8976-34d67e3e6607,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-9433e956-812c-4be4-b8d7-d3e46f2893bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-118401761-172.17.0.14-1595519001850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46727,DS-7c3eebb8-81b7-4a56-b005-80aecc95b7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-f5ee83ec-67aa-4d44-8dff-3bd32d39ec3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-9a66b056-be8f-4cde-b3e2-e4bac4f3ad2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-c3b3fbb1-33a8-4fe8-8a2b-bb7e143bb532,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-764be988-2f24-474a-9a62-5b08bfa5887f,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-212a05d4-4d5b-4de5-a812-b0349c7c9760,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-3ad030f0-5d94-4016-b6bd-94f138201b25,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-0c243e62-9689-4e35-9fb0-abc6bfa4b1f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-118401761-172.17.0.14-1595519001850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46727,DS-7c3eebb8-81b7-4a56-b005-80aecc95b7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-f5ee83ec-67aa-4d44-8dff-3bd32d39ec3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-9a66b056-be8f-4cde-b3e2-e4bac4f3ad2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-c3b3fbb1-33a8-4fe8-8a2b-bb7e143bb532,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-764be988-2f24-474a-9a62-5b08bfa5887f,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-212a05d4-4d5b-4de5-a812-b0349c7c9760,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-3ad030f0-5d94-4016-b6bd-94f138201b25,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-0c243e62-9689-4e35-9fb0-abc6bfa4b1f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1312378951-172.17.0.14-1595519078238:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35921,DS-60f95c76-dca8-4cf2-ac25-63d974782dca,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-d2c3298f-fb25-425e-97ac-0f125fd43717,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-83f572a8-2f9a-4f23-b6b2-399a6aae2eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-d3fb102c-e9f2-4657-a3d5-0b7c07f76bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-fca39359-542d-431a-8cb2-7182a29f1d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-c94f91ff-1bd9-42d0-bb86-4e2b0ad0717f,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-a86f461b-9372-48e0-aee2-2a7ccf6577ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-a6948271-0676-4fa0-9b7e-5ed37bada04f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1312378951-172.17.0.14-1595519078238:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35921,DS-60f95c76-dca8-4cf2-ac25-63d974782dca,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-d2c3298f-fb25-425e-97ac-0f125fd43717,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-83f572a8-2f9a-4f23-b6b2-399a6aae2eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-d3fb102c-e9f2-4657-a3d5-0b7c07f76bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-fca39359-542d-431a-8cb2-7182a29f1d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-c94f91ff-1bd9-42d0-bb86-4e2b0ad0717f,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-a86f461b-9372-48e0-aee2-2a7ccf6577ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-a6948271-0676-4fa0-9b7e-5ed37bada04f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1348555766-172.17.0.14-1595519599635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33704,DS-99c59473-e87e-40c3-8e3c-da00f593754c,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-debf0760-7229-445c-9180-3c49a856cf33,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-2187d42b-9998-4ef5-a784-dba655cfb6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-dc498a54-eaef-422b-8668-ef3779bf1c02,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-f2d37ece-ef5d-4ad7-a267-1ab6245e9f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-64dd6c44-2a7f-4f10-b054-265a046005c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37612,DS-84bd95b4-2dd1-4ce6-bf03-8ea75e834240,DISK], DatanodeInfoWithStorage[127.0.0.1:36099,DS-62054601-958a-4a9c-8367-eb6cea596cce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1348555766-172.17.0.14-1595519599635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33704,DS-99c59473-e87e-40c3-8e3c-da00f593754c,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-debf0760-7229-445c-9180-3c49a856cf33,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-2187d42b-9998-4ef5-a784-dba655cfb6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-dc498a54-eaef-422b-8668-ef3779bf1c02,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-f2d37ece-ef5d-4ad7-a267-1ab6245e9f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-64dd6c44-2a7f-4f10-b054-265a046005c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37612,DS-84bd95b4-2dd1-4ce6-bf03-8ea75e834240,DISK], DatanodeInfoWithStorage[127.0.0.1:36099,DS-62054601-958a-4a9c-8367-eb6cea596cce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1408897357-172.17.0.14-1595519635068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46425,DS-085d47d7-8431-4d10-9d5e-2fe56a7a906d,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-25a272c3-0aa9-4ca5-8887-12bc67e7cbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-c78efd74-966d-4eda-acc3-c24d63038f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-fc5c01f8-c61a-477d-a44e-f447aa06e945,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-74b1a3e3-5052-4d04-a7f9-ecac3b7c2f89,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-8d131e71-5a90-4b4e-ba6c-8ccef097b839,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-1ad324b2-7711-4423-bb10-09afe3b6be38,DISK], DatanodeInfoWithStorage[127.0.0.1:45737,DS-94beccce-7137-46b9-853b-7d7b320b59e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1408897357-172.17.0.14-1595519635068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46425,DS-085d47d7-8431-4d10-9d5e-2fe56a7a906d,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-25a272c3-0aa9-4ca5-8887-12bc67e7cbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-c78efd74-966d-4eda-acc3-c24d63038f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-fc5c01f8-c61a-477d-a44e-f447aa06e945,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-74b1a3e3-5052-4d04-a7f9-ecac3b7c2f89,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-8d131e71-5a90-4b4e-ba6c-8ccef097b839,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-1ad324b2-7711-4423-bb10-09afe3b6be38,DISK], DatanodeInfoWithStorage[127.0.0.1:45737,DS-94beccce-7137-46b9-853b-7d7b320b59e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-738891781-172.17.0.14-1595520107791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40014,DS-028003e4-419b-4395-87ce-1161bdf193ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-7ad3d693-8ed7-4899-8444-6dbdfa7dcdd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-0fd0b0e3-0f76-485b-a55c-5ef66a9b8fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-aaba5e6d-38dd-4564-a808-ebbf398f8629,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-47f8002f-ddbb-495e-832a-68cc77ca3548,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-206c828c-53ae-4483-918b-42ee6b252e41,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-0144ddbe-1ec7-4b26-820e-491162d5b42a,DISK], DatanodeInfoWithStorage[127.0.0.1:40106,DS-0f3d9bbd-965e-4140-aebf-ba19579a1c41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-738891781-172.17.0.14-1595520107791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40014,DS-028003e4-419b-4395-87ce-1161bdf193ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-7ad3d693-8ed7-4899-8444-6dbdfa7dcdd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-0fd0b0e3-0f76-485b-a55c-5ef66a9b8fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-aaba5e6d-38dd-4564-a808-ebbf398f8629,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-47f8002f-ddbb-495e-832a-68cc77ca3548,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-206c828c-53ae-4483-918b-42ee6b252e41,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-0144ddbe-1ec7-4b26-820e-491162d5b42a,DISK], DatanodeInfoWithStorage[127.0.0.1:40106,DS-0f3d9bbd-965e-4140-aebf-ba19579a1c41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1492403993-172.17.0.14-1595520283778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43410,DS-d3a03a70-5906-4050-9e2d-ed5015e7b480,DISK], DatanodeInfoWithStorage[127.0.0.1:44614,DS-7af7a044-3d11-4c94-a303-d16a4032dc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-92c8cab0-ee2c-4ce1-b9e3-b2f10a512a27,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-0ef0a198-5e05-44ce-955d-613da03d52d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-e6fb83d6-5f41-487c-8cba-6aa2bc27c4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-4b45d5fb-f31c-42be-bcb5-e20c64a0603b,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-f0f05669-3cbc-4eb9-a4d2-8f8e98028922,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-a3f64d23-3802-427d-929d-5763ad1fdf6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1492403993-172.17.0.14-1595520283778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43410,DS-d3a03a70-5906-4050-9e2d-ed5015e7b480,DISK], DatanodeInfoWithStorage[127.0.0.1:44614,DS-7af7a044-3d11-4c94-a303-d16a4032dc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-92c8cab0-ee2c-4ce1-b9e3-b2f10a512a27,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-0ef0a198-5e05-44ce-955d-613da03d52d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-e6fb83d6-5f41-487c-8cba-6aa2bc27c4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-4b45d5fb-f31c-42be-bcb5-e20c64a0603b,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-f0f05669-3cbc-4eb9-a4d2-8f8e98028922,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-a3f64d23-3802-427d-929d-5763ad1fdf6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1914142956-172.17.0.14-1595520422426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43106,DS-f5b9b403-804b-4f92-b221-59d7e2e6664d,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-5a6f0cb5-d737-4989-a76b-d5b92405e1af,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-711197d9-fa00-4e1c-adb4-7b230c681951,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-90181c24-93b8-4f1a-bd4c-7d2400d5fb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34894,DS-8bc76383-cbb6-4907-aca8-139c59afb8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45776,DS-0834929d-be83-49b2-ba15-3f73a861161e,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-050c11a0-f11d-4f0e-aaeb-cdb34f6fe06c,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-3c9a29a4-7663-44d3-b820-acd323fcdd4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1914142956-172.17.0.14-1595520422426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43106,DS-f5b9b403-804b-4f92-b221-59d7e2e6664d,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-5a6f0cb5-d737-4989-a76b-d5b92405e1af,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-711197d9-fa00-4e1c-adb4-7b230c681951,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-90181c24-93b8-4f1a-bd4c-7d2400d5fb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34894,DS-8bc76383-cbb6-4907-aca8-139c59afb8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45776,DS-0834929d-be83-49b2-ba15-3f73a861161e,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-050c11a0-f11d-4f0e-aaeb-cdb34f6fe06c,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-3c9a29a4-7663-44d3-b820-acd323fcdd4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1874248843-172.17.0.14-1595520496103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39724,DS-27b7f738-eb16-4136-b4e5-e9f92321e559,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-8ae79c1d-f395-4178-a23a-edcffd674e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-4095f066-8994-4c5d-8edc-2f2665f97867,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-184a7fe1-f8d8-40f6-9232-8a28c8511779,DISK], DatanodeInfoWithStorage[127.0.0.1:43379,DS-db6f6dc2-dbb1-4fde-a0b2-f68736b6b94f,DISK], DatanodeInfoWithStorage[127.0.0.1:35605,DS-42795e48-dc91-4375-937b-929c8680aff6,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-2cf10bdc-32d9-4818-bc20-a17815fa0e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-966361d8-0f5f-4b50-ad40-7c8795523459,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1874248843-172.17.0.14-1595520496103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39724,DS-27b7f738-eb16-4136-b4e5-e9f92321e559,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-8ae79c1d-f395-4178-a23a-edcffd674e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-4095f066-8994-4c5d-8edc-2f2665f97867,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-184a7fe1-f8d8-40f6-9232-8a28c8511779,DISK], DatanodeInfoWithStorage[127.0.0.1:43379,DS-db6f6dc2-dbb1-4fde-a0b2-f68736b6b94f,DISK], DatanodeInfoWithStorage[127.0.0.1:35605,DS-42795e48-dc91-4375-937b-929c8680aff6,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-2cf10bdc-32d9-4818-bc20-a17815fa0e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-966361d8-0f5f-4b50-ad40-7c8795523459,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5397
