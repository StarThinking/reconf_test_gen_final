reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-551526716-172.17.0.20-1595685106792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37308,DS-ad82d835-9f82-497e-be77-76ef3e8b77b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-1f7f3522-c5e0-475e-be18-d6f9b6f93a18,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-1a29565f-d23a-4738-bba7-3cb51e3de705,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-b63f48a7-bebb-4c06-aa45-bf37fd703dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-deaa5667-f9cc-4de5-9fd2-57c911661298,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-9c9bf426-e67f-4cc7-93bd-c7c34c993160,DISK], DatanodeInfoWithStorage[127.0.0.1:37842,DS-2216d75d-8505-40ac-b717-9beef1dfe553,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-d03c326b-2031-408d-ba04-7b6f57efecf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-551526716-172.17.0.20-1595685106792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37308,DS-ad82d835-9f82-497e-be77-76ef3e8b77b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-1f7f3522-c5e0-475e-be18-d6f9b6f93a18,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-1a29565f-d23a-4738-bba7-3cb51e3de705,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-b63f48a7-bebb-4c06-aa45-bf37fd703dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-deaa5667-f9cc-4de5-9fd2-57c911661298,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-9c9bf426-e67f-4cc7-93bd-c7c34c993160,DISK], DatanodeInfoWithStorage[127.0.0.1:37842,DS-2216d75d-8505-40ac-b717-9beef1dfe553,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-d03c326b-2031-408d-ba04-7b6f57efecf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-471526391-172.17.0.20-1595685408196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42390,DS-95c2f113-c783-4bff-aa4e-a7031ae52439,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-df74814c-1bb0-4622-87a6-f0cc3360849c,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-1f82ad67-5759-472d-a1c0-921e479b6dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-d50bb080-e0b9-48f4-9d34-2f6a6eed2cff,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-c06fe282-07cf-4272-b89b-48eec36da740,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-5ea6c96f-b04f-49f3-bad3-31d5d2deeb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-63b1528c-7d53-496c-b06a-b086c78f3506,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-807688ab-04f6-43e2-9899-8cf8fd933e69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-471526391-172.17.0.20-1595685408196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42390,DS-95c2f113-c783-4bff-aa4e-a7031ae52439,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-df74814c-1bb0-4622-87a6-f0cc3360849c,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-1f82ad67-5759-472d-a1c0-921e479b6dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-d50bb080-e0b9-48f4-9d34-2f6a6eed2cff,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-c06fe282-07cf-4272-b89b-48eec36da740,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-5ea6c96f-b04f-49f3-bad3-31d5d2deeb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-63b1528c-7d53-496c-b06a-b086c78f3506,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-807688ab-04f6-43e2-9899-8cf8fd933e69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950391225-172.17.0.20-1595686034946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46809,DS-fb8e0242-3451-44c9-80a7-9bec247f9cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:42716,DS-8c9a5c5e-595d-4768-b437-bbf42a5789f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-f51479fd-fca1-4bc6-9025-a1011c7ba20f,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-ac7097f2-5e02-45fc-a17b-a6f6280e0775,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-e131e197-8662-4f92-b1d0-9bb064c371e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-de4bf539-62a4-4cc0-930c-92f1fc6c9cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-817b44fa-887d-41c8-b2ef-2ec1c7bd306b,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-cadf04e7-b444-4ac1-945e-0ae211634175,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950391225-172.17.0.20-1595686034946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46809,DS-fb8e0242-3451-44c9-80a7-9bec247f9cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:42716,DS-8c9a5c5e-595d-4768-b437-bbf42a5789f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-f51479fd-fca1-4bc6-9025-a1011c7ba20f,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-ac7097f2-5e02-45fc-a17b-a6f6280e0775,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-e131e197-8662-4f92-b1d0-9bb064c371e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-de4bf539-62a4-4cc0-930c-92f1fc6c9cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-817b44fa-887d-41c8-b2ef-2ec1c7bd306b,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-cadf04e7-b444-4ac1-945e-0ae211634175,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-289400729-172.17.0.20-1595686397851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38487,DS-dcce0e7e-4646-4e86-b55a-821b5763a070,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-f79992ed-c850-442b-a271-de5831ec168d,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-26bb0f70-7780-4b09-820f-8d475a819501,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-68d7ef1d-5896-43c4-bbab-4a69ebd6baa7,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-5a325330-63a0-45f2-8f5f-2fbd41ccd92f,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-5f8cb73d-4d18-4b36-b256-e12a675b12b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-e6e91f0f-8222-4a15-b8ce-88532f6e0d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-701be07e-0523-4e65-bdd4-7b5576865c70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-289400729-172.17.0.20-1595686397851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38487,DS-dcce0e7e-4646-4e86-b55a-821b5763a070,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-f79992ed-c850-442b-a271-de5831ec168d,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-26bb0f70-7780-4b09-820f-8d475a819501,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-68d7ef1d-5896-43c4-bbab-4a69ebd6baa7,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-5a325330-63a0-45f2-8f5f-2fbd41ccd92f,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-5f8cb73d-4d18-4b36-b256-e12a675b12b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-e6e91f0f-8222-4a15-b8ce-88532f6e0d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-701be07e-0523-4e65-bdd4-7b5576865c70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-255088997-172.17.0.20-1595686719516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33960,DS-3b86b112-0389-4c5a-88f7-9f23d492601e,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-d5d7dad8-bb50-4de1-9ec3-c3edfd6037e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-3abd6849-a8bb-4161-961d-753395e6a03a,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-0225ca7f-7d18-47fe-b190-6ddf71f3c909,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-713c117f-4c07-4edf-8028-ed6d2c58105e,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-3968cd57-ef25-4b15-8cc9-d30f23fea2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-4aa37e34-2f09-4c21-9d29-95bf671804c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-b701049a-d4d9-488b-a38f-724fad562df6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-255088997-172.17.0.20-1595686719516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33960,DS-3b86b112-0389-4c5a-88f7-9f23d492601e,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-d5d7dad8-bb50-4de1-9ec3-c3edfd6037e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-3abd6849-a8bb-4161-961d-753395e6a03a,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-0225ca7f-7d18-47fe-b190-6ddf71f3c909,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-713c117f-4c07-4edf-8028-ed6d2c58105e,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-3968cd57-ef25-4b15-8cc9-d30f23fea2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-4aa37e34-2f09-4c21-9d29-95bf671804c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-b701049a-d4d9-488b-a38f-724fad562df6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1707350571-172.17.0.20-1595687652131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45637,DS-420a4dae-8353-47db-bd70-5cbaa97748eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-a906f60e-2084-425e-ab99-66b59f28431f,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-a322da26-344b-48a4-9016-1bf2b449376d,DISK], DatanodeInfoWithStorage[127.0.0.1:43551,DS-42ff347a-9f2c-4938-8079-fad56b5078df,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-539a4819-2cdd-42ab-b33d-f4fdd0a8a09e,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-981efda4-9432-47cf-badc-d6914b90dc66,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-46af7d36-1b31-4f04-a348-2dfd74f12ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-4ab78310-9668-4804-9f5c-cb1bf3aeb8bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1707350571-172.17.0.20-1595687652131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45637,DS-420a4dae-8353-47db-bd70-5cbaa97748eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-a906f60e-2084-425e-ab99-66b59f28431f,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-a322da26-344b-48a4-9016-1bf2b449376d,DISK], DatanodeInfoWithStorage[127.0.0.1:43551,DS-42ff347a-9f2c-4938-8079-fad56b5078df,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-539a4819-2cdd-42ab-b33d-f4fdd0a8a09e,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-981efda4-9432-47cf-badc-d6914b90dc66,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-46af7d36-1b31-4f04-a348-2dfd74f12ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-4ab78310-9668-4804-9f5c-cb1bf3aeb8bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1464044947-172.17.0.20-1595687867980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39043,DS-ea1fde92-2d7d-4fa1-b8e8-abc217ca9d62,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-3e275198-6edb-468a-bf08-8f4d22fcfc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-4686acaa-d84e-4517-966a-769a755fcd33,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-bbe9432c-d48a-47ce-a512-bead30f05ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-9ab04c2f-1b87-424b-93e6-d6bdd05d2a47,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-9904c0d5-2b19-4221-a328-43c6287ad689,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-a3abd260-d687-492c-b496-dc4cdc111ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-f55862e5-b2bf-4be6-a0f3-29144ec85cf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1464044947-172.17.0.20-1595687867980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39043,DS-ea1fde92-2d7d-4fa1-b8e8-abc217ca9d62,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-3e275198-6edb-468a-bf08-8f4d22fcfc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-4686acaa-d84e-4517-966a-769a755fcd33,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-bbe9432c-d48a-47ce-a512-bead30f05ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-9ab04c2f-1b87-424b-93e6-d6bdd05d2a47,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-9904c0d5-2b19-4221-a328-43c6287ad689,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-a3abd260-d687-492c-b496-dc4cdc111ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-f55862e5-b2bf-4be6-a0f3-29144ec85cf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-572896654-172.17.0.20-1595688060037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36861,DS-d6178414-5377-4ee6-a641-0e6f2ae7f907,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-86bd8aa3-b58b-4b6e-b529-638f5d4da602,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-99a536d5-4cc7-49e5-a687-a732987e115e,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-57bf9736-5a6b-4ab1-a0b8-ce2ab1bf6eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-fc278bf6-bbd4-4b7f-9825-63a1cc85cb00,DISK], DatanodeInfoWithStorage[127.0.0.1:36408,DS-d4efb9fd-4e3a-42d1-b6ae-fe2e620e95ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-f5bce83e-5123-4db8-8ee4-982a8fd32677,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-a8067c5f-f6e8-4ac3-9682-0f9d357e3faa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-572896654-172.17.0.20-1595688060037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36861,DS-d6178414-5377-4ee6-a641-0e6f2ae7f907,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-86bd8aa3-b58b-4b6e-b529-638f5d4da602,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-99a536d5-4cc7-49e5-a687-a732987e115e,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-57bf9736-5a6b-4ab1-a0b8-ce2ab1bf6eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-fc278bf6-bbd4-4b7f-9825-63a1cc85cb00,DISK], DatanodeInfoWithStorage[127.0.0.1:36408,DS-d4efb9fd-4e3a-42d1-b6ae-fe2e620e95ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-f5bce83e-5123-4db8-8ee4-982a8fd32677,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-a8067c5f-f6e8-4ac3-9682-0f9d357e3faa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1245441628-172.17.0.20-1595688275080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42373,DS-d002297f-5769-49ea-bc66-15a3748dbc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-f69fc565-0630-4bcb-a9ba-f87bd22bc503,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-e0d36091-b7b8-4d81-ba24-409c9302844e,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-40c819b7-4c2b-4799-89a9-cb0f7cf55e69,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-14599da2-f2e2-48ce-9a8e-6b3c695151e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33236,DS-97191c72-8f7a-485f-b9df-889bed006d80,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-299a7c86-71f4-4793-808f-6a0ef0776a89,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-11e625be-941f-40b3-8a19-1cf7a84ce76d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1245441628-172.17.0.20-1595688275080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42373,DS-d002297f-5769-49ea-bc66-15a3748dbc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-f69fc565-0630-4bcb-a9ba-f87bd22bc503,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-e0d36091-b7b8-4d81-ba24-409c9302844e,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-40c819b7-4c2b-4799-89a9-cb0f7cf55e69,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-14599da2-f2e2-48ce-9a8e-6b3c695151e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33236,DS-97191c72-8f7a-485f-b9df-889bed006d80,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-299a7c86-71f4-4793-808f-6a0ef0776a89,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-11e625be-941f-40b3-8a19-1cf7a84ce76d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-294854956-172.17.0.20-1595688616744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38686,DS-dd125d72-eb11-46b6-9fb5-712aa5553c61,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-5c369037-9f2a-422b-9cdc-b04eede4fc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35333,DS-4165a1aa-7467-4f61-95b8-b3821351a340,DISK], DatanodeInfoWithStorage[127.0.0.1:46358,DS-39d0bc54-bace-4636-ac29-3f77f056b0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-f19c3432-dea9-446a-bb48-c0af376f8669,DISK], DatanodeInfoWithStorage[127.0.0.1:34601,DS-8605aa49-71b1-48a9-a5b4-0220cf562875,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-5d771f7a-96cb-4a59-a94d-618f4bf1a7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-f1deeb8c-6839-40bf-b090-ab7cc73db0d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-294854956-172.17.0.20-1595688616744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38686,DS-dd125d72-eb11-46b6-9fb5-712aa5553c61,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-5c369037-9f2a-422b-9cdc-b04eede4fc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35333,DS-4165a1aa-7467-4f61-95b8-b3821351a340,DISK], DatanodeInfoWithStorage[127.0.0.1:46358,DS-39d0bc54-bace-4636-ac29-3f77f056b0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-f19c3432-dea9-446a-bb48-c0af376f8669,DISK], DatanodeInfoWithStorage[127.0.0.1:34601,DS-8605aa49-71b1-48a9-a5b4-0220cf562875,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-5d771f7a-96cb-4a59-a94d-618f4bf1a7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-f1deeb8c-6839-40bf-b090-ab7cc73db0d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1970032246-172.17.0.20-1595688861459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39196,DS-89062f58-381a-401c-a4d7-203370573beb,DISK], DatanodeInfoWithStorage[127.0.0.1:37444,DS-0dadd0f2-85ab-43a3-811d-a12cb5def5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-69f01773-9cb8-4ea3-a38d-2a5e159e8499,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-3a668fcf-95cb-43c8-8ceb-6f9350a0ac1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-77c4bf75-9f5e-41e5-96c7-0d8538e2acc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-7a0edef3-43c3-47c1-aafa-939cf585e912,DISK], DatanodeInfoWithStorage[127.0.0.1:33041,DS-987d95e4-0582-44bd-aac8-100d0d63598a,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-adf73972-f59b-477a-97b0-9a5ed9e6139f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1970032246-172.17.0.20-1595688861459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39196,DS-89062f58-381a-401c-a4d7-203370573beb,DISK], DatanodeInfoWithStorage[127.0.0.1:37444,DS-0dadd0f2-85ab-43a3-811d-a12cb5def5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-69f01773-9cb8-4ea3-a38d-2a5e159e8499,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-3a668fcf-95cb-43c8-8ceb-6f9350a0ac1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-77c4bf75-9f5e-41e5-96c7-0d8538e2acc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-7a0edef3-43c3-47c1-aafa-939cf585e912,DISK], DatanodeInfoWithStorage[127.0.0.1:33041,DS-987d95e4-0582-44bd-aac8-100d0d63598a,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-adf73972-f59b-477a-97b0-9a5ed9e6139f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1659940019-172.17.0.20-1595689320992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39086,DS-6b1e5e4d-f797-4839-aa27-25ffc6bda4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37466,DS-30b7edf2-32da-4d18-b027-2a15a38bd8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41244,DS-74ac1bcc-7fbd-4bf2-9d9e-b92220f37498,DISK], DatanodeInfoWithStorage[127.0.0.1:36996,DS-f7752b7c-1e38-4daf-9309-b7997bf0cfe2,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-a1277839-0b13-444b-bd83-d763924c7c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-9ae723a0-7e6b-46a4-86c6-47a78930e32b,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-ddb23463-4c4a-400f-8100-852919db41f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-757fcd4d-f975-4778-81aa-06d3271a65b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1659940019-172.17.0.20-1595689320992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39086,DS-6b1e5e4d-f797-4839-aa27-25ffc6bda4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37466,DS-30b7edf2-32da-4d18-b027-2a15a38bd8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41244,DS-74ac1bcc-7fbd-4bf2-9d9e-b92220f37498,DISK], DatanodeInfoWithStorage[127.0.0.1:36996,DS-f7752b7c-1e38-4daf-9309-b7997bf0cfe2,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-a1277839-0b13-444b-bd83-d763924c7c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-9ae723a0-7e6b-46a4-86c6-47a78930e32b,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-ddb23463-4c4a-400f-8100-852919db41f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-757fcd4d-f975-4778-81aa-06d3271a65b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1221531235-172.17.0.20-1595689394105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37061,DS-d9855d78-944b-4a64-9799-8433c1beaa20,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-b52eec08-57aa-4a38-b40d-afedb5381d76,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-6b2ce5eb-3d63-4393-97da-08c5266e9f10,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-8e7b2350-130d-493d-aabd-d32ddbe08a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-aa4d433c-0bf9-4477-be36-e8a4aa9ecc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-c6211a44-fd07-4834-9865-b02b30bf528f,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-184e1f52-afc0-42c6-890a-58f022bc470c,DISK], DatanodeInfoWithStorage[127.0.0.1:34273,DS-8b809d18-4ab9-48e6-b3d2-4f79f6fcdb76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1221531235-172.17.0.20-1595689394105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37061,DS-d9855d78-944b-4a64-9799-8433c1beaa20,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-b52eec08-57aa-4a38-b40d-afedb5381d76,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-6b2ce5eb-3d63-4393-97da-08c5266e9f10,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-8e7b2350-130d-493d-aabd-d32ddbe08a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-aa4d433c-0bf9-4477-be36-e8a4aa9ecc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-c6211a44-fd07-4834-9865-b02b30bf528f,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-184e1f52-afc0-42c6-890a-58f022bc470c,DISK], DatanodeInfoWithStorage[127.0.0.1:34273,DS-8b809d18-4ab9-48e6-b3d2-4f79f6fcdb76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5426
