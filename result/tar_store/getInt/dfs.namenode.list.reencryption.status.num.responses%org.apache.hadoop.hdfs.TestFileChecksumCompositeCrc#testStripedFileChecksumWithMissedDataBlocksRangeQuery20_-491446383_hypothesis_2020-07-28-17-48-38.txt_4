reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-434890648-172.17.0.13-1595958533652:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36979,DS-b75882b7-f2eb-4064-83c4-910fd94004dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-6688f879-2df5-4dd9-ad84-308f30a6b5db,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-1986d7a6-b52e-4487-acab-cdc93eec8bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-1381b5ad-a6df-4ecd-9304-24c461ab5199,DISK], DatanodeInfoWithStorage[127.0.0.1:39258,DS-02b44555-97c3-4c31-9091-babfd2a3cca7,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-8690cd89-2d48-47df-868b-0f7d3ef00ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-dd3e9be7-4e18-433d-86a0-2e12365245e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-bb116be2-620e-40cf-8bd1-6d1b2aa940d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-434890648-172.17.0.13-1595958533652:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36979,DS-b75882b7-f2eb-4064-83c4-910fd94004dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-6688f879-2df5-4dd9-ad84-308f30a6b5db,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-1986d7a6-b52e-4487-acab-cdc93eec8bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-1381b5ad-a6df-4ecd-9304-24c461ab5199,DISK], DatanodeInfoWithStorage[127.0.0.1:39258,DS-02b44555-97c3-4c31-9091-babfd2a3cca7,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-8690cd89-2d48-47df-868b-0f7d3ef00ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-dd3e9be7-4e18-433d-86a0-2e12365245e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-bb116be2-620e-40cf-8bd1-6d1b2aa940d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1068323897-172.17.0.13-1595959067285:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41664,DS-71f5223f-fb96-4b61-be71-eeffbc041f37,DISK], DatanodeInfoWithStorage[127.0.0.1:44590,DS-a8e4ea5b-c922-4b62-ac57-d2952fd92113,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-9da373f2-a521-4aa7-9489-5fe75c301eab,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-210976db-ffde-4989-94d5-16c021c5c285,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-9b62ad91-b996-42f7-9162-5ae4f2216e08,DISK], DatanodeInfoWithStorage[127.0.0.1:37377,DS-8003f7c7-2aa0-4955-b68f-5d83cbc83b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-b1002ccd-1a05-4905-9511-f17f789c82f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-d5fd015d-2fb7-4a18-bb5b-83b468fc6f71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1068323897-172.17.0.13-1595959067285:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41664,DS-71f5223f-fb96-4b61-be71-eeffbc041f37,DISK], DatanodeInfoWithStorage[127.0.0.1:44590,DS-a8e4ea5b-c922-4b62-ac57-d2952fd92113,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-9da373f2-a521-4aa7-9489-5fe75c301eab,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-210976db-ffde-4989-94d5-16c021c5c285,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-9b62ad91-b996-42f7-9162-5ae4f2216e08,DISK], DatanodeInfoWithStorage[127.0.0.1:37377,DS-8003f7c7-2aa0-4955-b68f-5d83cbc83b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-b1002ccd-1a05-4905-9511-f17f789c82f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-d5fd015d-2fb7-4a18-bb5b-83b468fc6f71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-308107197-172.17.0.13-1595959135647:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35845,DS-292adc3b-c921-40d7-9c94-41e90ec2a3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-887e72c8-1aea-4ac0-9e2a-459c50b5dcc2,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-52384243-ea4a-44b6-bcaf-5029b50356bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-cca87023-b945-4653-854e-3df96e45c6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-d93ff43f-0a42-4501-b724-28072b89ef75,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-6ccebfa6-dcb5-4f5b-8ca8-be5e553bb924,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-0d420e5f-f409-4fc2-a9fc-0064f8cd6cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-8850ce64-a1d6-4208-9659-287f0875bf62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-308107197-172.17.0.13-1595959135647:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35845,DS-292adc3b-c921-40d7-9c94-41e90ec2a3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-887e72c8-1aea-4ac0-9e2a-459c50b5dcc2,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-52384243-ea4a-44b6-bcaf-5029b50356bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-cca87023-b945-4653-854e-3df96e45c6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-d93ff43f-0a42-4501-b724-28072b89ef75,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-6ccebfa6-dcb5-4f5b-8ca8-be5e553bb924,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-0d420e5f-f409-4fc2-a9fc-0064f8cd6cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-8850ce64-a1d6-4208-9659-287f0875bf62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1786296237-172.17.0.13-1595959170253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46524,DS-e6aa7d93-f9c4-47fc-bbaa-f60b7601d481,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-2d7030df-75e9-4845-817a-06b2a8865a43,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-700a2ebb-81aa-4d11-80e5-6febdba5dc65,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-88e4cebe-010d-432a-84a1-a9c060ebd25a,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-5bf158d2-1195-4506-ba58-cdc7d9f166f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-8953d886-6b38-4663-8115-a718c55a2c47,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-66f0c26a-5ae1-42b6-bfb2-0316709070aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-d651e261-855f-4928-ac38-73e254cf62a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1786296237-172.17.0.13-1595959170253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46524,DS-e6aa7d93-f9c4-47fc-bbaa-f60b7601d481,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-2d7030df-75e9-4845-817a-06b2a8865a43,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-700a2ebb-81aa-4d11-80e5-6febdba5dc65,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-88e4cebe-010d-432a-84a1-a9c060ebd25a,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-5bf158d2-1195-4506-ba58-cdc7d9f166f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-8953d886-6b38-4663-8115-a718c55a2c47,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-66f0c26a-5ae1-42b6-bfb2-0316709070aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-d651e261-855f-4928-ac38-73e254cf62a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-516876230-172.17.0.13-1595959900112:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46636,DS-c7ac2659-ec85-4b3b-be92-46c11cc173c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-ac341653-1e54-43b1-9fe1-795d0c69a403,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-9247d097-8490-4152-88cc-df330cc3e9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36925,DS-1667de51-73f6-4344-8772-7ec0ac85f528,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-e356aff0-35b9-4024-b1f5-ccd597a4af3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-c85d43dd-4313-4a02-8566-4cf95e101c56,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-56cd7118-0756-4d1a-b243-217104035519,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-eabf48d7-9ab0-452e-b383-66de35a309e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-516876230-172.17.0.13-1595959900112:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46636,DS-c7ac2659-ec85-4b3b-be92-46c11cc173c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-ac341653-1e54-43b1-9fe1-795d0c69a403,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-9247d097-8490-4152-88cc-df330cc3e9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36925,DS-1667de51-73f6-4344-8772-7ec0ac85f528,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-e356aff0-35b9-4024-b1f5-ccd597a4af3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-c85d43dd-4313-4a02-8566-4cf95e101c56,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-56cd7118-0756-4d1a-b243-217104035519,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-eabf48d7-9ab0-452e-b383-66de35a309e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-49687911-172.17.0.13-1595959938264:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38793,DS-ed9d9fc7-49b5-4c90-a480-86014b554e79,DISK], DatanodeInfoWithStorage[127.0.0.1:42427,DS-74598801-16a1-49d0-a0e4-9a00068c3a33,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-4643dacf-4dfd-4532-8373-9eb36c51b65d,DISK], DatanodeInfoWithStorage[127.0.0.1:33092,DS-a3111495-87e5-461d-bc7e-9918532b455b,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-d38fe9e6-980e-4892-aab8-ff6da6618c25,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-05c150c3-c492-46d5-b499-15ce96091b12,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-601d68e2-7fd7-4d77-a298-2e6be23c1582,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-9fffd96d-d115-479d-b063-37755598efee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-49687911-172.17.0.13-1595959938264:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38793,DS-ed9d9fc7-49b5-4c90-a480-86014b554e79,DISK], DatanodeInfoWithStorage[127.0.0.1:42427,DS-74598801-16a1-49d0-a0e4-9a00068c3a33,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-4643dacf-4dfd-4532-8373-9eb36c51b65d,DISK], DatanodeInfoWithStorage[127.0.0.1:33092,DS-a3111495-87e5-461d-bc7e-9918532b455b,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-d38fe9e6-980e-4892-aab8-ff6da6618c25,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-05c150c3-c492-46d5-b499-15ce96091b12,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-601d68e2-7fd7-4d77-a298-2e6be23c1582,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-9fffd96d-d115-479d-b063-37755598efee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-841010956-172.17.0.13-1595960007840:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40425,DS-50555309-9b07-405e-840a-1b04633361c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36565,DS-5a4f36a2-42f1-45df-ae90-664be5d14663,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-b03df7e0-31d8-4a30-80a9-cd7f0a2f0024,DISK], DatanodeInfoWithStorage[127.0.0.1:34948,DS-30ab2130-484f-425d-9d1b-aea5543d2c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34568,DS-c8c5076a-1e2a-458e-afba-85eb0acaf860,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-7cf30fcd-d653-487d-a416-66dfa4f20c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-9bb0c3ab-28e7-4d72-a660-81277d2941a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-f6be6c71-ae21-4266-8cdc-66f6b5e2c2dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-841010956-172.17.0.13-1595960007840:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40425,DS-50555309-9b07-405e-840a-1b04633361c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36565,DS-5a4f36a2-42f1-45df-ae90-664be5d14663,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-b03df7e0-31d8-4a30-80a9-cd7f0a2f0024,DISK], DatanodeInfoWithStorage[127.0.0.1:34948,DS-30ab2130-484f-425d-9d1b-aea5543d2c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34568,DS-c8c5076a-1e2a-458e-afba-85eb0acaf860,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-7cf30fcd-d653-487d-a416-66dfa4f20c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-9bb0c3ab-28e7-4d72-a660-81277d2941a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-f6be6c71-ae21-4266-8cdc-66f6b5e2c2dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1363447292-172.17.0.13-1595960507490:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38262,DS-d62b2b99-a2ba-4e90-bb20-3e22681c0322,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-fcf66624-af98-4990-a0b5-9b4c69510ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-0bedcfb2-edb1-46c9-a2d7-c6048260e355,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-965d04ce-fe69-450f-8a89-18d5ce1e7585,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-c3847323-7bfa-4950-9ced-23d12eaa1d07,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-9f616200-821d-4b77-864d-2dfe254ea56a,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-1aa390a7-7a24-4c4f-ba79-1ddd75a1353b,DISK], DatanodeInfoWithStorage[127.0.0.1:46022,DS-e30f82d1-bc64-4889-b237-d4e3d4ce9fbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1363447292-172.17.0.13-1595960507490:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38262,DS-d62b2b99-a2ba-4e90-bb20-3e22681c0322,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-fcf66624-af98-4990-a0b5-9b4c69510ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-0bedcfb2-edb1-46c9-a2d7-c6048260e355,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-965d04ce-fe69-450f-8a89-18d5ce1e7585,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-c3847323-7bfa-4950-9ced-23d12eaa1d07,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-9f616200-821d-4b77-864d-2dfe254ea56a,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-1aa390a7-7a24-4c4f-ba79-1ddd75a1353b,DISK], DatanodeInfoWithStorage[127.0.0.1:46022,DS-e30f82d1-bc64-4889-b237-d4e3d4ce9fbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-544531637-172.17.0.13-1595960737866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41781,DS-426a4eeb-de5d-4331-ba3f-d50e16000a92,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-a2b25019-8661-4e74-a1bf-02af0ee95610,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-d2644a35-cfeb-4169-becf-235f982da19d,DISK], DatanodeInfoWithStorage[127.0.0.1:34731,DS-486143ec-b2e1-42e5-a262-ce6173f01558,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-08115bd2-2675-4081-a7f3-2526e85f479a,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-1e88ecf6-b743-48df-a522-a77c46d376f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-c1a5c91b-9999-4464-8192-e14a366b3258,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-cdc0d789-6920-46f6-8b2f-2437b9a11902,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-544531637-172.17.0.13-1595960737866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41781,DS-426a4eeb-de5d-4331-ba3f-d50e16000a92,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-a2b25019-8661-4e74-a1bf-02af0ee95610,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-d2644a35-cfeb-4169-becf-235f982da19d,DISK], DatanodeInfoWithStorage[127.0.0.1:34731,DS-486143ec-b2e1-42e5-a262-ce6173f01558,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-08115bd2-2675-4081-a7f3-2526e85f479a,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-1e88ecf6-b743-48df-a522-a77c46d376f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-c1a5c91b-9999-4464-8192-e14a366b3258,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-cdc0d789-6920-46f6-8b2f-2437b9a11902,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-549475541-172.17.0.13-1595961080696:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40517,DS-78457c5b-a667-44ed-9107-62846962f29f,DISK], DatanodeInfoWithStorage[127.0.0.1:34946,DS-8f35bae3-0ee8-4887-905a-d39d137a0e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-6207ad78-fcd6-43d8-8984-6a54a337fb34,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-e7aaf67d-177c-407d-9b09-e25c62e6041a,DISK], DatanodeInfoWithStorage[127.0.0.1:43801,DS-a64be9b6-491f-483f-9fdf-b200766640df,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-822f9967-3215-4cf7-a611-9a74a5fe3665,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-fb94875e-0db5-413a-b32c-df4d7c78cc20,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-f00cd741-dba0-4917-b6d8-42e2882ef070,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-549475541-172.17.0.13-1595961080696:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40517,DS-78457c5b-a667-44ed-9107-62846962f29f,DISK], DatanodeInfoWithStorage[127.0.0.1:34946,DS-8f35bae3-0ee8-4887-905a-d39d137a0e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-6207ad78-fcd6-43d8-8984-6a54a337fb34,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-e7aaf67d-177c-407d-9b09-e25c62e6041a,DISK], DatanodeInfoWithStorage[127.0.0.1:43801,DS-a64be9b6-491f-483f-9fdf-b200766640df,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-822f9967-3215-4cf7-a611-9a74a5fe3665,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-fb94875e-0db5-413a-b32c-df4d7c78cc20,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-f00cd741-dba0-4917-b6d8-42e2882ef070,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-952822132-172.17.0.13-1595961117447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42188,DS-52023652-1d41-45b2-9f81-8ad91a301d98,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-a48f179a-a2fe-46c3-9816-612880553e74,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-df7535ed-1cc3-49b1-91e2-745199851925,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-858aa118-ed02-41a7-8b69-b11b9337d3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-e4f8e65c-76cf-4266-9b92-0d339883a560,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-ecb1b205-20b4-4646-8408-96464594f960,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-a6d435de-7dae-40e7-8def-b169538f7daf,DISK], DatanodeInfoWithStorage[127.0.0.1:37325,DS-04977a2c-31d1-4a21-9278-aedd3ccb332a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-952822132-172.17.0.13-1595961117447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42188,DS-52023652-1d41-45b2-9f81-8ad91a301d98,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-a48f179a-a2fe-46c3-9816-612880553e74,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-df7535ed-1cc3-49b1-91e2-745199851925,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-858aa118-ed02-41a7-8b69-b11b9337d3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-e4f8e65c-76cf-4266-9b92-0d339883a560,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-ecb1b205-20b4-4646-8408-96464594f960,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-a6d435de-7dae-40e7-8def-b169538f7daf,DISK], DatanodeInfoWithStorage[127.0.0.1:37325,DS-04977a2c-31d1-4a21-9278-aedd3ccb332a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1715324881-172.17.0.13-1595961233860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36630,DS-6375d14b-4ff3-422f-9a8b-ed017934a8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-5e35951a-31f3-44b5-a502-966e423b4507,DISK], DatanodeInfoWithStorage[127.0.0.1:41130,DS-2aac2566-05fd-47f2-91cf-9059624825e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-b0ac53c6-9144-4f9b-b290-8bfc63dd221c,DISK], DatanodeInfoWithStorage[127.0.0.1:37051,DS-17679ed9-4a2b-4683-8ff8-f2789ed7ff12,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-c44c17c0-6d41-4291-b770-2a96ec517221,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-81478abe-016b-469c-9f7c-24f25862784c,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-56328402-5f53-4a0e-a9f8-362faddae7d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1715324881-172.17.0.13-1595961233860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36630,DS-6375d14b-4ff3-422f-9a8b-ed017934a8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-5e35951a-31f3-44b5-a502-966e423b4507,DISK], DatanodeInfoWithStorage[127.0.0.1:41130,DS-2aac2566-05fd-47f2-91cf-9059624825e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-b0ac53c6-9144-4f9b-b290-8bfc63dd221c,DISK], DatanodeInfoWithStorage[127.0.0.1:37051,DS-17679ed9-4a2b-4683-8ff8-f2789ed7ff12,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-c44c17c0-6d41-4291-b770-2a96ec517221,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-81478abe-016b-469c-9f7c-24f25862784c,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-56328402-5f53-4a0e-a9f8-362faddae7d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-409051890-172.17.0.13-1595961487006:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34365,DS-81686e67-2503-4551-87fd-1bbabc45fe2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-60c155c0-850a-4f26-8499-c0f038e9ae4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-7f7d984f-12b6-4663-a224-9d7673953f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39357,DS-c917d1f2-da8f-4d79-9bb2-c1008cc74cea,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-23bae315-f691-4b4b-a7d1-68d5a859e14e,DISK], DatanodeInfoWithStorage[127.0.0.1:44131,DS-051ff261-6eca-43fe-8686-21093fa24817,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-b0375ded-c4b5-472b-97d4-569565ff1387,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-1e70c9b1-7065-4d1a-a537-708386c48286,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-409051890-172.17.0.13-1595961487006:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34365,DS-81686e67-2503-4551-87fd-1bbabc45fe2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-60c155c0-850a-4f26-8499-c0f038e9ae4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-7f7d984f-12b6-4663-a224-9d7673953f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39357,DS-c917d1f2-da8f-4d79-9bb2-c1008cc74cea,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-23bae315-f691-4b4b-a7d1-68d5a859e14e,DISK], DatanodeInfoWithStorage[127.0.0.1:44131,DS-051ff261-6eca-43fe-8686-21093fa24817,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-b0375ded-c4b5-472b-97d4-569565ff1387,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-1e70c9b1-7065-4d1a-a537-708386c48286,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-216390052-172.17.0.13-1595962367867:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32925,DS-0c7790a4-5880-4c5a-935d-570ab3d9f7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-62863d1e-1362-49e0-bcf4-020602c15964,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-0d594f04-d730-41df-890f-86647594f899,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-575b039d-1cc8-4150-84b3-5fc53360e208,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-4a1b6194-f745-4ef5-8212-c6b8496bb6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-5fda6001-e28a-4d4f-a34a-ad79b90c4fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:33046,DS-80b9e839-1a5c-478d-9cca-7c55f720f8f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-4e6cf6ac-a495-4ee7-92f3-26fe321d6bd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-216390052-172.17.0.13-1595962367867:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32925,DS-0c7790a4-5880-4c5a-935d-570ab3d9f7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-62863d1e-1362-49e0-bcf4-020602c15964,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-0d594f04-d730-41df-890f-86647594f899,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-575b039d-1cc8-4150-84b3-5fc53360e208,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-4a1b6194-f745-4ef5-8212-c6b8496bb6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-5fda6001-e28a-4d4f-a34a-ad79b90c4fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:33046,DS-80b9e839-1a5c-478d-9cca-7c55f720f8f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-4e6cf6ac-a495-4ee7-92f3-26fe321d6bd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-900682702-172.17.0.13-1595962557541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41198,DS-ab28df08-bceb-4f58-94e9-b650097132d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-cc9c8aad-3c7f-4971-944b-ddcd72c5eecf,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-81036ca6-9cc6-4c08-909b-760a11d13509,DISK], DatanodeInfoWithStorage[127.0.0.1:42950,DS-c29d39fd-16cf-4d88-a04e-447a3cd9d875,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-8cdc7843-84b8-48d8-aec9-7faab1d11c63,DISK], DatanodeInfoWithStorage[127.0.0.1:39019,DS-652efa0a-4863-4cab-be39-38e7aab188c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-eec5af8a-41da-4ea4-b0bf-0048394a650c,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-a98dd88c-9e08-42c7-96e7-f4dc1919f178,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-900682702-172.17.0.13-1595962557541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41198,DS-ab28df08-bceb-4f58-94e9-b650097132d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-cc9c8aad-3c7f-4971-944b-ddcd72c5eecf,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-81036ca6-9cc6-4c08-909b-760a11d13509,DISK], DatanodeInfoWithStorage[127.0.0.1:42950,DS-c29d39fd-16cf-4d88-a04e-447a3cd9d875,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-8cdc7843-84b8-48d8-aec9-7faab1d11c63,DISK], DatanodeInfoWithStorage[127.0.0.1:39019,DS-652efa0a-4863-4cab-be39-38e7aab188c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-eec5af8a-41da-4ea4-b0bf-0048394a650c,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-a98dd88c-9e08-42c7-96e7-f4dc1919f178,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-245064078-172.17.0.13-1595962843927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33072,DS-e417221d-be2b-433a-8578-e8aa7fab7b31,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-da4b90b3-ea39-4d36-b66c-101551be91c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-9250ad87-5d0f-4839-ad55-d896fe69369f,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-98be00c4-aca2-4a20-93d8-e36ca3337d70,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-c062be18-65f9-40d5-a3e6-4093efd122de,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-d0dde02a-72c5-4766-98f2-5448f6b56891,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-20cb8204-06b8-444b-b9f4-8e22af18b6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-71a7eb45-5387-4700-8477-33b9f3e7023c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-245064078-172.17.0.13-1595962843927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33072,DS-e417221d-be2b-433a-8578-e8aa7fab7b31,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-da4b90b3-ea39-4d36-b66c-101551be91c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-9250ad87-5d0f-4839-ad55-d896fe69369f,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-98be00c4-aca2-4a20-93d8-e36ca3337d70,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-c062be18-65f9-40d5-a3e6-4093efd122de,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-d0dde02a-72c5-4766-98f2-5448f6b56891,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-20cb8204-06b8-444b-b9f4-8e22af18b6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-71a7eb45-5387-4700-8477-33b9f3e7023c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2009509950-172.17.0.13-1595963562462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40484,DS-8faa0f49-3818-4a7c-96e2-4cc7e95642b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-e6506f42-cea0-47ff-b9d5-d0be962d1c15,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-094c9a6c-87cc-4e2e-ade3-efeff6609839,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-fa7fd114-b023-4560-a263-47377832d1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-863e7389-46e5-4cf0-8fa4-396ecf8aedfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-2d0a4302-febc-4d4a-a2af-d964bd181566,DISK], DatanodeInfoWithStorage[127.0.0.1:34836,DS-5d9a8409-f321-4ae1-b296-4ef132155523,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-c80684f2-65e7-43ce-a49d-73baa8b7c073,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2009509950-172.17.0.13-1595963562462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40484,DS-8faa0f49-3818-4a7c-96e2-4cc7e95642b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-e6506f42-cea0-47ff-b9d5-d0be962d1c15,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-094c9a6c-87cc-4e2e-ade3-efeff6609839,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-fa7fd114-b023-4560-a263-47377832d1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-863e7389-46e5-4cf0-8fa4-396ecf8aedfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-2d0a4302-febc-4d4a-a2af-d964bd181566,DISK], DatanodeInfoWithStorage[127.0.0.1:34836,DS-5d9a8409-f321-4ae1-b296-4ef132155523,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-c80684f2-65e7-43ce-a49d-73baa8b7c073,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1821568999-172.17.0.13-1595963598229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40566,DS-0e813eef-26e7-45e5-9eca-4f1a5887cc91,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-a27efb6a-feb2-4c49-8f4f-4f522906fc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-c8d5d17d-43e6-4435-ba89-b5bfe06de37d,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-855f725b-8747-4b54-b906-e5cdffc7f9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-2069013e-7a99-4239-a56c-17f45093ff94,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-28451a69-9923-4607-a6ab-16bb2d682dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36083,DS-5aceaa74-1dc7-4f51-8b9e-63d71634edf3,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-6912e9d9-4dce-41d1-b6ac-0ff39180f8f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1821568999-172.17.0.13-1595963598229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40566,DS-0e813eef-26e7-45e5-9eca-4f1a5887cc91,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-a27efb6a-feb2-4c49-8f4f-4f522906fc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-c8d5d17d-43e6-4435-ba89-b5bfe06de37d,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-855f725b-8747-4b54-b906-e5cdffc7f9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-2069013e-7a99-4239-a56c-17f45093ff94,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-28451a69-9923-4607-a6ab-16bb2d682dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36083,DS-5aceaa74-1dc7-4f51-8b9e-63d71634edf3,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-6912e9d9-4dce-41d1-b6ac-0ff39180f8f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1188589975-172.17.0.13-1595963778949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35541,DS-b958a869-0e6f-4534-b7de-836bcd7bba1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-130e5cdf-3ae0-47a3-8af5-d6487caea398,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-07936c9b-859a-4a0b-b9f2-c3f1636a25ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-410a6c7c-653b-4d9f-9dcd-022e72504458,DISK], DatanodeInfoWithStorage[127.0.0.1:32773,DS-67ab1337-a4bf-4c06-b54c-2b8e6fdea17d,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-aef96d5b-7ee7-4de8-be75-5e5087e6b9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-241d2a7c-f613-48d1-bf61-65958be98237,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-21c14a0e-8a8f-4118-ad3d-d125e99a2432,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1188589975-172.17.0.13-1595963778949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35541,DS-b958a869-0e6f-4534-b7de-836bcd7bba1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-130e5cdf-3ae0-47a3-8af5-d6487caea398,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-07936c9b-859a-4a0b-b9f2-c3f1636a25ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-410a6c7c-653b-4d9f-9dcd-022e72504458,DISK], DatanodeInfoWithStorage[127.0.0.1:32773,DS-67ab1337-a4bf-4c06-b54c-2b8e6fdea17d,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-aef96d5b-7ee7-4de8-be75-5e5087e6b9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-241d2a7c-f613-48d1-bf61-65958be98237,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-21c14a0e-8a8f-4118-ad3d-d125e99a2432,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: might be true error
Total execution time in seconds : 5477
