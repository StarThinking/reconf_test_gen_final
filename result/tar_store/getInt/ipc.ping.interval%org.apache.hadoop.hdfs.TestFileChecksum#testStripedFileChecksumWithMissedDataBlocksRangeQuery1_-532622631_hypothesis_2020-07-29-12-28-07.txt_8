reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1641936383-172.17.0.18-1596026025906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33140,DS-ce3e44d6-737e-4789-a1c6-ea40315ca833,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-a70afd9a-3d39-4b27-8f9a-96c6a487cce1,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-5ea2ee84-fcb5-40ce-a0be-e6f6e555a4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-442573dd-2c69-44c6-9568-782449d36843,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-f63a8c90-17d4-4328-a04c-bfd0d85b087f,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-2b332873-c61f-4894-ad69-588c760c05a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-d68addd9-8874-4faf-a177-7e7e60616449,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-f01e9e0a-6057-4741-8f7d-83eb12b46c03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1641936383-172.17.0.18-1596026025906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33140,DS-ce3e44d6-737e-4789-a1c6-ea40315ca833,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-a70afd9a-3d39-4b27-8f9a-96c6a487cce1,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-5ea2ee84-fcb5-40ce-a0be-e6f6e555a4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-442573dd-2c69-44c6-9568-782449d36843,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-f63a8c90-17d4-4328-a04c-bfd0d85b087f,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-2b332873-c61f-4894-ad69-588c760c05a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-d68addd9-8874-4faf-a177-7e7e60616449,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-f01e9e0a-6057-4741-8f7d-83eb12b46c03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-738429042-172.17.0.18-1596026104643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44964,DS-5b5b9110-6f58-4974-b320-b6d7601563ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-caab857b-47dc-4009-87f2-a71d9b709b50,DISK], DatanodeInfoWithStorage[127.0.0.1:40025,DS-5662a6cc-ca05-4e90-aa40-935ced3874fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-9e6a1f92-8c54-4b54-b5b3-8f7283e0a51d,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-d3a28e3d-1568-4205-b8bc-33bda741942c,DISK], DatanodeInfoWithStorage[127.0.0.1:38200,DS-23ba6bb4-7b54-4443-859f-508cf5e9063b,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-1d89fa53-b81c-454a-a537-69a8e5f6c1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-e258d0c3-af41-4050-bc42-054399037c25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-738429042-172.17.0.18-1596026104643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44964,DS-5b5b9110-6f58-4974-b320-b6d7601563ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-caab857b-47dc-4009-87f2-a71d9b709b50,DISK], DatanodeInfoWithStorage[127.0.0.1:40025,DS-5662a6cc-ca05-4e90-aa40-935ced3874fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-9e6a1f92-8c54-4b54-b5b3-8f7283e0a51d,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-d3a28e3d-1568-4205-b8bc-33bda741942c,DISK], DatanodeInfoWithStorage[127.0.0.1:38200,DS-23ba6bb4-7b54-4443-859f-508cf5e9063b,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-1d89fa53-b81c-454a-a537-69a8e5f6c1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-e258d0c3-af41-4050-bc42-054399037c25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1199120119-172.17.0.18-1596026151635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32837,DS-9bb30ec8-7cf0-45d6-9f22-69d2d6b667ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36241,DS-2c4f9212-2321-45c9-bd4e-f546f1753a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-4da14b4b-6581-4ed9-95ae-1a299d0cef4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-d0419a00-4124-41ac-920f-b9260b2faff9,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-c1ae35c7-b725-4ffe-aef7-d2f8a1f10790,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-a4ec1870-dc62-4a38-917c-11cb9e5254cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42568,DS-9bb87472-cd54-4174-be33-ffc664032d22,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-d27a8cd9-f0c0-4f82-ba3b-715c43eb4301,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1199120119-172.17.0.18-1596026151635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32837,DS-9bb30ec8-7cf0-45d6-9f22-69d2d6b667ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36241,DS-2c4f9212-2321-45c9-bd4e-f546f1753a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-4da14b4b-6581-4ed9-95ae-1a299d0cef4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-d0419a00-4124-41ac-920f-b9260b2faff9,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-c1ae35c7-b725-4ffe-aef7-d2f8a1f10790,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-a4ec1870-dc62-4a38-917c-11cb9e5254cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42568,DS-9bb87472-cd54-4174-be33-ffc664032d22,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-d27a8cd9-f0c0-4f82-ba3b-715c43eb4301,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-420013688-172.17.0.18-1596026469157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45417,DS-b15e9fae-f884-46c3-8974-511365ac4b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-f60279af-8c0f-4b6a-a14b-a2da28b10a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33291,DS-f9435536-d72b-4bf0-b32f-2e3f5eed0682,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-6a93ddf5-9d41-495a-813b-01c155e5a761,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-7f05ef86-2b1e-4e7f-998a-3916c42887a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37796,DS-9eb2bec5-39e0-49c8-b3f9-ca1eb9445ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-ef2c1a7b-7e2c-4b32-b5a6-342087ea0bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-75a9de10-5e8e-44e6-9046-9e1be419acc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-420013688-172.17.0.18-1596026469157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45417,DS-b15e9fae-f884-46c3-8974-511365ac4b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-f60279af-8c0f-4b6a-a14b-a2da28b10a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33291,DS-f9435536-d72b-4bf0-b32f-2e3f5eed0682,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-6a93ddf5-9d41-495a-813b-01c155e5a761,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-7f05ef86-2b1e-4e7f-998a-3916c42887a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37796,DS-9eb2bec5-39e0-49c8-b3f9-ca1eb9445ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-ef2c1a7b-7e2c-4b32-b5a6-342087ea0bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-75a9de10-5e8e-44e6-9046-9e1be419acc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-707518268-172.17.0.18-1596026629122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33667,DS-9ece5d2c-0cb0-4dba-889e-a43354f2f89f,DISK], DatanodeInfoWithStorage[127.0.0.1:38242,DS-84d1a306-4895-42c2-8025-1461c5642343,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-448033a5-dce1-4e7b-a20a-8e1f04b5c704,DISK], DatanodeInfoWithStorage[127.0.0.1:39893,DS-a2142546-ce91-4b78-bfdf-2a178e4fbb27,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-152a5ac1-7117-4e11-bf92-08c9cad2d08c,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-adbdc099-7c62-4091-9495-49de026a3588,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-6ab05f55-6cde-4261-a7b2-12dd3074a4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-6bcdc177-ec5a-44dd-9985-e154d96a9815,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-707518268-172.17.0.18-1596026629122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33667,DS-9ece5d2c-0cb0-4dba-889e-a43354f2f89f,DISK], DatanodeInfoWithStorage[127.0.0.1:38242,DS-84d1a306-4895-42c2-8025-1461c5642343,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-448033a5-dce1-4e7b-a20a-8e1f04b5c704,DISK], DatanodeInfoWithStorage[127.0.0.1:39893,DS-a2142546-ce91-4b78-bfdf-2a178e4fbb27,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-152a5ac1-7117-4e11-bf92-08c9cad2d08c,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-adbdc099-7c62-4091-9495-49de026a3588,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-6ab05f55-6cde-4261-a7b2-12dd3074a4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-6bcdc177-ec5a-44dd-9985-e154d96a9815,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1162186258-172.17.0.18-1596027231142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34759,DS-f9d3ca2e-74f8-4606-a4e9-2c055466514c,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-58281d7d-1240-4d0b-b66c-6f8c43aa24d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-7480944f-74d0-4c41-a7fa-6f6dfa12a870,DISK], DatanodeInfoWithStorage[127.0.0.1:42216,DS-371dff7e-19a3-4083-aed7-24a3ad5c706b,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-13147879-e34a-424e-b468-7af34086bb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-b7b96af4-845e-4aaa-8d63-59fe81abf11b,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-d352727b-401e-4fa3-a982-3730793b107f,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-5da824a2-9abb-4552-a023-5e41c3b63010,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1162186258-172.17.0.18-1596027231142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34759,DS-f9d3ca2e-74f8-4606-a4e9-2c055466514c,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-58281d7d-1240-4d0b-b66c-6f8c43aa24d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-7480944f-74d0-4c41-a7fa-6f6dfa12a870,DISK], DatanodeInfoWithStorage[127.0.0.1:42216,DS-371dff7e-19a3-4083-aed7-24a3ad5c706b,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-13147879-e34a-424e-b468-7af34086bb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-b7b96af4-845e-4aaa-8d63-59fe81abf11b,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-d352727b-401e-4fa3-a982-3730793b107f,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-5da824a2-9abb-4552-a023-5e41c3b63010,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-408707197-172.17.0.18-1596027310950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38590,DS-cad04b68-0b50-4ecc-a4ee-3d663e420881,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-7b402e88-cc3e-417f-9ba3-614c5c61c3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-f4083015-538c-4321-9218-54f3ef794222,DISK], DatanodeInfoWithStorage[127.0.0.1:34159,DS-0684951d-a8eb-46ba-927f-f6b93be8bf15,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-1f649936-42e3-435f-b53d-7eddbc0b6840,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-52e42454-17ce-4a39-9452-4bc25826565b,DISK], DatanodeInfoWithStorage[127.0.0.1:39619,DS-fbae6d94-93fc-4555-989d-113a595db9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-7a294596-b77d-42f5-bc01-75c5b977f749,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-408707197-172.17.0.18-1596027310950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38590,DS-cad04b68-0b50-4ecc-a4ee-3d663e420881,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-7b402e88-cc3e-417f-9ba3-614c5c61c3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-f4083015-538c-4321-9218-54f3ef794222,DISK], DatanodeInfoWithStorage[127.0.0.1:34159,DS-0684951d-a8eb-46ba-927f-f6b93be8bf15,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-1f649936-42e3-435f-b53d-7eddbc0b6840,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-52e42454-17ce-4a39-9452-4bc25826565b,DISK], DatanodeInfoWithStorage[127.0.0.1:39619,DS-fbae6d94-93fc-4555-989d-113a595db9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-7a294596-b77d-42f5-bc01-75c5b977f749,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1570788082-172.17.0.18-1596027499881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46039,DS-46797c31-fc1d-44be-8892-c5de2d03951b,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-892696dc-eeb5-41e3-bde2-fb13adce314a,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-05f96b20-fad9-4f51-9e4d-1e935fe26984,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-f4c12169-7866-49fb-93bc-636758017391,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-561562e5-b1d4-4454-8308-8147c7a0b49d,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-54de62f4-3c31-404d-8dd8-7fa4ccc348d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44404,DS-9c94ce5d-aeed-4a1f-af3d-0966cca15bae,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-586ee665-300c-44e0-8900-9381d549236a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1570788082-172.17.0.18-1596027499881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46039,DS-46797c31-fc1d-44be-8892-c5de2d03951b,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-892696dc-eeb5-41e3-bde2-fb13adce314a,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-05f96b20-fad9-4f51-9e4d-1e935fe26984,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-f4c12169-7866-49fb-93bc-636758017391,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-561562e5-b1d4-4454-8308-8147c7a0b49d,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-54de62f4-3c31-404d-8dd8-7fa4ccc348d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44404,DS-9c94ce5d-aeed-4a1f-af3d-0966cca15bae,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-586ee665-300c-44e0-8900-9381d549236a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2048139638-172.17.0.18-1596027800786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38949,DS-d74a5398-8f13-4257-8e9b-afd0cd290251,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-32d1418f-75ba-461a-a9a0-f802872502ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-749f1af6-b40b-41bc-af5a-0814b3404675,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-bd6277f3-2933-49fd-a606-a0b5b2cb4169,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-4fd46911-f1ac-469f-83c7-01ff2f2d50c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-b85e7659-46d4-48e3-b088-f65302ac2023,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-930d6183-4b93-48e4-b1f0-0b110aa19c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40926,DS-a03272dc-dd68-4382-ae6f-2d3f600b8d34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2048139638-172.17.0.18-1596027800786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38949,DS-d74a5398-8f13-4257-8e9b-afd0cd290251,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-32d1418f-75ba-461a-a9a0-f802872502ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-749f1af6-b40b-41bc-af5a-0814b3404675,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-bd6277f3-2933-49fd-a606-a0b5b2cb4169,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-4fd46911-f1ac-469f-83c7-01ff2f2d50c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-b85e7659-46d4-48e3-b088-f65302ac2023,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-930d6183-4b93-48e4-b1f0-0b110aa19c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40926,DS-a03272dc-dd68-4382-ae6f-2d3f600b8d34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130227207-172.17.0.18-1596027816627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34647,DS-c429af12-d5eb-43a8-b7f3-718f14e42529,DISK], DatanodeInfoWithStorage[127.0.0.1:46155,DS-7a4bb83b-820e-4bf3-9472-1293a94273a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-68d7c533-536e-4654-b922-4cf9d98830f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-65fb9d7d-c99d-4511-ab5a-7f68d78c0ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-367846ef-7d89-4f00-bb08-8ad7f8cc7c90,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-4ed1666b-5ef5-4662-b66c-4c07236ea60e,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-82e53c95-2379-4115-a653-d1ccaa7f31bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33757,DS-0f91d4e3-30ab-41dc-8594-a173ad5b4de6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130227207-172.17.0.18-1596027816627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34647,DS-c429af12-d5eb-43a8-b7f3-718f14e42529,DISK], DatanodeInfoWithStorage[127.0.0.1:46155,DS-7a4bb83b-820e-4bf3-9472-1293a94273a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-68d7c533-536e-4654-b922-4cf9d98830f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-65fb9d7d-c99d-4511-ab5a-7f68d78c0ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-367846ef-7d89-4f00-bb08-8ad7f8cc7c90,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-4ed1666b-5ef5-4662-b66c-4c07236ea60e,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-82e53c95-2379-4115-a653-d1ccaa7f31bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33757,DS-0f91d4e3-30ab-41dc-8594-a173ad5b4de6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-547542601-172.17.0.18-1596028006047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35496,DS-58c73cd2-7354-4558-827e-90ca43d775ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-bb7c312f-52ce-42a2-9f8f-25518e3d5b29,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-b2097767-389c-4cba-90bb-da7225608cef,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-ca35e379-cd08-4297-a7a8-54e28f6cdaeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41595,DS-6fdb3f31-d3df-4e51-8d0c-540850943e81,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-5cb00859-8a69-43fe-9c6d-948776af9ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-82909f3e-362c-4304-87c4-dba3307ad455,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-5f5df0e2-9362-4ac7-8166-8ba86410c7aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-547542601-172.17.0.18-1596028006047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35496,DS-58c73cd2-7354-4558-827e-90ca43d775ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-bb7c312f-52ce-42a2-9f8f-25518e3d5b29,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-b2097767-389c-4cba-90bb-da7225608cef,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-ca35e379-cd08-4297-a7a8-54e28f6cdaeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41595,DS-6fdb3f31-d3df-4e51-8d0c-540850943e81,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-5cb00859-8a69-43fe-9c6d-948776af9ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-82909f3e-362c-4304-87c4-dba3307ad455,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-5f5df0e2-9362-4ac7-8166-8ba86410c7aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-71425948-172.17.0.18-1596028054029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43314,DS-dd898b7a-0e02-456e-ae3d-36afdb474c94,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-0cebcdc9-9908-4459-b790-65ecdc201ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-b636cb94-8b6c-4f40-8768-d19488b8de96,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-3d3a53c0-f8e9-4770-ae74-af97b59d4b83,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-4fa80c7c-202e-4d71-9292-10a4dcc818c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-6499922b-926a-411e-b74d-7ba6de451d76,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-af0cc11a-7f99-49d1-8c3b-7205d6da9b80,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-49b6deae-5eb2-4ba6-9d2b-f1887b76a115,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-71425948-172.17.0.18-1596028054029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43314,DS-dd898b7a-0e02-456e-ae3d-36afdb474c94,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-0cebcdc9-9908-4459-b790-65ecdc201ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-b636cb94-8b6c-4f40-8768-d19488b8de96,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-3d3a53c0-f8e9-4770-ae74-af97b59d4b83,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-4fa80c7c-202e-4d71-9292-10a4dcc818c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-6499922b-926a-411e-b74d-7ba6de451d76,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-af0cc11a-7f99-49d1-8c3b-7205d6da9b80,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-49b6deae-5eb2-4ba6-9d2b-f1887b76a115,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 2453
