reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-471513377-172.17.0.21-1596014242226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44579,DS-525e36f7-c778-49c0-a973-cd4c2b7eb0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-bd5fe8e7-aef4-4864-990e-735607492346,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-2cb133c5-20f0-4da3-9849-6e7c6bd289c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38875,DS-95cf610e-14a4-4c12-a7af-f4517bf136fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-1042010c-9344-4b94-96b9-bbf25169d69c,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-9c3326f9-7e61-459a-9918-9a8e12bb6b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-f8fbc22a-ba7d-41e4-a5ce-e71faa8f614a,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-84df9cd6-fa37-4b00-89d5-ad7ca8c2481f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-471513377-172.17.0.21-1596014242226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44579,DS-525e36f7-c778-49c0-a973-cd4c2b7eb0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-bd5fe8e7-aef4-4864-990e-735607492346,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-2cb133c5-20f0-4da3-9849-6e7c6bd289c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38875,DS-95cf610e-14a4-4c12-a7af-f4517bf136fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-1042010c-9344-4b94-96b9-bbf25169d69c,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-9c3326f9-7e61-459a-9918-9a8e12bb6b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-f8fbc22a-ba7d-41e4-a5ce-e71faa8f614a,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-84df9cd6-fa37-4b00-89d5-ad7ca8c2481f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-294732676-172.17.0.21-1596014309678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42910,DS-a5bb84f7-fca5-4456-add3-32cdf622ac32,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-5db0cd5e-7b74-4ffd-b135-2c867ac14581,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-63ac8e16-81c1-480e-bc48-3103f7208fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38261,DS-5ac132d3-69b4-4fea-96c1-b4a20d19161a,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-d10353e4-9386-40b8-8b80-5730362fa78b,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-1221c66d-0dbb-4556-89b6-7a3d87c72765,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-939f8c9e-e3d8-4355-88b6-db9295ac527a,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-1a0e36b1-e27b-48fd-ba5f-b5cf8932632c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-294732676-172.17.0.21-1596014309678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42910,DS-a5bb84f7-fca5-4456-add3-32cdf622ac32,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-5db0cd5e-7b74-4ffd-b135-2c867ac14581,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-63ac8e16-81c1-480e-bc48-3103f7208fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38261,DS-5ac132d3-69b4-4fea-96c1-b4a20d19161a,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-d10353e4-9386-40b8-8b80-5730362fa78b,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-1221c66d-0dbb-4556-89b6-7a3d87c72765,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-939f8c9e-e3d8-4355-88b6-db9295ac527a,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-1a0e36b1-e27b-48fd-ba5f-b5cf8932632c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-444719368-172.17.0.21-1596014368594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46836,DS-c70b860b-c7ff-4de9-90f7-d8f033548a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-37f27e3c-750b-4a25-9ffd-d6226b594464,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-e3cf391f-cd4d-46b9-96aa-caaa4e9dccc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40619,DS-5197c389-e8a0-47f1-936c-6e4a3aa9b4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-10049cbf-a451-4969-9681-90fa770fcf62,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-110f61ee-7c55-4b84-8040-872dcadce713,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-3f345f2e-8163-40a1-ac20-65d1d1e97dac,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-640001ab-a985-459e-9e87-9262d56e9c7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-444719368-172.17.0.21-1596014368594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46836,DS-c70b860b-c7ff-4de9-90f7-d8f033548a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-37f27e3c-750b-4a25-9ffd-d6226b594464,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-e3cf391f-cd4d-46b9-96aa-caaa4e9dccc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40619,DS-5197c389-e8a0-47f1-936c-6e4a3aa9b4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-10049cbf-a451-4969-9681-90fa770fcf62,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-110f61ee-7c55-4b84-8040-872dcadce713,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-3f345f2e-8163-40a1-ac20-65d1d1e97dac,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-640001ab-a985-459e-9e87-9262d56e9c7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1921551867-172.17.0.21-1596014730771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36772,DS-2e6509f0-7aac-4a85-925a-da4a8b410af6,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-74f1fb6f-c0e9-4c28-8787-1b569e3d1c00,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-c253d03f-9673-491d-86f9-d72b1fef6067,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-5d3ce8c4-282e-4320-80c0-a2438eb0414d,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-fdd92d2c-1735-445e-b9b4-8a67d989acb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-9711190e-9912-4a46-96f0-32edd9fdb847,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-24b67d27-75f6-4f15-b1dc-6ded9bc6ab70,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-1341c968-ead6-48d0-86af-2736bd1c89a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1921551867-172.17.0.21-1596014730771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36772,DS-2e6509f0-7aac-4a85-925a-da4a8b410af6,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-74f1fb6f-c0e9-4c28-8787-1b569e3d1c00,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-c253d03f-9673-491d-86f9-d72b1fef6067,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-5d3ce8c4-282e-4320-80c0-a2438eb0414d,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-fdd92d2c-1735-445e-b9b4-8a67d989acb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-9711190e-9912-4a46-96f0-32edd9fdb847,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-24b67d27-75f6-4f15-b1dc-6ded9bc6ab70,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-1341c968-ead6-48d0-86af-2736bd1c89a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1773595781-172.17.0.21-1596014948281:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43419,DS-5317fd27-7ca8-414f-9c0f-4e5d0a827336,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-fa015e93-0a77-402c-9cde-fe8f96d59cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-79533a32-b37f-4d08-bdd6-139ed606a574,DISK], DatanodeInfoWithStorage[127.0.0.1:40215,DS-36dff2e2-7bf6-422a-b0ec-9a6fe30ed8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-3d2b13f6-e986-494f-86e8-fb4158298f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-6dde8665-6e21-48ad-9413-e30a2a4d5c74,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-f1d07930-35be-42c8-93ac-5aa0458b7708,DISK], DatanodeInfoWithStorage[127.0.0.1:43840,DS-ab27df8c-c0cd-4f07-a7f9-c03e21c6cc1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1773595781-172.17.0.21-1596014948281:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43419,DS-5317fd27-7ca8-414f-9c0f-4e5d0a827336,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-fa015e93-0a77-402c-9cde-fe8f96d59cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-79533a32-b37f-4d08-bdd6-139ed606a574,DISK], DatanodeInfoWithStorage[127.0.0.1:40215,DS-36dff2e2-7bf6-422a-b0ec-9a6fe30ed8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-3d2b13f6-e986-494f-86e8-fb4158298f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-6dde8665-6e21-48ad-9413-e30a2a4d5c74,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-f1d07930-35be-42c8-93ac-5aa0458b7708,DISK], DatanodeInfoWithStorage[127.0.0.1:43840,DS-ab27df8c-c0cd-4f07-a7f9-c03e21c6cc1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-296377621-172.17.0.21-1596015287434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41257,DS-c3ad5d15-d201-4d4c-89aa-09922bc701d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35714,DS-6d3ff0b8-c9ae-4d5a-a3b3-9b822e9c5ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-0e10c0b2-cdc5-40dd-9e56-c20a8a5e90cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-f06696ed-81c9-4f57-8d60-91e574171acb,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-a5b04858-cb8d-40e0-8ae0-8fe9276ff8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-cf5c6879-20b7-44b1-b67d-be7966b49aee,DISK], DatanodeInfoWithStorage[127.0.0.1:41265,DS-727d2717-0ad2-4a6a-b41b-67d37bcdd679,DISK], DatanodeInfoWithStorage[127.0.0.1:42886,DS-ba0d261f-31c2-4dfa-ae67-281ced40f83f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-296377621-172.17.0.21-1596015287434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41257,DS-c3ad5d15-d201-4d4c-89aa-09922bc701d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35714,DS-6d3ff0b8-c9ae-4d5a-a3b3-9b822e9c5ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-0e10c0b2-cdc5-40dd-9e56-c20a8a5e90cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-f06696ed-81c9-4f57-8d60-91e574171acb,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-a5b04858-cb8d-40e0-8ae0-8fe9276ff8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-cf5c6879-20b7-44b1-b67d-be7966b49aee,DISK], DatanodeInfoWithStorage[127.0.0.1:41265,DS-727d2717-0ad2-4a6a-b41b-67d37bcdd679,DISK], DatanodeInfoWithStorage[127.0.0.1:42886,DS-ba0d261f-31c2-4dfa-ae67-281ced40f83f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1646923930-172.17.0.21-1596016366371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39242,DS-19bc6228-ff7a-4969-b391-51b4ec3ce7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40065,DS-b7032e89-3a71-4ac7-b7c6-f835fbdf1683,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-ebc21d10-50ff-45ed-b630-a2755954e668,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-3fc294e6-95fa-436d-a263-cb03d15e792a,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-d39a4c94-0208-471f-be61-d3542ed9e6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-e6473b69-b2bd-44ac-b1d6-5734b72c9121,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-83970bb2-0827-406b-a2d2-236373f3f034,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-7cc962a1-bbc5-474d-bb50-221255039f29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1646923930-172.17.0.21-1596016366371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39242,DS-19bc6228-ff7a-4969-b391-51b4ec3ce7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40065,DS-b7032e89-3a71-4ac7-b7c6-f835fbdf1683,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-ebc21d10-50ff-45ed-b630-a2755954e668,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-3fc294e6-95fa-436d-a263-cb03d15e792a,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-d39a4c94-0208-471f-be61-d3542ed9e6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-e6473b69-b2bd-44ac-b1d6-5734b72c9121,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-83970bb2-0827-406b-a2d2-236373f3f034,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-7cc962a1-bbc5-474d-bb50-221255039f29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-197474505-172.17.0.21-1596016430658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39431,DS-74636ef1-a152-4f7e-bacf-701652fe7488,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-2d38baae-39c1-430e-a070-645e6c9a4474,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-8e82751d-c88c-4faf-933e-d6c314924b52,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-0a54e893-bff3-4bad-8e61-68ca2e6a08f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-cea490f5-9311-4ffe-ac80-ecf9f5e32730,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-df8be5b8-9f37-4bf0-a5c8-d8a7c435b0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-9b11ca2f-c0ac-4e41-8c9b-4711c2d29879,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-b6456687-ddec-4669-9983-fa3afbd586c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-197474505-172.17.0.21-1596016430658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39431,DS-74636ef1-a152-4f7e-bacf-701652fe7488,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-2d38baae-39c1-430e-a070-645e6c9a4474,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-8e82751d-c88c-4faf-933e-d6c314924b52,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-0a54e893-bff3-4bad-8e61-68ca2e6a08f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-cea490f5-9311-4ffe-ac80-ecf9f5e32730,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-df8be5b8-9f37-4bf0-a5c8-d8a7c435b0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-9b11ca2f-c0ac-4e41-8c9b-4711c2d29879,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-b6456687-ddec-4669-9983-fa3afbd586c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1698803045-172.17.0.21-1596016530257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43430,DS-aae6c27b-c975-4bd8-9add-13e45eea28c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46118,DS-8deb6bbc-7837-4fdb-8fa5-87bc0269dcaf,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-8aa66744-2373-4cc1-ad6d-2ce0b26c1cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-f12896d3-4422-4bdb-b26a-625a9379503b,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-d1980dcb-04a4-4f4f-b1b1-60688cd22e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-c405bada-aa66-4056-88a0-7c0f30abbf1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-29ba5b40-cfba-4401-b8d9-2954619982a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-97ac98f1-2d23-42a5-a133-63135b70f349,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1698803045-172.17.0.21-1596016530257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43430,DS-aae6c27b-c975-4bd8-9add-13e45eea28c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46118,DS-8deb6bbc-7837-4fdb-8fa5-87bc0269dcaf,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-8aa66744-2373-4cc1-ad6d-2ce0b26c1cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-f12896d3-4422-4bdb-b26a-625a9379503b,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-d1980dcb-04a4-4f4f-b1b1-60688cd22e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-c405bada-aa66-4056-88a0-7c0f30abbf1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-29ba5b40-cfba-4401-b8d9-2954619982a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-97ac98f1-2d23-42a5-a133-63135b70f349,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-110390211-172.17.0.21-1596017561750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36451,DS-4ed23b4d-c43e-4b2e-b568-5ed17c2bf14d,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-61048c0b-1a98-4a56-9a45-f3eca9d207e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-a3bee6ab-1cc8-44a4-ae9d-b7b268977f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-9170cd1c-425b-4be1-a0aa-5777028a5af6,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-e7a317c9-2f63-4bd3-a991-41955f8ad4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-b7495720-f454-408e-b047-9371d759c105,DISK], DatanodeInfoWithStorage[127.0.0.1:46844,DS-26176a66-20d7-4581-907c-82873de3a60a,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-642c9f48-6c0d-4a25-9136-2f881726d5ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-110390211-172.17.0.21-1596017561750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36451,DS-4ed23b4d-c43e-4b2e-b568-5ed17c2bf14d,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-61048c0b-1a98-4a56-9a45-f3eca9d207e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-a3bee6ab-1cc8-44a4-ae9d-b7b268977f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-9170cd1c-425b-4be1-a0aa-5777028a5af6,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-e7a317c9-2f63-4bd3-a991-41955f8ad4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-b7495720-f454-408e-b047-9371d759c105,DISK], DatanodeInfoWithStorage[127.0.0.1:46844,DS-26176a66-20d7-4581-907c-82873de3a60a,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-642c9f48-6c0d-4a25-9136-2f881726d5ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-757524232-172.17.0.21-1596017851872:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44243,DS-556f7673-0f02-4c88-a689-526c3d662592,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-64073fe5-5800-4ce6-801f-06858b6f19a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34001,DS-e2e276e5-69c2-45db-8934-7aff8ebd1a05,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-e61d8936-0fb7-4311-b80d-fc83c7f644a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-da0c93d4-6797-444e-8b46-bc716d934828,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-0d203557-062d-45ed-8891-f0ce89e49fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-da28deee-1cf5-44ce-9b13-80119767731d,DISK], DatanodeInfoWithStorage[127.0.0.1:39893,DS-a5db6164-bfe3-41de-830d-f4508051ef7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-757524232-172.17.0.21-1596017851872:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44243,DS-556f7673-0f02-4c88-a689-526c3d662592,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-64073fe5-5800-4ce6-801f-06858b6f19a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34001,DS-e2e276e5-69c2-45db-8934-7aff8ebd1a05,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-e61d8936-0fb7-4311-b80d-fc83c7f644a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-da0c93d4-6797-444e-8b46-bc716d934828,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-0d203557-062d-45ed-8891-f0ce89e49fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-da28deee-1cf5-44ce-9b13-80119767731d,DISK], DatanodeInfoWithStorage[127.0.0.1:39893,DS-a5db6164-bfe3-41de-830d-f4508051ef7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1166972920-172.17.0.21-1596018025015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36003,DS-1eb306f6-3b8f-4db3-aa40-015daa6d3175,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-93649321-cfea-4d35-8e94-24cac3457131,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-db65eacc-561e-44fe-99b5-126b752fe659,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-2987aa76-092c-473e-86b8-8bc703e1483c,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-ebe29d19-eea1-4a46-b53f-9cb8d06771d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-6540294c-d0eb-4867-8ca5-61edc808e9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36576,DS-7672ac70-8768-404b-9417-ed524ad5ae02,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-93c1b940-35e5-491d-a58d-d1d2b43a6a52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1166972920-172.17.0.21-1596018025015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36003,DS-1eb306f6-3b8f-4db3-aa40-015daa6d3175,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-93649321-cfea-4d35-8e94-24cac3457131,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-db65eacc-561e-44fe-99b5-126b752fe659,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-2987aa76-092c-473e-86b8-8bc703e1483c,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-ebe29d19-eea1-4a46-b53f-9cb8d06771d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-6540294c-d0eb-4867-8ca5-61edc808e9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36576,DS-7672ac70-8768-404b-9417-ed524ad5ae02,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-93c1b940-35e5-491d-a58d-d1d2b43a6a52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1066641880-172.17.0.21-1596018582347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38159,DS-cea7fbac-0e46-4181-b08e-26b19e7dc0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-7b7b6dd5-c303-4dd9-82cc-91c8917da9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-afee875f-556a-4cb2-bca7-a4ddcade5bec,DISK], DatanodeInfoWithStorage[127.0.0.1:34906,DS-4e37d8b5-5317-4700-991c-4024454b6c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-4aaf7b05-2d1f-490a-94ab-0c2c4c3117ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-217765dc-6f93-413d-8806-96ac7fbbc882,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-a95f2058-94b6-40e7-abbc-14778da7ae00,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-cd8408bf-9ec5-46ff-96d9-47f34adf3392,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1066641880-172.17.0.21-1596018582347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38159,DS-cea7fbac-0e46-4181-b08e-26b19e7dc0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-7b7b6dd5-c303-4dd9-82cc-91c8917da9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-afee875f-556a-4cb2-bca7-a4ddcade5bec,DISK], DatanodeInfoWithStorage[127.0.0.1:34906,DS-4e37d8b5-5317-4700-991c-4024454b6c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-4aaf7b05-2d1f-490a-94ab-0c2c4c3117ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-217765dc-6f93-413d-8806-96ac7fbbc882,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-a95f2058-94b6-40e7-abbc-14778da7ae00,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-cd8408bf-9ec5-46ff-96d9-47f34adf3392,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-457397823-172.17.0.21-1596018658465:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35539,DS-084e3606-89d6-4837-8a0f-2449960bd742,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-65e9c159-6207-4fe1-a6bc-defa5cc4e3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-5a30bbfb-2fb3-4f6e-9572-b62a943644a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-6fa1651e-f7ee-49a6-b4f1-29914cf06fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-16b057f7-0808-427b-b544-efe3191d015d,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-6f8f57b5-a80c-4222-8207-37be7256c465,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-eb06822c-07e5-4f24-bdcb-e8422436301b,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-defb5788-9a75-4327-a3a9-ef35770a1518,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-457397823-172.17.0.21-1596018658465:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35539,DS-084e3606-89d6-4837-8a0f-2449960bd742,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-65e9c159-6207-4fe1-a6bc-defa5cc4e3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-5a30bbfb-2fb3-4f6e-9572-b62a943644a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-6fa1651e-f7ee-49a6-b4f1-29914cf06fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-16b057f7-0808-427b-b544-efe3191d015d,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-6f8f57b5-a80c-4222-8207-37be7256c465,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-eb06822c-07e5-4f24-bdcb-e8422436301b,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-defb5788-9a75-4327-a3a9-ef35770a1518,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5377
