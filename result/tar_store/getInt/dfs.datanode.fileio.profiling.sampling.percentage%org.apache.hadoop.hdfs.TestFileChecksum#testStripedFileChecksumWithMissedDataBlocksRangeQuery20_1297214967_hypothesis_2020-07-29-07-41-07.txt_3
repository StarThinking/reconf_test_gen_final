reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-988369385-172.17.0.12-1596008511800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33186,DS-89817168-3f31-46d6-a8cc-39ed99c43da7,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-f6c4bcd9-606b-40b6-9abb-3dfa94b6dafc,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-f8ce2285-e771-445c-9da6-b176cb4e31a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-d51da2ab-85d4-493f-b0d4-7ffe68c38f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-c142f829-125d-43a6-9762-89f44ee12de8,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-edf4c125-0fd1-4771-9328-f15fea208d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44389,DS-27322c0d-f6d4-4e96-b28e-f178c08e2130,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-29afeba4-f1bf-4e3f-b8b6-2c506ba6856a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-988369385-172.17.0.12-1596008511800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33186,DS-89817168-3f31-46d6-a8cc-39ed99c43da7,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-f6c4bcd9-606b-40b6-9abb-3dfa94b6dafc,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-f8ce2285-e771-445c-9da6-b176cb4e31a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-d51da2ab-85d4-493f-b0d4-7ffe68c38f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-c142f829-125d-43a6-9762-89f44ee12de8,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-edf4c125-0fd1-4771-9328-f15fea208d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44389,DS-27322c0d-f6d4-4e96-b28e-f178c08e2130,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-29afeba4-f1bf-4e3f-b8b6-2c506ba6856a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1409581021-172.17.0.12-1596008800524:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39749,DS-373d83fd-e423-46af-9906-be5dbfb07be7,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-b4187b52-7fd4-4875-8aa9-28a09af69dae,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-410d21c8-fce7-4832-a2ae-8bbd8d92dc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-00ff5965-e7c3-4bfa-bbb1-7c6768ca9535,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-ff538920-f186-4c52-aa1c-179c3e704e45,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-ce4ccde4-8969-463b-9d37-289b9d00a2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35755,DS-164d3ca4-90d2-46c4-b3c0-61b221d44bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-3bde635d-ccec-4947-a180-8b3a08c81190,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1409581021-172.17.0.12-1596008800524:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39749,DS-373d83fd-e423-46af-9906-be5dbfb07be7,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-b4187b52-7fd4-4875-8aa9-28a09af69dae,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-410d21c8-fce7-4832-a2ae-8bbd8d92dc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-00ff5965-e7c3-4bfa-bbb1-7c6768ca9535,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-ff538920-f186-4c52-aa1c-179c3e704e45,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-ce4ccde4-8969-463b-9d37-289b9d00a2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35755,DS-164d3ca4-90d2-46c4-b3c0-61b221d44bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-3bde635d-ccec-4947-a180-8b3a08c81190,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-596306233-172.17.0.12-1596008903165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32883,DS-76e16820-898f-4746-9890-3a57d0944ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-27c019e5-5e98-4cba-bba2-7cb7039b20a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-caf77b83-2d3b-4fba-b585-c9001e0c1326,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-46bc910c-b558-4a22-904b-14330d0fe68b,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-f153faca-5944-4942-be0d-c17134cbd81f,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-691a71e1-0b7b-4423-b872-309ae8d9555d,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-1896228d-abeb-4fe5-a6d2-fbb4450bdbe4,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-8089affb-099f-48e8-afb5-3b37b8b06395,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-596306233-172.17.0.12-1596008903165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32883,DS-76e16820-898f-4746-9890-3a57d0944ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-27c019e5-5e98-4cba-bba2-7cb7039b20a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-caf77b83-2d3b-4fba-b585-c9001e0c1326,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-46bc910c-b558-4a22-904b-14330d0fe68b,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-f153faca-5944-4942-be0d-c17134cbd81f,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-691a71e1-0b7b-4423-b872-309ae8d9555d,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-1896228d-abeb-4fe5-a6d2-fbb4450bdbe4,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-8089affb-099f-48e8-afb5-3b37b8b06395,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-274477970-172.17.0.12-1596009518837:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45334,DS-7e11c9b3-4097-4d3d-abc3-9ad31a65d5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-235b7bbe-46cc-41cf-91fd-5582747ca3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-dbe0c626-cabb-4b8f-926f-0b7873cf2717,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-e35770dc-4f78-4cd8-84f3-724d2f340079,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-e702919b-e45e-4eae-a321-269c68f048ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-91da1129-813f-4429-8d90-a60bfbc84cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-0769d2ec-4719-4817-8b9b-3f84660147b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-665d5e40-32d9-4cbf-aa9e-2f4ad3e3a9a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-274477970-172.17.0.12-1596009518837:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45334,DS-7e11c9b3-4097-4d3d-abc3-9ad31a65d5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-235b7bbe-46cc-41cf-91fd-5582747ca3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-dbe0c626-cabb-4b8f-926f-0b7873cf2717,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-e35770dc-4f78-4cd8-84f3-724d2f340079,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-e702919b-e45e-4eae-a321-269c68f048ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-91da1129-813f-4429-8d90-a60bfbc84cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-0769d2ec-4719-4817-8b9b-3f84660147b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-665d5e40-32d9-4cbf-aa9e-2f4ad3e3a9a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1907070517-172.17.0.12-1596009802493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43144,DS-e8473032-2797-48ca-b4ac-8b4571f5f365,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-59a40c96-9140-41e9-ac9c-48300fb67b19,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-c491c465-be56-4ecc-a3d1-6eb4ef69807b,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-b2029e28-d189-4859-baa4-ceadb6423aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-5ad8805e-3ca2-4d1a-b78c-43b896a3dd15,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-885c41a4-767d-4c48-ae81-71cae45966c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-f56ae202-f8e2-4100-b158-0d3253acb731,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-621698c7-f518-454a-a4d6-d06268c8a360,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1907070517-172.17.0.12-1596009802493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43144,DS-e8473032-2797-48ca-b4ac-8b4571f5f365,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-59a40c96-9140-41e9-ac9c-48300fb67b19,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-c491c465-be56-4ecc-a3d1-6eb4ef69807b,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-b2029e28-d189-4859-baa4-ceadb6423aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-5ad8805e-3ca2-4d1a-b78c-43b896a3dd15,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-885c41a4-767d-4c48-ae81-71cae45966c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-f56ae202-f8e2-4100-b158-0d3253acb731,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-621698c7-f518-454a-a4d6-d06268c8a360,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-944255169-172.17.0.12-1596010053272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41727,DS-d06f8d12-0ff3-4c2e-8621-3ecf5fc2797c,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-bb117854-ab4a-4268-bf17-fc46730bd479,DISK], DatanodeInfoWithStorage[127.0.0.1:41376,DS-760165da-4b44-48de-b693-ae36c57d383c,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-fa6e78f3-6c7b-4a4a-936b-3ef11ed0bf4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-84a0130a-2619-404f-b66c-b076109e191a,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-accba153-1918-4e44-9f26-82b5ccb19ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-b1f58ab4-5547-4992-aee0-b64f4c141a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35995,DS-7a7003ba-7bbd-4d70-a650-95be4054d885,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-944255169-172.17.0.12-1596010053272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41727,DS-d06f8d12-0ff3-4c2e-8621-3ecf5fc2797c,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-bb117854-ab4a-4268-bf17-fc46730bd479,DISK], DatanodeInfoWithStorage[127.0.0.1:41376,DS-760165da-4b44-48de-b693-ae36c57d383c,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-fa6e78f3-6c7b-4a4a-936b-3ef11ed0bf4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-84a0130a-2619-404f-b66c-b076109e191a,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-accba153-1918-4e44-9f26-82b5ccb19ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-b1f58ab4-5547-4992-aee0-b64f4c141a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35995,DS-7a7003ba-7bbd-4d70-a650-95be4054d885,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-912882244-172.17.0.12-1596010351296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35461,DS-5dc12e28-4d3c-4200-8634-3e534ea4834c,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-cd7a2f4f-971d-4711-820e-66215feef775,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-79f7e8a9-57ad-44c4-b38f-96f524047312,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-acc319a7-a952-463a-aa1d-cce12cf9c6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-4dfa9688-d5cf-4375-89a4-1224ab3f2f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-1b4b39f3-532e-40f5-a8ff-d9fd78766c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-0c5eb2a0-75cf-4469-9eef-8d6ce7d53e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44553,DS-034554ab-5eee-44b1-989a-eb002373d60e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-912882244-172.17.0.12-1596010351296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35461,DS-5dc12e28-4d3c-4200-8634-3e534ea4834c,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-cd7a2f4f-971d-4711-820e-66215feef775,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-79f7e8a9-57ad-44c4-b38f-96f524047312,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-acc319a7-a952-463a-aa1d-cce12cf9c6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-4dfa9688-d5cf-4375-89a4-1224ab3f2f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-1b4b39f3-532e-40f5-a8ff-d9fd78766c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-0c5eb2a0-75cf-4469-9eef-8d6ce7d53e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44553,DS-034554ab-5eee-44b1-989a-eb002373d60e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-251234017-172.17.0.12-1596010422946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34711,DS-f46bab9a-c5ee-4d8c-ab82-ec4fb550a5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-7ea6acba-3ce9-4911-b5ca-5fe151377ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-8b8495ac-e913-497a-8272-cb4e708201f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-1cff7add-4a71-49ba-95b8-598b8ecaad1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-37329a80-5639-49c9-b58d-340c3b8f8147,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-a91a4c89-51bb-4312-afc5-09af424d27fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-2dfb8f98-1ae0-469f-8551-2f5ece983e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-3490ae4f-81aa-471c-b824-cfbd76a6d565,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-251234017-172.17.0.12-1596010422946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34711,DS-f46bab9a-c5ee-4d8c-ab82-ec4fb550a5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-7ea6acba-3ce9-4911-b5ca-5fe151377ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-8b8495ac-e913-497a-8272-cb4e708201f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-1cff7add-4a71-49ba-95b8-598b8ecaad1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-37329a80-5639-49c9-b58d-340c3b8f8147,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-a91a4c89-51bb-4312-afc5-09af424d27fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-2dfb8f98-1ae0-469f-8551-2f5ece983e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-3490ae4f-81aa-471c-b824-cfbd76a6d565,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-803641775-172.17.0.12-1596010856412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32983,DS-a38aad51-ba6d-4626-9948-488ffc8a5452,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-f8d74b29-8ad5-4688-b73d-b2f25359e7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-78bea69c-3448-4225-8086-b5b688631b86,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-00d22455-9992-4515-820a-24fe12b59a08,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-25a0d17e-ff63-4284-bda8-a6e0a1b72c25,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-11445185-34c5-48bf-9831-73125048a65b,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-a39947a1-2e1f-4842-93ac-ab65726f1986,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-6eb92684-47da-4ca7-9931-bf5f3f01701f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-803641775-172.17.0.12-1596010856412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32983,DS-a38aad51-ba6d-4626-9948-488ffc8a5452,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-f8d74b29-8ad5-4688-b73d-b2f25359e7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-78bea69c-3448-4225-8086-b5b688631b86,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-00d22455-9992-4515-820a-24fe12b59a08,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-25a0d17e-ff63-4284-bda8-a6e0a1b72c25,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-11445185-34c5-48bf-9831-73125048a65b,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-a39947a1-2e1f-4842-93ac-ab65726f1986,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-6eb92684-47da-4ca7-9931-bf5f3f01701f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1821074527-172.17.0.12-1596011182419:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38601,DS-6986494b-cc9f-42cf-9fcc-746254dd81c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45178,DS-73b5d7c3-41fe-48c8-a10c-682b10cfaa2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-54e9a1d2-0a86-491a-9c6d-7acb16cc03fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-3684cf41-2de8-4c9e-8571-a090f7dbb56e,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-2554cee1-ae2c-4617-a045-daed181e09a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-8e4a3c0b-2c73-490a-a55d-85d4e328edc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-54c4bf36-648d-4742-8bb7-69fdd9f88116,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-d8058a76-b6a4-4c59-a8ef-2cf03f3568ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1821074527-172.17.0.12-1596011182419:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38601,DS-6986494b-cc9f-42cf-9fcc-746254dd81c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45178,DS-73b5d7c3-41fe-48c8-a10c-682b10cfaa2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-54e9a1d2-0a86-491a-9c6d-7acb16cc03fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-3684cf41-2de8-4c9e-8571-a090f7dbb56e,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-2554cee1-ae2c-4617-a045-daed181e09a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-8e4a3c0b-2c73-490a-a55d-85d4e328edc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-54c4bf36-648d-4742-8bb7-69fdd9f88116,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-d8058a76-b6a4-4c59-a8ef-2cf03f3568ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1841943425-172.17.0.12-1596012271488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46735,DS-94d5d5fb-be00-432a-97be-1cfea27e31e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-d2d82152-7c42-442b-87f2-c0a6ee767c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-ee58ffb2-f12b-4dac-8c3f-2542bf190aff,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-caeb70b9-e3b5-4d52-82a4-f82c7b029e10,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-e8b68507-f347-49f0-9f75-e86bc44d6495,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-05dd23e6-85d8-4160-af51-101695e7a417,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-375f475a-827d-45b1-b5ae-d314c9168010,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-854139b3-2ae4-41a3-8da1-94c3a770667e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1841943425-172.17.0.12-1596012271488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46735,DS-94d5d5fb-be00-432a-97be-1cfea27e31e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-d2d82152-7c42-442b-87f2-c0a6ee767c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-ee58ffb2-f12b-4dac-8c3f-2542bf190aff,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-caeb70b9-e3b5-4d52-82a4-f82c7b029e10,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-e8b68507-f347-49f0-9f75-e86bc44d6495,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-05dd23e6-85d8-4160-af51-101695e7a417,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-375f475a-827d-45b1-b5ae-d314c9168010,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-854139b3-2ae4-41a3-8da1-94c3a770667e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-812224599-172.17.0.12-1596012803023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43409,DS-412e7a3a-15a0-47bb-a312-c19241c1979c,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-7c7845be-2b7d-4b0d-8cd7-9a0c2e63c75f,DISK], DatanodeInfoWithStorage[127.0.0.1:34781,DS-837acf2e-00f1-4d43-a1fd-1f977e4d2040,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-5cdd69cc-3ccd-45b6-b6d2-f3985da2191c,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-b4dddda9-3cde-4557-9714-a0af8a09fb05,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-22f61c54-ce29-4ca5-b144-56b215f4bcff,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-e5ce76c9-129e-4138-b165-dbd546d0e3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-df8e5161-3c08-41da-83d4-a2c6c7dfb599,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-812224599-172.17.0.12-1596012803023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43409,DS-412e7a3a-15a0-47bb-a312-c19241c1979c,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-7c7845be-2b7d-4b0d-8cd7-9a0c2e63c75f,DISK], DatanodeInfoWithStorage[127.0.0.1:34781,DS-837acf2e-00f1-4d43-a1fd-1f977e4d2040,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-5cdd69cc-3ccd-45b6-b6d2-f3985da2191c,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-b4dddda9-3cde-4557-9714-a0af8a09fb05,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-22f61c54-ce29-4ca5-b144-56b215f4bcff,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-e5ce76c9-129e-4138-b165-dbd546d0e3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-df8e5161-3c08-41da-83d4-a2c6c7dfb599,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1605639806-172.17.0.12-1596012985921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33032,DS-8f37a63f-43eb-45ab-b0fa-954330c8ed0e,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-841ff416-cff3-490a-a0fe-301dea627ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-d0913e82-7195-4e39-8c5c-54d60cfd24db,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-75f3ee8d-60af-4409-ae34-1aacd54d6a31,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-5ab60eac-5ccb-4a61-8967-63bd19056b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-54ddcdbc-48f5-4b20-8000-e86d2ac2dc64,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-50a7ba84-ed14-4ea4-9ef0-5a2ab1572ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-f212a9a6-bd78-4c96-a520-973926fb5dcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1605639806-172.17.0.12-1596012985921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33032,DS-8f37a63f-43eb-45ab-b0fa-954330c8ed0e,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-841ff416-cff3-490a-a0fe-301dea627ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-d0913e82-7195-4e39-8c5c-54d60cfd24db,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-75f3ee8d-60af-4409-ae34-1aacd54d6a31,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-5ab60eac-5ccb-4a61-8967-63bd19056b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-54ddcdbc-48f5-4b20-8000-e86d2ac2dc64,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-50a7ba84-ed14-4ea4-9ef0-5a2ab1572ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-f212a9a6-bd78-4c96-a520-973926fb5dcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-74794408-172.17.0.12-1596013061597:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40361,DS-169ce3d9-94f6-46f2-b4a5-c84013cf6ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-bdbd66ee-55ce-4c76-a80a-a56bc5db2ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-60313a3a-2f9f-44f7-9ccc-da77a455e52f,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-35ec4017-b0a6-43f8-bb2e-41faca05abc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-90d9e571-a943-4466-a8b0-96611c6cbb50,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-f6ee56f6-c08d-4230-b583-efadc9c4dbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-d3481eca-42f0-4096-a439-83aa733db447,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-aeaef12d-8934-4d5a-8746-94620d6f82dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-74794408-172.17.0.12-1596013061597:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40361,DS-169ce3d9-94f6-46f2-b4a5-c84013cf6ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-bdbd66ee-55ce-4c76-a80a-a56bc5db2ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-60313a3a-2f9f-44f7-9ccc-da77a455e52f,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-35ec4017-b0a6-43f8-bb2e-41faca05abc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-90d9e571-a943-4466-a8b0-96611c6cbb50,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-f6ee56f6-c08d-4230-b583-efadc9c4dbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-d3481eca-42f0-4096-a439-83aa733db447,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-aeaef12d-8934-4d5a-8746-94620d6f82dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1125791416-172.17.0.12-1596013127137:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35296,DS-1ab41587-5f61-484e-a22d-6bc8ba243c90,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-1ef00b45-0eed-47fd-a3a5-b57108b7035f,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-81454909-fb18-4640-977b-8711d441f374,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-de3a32f9-edba-4077-ba46-9b336a25c383,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-adab5588-18f9-4240-8e9e-95016e926c69,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-e6fb8964-d94f-4705-b253-9543e83e2fad,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-8ead3f4b-5891-462c-9f12-75cba7efed77,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-e4f9da93-e770-4faf-9fc9-e9c45bcba786,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1125791416-172.17.0.12-1596013127137:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35296,DS-1ab41587-5f61-484e-a22d-6bc8ba243c90,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-1ef00b45-0eed-47fd-a3a5-b57108b7035f,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-81454909-fb18-4640-977b-8711d441f374,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-de3a32f9-edba-4077-ba46-9b336a25c383,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-adab5588-18f9-4240-8e9e-95016e926c69,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-e6fb8964-d94f-4705-b253-9543e83e2fad,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-8ead3f4b-5891-462c-9f12-75cba7efed77,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-e4f9da93-e770-4faf-9fc9-e9c45bcba786,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1702687523-172.17.0.12-1596013301887:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36608,DS-385d7d5b-ace9-42cd-aba0-7b1277d90e75,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-17eca7e7-3f11-4ef1-94e2-82c5cae4170e,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-6dc52449-5bd9-4a8b-b7b3-09a68aaec150,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-4c95594b-49da-46cf-900b-150393d96739,DISK], DatanodeInfoWithStorage[127.0.0.1:45360,DS-ad3bd904-72c6-46a5-8f46-ead52a2fcc44,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-58996fc7-54ed-4186-863c-de6a6f312c30,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-af8e707a-6a55-4362-a83a-737c404d543b,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-3d99e78d-bf69-4b03-a3c1-4e8acb5b70bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1702687523-172.17.0.12-1596013301887:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36608,DS-385d7d5b-ace9-42cd-aba0-7b1277d90e75,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-17eca7e7-3f11-4ef1-94e2-82c5cae4170e,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-6dc52449-5bd9-4a8b-b7b3-09a68aaec150,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-4c95594b-49da-46cf-900b-150393d96739,DISK], DatanodeInfoWithStorage[127.0.0.1:45360,DS-ad3bd904-72c6-46a5-8f46-ead52a2fcc44,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-58996fc7-54ed-4186-863c-de6a6f312c30,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-af8e707a-6a55-4362-a83a-737c404d543b,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-3d99e78d-bf69-4b03-a3c1-4e8acb5b70bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: might be true error
Total execution time in seconds : 5175
