reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-194259124-172.17.0.10-1595904681072:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39904,DS-3312b99c-a2f0-4850-8995-d0d605544a47,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-30ee78e2-a95f-471f-a238-41f24e959330,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-d236041d-203a-495e-a820-bba4cfb2fd3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41545,DS-b5e38583-cfcd-4526-b628-d0eccc876a62,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-7d9bcf35-1c10-4d1b-83c3-ffa86ca11409,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-bb7e1603-6777-4e5d-8d53-cb1444ddcad0,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-7828f000-ea2d-4f5f-8b74-0c8ecd611b33,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-f75597bd-8d2f-4167-8226-64ae4a4443ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-194259124-172.17.0.10-1595904681072:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39904,DS-3312b99c-a2f0-4850-8995-d0d605544a47,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-30ee78e2-a95f-471f-a238-41f24e959330,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-d236041d-203a-495e-a820-bba4cfb2fd3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41545,DS-b5e38583-cfcd-4526-b628-d0eccc876a62,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-7d9bcf35-1c10-4d1b-83c3-ffa86ca11409,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-bb7e1603-6777-4e5d-8d53-cb1444ddcad0,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-7828f000-ea2d-4f5f-8b74-0c8ecd611b33,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-f75597bd-8d2f-4167-8226-64ae4a4443ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1842826168-172.17.0.10-1595904903535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38333,DS-8e7a6836-2d87-45e4-8e0c-eeb2e4ae5c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-29c137ee-4ddf-44fe-9b9b-bcd162706bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-512d3621-6c7f-4fcb-b60a-57ab74822e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-7392741e-5538-4680-8804-14c0817406eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-4f8de624-c9c0-49b1-ac4b-41cb46548812,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-aaf9a8a3-02f9-4db8-ac3e-cdebb3a69c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-bfb72d49-3759-4cba-9af0-bc2275b34e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-4c7a2dc0-d4b6-46c7-8d10-bf0f7abb8a55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1842826168-172.17.0.10-1595904903535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38333,DS-8e7a6836-2d87-45e4-8e0c-eeb2e4ae5c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-29c137ee-4ddf-44fe-9b9b-bcd162706bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-512d3621-6c7f-4fcb-b60a-57ab74822e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-7392741e-5538-4680-8804-14c0817406eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-4f8de624-c9c0-49b1-ac4b-41cb46548812,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-aaf9a8a3-02f9-4db8-ac3e-cdebb3a69c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-bfb72d49-3759-4cba-9af0-bc2275b34e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-4c7a2dc0-d4b6-46c7-8d10-bf0f7abb8a55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-737762224-172.17.0.10-1595904940267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37547,DS-054f08f2-dd20-4e7f-a219-546ce60de854,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-b9241119-49a5-424e-8b20-ec9fec33b7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-bbc174f7-6013-4d50-8835-2834c6b7647d,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-ea036430-7993-4411-88e1-e23a2f188132,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-b6c44123-b286-4572-adf0-bbcbdbd45cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-bb3e80c4-d7e7-44b9-9f9d-8243baa69b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-06015915-1a3c-46c3-9e76-bd9b8302353f,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-d0ae35ee-f21e-4540-a49b-93fd0cc6b777,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-737762224-172.17.0.10-1595904940267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37547,DS-054f08f2-dd20-4e7f-a219-546ce60de854,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-b9241119-49a5-424e-8b20-ec9fec33b7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-bbc174f7-6013-4d50-8835-2834c6b7647d,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-ea036430-7993-4411-88e1-e23a2f188132,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-b6c44123-b286-4572-adf0-bbcbdbd45cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-bb3e80c4-d7e7-44b9-9f9d-8243baa69b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-06015915-1a3c-46c3-9e76-bd9b8302353f,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-d0ae35ee-f21e-4540-a49b-93fd0cc6b777,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1406620617-172.17.0.10-1595905119570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39549,DS-9a955d74-c1a2-47e3-bc8a-68d0f268e118,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-fbc99b0f-c29b-4c73-bb09-a64542817cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-a80a483c-0537-474f-be97-9106650b99b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-a66f63dc-3087-4f2f-9a5a-e631b98722a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-526b2240-04e4-4aba-932a-a7a3fdc0b335,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-08893c90-528c-4630-8dbd-829e75d19a42,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-66965b49-37aa-4e09-a11f-b38f2e4d0b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43110,DS-ff427c3e-e300-4fe4-9359-7e6fb1f28ced,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1406620617-172.17.0.10-1595905119570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39549,DS-9a955d74-c1a2-47e3-bc8a-68d0f268e118,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-fbc99b0f-c29b-4c73-bb09-a64542817cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-a80a483c-0537-474f-be97-9106650b99b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-a66f63dc-3087-4f2f-9a5a-e631b98722a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-526b2240-04e4-4aba-932a-a7a3fdc0b335,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-08893c90-528c-4630-8dbd-829e75d19a42,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-66965b49-37aa-4e09-a11f-b38f2e4d0b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43110,DS-ff427c3e-e300-4fe4-9359-7e6fb1f28ced,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-541173131-172.17.0.10-1595905195758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44678,DS-7053b712-4a63-4f13-acd2-3c99735de39a,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-ff85ce40-b816-45f4-8b32-f0b9cb031d84,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-59350a0c-00db-42a3-a173-44d07adcc982,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-c7169269-8cac-4ab3-9e74-ed6da990d571,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-294dda7c-39c2-4fb9-9102-d39b8946803e,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-e2a63194-634a-4f35-b794-8684e50eb462,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-8a42be1b-afad-4395-b837-d577192b8e96,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-9fd5c90b-7a76-40b6-84a7-82160c8e6a23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-541173131-172.17.0.10-1595905195758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44678,DS-7053b712-4a63-4f13-acd2-3c99735de39a,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-ff85ce40-b816-45f4-8b32-f0b9cb031d84,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-59350a0c-00db-42a3-a173-44d07adcc982,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-c7169269-8cac-4ab3-9e74-ed6da990d571,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-294dda7c-39c2-4fb9-9102-d39b8946803e,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-e2a63194-634a-4f35-b794-8684e50eb462,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-8a42be1b-afad-4395-b837-d577192b8e96,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-9fd5c90b-7a76-40b6-84a7-82160c8e6a23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-274807591-172.17.0.10-1595905655163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45241,DS-f0de2418-8747-4195-a114-854465db34a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-27b7e00f-fb7d-4b46-80a3-846fe56ccd13,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-79238041-5178-4dd5-9cb1-f05727d930b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-89011b00-c036-4654-b038-92f5e9be45a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-5df79e3f-6fec-4301-81d7-0d6b135be8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-b5629fd8-90c6-4192-a1cd-f80563d8464a,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-c67c2b31-868c-4f74-a12b-975b21b9eb83,DISK], DatanodeInfoWithStorage[127.0.0.1:38630,DS-4c29d8e6-3765-45f4-a3a7-366329deadb7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-274807591-172.17.0.10-1595905655163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45241,DS-f0de2418-8747-4195-a114-854465db34a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-27b7e00f-fb7d-4b46-80a3-846fe56ccd13,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-79238041-5178-4dd5-9cb1-f05727d930b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-89011b00-c036-4654-b038-92f5e9be45a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-5df79e3f-6fec-4301-81d7-0d6b135be8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-b5629fd8-90c6-4192-a1cd-f80563d8464a,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-c67c2b31-868c-4f74-a12b-975b21b9eb83,DISK], DatanodeInfoWithStorage[127.0.0.1:38630,DS-4c29d8e6-3765-45f4-a3a7-366329deadb7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851419472-172.17.0.10-1595905804246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35019,DS-7fe440be-7406-4d2f-9a71-c2f93a8e0b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39489,DS-46a63370-d7d3-4858-bd3f-7e49de4efd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-34ae183b-223e-4d8e-91c2-8cf74e28f336,DISK], DatanodeInfoWithStorage[127.0.0.1:36160,DS-5a02d263-1b16-457d-8991-9dea8fce3ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-648f508d-9287-4fc0-97a5-f4b99e8799e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-7d5582e7-5cce-4e26-a203-4219279fb930,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-aaba90a5-dac5-43a4-a7d1-43e1cf619f26,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-11597c5d-1936-462d-89cb-3ef112be2653,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851419472-172.17.0.10-1595905804246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35019,DS-7fe440be-7406-4d2f-9a71-c2f93a8e0b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39489,DS-46a63370-d7d3-4858-bd3f-7e49de4efd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-34ae183b-223e-4d8e-91c2-8cf74e28f336,DISK], DatanodeInfoWithStorage[127.0.0.1:36160,DS-5a02d263-1b16-457d-8991-9dea8fce3ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-648f508d-9287-4fc0-97a5-f4b99e8799e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-7d5582e7-5cce-4e26-a203-4219279fb930,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-aaba90a5-dac5-43a4-a7d1-43e1cf619f26,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-11597c5d-1936-462d-89cb-3ef112be2653,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1093419356-172.17.0.10-1595905997175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39124,DS-1f98cc9f-16e6-4a59-8f8d-31767c4051c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-bab48a63-f30e-40a3-8b34-e094bbf8305c,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-44f51563-f712-423d-ae51-0b6b746164f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-a064ba12-ef44-4428-95c4-c5c78e63a47b,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-ad533f6c-b145-4ff7-bebe-162971331897,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-3ad02344-b6fa-43f2-b588-726306eee5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-60eae55a-6e7e-4cb3-b33f-70592010c890,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-cc766298-44cb-473e-aa60-e90eee8e2b30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1093419356-172.17.0.10-1595905997175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39124,DS-1f98cc9f-16e6-4a59-8f8d-31767c4051c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-bab48a63-f30e-40a3-8b34-e094bbf8305c,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-44f51563-f712-423d-ae51-0b6b746164f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-a064ba12-ef44-4428-95c4-c5c78e63a47b,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-ad533f6c-b145-4ff7-bebe-162971331897,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-3ad02344-b6fa-43f2-b588-726306eee5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-60eae55a-6e7e-4cb3-b33f-70592010c890,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-cc766298-44cb-473e-aa60-e90eee8e2b30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-142633481-172.17.0.10-1595906078901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34181,DS-e6f03d01-add1-4f41-89c4-f78801f35076,DISK], DatanodeInfoWithStorage[127.0.0.1:34765,DS-1c218fec-b939-49f2-9cdd-efd140a8484d,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-0c7ba9ef-705a-43e8-afa6-0721ee74120d,DISK], DatanodeInfoWithStorage[127.0.0.1:44667,DS-16a0240e-d4e5-4378-9fee-008896cc66fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-e800264e-fc9f-4cfe-866f-d2840d5152e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-55b4c76c-f0c4-4e43-8db3-cf45205a7d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-954a55b8-8ca7-4e1f-b5b7-58d06c1d7915,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-9a79d029-5a36-4e90-9fe3-4e96c09161fa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-142633481-172.17.0.10-1595906078901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34181,DS-e6f03d01-add1-4f41-89c4-f78801f35076,DISK], DatanodeInfoWithStorage[127.0.0.1:34765,DS-1c218fec-b939-49f2-9cdd-efd140a8484d,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-0c7ba9ef-705a-43e8-afa6-0721ee74120d,DISK], DatanodeInfoWithStorage[127.0.0.1:44667,DS-16a0240e-d4e5-4378-9fee-008896cc66fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-e800264e-fc9f-4cfe-866f-d2840d5152e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-55b4c76c-f0c4-4e43-8db3-cf45205a7d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-954a55b8-8ca7-4e1f-b5b7-58d06c1d7915,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-9a79d029-5a36-4e90-9fe3-4e96c09161fa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-337779765-172.17.0.10-1595906117979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40495,DS-f9fa2cc8-ed70-4ac6-922f-f4429fb1b478,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-1241f4d3-f9b5-4218-b84f-b383881b6215,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-038c589b-122f-46ab-9aac-c25a760789d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-fbec2763-d403-40a8-a623-dac3eab8c6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-ccd48c4c-191c-45f5-a298-005dace10482,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-fd3939f5-4abe-4733-8d95-3650ccca8521,DISK], DatanodeInfoWithStorage[127.0.0.1:40891,DS-fa0b5d41-22d9-4dd6-a092-afd6f536cb06,DISK], DatanodeInfoWithStorage[127.0.0.1:43172,DS-7ef9558a-93d0-4c5a-b5a9-634cde3df750,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-337779765-172.17.0.10-1595906117979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40495,DS-f9fa2cc8-ed70-4ac6-922f-f4429fb1b478,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-1241f4d3-f9b5-4218-b84f-b383881b6215,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-038c589b-122f-46ab-9aac-c25a760789d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-fbec2763-d403-40a8-a623-dac3eab8c6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-ccd48c4c-191c-45f5-a298-005dace10482,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-fd3939f5-4abe-4733-8d95-3650ccca8521,DISK], DatanodeInfoWithStorage[127.0.0.1:40891,DS-fa0b5d41-22d9-4dd6-a092-afd6f536cb06,DISK], DatanodeInfoWithStorage[127.0.0.1:43172,DS-7ef9558a-93d0-4c5a-b5a9-634cde3df750,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-374138898-172.17.0.10-1595906452124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36084,DS-c0a3b85d-5cf7-49c9-a757-533d18aa6eff,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-f623b6e6-2b76-40a5-abb7-25539622be38,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-8879c6ef-9813-49cb-b94c-a2342b68c0db,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-c028fb14-e101-42fb-8bae-c005d3a3e30a,DISK], DatanodeInfoWithStorage[127.0.0.1:39734,DS-c98ba253-96ec-4bca-811c-0a0ab39a0745,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-d43027c0-8543-4fe7-873e-1eaef611cf05,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-5763d38e-25dc-4b7f-aa1f-caf16bb50ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-aa12cc4b-bff5-456b-b102-db3016657b21,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-374138898-172.17.0.10-1595906452124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36084,DS-c0a3b85d-5cf7-49c9-a757-533d18aa6eff,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-f623b6e6-2b76-40a5-abb7-25539622be38,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-8879c6ef-9813-49cb-b94c-a2342b68c0db,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-c028fb14-e101-42fb-8bae-c005d3a3e30a,DISK], DatanodeInfoWithStorage[127.0.0.1:39734,DS-c98ba253-96ec-4bca-811c-0a0ab39a0745,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-d43027c0-8543-4fe7-873e-1eaef611cf05,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-5763d38e-25dc-4b7f-aa1f-caf16bb50ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-aa12cc4b-bff5-456b-b102-db3016657b21,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1343496809-172.17.0.10-1595906720450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41737,DS-a93c0e5d-1ce8-45ca-b4dc-a6815bd581a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-606d01a1-3ef1-42b3-9d25-85d94ae188d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-42cad204-2b0c-4670-855a-18126327d0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42026,DS-4bae7cd1-21be-4350-b49a-55abb72d70bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-05818647-b430-401a-a85f-f29624521954,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-bc70e935-6f42-4ad7-b065-33d3039b4859,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-9032adb0-87a1-409a-95d3-7167c9b04f12,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-1388fcaf-d3d2-4515-bf4f-e3b4416da70f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1343496809-172.17.0.10-1595906720450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41737,DS-a93c0e5d-1ce8-45ca-b4dc-a6815bd581a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-606d01a1-3ef1-42b3-9d25-85d94ae188d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-42cad204-2b0c-4670-855a-18126327d0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42026,DS-4bae7cd1-21be-4350-b49a-55abb72d70bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-05818647-b430-401a-a85f-f29624521954,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-bc70e935-6f42-4ad7-b065-33d3039b4859,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-9032adb0-87a1-409a-95d3-7167c9b04f12,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-1388fcaf-d3d2-4515-bf4f-e3b4416da70f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-707623096-172.17.0.10-1595906757586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37319,DS-bbb9e098-72b8-45a6-a867-0a0b442c0a58,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-d1531711-71d9-4727-b682-2030b98928d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39322,DS-aa9f4865-fe69-4e92-b372-891329108ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-cbbc9424-5cf5-4ffc-ba82-596f07d7b729,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-c78af7a0-ece0-42c5-9f0a-dddf90258259,DISK], DatanodeInfoWithStorage[127.0.0.1:46594,DS-097bd540-9e15-4efa-a681-670a8656a6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-6d89bd7b-683b-4f4e-b9d4-06cb93a3368b,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-6d64a1bb-9adb-456d-893e-1388c976029c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-707623096-172.17.0.10-1595906757586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37319,DS-bbb9e098-72b8-45a6-a867-0a0b442c0a58,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-d1531711-71d9-4727-b682-2030b98928d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39322,DS-aa9f4865-fe69-4e92-b372-891329108ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-cbbc9424-5cf5-4ffc-ba82-596f07d7b729,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-c78af7a0-ece0-42c5-9f0a-dddf90258259,DISK], DatanodeInfoWithStorage[127.0.0.1:46594,DS-097bd540-9e15-4efa-a681-670a8656a6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-6d89bd7b-683b-4f4e-b9d4-06cb93a3368b,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-6d64a1bb-9adb-456d-893e-1388c976029c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1491977400-172.17.0.10-1595906825517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43658,DS-d2bd909c-e7e9-415f-bef1-e06831cc089a,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-e67bcfc2-7b2a-40ba-88b0-9b96beebfe3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-6bddc346-7546-46c2-9303-c234eb0a8a54,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-769e36bc-71cb-42c2-ac32-221403e99866,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-8cbd9f71-8939-4da9-a967-a1c5b12725b6,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-639db00f-9eb6-4d29-a6d8-7479c3fdde0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-d84258c2-4643-4e7f-8686-7721bf66aceb,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-8f4a29ff-117d-4030-ab77-8d3b66e06d98,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1491977400-172.17.0.10-1595906825517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43658,DS-d2bd909c-e7e9-415f-bef1-e06831cc089a,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-e67bcfc2-7b2a-40ba-88b0-9b96beebfe3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-6bddc346-7546-46c2-9303-c234eb0a8a54,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-769e36bc-71cb-42c2-ac32-221403e99866,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-8cbd9f71-8939-4da9-a967-a1c5b12725b6,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-639db00f-9eb6-4d29-a6d8-7479c3fdde0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-d84258c2-4643-4e7f-8686-7721bf66aceb,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-8f4a29ff-117d-4030-ab77-8d3b66e06d98,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894911746-172.17.0.10-1595906862978:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45534,DS-4524104a-4183-47e0-9d97-dd8f9b2925aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-9b714eef-7d89-4c2b-b546-2e803cae88ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43051,DS-2c3ef5ea-58ab-4003-b55c-88fd662b76e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-c57243fc-6018-4da2-b720-3da2ba88a3da,DISK], DatanodeInfoWithStorage[127.0.0.1:37249,DS-d0604c96-d998-43d6-b673-a01f709496ff,DISK], DatanodeInfoWithStorage[127.0.0.1:32913,DS-0756465d-9bcd-47d4-82f5-9ef57f67a2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-6ab4bff7-9ca3-4fe6-a6f9-a5499357b347,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-3f71661e-92b5-4654-9604-2245a3520a35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894911746-172.17.0.10-1595906862978:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45534,DS-4524104a-4183-47e0-9d97-dd8f9b2925aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-9b714eef-7d89-4c2b-b546-2e803cae88ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43051,DS-2c3ef5ea-58ab-4003-b55c-88fd662b76e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-c57243fc-6018-4da2-b720-3da2ba88a3da,DISK], DatanodeInfoWithStorage[127.0.0.1:37249,DS-d0604c96-d998-43d6-b673-a01f709496ff,DISK], DatanodeInfoWithStorage[127.0.0.1:32913,DS-0756465d-9bcd-47d4-82f5-9ef57f67a2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-6ab4bff7-9ca3-4fe6-a6f9-a5499357b347,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-3f71661e-92b5-4654-9604-2245a3520a35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1885610250-172.17.0.10-1595906927933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34936,DS-5907a964-f4a0-4d8f-ab7e-e3568761b15d,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-85c10b76-3aaa-4224-ad17-b923f035cf6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-db17181d-8e43-4df9-86c1-d6dee85fe17f,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-73bb2976-b085-4ce5-ba2d-d59c0407b843,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-671e7a0b-d5db-4230-81d3-8ed2ce4d0cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-3c65ba60-14a2-4810-9998-96593add2dde,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-1abc34c3-9fa6-4b58-8dc5-659cbcd8324e,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-334d919f-f31c-465c-913b-e6d2236125ac,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1885610250-172.17.0.10-1595906927933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34936,DS-5907a964-f4a0-4d8f-ab7e-e3568761b15d,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-85c10b76-3aaa-4224-ad17-b923f035cf6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-db17181d-8e43-4df9-86c1-d6dee85fe17f,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-73bb2976-b085-4ce5-ba2d-d59c0407b843,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-671e7a0b-d5db-4230-81d3-8ed2ce4d0cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-3c65ba60-14a2-4810-9998-96593add2dde,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-1abc34c3-9fa6-4b58-8dc5-659cbcd8324e,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-334d919f-f31c-465c-913b-e6d2236125ac,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-770878125-172.17.0.10-1595906962253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34599,DS-bb159ed0-a74f-4ee3-9d19-9ccdc16bf851,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-0c982c7c-6a61-43e8-8d62-b856b3b46fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-1ccf378f-1aa0-416b-9f9a-5e13ae7581d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-9845a347-f6b1-46d8-979d-f5ffc3382b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-5de5a06b-b227-4b78-b193-0c65a1c049d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-4ace8942-1e3e-49f4-b850-8fd0ad0207c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-3bee3a31-54a0-490a-afd6-fae5e2b3d013,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-446330d7-5e20-474b-8027-a581c2393ed7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-770878125-172.17.0.10-1595906962253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34599,DS-bb159ed0-a74f-4ee3-9d19-9ccdc16bf851,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-0c982c7c-6a61-43e8-8d62-b856b3b46fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-1ccf378f-1aa0-416b-9f9a-5e13ae7581d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-9845a347-f6b1-46d8-979d-f5ffc3382b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-5de5a06b-b227-4b78-b193-0c65a1c049d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-4ace8942-1e3e-49f4-b850-8fd0ad0207c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-3bee3a31-54a0-490a-afd6-fae5e2b3d013,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-446330d7-5e20-474b-8027-a581c2393ed7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-515468171-172.17.0.10-1595907000092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41457,DS-7272b582-8cee-4ed1-b400-db8ef219013d,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-f3f92c14-c9d5-4dd8-8144-711635858e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-d1e2982b-ccdb-4efc-b290-fd35913fd944,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-04d2bae0-858e-42cf-ab06-c3dc3a9c69fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46795,DS-3db467ae-0715-4c4e-ac95-ca40932d64b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-adaef586-68af-4023-95b1-14e6d973ae23,DISK], DatanodeInfoWithStorage[127.0.0.1:44795,DS-fb7aea17-2aca-4a78-9301-7aeae9b9dd8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-8f32a171-fdf1-448f-a01e-ca528e371590,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-515468171-172.17.0.10-1595907000092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41457,DS-7272b582-8cee-4ed1-b400-db8ef219013d,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-f3f92c14-c9d5-4dd8-8144-711635858e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-d1e2982b-ccdb-4efc-b290-fd35913fd944,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-04d2bae0-858e-42cf-ab06-c3dc3a9c69fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46795,DS-3db467ae-0715-4c4e-ac95-ca40932d64b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-adaef586-68af-4023-95b1-14e6d973ae23,DISK], DatanodeInfoWithStorage[127.0.0.1:44795,DS-fb7aea17-2aca-4a78-9301-7aeae9b9dd8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-8f32a171-fdf1-448f-a01e-ca528e371590,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-160373758-172.17.0.10-1595907585729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33402,DS-cb2b6e56-b21d-4c10-92e2-9cf78b43cb12,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-db5032f5-1b8c-43f7-be0c-04d88936b168,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-0fc9ed9f-11ff-40e6-9571-6df307bc59a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-658edc59-35d5-474c-bc75-11d65548edb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-86dbec81-5e7c-4109-a041-47d6aeb8f51a,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-5553e084-e5f7-439f-ba3d-d37e312b5196,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-81ed3b89-15e9-4fe5-a551-948db4752d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-2e96f122-0298-46d3-9eb6-25a97ae51286,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-160373758-172.17.0.10-1595907585729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33402,DS-cb2b6e56-b21d-4c10-92e2-9cf78b43cb12,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-db5032f5-1b8c-43f7-be0c-04d88936b168,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-0fc9ed9f-11ff-40e6-9571-6df307bc59a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-658edc59-35d5-474c-bc75-11d65548edb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-86dbec81-5e7c-4109-a041-47d6aeb8f51a,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-5553e084-e5f7-439f-ba3d-d37e312b5196,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-81ed3b89-15e9-4fe5-a551-948db4752d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-2e96f122-0298-46d3-9eb6-25a97ae51286,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2000778704-172.17.0.10-1595907738436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33217,DS-407746b8-63bc-48b7-8905-ae03ec533e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-969ccff9-a16f-4dc0-a6e6-c8da4e5b0428,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-3873d5bb-1339-4420-8a9d-09b74bc440c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-db10b68c-45b8-4caf-981f-847a836f1d20,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-2a86e8ca-c989-49d8-9466-5d4c562c19fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-0a596eb9-60a3-48e6-bc8a-42ef1482191e,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-e5daa9ef-18c5-4fce-bae9-80ebf5e0a2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-ae39404e-e6bc-46c4-abf3-3342643595ba,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2000778704-172.17.0.10-1595907738436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33217,DS-407746b8-63bc-48b7-8905-ae03ec533e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-969ccff9-a16f-4dc0-a6e6-c8da4e5b0428,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-3873d5bb-1339-4420-8a9d-09b74bc440c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-db10b68c-45b8-4caf-981f-847a836f1d20,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-2a86e8ca-c989-49d8-9466-5d4c562c19fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-0a596eb9-60a3-48e6-bc8a-42ef1482191e,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-e5daa9ef-18c5-4fce-bae9-80ebf5e0a2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-ae39404e-e6bc-46c4-abf3-3342643595ba,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1377896589-172.17.0.10-1595907972853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34522,DS-a7804ed7-eba3-4097-8333-05953fe7e8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-abcdefd4-3135-48ba-a4a4-3df935dab3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-3d6e552c-3faa-472c-a45e-63a52e0ca1ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-e0709084-5175-4e83-9494-a7b1c2f139ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-d00b5dd2-1099-4702-9a3a-5cef786635c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-07abf162-93af-4188-b91c-67761a7ee143,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-a9dc92a2-4c0d-4e0c-8541-2eddc5ce1a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-554eaa6b-df5b-49a3-95f8-a95d110d5e1f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1377896589-172.17.0.10-1595907972853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34522,DS-a7804ed7-eba3-4097-8333-05953fe7e8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-abcdefd4-3135-48ba-a4a4-3df935dab3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-3d6e552c-3faa-472c-a45e-63a52e0ca1ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-e0709084-5175-4e83-9494-a7b1c2f139ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-d00b5dd2-1099-4702-9a3a-5cef786635c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-07abf162-93af-4188-b91c-67761a7ee143,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-a9dc92a2-4c0d-4e0c-8541-2eddc5ce1a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-554eaa6b-df5b-49a3-95f8-a95d110d5e1f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879757187-172.17.0.10-1595908198624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41539,DS-5be4d8ff-7a80-4f2b-9795-1fe5901815de,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-e040e8ed-71a1-43a2-b09d-50511e5f4efb,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-38db974d-ac5a-4813-8e64-1fc1156069e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-33c820fd-6e9e-486f-be48-479c87822544,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-5d163fb1-698e-4e51-95a8-2ab3643a3873,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-2a2c289a-1b3f-4f5e-9e5a-ce84d3ada99d,DISK], DatanodeInfoWithStorage[127.0.0.1:33508,DS-41a98806-8efd-4f87-a3fa-2db3cd2df148,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-65baf875-693b-4afa-8fba-e14dc3a0af1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879757187-172.17.0.10-1595908198624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41539,DS-5be4d8ff-7a80-4f2b-9795-1fe5901815de,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-e040e8ed-71a1-43a2-b09d-50511e5f4efb,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-38db974d-ac5a-4813-8e64-1fc1156069e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-33c820fd-6e9e-486f-be48-479c87822544,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-5d163fb1-698e-4e51-95a8-2ab3643a3873,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-2a2c289a-1b3f-4f5e-9e5a-ce84d3ada99d,DISK], DatanodeInfoWithStorage[127.0.0.1:33508,DS-41a98806-8efd-4f87-a3fa-2db3cd2df148,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-65baf875-693b-4afa-8fba-e14dc3a0af1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-848211441-172.17.0.10-1595908687062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40511,DS-d5b1b157-9dfb-4d57-aecf-5183c1558d81,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-e16bb60e-31d3-4e0e-8fa2-fd9fcc91d01f,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-0da642a2-4160-4c2d-a65a-04bd62de881c,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-d5c7c9f6-ba12-49f6-a326-2561fdfe0abb,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-6051b641-49b8-4036-98fa-d397ecd59420,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-99a970eb-6f66-41f7-bae3-8113c78f4544,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-06409c8f-3577-4a3e-902d-3bbbf8c5ce0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46388,DS-69e95189-7b24-4ddf-bd97-b4a06409673b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-848211441-172.17.0.10-1595908687062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40511,DS-d5b1b157-9dfb-4d57-aecf-5183c1558d81,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-e16bb60e-31d3-4e0e-8fa2-fd9fcc91d01f,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-0da642a2-4160-4c2d-a65a-04bd62de881c,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-d5c7c9f6-ba12-49f6-a326-2561fdfe0abb,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-6051b641-49b8-4036-98fa-d397ecd59420,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-99a970eb-6f66-41f7-bae3-8113c78f4544,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-06409c8f-3577-4a3e-902d-3bbbf8c5ce0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46388,DS-69e95189-7b24-4ddf-bd97-b4a06409673b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-134597594-172.17.0.10-1595908833583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38497,DS-f3014e9c-0aaa-4ae9-9fcb-1d3fb1e0a6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46155,DS-967dcf5e-dce0-4f2a-8fd6-3a8cb0218372,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-933d9928-4266-4de8-b99b-9fe8b251035e,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-b65bfdcc-1c09-43c4-a3ee-a32251b6e0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-ea7150d6-c7f4-433a-9b34-bc27dd6f00e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-ff153867-aa70-4eac-8d0d-5dae1cbe8892,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-5256136e-c440-4d81-a8b1-2766322878ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-ca19e84e-441b-4c72-87a3-f592426e3ca0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-134597594-172.17.0.10-1595908833583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38497,DS-f3014e9c-0aaa-4ae9-9fcb-1d3fb1e0a6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46155,DS-967dcf5e-dce0-4f2a-8fd6-3a8cb0218372,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-933d9928-4266-4de8-b99b-9fe8b251035e,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-b65bfdcc-1c09-43c4-a3ee-a32251b6e0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-ea7150d6-c7f4-433a-9b34-bc27dd6f00e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-ff153867-aa70-4eac-8d0d-5dae1cbe8892,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-5256136e-c440-4d81-a8b1-2766322878ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-ca19e84e-441b-4c72-87a3-f592426e3ca0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-607239794-172.17.0.10-1595909119825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39457,DS-8b99e9c0-754b-4fbb-aa79-7e9f2c7e93ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-8e960597-072f-47b2-bcc6-66d8d8a3876f,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-e371cc3e-1210-4a57-97ed-6ebcbb2886e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-d790991f-e3c8-469b-a1d7-b8d0a5d75ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-e51feff0-d194-43df-9795-0491af8b04ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-81f6f8f9-f790-45c7-b8f9-a4fcec8172f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-ca8136ae-8e7b-421f-a5cb-37e34eda6207,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-57990476-23b1-439a-a932-5a3f25b1f9c1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-607239794-172.17.0.10-1595909119825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39457,DS-8b99e9c0-754b-4fbb-aa79-7e9f2c7e93ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-8e960597-072f-47b2-bcc6-66d8d8a3876f,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-e371cc3e-1210-4a57-97ed-6ebcbb2886e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-d790991f-e3c8-469b-a1d7-b8d0a5d75ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-e51feff0-d194-43df-9795-0491af8b04ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-81f6f8f9-f790-45c7-b8f9-a4fcec8172f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-ca8136ae-8e7b-421f-a5cb-37e34eda6207,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-57990476-23b1-439a-a932-5a3f25b1f9c1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1729456165-172.17.0.10-1595909373905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36829,DS-c444448f-9b01-4327-a92e-282c52b1304f,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-6b5608fa-f874-449e-9626-18c8a89c391f,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-fe518178-fec0-4d89-95f5-005ac0af49e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-8a1d78d7-dbaa-491d-8cc9-5b18f3478d17,DISK], DatanodeInfoWithStorage[127.0.0.1:45532,DS-b31b0457-9851-4b08-b8b6-2d21092ce4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-f5fe266f-2feb-43da-85f1-9e92b0155055,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-54866938-dbcf-4dde-bd6b-33a38f0da310,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-78caa204-3115-4979-87e8-b11782af5162,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1729456165-172.17.0.10-1595909373905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36829,DS-c444448f-9b01-4327-a92e-282c52b1304f,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-6b5608fa-f874-449e-9626-18c8a89c391f,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-fe518178-fec0-4d89-95f5-005ac0af49e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-8a1d78d7-dbaa-491d-8cc9-5b18f3478d17,DISK], DatanodeInfoWithStorage[127.0.0.1:45532,DS-b31b0457-9851-4b08-b8b6-2d21092ce4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-f5fe266f-2feb-43da-85f1-9e92b0155055,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-54866938-dbcf-4dde-bd6b-33a38f0da310,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-78caa204-3115-4979-87e8-b11782af5162,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2044544445-172.17.0.10-1595909472660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45755,DS-c531c137-8359-435d-be3d-72f203406cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-120d319a-ad88-40b6-815b-98c1a5ae56bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-7d354551-4a10-440e-9b36-3b37c5925bae,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-305ba19d-953d-48aa-abba-60fce16f718d,DISK], DatanodeInfoWithStorage[127.0.0.1:42638,DS-935e2706-e581-485d-8914-df22fa15993b,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-d86bf4f6-8c6d-4dc4-80a6-2468ea970e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-5c12a58b-1fe5-4c89-83f2-bce225c439c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-689b4b52-8b6a-42d7-90e2-8960f5f1206d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2044544445-172.17.0.10-1595909472660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45755,DS-c531c137-8359-435d-be3d-72f203406cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-120d319a-ad88-40b6-815b-98c1a5ae56bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-7d354551-4a10-440e-9b36-3b37c5925bae,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-305ba19d-953d-48aa-abba-60fce16f718d,DISK], DatanodeInfoWithStorage[127.0.0.1:42638,DS-935e2706-e581-485d-8914-df22fa15993b,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-d86bf4f6-8c6d-4dc4-80a6-2468ea970e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-5c12a58b-1fe5-4c89-83f2-bce225c439c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-689b4b52-8b6a-42d7-90e2-8960f5f1206d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-336500796-172.17.0.10-1595909504431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41081,DS-55861a77-2848-4507-8471-76c3e4641ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:37095,DS-46d09051-149b-4cab-9c3a-9b25015ef0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-557fb51d-f716-4595-9133-56e4834d0089,DISK], DatanodeInfoWithStorage[127.0.0.1:34343,DS-11d1754b-3309-4a2c-a61d-1ec09bd0243b,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-62d931fb-b612-47ec-8c7b-2bf98a81dddd,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-90c575da-692d-430d-a953-98d2e71a6538,DISK], DatanodeInfoWithStorage[127.0.0.1:43164,DS-e8113ebc-2a47-406b-a033-53ae61ab513c,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-cc3864e9-7281-4bb2-8357-aada7aac8bfa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-336500796-172.17.0.10-1595909504431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41081,DS-55861a77-2848-4507-8471-76c3e4641ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:37095,DS-46d09051-149b-4cab-9c3a-9b25015ef0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-557fb51d-f716-4595-9133-56e4834d0089,DISK], DatanodeInfoWithStorage[127.0.0.1:34343,DS-11d1754b-3309-4a2c-a61d-1ec09bd0243b,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-62d931fb-b612-47ec-8c7b-2bf98a81dddd,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-90c575da-692d-430d-a953-98d2e71a6538,DISK], DatanodeInfoWithStorage[127.0.0.1:43164,DS-e8113ebc-2a47-406b-a033-53ae61ab513c,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-cc3864e9-7281-4bb2-8357-aada7aac8bfa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1952891201-172.17.0.10-1595909616721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43268,DS-dc8ea639-649e-44ca-be3c-ff109b8de9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-650b745c-9bdd-41de-8ade-6aa343dce07b,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-c4817971-b2ec-4e1e-9631-bcf17033d2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-f1e58233-29ef-483c-8ecc-16daf4840776,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-3dbf6bf1-684b-4c64-b472-c3e34593e81a,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-3a88b870-ca32-4dfd-9bd6-83742dd32252,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-818e25d7-4f92-40af-ac75-d71750d37977,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-ce8351e3-6765-4891-a852-22a8afc80ef5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1952891201-172.17.0.10-1595909616721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43268,DS-dc8ea639-649e-44ca-be3c-ff109b8de9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-650b745c-9bdd-41de-8ade-6aa343dce07b,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-c4817971-b2ec-4e1e-9631-bcf17033d2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-f1e58233-29ef-483c-8ecc-16daf4840776,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-3dbf6bf1-684b-4c64-b472-c3e34593e81a,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-3a88b870-ca32-4dfd-9bd6-83742dd32252,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-818e25d7-4f92-40af-ac75-d71750d37977,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-ce8351e3-6765-4891-a852-22a8afc80ef5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-688760932-172.17.0.10-1595909944936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36967,DS-034565c9-d3a4-4ed7-9a33-80c6caffaa63,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-874994ec-5467-456a-8df2-c596998793b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-d0d7811a-d48b-4a91-a569-c0c99b62ea0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35116,DS-f9f7cdcb-ccf9-4b66-b0f5-cdc6e6d1bd34,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-9cecd9ee-5a02-40ff-8ba6-6275b32fa874,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-2a67a83b-bf85-4503-b72e-f0967b06383a,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-89b36836-345b-42ce-9c9b-68aa0904c50b,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-2e35d3ba-8e6f-4a3e-b854-9d5ed7cb0f25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-688760932-172.17.0.10-1595909944936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36967,DS-034565c9-d3a4-4ed7-9a33-80c6caffaa63,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-874994ec-5467-456a-8df2-c596998793b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-d0d7811a-d48b-4a91-a569-c0c99b62ea0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35116,DS-f9f7cdcb-ccf9-4b66-b0f5-cdc6e6d1bd34,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-9cecd9ee-5a02-40ff-8ba6-6275b32fa874,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-2a67a83b-bf85-4503-b72e-f0967b06383a,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-89b36836-345b-42ce-9c9b-68aa0904c50b,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-2e35d3ba-8e6f-4a3e-b854-9d5ed7cb0f25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1374658561-172.17.0.10-1595909982975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35215,DS-fb4de668-67b0-44f0-b0d0-11b2132c6184,DISK], DatanodeInfoWithStorage[127.0.0.1:35686,DS-1aec8f67-baa9-4827-94bd-9db8cba776f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40025,DS-d67cd2e4-c0f5-4837-ab12-16bb5a175616,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-eab99e0f-69ac-4cef-b059-f82c43e2a80c,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-2dd25aec-e85c-4120-9ba4-c2f6e9dc3c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-61cbe431-fac3-4dfa-9d0d-4a01c2d433ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43386,DS-50338266-2a83-4150-9fd1-5b6d3bc9ed83,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-bb30e278-2e9c-4543-941f-79a390c6a214,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1374658561-172.17.0.10-1595909982975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35215,DS-fb4de668-67b0-44f0-b0d0-11b2132c6184,DISK], DatanodeInfoWithStorage[127.0.0.1:35686,DS-1aec8f67-baa9-4827-94bd-9db8cba776f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40025,DS-d67cd2e4-c0f5-4837-ab12-16bb5a175616,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-eab99e0f-69ac-4cef-b059-f82c43e2a80c,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-2dd25aec-e85c-4120-9ba4-c2f6e9dc3c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-61cbe431-fac3-4dfa-9d0d-4a01c2d433ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43386,DS-50338266-2a83-4150-9fd1-5b6d3bc9ed83,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-bb30e278-2e9c-4543-941f-79a390c6a214,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 18 out of 50
result: false positive !!!
Total execution time in seconds : 5499
