reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1999443675-172.17.0.15-1595842326983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33644,DS-e3803589-5246-45e2-ae30-0ac60d0000ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-cd8160d3-6517-4cad-8905-26ac4b2db489,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-43b7eee0-affd-443e-8ad7-f22a87debceb,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-6c0159a5-5a4e-4de7-b318-5da9efd073a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34894,DS-5ea31733-0f73-4b0a-94a7-c1150c19344a,DISK], DatanodeInfoWithStorage[127.0.0.1:42282,DS-392ae235-0187-4556-a061-5ef3b968c4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-a047d4f7-3f29-4787-a2b1-d925a280c068,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-413e31a4-de54-4395-8891-691b9461ed6d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1999443675-172.17.0.15-1595842326983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33644,DS-e3803589-5246-45e2-ae30-0ac60d0000ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-cd8160d3-6517-4cad-8905-26ac4b2db489,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-43b7eee0-affd-443e-8ad7-f22a87debceb,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-6c0159a5-5a4e-4de7-b318-5da9efd073a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34894,DS-5ea31733-0f73-4b0a-94a7-c1150c19344a,DISK], DatanodeInfoWithStorage[127.0.0.1:42282,DS-392ae235-0187-4556-a061-5ef3b968c4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-a047d4f7-3f29-4787-a2b1-d925a280c068,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-413e31a4-de54-4395-8891-691b9461ed6d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-660337506-172.17.0.15-1595842638707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38530,DS-f11e604c-5832-487a-8763-71371d9e1a79,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-71a07c5b-338f-4dd9-a503-cd66cad92742,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-8693f371-71af-4af8-bf5d-b1e66f7d7e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-e6d0249e-288a-448c-84fb-d04d74c4bb95,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-81978c9a-70c3-4503-ba15-d409fac1ef1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-aabc5f49-ede6-43e0-bc82-883b4f742b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-94b95c71-bfa7-4925-a979-e800590f1931,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-fb616f11-8f8c-464a-85bc-05c6d8dc191b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-660337506-172.17.0.15-1595842638707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38530,DS-f11e604c-5832-487a-8763-71371d9e1a79,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-71a07c5b-338f-4dd9-a503-cd66cad92742,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-8693f371-71af-4af8-bf5d-b1e66f7d7e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-e6d0249e-288a-448c-84fb-d04d74c4bb95,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-81978c9a-70c3-4503-ba15-d409fac1ef1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-aabc5f49-ede6-43e0-bc82-883b4f742b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-94b95c71-bfa7-4925-a979-e800590f1931,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-fb616f11-8f8c-464a-85bc-05c6d8dc191b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2000374955-172.17.0.15-1595842822157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44643,DS-256f8eff-f0e4-4ce2-96e3-55561ab40cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33254,DS-e82b9d10-c60e-4a28-b50f-76f3db14a231,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-5352c758-60c0-4286-9b64-0cc649dd241c,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-2ae7e373-a6c2-4b99-841c-f9ff22d3d614,DISK], DatanodeInfoWithStorage[127.0.0.1:37250,DS-577dbd48-e39c-4f96-860d-47a044058131,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-7a09ba0f-4417-4fd5-8697-cd0432ea6a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-991dd9ef-a427-4ae1-a8e7-848b3cc69f03,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-a0fe484f-3898-496d-940f-dd82e8552f7e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2000374955-172.17.0.15-1595842822157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44643,DS-256f8eff-f0e4-4ce2-96e3-55561ab40cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33254,DS-e82b9d10-c60e-4a28-b50f-76f3db14a231,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-5352c758-60c0-4286-9b64-0cc649dd241c,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-2ae7e373-a6c2-4b99-841c-f9ff22d3d614,DISK], DatanodeInfoWithStorage[127.0.0.1:37250,DS-577dbd48-e39c-4f96-860d-47a044058131,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-7a09ba0f-4417-4fd5-8697-cd0432ea6a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-991dd9ef-a427-4ae1-a8e7-848b3cc69f03,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-a0fe484f-3898-496d-940f-dd82e8552f7e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1864950623-172.17.0.15-1595843092015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43839,DS-8abff4a8-1401-4ad6-b778-91c7513f8565,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-ec11553c-fdca-47c8-b1f2-af3ae766c8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-b00489c4-f5e8-457c-943a-527f9c0abeec,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-0fa0bef0-2cd4-46a8-a0eb-16e2b2b5f7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-d7f0b9c4-b3bc-42dc-aa05-3a3a38fa51c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34921,DS-75b7a815-7caa-478e-85aa-9893cec89358,DISK], DatanodeInfoWithStorage[127.0.0.1:37585,DS-6df14a13-7195-4409-9b0f-eb4fc5232720,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-ae8e4f77-3f75-4165-895b-618a2b1db2a3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1864950623-172.17.0.15-1595843092015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43839,DS-8abff4a8-1401-4ad6-b778-91c7513f8565,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-ec11553c-fdca-47c8-b1f2-af3ae766c8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-b00489c4-f5e8-457c-943a-527f9c0abeec,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-0fa0bef0-2cd4-46a8-a0eb-16e2b2b5f7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-d7f0b9c4-b3bc-42dc-aa05-3a3a38fa51c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34921,DS-75b7a815-7caa-478e-85aa-9893cec89358,DISK], DatanodeInfoWithStorage[127.0.0.1:37585,DS-6df14a13-7195-4409-9b0f-eb4fc5232720,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-ae8e4f77-3f75-4165-895b-618a2b1db2a3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700927757-172.17.0.15-1595843156504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35114,DS-3a29762f-836a-484d-b01b-38e3ec59e68d,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-2c847f83-b777-470b-89f2-6cdec7216fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-dd52c83c-3be7-4451-b737-932c632982e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-b63ff90a-5af3-44bc-9906-9cccf58e7869,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-0436b16b-6a36-4f32-b56b-527626771796,DISK], DatanodeInfoWithStorage[127.0.0.1:42824,DS-28bbef0e-4797-45bb-a0f5-584ce2a85854,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-df75c3f8-d334-43de-a2ec-e4fb79a4d171,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-3158134e-2731-4de6-ab1c-23bcca9a95f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700927757-172.17.0.15-1595843156504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35114,DS-3a29762f-836a-484d-b01b-38e3ec59e68d,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-2c847f83-b777-470b-89f2-6cdec7216fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-dd52c83c-3be7-4451-b737-932c632982e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-b63ff90a-5af3-44bc-9906-9cccf58e7869,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-0436b16b-6a36-4f32-b56b-527626771796,DISK], DatanodeInfoWithStorage[127.0.0.1:42824,DS-28bbef0e-4797-45bb-a0f5-584ce2a85854,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-df75c3f8-d334-43de-a2ec-e4fb79a4d171,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-3158134e-2731-4de6-ab1c-23bcca9a95f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1632259958-172.17.0.15-1595843441455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45194,DS-37702a7f-6526-45d6-84ef-281be30e0be7,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-d199856c-8df2-46df-a03d-001108a8d141,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-54917ca6-044d-45f8-8dee-405535436b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-1659e991-2520-4eab-811d-c0c74696f71a,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-c0d018a6-2aa5-4ecd-b35c-ff25be05a362,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-18877c9e-f32e-4f81-a088-c9045e141a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-0bedc96d-6722-4dbe-92b8-9d978d729665,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-cae44400-af6b-45be-a12a-16effe86bcef,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1632259958-172.17.0.15-1595843441455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45194,DS-37702a7f-6526-45d6-84ef-281be30e0be7,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-d199856c-8df2-46df-a03d-001108a8d141,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-54917ca6-044d-45f8-8dee-405535436b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-1659e991-2520-4eab-811d-c0c74696f71a,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-c0d018a6-2aa5-4ecd-b35c-ff25be05a362,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-18877c9e-f32e-4f81-a088-c9045e141a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-0bedc96d-6722-4dbe-92b8-9d978d729665,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-cae44400-af6b-45be-a12a-16effe86bcef,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-55389667-172.17.0.15-1595843676300:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38700,DS-596d2af5-750b-400a-baae-6b885fd7e066,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-52eaf786-7437-40d6-a34f-65d4d02776c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-0fc8459e-efd3-49eb-90f7-78f5902c9228,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-d736dba9-4390-4424-a9a4-45f4c8a6a9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-4965c89b-0b3c-4396-977d-41106bf750cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-16b47bad-920a-466b-8234-e3cc537c373d,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-d8358616-c0a8-45d2-a6de-824754752328,DISK], DatanodeInfoWithStorage[127.0.0.1:40470,DS-504c33c3-4a87-4a18-95d4-a3c70264a12c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-55389667-172.17.0.15-1595843676300:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38700,DS-596d2af5-750b-400a-baae-6b885fd7e066,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-52eaf786-7437-40d6-a34f-65d4d02776c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-0fc8459e-efd3-49eb-90f7-78f5902c9228,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-d736dba9-4390-4424-a9a4-45f4c8a6a9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-4965c89b-0b3c-4396-977d-41106bf750cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-16b47bad-920a-466b-8234-e3cc537c373d,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-d8358616-c0a8-45d2-a6de-824754752328,DISK], DatanodeInfoWithStorage[127.0.0.1:40470,DS-504c33c3-4a87-4a18-95d4-a3c70264a12c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1613625073-172.17.0.15-1595843891801:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46867,DS-b757bcf8-55ee-467b-8953-7d361fb2b56c,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-311c5e62-05c5-46e6-bfaf-3315eef16d44,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-5e6686d8-ca3d-437c-b605-b50fe449c121,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-aa395b44-8761-446d-9403-7246d1e83b96,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-2c741f75-3b97-49bd-aa6c-77078d19997c,DISK], DatanodeInfoWithStorage[127.0.0.1:45786,DS-cfffb647-5373-4835-ab43-8b7fd7f8eda2,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-84d00d98-0c87-4f58-8909-6c9878ac640e,DISK], DatanodeInfoWithStorage[127.0.0.1:43915,DS-d7a1fa46-c4f4-4780-b1f1-4ad42b9d58f9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1613625073-172.17.0.15-1595843891801:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46867,DS-b757bcf8-55ee-467b-8953-7d361fb2b56c,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-311c5e62-05c5-46e6-bfaf-3315eef16d44,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-5e6686d8-ca3d-437c-b605-b50fe449c121,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-aa395b44-8761-446d-9403-7246d1e83b96,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-2c741f75-3b97-49bd-aa6c-77078d19997c,DISK], DatanodeInfoWithStorage[127.0.0.1:45786,DS-cfffb647-5373-4835-ab43-8b7fd7f8eda2,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-84d00d98-0c87-4f58-8909-6c9878ac640e,DISK], DatanodeInfoWithStorage[127.0.0.1:43915,DS-d7a1fa46-c4f4-4780-b1f1-4ad42b9d58f9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-145038886-172.17.0.15-1595843961070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46783,DS-1ecd4183-f45f-42aa-a488-daadee395d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-c4115e02-f6be-48e2-ad9c-e3a36bdc7842,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-6f5e4069-0faf-418c-9597-e14efc962ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-5b10ded6-015d-42ed-a914-7c4ab5ad28a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-c563751c-024a-4772-90d9-216921db5e08,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-f40ac39e-b03b-4b71-9dc2-95e0bf1e4057,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-af289b91-f4da-4204-a454-d29863a7657a,DISK], DatanodeInfoWithStorage[127.0.0.1:40346,DS-22c4bffd-cd71-4dd0-9138-7994e09230a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-145038886-172.17.0.15-1595843961070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46783,DS-1ecd4183-f45f-42aa-a488-daadee395d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-c4115e02-f6be-48e2-ad9c-e3a36bdc7842,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-6f5e4069-0faf-418c-9597-e14efc962ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-5b10ded6-015d-42ed-a914-7c4ab5ad28a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-c563751c-024a-4772-90d9-216921db5e08,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-f40ac39e-b03b-4b71-9dc2-95e0bf1e4057,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-af289b91-f4da-4204-a454-d29863a7657a,DISK], DatanodeInfoWithStorage[127.0.0.1:40346,DS-22c4bffd-cd71-4dd0-9138-7994e09230a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-579862676-172.17.0.15-1595844169906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32777,DS-8effac15-db3e-4ae8-8472-8a2a3e6147d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-4366bad7-6dd7-4576-b0dd-ac1229c46783,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-ea18f13e-0924-4483-b595-268d56316ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-1562cb8d-201a-48c2-b53c-5659b194f7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-730c8145-5058-4c16-8404-da1aacafc72d,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-2061ec42-da49-4340-aff7-4a02de9d8081,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-8647ead0-d121-4864-988a-8226c205efda,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-b7fe5dad-215b-4ee3-a882-101871fa3d1c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-579862676-172.17.0.15-1595844169906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32777,DS-8effac15-db3e-4ae8-8472-8a2a3e6147d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-4366bad7-6dd7-4576-b0dd-ac1229c46783,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-ea18f13e-0924-4483-b595-268d56316ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-1562cb8d-201a-48c2-b53c-5659b194f7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-730c8145-5058-4c16-8404-da1aacafc72d,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-2061ec42-da49-4340-aff7-4a02de9d8081,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-8647ead0-d121-4864-988a-8226c205efda,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-b7fe5dad-215b-4ee3-a882-101871fa3d1c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1940494534-172.17.0.15-1595844241820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39965,DS-53527804-40e3-45eb-b70f-c65e4b65cbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-66376db3-b9da-457c-9450-5b6b812adf50,DISK], DatanodeInfoWithStorage[127.0.0.1:35303,DS-d9c8792e-06b2-4735-b875-863fdf93f577,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-0aa3a387-d33c-48e1-8ec9-d9c5304f7440,DISK], DatanodeInfoWithStorage[127.0.0.1:41974,DS-88aa3f56-505a-4099-b82c-f5b1d1ba580b,DISK], DatanodeInfoWithStorage[127.0.0.1:44255,DS-6e590c97-18dd-4b6b-aca6-04507ad02525,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-cffd8b5a-91bc-428e-b12f-723c10b03d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43262,DS-388d033d-7397-4ef5-879d-c58692696f7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1940494534-172.17.0.15-1595844241820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39965,DS-53527804-40e3-45eb-b70f-c65e4b65cbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-66376db3-b9da-457c-9450-5b6b812adf50,DISK], DatanodeInfoWithStorage[127.0.0.1:35303,DS-d9c8792e-06b2-4735-b875-863fdf93f577,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-0aa3a387-d33c-48e1-8ec9-d9c5304f7440,DISK], DatanodeInfoWithStorage[127.0.0.1:41974,DS-88aa3f56-505a-4099-b82c-f5b1d1ba580b,DISK], DatanodeInfoWithStorage[127.0.0.1:44255,DS-6e590c97-18dd-4b6b-aca6-04507ad02525,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-cffd8b5a-91bc-428e-b12f-723c10b03d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43262,DS-388d033d-7397-4ef5-879d-c58692696f7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2027731297-172.17.0.15-1595844475040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39729,DS-a9e8043a-582b-4586-ab91-c4900b192277,DISK], DatanodeInfoWithStorage[127.0.0.1:35688,DS-68f5ea95-a9c5-4e82-b072-41e58820442e,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-9f20ebc2-e70d-4a7f-902a-09f8c7e4bd47,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-b224e35a-b734-4db9-9d83-528f1c90c1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-9e07fd3b-7a5d-475e-b335-ede58dac50ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-172f3eb9-a92e-464c-94e9-578587e9ec39,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-d92d083d-aee5-4ab3-9ec4-6971e2eef79f,DISK], DatanodeInfoWithStorage[127.0.0.1:33291,DS-ca5509bc-7c7b-425f-a38c-08258da1bd88,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2027731297-172.17.0.15-1595844475040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39729,DS-a9e8043a-582b-4586-ab91-c4900b192277,DISK], DatanodeInfoWithStorage[127.0.0.1:35688,DS-68f5ea95-a9c5-4e82-b072-41e58820442e,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-9f20ebc2-e70d-4a7f-902a-09f8c7e4bd47,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-b224e35a-b734-4db9-9d83-528f1c90c1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-9e07fd3b-7a5d-475e-b335-ede58dac50ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-172f3eb9-a92e-464c-94e9-578587e9ec39,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-d92d083d-aee5-4ab3-9ec4-6971e2eef79f,DISK], DatanodeInfoWithStorage[127.0.0.1:33291,DS-ca5509bc-7c7b-425f-a38c-08258da1bd88,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1239195331-172.17.0.15-1595844647276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42636,DS-8cf1d1d8-9d0b-4824-ac26-38cda5668842,DISK], DatanodeInfoWithStorage[127.0.0.1:46205,DS-15844188-8d61-4aab-a3c9-b741555ff9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-3abc5e6b-1508-44c4-bbd9-7e299b86a284,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-d6c589d9-845a-4446-baf8-6fcc99f71be8,DISK], DatanodeInfoWithStorage[127.0.0.1:38360,DS-5d6570a7-eb60-4eb6-8bbd-9470c8e83c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-35c0201a-54b7-4996-b18c-7b926933d5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41253,DS-46cd8428-3f59-47b6-baef-f04b270a6b76,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-fd018bbd-a378-46c4-9b79-eeeebac4606f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1239195331-172.17.0.15-1595844647276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42636,DS-8cf1d1d8-9d0b-4824-ac26-38cda5668842,DISK], DatanodeInfoWithStorage[127.0.0.1:46205,DS-15844188-8d61-4aab-a3c9-b741555ff9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-3abc5e6b-1508-44c4-bbd9-7e299b86a284,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-d6c589d9-845a-4446-baf8-6fcc99f71be8,DISK], DatanodeInfoWithStorage[127.0.0.1:38360,DS-5d6570a7-eb60-4eb6-8bbd-9470c8e83c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-35c0201a-54b7-4996-b18c-7b926933d5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41253,DS-46cd8428-3f59-47b6-baef-f04b270a6b76,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-fd018bbd-a378-46c4-9b79-eeeebac4606f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-826068124-172.17.0.15-1595844869321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40793,DS-bf3d2a7d-bb59-49c7-8179-05b18759edef,DISK], DatanodeInfoWithStorage[127.0.0.1:35294,DS-69a1fcaa-5ac3-49a6-95b2-f41b3c885fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-188bfdb6-d633-454f-9207-638bda93e088,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-7a729364-166e-4570-827b-7afb7d178cac,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-0e7f8666-22e8-474c-a122-d7e98c0364ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-88d7a857-7270-4a78-b497-f09fe2e29415,DISK], DatanodeInfoWithStorage[127.0.0.1:42347,DS-47ce9b2f-4faa-447a-95cd-62bb23218beb,DISK], DatanodeInfoWithStorage[127.0.0.1:36977,DS-ce42db7e-fdf7-4146-8119-47eec6c6e8f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-826068124-172.17.0.15-1595844869321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40793,DS-bf3d2a7d-bb59-49c7-8179-05b18759edef,DISK], DatanodeInfoWithStorage[127.0.0.1:35294,DS-69a1fcaa-5ac3-49a6-95b2-f41b3c885fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-188bfdb6-d633-454f-9207-638bda93e088,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-7a729364-166e-4570-827b-7afb7d178cac,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-0e7f8666-22e8-474c-a122-d7e98c0364ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-88d7a857-7270-4a78-b497-f09fe2e29415,DISK], DatanodeInfoWithStorage[127.0.0.1:42347,DS-47ce9b2f-4faa-447a-95cd-62bb23218beb,DISK], DatanodeInfoWithStorage[127.0.0.1:36977,DS-ce42db7e-fdf7-4146-8119-47eec6c6e8f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-452021596-172.17.0.15-1595844942498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40234,DS-98b303fc-d064-469d-b233-6d70bd3940d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-e00ea3df-6744-403c-9499-8ef67bce7bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-9e763d9f-b018-4fa5-bfac-24f105e1c9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-f7b14a72-7b55-482a-838d-8d3956f86591,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-377f63ea-bd64-42c3-b705-193dd502ed03,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-fb6dea7b-450b-4f41-8646-d7b1fa98aaae,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-9aea2c8f-c583-48b0-adad-1d1f103affce,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-bea44ef3-9723-430c-9c0e-c5153dffd399,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-452021596-172.17.0.15-1595844942498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40234,DS-98b303fc-d064-469d-b233-6d70bd3940d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-e00ea3df-6744-403c-9499-8ef67bce7bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-9e763d9f-b018-4fa5-bfac-24f105e1c9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-f7b14a72-7b55-482a-838d-8d3956f86591,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-377f63ea-bd64-42c3-b705-193dd502ed03,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-fb6dea7b-450b-4f41-8646-d7b1fa98aaae,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-9aea2c8f-c583-48b0-adad-1d1f103affce,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-bea44ef3-9723-430c-9c0e-c5153dffd399,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-131973540-172.17.0.15-1595845500932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45492,DS-ee81e374-b444-4b17-ab4e-186db91abf42,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-6060f36b-67fc-4ec0-8a63-d26abf5cf489,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-4ef3e8e4-a656-44b6-b257-d96b26a44a52,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-2a8dfd1a-4b19-4062-90e8-4b042fd37fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-db232031-4bd9-4cca-9fbc-65462054c39e,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-4578197b-211f-48ed-abc2-57db9a90cc67,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-1d79862b-eda1-4770-a394-3bc68a25c98a,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-d74c5a1d-1c77-485f-b0a3-e8707dc4acfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-131973540-172.17.0.15-1595845500932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45492,DS-ee81e374-b444-4b17-ab4e-186db91abf42,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-6060f36b-67fc-4ec0-8a63-d26abf5cf489,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-4ef3e8e4-a656-44b6-b257-d96b26a44a52,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-2a8dfd1a-4b19-4062-90e8-4b042fd37fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-db232031-4bd9-4cca-9fbc-65462054c39e,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-4578197b-211f-48ed-abc2-57db9a90cc67,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-1d79862b-eda1-4770-a394-3bc68a25c98a,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-d74c5a1d-1c77-485f-b0a3-e8707dc4acfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1966459418-172.17.0.15-1595845541824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36551,DS-9a3c6861-c4aa-4c43-980c-7c18b4203c55,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-49d699c1-278d-4300-acbb-8ee9efee58f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44661,DS-5e37c6be-2a92-4e57-a8a4-ef73b894aca9,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-e30ef7c5-b0ca-41e2-bd6e-c9b5a8dc984d,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-129d9eeb-a651-46ee-9121-ce64cf404f27,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-1b007176-e2ae-4138-84fd-e4f75befafef,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-fd960e50-9220-4f26-9166-a54233c7480e,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-bfbe55fc-90d8-4d95-8eba-6e89616050c9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1966459418-172.17.0.15-1595845541824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36551,DS-9a3c6861-c4aa-4c43-980c-7c18b4203c55,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-49d699c1-278d-4300-acbb-8ee9efee58f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44661,DS-5e37c6be-2a92-4e57-a8a4-ef73b894aca9,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-e30ef7c5-b0ca-41e2-bd6e-c9b5a8dc984d,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-129d9eeb-a651-46ee-9121-ce64cf404f27,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-1b007176-e2ae-4138-84fd-e4f75befafef,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-fd960e50-9220-4f26-9166-a54233c7480e,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-bfbe55fc-90d8-4d95-8eba-6e89616050c9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029956726-172.17.0.15-1595845678329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38257,DS-c7a251b0-ac46-4093-815b-3c8e1f2fb124,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-94a1d763-110f-4ed1-99de-0a45e9083d34,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-1265fdc7-fea6-43b5-8023-3282af140fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-08ace39a-b304-4a0e-a192-21bda586773f,DISK], DatanodeInfoWithStorage[127.0.0.1:37199,DS-e70727a4-b1a7-44ee-bcd9-95d060e158b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-06956626-58d0-42ad-add3-7dc443cc3a87,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-242e8b7b-c78f-406d-84f6-965d23c0ea46,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-a318954e-07e0-4e64-8d88-47c8e681afe0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029956726-172.17.0.15-1595845678329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38257,DS-c7a251b0-ac46-4093-815b-3c8e1f2fb124,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-94a1d763-110f-4ed1-99de-0a45e9083d34,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-1265fdc7-fea6-43b5-8023-3282af140fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-08ace39a-b304-4a0e-a192-21bda586773f,DISK], DatanodeInfoWithStorage[127.0.0.1:37199,DS-e70727a4-b1a7-44ee-bcd9-95d060e158b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-06956626-58d0-42ad-add3-7dc443cc3a87,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-242e8b7b-c78f-406d-84f6-965d23c0ea46,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-a318954e-07e0-4e64-8d88-47c8e681afe0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1549791014-172.17.0.15-1595845871328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40181,DS-40e25e05-8f89-48b2-a87f-7da23d915c89,DISK], DatanodeInfoWithStorage[127.0.0.1:40873,DS-74a08992-7dd2-42eb-b18d-9d6b161a5197,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-4d0fe024-59d1-434d-9760-6b59090d92ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-c11e5aa9-1d8b-4013-93f8-6cadc5c4e566,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-67f3c405-2482-446a-9957-44046925ed99,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-6644c32a-752c-4f95-9011-913e16324c40,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-f5ba6413-c3e6-4e95-85e5-fd12be615d73,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-2e856dc1-8a62-44e9-a033-4e6f21c63178,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1549791014-172.17.0.15-1595845871328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40181,DS-40e25e05-8f89-48b2-a87f-7da23d915c89,DISK], DatanodeInfoWithStorage[127.0.0.1:40873,DS-74a08992-7dd2-42eb-b18d-9d6b161a5197,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-4d0fe024-59d1-434d-9760-6b59090d92ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-c11e5aa9-1d8b-4013-93f8-6cadc5c4e566,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-67f3c405-2482-446a-9957-44046925ed99,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-6644c32a-752c-4f95-9011-913e16324c40,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-f5ba6413-c3e6-4e95-85e5-fd12be615d73,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-2e856dc1-8a62-44e9-a033-4e6f21c63178,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2118711071-172.17.0.15-1595845905505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34308,DS-59048df0-616f-489b-b06e-bae7f1f02d77,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-034fb9d5-f303-40f9-a0c0-b539262487db,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-f9720138-fc50-49b3-bda0-59de7a16da4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35295,DS-b046441e-cadd-47b2-b0d8-38ceb827a656,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-19ea1f39-0010-4d18-bb7e-2911824794b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-c3b0bc0e-24e3-42d2-8105-82c1e100ea51,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-83c3773c-aab3-4482-948b-b2cf9d31b899,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-e239fac6-b032-4b8a-a0b7-4b3874070206,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2118711071-172.17.0.15-1595845905505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34308,DS-59048df0-616f-489b-b06e-bae7f1f02d77,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-034fb9d5-f303-40f9-a0c0-b539262487db,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-f9720138-fc50-49b3-bda0-59de7a16da4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35295,DS-b046441e-cadd-47b2-b0d8-38ceb827a656,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-19ea1f39-0010-4d18-bb7e-2911824794b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-c3b0bc0e-24e3-42d2-8105-82c1e100ea51,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-83c3773c-aab3-4482-948b-b2cf9d31b899,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-e239fac6-b032-4b8a-a0b7-4b3874070206,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-841545475-172.17.0.15-1595846250783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43605,DS-639702e3-f795-415a-9f9a-a3cac9149154,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-3f021847-c1a6-4b05-9d9b-ea99a781d7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-e23374db-491a-4c42-ba05-065a1dba7d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-f02a1b66-ca3d-421d-bc51-162d169e1ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-37c8e38d-edad-4001-ae27-e7943cc625c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-5be538ad-1a82-4931-a170-9d5d98891ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-0f6f8acb-6b74-4c3e-a53f-68b2b6f253cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-ab5b6583-1447-474b-8de2-d660edd04f98,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-841545475-172.17.0.15-1595846250783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43605,DS-639702e3-f795-415a-9f9a-a3cac9149154,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-3f021847-c1a6-4b05-9d9b-ea99a781d7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-e23374db-491a-4c42-ba05-065a1dba7d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-f02a1b66-ca3d-421d-bc51-162d169e1ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-37c8e38d-edad-4001-ae27-e7943cc625c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-5be538ad-1a82-4931-a170-9d5d98891ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-0f6f8acb-6b74-4c3e-a53f-68b2b6f253cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-ab5b6583-1447-474b-8de2-d660edd04f98,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-108535846-172.17.0.15-1595846352721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39370,DS-73e4bab5-15b7-4180-95dc-4ff1c984243a,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-e4f2c0b2-fddb-4a14-aad7-ca5801ef4fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-2c421cac-8f72-4ede-a562-f5ebcefab6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-b5f10963-9e70-4aaf-a8c0-9ca0cb892ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:39877,DS-5d8a3afe-3aec-4845-88be-f6358a1cff34,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-b944ed3d-dcee-4d01-93cf-a26b6dbf81a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-2f07c262-9040-4c8f-a91f-8c3caab8a1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-031de557-e3c8-47f2-a7c2-cb3dd4f2c0cd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-108535846-172.17.0.15-1595846352721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39370,DS-73e4bab5-15b7-4180-95dc-4ff1c984243a,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-e4f2c0b2-fddb-4a14-aad7-ca5801ef4fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-2c421cac-8f72-4ede-a562-f5ebcefab6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-b5f10963-9e70-4aaf-a8c0-9ca0cb892ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:39877,DS-5d8a3afe-3aec-4845-88be-f6358a1cff34,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-b944ed3d-dcee-4d01-93cf-a26b6dbf81a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-2f07c262-9040-4c8f-a91f-8c3caab8a1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-031de557-e3c8-47f2-a7c2-cb3dd4f2c0cd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-632568593-172.17.0.15-1595846387259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40975,DS-e7be613c-cb93-493d-9c6b-64ceea106fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:36116,DS-026737a5-112a-48ce-9453-620800f78b56,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-4cc6ea5e-aba0-40f8-83bb-36cb4186c840,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-5db8f08c-a014-406f-8248-7a2c2c618ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-4eb1a344-8dc0-43b0-9f19-02f1e0a259db,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-a87e9e6a-9910-4787-ae17-0486773e3ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-5288ce89-fc5e-4153-a994-0e44d07d998b,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-5959ecfb-fe0e-4265-ae48-7c5d117484c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-632568593-172.17.0.15-1595846387259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40975,DS-e7be613c-cb93-493d-9c6b-64ceea106fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:36116,DS-026737a5-112a-48ce-9453-620800f78b56,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-4cc6ea5e-aba0-40f8-83bb-36cb4186c840,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-5db8f08c-a014-406f-8248-7a2c2c618ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-4eb1a344-8dc0-43b0-9f19-02f1e0a259db,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-a87e9e6a-9910-4787-ae17-0486773e3ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-5288ce89-fc5e-4153-a994-0e44d07d998b,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-5959ecfb-fe0e-4265-ae48-7c5d117484c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-98167949-172.17.0.15-1595846448505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39070,DS-60032424-ab0e-46c1-9f92-6c3499ba1bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-3fb8a761-10c5-417e-8fb4-ffdede707720,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-88596f80-fd80-4b40-a43c-8a9f6ee66275,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-ee4504d2-216e-4b1b-857d-72f605e65cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-be4d8c0a-e5d2-4a91-bce4-5cff94ba8a54,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-fdad3c4e-54dc-4b6c-b9a1-8cff7b76e707,DISK], DatanodeInfoWithStorage[127.0.0.1:40434,DS-0147d81c-1988-41eb-9663-89019a1ac5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-5179ae81-b1c9-41c9-8f49-503e3103916c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-98167949-172.17.0.15-1595846448505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39070,DS-60032424-ab0e-46c1-9f92-6c3499ba1bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-3fb8a761-10c5-417e-8fb4-ffdede707720,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-88596f80-fd80-4b40-a43c-8a9f6ee66275,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-ee4504d2-216e-4b1b-857d-72f605e65cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-be4d8c0a-e5d2-4a91-bce4-5cff94ba8a54,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-fdad3c4e-54dc-4b6c-b9a1-8cff7b76e707,DISK], DatanodeInfoWithStorage[127.0.0.1:40434,DS-0147d81c-1988-41eb-9663-89019a1ac5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-5179ae81-b1c9-41c9-8f49-503e3103916c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1861126536-172.17.0.15-1595846789668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39136,DS-5f5754e1-aa7c-465b-91f2-a3c23e6d5bab,DISK], DatanodeInfoWithStorage[127.0.0.1:36278,DS-571369fe-54a6-4b85-8124-d6212c15e794,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-b0a9a944-64b7-42b5-b8b9-ab5b15967a78,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-88b8d81a-c6c5-4041-9d97-783b505ea2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34465,DS-d72fcf18-aa91-43cc-aa59-7b7d9069d3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-4500bac7-3c1b-430f-aff0-306ae5643a13,DISK], DatanodeInfoWithStorage[127.0.0.1:42679,DS-78e549c9-2e22-4d67-aef8-360ba6f33f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-12b08824-7b08-4973-a70d-af4635d5f723,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1861126536-172.17.0.15-1595846789668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39136,DS-5f5754e1-aa7c-465b-91f2-a3c23e6d5bab,DISK], DatanodeInfoWithStorage[127.0.0.1:36278,DS-571369fe-54a6-4b85-8124-d6212c15e794,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-b0a9a944-64b7-42b5-b8b9-ab5b15967a78,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-88b8d81a-c6c5-4041-9d97-783b505ea2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34465,DS-d72fcf18-aa91-43cc-aa59-7b7d9069d3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-4500bac7-3c1b-430f-aff0-306ae5643a13,DISK], DatanodeInfoWithStorage[127.0.0.1:42679,DS-78e549c9-2e22-4d67-aef8-360ba6f33f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-12b08824-7b08-4973-a70d-af4635d5f723,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1971412929-172.17.0.15-1595846913983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38390,DS-c0ea55b8-525e-4132-8411-a67e3652b83d,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-2beb94f4-1608-4a25-927f-e23e9713095c,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-e9abe743-8b15-4e5c-96a7-c964bf781737,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-ddd3d3d4-b64e-4f78-a979-1ebb1e5cae99,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-6c9fb395-c658-476b-bef7-42742cd0831e,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-26d91fc2-036c-4009-9057-76a5c81b1f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-4ce10a97-c896-4645-9c8d-7db332c933fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-c185f59e-7b82-41f4-9c28-0fd543c779f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1971412929-172.17.0.15-1595846913983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38390,DS-c0ea55b8-525e-4132-8411-a67e3652b83d,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-2beb94f4-1608-4a25-927f-e23e9713095c,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-e9abe743-8b15-4e5c-96a7-c964bf781737,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-ddd3d3d4-b64e-4f78-a979-1ebb1e5cae99,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-6c9fb395-c658-476b-bef7-42742cd0831e,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-26d91fc2-036c-4009-9057-76a5c81b1f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-4ce10a97-c896-4645-9c8d-7db332c933fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-c185f59e-7b82-41f4-9c28-0fd543c779f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-911727573-172.17.0.15-1595846946882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46785,DS-29294a54-b39a-4038-8bd2-9ff030e588a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-d3b5b636-6948-47fd-b8e5-973929bec91b,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-1530022a-d756-4c2a-829b-80f2b5e3f040,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-58e56bfd-e789-4b39-9626-a59d846282dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-74a75246-03d7-4e95-ad82-d6cc0de31454,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-53e5bdf2-404e-4aa8-af86-d425277ebf01,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-b19ad7b8-a939-458d-926b-f4b73ad31b96,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-3ce8c787-3d7b-45a3-a021-0f928fd9476f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-911727573-172.17.0.15-1595846946882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46785,DS-29294a54-b39a-4038-8bd2-9ff030e588a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-d3b5b636-6948-47fd-b8e5-973929bec91b,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-1530022a-d756-4c2a-829b-80f2b5e3f040,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-58e56bfd-e789-4b39-9626-a59d846282dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-74a75246-03d7-4e95-ad82-d6cc0de31454,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-53e5bdf2-404e-4aa8-af86-d425277ebf01,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-b19ad7b8-a939-458d-926b-f4b73ad31b96,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-3ce8c787-3d7b-45a3-a021-0f928fd9476f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-684508260-172.17.0.15-1595846985680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41234,DS-d80403bb-01e3-4e95-bcbb-f69bd282eefd,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-65252cca-934d-497a-b7ef-a03c501e1d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-6466d6a4-002e-43a5-a79e-5186ae4d1923,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-34977fe4-4d74-42af-8c78-2a5d77652432,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-4945b13b-f800-4257-90a3-bef6ae6df4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-f08768c1-b7e3-433b-8479-0d3227119a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-df2727dd-4bde-4c46-a654-0805496c68a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-239ddf3d-8776-4ce6-a3b8-310e9bfacf8b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-684508260-172.17.0.15-1595846985680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41234,DS-d80403bb-01e3-4e95-bcbb-f69bd282eefd,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-65252cca-934d-497a-b7ef-a03c501e1d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-6466d6a4-002e-43a5-a79e-5186ae4d1923,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-34977fe4-4d74-42af-8c78-2a5d77652432,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-4945b13b-f800-4257-90a3-bef6ae6df4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-f08768c1-b7e3-433b-8479-0d3227119a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-df2727dd-4bde-4c46-a654-0805496c68a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-239ddf3d-8776-4ce6-a3b8-310e9bfacf8b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1292625851-172.17.0.15-1595847058291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36043,DS-fc4b68dc-c7db-4581-a125-f752040ff368,DISK], DatanodeInfoWithStorage[127.0.0.1:36990,DS-282dd135-fcfe-4dab-aa09-ccbec3511bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-b90934cc-7f76-4105-9422-5dcf680b577d,DISK], DatanodeInfoWithStorage[127.0.0.1:43835,DS-6059368f-e942-4a5d-a2fb-e18bc2f58f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-5a917366-972b-4a49-9a63-4cdbf58e7c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39813,DS-285300aa-f105-40b3-9a59-2f95021c42fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38697,DS-0356de07-158d-46db-b964-3492818ba336,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-1cc46d1e-b62a-4fdc-8022-9d8e608a8ef6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1292625851-172.17.0.15-1595847058291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36043,DS-fc4b68dc-c7db-4581-a125-f752040ff368,DISK], DatanodeInfoWithStorage[127.0.0.1:36990,DS-282dd135-fcfe-4dab-aa09-ccbec3511bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-b90934cc-7f76-4105-9422-5dcf680b577d,DISK], DatanodeInfoWithStorage[127.0.0.1:43835,DS-6059368f-e942-4a5d-a2fb-e18bc2f58f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-5a917366-972b-4a49-9a63-4cdbf58e7c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39813,DS-285300aa-f105-40b3-9a59-2f95021c42fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38697,DS-0356de07-158d-46db-b964-3492818ba336,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-1cc46d1e-b62a-4fdc-8022-9d8e608a8ef6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1483733681-172.17.0.15-1595847089375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40942,DS-34a396cc-68bc-452b-9558-7ba3dc214d51,DISK], DatanodeInfoWithStorage[127.0.0.1:45152,DS-08426a91-b75f-4f2e-aa4c-a2d34ce640b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-dd60c741-d6ab-4c2b-8ead-9be98645f581,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-d0744fc7-a34a-4f2b-a14c-355e62e095bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37394,DS-48ae0a78-8f79-4a17-8128-4b9424e1cc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-9677c501-dc5f-49c2-8e57-18fd0a6f6bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-6f50f447-e1d2-495e-973d-76626a3b04c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-f1ac71da-799d-4c6e-8dea-9fde6fdf7a6f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1483733681-172.17.0.15-1595847089375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40942,DS-34a396cc-68bc-452b-9558-7ba3dc214d51,DISK], DatanodeInfoWithStorage[127.0.0.1:45152,DS-08426a91-b75f-4f2e-aa4c-a2d34ce640b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-dd60c741-d6ab-4c2b-8ead-9be98645f581,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-d0744fc7-a34a-4f2b-a14c-355e62e095bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37394,DS-48ae0a78-8f79-4a17-8128-4b9424e1cc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-9677c501-dc5f-49c2-8e57-18fd0a6f6bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-6f50f447-e1d2-495e-973d-76626a3b04c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-f1ac71da-799d-4c6e-8dea-9fde6fdf7a6f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1403557538-172.17.0.15-1595847344320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40656,DS-c5e3cfcd-42ef-4d71-87f2-5a62532e84b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-7dde1a23-9ba5-4b61-93b0-737033e4cbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-4a1e7f9c-0f35-4568-8711-4e3166fe2b94,DISK], DatanodeInfoWithStorage[127.0.0.1:35829,DS-e8e9960f-4f76-492d-929f-0e9c68847c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-22ec1495-dd7e-49ce-b8d1-479461a82d33,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-5264f26b-d7f7-42d8-b635-7f6e5620a0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-b27b2ebe-9808-4b72-bf02-02dd959a9b08,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-ae95cb94-acd2-442b-b3ba-2f4acec00bbb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1403557538-172.17.0.15-1595847344320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40656,DS-c5e3cfcd-42ef-4d71-87f2-5a62532e84b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-7dde1a23-9ba5-4b61-93b0-737033e4cbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-4a1e7f9c-0f35-4568-8711-4e3166fe2b94,DISK], DatanodeInfoWithStorage[127.0.0.1:35829,DS-e8e9960f-4f76-492d-929f-0e9c68847c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-22ec1495-dd7e-49ce-b8d1-479461a82d33,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-5264f26b-d7f7-42d8-b635-7f6e5620a0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-b27b2ebe-9808-4b72-bf02-02dd959a9b08,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-ae95cb94-acd2-442b-b3ba-2f4acec00bbb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1801796847-172.17.0.15-1595847375106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46173,DS-d4544f55-fa29-47d9-b008-94a426bbc022,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-24fabf4a-85c8-407e-8a17-0e42a31668f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-d0c06f92-ed7b-4b07-96fa-6d3e96b1280f,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-8d18f1fd-c398-45e9-a319-f6e02a9780d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-09a0ccb2-8ea7-466f-9699-1f6ef5edb5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45276,DS-0b9abe95-1ca1-43dd-8b0d-438b496c9248,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-90af7bee-96ae-451c-92bf-2956a2705e41,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-27b2300a-8f53-499d-81fc-ebefee84092d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1801796847-172.17.0.15-1595847375106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46173,DS-d4544f55-fa29-47d9-b008-94a426bbc022,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-24fabf4a-85c8-407e-8a17-0e42a31668f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-d0c06f92-ed7b-4b07-96fa-6d3e96b1280f,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-8d18f1fd-c398-45e9-a319-f6e02a9780d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-09a0ccb2-8ea7-466f-9699-1f6ef5edb5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45276,DS-0b9abe95-1ca1-43dd-8b0d-438b496c9248,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-90af7bee-96ae-451c-92bf-2956a2705e41,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-27b2300a-8f53-499d-81fc-ebefee84092d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 20 out of 50
result: false positive !!!
Total execution time in seconds : 5331
