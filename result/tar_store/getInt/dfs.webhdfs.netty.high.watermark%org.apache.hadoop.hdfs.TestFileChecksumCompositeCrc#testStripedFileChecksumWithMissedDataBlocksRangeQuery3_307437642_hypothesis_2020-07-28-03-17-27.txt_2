reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-10982481-172.17.0.6-1595906262561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39930,DS-90323e8b-d504-4d6e-86ca-b248ae899009,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-82f890fb-50f5-426a-a383-a81025888755,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-6dd63210-954d-4ec8-a33b-95de62343349,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-f8df0670-a2d9-45c9-8d05-f571d3d4477a,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-9a86573b-3e93-441d-a2e6-b6b165234d88,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-667d3a94-1a32-4d9b-a4af-af1fa7dc6268,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-dc88fdf6-c05f-4838-99e2-0639932c34cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45166,DS-58f69983-14d5-48d1-bbcc-14c5acb07a4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-10982481-172.17.0.6-1595906262561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39930,DS-90323e8b-d504-4d6e-86ca-b248ae899009,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-82f890fb-50f5-426a-a383-a81025888755,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-6dd63210-954d-4ec8-a33b-95de62343349,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-f8df0670-a2d9-45c9-8d05-f571d3d4477a,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-9a86573b-3e93-441d-a2e6-b6b165234d88,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-667d3a94-1a32-4d9b-a4af-af1fa7dc6268,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-dc88fdf6-c05f-4838-99e2-0639932c34cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45166,DS-58f69983-14d5-48d1-bbcc-14c5acb07a4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-680163838-172.17.0.6-1595906528752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34499,DS-c9bd6838-3505-48a3-8173-c96ccb6296ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35891,DS-e7022ead-4efc-4080-b4be-4bcf0c55b030,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-e22c292b-b23d-4f45-94e8-6e532414a295,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-576f82b1-5ab2-4396-93f1-3860c0c55717,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-fca96811-6a91-4eca-bcf1-6b6be443c88a,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-ba02a0b0-ebc3-4363-a0d7-5e2a81f7b7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-405d6624-329a-44c3-bbeb-b479ca30d4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-442235a6-abc2-49ce-b4a8-15fd8de00cc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-680163838-172.17.0.6-1595906528752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34499,DS-c9bd6838-3505-48a3-8173-c96ccb6296ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35891,DS-e7022ead-4efc-4080-b4be-4bcf0c55b030,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-e22c292b-b23d-4f45-94e8-6e532414a295,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-576f82b1-5ab2-4396-93f1-3860c0c55717,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-fca96811-6a91-4eca-bcf1-6b6be443c88a,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-ba02a0b0-ebc3-4363-a0d7-5e2a81f7b7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-405d6624-329a-44c3-bbeb-b479ca30d4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-442235a6-abc2-49ce-b4a8-15fd8de00cc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-481084461-172.17.0.6-1595906719698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46565,DS-16c4a782-7f61-4590-a1e7-a3fe00cfee7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-4515eded-db77-48aa-b24c-4f271a87be1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-66db03f9-40a1-4083-8542-50535af052fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-f7eb5a2e-ff6a-433c-b61b-f1f3088608eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40120,DS-372fb8d1-cde3-4184-9e84-8ee3c42e48f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-8384edb3-3de0-4e9a-ab41-101bbbd71aba,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-bfd8f711-91ca-4b76-b29b-c72b70f4e890,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-def18332-84cc-4282-befe-ffffaf0beb00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-481084461-172.17.0.6-1595906719698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46565,DS-16c4a782-7f61-4590-a1e7-a3fe00cfee7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-4515eded-db77-48aa-b24c-4f271a87be1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-66db03f9-40a1-4083-8542-50535af052fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-f7eb5a2e-ff6a-433c-b61b-f1f3088608eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40120,DS-372fb8d1-cde3-4184-9e84-8ee3c42e48f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-8384edb3-3de0-4e9a-ab41-101bbbd71aba,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-bfd8f711-91ca-4b76-b29b-c72b70f4e890,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-def18332-84cc-4282-befe-ffffaf0beb00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1097454808-172.17.0.6-1595907454673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46870,DS-f73db8f5-96c2-4f8a-a6d5-6ad5d9bb44d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34818,DS-a0a7e2c0-ee73-4ff1-a6cd-aa3ac85ce904,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-5e16d36b-a195-4833-a0f2-ccfb98470b09,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-526549d9-5799-4360-bc89-508b3f22eda7,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-4d0f819c-8ac2-48f7-b85f-c8dbe74c1202,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-f1ceb275-d0f4-455d-a26a-00025d62f336,DISK], DatanodeInfoWithStorage[127.0.0.1:41963,DS-1816dfdf-dab2-40ba-854c-f3e7ca97dcf3,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-8cb2a950-dc53-47bb-9b88-e51b6017e90a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1097454808-172.17.0.6-1595907454673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46870,DS-f73db8f5-96c2-4f8a-a6d5-6ad5d9bb44d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34818,DS-a0a7e2c0-ee73-4ff1-a6cd-aa3ac85ce904,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-5e16d36b-a195-4833-a0f2-ccfb98470b09,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-526549d9-5799-4360-bc89-508b3f22eda7,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-4d0f819c-8ac2-48f7-b85f-c8dbe74c1202,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-f1ceb275-d0f4-455d-a26a-00025d62f336,DISK], DatanodeInfoWithStorage[127.0.0.1:41963,DS-1816dfdf-dab2-40ba-854c-f3e7ca97dcf3,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-8cb2a950-dc53-47bb-9b88-e51b6017e90a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-61757483-172.17.0.6-1595908573336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38460,DS-352ac133-f4d7-40e1-98e8-dc163891de8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-faf61302-d334-4488-b46c-91db8655e242,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-7c0109fb-7287-402f-82ce-0236977a84eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-fe9741af-f6c0-4b77-98fc-df7b5a6b13b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-7da6b3b4-dda3-4357-b69b-de9fcf411baa,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-edf10594-2e55-4463-95e7-c41687a38b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-89adf63e-863b-4ef7-a751-fb837568e5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-64181ec0-8636-4fe8-a693-81096e548eda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-61757483-172.17.0.6-1595908573336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38460,DS-352ac133-f4d7-40e1-98e8-dc163891de8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-faf61302-d334-4488-b46c-91db8655e242,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-7c0109fb-7287-402f-82ce-0236977a84eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-fe9741af-f6c0-4b77-98fc-df7b5a6b13b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-7da6b3b4-dda3-4357-b69b-de9fcf411baa,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-edf10594-2e55-4463-95e7-c41687a38b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-89adf63e-863b-4ef7-a751-fb837568e5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-64181ec0-8636-4fe8-a693-81096e548eda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-430151107-172.17.0.6-1595908870939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36241,DS-08d2a7cc-6ff6-4efe-a7be-da74ee07aaba,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-b16c6942-a1a4-4e86-a603-40e5dfc968ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-18000738-f2c1-41d7-aaf9-bf0b757fcea7,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-fd98da18-de3d-46a8-966e-7c0dec18cab0,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-29e313d0-6211-4b91-8e2d-aa62455d3fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-27412490-59c8-4940-820d-d9be4f7f8e67,DISK], DatanodeInfoWithStorage[127.0.0.1:43558,DS-d683dff3-04ee-445d-9859-d31002caa78d,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-9d3bf60d-cfdf-4121-a65d-e85a5a7224ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-430151107-172.17.0.6-1595908870939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36241,DS-08d2a7cc-6ff6-4efe-a7be-da74ee07aaba,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-b16c6942-a1a4-4e86-a603-40e5dfc968ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-18000738-f2c1-41d7-aaf9-bf0b757fcea7,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-fd98da18-de3d-46a8-966e-7c0dec18cab0,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-29e313d0-6211-4b91-8e2d-aa62455d3fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-27412490-59c8-4940-820d-d9be4f7f8e67,DISK], DatanodeInfoWithStorage[127.0.0.1:43558,DS-d683dff3-04ee-445d-9859-d31002caa78d,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-9d3bf60d-cfdf-4121-a65d-e85a5a7224ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1427080673-172.17.0.6-1595909027363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41817,DS-ade0453b-92cc-4d35-bf16-8507e3d7c0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-6cb8d68d-3738-4a25-ab7f-0944db4df79f,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-3392077e-c294-4a3e-98bb-b66f1402ab0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-ad50f8f1-5a25-45ea-a292-fb79d3c3523e,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-b31db3ba-bee7-4518-bb28-af90f538ca04,DISK], DatanodeInfoWithStorage[127.0.0.1:37654,DS-94141f4a-274c-4590-846b-165aba1390b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-3cb799ef-dcbe-41e6-b080-7b3bf5f18c43,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-3dfbb4b7-88f9-401c-b42a-10e4b951d0c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1427080673-172.17.0.6-1595909027363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41817,DS-ade0453b-92cc-4d35-bf16-8507e3d7c0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-6cb8d68d-3738-4a25-ab7f-0944db4df79f,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-3392077e-c294-4a3e-98bb-b66f1402ab0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-ad50f8f1-5a25-45ea-a292-fb79d3c3523e,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-b31db3ba-bee7-4518-bb28-af90f538ca04,DISK], DatanodeInfoWithStorage[127.0.0.1:37654,DS-94141f4a-274c-4590-846b-165aba1390b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-3cb799ef-dcbe-41e6-b080-7b3bf5f18c43,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-3dfbb4b7-88f9-401c-b42a-10e4b951d0c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-969963842-172.17.0.6-1595909274404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39708,DS-6010ea53-3837-4533-829b-4f0038ea4b93,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-99b8834f-83f6-4abc-bac0-99c349798d53,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-8c0fe445-c8a5-4370-9da5-09ce9ebbea76,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-a8404c71-d644-44b9-a5c2-1e5d9ce2cc32,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-67ed0c23-1c98-44a3-a25a-d91825c68a58,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-c9c5158a-d853-41cb-bb04-3a7926b84ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-4a6bd2bb-5859-4adc-914b-fe9176e52ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-8a8cd708-aace-4604-948d-3a7c5ae2f431,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-969963842-172.17.0.6-1595909274404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39708,DS-6010ea53-3837-4533-829b-4f0038ea4b93,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-99b8834f-83f6-4abc-bac0-99c349798d53,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-8c0fe445-c8a5-4370-9da5-09ce9ebbea76,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-a8404c71-d644-44b9-a5c2-1e5d9ce2cc32,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-67ed0c23-1c98-44a3-a25a-d91825c68a58,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-c9c5158a-d853-41cb-bb04-3a7926b84ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-4a6bd2bb-5859-4adc-914b-fe9176e52ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-8a8cd708-aace-4604-948d-3a7c5ae2f431,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2034605760-172.17.0.6-1595909368149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37035,DS-abaf8c59-ceac-4d0d-b25c-84527530250e,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-d806ece1-9f7f-464b-945d-63f28b98f656,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-c3862ee9-9455-4f4c-a6c8-86edf0652e70,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-e63781c5-47fd-49fb-aac8-7714e9b88837,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-f899b232-f25b-490d-88fb-13b518c98a03,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-5f284824-cfc8-4026-8200-3d8a77b65e71,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-d32286a6-0889-4774-b39c-523b37ba628a,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-84c18305-3827-444e-a7d8-351b742d4620,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2034605760-172.17.0.6-1595909368149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37035,DS-abaf8c59-ceac-4d0d-b25c-84527530250e,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-d806ece1-9f7f-464b-945d-63f28b98f656,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-c3862ee9-9455-4f4c-a6c8-86edf0652e70,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-e63781c5-47fd-49fb-aac8-7714e9b88837,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-f899b232-f25b-490d-88fb-13b518c98a03,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-5f284824-cfc8-4026-8200-3d8a77b65e71,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-d32286a6-0889-4774-b39c-523b37ba628a,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-84c18305-3827-444e-a7d8-351b742d4620,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-569811645-172.17.0.6-1595909410272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45828,DS-fbe617ab-e588-49a1-809c-2c93b681d583,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-e68e73b7-cae2-41c4-95fe-ccfa1c2d5878,DISK], DatanodeInfoWithStorage[127.0.0.1:41693,DS-d68888fc-14b7-403e-b08e-743eac16a7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-1e3955ee-73e0-4a55-bcdc-f66848c22a51,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-7a86bb5e-baec-4e1e-bae9-6ca56dc5a638,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-b7905224-3ce6-4d82-8ec5-64a253843b52,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-d6c10926-5aa8-4283-ad24-60b5261586cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-b0632116-484a-46ca-9573-b087d3c8dd12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-569811645-172.17.0.6-1595909410272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45828,DS-fbe617ab-e588-49a1-809c-2c93b681d583,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-e68e73b7-cae2-41c4-95fe-ccfa1c2d5878,DISK], DatanodeInfoWithStorage[127.0.0.1:41693,DS-d68888fc-14b7-403e-b08e-743eac16a7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-1e3955ee-73e0-4a55-bcdc-f66848c22a51,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-7a86bb5e-baec-4e1e-bae9-6ca56dc5a638,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-b7905224-3ce6-4d82-8ec5-64a253843b52,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-d6c10926-5aa8-4283-ad24-60b5261586cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-b0632116-484a-46ca-9573-b087d3c8dd12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-926710846-172.17.0.6-1595910446833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34127,DS-84c67938-c3b8-4d17-b2f1-c5607e3633ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-148d329d-d1c5-4a89-98ff-e8d76cac11db,DISK], DatanodeInfoWithStorage[127.0.0.1:40034,DS-65a59784-84b4-4bcb-bf58-d27b4ca20676,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-c5f4bff7-c802-44dd-9566-b5aebfacafb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-037d9899-1dbf-4ef5-b0e0-714fadf08608,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-4aca7f47-7469-469f-afcb-1db5d1c519f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-af4706bf-6143-46ed-bea7-89fe00e56c36,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-084a8218-f619-4c0b-a8a3-4ce7f4cb37bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-926710846-172.17.0.6-1595910446833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34127,DS-84c67938-c3b8-4d17-b2f1-c5607e3633ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-148d329d-d1c5-4a89-98ff-e8d76cac11db,DISK], DatanodeInfoWithStorage[127.0.0.1:40034,DS-65a59784-84b4-4bcb-bf58-d27b4ca20676,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-c5f4bff7-c802-44dd-9566-b5aebfacafb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-037d9899-1dbf-4ef5-b0e0-714fadf08608,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-4aca7f47-7469-469f-afcb-1db5d1c519f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-af4706bf-6143-46ed-bea7-89fe00e56c36,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-084a8218-f619-4c0b-a8a3-4ce7f4cb37bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-251516609-172.17.0.6-1595910593592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35662,DS-6dc20666-d0bd-426a-8626-bcf3bf174891,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-874ac7fe-4ef2-4b93-8447-601345714e87,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-fd224e37-4785-427a-bb65-b7f79adede9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40355,DS-d29cff33-0edc-4c23-b78a-870352e6fd64,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-22cf25a0-91a4-4ebc-9704-99d92d27a66f,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-6e6524d5-e21e-4919-9e94-8a9d0cb523bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-2b4b9495-1510-4017-8464-0cc13e1e105d,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-77c8acc0-a140-4c77-a358-9d1f892eb142,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-251516609-172.17.0.6-1595910593592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35662,DS-6dc20666-d0bd-426a-8626-bcf3bf174891,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-874ac7fe-4ef2-4b93-8447-601345714e87,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-fd224e37-4785-427a-bb65-b7f79adede9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40355,DS-d29cff33-0edc-4c23-b78a-870352e6fd64,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-22cf25a0-91a4-4ebc-9704-99d92d27a66f,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-6e6524d5-e21e-4919-9e94-8a9d0cb523bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-2b4b9495-1510-4017-8464-0cc13e1e105d,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-77c8acc0-a140-4c77-a358-9d1f892eb142,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-485127387-172.17.0.6-1595910694272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42914,DS-5745a841-8a31-4780-b31b-62f8a4c5f0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-07a9f8bf-9712-4b14-b194-87ecfa36eef5,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-5020970e-8942-4684-a675-835ff881b3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-742ad60e-03f4-4665-9ba6-6a5bea444a67,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-cfa0bd3a-0014-40b1-9e4b-f10b813cb5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-16339127-5958-4aba-976d-69d8d189a275,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-02d7ed02-637b-4088-9060-57f5000049b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-b8f48c2e-ecc3-43ed-934e-4869a8eca2b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-485127387-172.17.0.6-1595910694272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42914,DS-5745a841-8a31-4780-b31b-62f8a4c5f0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-07a9f8bf-9712-4b14-b194-87ecfa36eef5,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-5020970e-8942-4684-a675-835ff881b3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-742ad60e-03f4-4665-9ba6-6a5bea444a67,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-cfa0bd3a-0014-40b1-9e4b-f10b813cb5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-16339127-5958-4aba-976d-69d8d189a275,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-02d7ed02-637b-4088-9060-57f5000049b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-b8f48c2e-ecc3-43ed-934e-4869a8eca2b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-811776798-172.17.0.6-1595911074283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34635,DS-b1064ebb-184a-4c0f-921d-debd7a31c604,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-7e858a4f-7999-4ad2-a8dd-c4bdff3fd889,DISK], DatanodeInfoWithStorage[127.0.0.1:37469,DS-c2b5c343-a067-490c-ab7b-42836656c765,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-9c7eea3d-491a-4a64-9eec-c861a0842a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33030,DS-b798546e-afae-462d-9678-250cdfbecda3,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-032e616e-cc24-4410-a14b-08658b2f0b79,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-9e94f81c-6bc0-47ef-91df-f622b981885c,DISK], DatanodeInfoWithStorage[127.0.0.1:43832,DS-52fb1d24-76aa-413b-9b03-a2b6700f923c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-811776798-172.17.0.6-1595911074283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34635,DS-b1064ebb-184a-4c0f-921d-debd7a31c604,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-7e858a4f-7999-4ad2-a8dd-c4bdff3fd889,DISK], DatanodeInfoWithStorage[127.0.0.1:37469,DS-c2b5c343-a067-490c-ab7b-42836656c765,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-9c7eea3d-491a-4a64-9eec-c861a0842a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33030,DS-b798546e-afae-462d-9678-250cdfbecda3,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-032e616e-cc24-4410-a14b-08658b2f0b79,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-9e94f81c-6bc0-47ef-91df-f622b981885c,DISK], DatanodeInfoWithStorage[127.0.0.1:43832,DS-52fb1d24-76aa-413b-9b03-a2b6700f923c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-785977210-172.17.0.6-1595911771279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43212,DS-b8c875ea-f848-4dfd-b546-ba9b8dc80138,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-5d771fdc-804a-4303-b1d2-b9a8239677ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-41f3b295-f136-4fcf-b15a-912639ee4f18,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-b73ee620-c6fa-40a6-975b-a225cdf76ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-c6a97750-3f8d-44d7-9a42-c27d562c7edb,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-0edd6537-f62c-4eb9-8ee0-b417c762f0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-626f5c16-df6f-4c2a-8785-29b1cdbc7b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:32928,DS-00b4329a-25ce-4933-a8c0-e89c6959aab8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-785977210-172.17.0.6-1595911771279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43212,DS-b8c875ea-f848-4dfd-b546-ba9b8dc80138,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-5d771fdc-804a-4303-b1d2-b9a8239677ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-41f3b295-f136-4fcf-b15a-912639ee4f18,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-b73ee620-c6fa-40a6-975b-a225cdf76ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-c6a97750-3f8d-44d7-9a42-c27d562c7edb,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-0edd6537-f62c-4eb9-8ee0-b417c762f0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-626f5c16-df6f-4c2a-8785-29b1cdbc7b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:32928,DS-00b4329a-25ce-4933-a8c0-e89c6959aab8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-93443822-172.17.0.6-1595912103187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33526,DS-bef4e377-18da-44a4-88cb-845fee7d4a65,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-9881b715-1621-4f95-aed4-3be18ecd102a,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-f84ec0d8-7700-436b-8ba9-3022f5eb01c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-86e1e596-1357-4daf-b1f7-7cfadcc34256,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-89a60152-a5fd-4142-90e7-0fa4331f06cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-04103355-3d0e-4fc9-a276-4d8cb9465175,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-67132121-3692-40b9-804e-d4ab3206397b,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-37c5d709-5da5-4893-a059-2bbcec60d1e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-93443822-172.17.0.6-1595912103187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33526,DS-bef4e377-18da-44a4-88cb-845fee7d4a65,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-9881b715-1621-4f95-aed4-3be18ecd102a,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-f84ec0d8-7700-436b-8ba9-3022f5eb01c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-86e1e596-1357-4daf-b1f7-7cfadcc34256,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-89a60152-a5fd-4142-90e7-0fa4331f06cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-04103355-3d0e-4fc9-a276-4d8cb9465175,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-67132121-3692-40b9-804e-d4ab3206397b,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-37c5d709-5da5-4893-a059-2bbcec60d1e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-646770768-172.17.0.6-1595912544693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38627,DS-cfb39bc1-de91-4154-84e6-142c0f7f6360,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-62e753a5-964a-4e1e-a2a5-aa96ef3e71d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-c374144b-515e-4a3f-be56-5cbfdf155bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-aff39577-988e-408f-b87c-8bb9765495db,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-a025c9f7-1311-4d04-b838-edb2ebd5c333,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-cd0916f1-5a1d-4f7e-8a57-eef905f4471c,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-8b8b20f4-8ab9-4814-ac01-3cbaf9d4fd73,DISK], DatanodeInfoWithStorage[127.0.0.1:45233,DS-00b11766-542c-49b7-b8bf-d271d0b9bff2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-646770768-172.17.0.6-1595912544693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38627,DS-cfb39bc1-de91-4154-84e6-142c0f7f6360,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-62e753a5-964a-4e1e-a2a5-aa96ef3e71d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-c374144b-515e-4a3f-be56-5cbfdf155bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-aff39577-988e-408f-b87c-8bb9765495db,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-a025c9f7-1311-4d04-b838-edb2ebd5c333,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-cd0916f1-5a1d-4f7e-8a57-eef905f4471c,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-8b8b20f4-8ab9-4814-ac01-3cbaf9d4fd73,DISK], DatanodeInfoWithStorage[127.0.0.1:45233,DS-00b11766-542c-49b7-b8bf-d271d0b9bff2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-432564516-172.17.0.6-1595913271675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40500,DS-1ea889bc-389f-4e08-a346-4d444aef5a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35643,DS-0baf2ed8-d8d2-4e2a-bcdf-fb321be97f56,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-7a53cb8f-c695-4a54-8824-96375bdb653b,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-7a65a0bb-a0c3-4b1c-9f38-f4fdf7bfeff7,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-5c792259-dbf2-48aa-bcc2-3bbcac9acfce,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-ebbd3c04-0723-49ae-a8c7-05673fab417c,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-ea8f6b2a-d871-4467-96a1-1c6eed834aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:44332,DS-eb3e9882-cb32-4a9c-82fd-1aa48e6565a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-432564516-172.17.0.6-1595913271675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40500,DS-1ea889bc-389f-4e08-a346-4d444aef5a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35643,DS-0baf2ed8-d8d2-4e2a-bcdf-fb321be97f56,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-7a53cb8f-c695-4a54-8824-96375bdb653b,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-7a65a0bb-a0c3-4b1c-9f38-f4fdf7bfeff7,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-5c792259-dbf2-48aa-bcc2-3bbcac9acfce,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-ebbd3c04-0723-49ae-a8c7-05673fab417c,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-ea8f6b2a-d871-4467-96a1-1c6eed834aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:44332,DS-eb3e9882-cb32-4a9c-82fd-1aa48e6565a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 7128
