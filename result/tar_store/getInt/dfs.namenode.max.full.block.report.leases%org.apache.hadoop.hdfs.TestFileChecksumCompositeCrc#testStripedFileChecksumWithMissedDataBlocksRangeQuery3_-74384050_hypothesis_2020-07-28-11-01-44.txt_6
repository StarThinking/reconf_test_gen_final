reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1664908485-172.17.0.7-1595934155234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38527,DS-b3486f84-3aa9-47e2-9551-34e6a617bcba,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-44679577-4705-4f01-abb5-770e692860d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-eabc8970-de19-40a4-9d9b-0e57e0cf5d90,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-3e1f8cf4-5620-41b7-810d-00df11946f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-61cf210e-a33a-4cce-9a0c-238aba57ea94,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-cc12bf5b-ccf4-4ff9-8bdc-b09061048035,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-c362edf1-1376-4465-870c-aca67397bd91,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-d8c209a6-8683-4d16-9aef-3a6b42b0c71e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1664908485-172.17.0.7-1595934155234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38527,DS-b3486f84-3aa9-47e2-9551-34e6a617bcba,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-44679577-4705-4f01-abb5-770e692860d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-eabc8970-de19-40a4-9d9b-0e57e0cf5d90,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-3e1f8cf4-5620-41b7-810d-00df11946f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-61cf210e-a33a-4cce-9a0c-238aba57ea94,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-cc12bf5b-ccf4-4ff9-8bdc-b09061048035,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-c362edf1-1376-4465-870c-aca67397bd91,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-d8c209a6-8683-4d16-9aef-3a6b42b0c71e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1949450797-172.17.0.7-1595934444717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42359,DS-9dc53199-4246-4624-9da6-d13129720adb,DISK], DatanodeInfoWithStorage[127.0.0.1:34416,DS-74fcc39b-6dfb-461b-aec3-480abd834c11,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-976d126b-3511-426e-b4a5-c87fc5340062,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-69b8f25a-85b3-41fc-b2f4-ec7cfca674f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38303,DS-25eb631d-f65f-4575-ac6d-c3ae5c045543,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-d497dc06-ee7d-40d0-a4cb-e843536feeb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-8954f507-9ce0-4ed4-b3d3-d08f4b4e017b,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-ea4baf14-c4ff-43a9-9b7e-eb764e5a88fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1949450797-172.17.0.7-1595934444717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42359,DS-9dc53199-4246-4624-9da6-d13129720adb,DISK], DatanodeInfoWithStorage[127.0.0.1:34416,DS-74fcc39b-6dfb-461b-aec3-480abd834c11,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-976d126b-3511-426e-b4a5-c87fc5340062,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-69b8f25a-85b3-41fc-b2f4-ec7cfca674f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38303,DS-25eb631d-f65f-4575-ac6d-c3ae5c045543,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-d497dc06-ee7d-40d0-a4cb-e843536feeb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-8954f507-9ce0-4ed4-b3d3-d08f4b4e017b,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-ea4baf14-c4ff-43a9-9b7e-eb764e5a88fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1305464644-172.17.0.7-1595935195104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42498,DS-b3f11ae6-bfe6-4203-8b3c-164fb5d664ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-1f2a44a8-6e96-4552-bf6d-fa05a62fdbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42617,DS-944b1c30-a1ed-4d49-9765-e60f77c8784f,DISK], DatanodeInfoWithStorage[127.0.0.1:46239,DS-f249089c-89f5-4a66-b767-b05b3aeaa14e,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-be333363-b5ed-4dad-b2ef-e27d12b974a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-cfd35a9e-d5ac-42a6-a496-562a423149fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-732ff02f-a417-46ee-bb7e-3aa2c97902c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-53e87f94-c45e-4a62-ad8d-0d8cbd442783,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1305464644-172.17.0.7-1595935195104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42498,DS-b3f11ae6-bfe6-4203-8b3c-164fb5d664ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-1f2a44a8-6e96-4552-bf6d-fa05a62fdbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42617,DS-944b1c30-a1ed-4d49-9765-e60f77c8784f,DISK], DatanodeInfoWithStorage[127.0.0.1:46239,DS-f249089c-89f5-4a66-b767-b05b3aeaa14e,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-be333363-b5ed-4dad-b2ef-e27d12b974a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-cfd35a9e-d5ac-42a6-a496-562a423149fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-732ff02f-a417-46ee-bb7e-3aa2c97902c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-53e87f94-c45e-4a62-ad8d-0d8cbd442783,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1434314902-172.17.0.7-1595935342402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43368,DS-8cbcbecf-1236-4083-ba2f-5fd1f553fd9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-82849607-878d-4071-8798-31d78f3acee2,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-cf2805bf-dbda-4520-9de7-51c9f481a862,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-09d39a89-dbf8-46c1-aab0-1ccd0eba01ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-020f504e-cbda-4daf-830f-0333ae6549c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-c7a316e2-64eb-40e3-a71a-11d43532facf,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-463d12d6-39c3-4380-a140-fecfa8347d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-59d7620f-d432-40dc-9593-a04479b3e822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1434314902-172.17.0.7-1595935342402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43368,DS-8cbcbecf-1236-4083-ba2f-5fd1f553fd9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-82849607-878d-4071-8798-31d78f3acee2,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-cf2805bf-dbda-4520-9de7-51c9f481a862,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-09d39a89-dbf8-46c1-aab0-1ccd0eba01ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-020f504e-cbda-4daf-830f-0333ae6549c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-c7a316e2-64eb-40e3-a71a-11d43532facf,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-463d12d6-39c3-4380-a140-fecfa8347d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-59d7620f-d432-40dc-9593-a04479b3e822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-568052103-172.17.0.7-1595935501586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37533,DS-e685a794-1668-4f3c-ae70-ebfe84d0bba4,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-436d068c-21de-4a3c-a97b-57cec48117d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-86927a57-221a-4b03-b6a7-22f2faf6bdfe,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-31cefdfa-7641-4460-beb9-0310286aff8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-65fa923c-538a-4653-999d-9e102e951932,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-71ba2d5c-67c6-44eb-a486-dc3d66ca9a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36540,DS-391c797b-4a3c-479c-8863-2b6db0a945cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-00768377-a5ac-47c7-a40f-a59393521607,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-568052103-172.17.0.7-1595935501586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37533,DS-e685a794-1668-4f3c-ae70-ebfe84d0bba4,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-436d068c-21de-4a3c-a97b-57cec48117d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-86927a57-221a-4b03-b6a7-22f2faf6bdfe,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-31cefdfa-7641-4460-beb9-0310286aff8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-65fa923c-538a-4653-999d-9e102e951932,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-71ba2d5c-67c6-44eb-a486-dc3d66ca9a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36540,DS-391c797b-4a3c-479c-8863-2b6db0a945cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-00768377-a5ac-47c7-a40f-a59393521607,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-440228870-172.17.0.7-1595935685788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37616,DS-50cf9393-cb41-48f1-8061-9bba5e0f377a,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-b9ec1613-75ab-4995-85b7-419b12ac4e01,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-7d44fc26-6038-4fec-8352-472c81960440,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-64cb2bbe-28e5-4ea0-ba0f-285ef0b5d041,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-96711b26-a7f0-4c5b-b0a5-2e28b5d9bfdc,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-0f4e250b-c615-47e4-842d-def6123b6b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-fde91e9e-8c31-4968-9f6e-d9273da572ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-3d1b8e16-0c88-4600-aca5-92b0f569fee1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-440228870-172.17.0.7-1595935685788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37616,DS-50cf9393-cb41-48f1-8061-9bba5e0f377a,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-b9ec1613-75ab-4995-85b7-419b12ac4e01,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-7d44fc26-6038-4fec-8352-472c81960440,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-64cb2bbe-28e5-4ea0-ba0f-285ef0b5d041,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-96711b26-a7f0-4c5b-b0a5-2e28b5d9bfdc,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-0f4e250b-c615-47e4-842d-def6123b6b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-fde91e9e-8c31-4968-9f6e-d9273da572ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-3d1b8e16-0c88-4600-aca5-92b0f569fee1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-958346343-172.17.0.7-1595936337676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42536,DS-8fa88885-a7d0-4dfc-9b11-ba3f3f3e5b87,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-5efcae0d-729a-4117-a647-c2b83d510d02,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-5d1b6bf0-3aa4-46a0-baac-efa56c11ac3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-425eb8dd-2dd4-4d6e-ab17-47c606810416,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-0514366f-081b-4d14-a4b9-acb2b44a6f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-afabf908-9b30-4c2d-80d3-6792da4d3096,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-9f042f29-3d0b-4195-a009-d5692388c054,DISK], DatanodeInfoWithStorage[127.0.0.1:41935,DS-c46be723-6bce-4e3f-8a35-4d58336c7f38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-958346343-172.17.0.7-1595936337676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42536,DS-8fa88885-a7d0-4dfc-9b11-ba3f3f3e5b87,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-5efcae0d-729a-4117-a647-c2b83d510d02,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-5d1b6bf0-3aa4-46a0-baac-efa56c11ac3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-425eb8dd-2dd4-4d6e-ab17-47c606810416,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-0514366f-081b-4d14-a4b9-acb2b44a6f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-afabf908-9b30-4c2d-80d3-6792da4d3096,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-9f042f29-3d0b-4195-a009-d5692388c054,DISK], DatanodeInfoWithStorage[127.0.0.1:41935,DS-c46be723-6bce-4e3f-8a35-4d58336c7f38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1327921972-172.17.0.7-1595936876637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44934,DS-abac4a5a-2e7f-4fe0-9082-d069253c1288,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-9ca9cf43-2644-46db-b2fa-6ba9cf7cccb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-90ae1038-12fb-425c-8d81-ced4da95d33b,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-710b4a8d-b8ce-4863-bac5-fd4ed6ac6444,DISK], DatanodeInfoWithStorage[127.0.0.1:35091,DS-b71c3303-8f08-4643-ad57-31271ccfcba0,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-b77af201-204a-4887-b81f-66a333bc4945,DISK], DatanodeInfoWithStorage[127.0.0.1:38026,DS-2a759eed-8d7b-4384-b7e7-c7acff86a85e,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-0be24871-839e-4c56-953a-857df42e0d30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1327921972-172.17.0.7-1595936876637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44934,DS-abac4a5a-2e7f-4fe0-9082-d069253c1288,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-9ca9cf43-2644-46db-b2fa-6ba9cf7cccb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-90ae1038-12fb-425c-8d81-ced4da95d33b,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-710b4a8d-b8ce-4863-bac5-fd4ed6ac6444,DISK], DatanodeInfoWithStorage[127.0.0.1:35091,DS-b71c3303-8f08-4643-ad57-31271ccfcba0,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-b77af201-204a-4887-b81f-66a333bc4945,DISK], DatanodeInfoWithStorage[127.0.0.1:38026,DS-2a759eed-8d7b-4384-b7e7-c7acff86a85e,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-0be24871-839e-4c56-953a-857df42e0d30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-127764646-172.17.0.7-1595936921966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43837,DS-18b685d9-57c8-4c3e-a3dd-220926309b03,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-a372c520-e3dc-4c52-a090-917779d51a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-868c9452-abfa-4a93-b7b4-96d63500e02a,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-76a0d292-2a89-4ece-acdd-d0fdfefb140e,DISK], DatanodeInfoWithStorage[127.0.0.1:46406,DS-da7ddee1-a9b6-426e-8ad3-226b0a48a704,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-647326ab-ea95-4bdf-afa3-f0f82328e780,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-bd3cf670-a60e-45b7-9ad8-a422e4c96295,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-1d5b7370-f72f-49e7-a4c3-639a90e75927,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-127764646-172.17.0.7-1595936921966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43837,DS-18b685d9-57c8-4c3e-a3dd-220926309b03,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-a372c520-e3dc-4c52-a090-917779d51a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-868c9452-abfa-4a93-b7b4-96d63500e02a,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-76a0d292-2a89-4ece-acdd-d0fdfefb140e,DISK], DatanodeInfoWithStorage[127.0.0.1:46406,DS-da7ddee1-a9b6-426e-8ad3-226b0a48a704,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-647326ab-ea95-4bdf-afa3-f0f82328e780,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-bd3cf670-a60e-45b7-9ad8-a422e4c96295,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-1d5b7370-f72f-49e7-a4c3-639a90e75927,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1232213603-172.17.0.7-1595937425791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45567,DS-52c376ae-3f81-442d-afa1-e40ea6caad2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-30e94180-f090-4469-887c-eb9aa86a20e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35462,DS-b57ba5e3-8ef8-4cad-9321-0e4c77b23e26,DISK], DatanodeInfoWithStorage[127.0.0.1:37232,DS-2f4b8746-d44f-4ce4-8f37-eca8dcf5f5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-9553ccf8-044c-4446-9d17-9a64b207a01c,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-c2f336d5-0359-4a6d-b62d-fc716203af05,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-8c42c938-eb4e-48cf-b1d1-006056e83351,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-1e6a938d-5108-40af-84a3-5f11cfee7202,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1232213603-172.17.0.7-1595937425791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45567,DS-52c376ae-3f81-442d-afa1-e40ea6caad2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-30e94180-f090-4469-887c-eb9aa86a20e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35462,DS-b57ba5e3-8ef8-4cad-9321-0e4c77b23e26,DISK], DatanodeInfoWithStorage[127.0.0.1:37232,DS-2f4b8746-d44f-4ce4-8f37-eca8dcf5f5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-9553ccf8-044c-4446-9d17-9a64b207a01c,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-c2f336d5-0359-4a6d-b62d-fc716203af05,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-8c42c938-eb4e-48cf-b1d1-006056e83351,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-1e6a938d-5108-40af-84a3-5f11cfee7202,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2012158606-172.17.0.7-1595937518203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43858,DS-70dae449-7c78-4af3-9a6e-1cc539768c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-d7299572-7850-47c3-aa87-cc4d7a72e136,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-b9ce5fa4-062f-4243-b7c6-50f814ebb643,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-bc21e007-ba9c-45e5-baf8-08be94fc90c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-f7836547-8838-4f13-bfc5-4b1869b0e4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-7cf0f278-e362-418b-a23d-e415a6e5673e,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-1975a8f7-197e-4695-84e4-fc1c3dc41678,DISK], DatanodeInfoWithStorage[127.0.0.1:42358,DS-7db8222a-554f-442e-b221-3ac6d0919f50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2012158606-172.17.0.7-1595937518203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43858,DS-70dae449-7c78-4af3-9a6e-1cc539768c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-d7299572-7850-47c3-aa87-cc4d7a72e136,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-b9ce5fa4-062f-4243-b7c6-50f814ebb643,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-bc21e007-ba9c-45e5-baf8-08be94fc90c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-f7836547-8838-4f13-bfc5-4b1869b0e4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-7cf0f278-e362-418b-a23d-e415a6e5673e,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-1975a8f7-197e-4695-84e4-fc1c3dc41678,DISK], DatanodeInfoWithStorage[127.0.0.1:42358,DS-7db8222a-554f-442e-b221-3ac6d0919f50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-617755788-172.17.0.7-1595937721558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41972,DS-49e77457-c179-4fb7-a49d-2ef333798f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-a53f7936-9922-47e3-bbbc-2ff8ea7a7569,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-e87884d6-d23a-4a7e-a5aa-da77cabc7ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-a48f89a5-4efd-47dc-8e89-aae7b594ae81,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-9ceb10b6-f04e-4cd1-8f76-77bba6983aba,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-317b3a83-77df-492b-8f94-d4a2202d8611,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-26efd948-c749-4c94-97b5-04c5464d11da,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-ea8e5a0a-ceb8-4b7c-9c0f-08a38b14b3bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-617755788-172.17.0.7-1595937721558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41972,DS-49e77457-c179-4fb7-a49d-2ef333798f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-a53f7936-9922-47e3-bbbc-2ff8ea7a7569,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-e87884d6-d23a-4a7e-a5aa-da77cabc7ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-a48f89a5-4efd-47dc-8e89-aae7b594ae81,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-9ceb10b6-f04e-4cd1-8f76-77bba6983aba,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-317b3a83-77df-492b-8f94-d4a2202d8611,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-26efd948-c749-4c94-97b5-04c5464d11da,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-ea8e5a0a-ceb8-4b7c-9c0f-08a38b14b3bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1430867493-172.17.0.7-1595937864162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42197,DS-ffa9d0e0-fcb7-4903-88d7-7af9c520d4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-a21b30fa-b0e6-42f2-9b2e-ccce0caf381b,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-622d68b4-12df-4952-84c5-dcef971a336a,DISK], DatanodeInfoWithStorage[127.0.0.1:46053,DS-719e64be-2499-40a8-83aa-e3a6515dc228,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-8c7b3f6b-4e6a-43c3-9597-298fee65a708,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-fdc882fa-97bb-47c5-9372-73831c5ee2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-78f46ddf-1adc-47a7-b085-de3bc27044d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-ec4f3fd2-4d90-4643-b714-f827d363039c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1430867493-172.17.0.7-1595937864162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42197,DS-ffa9d0e0-fcb7-4903-88d7-7af9c520d4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-a21b30fa-b0e6-42f2-9b2e-ccce0caf381b,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-622d68b4-12df-4952-84c5-dcef971a336a,DISK], DatanodeInfoWithStorage[127.0.0.1:46053,DS-719e64be-2499-40a8-83aa-e3a6515dc228,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-8c7b3f6b-4e6a-43c3-9597-298fee65a708,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-fdc882fa-97bb-47c5-9372-73831c5ee2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-78f46ddf-1adc-47a7-b085-de3bc27044d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-ec4f3fd2-4d90-4643-b714-f827d363039c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1680646635-172.17.0.7-1595938251093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33108,DS-0c34121a-14b3-4da4-98f1-b2e3c5555ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-3bcc9233-bb57-47c7-9dd5-f0f96f19bbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-c94c40a5-0b94-4ca4-8adf-192b34d8df27,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-fecc9e3d-f346-440b-bdf7-e37bb961691c,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-f1851df0-55da-45eb-ac0b-f182467da33b,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-e7cb6196-873e-43ff-9632-710261fb0547,DISK], DatanodeInfoWithStorage[127.0.0.1:37401,DS-75162c1b-8a22-407d-a4e8-50294873d85c,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-348342b9-a27a-45d9-b35f-067778ae5893,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1680646635-172.17.0.7-1595938251093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33108,DS-0c34121a-14b3-4da4-98f1-b2e3c5555ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-3bcc9233-bb57-47c7-9dd5-f0f96f19bbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-c94c40a5-0b94-4ca4-8adf-192b34d8df27,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-fecc9e3d-f346-440b-bdf7-e37bb961691c,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-f1851df0-55da-45eb-ac0b-f182467da33b,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-e7cb6196-873e-43ff-9632-710261fb0547,DISK], DatanodeInfoWithStorage[127.0.0.1:37401,DS-75162c1b-8a22-407d-a4e8-50294873d85c,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-348342b9-a27a-45d9-b35f-067778ae5893,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-65036083-172.17.0.7-1595938491859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41645,DS-d414f914-db88-4029-af92-3401fd872982,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-cfe4844f-ecc5-4e07-82c8-2a595bbcd0be,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-0ca0412b-7ca1-49d9-bd3b-039fd386ff9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44054,DS-90044b46-032e-44a1-bc4c-a4d6dc5c0cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-347d6a1c-5d4e-4fd0-8b9c-3168cb3aa766,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-0d1e2624-8a7c-4e57-907d-98edd75ae1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-6e0644e3-a9e8-42fb-a9f5-2cf4ec6b09e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-29767661-063b-4a59-bdf3-08839516e3b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-65036083-172.17.0.7-1595938491859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41645,DS-d414f914-db88-4029-af92-3401fd872982,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-cfe4844f-ecc5-4e07-82c8-2a595bbcd0be,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-0ca0412b-7ca1-49d9-bd3b-039fd386ff9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44054,DS-90044b46-032e-44a1-bc4c-a4d6dc5c0cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-347d6a1c-5d4e-4fd0-8b9c-3168cb3aa766,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-0d1e2624-8a7c-4e57-907d-98edd75ae1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-6e0644e3-a9e8-42fb-a9f5-2cf4ec6b09e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-29767661-063b-4a59-bdf3-08839516e3b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1485471180-172.17.0.7-1595938532975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44070,DS-f58add63-32c0-4c2a-92f5-71470e8d9b25,DISK], DatanodeInfoWithStorage[127.0.0.1:40711,DS-c1560e3f-edc7-41dd-bb3d-7fb1a499396c,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-bc5d400e-3e90-40a9-80fc-fb14f4da0096,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-f225a91a-24f2-4096-b931-072b367b0310,DISK], DatanodeInfoWithStorage[127.0.0.1:42749,DS-a6d2506f-a721-4a51-a195-505eb2023797,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-4b5a94f9-ada7-40bc-b0c8-1ada4ad25863,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-183e9e5f-b2e9-400f-a364-7e9364987f97,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-b30c264f-1791-4d50-872d-1350beb4c74a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1485471180-172.17.0.7-1595938532975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44070,DS-f58add63-32c0-4c2a-92f5-71470e8d9b25,DISK], DatanodeInfoWithStorage[127.0.0.1:40711,DS-c1560e3f-edc7-41dd-bb3d-7fb1a499396c,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-bc5d400e-3e90-40a9-80fc-fb14f4da0096,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-f225a91a-24f2-4096-b931-072b367b0310,DISK], DatanodeInfoWithStorage[127.0.0.1:42749,DS-a6d2506f-a721-4a51-a195-505eb2023797,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-4b5a94f9-ada7-40bc-b0c8-1ada4ad25863,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-183e9e5f-b2e9-400f-a364-7e9364987f97,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-b30c264f-1791-4d50-872d-1350beb4c74a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-626204970-172.17.0.7-1595938921224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33699,DS-d9fa2a3a-f4b7-421b-90d5-708261508280,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-8bd30418-ae35-43e4-a49b-bce259c3b6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-4dbd8428-a25a-4e74-a90a-2ae638deb980,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-613d7052-67a0-40bf-8199-8fb3e3764895,DISK], DatanodeInfoWithStorage[127.0.0.1:36841,DS-973edc7b-489e-4f9a-acb7-e3aa3fa8d938,DISK], DatanodeInfoWithStorage[127.0.0.1:36218,DS-1be129fe-cf79-4ded-948d-2221f850e1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-896fec8f-c5a1-403a-9a73-0ada24a94dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-ad1669c8-93bb-451a-8d6b-12c0301d64b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-626204970-172.17.0.7-1595938921224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33699,DS-d9fa2a3a-f4b7-421b-90d5-708261508280,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-8bd30418-ae35-43e4-a49b-bce259c3b6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-4dbd8428-a25a-4e74-a90a-2ae638deb980,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-613d7052-67a0-40bf-8199-8fb3e3764895,DISK], DatanodeInfoWithStorage[127.0.0.1:36841,DS-973edc7b-489e-4f9a-acb7-e3aa3fa8d938,DISK], DatanodeInfoWithStorage[127.0.0.1:36218,DS-1be129fe-cf79-4ded-948d-2221f850e1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-896fec8f-c5a1-403a-9a73-0ada24a94dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-ad1669c8-93bb-451a-8d6b-12c0301d64b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1654708767-172.17.0.7-1595939294482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42738,DS-16ba2f2a-2bf4-43ae-857c-e4e6803b2fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-ce7ce276-5756-4a09-a026-3bba2bb28cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:46523,DS-064ff661-a6b1-4909-8ebc-584911f0b142,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-e8f1e2e0-b3aa-4ee6-9fa7-b361a76df023,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-cf7d2e40-b4cf-4c59-965a-923a0eaaba5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-8a55f5c7-04ff-4a7e-8137-5bc5a5161b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-b328043d-56dd-4521-9729-7c256af4f005,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-fb52995e-5fb3-48be-b625-3d767bc572fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1654708767-172.17.0.7-1595939294482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42738,DS-16ba2f2a-2bf4-43ae-857c-e4e6803b2fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-ce7ce276-5756-4a09-a026-3bba2bb28cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:46523,DS-064ff661-a6b1-4909-8ebc-584911f0b142,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-e8f1e2e0-b3aa-4ee6-9fa7-b361a76df023,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-cf7d2e40-b4cf-4c59-965a-923a0eaaba5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-8a55f5c7-04ff-4a7e-8137-5bc5a5161b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-b328043d-56dd-4521-9729-7c256af4f005,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-fb52995e-5fb3-48be-b625-3d767bc572fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1753924498-172.17.0.7-1595939456927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38468,DS-df29ae83-8f30-447b-92a7-d8323bac7a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-2e86daaf-216d-4bf7-8167-06406655192c,DISK], DatanodeInfoWithStorage[127.0.0.1:43946,DS-0e446c66-ac1e-4f96-893d-e3a445002048,DISK], DatanodeInfoWithStorage[127.0.0.1:34046,DS-6d9a3009-0d0e-462f-a484-adaeac25cded,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-5f3a8102-0fe5-4669-b262-7135364ef6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-92eb73d0-f35c-43e1-972d-08a65b020c82,DISK], DatanodeInfoWithStorage[127.0.0.1:44345,DS-48bff650-256d-44b4-b266-915a3e0d333f,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-cccdec04-16b7-4f3d-9755-d655be2d9691,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1753924498-172.17.0.7-1595939456927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38468,DS-df29ae83-8f30-447b-92a7-d8323bac7a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-2e86daaf-216d-4bf7-8167-06406655192c,DISK], DatanodeInfoWithStorage[127.0.0.1:43946,DS-0e446c66-ac1e-4f96-893d-e3a445002048,DISK], DatanodeInfoWithStorage[127.0.0.1:34046,DS-6d9a3009-0d0e-462f-a484-adaeac25cded,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-5f3a8102-0fe5-4669-b262-7135364ef6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-92eb73d0-f35c-43e1-972d-08a65b020c82,DISK], DatanodeInfoWithStorage[127.0.0.1:44345,DS-48bff650-256d-44b4-b266-915a3e0d333f,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-cccdec04-16b7-4f3d-9755-d655be2d9691,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1649210088-172.17.0.7-1595939615758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36061,DS-b336dd7c-9fd2-452f-938d-79bb5040aca3,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-1813df2d-74ec-4295-8d94-f122051e7f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-71281708-3525-4d43-a453-08e82a74d65b,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-e63a925d-f977-47a3-931b-9b56fd376255,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-54593802-67ad-4798-b72c-ad8459f14569,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-3318a667-1349-487a-bf0e-97112846b329,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-6545a369-c74b-4ad9-9197-fd44ea86d7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39847,DS-51117428-51b2-42f6-a4e7-b25faa9dfd4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1649210088-172.17.0.7-1595939615758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36061,DS-b336dd7c-9fd2-452f-938d-79bb5040aca3,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-1813df2d-74ec-4295-8d94-f122051e7f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-71281708-3525-4d43-a453-08e82a74d65b,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-e63a925d-f977-47a3-931b-9b56fd376255,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-54593802-67ad-4798-b72c-ad8459f14569,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-3318a667-1349-487a-bf0e-97112846b329,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-6545a369-c74b-4ad9-9197-fd44ea86d7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39847,DS-51117428-51b2-42f6-a4e7-b25faa9dfd4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5609
