reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1708039387-172.17.0.9-1595748458883:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38575,DS-7c248092-ac45-4421-adbb-892d432b79d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-dcb39323-239c-4d6d-ad85-203719ec2633,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-d252f94a-4b97-4d7d-91f9-e833b2fbc469,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-046a27fa-e755-4b02-b02d-98d4d1bc9ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-5ca6f338-3501-4c91-af43-40ac8dd8e38b,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-fcaa9409-4021-43f2-8545-f61a91022ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-16838698-db53-4c94-b5d5-d52f06229bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-01efd121-7412-4836-86bd-5e8da53a7b13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1708039387-172.17.0.9-1595748458883:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38575,DS-7c248092-ac45-4421-adbb-892d432b79d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-dcb39323-239c-4d6d-ad85-203719ec2633,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-d252f94a-4b97-4d7d-91f9-e833b2fbc469,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-046a27fa-e755-4b02-b02d-98d4d1bc9ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-5ca6f338-3501-4c91-af43-40ac8dd8e38b,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-fcaa9409-4021-43f2-8545-f61a91022ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-16838698-db53-4c94-b5d5-d52f06229bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-01efd121-7412-4836-86bd-5e8da53a7b13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1998606797-172.17.0.9-1595748599174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42556,DS-6cea118a-1806-4ae0-8c2b-93aad4f6ad85,DISK], DatanodeInfoWithStorage[127.0.0.1:34155,DS-74d34622-5ad3-41de-a9ac-ea47a3a64ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-0370867a-424c-430c-b6c5-578809f8a7da,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-94005780-3912-41a0-b9e2-584c72dd2e74,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-671a8f5b-0d20-4d14-bc0a-8784e3d3b9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-93cbf3a2-ac73-4d95-b676-5a4bb712a683,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-5508a255-6284-47ab-921e-82ce2f0dd6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41888,DS-f8ff0302-a5c3-4a43-b144-d29fc140bec6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1998606797-172.17.0.9-1595748599174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42556,DS-6cea118a-1806-4ae0-8c2b-93aad4f6ad85,DISK], DatanodeInfoWithStorage[127.0.0.1:34155,DS-74d34622-5ad3-41de-a9ac-ea47a3a64ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-0370867a-424c-430c-b6c5-578809f8a7da,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-94005780-3912-41a0-b9e2-584c72dd2e74,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-671a8f5b-0d20-4d14-bc0a-8784e3d3b9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-93cbf3a2-ac73-4d95-b676-5a4bb712a683,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-5508a255-6284-47ab-921e-82ce2f0dd6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41888,DS-f8ff0302-a5c3-4a43-b144-d29fc140bec6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2014435794-172.17.0.9-1595749079636:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43828,DS-2c69de60-1037-4dbd-87c8-9079c469f1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-c0dc75c6-a74e-4c1a-bf1c-d9bccfe14b35,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-45fb8b75-62be-41d2-b20e-8361bfe76a51,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-8df97c2c-e3a4-408d-8a0a-0fa72ea959de,DISK], DatanodeInfoWithStorage[127.0.0.1:36594,DS-d16fe4dc-3165-4e56-a49f-3e325ef24a84,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-46341f0e-3ba4-4e13-a819-ffaddeb2d165,DISK], DatanodeInfoWithStorage[127.0.0.1:35245,DS-c7c2ef86-6018-43c2-9567-395b5d4e9efc,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-34600e25-e770-4e59-bba2-ec4cd0536a85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2014435794-172.17.0.9-1595749079636:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43828,DS-2c69de60-1037-4dbd-87c8-9079c469f1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-c0dc75c6-a74e-4c1a-bf1c-d9bccfe14b35,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-45fb8b75-62be-41d2-b20e-8361bfe76a51,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-8df97c2c-e3a4-408d-8a0a-0fa72ea959de,DISK], DatanodeInfoWithStorage[127.0.0.1:36594,DS-d16fe4dc-3165-4e56-a49f-3e325ef24a84,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-46341f0e-3ba4-4e13-a819-ffaddeb2d165,DISK], DatanodeInfoWithStorage[127.0.0.1:35245,DS-c7c2ef86-6018-43c2-9567-395b5d4e9efc,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-34600e25-e770-4e59-bba2-ec4cd0536a85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-933526347-172.17.0.9-1595749212650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44984,DS-789d1950-5008-43f8-8bce-c406a887b2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-dba5535c-493a-4f3b-83af-bde33c185d81,DISK], DatanodeInfoWithStorage[127.0.0.1:39960,DS-46a3fe4b-3e13-4648-b386-70718351a619,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-6082f8fa-988d-4168-8d55-f211c95e979b,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-cd035451-7beb-420a-b57a-d7d98afa40e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-198f7dc3-dcfe-4769-bea8-9ede82546497,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-b419f55d-c310-48f2-880e-0477e8bac7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-c5c55586-c170-42e4-ae38-436725c06851,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-933526347-172.17.0.9-1595749212650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44984,DS-789d1950-5008-43f8-8bce-c406a887b2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-dba5535c-493a-4f3b-83af-bde33c185d81,DISK], DatanodeInfoWithStorage[127.0.0.1:39960,DS-46a3fe4b-3e13-4648-b386-70718351a619,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-6082f8fa-988d-4168-8d55-f211c95e979b,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-cd035451-7beb-420a-b57a-d7d98afa40e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-198f7dc3-dcfe-4769-bea8-9ede82546497,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-b419f55d-c310-48f2-880e-0477e8bac7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-c5c55586-c170-42e4-ae38-436725c06851,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-686546350-172.17.0.9-1595749868094:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46674,DS-5793e8b1-61cc-467d-9217-afcf3a4c40b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-103815c6-9a7c-499a-961e-efec3f6aed63,DISK], DatanodeInfoWithStorage[127.0.0.1:39963,DS-1c2f45f5-7849-4714-bf7d-c859872f090b,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-ab5b0f44-91ee-4c8f-a568-afa336bd2387,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-0aeb0f88-c6f4-43af-92de-c4fca5e48595,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-d15a4a3b-fe65-4b32-9666-5146de9b1564,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-409017a5-6968-4ace-8fb3-9e686bed573c,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-6a1f1338-6ecb-4437-b543-b6cf5a64bb00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-686546350-172.17.0.9-1595749868094:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46674,DS-5793e8b1-61cc-467d-9217-afcf3a4c40b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-103815c6-9a7c-499a-961e-efec3f6aed63,DISK], DatanodeInfoWithStorage[127.0.0.1:39963,DS-1c2f45f5-7849-4714-bf7d-c859872f090b,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-ab5b0f44-91ee-4c8f-a568-afa336bd2387,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-0aeb0f88-c6f4-43af-92de-c4fca5e48595,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-d15a4a3b-fe65-4b32-9666-5146de9b1564,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-409017a5-6968-4ace-8fb3-9e686bed573c,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-6a1f1338-6ecb-4437-b543-b6cf5a64bb00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1822396022-172.17.0.9-1595750160996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43200,DS-a8358946-61ac-4608-a24e-6e7fe141946c,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-5b2527a9-1a3c-430b-a8f4-6fac9ee517ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-a6eef7db-ba89-45b5-a086-fc241328aed4,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-b1b7fe66-1f21-44a7-a5de-fcfe9068f37c,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-fb0a4e4c-da93-4812-a8b8-409b49d7411d,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-73a899b5-ce45-4ef6-a768-37e4c8ebfea2,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-05464124-64fe-4419-9a31-a745e0448b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-4f9e75b9-d757-4692-9aa2-d334c8766bef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1822396022-172.17.0.9-1595750160996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43200,DS-a8358946-61ac-4608-a24e-6e7fe141946c,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-5b2527a9-1a3c-430b-a8f4-6fac9ee517ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-a6eef7db-ba89-45b5-a086-fc241328aed4,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-b1b7fe66-1f21-44a7-a5de-fcfe9068f37c,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-fb0a4e4c-da93-4812-a8b8-409b49d7411d,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-73a899b5-ce45-4ef6-a768-37e4c8ebfea2,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-05464124-64fe-4419-9a31-a745e0448b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-4f9e75b9-d757-4692-9aa2-d334c8766bef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-675357950-172.17.0.9-1595750250143:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35112,DS-c316aeff-187e-42a1-b77b-1baca5217e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-2c683b45-b598-4751-a747-f26b494cc583,DISK], DatanodeInfoWithStorage[127.0.0.1:43154,DS-e506cf7f-1d5f-4ea3-a734-c7664b68566c,DISK], DatanodeInfoWithStorage[127.0.0.1:38126,DS-d948bd59-f32f-4352-b60f-38234fdd6d51,DISK], DatanodeInfoWithStorage[127.0.0.1:35686,DS-981610ba-b061-4474-be2c-e4a11f8b7247,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-8f8ed973-c076-4f14-a78b-f56433eebd83,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-bcb66afd-be4a-41c8-88ef-88bad411eec4,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-cb93cfa6-d1b0-476f-b478-89f808b452a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-675357950-172.17.0.9-1595750250143:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35112,DS-c316aeff-187e-42a1-b77b-1baca5217e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-2c683b45-b598-4751-a747-f26b494cc583,DISK], DatanodeInfoWithStorage[127.0.0.1:43154,DS-e506cf7f-1d5f-4ea3-a734-c7664b68566c,DISK], DatanodeInfoWithStorage[127.0.0.1:38126,DS-d948bd59-f32f-4352-b60f-38234fdd6d51,DISK], DatanodeInfoWithStorage[127.0.0.1:35686,DS-981610ba-b061-4474-be2c-e4a11f8b7247,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-8f8ed973-c076-4f14-a78b-f56433eebd83,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-bcb66afd-be4a-41c8-88ef-88bad411eec4,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-cb93cfa6-d1b0-476f-b478-89f808b452a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1231880785-172.17.0.9-1595751548721:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44541,DS-9fc6b7b6-926b-4bbb-a5d1-aa5316bbd0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-8f89504f-dddc-4e8a-9360-dd8261c3e6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-cdf4eed7-7b7f-4ff1-a59f-1fc4157b1e73,DISK], DatanodeInfoWithStorage[127.0.0.1:35643,DS-3619618c-689c-4f7a-9dc5-11eb07517815,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-7006dc3a-4bb3-4107-bcc7-f3f1a8c7b23e,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-dc8462dc-c3d7-4194-b093-783eaded8d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-0ae15c40-aad5-4a89-8c2c-35863f1b20d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-34698118-7a04-4caa-ab82-75977ee540dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1231880785-172.17.0.9-1595751548721:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44541,DS-9fc6b7b6-926b-4bbb-a5d1-aa5316bbd0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-8f89504f-dddc-4e8a-9360-dd8261c3e6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-cdf4eed7-7b7f-4ff1-a59f-1fc4157b1e73,DISK], DatanodeInfoWithStorage[127.0.0.1:35643,DS-3619618c-689c-4f7a-9dc5-11eb07517815,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-7006dc3a-4bb3-4107-bcc7-f3f1a8c7b23e,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-dc8462dc-c3d7-4194-b093-783eaded8d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-0ae15c40-aad5-4a89-8c2c-35863f1b20d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-34698118-7a04-4caa-ab82-75977ee540dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-163682715-172.17.0.9-1595751949456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36526,DS-f3ccf698-5887-4ca9-b9d0-199e36249891,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-542a96b3-649f-401e-9fed-8cf818029bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42113,DS-04f3a0ec-251f-4e1c-9398-fe7f3e90067d,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-5f55ead5-3d38-4f98-b6f8-562b25190862,DISK], DatanodeInfoWithStorage[127.0.0.1:45084,DS-7e29b465-98d8-4c9c-a542-d9b5cb82ef07,DISK], DatanodeInfoWithStorage[127.0.0.1:38948,DS-34648dad-28a5-4c55-8de4-eb96433c87f3,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-b06b5c71-43fd-4585-9e75-d5c765ec8eef,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-4b2fbe2e-a2ef-4da5-8438-0592372164fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-163682715-172.17.0.9-1595751949456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36526,DS-f3ccf698-5887-4ca9-b9d0-199e36249891,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-542a96b3-649f-401e-9fed-8cf818029bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42113,DS-04f3a0ec-251f-4e1c-9398-fe7f3e90067d,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-5f55ead5-3d38-4f98-b6f8-562b25190862,DISK], DatanodeInfoWithStorage[127.0.0.1:45084,DS-7e29b465-98d8-4c9c-a542-d9b5cb82ef07,DISK], DatanodeInfoWithStorage[127.0.0.1:38948,DS-34648dad-28a5-4c55-8de4-eb96433c87f3,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-b06b5c71-43fd-4585-9e75-d5c765ec8eef,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-4b2fbe2e-a2ef-4da5-8438-0592372164fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1869385265-172.17.0.9-1595752219872:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45211,DS-ffde7b54-7cdc-412a-80ef-4bfece9c353c,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-19982962-f6ef-41f5-b28a-87b57cf7fb30,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-7d87b51a-a7da-4725-944c-1c6003b203c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-180d1eeb-bab3-4a61-899c-0b119ca345df,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-0efeea8c-1eed-4ffd-a2af-df1226ec0099,DISK], DatanodeInfoWithStorage[127.0.0.1:38152,DS-edd02ed4-f5e5-4159-8ea4-3f76fb5aef43,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-29a670d3-ebd9-4153-a032-f8d6b563c1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-8b6ef884-2ce3-486a-8d9c-8786f17899b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1869385265-172.17.0.9-1595752219872:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45211,DS-ffde7b54-7cdc-412a-80ef-4bfece9c353c,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-19982962-f6ef-41f5-b28a-87b57cf7fb30,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-7d87b51a-a7da-4725-944c-1c6003b203c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-180d1eeb-bab3-4a61-899c-0b119ca345df,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-0efeea8c-1eed-4ffd-a2af-df1226ec0099,DISK], DatanodeInfoWithStorage[127.0.0.1:38152,DS-edd02ed4-f5e5-4159-8ea4-3f76fb5aef43,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-29a670d3-ebd9-4153-a032-f8d6b563c1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-8b6ef884-2ce3-486a-8d9c-8786f17899b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-248490927-172.17.0.9-1595752582045:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41132,DS-8e7d133a-8831-4758-bcc7-ff17e1d12d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-f5373a58-add4-4600-a488-b5592ddd9f68,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-cc7082ad-d678-4cd1-89f9-e2a3627a3f31,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-6640ec54-4018-41e2-af97-2bfcf6e34bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-47881ca0-77a1-441a-9e08-c315ba348c53,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-c7775cfb-5a9d-4d13-afe5-8e5d62bc65cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-99d4ae53-5bb2-4853-a321-5044aad66951,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-a7625cea-9311-4a87-bd1b-1599953243c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-248490927-172.17.0.9-1595752582045:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41132,DS-8e7d133a-8831-4758-bcc7-ff17e1d12d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-f5373a58-add4-4600-a488-b5592ddd9f68,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-cc7082ad-d678-4cd1-89f9-e2a3627a3f31,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-6640ec54-4018-41e2-af97-2bfcf6e34bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-47881ca0-77a1-441a-9e08-c315ba348c53,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-c7775cfb-5a9d-4d13-afe5-8e5d62bc65cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-99d4ae53-5bb2-4853-a321-5044aad66951,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-a7625cea-9311-4a87-bd1b-1599953243c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-96898589-172.17.0.9-1595752765726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39497,DS-59f3479e-4c62-4260-b6fa-757d355b2d80,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-3e6582cd-c73e-437a-975f-9dac385351e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-5c5b68de-8a87-41a8-898b-b50b39159e92,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-7516c7e7-b00c-4e1c-bf13-72ae5feba3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-61912d42-5c53-4d0b-b6af-29281500f8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-87b43511-f2cc-4c79-9834-af7d8edb9c14,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-335bab2f-f0f5-4368-8dd5-56590ee25bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-28a143fd-54bc-4e56-967d-1d9f76b4b0d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-96898589-172.17.0.9-1595752765726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39497,DS-59f3479e-4c62-4260-b6fa-757d355b2d80,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-3e6582cd-c73e-437a-975f-9dac385351e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-5c5b68de-8a87-41a8-898b-b50b39159e92,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-7516c7e7-b00c-4e1c-bf13-72ae5feba3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-61912d42-5c53-4d0b-b6af-29281500f8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-87b43511-f2cc-4c79-9834-af7d8edb9c14,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-335bab2f-f0f5-4368-8dd5-56590ee25bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-28a143fd-54bc-4e56-967d-1d9f76b4b0d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-20153102-172.17.0.9-1595753138861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33988,DS-19f5b03f-e107-4f30-991f-82401aba8a64,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-c76c0c6c-8e06-484f-b04f-e2deea7b9a97,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-7330e676-7f09-46bd-9ba1-a36a12f536f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-ec33453e-8352-484e-8034-ee9dca01d037,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-c173b907-8099-44d2-96d0-c53b5224abb6,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-fb0305cc-d956-412f-82db-e8c919511307,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-30a2b94a-2d2e-4684-ac1f-545925b80b15,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-fed27251-6d28-40d1-ab9b-b897370a6aca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-20153102-172.17.0.9-1595753138861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33988,DS-19f5b03f-e107-4f30-991f-82401aba8a64,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-c76c0c6c-8e06-484f-b04f-e2deea7b9a97,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-7330e676-7f09-46bd-9ba1-a36a12f536f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-ec33453e-8352-484e-8034-ee9dca01d037,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-c173b907-8099-44d2-96d0-c53b5224abb6,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-fb0305cc-d956-412f-82db-e8c919511307,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-30a2b94a-2d2e-4684-ac1f-545925b80b15,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-fed27251-6d28-40d1-ab9b-b897370a6aca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-685644875-172.17.0.9-1595753773436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43458,DS-c5dc23b8-925c-4938-aa50-d46f0c9e4740,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-56242820-4d25-4d44-be6e-08f3f56c4cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-97a605e0-846b-4a1e-8e8b-5284560714f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-49bc0926-bb00-4085-b327-f2846042e923,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-32946b31-e5a5-4263-bbe8-f5b162e53029,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-010f5c83-c5e7-4bc1-ad41-314a5d0e4c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-02b17276-6313-46d5-a765-667922f6253f,DISK], DatanodeInfoWithStorage[127.0.0.1:35282,DS-8cb4dab5-c3e4-4e6f-b989-b252873b7709,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-685644875-172.17.0.9-1595753773436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43458,DS-c5dc23b8-925c-4938-aa50-d46f0c9e4740,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-56242820-4d25-4d44-be6e-08f3f56c4cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-97a605e0-846b-4a1e-8e8b-5284560714f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-49bc0926-bb00-4085-b327-f2846042e923,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-32946b31-e5a5-4263-bbe8-f5b162e53029,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-010f5c83-c5e7-4bc1-ad41-314a5d0e4c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-02b17276-6313-46d5-a765-667922f6253f,DISK], DatanodeInfoWithStorage[127.0.0.1:35282,DS-8cb4dab5-c3e4-4e6f-b989-b252873b7709,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1206794830-172.17.0.9-1595754523609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39809,DS-165bdde6-5fff-4ce2-9972-afe3202d2020,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-73c2843b-fda3-411c-9a82-c95f52d38e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45468,DS-2534fc92-552c-4523-8064-761b21e4cfa5,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-9f1f57d2-f4f0-4ebf-a721-5724686b81ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39812,DS-5f27d826-d8a2-40b5-9b27-a7971e37123f,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-bddcd305-4f3f-4524-b766-3bd2b7e38042,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-376ceb69-bccb-4582-a2c3-f1df782e7bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-1eb46639-5c38-4f18-9e32-b632c21b993d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1206794830-172.17.0.9-1595754523609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39809,DS-165bdde6-5fff-4ce2-9972-afe3202d2020,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-73c2843b-fda3-411c-9a82-c95f52d38e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45468,DS-2534fc92-552c-4523-8064-761b21e4cfa5,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-9f1f57d2-f4f0-4ebf-a721-5724686b81ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39812,DS-5f27d826-d8a2-40b5-9b27-a7971e37123f,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-bddcd305-4f3f-4524-b766-3bd2b7e38042,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-376ceb69-bccb-4582-a2c3-f1df782e7bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-1eb46639-5c38-4f18-9e32-b632c21b993d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1504146214-172.17.0.9-1595754747580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38043,DS-c4c6b553-6c15-4a4e-b350-55002e85240d,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-a0c7452d-643a-4025-8618-fa413aba0a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-f3f1d605-fbc3-4e32-8be2-1e46bccb07e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34440,DS-7ebb61c9-5bac-4bb4-b8b0-fba00adfa344,DISK], DatanodeInfoWithStorage[127.0.0.1:35116,DS-00b0d4a0-3a1e-4cb7-a417-91ee43788e79,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-c5831aa2-3177-4c6d-8403-a7921683f35b,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-485cb6b0-3e62-4c91-8de6-f2c8f9218114,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-276067ae-3e04-4523-a6b0-91cc96212625,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1504146214-172.17.0.9-1595754747580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38043,DS-c4c6b553-6c15-4a4e-b350-55002e85240d,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-a0c7452d-643a-4025-8618-fa413aba0a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-f3f1d605-fbc3-4e32-8be2-1e46bccb07e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34440,DS-7ebb61c9-5bac-4bb4-b8b0-fba00adfa344,DISK], DatanodeInfoWithStorage[127.0.0.1:35116,DS-00b0d4a0-3a1e-4cb7-a417-91ee43788e79,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-c5831aa2-3177-4c6d-8403-a7921683f35b,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-485cb6b0-3e62-4c91-8de6-f2c8f9218114,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-276067ae-3e04-4523-a6b0-91cc96212625,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1366630479-172.17.0.9-1595754963612:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38657,DS-7f7ef805-9c50-4ac4-acc4-9f7c7d562ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:45736,DS-f24a12fe-841f-4000-8f6d-e0bbe3ebb7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-aecc5183-f3b5-493b-8aa5-5a7976fd0895,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-b0828829-10cd-434a-8172-d8d6dc372c31,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-1924a0e2-eef8-4a33-a38d-aee0c320e9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-20ca1896-a674-4590-8fd6-c0e41f3ae906,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-390adb07-14e6-461f-97fc-f5779e531cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-4c964dee-f282-4a74-b58f-246e1820a855,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1366630479-172.17.0.9-1595754963612:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38657,DS-7f7ef805-9c50-4ac4-acc4-9f7c7d562ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:45736,DS-f24a12fe-841f-4000-8f6d-e0bbe3ebb7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-aecc5183-f3b5-493b-8aa5-5a7976fd0895,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-b0828829-10cd-434a-8172-d8d6dc372c31,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-1924a0e2-eef8-4a33-a38d-aee0c320e9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-20ca1896-a674-4590-8fd6-c0e41f3ae906,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-390adb07-14e6-461f-97fc-f5779e531cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-4c964dee-f282-4a74-b58f-246e1820a855,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-651701511-172.17.0.9-1595755100686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42117,DS-e2f42237-1c65-4670-9915-b07dcb4860b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-b4678fd3-ddd9-40bd-87cd-14f1f1ae1f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-13aa0d7d-b498-49aa-aa87-50a87f145931,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-fc45d1d0-eadc-4266-8448-b6bd8d220005,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-b6e6bb93-e73f-45d6-8c22-e8ebbaf5881b,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-d1f17fc8-48a5-4a58-bbfc-52add4f74946,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-52db34ca-9129-4cea-ab9f-44e498dbaac4,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-9d8788c8-2df1-4761-8c77-49d318d74656,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-651701511-172.17.0.9-1595755100686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42117,DS-e2f42237-1c65-4670-9915-b07dcb4860b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-b4678fd3-ddd9-40bd-87cd-14f1f1ae1f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-13aa0d7d-b498-49aa-aa87-50a87f145931,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-fc45d1d0-eadc-4266-8448-b6bd8d220005,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-b6e6bb93-e73f-45d6-8c22-e8ebbaf5881b,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-d1f17fc8-48a5-4a58-bbfc-52add4f74946,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-52db34ca-9129-4cea-ab9f-44e498dbaac4,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-9d8788c8-2df1-4761-8c77-49d318d74656,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 6818
