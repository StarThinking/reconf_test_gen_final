reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-40112245-172.17.0.12-1595615905272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39921,DS-43efe05b-5f49-4abe-88b3-e0341e38d69c,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-ffffd90b-77f6-42f3-9d60-a9b714cee29d,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-3b1499ba-1303-49f5-b299-6a6a2d878484,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-75644899-f8f5-444c-a8f4-f01970717d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41957,DS-d3f87723-004a-4e6b-b213-e68cad81095f,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-944e44b6-f260-4ec3-a96c-f3cbd35ff215,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-f4602980-5bda-46a3-a867-4f14c183df3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43558,DS-2a2ad5fd-2cc1-48a4-8f47-278942c5d1b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-40112245-172.17.0.12-1595615905272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39921,DS-43efe05b-5f49-4abe-88b3-e0341e38d69c,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-ffffd90b-77f6-42f3-9d60-a9b714cee29d,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-3b1499ba-1303-49f5-b299-6a6a2d878484,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-75644899-f8f5-444c-a8f4-f01970717d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41957,DS-d3f87723-004a-4e6b-b213-e68cad81095f,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-944e44b6-f260-4ec3-a96c-f3cbd35ff215,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-f4602980-5bda-46a3-a867-4f14c183df3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43558,DS-2a2ad5fd-2cc1-48a4-8f47-278942c5d1b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-914001900-172.17.0.12-1595616066225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40120,DS-f892739f-e2a1-46f5-9aa7-a226e67cf20d,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-a0c54e36-0772-4bb5-bb87-cd91c834cc17,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-1996bae3-81ea-4487-98f3-c5b5c4e148dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-63fbc4e3-f64c-4dfc-a57d-1f8ee9bfa277,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-26929bcf-1a9d-45a6-83db-919204c0905d,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-263bad29-3185-4490-893d-dffb695bdb52,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-ed312383-d5d6-4142-8715-ffe2b3877146,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-861cf259-13f1-4273-a643-573799d7370e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-914001900-172.17.0.12-1595616066225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40120,DS-f892739f-e2a1-46f5-9aa7-a226e67cf20d,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-a0c54e36-0772-4bb5-bb87-cd91c834cc17,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-1996bae3-81ea-4487-98f3-c5b5c4e148dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-63fbc4e3-f64c-4dfc-a57d-1f8ee9bfa277,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-26929bcf-1a9d-45a6-83db-919204c0905d,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-263bad29-3185-4490-893d-dffb695bdb52,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-ed312383-d5d6-4142-8715-ffe2b3877146,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-861cf259-13f1-4273-a643-573799d7370e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-904150761-172.17.0.12-1595616383714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36934,DS-36279eb9-dbc4-4f4d-8c67-a31b2334ff90,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-111f35df-ee84-4c9c-809c-e34ec286d818,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-47c5ba16-f447-4c95-8862-3f62eb779a42,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-f48ddfe4-79e7-4078-9d4a-acd023f51396,DISK], DatanodeInfoWithStorage[127.0.0.1:34558,DS-25ae2e97-5c2b-46bb-9a05-2736a6c01ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-cb52f6d8-3af5-4a15-adfe-05dace46ed0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45482,DS-7e64f41a-3816-4b15-8b2d-385c4551f2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-6e42d341-6c2e-4df4-be3d-12fd2773aba9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-904150761-172.17.0.12-1595616383714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36934,DS-36279eb9-dbc4-4f4d-8c67-a31b2334ff90,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-111f35df-ee84-4c9c-809c-e34ec286d818,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-47c5ba16-f447-4c95-8862-3f62eb779a42,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-f48ddfe4-79e7-4078-9d4a-acd023f51396,DISK], DatanodeInfoWithStorage[127.0.0.1:34558,DS-25ae2e97-5c2b-46bb-9a05-2736a6c01ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-cb52f6d8-3af5-4a15-adfe-05dace46ed0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45482,DS-7e64f41a-3816-4b15-8b2d-385c4551f2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-6e42d341-6c2e-4df4-be3d-12fd2773aba9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-971714397-172.17.0.12-1595616702899:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33071,DS-c1a9f9bc-88ae-4f88-a481-0b86e01e0707,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-e89b827b-8302-4e4f-b1f4-0ef34e5851ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-b6b074a0-9b5d-4522-ad98-f4547aec5cea,DISK], DatanodeInfoWithStorage[127.0.0.1:46844,DS-19768716-a997-4936-8f2b-b703dfce76ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-2d9a3c3f-1842-4574-b570-08086ddc305c,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-5dfefbee-cb5d-4f4c-b003-a1e520428c40,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-93dd6dea-1794-4978-9869-a66d49c6f54c,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-d66da848-547a-4498-8592-cb38a4956b3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-971714397-172.17.0.12-1595616702899:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33071,DS-c1a9f9bc-88ae-4f88-a481-0b86e01e0707,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-e89b827b-8302-4e4f-b1f4-0ef34e5851ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-b6b074a0-9b5d-4522-ad98-f4547aec5cea,DISK], DatanodeInfoWithStorage[127.0.0.1:46844,DS-19768716-a997-4936-8f2b-b703dfce76ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-2d9a3c3f-1842-4574-b570-08086ddc305c,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-5dfefbee-cb5d-4f4c-b003-a1e520428c40,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-93dd6dea-1794-4978-9869-a66d49c6f54c,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-d66da848-547a-4498-8592-cb38a4956b3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1457084393-172.17.0.12-1595616844354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45324,DS-fefabb38-51c5-4753-b5c3-1cb994044753,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-08ebfacf-ca80-4a67-ac85-834b2c687bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-dbd1c51f-8d8b-4414-b89a-c53b62336738,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-31ba996b-5173-4580-8196-5c6b58353246,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-fd8e9769-047a-40b4-82c7-fdb562a37736,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-0263efe6-7390-4c1a-8ab2-8b82fe5f904f,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-46a6bbe2-1a05-46fa-9e3c-e646f08cd207,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-51dd36f0-835c-4e28-bf07-efd31404763a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1457084393-172.17.0.12-1595616844354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45324,DS-fefabb38-51c5-4753-b5c3-1cb994044753,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-08ebfacf-ca80-4a67-ac85-834b2c687bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-dbd1c51f-8d8b-4414-b89a-c53b62336738,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-31ba996b-5173-4580-8196-5c6b58353246,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-fd8e9769-047a-40b4-82c7-fdb562a37736,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-0263efe6-7390-4c1a-8ab2-8b82fe5f904f,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-46a6bbe2-1a05-46fa-9e3c-e646f08cd207,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-51dd36f0-835c-4e28-bf07-efd31404763a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1921815784-172.17.0.12-1595617162696:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34327,DS-fb72fda8-eaf7-4b9b-a5c2-c646c97b523f,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-f30b4175-6c6a-496b-a7df-ca539a93c04b,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-db18d818-c499-44bc-8695-c0a9b61713ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-d0c8227c-c125-4f2f-b447-e80420bafed4,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-0da7f4ce-a96a-4f1e-b6fc-e8662f8e45de,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-87f867d8-e638-4629-9b24-7475bec83db0,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-77a6bfb6-358d-4d02-bbba-6da4514f0635,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-061f0b74-41eb-4813-b504-e1e7a2a64cfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1921815784-172.17.0.12-1595617162696:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34327,DS-fb72fda8-eaf7-4b9b-a5c2-c646c97b523f,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-f30b4175-6c6a-496b-a7df-ca539a93c04b,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-db18d818-c499-44bc-8695-c0a9b61713ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-d0c8227c-c125-4f2f-b447-e80420bafed4,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-0da7f4ce-a96a-4f1e-b6fc-e8662f8e45de,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-87f867d8-e638-4629-9b24-7475bec83db0,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-77a6bfb6-358d-4d02-bbba-6da4514f0635,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-061f0b74-41eb-4813-b504-e1e7a2a64cfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1110562074-172.17.0.12-1595617337015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44805,DS-a301c55e-0ab9-4449-97aa-5fb57a72599c,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-5d3ec049-0b37-4c07-ab6c-5770dd6590a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37232,DS-a9d17063-0ae9-4e5a-ab51-62e4d9fcdaad,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-ebd12fb9-8786-4788-a146-a35a89a20c83,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-1dd28bf2-f18c-4568-96fb-f72d4487dbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-566edb57-7bc8-4cc8-96c5-0656ff89f2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-44a07599-544b-4c4a-961d-cab7cf7e62c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-73ce54c4-2717-4f88-bd36-da694fee8f7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1110562074-172.17.0.12-1595617337015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44805,DS-a301c55e-0ab9-4449-97aa-5fb57a72599c,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-5d3ec049-0b37-4c07-ab6c-5770dd6590a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37232,DS-a9d17063-0ae9-4e5a-ab51-62e4d9fcdaad,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-ebd12fb9-8786-4788-a146-a35a89a20c83,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-1dd28bf2-f18c-4568-96fb-f72d4487dbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-566edb57-7bc8-4cc8-96c5-0656ff89f2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-44a07599-544b-4c4a-961d-cab7cf7e62c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-73ce54c4-2717-4f88-bd36-da694fee8f7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-5976377-172.17.0.12-1595617486577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34989,DS-29e1da73-6166-4148-92dd-a106a3ac8b66,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-e825771e-5b18-436d-b102-2a754f1e36c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-945002f3-16db-4617-9fbe-cb9d6fe3c8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40776,DS-56066404-93df-4e31-b95e-e48b9ef1a890,DISK], DatanodeInfoWithStorage[127.0.0.1:45534,DS-08b023bd-552f-4682-b83c-8d31f1e2b13a,DISK], DatanodeInfoWithStorage[127.0.0.1:38646,DS-8d892cb1-c626-426e-9ab4-c76ea5f26c11,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-aac47930-1d01-4f58-8f34-aa821e845ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-7c7b3f1c-16dd-4725-823c-9b7ea97e9427,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-5976377-172.17.0.12-1595617486577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34989,DS-29e1da73-6166-4148-92dd-a106a3ac8b66,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-e825771e-5b18-436d-b102-2a754f1e36c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-945002f3-16db-4617-9fbe-cb9d6fe3c8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40776,DS-56066404-93df-4e31-b95e-e48b9ef1a890,DISK], DatanodeInfoWithStorage[127.0.0.1:45534,DS-08b023bd-552f-4682-b83c-8d31f1e2b13a,DISK], DatanodeInfoWithStorage[127.0.0.1:38646,DS-8d892cb1-c626-426e-9ab4-c76ea5f26c11,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-aac47930-1d01-4f58-8f34-aa821e845ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-7c7b3f1c-16dd-4725-823c-9b7ea97e9427,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-325183579-172.17.0.12-1595617674153:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36507,DS-36be6794-c2a3-4873-91db-9b32f28ae432,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-45ea350c-666b-442a-9986-9bcd1ec11b20,DISK], DatanodeInfoWithStorage[127.0.0.1:42813,DS-91840838-fcda-44e9-aff3-8799707ff64d,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-b8f495f2-e79e-41f8-8cd3-6d7b2883a46f,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-9f6d3613-58e2-46e4-a9ea-bad1907e2b82,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-2083b9b8-454c-40b8-9e7d-a9ec6e428c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-f22df50a-0fa9-4470-953d-5ada0e1658b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-95ca8f63-9937-4c39-99b0-5f3f8ae30fcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-325183579-172.17.0.12-1595617674153:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36507,DS-36be6794-c2a3-4873-91db-9b32f28ae432,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-45ea350c-666b-442a-9986-9bcd1ec11b20,DISK], DatanodeInfoWithStorage[127.0.0.1:42813,DS-91840838-fcda-44e9-aff3-8799707ff64d,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-b8f495f2-e79e-41f8-8cd3-6d7b2883a46f,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-9f6d3613-58e2-46e4-a9ea-bad1907e2b82,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-2083b9b8-454c-40b8-9e7d-a9ec6e428c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-f22df50a-0fa9-4470-953d-5ada0e1658b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-95ca8f63-9937-4c39-99b0-5f3f8ae30fcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-6523754-172.17.0.12-1595618198753:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44757,DS-dfae8cea-477c-4880-b73f-ec98001c01fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40388,DS-600760cd-f2ce-4638-a08e-1431fe84d794,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-89673405-3994-4f65-8b96-0b01f5c9453e,DISK], DatanodeInfoWithStorage[127.0.0.1:39376,DS-ab18c1e0-5347-4a14-aa73-133c43493cab,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-65667eac-afbe-47eb-b1a7-3797866a5763,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-37c9afd6-9bf6-41f0-975d-3fee7e0191bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-6c4d9735-d6af-4bdb-873b-35aeff28bb77,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-1bc4d17d-74b9-42db-bc33-c39289409d6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-6523754-172.17.0.12-1595618198753:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44757,DS-dfae8cea-477c-4880-b73f-ec98001c01fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40388,DS-600760cd-f2ce-4638-a08e-1431fe84d794,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-89673405-3994-4f65-8b96-0b01f5c9453e,DISK], DatanodeInfoWithStorage[127.0.0.1:39376,DS-ab18c1e0-5347-4a14-aa73-133c43493cab,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-65667eac-afbe-47eb-b1a7-3797866a5763,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-37c9afd6-9bf6-41f0-975d-3fee7e0191bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-6c4d9735-d6af-4bdb-873b-35aeff28bb77,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-1bc4d17d-74b9-42db-bc33-c39289409d6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-878495606-172.17.0.12-1595618312250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44723,DS-6add7722-1266-4a3b-ae00-b1a08e858bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-fe558488-2082-4f8d-86c7-b6b3f848edec,DISK], DatanodeInfoWithStorage[127.0.0.1:42947,DS-cf49b5e1-6ad9-4dd2-9047-64f369109f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-6520b5d1-f20c-4627-a644-5f1b1f4140f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37626,DS-804de5ce-e63b-450e-840a-6709f3a4ab1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-a0dec741-4bd9-4612-a73a-abe6e80e85ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-9bdf52e4-a1fe-4463-8a4a-2152291c25e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-1e4248ed-191f-4e60-ad8a-f916cd7eab13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-878495606-172.17.0.12-1595618312250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44723,DS-6add7722-1266-4a3b-ae00-b1a08e858bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-fe558488-2082-4f8d-86c7-b6b3f848edec,DISK], DatanodeInfoWithStorage[127.0.0.1:42947,DS-cf49b5e1-6ad9-4dd2-9047-64f369109f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-6520b5d1-f20c-4627-a644-5f1b1f4140f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37626,DS-804de5ce-e63b-450e-840a-6709f3a4ab1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-a0dec741-4bd9-4612-a73a-abe6e80e85ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-9bdf52e4-a1fe-4463-8a4a-2152291c25e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-1e4248ed-191f-4e60-ad8a-f916cd7eab13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1365438413-172.17.0.12-1595618706190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33021,DS-42218fa7-907d-4219-9c3d-093dbda12346,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-ea320719-ac8e-4f53-a6bf-a10ed155c060,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-235ad977-5568-46cb-8549-07d1c07bb905,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-84a34c4c-bc7f-47d5-baba-340e62a10eac,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-e1f86f14-09b2-4d36-ae35-f99645aa324f,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-68981270-6df8-4091-8cf8-6ff5b557b1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-fd8faf37-1e1b-40b0-bc76-e10730ce80ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-b8fde553-cb5f-4ed4-9cf1-73d457f054a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1365438413-172.17.0.12-1595618706190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33021,DS-42218fa7-907d-4219-9c3d-093dbda12346,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-ea320719-ac8e-4f53-a6bf-a10ed155c060,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-235ad977-5568-46cb-8549-07d1c07bb905,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-84a34c4c-bc7f-47d5-baba-340e62a10eac,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-e1f86f14-09b2-4d36-ae35-f99645aa324f,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-68981270-6df8-4091-8cf8-6ff5b557b1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-fd8faf37-1e1b-40b0-bc76-e10730ce80ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-b8fde553-cb5f-4ed4-9cf1-73d457f054a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1484020309-172.17.0.12-1595618767994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35655,DS-390922d7-bfde-46f7-8854-8cc39aa8f2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-bb3f9657-6544-4563-8aab-83efc8014a27,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-9a592bad-c12b-4547-9273-f68b74995bab,DISK], DatanodeInfoWithStorage[127.0.0.1:45227,DS-7dd9e95c-9d43-452f-b0f5-54e44fec93be,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-518b11a6-d05d-4aa2-97a8-65ba6f810d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-2671cf06-f823-4acf-87d2-b229c9547619,DISK], DatanodeInfoWithStorage[127.0.0.1:44281,DS-052dd129-5185-46ef-b8d2-d70ca058e30c,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-760edd08-e56d-402a-821e-bd23df63d8d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1484020309-172.17.0.12-1595618767994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35655,DS-390922d7-bfde-46f7-8854-8cc39aa8f2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-bb3f9657-6544-4563-8aab-83efc8014a27,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-9a592bad-c12b-4547-9273-f68b74995bab,DISK], DatanodeInfoWithStorage[127.0.0.1:45227,DS-7dd9e95c-9d43-452f-b0f5-54e44fec93be,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-518b11a6-d05d-4aa2-97a8-65ba6f810d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-2671cf06-f823-4acf-87d2-b229c9547619,DISK], DatanodeInfoWithStorage[127.0.0.1:44281,DS-052dd129-5185-46ef-b8d2-d70ca058e30c,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-760edd08-e56d-402a-821e-bd23df63d8d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1101484446-172.17.0.12-1595619002523:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43587,DS-190d749b-89ba-4911-b2c9-9e96ce554390,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-5a40f231-d204-4469-b4f7-3aafc7d1d0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-d0bcf64e-52c7-49f2-a8cb-bdcca49a66c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-69b1f117-bdd2-4214-b752-7b4bcb67f8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34594,DS-5ad2d91b-4e16-4a9b-b116-8be9dbe0db2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-75d0b658-f2b1-43e5-ad41-e4332da4b237,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-080eee25-eb1d-4471-9f8f-713f2147922b,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-0a522833-d815-4e57-8bac-f32a7ceb48af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1101484446-172.17.0.12-1595619002523:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43587,DS-190d749b-89ba-4911-b2c9-9e96ce554390,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-5a40f231-d204-4469-b4f7-3aafc7d1d0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-d0bcf64e-52c7-49f2-a8cb-bdcca49a66c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-69b1f117-bdd2-4214-b752-7b4bcb67f8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34594,DS-5ad2d91b-4e16-4a9b-b116-8be9dbe0db2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-75d0b658-f2b1-43e5-ad41-e4332da4b237,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-080eee25-eb1d-4471-9f8f-713f2147922b,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-0a522833-d815-4e57-8bac-f32a7ceb48af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1345399097-172.17.0.12-1595619363218:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35784,DS-fb3da738-d44b-4abd-8c33-124e000c9206,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-f46150d9-7d17-4e44-8a8e-7fce353046d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46069,DS-ae623545-b122-403d-aadc-280fe071a703,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-76cacdc9-7abe-4f5b-a9a7-c3430f09d475,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-2754a3c8-1f1f-472e-95c2-06ae18025876,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-ef7671f9-1d3a-40b2-9c51-7926a28afbd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-1af8a1ef-715f-4926-a59b-d96bfe24ff17,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-2d39f510-82dc-4b72-9540-76741b4df9fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1345399097-172.17.0.12-1595619363218:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35784,DS-fb3da738-d44b-4abd-8c33-124e000c9206,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-f46150d9-7d17-4e44-8a8e-7fce353046d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46069,DS-ae623545-b122-403d-aadc-280fe071a703,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-76cacdc9-7abe-4f5b-a9a7-c3430f09d475,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-2754a3c8-1f1f-472e-95c2-06ae18025876,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-ef7671f9-1d3a-40b2-9c51-7926a28afbd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-1af8a1ef-715f-4926-a59b-d96bfe24ff17,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-2d39f510-82dc-4b72-9540-76741b4df9fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-357303412-172.17.0.12-1595619979149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33712,DS-f128fd2d-2519-43a7-913b-48409505d18e,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-99db1c71-df2a-4e67-9811-11efb9429ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-9e4944df-d75b-4e37-8219-8215e1cc4d20,DISK], DatanodeInfoWithStorage[127.0.0.1:37146,DS-adccbbd5-b229-4021-a885-8577687f2759,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-0d4e6f73-2724-4714-bc6f-a7493d84d1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-9735f8d2-99ec-483e-bf11-6b0cb2d1c295,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-8e5a61b1-c8f5-4241-85c2-018a760939c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-c49203ab-1687-45cb-8ef1-de5ea1d94946,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-357303412-172.17.0.12-1595619979149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33712,DS-f128fd2d-2519-43a7-913b-48409505d18e,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-99db1c71-df2a-4e67-9811-11efb9429ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-9e4944df-d75b-4e37-8219-8215e1cc4d20,DISK], DatanodeInfoWithStorage[127.0.0.1:37146,DS-adccbbd5-b229-4021-a885-8577687f2759,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-0d4e6f73-2724-4714-bc6f-a7493d84d1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-9735f8d2-99ec-483e-bf11-6b0cb2d1c295,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-8e5a61b1-c8f5-4241-85c2-018a760939c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-c49203ab-1687-45cb-8ef1-de5ea1d94946,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-253214255-172.17.0.12-1595620501300:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42262,DS-486a307c-f24d-4b51-8617-137fa3d47faa,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-caee931e-f90f-498c-ac5b-44789fbc0b96,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-caa983f9-01e4-45eb-af12-c823ed3f00ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-16826733-38fc-46b2-9d2d-355e9cb35908,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-da072a4a-0f79-4beb-85ae-0e256183ba2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-13e8b393-3b37-4242-ab12-fd0499d74fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-9634a7f7-1269-48f1-a7cd-67260dc3404c,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-2b678f32-3f56-4f21-bb33-63dc2ff2eee4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-253214255-172.17.0.12-1595620501300:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42262,DS-486a307c-f24d-4b51-8617-137fa3d47faa,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-caee931e-f90f-498c-ac5b-44789fbc0b96,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-caa983f9-01e4-45eb-af12-c823ed3f00ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-16826733-38fc-46b2-9d2d-355e9cb35908,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-da072a4a-0f79-4beb-85ae-0e256183ba2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-13e8b393-3b37-4242-ab12-fd0499d74fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-9634a7f7-1269-48f1-a7cd-67260dc3404c,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-2b678f32-3f56-4f21-bb33-63dc2ff2eee4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2024631083-172.17.0.12-1595620752841:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38663,DS-b2b5f455-7b82-4b2f-bc39-0c8a9a80ec3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-1946cf35-3bf3-4dc7-bad6-82c1ce82446c,DISK], DatanodeInfoWithStorage[127.0.0.1:44609,DS-8611c155-d39a-4189-8c14-37053a119e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-6236f302-9d37-45a9-beef-c8ea83e113a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-8e3de033-68c0-47ee-8640-b0691e42bf3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-2744916e-61f3-4a58-a148-cec70b3af73c,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-29ad08a1-d4f7-4675-ac73-3fd8887fec3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-5d561ff2-06e9-4311-9a7f-cd5ae60355df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2024631083-172.17.0.12-1595620752841:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38663,DS-b2b5f455-7b82-4b2f-bc39-0c8a9a80ec3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-1946cf35-3bf3-4dc7-bad6-82c1ce82446c,DISK], DatanodeInfoWithStorage[127.0.0.1:44609,DS-8611c155-d39a-4189-8c14-37053a119e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-6236f302-9d37-45a9-beef-c8ea83e113a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-8e3de033-68c0-47ee-8640-b0691e42bf3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-2744916e-61f3-4a58-a148-cec70b3af73c,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-29ad08a1-d4f7-4675-ac73-3fd8887fec3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-5d561ff2-06e9-4311-9a7f-cd5ae60355df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5273
