reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 1
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 1
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1221205584-172.17.0.2-1595992792543:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38280,DS-58be863a-8d68-48bb-afcf-90bc526a10b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34001,DS-27cb4b45-7190-4e71-87ae-d470199c65c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-06edd767-4cf5-4f76-aad8-a381d1b02ade,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-0b7fd9b6-9be7-4d05-8c98-857984586d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-3b3ed5f6-bce0-41b8-b261-7a7e9ca31a20,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-4bcb319f-9283-43af-8196-4852ad3489fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33518,DS-4dc27306-b087-4345-b69e-51cfbc20150c,DISK], DatanodeInfoWithStorage[127.0.0.1:33816,DS-5367ba5f-1838-48a9-80c6-adfe9139dcc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1221205584-172.17.0.2-1595992792543:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38280,DS-58be863a-8d68-48bb-afcf-90bc526a10b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34001,DS-27cb4b45-7190-4e71-87ae-d470199c65c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-06edd767-4cf5-4f76-aad8-a381d1b02ade,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-0b7fd9b6-9be7-4d05-8c98-857984586d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-3b3ed5f6-bce0-41b8-b261-7a7e9ca31a20,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-4bcb319f-9283-43af-8196-4852ad3489fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33518,DS-4dc27306-b087-4345-b69e-51cfbc20150c,DISK], DatanodeInfoWithStorage[127.0.0.1:33816,DS-5367ba5f-1838-48a9-80c6-adfe9139dcc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 1
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1704383586-172.17.0.2-1595992957822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34217,DS-cdd913c0-753c-48cc-ba21-9270106f5cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-b80680ae-240d-411d-8589-906743e3707c,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-cee2472e-0362-4ff7-b14c-b224cefc4ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-625a6ae6-e42b-4469-a40e-f9c7dbac1899,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-e6f5df43-36f3-4636-80bb-c3352870c973,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-b9024cbc-7e19-4e74-9a99-282dbbea3455,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-24d888eb-5619-44c1-bef6-3d4f57432f58,DISK], DatanodeInfoWithStorage[127.0.0.1:43841,DS-7e55524f-ea2d-4357-86ed-9ad41591dad6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1704383586-172.17.0.2-1595992957822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34217,DS-cdd913c0-753c-48cc-ba21-9270106f5cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-b80680ae-240d-411d-8589-906743e3707c,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-cee2472e-0362-4ff7-b14c-b224cefc4ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-625a6ae6-e42b-4469-a40e-f9c7dbac1899,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-e6f5df43-36f3-4636-80bb-c3352870c973,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-b9024cbc-7e19-4e74-9a99-282dbbea3455,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-24d888eb-5619-44c1-bef6-3d4f57432f58,DISK], DatanodeInfoWithStorage[127.0.0.1:43841,DS-7e55524f-ea2d-4357-86ed-9ad41591dad6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 1
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1287529465-172.17.0.2-1595994216076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43452,DS-c60abee5-aafd-4ec0-bc68-0bcda2f6b068,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-fff5c849-9698-485e-8295-814eda72dc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-5e148523-e908-4307-b60d-cf3f9784db01,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-43168347-ec77-4fc7-bb67-78714b415352,DISK], DatanodeInfoWithStorage[127.0.0.1:43448,DS-c8bad6a1-6a87-4628-9efd-045d8ac0fa1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-937904bf-6509-4141-99e8-72e95d3ec40a,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-3e74ad59-3041-41c9-b00b-e44c51aafd9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-72d692e9-3361-4aa2-a801-240bce9abc37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1287529465-172.17.0.2-1595994216076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43452,DS-c60abee5-aafd-4ec0-bc68-0bcda2f6b068,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-fff5c849-9698-485e-8295-814eda72dc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-5e148523-e908-4307-b60d-cf3f9784db01,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-43168347-ec77-4fc7-bb67-78714b415352,DISK], DatanodeInfoWithStorage[127.0.0.1:43448,DS-c8bad6a1-6a87-4628-9efd-045d8ac0fa1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-937904bf-6509-4141-99e8-72e95d3ec40a,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-3e74ad59-3041-41c9-b00b-e44c51aafd9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-72d692e9-3361-4aa2-a801-240bce9abc37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 1
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-694696540-172.17.0.2-1595994422119:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39474,DS-68a1b1da-a6f7-4bef-b890-09378449e4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-8c83daf5-9a5b-4a93-9dd8-f638cc6ebd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-67d4611d-9430-417b-9464-5949fd717374,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-361a4456-b3ee-4f5d-95c5-ff48b5c570ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-6f47d951-d68c-44cd-8767-89195afe73b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-1c575e60-99fc-4f03-82d9-0ca9b477cbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41733,DS-40b08d78-d224-4aee-a4d1-17522b64676f,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-b2794872-1b24-4629-b393-3fee5bf28a8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-694696540-172.17.0.2-1595994422119:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39474,DS-68a1b1da-a6f7-4bef-b890-09378449e4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-8c83daf5-9a5b-4a93-9dd8-f638cc6ebd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-67d4611d-9430-417b-9464-5949fd717374,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-361a4456-b3ee-4f5d-95c5-ff48b5c570ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-6f47d951-d68c-44cd-8767-89195afe73b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-1c575e60-99fc-4f03-82d9-0ca9b477cbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41733,DS-40b08d78-d224-4aee-a4d1-17522b64676f,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-b2794872-1b24-4629-b393-3fee5bf28a8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 1
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-511535455-172.17.0.2-1595994597688:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33614,DS-62eaa57b-2962-496e-a958-c580498c1850,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-1af2fb2f-6f21-4711-bd02-8c69a1e8622e,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-58d6da01-087d-4b85-881b-dfdd6469eec6,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-e1b770da-98ff-4612-b3bd-31b979dbeebe,DISK], DatanodeInfoWithStorage[127.0.0.1:38684,DS-6d9deb2f-14a7-424d-9fad-8b7ffbdb9904,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-31de3580-6ebd-47d5-9d91-739db0e14210,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-33b2dc37-9ebf-4afd-b37d-1088f79956dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45563,DS-268fecd9-ad8c-4150-99ef-7571da4d025c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-511535455-172.17.0.2-1595994597688:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33614,DS-62eaa57b-2962-496e-a958-c580498c1850,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-1af2fb2f-6f21-4711-bd02-8c69a1e8622e,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-58d6da01-087d-4b85-881b-dfdd6469eec6,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-e1b770da-98ff-4612-b3bd-31b979dbeebe,DISK], DatanodeInfoWithStorage[127.0.0.1:38684,DS-6d9deb2f-14a7-424d-9fad-8b7ffbdb9904,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-31de3580-6ebd-47d5-9d91-739db0e14210,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-33b2dc37-9ebf-4afd-b37d-1088f79956dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45563,DS-268fecd9-ad8c-4150-99ef-7571da4d025c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 1
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1060639380-172.17.0.2-1595994721421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32937,DS-d4daf950-e0ae-49a4-b9e5-fe15cb5026f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-b3cac351-3e17-4c14-b3e1-64c1275a0ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-84cfae03-1213-4715-b531-12f19c15148f,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-3bda1fb3-3bed-4c55-87f3-db9566326c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-5dbac722-9dd9-4c0d-8755-f96e2431fafc,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-9369a780-3c2d-4c77-9622-7f8c0d280cca,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-1702bd72-0c5e-4369-9d02-ea995caae6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-7e10f71d-c0c9-4439-8708-bd0660a759bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1060639380-172.17.0.2-1595994721421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32937,DS-d4daf950-e0ae-49a4-b9e5-fe15cb5026f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-b3cac351-3e17-4c14-b3e1-64c1275a0ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-84cfae03-1213-4715-b531-12f19c15148f,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-3bda1fb3-3bed-4c55-87f3-db9566326c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-5dbac722-9dd9-4c0d-8755-f96e2431fafc,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-9369a780-3c2d-4c77-9622-7f8c0d280cca,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-1702bd72-0c5e-4369-9d02-ea995caae6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-7e10f71d-c0c9-4439-8708-bd0660a759bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 1
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-869877013-172.17.0.2-1595995105084:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33008,DS-3f2af040-cd8d-4b97-a2d3-09631ad479e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-a9847099-e867-45c5-96e3-7f76014e14a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-6c66e93f-9e68-4309-9a5e-f4796cbe822b,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-4ceb0e28-0323-4f66-bc22-df4038f8e84b,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-41a73b8a-1e97-453b-ae7d-f8824df86af3,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-d8be7229-675f-4768-aa1f-eba2f8e3cb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36269,DS-1e39d7dd-ff57-41eb-9991-b3f3d8e3f29e,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-d17a8079-a594-401b-9e63-338a9533ed17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-869877013-172.17.0.2-1595995105084:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33008,DS-3f2af040-cd8d-4b97-a2d3-09631ad479e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-a9847099-e867-45c5-96e3-7f76014e14a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-6c66e93f-9e68-4309-9a5e-f4796cbe822b,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-4ceb0e28-0323-4f66-bc22-df4038f8e84b,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-41a73b8a-1e97-453b-ae7d-f8824df86af3,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-d8be7229-675f-4768-aa1f-eba2f8e3cb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36269,DS-1e39d7dd-ff57-41eb-9991-b3f3d8e3f29e,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-d17a8079-a594-401b-9e63-338a9533ed17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 1
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-921489171-172.17.0.2-1595995357057:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45899,DS-3dcb677b-b2b3-4a4e-a101-c75a052c080a,DISK], DatanodeInfoWithStorage[127.0.0.1:44444,DS-b61b4a68-e3c3-47cd-8c6c-79a9b8487947,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-c6c440d1-fe56-41b3-9444-d7c6a8cb055a,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-76598d1e-50a9-4795-afc0-9855917e8f91,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-d8f03840-b7d1-4ade-94f0-9d5b96932f65,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-f51b8076-d974-484f-9a9c-7d00e015c959,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-a2fce3f0-561f-4cf1-9081-fff26066a85a,DISK], DatanodeInfoWithStorage[127.0.0.1:43173,DS-99504b03-1282-4930-9ef8-4053df760bb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-921489171-172.17.0.2-1595995357057:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45899,DS-3dcb677b-b2b3-4a4e-a101-c75a052c080a,DISK], DatanodeInfoWithStorage[127.0.0.1:44444,DS-b61b4a68-e3c3-47cd-8c6c-79a9b8487947,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-c6c440d1-fe56-41b3-9444-d7c6a8cb055a,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-76598d1e-50a9-4795-afc0-9855917e8f91,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-d8f03840-b7d1-4ade-94f0-9d5b96932f65,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-f51b8076-d974-484f-9a9c-7d00e015c959,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-a2fce3f0-561f-4cf1-9081-fff26066a85a,DISK], DatanodeInfoWithStorage[127.0.0.1:43173,DS-99504b03-1282-4930-9ef8-4053df760bb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 1
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-780762784-172.17.0.2-1595995561448:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35113,DS-d641d814-77a3-42a2-9f60-bd35928ec54b,DISK], DatanodeInfoWithStorage[127.0.0.1:38242,DS-d3b02ef3-9467-42a8-9685-c3f55a6bb3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44195,DS-c380c7d1-d5ea-4eee-8767-e4c834644cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-2e7ab984-0a54-4739-82b0-56446c9aa81b,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-8baf5708-8ee9-4c6b-bee7-94d3329a48d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-3ca4c3c3-9ecb-495b-b7f7-31c08c7eecf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-d396bd18-5bf9-4e4e-91af-9e08ca2cfd40,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-fa312c91-8ecc-4b33-8901-aa6fca9745b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-780762784-172.17.0.2-1595995561448:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35113,DS-d641d814-77a3-42a2-9f60-bd35928ec54b,DISK], DatanodeInfoWithStorage[127.0.0.1:38242,DS-d3b02ef3-9467-42a8-9685-c3f55a6bb3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44195,DS-c380c7d1-d5ea-4eee-8767-e4c834644cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-2e7ab984-0a54-4739-82b0-56446c9aa81b,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-8baf5708-8ee9-4c6b-bee7-94d3329a48d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-3ca4c3c3-9ecb-495b-b7f7-31c08c7eecf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-d396bd18-5bf9-4e4e-91af-9e08ca2cfd40,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-fa312c91-8ecc-4b33-8901-aa6fca9745b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 1
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1970418978-172.17.0.2-1595995946607:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34488,DS-f4c98aa8-ce3f-4be2-8328-c400f28d7c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-5cf8561b-d320-4e71-8a73-5b6a86588746,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-42bf6c91-923a-425e-b8bb-d01d6e0a2c91,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-d115ff4a-b439-4aaf-b0cc-835263f94a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-869b7a88-cee3-486b-9584-cbafaafce3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-5b0ad660-98d9-4c59-a9e9-624c1ae52d75,DISK], DatanodeInfoWithStorage[127.0.0.1:41716,DS-d2dd277f-1b9f-42a3-833f-460439274e25,DISK], DatanodeInfoWithStorage[127.0.0.1:39812,DS-6169804a-1d54-45c4-9e33-5d286cc0c7cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1970418978-172.17.0.2-1595995946607:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34488,DS-f4c98aa8-ce3f-4be2-8328-c400f28d7c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-5cf8561b-d320-4e71-8a73-5b6a86588746,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-42bf6c91-923a-425e-b8bb-d01d6e0a2c91,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-d115ff4a-b439-4aaf-b0cc-835263f94a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-869b7a88-cee3-486b-9584-cbafaafce3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-5b0ad660-98d9-4c59-a9e9-624c1ae52d75,DISK], DatanodeInfoWithStorage[127.0.0.1:41716,DS-d2dd277f-1b9f-42a3-833f-460439274e25,DISK], DatanodeInfoWithStorage[127.0.0.1:39812,DS-6169804a-1d54-45c4-9e33-5d286cc0c7cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 1
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-483764741-172.17.0.2-1595996187954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39822,DS-9878d246-adf5-4098-bd0f-a28892ce2814,DISK], DatanodeInfoWithStorage[127.0.0.1:37612,DS-603ef849-5f39-4bb3-8669-ab453f31a638,DISK], DatanodeInfoWithStorage[127.0.0.1:46653,DS-5d674e69-6b85-4c7b-824d-283e1ad4bd31,DISK], DatanodeInfoWithStorage[127.0.0.1:41842,DS-9b2b9122-b83a-4a52-a0b0-4d405c1a262a,DISK], DatanodeInfoWithStorage[127.0.0.1:46881,DS-f21f0faa-cebc-404d-9dbf-67fc58862489,DISK], DatanodeInfoWithStorage[127.0.0.1:37745,DS-c10f172e-6996-4f17-804f-f0c209979769,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-841ac64b-862e-4378-b1f0-06ee5abcf557,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-8d161755-f366-4895-8039-79c34c35f3e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-483764741-172.17.0.2-1595996187954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39822,DS-9878d246-adf5-4098-bd0f-a28892ce2814,DISK], DatanodeInfoWithStorage[127.0.0.1:37612,DS-603ef849-5f39-4bb3-8669-ab453f31a638,DISK], DatanodeInfoWithStorage[127.0.0.1:46653,DS-5d674e69-6b85-4c7b-824d-283e1ad4bd31,DISK], DatanodeInfoWithStorage[127.0.0.1:41842,DS-9b2b9122-b83a-4a52-a0b0-4d405c1a262a,DISK], DatanodeInfoWithStorage[127.0.0.1:46881,DS-f21f0faa-cebc-404d-9dbf-67fc58862489,DISK], DatanodeInfoWithStorage[127.0.0.1:37745,DS-c10f172e-6996-4f17-804f-f0c209979769,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-841ac64b-862e-4378-b1f0-06ee5abcf557,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-8d161755-f366-4895-8039-79c34c35f3e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 1
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-211777684-172.17.0.2-1595996896619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33192,DS-c799181f-1922-4569-af71-d4d2f936b14f,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-af8f8a86-0ad7-46cd-abcc-45cebd731db4,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-92b4fd1e-6c87-4dcc-85cd-28fad12b60a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-258e99ca-2961-4a0d-87b0-7ed66a4d529a,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-7789a9b9-1037-4cf8-9586-2fef4a533251,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-5aad0414-cb3f-4474-ac5d-fb7ea4a5dbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-7578a61b-9049-4fde-a679-1f5f9453736c,DISK], DatanodeInfoWithStorage[127.0.0.1:34894,DS-00d76ed3-bd1f-41a9-98a7-dab0c665d0ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-211777684-172.17.0.2-1595996896619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33192,DS-c799181f-1922-4569-af71-d4d2f936b14f,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-af8f8a86-0ad7-46cd-abcc-45cebd731db4,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-92b4fd1e-6c87-4dcc-85cd-28fad12b60a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-258e99ca-2961-4a0d-87b0-7ed66a4d529a,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-7789a9b9-1037-4cf8-9586-2fef4a533251,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-5aad0414-cb3f-4474-ac5d-fb7ea4a5dbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-7578a61b-9049-4fde-a679-1f5f9453736c,DISK], DatanodeInfoWithStorage[127.0.0.1:34894,DS-00d76ed3-bd1f-41a9-98a7-dab0c665d0ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 6242
