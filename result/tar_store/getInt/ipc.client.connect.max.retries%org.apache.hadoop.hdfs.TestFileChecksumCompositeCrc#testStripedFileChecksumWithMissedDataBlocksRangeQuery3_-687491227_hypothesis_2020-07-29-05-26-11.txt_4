reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1770003919-172.17.0.18-1596000386469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43787,DS-6b93cbb3-127e-4fb1-89cb-d5af29c1385f,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-a55e0f49-42b9-407b-b198-cf04739b3dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-eccae2da-8cf3-4dce-a66a-b0e764af1c10,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-453eb80a-7cb4-4d6a-a9c4-cbe3523402aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33200,DS-337729f0-d174-46a8-bbea-f1776301d877,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-dc51e4b7-1d63-4d9a-a8be-ee49ac677d83,DISK], DatanodeInfoWithStorage[127.0.0.1:33699,DS-3ab3a5e7-3df0-4bf3-a5d6-79ace9b616dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-7f5e7af2-514a-4266-9ab5-67602e83c3dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1770003919-172.17.0.18-1596000386469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43787,DS-6b93cbb3-127e-4fb1-89cb-d5af29c1385f,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-a55e0f49-42b9-407b-b198-cf04739b3dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-eccae2da-8cf3-4dce-a66a-b0e764af1c10,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-453eb80a-7cb4-4d6a-a9c4-cbe3523402aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33200,DS-337729f0-d174-46a8-bbea-f1776301d877,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-dc51e4b7-1d63-4d9a-a8be-ee49ac677d83,DISK], DatanodeInfoWithStorage[127.0.0.1:33699,DS-3ab3a5e7-3df0-4bf3-a5d6-79ace9b616dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-7f5e7af2-514a-4266-9ab5-67602e83c3dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-909414934-172.17.0.18-1596000760764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39140,DS-a36b584f-c2ef-4df8-8ecb-31e700678d32,DISK], DatanodeInfoWithStorage[127.0.0.1:40254,DS-f74a52c3-4d81-49c7-bc47-b6c03982847f,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-593683ca-85ea-4c8f-9bf2-17cd80e0d8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-2c547ec6-f75a-44b7-9528-71e03d33ae07,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-85b64bd0-3598-4846-99d7-7339fcf1e32d,DISK], DatanodeInfoWithStorage[127.0.0.1:32960,DS-349ae88a-2902-4065-8da8-51f70c9d4b02,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-117cf77b-b8bc-4a40-8654-a384ff881c73,DISK], DatanodeInfoWithStorage[127.0.0.1:40346,DS-a7bd0887-ffca-4611-9d5b-12a728369002,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-909414934-172.17.0.18-1596000760764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39140,DS-a36b584f-c2ef-4df8-8ecb-31e700678d32,DISK], DatanodeInfoWithStorage[127.0.0.1:40254,DS-f74a52c3-4d81-49c7-bc47-b6c03982847f,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-593683ca-85ea-4c8f-9bf2-17cd80e0d8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-2c547ec6-f75a-44b7-9528-71e03d33ae07,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-85b64bd0-3598-4846-99d7-7339fcf1e32d,DISK], DatanodeInfoWithStorage[127.0.0.1:32960,DS-349ae88a-2902-4065-8da8-51f70c9d4b02,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-117cf77b-b8bc-4a40-8654-a384ff881c73,DISK], DatanodeInfoWithStorage[127.0.0.1:40346,DS-a7bd0887-ffca-4611-9d5b-12a728369002,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905434607-172.17.0.18-1596000791988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41657,DS-bda47daa-2534-4013-b644-5164dcbfe12a,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-166567a9-0fc5-44f0-a006-655a5c3cb11d,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-ce2c22b5-717a-409c-b932-69983bb06ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-c60e3467-cfd7-4ea6-8a45-df045687d289,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-83dfac60-8c0d-40f9-9a40-a09f45ee765c,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-cad8839b-754f-4fe7-a001-e8498211b1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-13fc53f6-9b40-4750-ad53-c4784a0f75f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40025,DS-ab8f7b66-4356-407a-8434-af45fdd92b92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905434607-172.17.0.18-1596000791988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41657,DS-bda47daa-2534-4013-b644-5164dcbfe12a,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-166567a9-0fc5-44f0-a006-655a5c3cb11d,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-ce2c22b5-717a-409c-b932-69983bb06ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-c60e3467-cfd7-4ea6-8a45-df045687d289,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-83dfac60-8c0d-40f9-9a40-a09f45ee765c,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-cad8839b-754f-4fe7-a001-e8498211b1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-13fc53f6-9b40-4750-ad53-c4784a0f75f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40025,DS-ab8f7b66-4356-407a-8434-af45fdd92b92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-234128584-172.17.0.18-1596001480392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45487,DS-effd0250-4e09-477a-9e4d-dd8f4a87057f,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-c227fc70-f4a7-479d-b0b6-fa2548effc32,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-24ba07bf-6f51-4127-9468-e570c2a1a0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-c2eee7ff-a0f6-4fed-9e7a-b2f55198f4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-dbfbebae-8d5b-49d7-a016-029c9d2d9553,DISK], DatanodeInfoWithStorage[127.0.0.1:43835,DS-07d40393-a790-4c48-8b9d-c1c131804ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-d8c4c4c1-9d88-4a94-b53e-a109dfb591d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-8e98ec9e-e09b-44ce-af33-f7778c0fe222,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-234128584-172.17.0.18-1596001480392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45487,DS-effd0250-4e09-477a-9e4d-dd8f4a87057f,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-c227fc70-f4a7-479d-b0b6-fa2548effc32,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-24ba07bf-6f51-4127-9468-e570c2a1a0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-c2eee7ff-a0f6-4fed-9e7a-b2f55198f4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-dbfbebae-8d5b-49d7-a016-029c9d2d9553,DISK], DatanodeInfoWithStorage[127.0.0.1:43835,DS-07d40393-a790-4c48-8b9d-c1c131804ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-d8c4c4c1-9d88-4a94-b53e-a109dfb591d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-8e98ec9e-e09b-44ce-af33-f7778c0fe222,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1289723814-172.17.0.18-1596001653543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35071,DS-f318bd65-a245-4726-8604-3e44daf40f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-6949d093-161f-403e-be0d-10d65c72dcc2,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-7e7ad743-325f-444d-8871-e8165d99e469,DISK], DatanodeInfoWithStorage[127.0.0.1:46587,DS-bf816da3-4d56-4254-9a3e-45e063bf124e,DISK], DatanodeInfoWithStorage[127.0.0.1:41842,DS-7fe264fb-92e0-449f-8eae-f1ac8dfbb40d,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-fa7e3496-cb50-46ee-9fd5-4bb22122593c,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-546524d1-80b1-4121-bedc-3164c8e2a498,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-5ec5ed3a-8a4b-424a-8765-ec24ad10a2fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1289723814-172.17.0.18-1596001653543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35071,DS-f318bd65-a245-4726-8604-3e44daf40f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-6949d093-161f-403e-be0d-10d65c72dcc2,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-7e7ad743-325f-444d-8871-e8165d99e469,DISK], DatanodeInfoWithStorage[127.0.0.1:46587,DS-bf816da3-4d56-4254-9a3e-45e063bf124e,DISK], DatanodeInfoWithStorage[127.0.0.1:41842,DS-7fe264fb-92e0-449f-8eae-f1ac8dfbb40d,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-fa7e3496-cb50-46ee-9fd5-4bb22122593c,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-546524d1-80b1-4121-bedc-3164c8e2a498,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-5ec5ed3a-8a4b-424a-8765-ec24ad10a2fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-183668905-172.17.0.18-1596002170182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38858,DS-aecec99a-f1a8-4b1b-86ef-e01452f21455,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-f500c8a9-487a-47f3-993b-68e45e033362,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-100631a9-834d-4661-8b57-267d08b9ae58,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-5796bf1f-5d00-4ed8-a7c5-50e49137b8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-51fc4d19-8f39-4754-93cc-bd98542945eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-d50c778c-451b-4ffc-8558-c6dba78af6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-8feec121-3790-4edd-a1fa-22533ea048ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-7ca02483-3efb-4b21-b79d-febbbe58bbc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-183668905-172.17.0.18-1596002170182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38858,DS-aecec99a-f1a8-4b1b-86ef-e01452f21455,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-f500c8a9-487a-47f3-993b-68e45e033362,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-100631a9-834d-4661-8b57-267d08b9ae58,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-5796bf1f-5d00-4ed8-a7c5-50e49137b8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-51fc4d19-8f39-4754-93cc-bd98542945eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-d50c778c-451b-4ffc-8558-c6dba78af6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-8feec121-3790-4edd-a1fa-22533ea048ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-7ca02483-3efb-4b21-b79d-febbbe58bbc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109561011-172.17.0.18-1596002854975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43706,DS-53a2876a-5e50-4159-a7f1-76f72af47344,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-20f2ebeb-aa2c-4e2c-890d-876e9f1261fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44268,DS-f8815bb9-1897-4a9a-9c43-1159824e5cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-c713a1a8-bb3a-4907-8e73-0b5181e76d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-f55bc950-298c-488b-b5ab-c362bb0f190c,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-c0b3f344-7206-46e3-936a-3030f5fcbc43,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-e5b0e693-d917-4177-af5c-3d8140f485ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-139811bc-7584-4222-9784-dab7d869a309,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109561011-172.17.0.18-1596002854975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43706,DS-53a2876a-5e50-4159-a7f1-76f72af47344,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-20f2ebeb-aa2c-4e2c-890d-876e9f1261fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44268,DS-f8815bb9-1897-4a9a-9c43-1159824e5cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-c713a1a8-bb3a-4907-8e73-0b5181e76d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-f55bc950-298c-488b-b5ab-c362bb0f190c,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-c0b3f344-7206-46e3-936a-3030f5fcbc43,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-e5b0e693-d917-4177-af5c-3d8140f485ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-139811bc-7584-4222-9784-dab7d869a309,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1397824477-172.17.0.18-1596003184135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34432,DS-10ffb2e3-a835-4de4-8e3e-b51dc7230b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-abd5e82b-628b-4269-a1c6-bd7c83394df8,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-180a46f7-8b87-45fd-8e1c-91d194bba13c,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-f3a0597b-decd-4ed7-8346-ea9a25424d90,DISK], DatanodeInfoWithStorage[127.0.0.1:41851,DS-fac47314-086e-444b-89b6-4f3b9e2a5e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-e224db02-2020-4e30-83dc-1938ea27444a,DISK], DatanodeInfoWithStorage[127.0.0.1:45370,DS-0c5a6ee4-0e18-456c-83cf-bc0187d386bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-43b377ee-589a-4c0c-a273-d8c416870351,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1397824477-172.17.0.18-1596003184135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34432,DS-10ffb2e3-a835-4de4-8e3e-b51dc7230b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-abd5e82b-628b-4269-a1c6-bd7c83394df8,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-180a46f7-8b87-45fd-8e1c-91d194bba13c,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-f3a0597b-decd-4ed7-8346-ea9a25424d90,DISK], DatanodeInfoWithStorage[127.0.0.1:41851,DS-fac47314-086e-444b-89b6-4f3b9e2a5e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-e224db02-2020-4e30-83dc-1938ea27444a,DISK], DatanodeInfoWithStorage[127.0.0.1:45370,DS-0c5a6ee4-0e18-456c-83cf-bc0187d386bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-43b377ee-589a-4c0c-a273-d8c416870351,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-981504961-172.17.0.18-1596003220945:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34633,DS-8d2ccc1e-e2da-4819-814e-187602c668bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-dc8bef65-04be-4971-a2a6-9a7e46f0f067,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-c3780b48-2a02-4919-a140-258fc217a041,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-c6df6399-2c81-4d82-8af9-112ea8a7353c,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-71fc573a-184a-4c72-87fe-ea4325f3c4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-0346746c-7588-4440-942d-b76d11babef5,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-4e2a9d11-2b2e-47dc-973e-627ade2008b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-4f5b123a-3ed9-4fd5-ac39-e653a622b5d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-981504961-172.17.0.18-1596003220945:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34633,DS-8d2ccc1e-e2da-4819-814e-187602c668bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-dc8bef65-04be-4971-a2a6-9a7e46f0f067,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-c3780b48-2a02-4919-a140-258fc217a041,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-c6df6399-2c81-4d82-8af9-112ea8a7353c,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-71fc573a-184a-4c72-87fe-ea4325f3c4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-0346746c-7588-4440-942d-b76d11babef5,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-4e2a9d11-2b2e-47dc-973e-627ade2008b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-4f5b123a-3ed9-4fd5-ac39-e653a622b5d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2084129580-172.17.0.18-1596003471252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45953,DS-a7c376ad-695f-49d7-853d-1c0003811b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-e5402d76-9df4-482e-8af9-c6a9f02dc3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-8784fbee-ab95-42bc-8d6c-e44d1a49e980,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-a45ae7a6-5759-49d8-9bea-b914f6970cec,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-0aed57c0-640c-43ee-9fc9-557d5513edae,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-e9e27855-1dfd-4f07-a455-098cee1c44a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-97a3b8ae-5c35-4bd8-8657-faaa424bc430,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-b7b4a51e-16e8-4043-afed-5bb841a72f17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2084129580-172.17.0.18-1596003471252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45953,DS-a7c376ad-695f-49d7-853d-1c0003811b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-e5402d76-9df4-482e-8af9-c6a9f02dc3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-8784fbee-ab95-42bc-8d6c-e44d1a49e980,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-a45ae7a6-5759-49d8-9bea-b914f6970cec,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-0aed57c0-640c-43ee-9fc9-557d5513edae,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-e9e27855-1dfd-4f07-a455-098cee1c44a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-97a3b8ae-5c35-4bd8-8657-faaa424bc430,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-b7b4a51e-16e8-4043-afed-5bb841a72f17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-205819062-172.17.0.18-1596003683337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42526,DS-f0c01981-83c5-4b5a-a46f-ca76b65a8163,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-59efd149-da7c-482c-91f9-6bfa17c0c3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-8c37b6f0-a311-4c50-a2f5-2ed2aadbf074,DISK], DatanodeInfoWithStorage[127.0.0.1:39876,DS-c61af5d7-300e-4bba-a392-04362e9953b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-54f3aaa5-3c0f-40ca-92ca-db64968391c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-b16b53b5-0adc-49a5-acae-8bc2fe80203d,DISK], DatanodeInfoWithStorage[127.0.0.1:33076,DS-d961a9c1-cc36-415f-9020-40c1d33fa0df,DISK], DatanodeInfoWithStorage[127.0.0.1:37524,DS-9292fba4-c5a1-43b3-8201-89d9c1b6fbd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-205819062-172.17.0.18-1596003683337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42526,DS-f0c01981-83c5-4b5a-a46f-ca76b65a8163,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-59efd149-da7c-482c-91f9-6bfa17c0c3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-8c37b6f0-a311-4c50-a2f5-2ed2aadbf074,DISK], DatanodeInfoWithStorage[127.0.0.1:39876,DS-c61af5d7-300e-4bba-a392-04362e9953b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-54f3aaa5-3c0f-40ca-92ca-db64968391c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-b16b53b5-0adc-49a5-acae-8bc2fe80203d,DISK], DatanodeInfoWithStorage[127.0.0.1:33076,DS-d961a9c1-cc36-415f-9020-40c1d33fa0df,DISK], DatanodeInfoWithStorage[127.0.0.1:37524,DS-9292fba4-c5a1-43b3-8201-89d9c1b6fbd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1195460664-172.17.0.18-1596003958547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34331,DS-d1f67531-6eea-4aa1-b49d-fdd54e605d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-2f64704d-b43f-4094-b3d7-9e4ba17ce8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-0a47d8dd-ebe3-45c6-8971-2d1b2c86b54f,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-71f5b45d-4aa3-4a58-965a-45e957809667,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-576ae5d5-453b-4ebf-93c7-c72eec7f8537,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-12945b58-1456-4487-ba5d-79d1f0e7dfb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-49f9f2eb-6cf3-4b6c-9491-73529bf4dfec,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-4123617e-da36-4c70-9465-343d870907fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1195460664-172.17.0.18-1596003958547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34331,DS-d1f67531-6eea-4aa1-b49d-fdd54e605d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-2f64704d-b43f-4094-b3d7-9e4ba17ce8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-0a47d8dd-ebe3-45c6-8971-2d1b2c86b54f,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-71f5b45d-4aa3-4a58-965a-45e957809667,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-576ae5d5-453b-4ebf-93c7-c72eec7f8537,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-12945b58-1456-4487-ba5d-79d1f0e7dfb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-49f9f2eb-6cf3-4b6c-9491-73529bf4dfec,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-4123617e-da36-4c70-9465-343d870907fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-620896459-172.17.0.18-1596004923848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38356,DS-302bc90d-89e5-42f2-ad9c-e522b537cdd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-82cdebb9-3a36-42f7-92ba-dfe26b8b0e54,DISK], DatanodeInfoWithStorage[127.0.0.1:34562,DS-ba0fa3aa-1921-4a2c-a7f1-1e81367d4b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-3d69173c-23a2-42d0-8623-c0c134d2f386,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-8640c296-433c-4447-8871-f7b6c9a2c621,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-a238706b-4e86-4016-a513-95f84fc319b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-43075185-6a09-47d4-883b-a3c6dd4f7d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-409b9ab3-65d5-4ac7-82e6-90a1dc4563f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-620896459-172.17.0.18-1596004923848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38356,DS-302bc90d-89e5-42f2-ad9c-e522b537cdd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-82cdebb9-3a36-42f7-92ba-dfe26b8b0e54,DISK], DatanodeInfoWithStorage[127.0.0.1:34562,DS-ba0fa3aa-1921-4a2c-a7f1-1e81367d4b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-3d69173c-23a2-42d0-8623-c0c134d2f386,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-8640c296-433c-4447-8871-f7b6c9a2c621,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-a238706b-4e86-4016-a513-95f84fc319b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-43075185-6a09-47d4-883b-a3c6dd4f7d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-409b9ab3-65d5-4ac7-82e6-90a1dc4563f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1693437516-172.17.0.18-1596005259181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39665,DS-cece6383-033d-4335-87e4-6cba572563fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-a3253318-e65c-4da9-ba7e-a9a681a5b1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-42a384cb-f12c-4cb4-b69c-c363ecdd184b,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-927dbcce-799a-4a07-838e-837b4c3208e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-10885780-680e-431f-94c8-d6e27250f38b,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-5bb6df66-fe23-4791-91cb-4786f2c53fae,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-9528e96d-c734-400c-8139-03faf26880e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-447998a5-612d-49dd-be46-fde1bb695ff9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1693437516-172.17.0.18-1596005259181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39665,DS-cece6383-033d-4335-87e4-6cba572563fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-a3253318-e65c-4da9-ba7e-a9a681a5b1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-42a384cb-f12c-4cb4-b69c-c363ecdd184b,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-927dbcce-799a-4a07-838e-837b4c3208e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-10885780-680e-431f-94c8-d6e27250f38b,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-5bb6df66-fe23-4791-91cb-4786f2c53fae,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-9528e96d-c734-400c-8139-03faf26880e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-447998a5-612d-49dd-be46-fde1bb695ff9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5393
