reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-781475163-172.17.0.5-1595479875422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33307,DS-8da299c7-6687-4151-92ec-1e0b9f423442,DISK], DatanodeInfoWithStorage[127.0.0.1:41139,DS-8d5c6e0c-2591-4d8f-a059-fb22e5f4c53f,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-3b7ff401-cf63-4194-a896-2ee0eef7075d,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-2e36de18-c594-4c43-ad55-277c771ffac4,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-2356dc9a-141f-45f0-899c-f77dba0d4a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-271cc9ea-8ece-48b8-9adf-9ff82a90c223,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-d0e48217-e644-4243-9b1a-6a17e37a70b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-e8a68385-481f-4932-9904-1725a161e5f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-781475163-172.17.0.5-1595479875422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33307,DS-8da299c7-6687-4151-92ec-1e0b9f423442,DISK], DatanodeInfoWithStorage[127.0.0.1:41139,DS-8d5c6e0c-2591-4d8f-a059-fb22e5f4c53f,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-3b7ff401-cf63-4194-a896-2ee0eef7075d,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-2e36de18-c594-4c43-ad55-277c771ffac4,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-2356dc9a-141f-45f0-899c-f77dba0d4a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-271cc9ea-8ece-48b8-9adf-9ff82a90c223,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-d0e48217-e644-4243-9b1a-6a17e37a70b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-e8a68385-481f-4932-9904-1725a161e5f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-76412917-172.17.0.5-1595480170432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33583,DS-25c2c29e-4997-443e-a9bc-e7c8bff05c87,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-30823189-467d-4afb-a5a6-a377163bb700,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-38ec4cf0-2975-459b-a9b5-b56035fbfb71,DISK], DatanodeInfoWithStorage[127.0.0.1:34568,DS-19e4d535-5040-4984-bb28-29991743e28d,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-9755c0ec-d3fa-45a7-9fb8-25ca356bd1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-881383b6-5971-465c-a13c-8ca2b91a2e40,DISK], DatanodeInfoWithStorage[127.0.0.1:34225,DS-41186509-7a8b-453f-99f9-75bf574f121d,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-d1843ef2-555c-44db-b0c3-d892a1544109,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-76412917-172.17.0.5-1595480170432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33583,DS-25c2c29e-4997-443e-a9bc-e7c8bff05c87,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-30823189-467d-4afb-a5a6-a377163bb700,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-38ec4cf0-2975-459b-a9b5-b56035fbfb71,DISK], DatanodeInfoWithStorage[127.0.0.1:34568,DS-19e4d535-5040-4984-bb28-29991743e28d,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-9755c0ec-d3fa-45a7-9fb8-25ca356bd1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-881383b6-5971-465c-a13c-8ca2b91a2e40,DISK], DatanodeInfoWithStorage[127.0.0.1:34225,DS-41186509-7a8b-453f-99f9-75bf574f121d,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-d1843ef2-555c-44db-b0c3-d892a1544109,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1116707655-172.17.0.5-1595480280731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37594,DS-48395dfc-0693-4cdf-b760-564557105b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-3ed401c5-265d-46b3-a4d8-15c8933cdef3,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-ac7d4e50-6f50-472d-a996-e886ad1910ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-df5071cc-bae3-4d4a-8715-ac2c46af8773,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-48dc3965-4053-48a1-be83-76e380519a95,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-9d237b00-6997-48b0-a628-398826edee81,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-309bc7f4-a6e2-406b-8a03-4e009587fcbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38486,DS-11788fbb-4514-457a-9676-a5ddb9e72864,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1116707655-172.17.0.5-1595480280731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37594,DS-48395dfc-0693-4cdf-b760-564557105b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-3ed401c5-265d-46b3-a4d8-15c8933cdef3,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-ac7d4e50-6f50-472d-a996-e886ad1910ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-df5071cc-bae3-4d4a-8715-ac2c46af8773,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-48dc3965-4053-48a1-be83-76e380519a95,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-9d237b00-6997-48b0-a628-398826edee81,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-309bc7f4-a6e2-406b-8a03-4e009587fcbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38486,DS-11788fbb-4514-457a-9676-a5ddb9e72864,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-337692095-172.17.0.5-1595480414724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38018,DS-cf2303a2-916a-487a-9540-cbb62c765f79,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-8e904b05-e39c-46a3-9690-68f7b1c6e895,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-377d11f2-ec8b-44c1-a28c-1b95a4cb140c,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-bda019c6-7123-4d75-9a45-38ac14ffb205,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-47bf13c3-913e-466d-a108-ddac1515e632,DISK], DatanodeInfoWithStorage[127.0.0.1:45430,DS-8f8d7e3f-1349-4bb7-b66b-eaa5f5788582,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-fd2066c9-c893-4d01-9ad3-ed1d61779379,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-63cd5ae5-209d-4369-815f-b8b8733a383d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-337692095-172.17.0.5-1595480414724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38018,DS-cf2303a2-916a-487a-9540-cbb62c765f79,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-8e904b05-e39c-46a3-9690-68f7b1c6e895,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-377d11f2-ec8b-44c1-a28c-1b95a4cb140c,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-bda019c6-7123-4d75-9a45-38ac14ffb205,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-47bf13c3-913e-466d-a108-ddac1515e632,DISK], DatanodeInfoWithStorage[127.0.0.1:45430,DS-8f8d7e3f-1349-4bb7-b66b-eaa5f5788582,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-fd2066c9-c893-4d01-9ad3-ed1d61779379,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-63cd5ae5-209d-4369-815f-b8b8733a383d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1207956134-172.17.0.5-1595480489360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45794,DS-10a34f8c-0c68-4c58-8361-3c34d4fe7b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38307,DS-ad7f6cb3-8493-40a1-a436-98abdf3d3d88,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-70e94f42-94bf-44a7-8701-e8283765d8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-b9735817-d049-4fee-b901-73792b94448b,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-c7c61800-e64b-4c9a-95da-6f2491c37c94,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-2ce4ccf9-6fb2-43cc-9ae8-5fb49d2f0846,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-bba48a0c-adbf-48b7-9f8b-711d3d100fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-e9292330-0361-45ba-aaaa-65ab1e3d2a86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1207956134-172.17.0.5-1595480489360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45794,DS-10a34f8c-0c68-4c58-8361-3c34d4fe7b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38307,DS-ad7f6cb3-8493-40a1-a436-98abdf3d3d88,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-70e94f42-94bf-44a7-8701-e8283765d8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-b9735817-d049-4fee-b901-73792b94448b,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-c7c61800-e64b-4c9a-95da-6f2491c37c94,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-2ce4ccf9-6fb2-43cc-9ae8-5fb49d2f0846,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-bba48a0c-adbf-48b7-9f8b-711d3d100fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-e9292330-0361-45ba-aaaa-65ab1e3d2a86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-394959688-172.17.0.5-1595480584290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42337,DS-5b3c7fb8-5243-4b27-bd18-bca9edb7968f,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-b0fe6dfa-42ff-43e0-9854-5453d14543c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-81ea55f9-d33e-4781-b297-bba603e00d41,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-abfa47c0-7789-4b10-a389-e7a251075321,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-af1fa6b8-7466-4ea0-a0ed-e067bea8e155,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-c9f7e8fa-158b-4504-b2dc-e2842f7171f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-efd6cb75-a581-46d5-a540-c3f882b46ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-9f114c4b-eeb2-480c-affd-8420c844f34c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-394959688-172.17.0.5-1595480584290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42337,DS-5b3c7fb8-5243-4b27-bd18-bca9edb7968f,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-b0fe6dfa-42ff-43e0-9854-5453d14543c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-81ea55f9-d33e-4781-b297-bba603e00d41,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-abfa47c0-7789-4b10-a389-e7a251075321,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-af1fa6b8-7466-4ea0-a0ed-e067bea8e155,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-c9f7e8fa-158b-4504-b2dc-e2842f7171f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-efd6cb75-a581-46d5-a540-c3f882b46ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-9f114c4b-eeb2-480c-affd-8420c844f34c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2080465307-172.17.0.5-1595480720694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38313,DS-034c0e3c-cce8-41a6-8007-8bc34616cd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-ca6e5601-5845-48fd-9161-6cdf8f4948e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38547,DS-0caf6c3e-f658-4283-80ac-60e3d9354f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-1a739670-87fe-44c2-81cf-aced7042edba,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-69623ae9-58a7-4e3c-b368-e6f066ee2277,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-de4a34cc-554c-44bc-8947-a23483d7e0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-6ee94031-3f95-4700-a161-c18f2a5e84fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-a811ebee-c7aa-4934-85a2-de3a1d8fa74c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2080465307-172.17.0.5-1595480720694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38313,DS-034c0e3c-cce8-41a6-8007-8bc34616cd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-ca6e5601-5845-48fd-9161-6cdf8f4948e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38547,DS-0caf6c3e-f658-4283-80ac-60e3d9354f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-1a739670-87fe-44c2-81cf-aced7042edba,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-69623ae9-58a7-4e3c-b368-e6f066ee2277,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-de4a34cc-554c-44bc-8947-a23483d7e0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-6ee94031-3f95-4700-a161-c18f2a5e84fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-a811ebee-c7aa-4934-85a2-de3a1d8fa74c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86010850-172.17.0.5-1595480789554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43311,DS-9d77f16f-ad66-4a0e-94f1-067b1de2824b,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-122b7216-8161-4e23-b9fa-df179d489f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-666e589a-00d7-4496-addb-ce3f7f2e7022,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-7874d8e7-8831-4040-ada3-e4c1c4b0bd08,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-632f504c-3c09-4f1c-933d-e2517dfd1b57,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-6725ffc0-3f36-4e74-8e7c-46fa5b72098b,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-d0fe744d-9ec1-4da9-bb9a-d5c9e5077944,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-f04295f6-3776-4a74-9741-f56a85ab341d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86010850-172.17.0.5-1595480789554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43311,DS-9d77f16f-ad66-4a0e-94f1-067b1de2824b,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-122b7216-8161-4e23-b9fa-df179d489f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-666e589a-00d7-4496-addb-ce3f7f2e7022,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-7874d8e7-8831-4040-ada3-e4c1c4b0bd08,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-632f504c-3c09-4f1c-933d-e2517dfd1b57,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-6725ffc0-3f36-4e74-8e7c-46fa5b72098b,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-d0fe744d-9ec1-4da9-bb9a-d5c9e5077944,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-f04295f6-3776-4a74-9741-f56a85ab341d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1467379055-172.17.0.5-1595481179546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44475,DS-3750d4ba-33ce-4b1a-be20-2701692b09b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-96d0e2e2-d781-4218-995d-ae29d1e226e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-fe351fbc-303f-4fb2-88b5-efd64967705a,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-bf91173e-05cf-480d-a653-853659367a14,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-3087879c-5707-491c-8952-d01e5bb6d6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-1d9a3114-10d5-4d54-98ec-aca483da568b,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-8bb4712e-7027-41de-987b-fe6960946994,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-7369b3cc-c714-4e73-b46c-6a79444e8a48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1467379055-172.17.0.5-1595481179546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44475,DS-3750d4ba-33ce-4b1a-be20-2701692b09b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-96d0e2e2-d781-4218-995d-ae29d1e226e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-fe351fbc-303f-4fb2-88b5-efd64967705a,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-bf91173e-05cf-480d-a653-853659367a14,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-3087879c-5707-491c-8952-d01e5bb6d6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-1d9a3114-10d5-4d54-98ec-aca483da568b,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-8bb4712e-7027-41de-987b-fe6960946994,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-7369b3cc-c714-4e73-b46c-6a79444e8a48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-803375995-172.17.0.5-1595481214971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42667,DS-ed11bd68-aa80-4885-9500-2195851dec37,DISK], DatanodeInfoWithStorage[127.0.0.1:38556,DS-256cf7bf-423e-4ec0-bd1d-3950c38d3af6,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-ee792d6a-ace8-4b00-a5a1-72a7ea09cae2,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-87f6105d-0b85-47a9-8fbd-b7ce2e24ffae,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-a8f8f72d-6bd4-41ea-997f-ca6f501fdbab,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-7b5acc4e-93d3-4278-a1b1-86355e235a61,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-a45398ad-04c8-44a3-8903-f38c7b96c5af,DISK], DatanodeInfoWithStorage[127.0.0.1:44008,DS-c5c8da8c-48e9-4d61-b947-3801920b8394,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-803375995-172.17.0.5-1595481214971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42667,DS-ed11bd68-aa80-4885-9500-2195851dec37,DISK], DatanodeInfoWithStorage[127.0.0.1:38556,DS-256cf7bf-423e-4ec0-bd1d-3950c38d3af6,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-ee792d6a-ace8-4b00-a5a1-72a7ea09cae2,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-87f6105d-0b85-47a9-8fbd-b7ce2e24ffae,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-a8f8f72d-6bd4-41ea-997f-ca6f501fdbab,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-7b5acc4e-93d3-4278-a1b1-86355e235a61,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-a45398ad-04c8-44a3-8903-f38c7b96c5af,DISK], DatanodeInfoWithStorage[127.0.0.1:44008,DS-c5c8da8c-48e9-4d61-b947-3801920b8394,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-586087051-172.17.0.5-1595481280502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42698,DS-9e31c23f-e906-40a4-8378-981bdb9042ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-96b997d9-685c-4d77-8cd6-98f1491ced9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-46a5c51b-2eaa-4705-88bd-8a76d01f19f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-2d5c7e47-3dcb-4b95-bd0f-f4c07ea4f97d,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-8110398a-0320-42fe-9e45-4874df979236,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-2a4433f2-2e7e-4764-8a63-f2b4771ce5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-dcdb1fc7-6794-4781-be6d-a6c92faf7c21,DISK], DatanodeInfoWithStorage[127.0.0.1:33358,DS-533c2037-b42b-4842-af13-9e13e7fced22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-586087051-172.17.0.5-1595481280502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42698,DS-9e31c23f-e906-40a4-8378-981bdb9042ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-96b997d9-685c-4d77-8cd6-98f1491ced9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-46a5c51b-2eaa-4705-88bd-8a76d01f19f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-2d5c7e47-3dcb-4b95-bd0f-f4c07ea4f97d,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-8110398a-0320-42fe-9e45-4874df979236,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-2a4433f2-2e7e-4764-8a63-f2b4771ce5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-dcdb1fc7-6794-4781-be6d-a6c92faf7c21,DISK], DatanodeInfoWithStorage[127.0.0.1:33358,DS-533c2037-b42b-4842-af13-9e13e7fced22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1039492656-172.17.0.5-1595481390566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39943,DS-e9b21028-6aff-477f-b09c-eaaba6f12ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-195ffee8-b043-4645-acc1-b0577829a136,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-174dc569-aa84-473e-a037-3f4f33fa26cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-d81e78fe-55e5-405d-930b-56beb6f3bce9,DISK], DatanodeInfoWithStorage[127.0.0.1:44815,DS-ae081455-364c-4052-b3da-2a34d1cff935,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-1aad31f4-748f-4a07-96d1-3364449fa182,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-aedb7df6-ca71-47f1-a1dc-cee96a872855,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-e8f18c12-fe1c-470a-84b3-25de60b8080b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1039492656-172.17.0.5-1595481390566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39943,DS-e9b21028-6aff-477f-b09c-eaaba6f12ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-195ffee8-b043-4645-acc1-b0577829a136,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-174dc569-aa84-473e-a037-3f4f33fa26cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-d81e78fe-55e5-405d-930b-56beb6f3bce9,DISK], DatanodeInfoWithStorage[127.0.0.1:44815,DS-ae081455-364c-4052-b3da-2a34d1cff935,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-1aad31f4-748f-4a07-96d1-3364449fa182,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-aedb7df6-ca71-47f1-a1dc-cee96a872855,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-e8f18c12-fe1c-470a-84b3-25de60b8080b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1561455132-172.17.0.5-1595482224684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33893,DS-96380c93-cd81-487c-9043-2c09309acf72,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-772a2544-50d2-4a14-9d54-ee80d09bd300,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-7dbc37ff-8be4-4a12-a986-8cc599d10a48,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-1378aa40-1c7b-427b-8912-a289cd5cb220,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-af9a1ad3-b08c-4835-bf21-3499ad43ea8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-f3d32d65-6a86-4f78-83ff-b7cb29ca76db,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-50e672d4-e510-4b43-ae59-0c10224ae720,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-c064a47a-34d4-4aaa-bf0b-ffc306eae27e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1561455132-172.17.0.5-1595482224684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33893,DS-96380c93-cd81-487c-9043-2c09309acf72,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-772a2544-50d2-4a14-9d54-ee80d09bd300,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-7dbc37ff-8be4-4a12-a986-8cc599d10a48,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-1378aa40-1c7b-427b-8912-a289cd5cb220,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-af9a1ad3-b08c-4835-bf21-3499ad43ea8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-f3d32d65-6a86-4f78-83ff-b7cb29ca76db,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-50e672d4-e510-4b43-ae59-0c10224ae720,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-c064a47a-34d4-4aaa-bf0b-ffc306eae27e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1318652181-172.17.0.5-1595482541245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44464,DS-5c645e0a-47b5-4377-b4fc-419237101575,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-0b5b82ac-917e-4874-a6cc-119673afa288,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-de52a6b3-625c-438d-b6dd-bf5db0119adf,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-3d7d6527-a789-4e98-9da3-76b68388cb10,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-b9852088-8068-4d46-ae59-3f4d79e0eac8,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-618907f5-97ba-48e9-8409-a46832678c94,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-81743634-8e1d-468c-8c8d-c5234bd54a67,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-0a5bdda7-8106-4e80-b34e-92d1f3873109,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1318652181-172.17.0.5-1595482541245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44464,DS-5c645e0a-47b5-4377-b4fc-419237101575,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-0b5b82ac-917e-4874-a6cc-119673afa288,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-de52a6b3-625c-438d-b6dd-bf5db0119adf,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-3d7d6527-a789-4e98-9da3-76b68388cb10,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-b9852088-8068-4d46-ae59-3f4d79e0eac8,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-618907f5-97ba-48e9-8409-a46832678c94,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-81743634-8e1d-468c-8c8d-c5234bd54a67,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-0a5bdda7-8106-4e80-b34e-92d1f3873109,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1465499919-172.17.0.5-1595482770325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41179,DS-f5879668-7632-42d6-b468-8f016e9feddc,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-7b104c20-ee4b-48d2-8b0f-e0cad4a801d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-3ceb130d-2bb6-4031-aca1-bc8df3db728b,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-2545d902-fa23-4b6f-a0b5-bfb14ca1d360,DISK], DatanodeInfoWithStorage[127.0.0.1:34918,DS-c60786c1-02c0-47b7-9cdc-cb51a9c89387,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-1eeab2e3-aa7f-4590-9cfe-6bf4cda8b30e,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-42d7901d-b262-4700-9bd2-bd96ac8af634,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-e3968bba-9894-4817-9acc-03ff23715491,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1465499919-172.17.0.5-1595482770325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41179,DS-f5879668-7632-42d6-b468-8f016e9feddc,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-7b104c20-ee4b-48d2-8b0f-e0cad4a801d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-3ceb130d-2bb6-4031-aca1-bc8df3db728b,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-2545d902-fa23-4b6f-a0b5-bfb14ca1d360,DISK], DatanodeInfoWithStorage[127.0.0.1:34918,DS-c60786c1-02c0-47b7-9cdc-cb51a9c89387,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-1eeab2e3-aa7f-4590-9cfe-6bf4cda8b30e,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-42d7901d-b262-4700-9bd2-bd96ac8af634,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-e3968bba-9894-4817-9acc-03ff23715491,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514346695-172.17.0.5-1595482942463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40526,DS-35ead045-7ad4-4d73-ab1c-80fdb587a083,DISK], DatanodeInfoWithStorage[127.0.0.1:37290,DS-d7467c14-4433-4e3d-9200-973679ad59d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-b2f016c2-b11c-4c02-816c-1593cc71ce2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44365,DS-9c9a0b26-a29e-4eab-b9d3-1e03175ce6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-f2839a23-9582-47ad-acb6-fce1e4d158cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-308bd3cc-f466-4c81-b1be-2a663b8d0199,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-2cda9db7-818f-42fb-a8a6-01f92b8fb9af,DISK], DatanodeInfoWithStorage[127.0.0.1:36156,DS-81176177-4902-4c8a-8fd9-970681ab16cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514346695-172.17.0.5-1595482942463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40526,DS-35ead045-7ad4-4d73-ab1c-80fdb587a083,DISK], DatanodeInfoWithStorage[127.0.0.1:37290,DS-d7467c14-4433-4e3d-9200-973679ad59d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-b2f016c2-b11c-4c02-816c-1593cc71ce2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44365,DS-9c9a0b26-a29e-4eab-b9d3-1e03175ce6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-f2839a23-9582-47ad-acb6-fce1e4d158cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-308bd3cc-f466-4c81-b1be-2a663b8d0199,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-2cda9db7-818f-42fb-a8a6-01f92b8fb9af,DISK], DatanodeInfoWithStorage[127.0.0.1:36156,DS-81176177-4902-4c8a-8fd9-970681ab16cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1148633111-172.17.0.5-1595483391486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36167,DS-4cfa275a-3e83-4d36-8906-ca1baf95bb49,DISK], DatanodeInfoWithStorage[127.0.0.1:34751,DS-9711ff28-45cb-4720-ba17-f314cbcdb983,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-2318a9cd-e5cb-4278-aa63-87f15def5040,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-525b3df3-6a82-4c63-bfcc-df1b22856f01,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-6b7683d6-2132-4e03-9251-3b3bccdce8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-0738ece4-f683-487d-99b0-b713dee2a08a,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-f0654b01-b7f4-4dd3-91fb-3891d98f1028,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-b7c7e1e9-2de9-453b-90da-071833c3df73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1148633111-172.17.0.5-1595483391486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36167,DS-4cfa275a-3e83-4d36-8906-ca1baf95bb49,DISK], DatanodeInfoWithStorage[127.0.0.1:34751,DS-9711ff28-45cb-4720-ba17-f314cbcdb983,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-2318a9cd-e5cb-4278-aa63-87f15def5040,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-525b3df3-6a82-4c63-bfcc-df1b22856f01,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-6b7683d6-2132-4e03-9251-3b3bccdce8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-0738ece4-f683-487d-99b0-b713dee2a08a,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-f0654b01-b7f4-4dd3-91fb-3891d98f1028,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-b7c7e1e9-2de9-453b-90da-071833c3df73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-715635308-172.17.0.5-1595483951007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34949,DS-f5a5be2f-d211-4e21-a7f3-726b75390074,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-6f5141f8-d4f0-445e-936d-922a623716cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-6648080a-37fa-4ac6-9704-4ecc1b964eae,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-62ccdd3a-25e2-4751-b2c4-420cc4e662f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-111420b4-c198-4de7-8a58-9ad7a69efda6,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-00ce32d3-0ab8-4ec7-afc7-078155dbf6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-3e2622d6-8ac7-4df6-8379-a07dc5c32716,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-420b11a1-f77f-419c-87a5-780c39c64377,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-715635308-172.17.0.5-1595483951007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34949,DS-f5a5be2f-d211-4e21-a7f3-726b75390074,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-6f5141f8-d4f0-445e-936d-922a623716cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-6648080a-37fa-4ac6-9704-4ecc1b964eae,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-62ccdd3a-25e2-4751-b2c4-420cc4e662f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-111420b4-c198-4de7-8a58-9ad7a69efda6,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-00ce32d3-0ab8-4ec7-afc7-078155dbf6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-3e2622d6-8ac7-4df6-8379-a07dc5c32716,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-420b11a1-f77f-419c-87a5-780c39c64377,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1167669709-172.17.0.5-1595484022075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40554,DS-ff4befdb-c0d8-4bb5-b515-689c052bf29a,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-d0767d6e-9e03-44a3-bc57-356b7d0ca47b,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-8a98e9f6-b88c-472c-b15b-714d74d5eb49,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-3fafab8b-f28a-40e7-878d-0f2f6c50385e,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-ccdd490c-130a-4456-9ecf-649423778466,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-6f8eeedc-a13e-4c14-b31c-ae0ab676c6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-4d611386-8b50-4992-9503-47cff4ab7db4,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-ad943048-f341-406b-afb9-bf682437f294,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1167669709-172.17.0.5-1595484022075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40554,DS-ff4befdb-c0d8-4bb5-b515-689c052bf29a,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-d0767d6e-9e03-44a3-bc57-356b7d0ca47b,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-8a98e9f6-b88c-472c-b15b-714d74d5eb49,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-3fafab8b-f28a-40e7-878d-0f2f6c50385e,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-ccdd490c-130a-4456-9ecf-649423778466,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-6f8eeedc-a13e-4c14-b31c-ae0ab676c6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-4d611386-8b50-4992-9503-47cff4ab7db4,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-ad943048-f341-406b-afb9-bf682437f294,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2139699282-172.17.0.5-1595484052085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34654,DS-69a4a6d1-5e7b-41fa-9a6e-d1c0add1ddb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-03667603-c571-456c-9a66-8d9773f3fec7,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-c8856186-57b5-4b51-820c-7f7eebfdda6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-d67745e0-47f8-437d-aab1-82cce674ddac,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-1dc379c8-28c0-4898-80f7-71089c66156b,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-776d2e8a-cfde-4d84-b8d1-5742f0782c02,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-6b5f1510-df20-4c24-9bb5-6bff8e13f651,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-2ab40b6e-54af-40a7-9352-109e046b4a94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2139699282-172.17.0.5-1595484052085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34654,DS-69a4a6d1-5e7b-41fa-9a6e-d1c0add1ddb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-03667603-c571-456c-9a66-8d9773f3fec7,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-c8856186-57b5-4b51-820c-7f7eebfdda6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-d67745e0-47f8-437d-aab1-82cce674ddac,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-1dc379c8-28c0-4898-80f7-71089c66156b,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-776d2e8a-cfde-4d84-b8d1-5742f0782c02,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-6b5f1510-df20-4c24-9bb5-6bff8e13f651,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-2ab40b6e-54af-40a7-9352-109e046b4a94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-95158471-172.17.0.5-1595484331930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35761,DS-eaa6d40c-9e30-4a82-b595-a4dafbe51e53,DISK], DatanodeInfoWithStorage[127.0.0.1:39356,DS-69cf2532-6ee5-45cf-a05a-f7e344b8671a,DISK], DatanodeInfoWithStorage[127.0.0.1:42119,DS-e7582a64-31c8-4ae0-a367-59f39d1323a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-998b42dc-827c-44fa-a066-3c340171c408,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-22d38289-73ba-47e7-984e-5ca8a6da3806,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-d1c4a032-d7f5-4e7d-a2c0-32d805888e32,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-af141f81-f184-40c8-9928-20ed0d7892d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-4416ebb0-22e1-43e5-be82-4e7d502483d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-95158471-172.17.0.5-1595484331930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35761,DS-eaa6d40c-9e30-4a82-b595-a4dafbe51e53,DISK], DatanodeInfoWithStorage[127.0.0.1:39356,DS-69cf2532-6ee5-45cf-a05a-f7e344b8671a,DISK], DatanodeInfoWithStorage[127.0.0.1:42119,DS-e7582a64-31c8-4ae0-a367-59f39d1323a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-998b42dc-827c-44fa-a066-3c340171c408,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-22d38289-73ba-47e7-984e-5ca8a6da3806,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-d1c4a032-d7f5-4e7d-a2c0-32d805888e32,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-af141f81-f184-40c8-9928-20ed0d7892d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-4416ebb0-22e1-43e5-be82-4e7d502483d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-445895401-172.17.0.5-1595484541430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40111,DS-64e41668-998a-4c79-87d3-84cb95b9674f,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-b379a665-ae7c-4f9b-8c60-66c9c34f9ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-8621ec1e-5276-4a35-aac6-9f002907efd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-9a559d00-d1ef-4afc-9d6b-80640261012e,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-c5fafb25-6184-4a9c-8554-514685f51db0,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-f6d5a5f7-3b9e-4b0a-9c94-1f869e60260b,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-ec15eaf7-f2d7-4d69-923b-ead00b2cf546,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-3628ceaf-a664-487e-b410-097b19fd03ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-445895401-172.17.0.5-1595484541430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40111,DS-64e41668-998a-4c79-87d3-84cb95b9674f,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-b379a665-ae7c-4f9b-8c60-66c9c34f9ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-8621ec1e-5276-4a35-aac6-9f002907efd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-9a559d00-d1ef-4afc-9d6b-80640261012e,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-c5fafb25-6184-4a9c-8554-514685f51db0,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-f6d5a5f7-3b9e-4b0a-9c94-1f869e60260b,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-ec15eaf7-f2d7-4d69-923b-ead00b2cf546,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-3628ceaf-a664-487e-b410-097b19fd03ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1690380214-172.17.0.5-1595484707727:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40826,DS-b575e057-691c-4239-b22d-fe3b43517aab,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-0ffe3c78-e613-4b2d-8682-71b47581e3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40684,DS-65c85c80-0eaa-425f-bf2b-2a4934e04bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40707,DS-b6892340-cdff-4300-876f-982d39085f27,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-728b86e4-b541-401b-8591-ddc2224083a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-cf5969be-7370-4859-8098-4b5edd5b87dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-43a160b0-2b66-48d8-8f7b-421fc3905df4,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-24b44d70-0e48-44af-b434-6d51229c4a46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1690380214-172.17.0.5-1595484707727:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40826,DS-b575e057-691c-4239-b22d-fe3b43517aab,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-0ffe3c78-e613-4b2d-8682-71b47581e3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40684,DS-65c85c80-0eaa-425f-bf2b-2a4934e04bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40707,DS-b6892340-cdff-4300-876f-982d39085f27,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-728b86e4-b541-401b-8591-ddc2224083a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-cf5969be-7370-4859-8098-4b5edd5b87dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-43a160b0-2b66-48d8-8f7b-421fc3905df4,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-24b44d70-0e48-44af-b434-6d51229c4a46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-785387999-172.17.0.5-1595484749190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33895,DS-a8367b5e-8f05-4864-9d46-db4b64faa775,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-0b2aee3d-435a-4276-b062-aaf5bbe49849,DISK], DatanodeInfoWithStorage[127.0.0.1:42457,DS-4541f30e-44fd-4540-8187-4966a571333e,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-13cc7947-b1f0-4294-aa10-071a3329b518,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-fe2ab158-a2ec-41cc-a7fd-2e637cbf6b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-11136b59-bbe6-4560-ac9f-3414696b7b55,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-203dd7cd-3283-4d01-b7be-b6fc7b203afc,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-8bc2529f-4eff-4c06-95fd-d9fcd291262a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-785387999-172.17.0.5-1595484749190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33895,DS-a8367b5e-8f05-4864-9d46-db4b64faa775,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-0b2aee3d-435a-4276-b062-aaf5bbe49849,DISK], DatanodeInfoWithStorage[127.0.0.1:42457,DS-4541f30e-44fd-4540-8187-4966a571333e,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-13cc7947-b1f0-4294-aa10-071a3329b518,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-fe2ab158-a2ec-41cc-a7fd-2e637cbf6b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-11136b59-bbe6-4560-ac9f-3414696b7b55,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-203dd7cd-3283-4d01-b7be-b6fc7b203afc,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-8bc2529f-4eff-4c06-95fd-d9fcd291262a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5113
