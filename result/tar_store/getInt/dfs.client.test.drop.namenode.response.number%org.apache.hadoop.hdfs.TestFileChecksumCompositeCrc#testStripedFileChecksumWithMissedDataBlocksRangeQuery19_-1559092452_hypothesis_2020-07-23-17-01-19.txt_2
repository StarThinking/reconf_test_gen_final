reconf_parameter: dfs.client.test.drop.namenode.response.number
component: hdfs:NameNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.test.drop.namenode.response.number
component: hdfs:NameNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1929909576-172.17.0.14-1595523729028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40625,DS-f207eeca-6bde-4db2-bd42-f6a3389545d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-adc48cb7-6617-4aaa-80a0-b56c204bfb24,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-1326ddfd-5a66-4541-9b9e-a901163b7463,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-68b3b0f9-d4cd-4b38-af82-0ee3813a0f85,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-5959fdde-1257-4344-b62f-27f8fe682a00,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-11466435-c3d5-402e-966a-0cf989a0c9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-9985f3a8-354b-47f9-bd0a-1ebceafd496d,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-fda06987-3878-4e08-9255-b49a04120085,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1929909576-172.17.0.14-1595523729028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40625,DS-f207eeca-6bde-4db2-bd42-f6a3389545d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-adc48cb7-6617-4aaa-80a0-b56c204bfb24,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-1326ddfd-5a66-4541-9b9e-a901163b7463,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-68b3b0f9-d4cd-4b38-af82-0ee3813a0f85,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-5959fdde-1257-4344-b62f-27f8fe682a00,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-11466435-c3d5-402e-966a-0cf989a0c9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-9985f3a8-354b-47f9-bd0a-1ebceafd496d,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-fda06987-3878-4e08-9255-b49a04120085,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.test.drop.namenode.response.number
component: hdfs:NameNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2044429154-172.17.0.14-1595523837436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43627,DS-bd70ec1c-3196-45b9-aa0c-4d8a605d5ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-2ed350a6-2b55-4513-93b5-bfba4d6f27d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-936a79f8-00ad-47ab-b7ca-71673d35d489,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-fb4c1e8f-cd18-442c-b7ab-771693488b85,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-80d18dde-75f9-4ee3-aa50-73d97227d96c,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-339f4cd1-ab54-4859-9633-2453a3b807f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-72bd75d3-061b-47d9-855a-3db1a31f2809,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-caa3d955-5c61-457f-827c-3de36e022378,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2044429154-172.17.0.14-1595523837436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43627,DS-bd70ec1c-3196-45b9-aa0c-4d8a605d5ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-2ed350a6-2b55-4513-93b5-bfba4d6f27d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-936a79f8-00ad-47ab-b7ca-71673d35d489,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-fb4c1e8f-cd18-442c-b7ab-771693488b85,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-80d18dde-75f9-4ee3-aa50-73d97227d96c,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-339f4cd1-ab54-4859-9633-2453a3b807f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-72bd75d3-061b-47d9-855a-3db1a31f2809,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-caa3d955-5c61-457f-827c-3de36e022378,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.test.drop.namenode.response.number
component: hdfs:NameNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-401384515-172.17.0.14-1595524300017:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44734,DS-9ec94816-6543-4fce-8313-0b41d8504d61,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-6c5be685-c3e9-4306-9ce5-0366c5cf474d,DISK], DatanodeInfoWithStorage[127.0.0.1:46329,DS-47410781-fd1a-4164-9f8e-b4ef436bf5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33567,DS-aebd8d58-ccde-4e36-b90e-45d69b3e1f73,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-e5c0d529-ef62-4e81-adb0-8e647a411bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-dccb91f8-728e-47bc-9384-74351ed85187,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-a53967d2-0a8c-499e-bdb4-ae3864145e88,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-78a0d9c1-f646-488f-bc09-987909980f0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-401384515-172.17.0.14-1595524300017:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44734,DS-9ec94816-6543-4fce-8313-0b41d8504d61,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-6c5be685-c3e9-4306-9ce5-0366c5cf474d,DISK], DatanodeInfoWithStorage[127.0.0.1:46329,DS-47410781-fd1a-4164-9f8e-b4ef436bf5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33567,DS-aebd8d58-ccde-4e36-b90e-45d69b3e1f73,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-e5c0d529-ef62-4e81-adb0-8e647a411bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-dccb91f8-728e-47bc-9384-74351ed85187,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-a53967d2-0a8c-499e-bdb4-ae3864145e88,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-78a0d9c1-f646-488f-bc09-987909980f0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.test.drop.namenode.response.number
component: hdfs:NameNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1978782755-172.17.0.14-1595524565449:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38017,DS-a5d637e1-cbbd-4953-92fa-6cc96802bf31,DISK], DatanodeInfoWithStorage[127.0.0.1:46003,DS-e29f6c61-f942-4cfb-a26d-3d7c32ffe0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-d928a815-ede5-4314-821c-24bf15ba3bba,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-678dc965-526e-47c3-a29f-567cf6656fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-0acda423-e37d-4965-824c-cacda5b68573,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-f63323bb-c4ba-4979-a776-5a7a2dfabe58,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-0db36407-2183-4bf0-8e0c-25a173318f09,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-f32ecec4-4abf-403c-8b4c-7754b02459a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1978782755-172.17.0.14-1595524565449:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38017,DS-a5d637e1-cbbd-4953-92fa-6cc96802bf31,DISK], DatanodeInfoWithStorage[127.0.0.1:46003,DS-e29f6c61-f942-4cfb-a26d-3d7c32ffe0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-d928a815-ede5-4314-821c-24bf15ba3bba,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-678dc965-526e-47c3-a29f-567cf6656fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-0acda423-e37d-4965-824c-cacda5b68573,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-f63323bb-c4ba-4979-a776-5a7a2dfabe58,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-0db36407-2183-4bf0-8e0c-25a173318f09,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-f32ecec4-4abf-403c-8b4c-7754b02459a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.test.drop.namenode.response.number
component: hdfs:NameNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-260591025-172.17.0.14-1595525082216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41331,DS-a6e732c1-e345-4fcf-9afe-800963690e03,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-9e2d3a22-cf57-4bab-b8c3-d207a3462c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-08a18aa1-cf2a-4816-90d7-f9b565fa14c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-276a2551-0dca-4cb6-880d-9b92ddaea5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-776b271d-5df5-468f-8b84-9db74bd4ba99,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-c5fc9706-eed4-4983-987c-ae4650f8d04d,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-6466ed79-1c56-4f4c-993c-d038017e2b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-2fec7697-1126-495d-87b1-04d40b2265e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-260591025-172.17.0.14-1595525082216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41331,DS-a6e732c1-e345-4fcf-9afe-800963690e03,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-9e2d3a22-cf57-4bab-b8c3-d207a3462c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-08a18aa1-cf2a-4816-90d7-f9b565fa14c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-276a2551-0dca-4cb6-880d-9b92ddaea5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-776b271d-5df5-468f-8b84-9db74bd4ba99,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-c5fc9706-eed4-4983-987c-ae4650f8d04d,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-6466ed79-1c56-4f4c-993c-d038017e2b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-2fec7697-1126-495d-87b1-04d40b2265e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.test.drop.namenode.response.number
component: hdfs:NameNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-55968692-172.17.0.14-1595526168536:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39982,DS-06fe0f21-5ab5-4c46-82bd-bded68803517,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-065ef9a0-048c-4e43-b3e1-21453f18bf0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-72ffb974-fe8d-4efd-bea8-c42ca541db00,DISK], DatanodeInfoWithStorage[127.0.0.1:45068,DS-441d89a9-a25e-4cbe-b98c-15969addf96b,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-2216c2bc-4394-43c2-a7bc-c90f5c64d474,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-72e947cd-247c-4f6b-8c94-9c5ae5dde381,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-0038769f-a133-4076-a4ef-23aa3f9f41e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-e127b88c-f7e2-4898-9ab4-5c7d061ac031,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-55968692-172.17.0.14-1595526168536:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39982,DS-06fe0f21-5ab5-4c46-82bd-bded68803517,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-065ef9a0-048c-4e43-b3e1-21453f18bf0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-72ffb974-fe8d-4efd-bea8-c42ca541db00,DISK], DatanodeInfoWithStorage[127.0.0.1:45068,DS-441d89a9-a25e-4cbe-b98c-15969addf96b,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-2216c2bc-4394-43c2-a7bc-c90f5c64d474,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-72e947cd-247c-4f6b-8c94-9c5ae5dde381,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-0038769f-a133-4076-a4ef-23aa3f9f41e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-e127b88c-f7e2-4898-9ab4-5c7d061ac031,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.test.drop.namenode.response.number
component: hdfs:NameNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1211948507-172.17.0.14-1595526279249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37233,DS-08ead042-a582-432c-9d23-a1d5f6790e47,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-d829ebbc-1635-4b3a-85c7-c88a4d07c365,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-c5d2e237-e3e6-4431-884f-bbc5f2007a58,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-46b8b9b4-5187-47ee-910b-faf681e9bb66,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-9e468193-9a9e-4830-a203-a7d3edc3442e,DISK], DatanodeInfoWithStorage[127.0.0.1:37729,DS-f64a3aa3-6e71-4d34-8c38-d41208e29301,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-f520e387-0185-4bc1-862a-7c617aa9951d,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-9f187e9c-7854-40f0-a0c2-ffb62668eb62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1211948507-172.17.0.14-1595526279249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37233,DS-08ead042-a582-432c-9d23-a1d5f6790e47,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-d829ebbc-1635-4b3a-85c7-c88a4d07c365,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-c5d2e237-e3e6-4431-884f-bbc5f2007a58,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-46b8b9b4-5187-47ee-910b-faf681e9bb66,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-9e468193-9a9e-4830-a203-a7d3edc3442e,DISK], DatanodeInfoWithStorage[127.0.0.1:37729,DS-f64a3aa3-6e71-4d34-8c38-d41208e29301,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-f520e387-0185-4bc1-862a-7c617aa9951d,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-9f187e9c-7854-40f0-a0c2-ffb62668eb62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.test.drop.namenode.response.number
component: hdfs:NameNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-813495844-172.17.0.14-1595526614270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39109,DS-5b794eef-b588-4207-97a7-8453ad9d235a,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-bc45601f-fc1f-4f68-9fe4-47dee6cfdab1,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-ced121ac-87c2-4eea-9cd7-af7de502e185,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-f30e00d4-010f-4ab3-b553-1f06afaaa891,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-4895dec7-684c-41bd-a529-522e84eaad3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-ba8cb3e8-ebf2-484d-b6bf-403fe7f4fea8,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-8560a3d2-3252-4613-a43b-be052a14c3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39079,DS-419f15b2-1a36-475b-a140-a4615c65ea63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-813495844-172.17.0.14-1595526614270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39109,DS-5b794eef-b588-4207-97a7-8453ad9d235a,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-bc45601f-fc1f-4f68-9fe4-47dee6cfdab1,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-ced121ac-87c2-4eea-9cd7-af7de502e185,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-f30e00d4-010f-4ab3-b553-1f06afaaa891,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-4895dec7-684c-41bd-a529-522e84eaad3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-ba8cb3e8-ebf2-484d-b6bf-403fe7f4fea8,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-8560a3d2-3252-4613-a43b-be052a14c3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39079,DS-419f15b2-1a36-475b-a140-a4615c65ea63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.test.drop.namenode.response.number
component: hdfs:NameNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1046676694-172.17.0.14-1595527031334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36869,DS-e4db431c-799e-4c8a-8cdf-ece3dc39f5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-9d76d648-7c86-456e-b696-7e2a1cd81fff,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-507619a7-ee68-4524-b6bb-536ce9e641d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34253,DS-7af52bdb-b0f4-4df3-bd2b-68a2429f0b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-0b5631c9-e96d-4c0e-829d-32e2378930e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-074471a4-f4b9-4533-b8a5-313a06fb8d42,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-2eaa8aa1-19ef-4b93-9d59-74f3b6deeb43,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-eb5f7461-19d2-4724-a56d-e1b0f7c4a312,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1046676694-172.17.0.14-1595527031334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36869,DS-e4db431c-799e-4c8a-8cdf-ece3dc39f5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-9d76d648-7c86-456e-b696-7e2a1cd81fff,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-507619a7-ee68-4524-b6bb-536ce9e641d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34253,DS-7af52bdb-b0f4-4df3-bd2b-68a2429f0b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-0b5631c9-e96d-4c0e-829d-32e2378930e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-074471a4-f4b9-4533-b8a5-313a06fb8d42,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-2eaa8aa1-19ef-4b93-9d59-74f3b6deeb43,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-eb5f7461-19d2-4724-a56d-e1b0f7c4a312,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.test.drop.namenode.response.number
component: hdfs:NameNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1689541131-172.17.0.14-1595527257576:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44231,DS-6e1f488c-be8b-4aa1-8d67-f57ce6676022,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-8101ffc7-0061-43cd-8a3d-7cea62336ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-9414c822-fc7f-43b1-b95e-038f872486ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-8734fc51-e5ac-4427-8d2f-0a8e22f14c96,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-8aec097b-08f3-47ec-aa92-b5aa1ad72d61,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-2212648a-15b0-4a6a-be32-eaf3ac94915a,DISK], DatanodeInfoWithStorage[127.0.0.1:41819,DS-e6b8e4a8-0fe7-48e8-8b1e-53d04b12d3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-76c80650-cd40-40d3-9e3a-eb271d664355,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1689541131-172.17.0.14-1595527257576:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44231,DS-6e1f488c-be8b-4aa1-8d67-f57ce6676022,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-8101ffc7-0061-43cd-8a3d-7cea62336ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-9414c822-fc7f-43b1-b95e-038f872486ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-8734fc51-e5ac-4427-8d2f-0a8e22f14c96,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-8aec097b-08f3-47ec-aa92-b5aa1ad72d61,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-2212648a-15b0-4a6a-be32-eaf3ac94915a,DISK], DatanodeInfoWithStorage[127.0.0.1:41819,DS-e6b8e4a8-0fe7-48e8-8b1e-53d04b12d3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-76c80650-cd40-40d3-9e3a-eb271d664355,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.test.drop.namenode.response.number
component: hdfs:NameNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1198445956-172.17.0.14-1595527367594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44893,DS-8bb8ae4f-55b9-4e72-be62-232e942ff6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-cd2ed6e5-9d7e-41e6-958c-74f489ffd0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-6672c7be-d524-4c2f-bc3f-8ed8a35197a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46043,DS-c15912c8-679d-4294-a49b-025c72235f61,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-a5828794-35f1-4d81-acf1-8270144afdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-b5d0efdd-af78-4d3c-b031-1b2ea746e591,DISK], DatanodeInfoWithStorage[127.0.0.1:40142,DS-e6f6f87c-a759-4972-afd3-1cbc264d7cff,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-41dd291a-c955-46e2-ba86-31aa82d59df3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1198445956-172.17.0.14-1595527367594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44893,DS-8bb8ae4f-55b9-4e72-be62-232e942ff6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-cd2ed6e5-9d7e-41e6-958c-74f489ffd0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-6672c7be-d524-4c2f-bc3f-8ed8a35197a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46043,DS-c15912c8-679d-4294-a49b-025c72235f61,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-a5828794-35f1-4d81-acf1-8270144afdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-b5d0efdd-af78-4d3c-b031-1b2ea746e591,DISK], DatanodeInfoWithStorage[127.0.0.1:40142,DS-e6f6f87c-a759-4972-afd3-1cbc264d7cff,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-41dd291a-c955-46e2-ba86-31aa82d59df3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.test.drop.namenode.response.number
component: hdfs:NameNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1018849543-172.17.0.14-1595527832919:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45251,DS-f25fb539-b70e-4482-b395-162fd8bd149f,DISK], DatanodeInfoWithStorage[127.0.0.1:36936,DS-352a7ccf-a422-4cd8-a2dd-c64ca375ccb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-a4343744-9dad-43af-acf5-46ae8935b24d,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-d76f413f-dfc1-4b95-9edf-c0325d3e7644,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-28b17d49-26f1-47bc-ab1d-72be6b4560d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-ff4d528d-6a4d-46db-8795-bf9e613a2f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-1e64b196-ad8a-47ce-a0cc-d826b9c554b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-e69ebd35-1e25-4611-ac9c-2b7af65e3f95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1018849543-172.17.0.14-1595527832919:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45251,DS-f25fb539-b70e-4482-b395-162fd8bd149f,DISK], DatanodeInfoWithStorage[127.0.0.1:36936,DS-352a7ccf-a422-4cd8-a2dd-c64ca375ccb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-a4343744-9dad-43af-acf5-46ae8935b24d,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-d76f413f-dfc1-4b95-9edf-c0325d3e7644,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-28b17d49-26f1-47bc-ab1d-72be6b4560d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-ff4d528d-6a4d-46db-8795-bf9e613a2f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-1e64b196-ad8a-47ce-a0cc-d826b9c554b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-e69ebd35-1e25-4611-ac9c-2b7af65e3f95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.test.drop.namenode.response.number
component: hdfs:NameNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1189705282-172.17.0.14-1595528008187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45007,DS-7feb1980-56c5-4aa1-8954-c5e6add29ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:36290,DS-0569a11e-6ba8-48e9-8e21-68c0dd58e148,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-8ff5578b-baf7-4f5b-9aa3-0f6a84dfa5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-137362e1-41ce-4232-a802-99f66612c806,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-1997700f-d2d8-487c-a07b-635baa1e9edf,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-1b29569c-e40a-4250-bf3f-c5267c555b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-82809018-6f39-4f0c-bded-df9956455408,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-f9ee22d2-8898-4d2f-a556-5be4a60e9394,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1189705282-172.17.0.14-1595528008187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45007,DS-7feb1980-56c5-4aa1-8954-c5e6add29ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:36290,DS-0569a11e-6ba8-48e9-8e21-68c0dd58e148,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-8ff5578b-baf7-4f5b-9aa3-0f6a84dfa5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-137362e1-41ce-4232-a802-99f66612c806,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-1997700f-d2d8-487c-a07b-635baa1e9edf,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-1b29569c-e40a-4250-bf3f-c5267c555b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-82809018-6f39-4f0c-bded-df9956455408,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-f9ee22d2-8898-4d2f-a556-5be4a60e9394,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.test.drop.namenode.response.number
component: hdfs:NameNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-828059985-172.17.0.14-1595528139297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34499,DS-ba87c7fd-f949-4a6e-9ff6-4169f6ad891b,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-3fd969be-62be-4bad-b100-96e20f2053b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-ccc7d190-4a06-4daf-ba23-1e875f1c6b79,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-174cd5fe-05e0-417a-8a25-40698d309572,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-7131c118-2a11-4b3c-9767-c830d5edabc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-3fdf61c9-6ef1-413f-bf7c-d7836b094169,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-63f69ad2-44a1-426b-ac06-9e9f0042630a,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-eb785394-dabc-4562-ab22-6e63ecaf0186,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-828059985-172.17.0.14-1595528139297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34499,DS-ba87c7fd-f949-4a6e-9ff6-4169f6ad891b,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-3fd969be-62be-4bad-b100-96e20f2053b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-ccc7d190-4a06-4daf-ba23-1e875f1c6b79,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-174cd5fe-05e0-417a-8a25-40698d309572,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-7131c118-2a11-4b3c-9767-c830d5edabc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-3fdf61c9-6ef1-413f-bf7c-d7836b094169,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-63f69ad2-44a1-426b-ac06-9e9f0042630a,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-eb785394-dabc-4562-ab22-6e63ecaf0186,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.test.drop.namenode.response.number
component: hdfs:NameNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2103192282-172.17.0.14-1595528274834:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40169,DS-ed0ca44c-66ac-4442-9d56-26f6790bea8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-3bbb817d-38b0-4aa4-a895-6ba4076deace,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-ae711559-06b8-496d-a375-949fb92f4ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-7dac9599-3b45-4907-a9c9-588a7225c50f,DISK], DatanodeInfoWithStorage[127.0.0.1:36514,DS-9648156a-8c7e-4195-a4e9-9f475e2210d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-c25e149d-9da8-42b1-984f-0b9be719be55,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-e5e2bdad-24d9-4893-be62-57a005fa2f37,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-80c9e706-9faf-4cf9-9be8-f99913b8e454,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2103192282-172.17.0.14-1595528274834:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40169,DS-ed0ca44c-66ac-4442-9d56-26f6790bea8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-3bbb817d-38b0-4aa4-a895-6ba4076deace,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-ae711559-06b8-496d-a375-949fb92f4ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-7dac9599-3b45-4907-a9c9-588a7225c50f,DISK], DatanodeInfoWithStorage[127.0.0.1:36514,DS-9648156a-8c7e-4195-a4e9-9f475e2210d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-c25e149d-9da8-42b1-984f-0b9be719be55,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-e5e2bdad-24d9-4893-be62-57a005fa2f37,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-80c9e706-9faf-4cf9-9be8-f99913b8e454,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5377
