reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1758368106-172.17.0.10-1595631975911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39151,DS-b3cdb715-5d50-42ae-acf4-9f2b71e7ceb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44350,DS-12d4bd9b-f026-4064-ada6-2a0b3c1bf14a,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-b38affec-0842-4048-8ede-46f68c4c50f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-1b67fef6-2082-422a-9c34-3658ae6c4b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-ba6ef732-1d35-4090-a276-0f88ffa92914,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-69ae084a-ac1e-4678-8613-4e473ad2a550,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-f5e89b66-ec26-4b00-b819-651c70b25fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-1fdf44df-9237-4d7c-b9b3-5d6f47d50f1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1758368106-172.17.0.10-1595631975911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39151,DS-b3cdb715-5d50-42ae-acf4-9f2b71e7ceb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44350,DS-12d4bd9b-f026-4064-ada6-2a0b3c1bf14a,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-b38affec-0842-4048-8ede-46f68c4c50f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-1b67fef6-2082-422a-9c34-3658ae6c4b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-ba6ef732-1d35-4090-a276-0f88ffa92914,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-69ae084a-ac1e-4678-8613-4e473ad2a550,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-f5e89b66-ec26-4b00-b819-651c70b25fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-1fdf44df-9237-4d7c-b9b3-5d6f47d50f1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1976903188-172.17.0.10-1595632135938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37930,DS-9d326dd2-e3ec-4269-b31d-550920e3b078,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-b27038f1-2e9e-4595-9271-75d82af1954e,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-76ccc4cb-166c-4578-8230-0bd335bc3bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41964,DS-53df7da4-eddb-4d61-91cc-55c02bb29f74,DISK], DatanodeInfoWithStorage[127.0.0.1:41503,DS-d2029aad-14e0-4284-b330-873fe572a798,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-c1e8b535-02f1-43a6-878f-5fbf24d0895e,DISK], DatanodeInfoWithStorage[127.0.0.1:39813,DS-22b078e0-1f93-4a5e-9ddf-c697b1405caf,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-4e6a9078-c36c-477c-ad93-dfc4da859b40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1976903188-172.17.0.10-1595632135938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37930,DS-9d326dd2-e3ec-4269-b31d-550920e3b078,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-b27038f1-2e9e-4595-9271-75d82af1954e,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-76ccc4cb-166c-4578-8230-0bd335bc3bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41964,DS-53df7da4-eddb-4d61-91cc-55c02bb29f74,DISK], DatanodeInfoWithStorage[127.0.0.1:41503,DS-d2029aad-14e0-4284-b330-873fe572a798,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-c1e8b535-02f1-43a6-878f-5fbf24d0895e,DISK], DatanodeInfoWithStorage[127.0.0.1:39813,DS-22b078e0-1f93-4a5e-9ddf-c697b1405caf,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-4e6a9078-c36c-477c-ad93-dfc4da859b40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-490205178-172.17.0.10-1595632637868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38425,DS-ee77d5e7-c51c-42c2-b031-a71e7a9f8464,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-9f336ca4-29be-4dd3-a1ad-cdf4b091dd4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-bb342f8f-2d58-426a-85cb-8a4b0224d28f,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-4f007a91-4ad3-4988-997f-bc0990613d29,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-dd96a001-ff9c-44bb-be84-96a2ade0e8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-b9edc157-c4d3-46b9-9b34-61620caffd27,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-f9bef204-3374-48cf-a970-9f64ecd6398e,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-f72e99e0-78e1-42f9-a886-2ef527836183,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-490205178-172.17.0.10-1595632637868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38425,DS-ee77d5e7-c51c-42c2-b031-a71e7a9f8464,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-9f336ca4-29be-4dd3-a1ad-cdf4b091dd4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-bb342f8f-2d58-426a-85cb-8a4b0224d28f,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-4f007a91-4ad3-4988-997f-bc0990613d29,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-dd96a001-ff9c-44bb-be84-96a2ade0e8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-b9edc157-c4d3-46b9-9b34-61620caffd27,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-f9bef204-3374-48cf-a970-9f64ecd6398e,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-f72e99e0-78e1-42f9-a886-2ef527836183,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-128696382-172.17.0.10-1595633205093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44214,DS-24fa69de-cf92-4aa7-b9af-5e4948f6b7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-6e8ed33f-3c96-447a-93f5-1361efd21e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-aa8b994c-72ad-440f-9c52-e44b0767f6da,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-0fa6cfe6-ed45-4f8c-9c9b-aaf3ada50604,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-7525b208-9a3e-4367-969f-44bce87a1d74,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-a6ce244b-ff83-476d-a795-f917e2768809,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-1a7a5d01-63eb-4bd6-9b35-16d42f098cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-c1aa15db-a44b-4f3d-98e8-c7097157bfb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-128696382-172.17.0.10-1595633205093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44214,DS-24fa69de-cf92-4aa7-b9af-5e4948f6b7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-6e8ed33f-3c96-447a-93f5-1361efd21e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-aa8b994c-72ad-440f-9c52-e44b0767f6da,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-0fa6cfe6-ed45-4f8c-9c9b-aaf3ada50604,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-7525b208-9a3e-4367-969f-44bce87a1d74,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-a6ce244b-ff83-476d-a795-f917e2768809,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-1a7a5d01-63eb-4bd6-9b35-16d42f098cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-c1aa15db-a44b-4f3d-98e8-c7097157bfb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-747164275-172.17.0.10-1595633515242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37767,DS-b4c34383-2501-4f7a-9bf0-639ac57daf79,DISK], DatanodeInfoWithStorage[127.0.0.1:40504,DS-d2d9e526-9e4c-44a2-ac32-43ec70672eae,DISK], DatanodeInfoWithStorage[127.0.0.1:43893,DS-7f9fdec9-b8e9-49eb-af32-42b544d87558,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-8f702eba-b4e4-4291-8282-554b80ddef31,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-dee73fd6-74ee-4551-b5d7-75d197d7bcaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-f4a0bae6-5764-4490-b6cd-ba15c72f5ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-8149e7ec-4c5d-4f8c-a629-5f56fff16d50,DISK], DatanodeInfoWithStorage[127.0.0.1:37082,DS-dbd61400-ce0f-44b7-ada4-6dae6c9fa8e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-747164275-172.17.0.10-1595633515242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37767,DS-b4c34383-2501-4f7a-9bf0-639ac57daf79,DISK], DatanodeInfoWithStorage[127.0.0.1:40504,DS-d2d9e526-9e4c-44a2-ac32-43ec70672eae,DISK], DatanodeInfoWithStorage[127.0.0.1:43893,DS-7f9fdec9-b8e9-49eb-af32-42b544d87558,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-8f702eba-b4e4-4291-8282-554b80ddef31,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-dee73fd6-74ee-4551-b5d7-75d197d7bcaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-f4a0bae6-5764-4490-b6cd-ba15c72f5ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-8149e7ec-4c5d-4f8c-a629-5f56fff16d50,DISK], DatanodeInfoWithStorage[127.0.0.1:37082,DS-dbd61400-ce0f-44b7-ada4-6dae6c9fa8e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-827521419-172.17.0.10-1595633588064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36021,DS-428aaad1-dedd-41ba-9605-092dd07db6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-26274750-dacb-4536-bbea-0de74ce1f07a,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-61b76968-c03e-4649-9f2a-4ab4c79d47fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-94ea1eb4-e7f9-48f1-ad1c-ba6e6c2941ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-f9fa342a-e15e-424a-9672-6d9d693e1a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-4b839137-c785-4cc2-877e-948d539ce668,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-0a799cb0-a08d-45bd-b4fd-c84f574a9363,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-c0a14312-dc9d-4a74-92de-1321a68c9136,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-827521419-172.17.0.10-1595633588064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36021,DS-428aaad1-dedd-41ba-9605-092dd07db6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-26274750-dacb-4536-bbea-0de74ce1f07a,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-61b76968-c03e-4649-9f2a-4ab4c79d47fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-94ea1eb4-e7f9-48f1-ad1c-ba6e6c2941ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-f9fa342a-e15e-424a-9672-6d9d693e1a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-4b839137-c785-4cc2-877e-948d539ce668,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-0a799cb0-a08d-45bd-b4fd-c84f574a9363,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-c0a14312-dc9d-4a74-92de-1321a68c9136,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2032914370-172.17.0.10-1595634345547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45352,DS-07fae93a-5c85-456d-88cf-71bbd1e24499,DISK], DatanodeInfoWithStorage[127.0.0.1:37458,DS-6fcd5546-f8b1-41a1-a631-6c07747e7f35,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-2360fa84-64e2-4b04-a283-2926b64eaff5,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-58f657c7-d188-4561-8943-874e7c711c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-8445648f-444a-40f2-a862-6d5fb31c5181,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-d4e52338-433c-4933-bfb9-de544ac1283d,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-51754b04-2cc2-4e75-aa9b-9f22f1abd3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-0eeaf450-4f59-4983-a2de-5b130b8fa8e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2032914370-172.17.0.10-1595634345547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45352,DS-07fae93a-5c85-456d-88cf-71bbd1e24499,DISK], DatanodeInfoWithStorage[127.0.0.1:37458,DS-6fcd5546-f8b1-41a1-a631-6c07747e7f35,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-2360fa84-64e2-4b04-a283-2926b64eaff5,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-58f657c7-d188-4561-8943-874e7c711c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-8445648f-444a-40f2-a862-6d5fb31c5181,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-d4e52338-433c-4933-bfb9-de544ac1283d,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-51754b04-2cc2-4e75-aa9b-9f22f1abd3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-0eeaf450-4f59-4983-a2de-5b130b8fa8e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2127788261-172.17.0.10-1595636711806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42983,DS-40c31e36-d315-434f-af5b-64a161411923,DISK], DatanodeInfoWithStorage[127.0.0.1:35473,DS-12f7662c-9955-4f0e-8c8f-2d71ae035862,DISK], DatanodeInfoWithStorage[127.0.0.1:44544,DS-ccfc0b9f-1dab-410a-8ec3-8887befec667,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-e0f86db3-9ec3-4cdf-b3bc-d52253ec5b38,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-ea0549a2-8b37-4ed9-acd7-628cd39f0038,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-6242a90f-1eee-4eb9-94a9-91f13ee246b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-52717cf7-86dc-442d-b2e7-48c118aac4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-71deca67-9748-40d5-872d-69d5a22e1289,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2127788261-172.17.0.10-1595636711806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42983,DS-40c31e36-d315-434f-af5b-64a161411923,DISK], DatanodeInfoWithStorage[127.0.0.1:35473,DS-12f7662c-9955-4f0e-8c8f-2d71ae035862,DISK], DatanodeInfoWithStorage[127.0.0.1:44544,DS-ccfc0b9f-1dab-410a-8ec3-8887befec667,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-e0f86db3-9ec3-4cdf-b3bc-d52253ec5b38,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-ea0549a2-8b37-4ed9-acd7-628cd39f0038,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-6242a90f-1eee-4eb9-94a9-91f13ee246b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-52717cf7-86dc-442d-b2e7-48c118aac4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-71deca67-9748-40d5-872d-69d5a22e1289,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1849939318-172.17.0.10-1595637276819:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34358,DS-7930074b-9503-45f1-8bc8-182513a658ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-7f324bf3-e7c1-4684-b586-e1cf1af68ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-8e19c932-cba1-4f61-a5b0-82cc8c2b234e,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-e7df3ba7-0067-4522-9b14-2d61b180aaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-23d5b4f9-9302-4833-b87d-d1e1c3ad8fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-0c1d0bf4-2187-46b2-9602-b61aa6aded14,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-556a3a65-9292-4692-a764-8c49c131b283,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-5dde1120-2742-4fb2-a6a9-7b05ea2644df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1849939318-172.17.0.10-1595637276819:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34358,DS-7930074b-9503-45f1-8bc8-182513a658ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-7f324bf3-e7c1-4684-b586-e1cf1af68ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-8e19c932-cba1-4f61-a5b0-82cc8c2b234e,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-e7df3ba7-0067-4522-9b14-2d61b180aaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-23d5b4f9-9302-4833-b87d-d1e1c3ad8fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-0c1d0bf4-2187-46b2-9602-b61aa6aded14,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-556a3a65-9292-4692-a764-8c49c131b283,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-5dde1120-2742-4fb2-a6a9-7b05ea2644df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 1 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 6330
