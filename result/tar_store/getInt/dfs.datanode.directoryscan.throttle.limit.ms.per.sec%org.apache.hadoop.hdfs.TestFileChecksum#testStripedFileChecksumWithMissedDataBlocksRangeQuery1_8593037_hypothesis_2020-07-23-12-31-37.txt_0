reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1748703001-172.17.0.14-1595507884268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36318,DS-f9dec5e6-96d0-456a-bb27-c69c3653fb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40072,DS-1f554dc0-d0ff-4671-a5fb-4f5be10e53a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-13358b20-8b41-42d1-80c8-d856c18d3537,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-8f82047e-20d0-4ff7-bcd0-9c4c41cbd2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-731072d1-cba5-475e-9a63-4f29c208b00e,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-f6ba95b9-d6ff-4e3b-ba73-bd737cd63945,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-890835d3-ed7a-4c36-a0b8-3b9401a28bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-32f98129-b54d-4393-a9fc-da7ccf5c5361,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1748703001-172.17.0.14-1595507884268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36318,DS-f9dec5e6-96d0-456a-bb27-c69c3653fb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40072,DS-1f554dc0-d0ff-4671-a5fb-4f5be10e53a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-13358b20-8b41-42d1-80c8-d856c18d3537,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-8f82047e-20d0-4ff7-bcd0-9c4c41cbd2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-731072d1-cba5-475e-9a63-4f29c208b00e,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-f6ba95b9-d6ff-4e3b-ba73-bd737cd63945,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-890835d3-ed7a-4c36-a0b8-3b9401a28bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-32f98129-b54d-4393-a9fc-da7ccf5c5361,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-355641934-172.17.0.14-1595508402433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46648,DS-5ee5a8f1-7799-4fc6-aef6-bf1d6da3d5af,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-a2bd7edf-ccdb-4d75-853b-b53c62915fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-829dc119-4aac-4e95-bee7-3d47c6b4a3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-cecc9fd7-e999-41dd-a18f-1f9f997bc6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-8fddb9fb-2417-438d-b6b5-d85c465ea687,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-72889e4f-a1c7-4cd0-95ee-7ab908893112,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-8031a269-9db7-45c1-99b8-bfe3ca8e8649,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-db3184c3-4de2-4e54-abb5-0706db92a160,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-355641934-172.17.0.14-1595508402433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46648,DS-5ee5a8f1-7799-4fc6-aef6-bf1d6da3d5af,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-a2bd7edf-ccdb-4d75-853b-b53c62915fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-829dc119-4aac-4e95-bee7-3d47c6b4a3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-cecc9fd7-e999-41dd-a18f-1f9f997bc6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-8fddb9fb-2417-438d-b6b5-d85c465ea687,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-72889e4f-a1c7-4cd0-95ee-7ab908893112,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-8031a269-9db7-45c1-99b8-bfe3ca8e8649,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-db3184c3-4de2-4e54-abb5-0706db92a160,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2032001125-172.17.0.14-1595509089555:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41428,DS-45aee4fc-463b-4d47-810f-5bf3d649cf97,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-b5f10f79-50c6-4e4a-bdb3-f386a93075c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-801b4d45-f352-4c29-9c09-4a43915bf61e,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-244fe59d-5dc2-463d-bbdd-2f28d5577da2,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-1d2c8838-a3b5-44c1-9de9-17eae9cb59b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-e85b6756-3b3b-49e5-8b13-2befbcfdb7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-6a3e78af-208a-4d04-a7b7-e9236f55d171,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-6435f4f2-7d8a-46de-b5c0-b40d26f0df9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2032001125-172.17.0.14-1595509089555:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41428,DS-45aee4fc-463b-4d47-810f-5bf3d649cf97,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-b5f10f79-50c6-4e4a-bdb3-f386a93075c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-801b4d45-f352-4c29-9c09-4a43915bf61e,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-244fe59d-5dc2-463d-bbdd-2f28d5577da2,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-1d2c8838-a3b5-44c1-9de9-17eae9cb59b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-e85b6756-3b3b-49e5-8b13-2befbcfdb7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-6a3e78af-208a-4d04-a7b7-e9236f55d171,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-6435f4f2-7d8a-46de-b5c0-b40d26f0df9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1760437516-172.17.0.14-1595509165442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35380,DS-ef39d543-b4c6-47bb-b3aa-eba29d925168,DISK], DatanodeInfoWithStorage[127.0.0.1:46804,DS-cee567be-243f-4e62-bf21-37765a9c4e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:32954,DS-9c0cd51b-e614-47a4-a4e7-d46c72559218,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-ea97d1b0-3758-4ec1-a661-2a45d9b6e364,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-62fc6856-2990-4c5d-807e-8388b7bbbaaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35312,DS-7653ea04-490a-427d-bf05-86c813e7a9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-84aabeba-a1f1-45d7-a74c-6ac3da815412,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-ce0049a9-7873-4358-9d97-7aacf987cc88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1760437516-172.17.0.14-1595509165442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35380,DS-ef39d543-b4c6-47bb-b3aa-eba29d925168,DISK], DatanodeInfoWithStorage[127.0.0.1:46804,DS-cee567be-243f-4e62-bf21-37765a9c4e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:32954,DS-9c0cd51b-e614-47a4-a4e7-d46c72559218,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-ea97d1b0-3758-4ec1-a661-2a45d9b6e364,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-62fc6856-2990-4c5d-807e-8388b7bbbaaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35312,DS-7653ea04-490a-427d-bf05-86c813e7a9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-84aabeba-a1f1-45d7-a74c-6ac3da815412,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-ce0049a9-7873-4358-9d97-7aacf987cc88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1555944962-172.17.0.14-1595509508267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36558,DS-b9d2068d-629c-44fa-b881-f510315de00e,DISK], DatanodeInfoWithStorage[127.0.0.1:33998,DS-99eae5d6-aa35-429f-919d-bb68fcb726df,DISK], DatanodeInfoWithStorage[127.0.0.1:36514,DS-7fd58dea-4389-4130-984e-5c2603aecda9,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-dcfcc737-f1c2-436c-af78-81f6e848d610,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-4ede222f-a82b-4b4a-86ac-515d671dbfe3,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-df57d890-2f8a-4373-b720-48fa053dd304,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-342658a4-a429-4470-a6aa-1198662aa965,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-cd47e3ac-0589-4cc2-9722-9c4c31375b95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1555944962-172.17.0.14-1595509508267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36558,DS-b9d2068d-629c-44fa-b881-f510315de00e,DISK], DatanodeInfoWithStorage[127.0.0.1:33998,DS-99eae5d6-aa35-429f-919d-bb68fcb726df,DISK], DatanodeInfoWithStorage[127.0.0.1:36514,DS-7fd58dea-4389-4130-984e-5c2603aecda9,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-dcfcc737-f1c2-436c-af78-81f6e848d610,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-4ede222f-a82b-4b4a-86ac-515d671dbfe3,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-df57d890-2f8a-4373-b720-48fa053dd304,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-342658a4-a429-4470-a6aa-1198662aa965,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-cd47e3ac-0589-4cc2-9722-9c4c31375b95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-76801585-172.17.0.14-1595510192637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32788,DS-d6b5de97-217f-4d5c-ad6f-fa4d09855142,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-213eed75-31c3-49af-85bc-0e565ff79b25,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-2f953a80-1dcc-4198-97b3-2f8ae6d218ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-a09ab9db-c78a-4922-a26e-ac354b5c9c89,DISK], DatanodeInfoWithStorage[127.0.0.1:38542,DS-2f9e5b63-2f38-481f-91a7-8576b1c93dad,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-2d1d5357-6d67-429c-aa01-4dc7b663b638,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-f299b36b-c589-4378-a7a5-226bd1672313,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-22422ba9-19a5-40a4-978f-6bb280a88a41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-76801585-172.17.0.14-1595510192637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32788,DS-d6b5de97-217f-4d5c-ad6f-fa4d09855142,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-213eed75-31c3-49af-85bc-0e565ff79b25,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-2f953a80-1dcc-4198-97b3-2f8ae6d218ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-a09ab9db-c78a-4922-a26e-ac354b5c9c89,DISK], DatanodeInfoWithStorage[127.0.0.1:38542,DS-2f9e5b63-2f38-481f-91a7-8576b1c93dad,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-2d1d5357-6d67-429c-aa01-4dc7b663b638,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-f299b36b-c589-4378-a7a5-226bd1672313,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-22422ba9-19a5-40a4-978f-6bb280a88a41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-797567737-172.17.0.14-1595510632948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33650,DS-04a8ed63-10d4-492a-99d5-310149897cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-c077e42e-3e5f-4af8-af23-a98a4699ecd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-1071d55e-3fe5-47a1-9b45-90c3b3afad63,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-eba7ebda-3f7c-4a71-ac63-c4b6a02ce09b,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-ddb001cf-ea99-497c-9cee-c93720715ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-a170cb5c-6d92-485e-99d2-dc24cd443a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-ae7880d3-1f9c-4ce9-bd8f-1a899c51f664,DISK], DatanodeInfoWithStorage[127.0.0.1:36261,DS-735d4834-24c8-436e-9d02-fe36d6e9f494,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-797567737-172.17.0.14-1595510632948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33650,DS-04a8ed63-10d4-492a-99d5-310149897cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-c077e42e-3e5f-4af8-af23-a98a4699ecd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-1071d55e-3fe5-47a1-9b45-90c3b3afad63,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-eba7ebda-3f7c-4a71-ac63-c4b6a02ce09b,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-ddb001cf-ea99-497c-9cee-c93720715ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-a170cb5c-6d92-485e-99d2-dc24cd443a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-ae7880d3-1f9c-4ce9-bd8f-1a899c51f664,DISK], DatanodeInfoWithStorage[127.0.0.1:36261,DS-735d4834-24c8-436e-9d02-fe36d6e9f494,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752372796-172.17.0.14-1595510985495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34024,DS-de666337-de2d-4e36-b8b5-ff7d89c52b89,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-5989e6cf-99f9-41fa-b0ce-d40a949e3c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-e44ef2ef-bc4b-4f47-8413-2b679de63d16,DISK], DatanodeInfoWithStorage[127.0.0.1:40370,DS-c88f5684-c0df-4504-a4ca-e2ed17730eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-f24ce4bf-27de-4078-8ba7-ec5ed6c39ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-6747cbc2-c814-47bc-b753-fae596364ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-e2592b6f-a543-4ad3-b2ac-26cc19ad4c30,DISK], DatanodeInfoWithStorage[127.0.0.1:42540,DS-d88186a8-7578-4758-821f-91bfc93e0dc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752372796-172.17.0.14-1595510985495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34024,DS-de666337-de2d-4e36-b8b5-ff7d89c52b89,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-5989e6cf-99f9-41fa-b0ce-d40a949e3c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-e44ef2ef-bc4b-4f47-8413-2b679de63d16,DISK], DatanodeInfoWithStorage[127.0.0.1:40370,DS-c88f5684-c0df-4504-a4ca-e2ed17730eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-f24ce4bf-27de-4078-8ba7-ec5ed6c39ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-6747cbc2-c814-47bc-b753-fae596364ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-e2592b6f-a543-4ad3-b2ac-26cc19ad4c30,DISK], DatanodeInfoWithStorage[127.0.0.1:42540,DS-d88186a8-7578-4758-821f-91bfc93e0dc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-712213812-172.17.0.14-1595511157903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37233,DS-426bd767-1d1e-42a8-981b-651dc9f50e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-da286ad8-3a9e-4734-bd95-7f79e6c8c51b,DISK], DatanodeInfoWithStorage[127.0.0.1:42091,DS-77f719fb-c020-4346-952b-fdeef307da0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-c4acf6dd-a14e-4d7a-bbca-9497ebfd3346,DISK], DatanodeInfoWithStorage[127.0.0.1:33595,DS-11894e96-5513-475e-826e-258ac72c0dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-66622348-ae16-4d40-8241-d6fe62f9f8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-209cae22-2267-449d-8caf-7a5fb9dbe342,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-fd1059b3-ea0b-4117-9c05-6ec57bacf0fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-712213812-172.17.0.14-1595511157903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37233,DS-426bd767-1d1e-42a8-981b-651dc9f50e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-da286ad8-3a9e-4734-bd95-7f79e6c8c51b,DISK], DatanodeInfoWithStorage[127.0.0.1:42091,DS-77f719fb-c020-4346-952b-fdeef307da0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-c4acf6dd-a14e-4d7a-bbca-9497ebfd3346,DISK], DatanodeInfoWithStorage[127.0.0.1:33595,DS-11894e96-5513-475e-826e-258ac72c0dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-66622348-ae16-4d40-8241-d6fe62f9f8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-209cae22-2267-449d-8caf-7a5fb9dbe342,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-fd1059b3-ea0b-4117-9c05-6ec57bacf0fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-676660755-172.17.0.14-1595511578156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40257,DS-e1f2d84e-f748-429e-9c24-3c56928c9ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-2a19ba61-7d95-4fbe-9682-eb79b0a46b20,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-e3555aab-5c2c-40ca-a7af-dcebb6c7d1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-b7196e54-97ee-4847-a7a0-5e30818dd28c,DISK], DatanodeInfoWithStorage[127.0.0.1:45146,DS-a3a6d6df-d3c2-4eb3-a9d2-c6ec59315464,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-a7653a87-abb4-4c4c-9c41-69bdf5c41c14,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-1ffb3cf7-2beb-46db-974b-5c203406d598,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-28e7df8a-5dc9-4447-a6b8-b014e307e41f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-676660755-172.17.0.14-1595511578156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40257,DS-e1f2d84e-f748-429e-9c24-3c56928c9ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-2a19ba61-7d95-4fbe-9682-eb79b0a46b20,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-e3555aab-5c2c-40ca-a7af-dcebb6c7d1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-b7196e54-97ee-4847-a7a0-5e30818dd28c,DISK], DatanodeInfoWithStorage[127.0.0.1:45146,DS-a3a6d6df-d3c2-4eb3-a9d2-c6ec59315464,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-a7653a87-abb4-4c4c-9c41-69bdf5c41c14,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-1ffb3cf7-2beb-46db-974b-5c203406d598,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-28e7df8a-5dc9-4447-a6b8-b014e307e41f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1047234582-172.17.0.14-1595511984880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46684,DS-2f89f134-a453-415c-a942-69a2678761fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38901,DS-61e388fe-6b90-4f48-8fef-bc362e26186c,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-601fe5c6-d162-4af8-af68-e35a7b1a5360,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-eaabb9ec-da46-4cb1-b45c-155c735e81c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-e69b9c81-16c0-4995-89ee-53dd3908a229,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-8b8ffc42-d958-4451-8a92-b149275b6bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-446fad48-25af-4f21-b0b9-d40bf837ec2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-50f65123-c6a9-4243-9598-b4f0070c19a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1047234582-172.17.0.14-1595511984880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46684,DS-2f89f134-a453-415c-a942-69a2678761fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38901,DS-61e388fe-6b90-4f48-8fef-bc362e26186c,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-601fe5c6-d162-4af8-af68-e35a7b1a5360,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-eaabb9ec-da46-4cb1-b45c-155c735e81c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-e69b9c81-16c0-4995-89ee-53dd3908a229,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-8b8ffc42-d958-4451-8a92-b149275b6bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-446fad48-25af-4f21-b0b9-d40bf837ec2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-50f65123-c6a9-4243-9598-b4f0070c19a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1137589617-172.17.0.14-1595512025699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37605,DS-54b52c2d-188a-42ab-ac74-29e21fc40575,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-b99c15cc-ca62-4c0d-bd52-2b925e6eb56e,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-2017aabf-a976-4172-863d-3f440a993631,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-5b6e2c2c-ade8-4786-b2a0-b332cbc7b5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-b4162b3e-f1fb-4483-a8ca-0726663445eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-e4574aec-c4a1-438f-833d-5e23ade948d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-e4fb56c2-c476-4ea9-b8af-d50145b726fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-f00e71cb-0e3d-4a72-9a12-bf8a3d85a7dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1137589617-172.17.0.14-1595512025699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37605,DS-54b52c2d-188a-42ab-ac74-29e21fc40575,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-b99c15cc-ca62-4c0d-bd52-2b925e6eb56e,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-2017aabf-a976-4172-863d-3f440a993631,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-5b6e2c2c-ade8-4786-b2a0-b332cbc7b5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-b4162b3e-f1fb-4483-a8ca-0726663445eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-e4574aec-c4a1-438f-833d-5e23ade948d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-e4fb56c2-c476-4ea9-b8af-d50145b726fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-f00e71cb-0e3d-4a72-9a12-bf8a3d85a7dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5353
