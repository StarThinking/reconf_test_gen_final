reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-771070728-172.17.0.4-1595929900677:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41537,DS-9ec5a58c-0201-4d3e-be9c-11e3ba8b8620,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-e8c7f448-36e4-4129-b5a0-a2edb224f6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-c6e9215b-8267-4d92-aba6-d9eb7ac862d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-a302b617-9098-4442-a5ad-86df1a192eee,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-63093f0a-8f59-4019-a154-697d8336a5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-88de6946-005e-48d5-8316-3fba36715f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33699,DS-6c888917-8cc4-40da-b51d-35d95dbd5395,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-ba16cf0e-8c8e-4a8e-b69d-331455932a14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-771070728-172.17.0.4-1595929900677:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41537,DS-9ec5a58c-0201-4d3e-be9c-11e3ba8b8620,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-e8c7f448-36e4-4129-b5a0-a2edb224f6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-c6e9215b-8267-4d92-aba6-d9eb7ac862d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-a302b617-9098-4442-a5ad-86df1a192eee,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-63093f0a-8f59-4019-a154-697d8336a5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-88de6946-005e-48d5-8316-3fba36715f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33699,DS-6c888917-8cc4-40da-b51d-35d95dbd5395,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-ba16cf0e-8c8e-4a8e-b69d-331455932a14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-793118715-172.17.0.4-1595930519035:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45281,DS-7d092336-2da7-4342-bc95-8a099de046b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39053,DS-e949050c-8304-4e61-b509-304ec207f6df,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-88ff4913-d510-4e13-b85e-78d3827aa73d,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-650a7e86-cf4d-40d5-ba13-bc746553ab3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-9718a67e-d511-4c7c-afd7-34171d0018f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-fbfe83df-bcaf-443c-b0e7-a56ff473031b,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-189c3bf6-d080-42c0-8bd2-d19695faadb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33374,DS-32d67bb8-e9cc-4ad5-a5a4-63ececf85856,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-793118715-172.17.0.4-1595930519035:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45281,DS-7d092336-2da7-4342-bc95-8a099de046b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39053,DS-e949050c-8304-4e61-b509-304ec207f6df,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-88ff4913-d510-4e13-b85e-78d3827aa73d,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-650a7e86-cf4d-40d5-ba13-bc746553ab3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-9718a67e-d511-4c7c-afd7-34171d0018f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-fbfe83df-bcaf-443c-b0e7-a56ff473031b,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-189c3bf6-d080-42c0-8bd2-d19695faadb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33374,DS-32d67bb8-e9cc-4ad5-a5a4-63ececf85856,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-706676370-172.17.0.4-1595931261943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46560,DS-c775eacf-31a8-4942-9c84-317bf5940c59,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-adc40ee3-227d-4783-9e73-8576e08a77ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-31d61bf0-61c2-4779-ae5a-02c78058d644,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-e52317da-c604-43ee-8c35-0461d5680cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-d5cf255b-6d2c-49da-90c8-ce6c9f1df6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-b428580a-1ab0-4a83-aae0-6e67a1a71788,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-b3106388-9cee-4036-81b9-2c655a0d4f31,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-a2555ca9-5284-44a9-a493-01b9387281fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-706676370-172.17.0.4-1595931261943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46560,DS-c775eacf-31a8-4942-9c84-317bf5940c59,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-adc40ee3-227d-4783-9e73-8576e08a77ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-31d61bf0-61c2-4779-ae5a-02c78058d644,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-e52317da-c604-43ee-8c35-0461d5680cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-d5cf255b-6d2c-49da-90c8-ce6c9f1df6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-b428580a-1ab0-4a83-aae0-6e67a1a71788,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-b3106388-9cee-4036-81b9-2c655a0d4f31,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-a2555ca9-5284-44a9-a493-01b9387281fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-307356419-172.17.0.4-1595931543879:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45890,DS-140e875b-c9ff-4803-81a5-34b1633efb81,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-59d8a7b9-01ac-4c51-bc23-d76f0db9bd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-b01af059-13b3-4e12-ab92-7cb1bc2e2f51,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-bdfcfec7-b9c9-4559-917f-c9ae398c46cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-4139725e-d483-49a1-bb03-a981d161644e,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-9ae9ef4d-ffe7-4d76-b5fa-1050690c8244,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-ea461cc4-4803-40f5-aaff-685d4eeeeade,DISK], DatanodeInfoWithStorage[127.0.0.1:36187,DS-f5c048cb-6b69-4dcd-afea-f06c09ddf8bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-307356419-172.17.0.4-1595931543879:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45890,DS-140e875b-c9ff-4803-81a5-34b1633efb81,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-59d8a7b9-01ac-4c51-bc23-d76f0db9bd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-b01af059-13b3-4e12-ab92-7cb1bc2e2f51,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-bdfcfec7-b9c9-4559-917f-c9ae398c46cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-4139725e-d483-49a1-bb03-a981d161644e,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-9ae9ef4d-ffe7-4d76-b5fa-1050690c8244,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-ea461cc4-4803-40f5-aaff-685d4eeeeade,DISK], DatanodeInfoWithStorage[127.0.0.1:36187,DS-f5c048cb-6b69-4dcd-afea-f06c09ddf8bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1489165985-172.17.0.4-1595931644739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38142,DS-987b7417-c08a-45e5-9b70-cc800bfb85c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-18405cdf-cacf-47c8-833c-a7161e802a09,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-10a7172a-2178-499c-af0e-08a38a8481e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-f9d81406-be17-404f-9c72-5c05c719078a,DISK], DatanodeInfoWithStorage[127.0.0.1:35997,DS-7a6e7c35-1e74-4a06-993f-b17fd7022e01,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-1dc7a0ba-325f-49eb-b348-6be428ac786c,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-d0f89633-90aa-40d5-99d6-065083404686,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-87243344-2780-4a1a-aa74-4c9f16a2edf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1489165985-172.17.0.4-1595931644739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38142,DS-987b7417-c08a-45e5-9b70-cc800bfb85c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-18405cdf-cacf-47c8-833c-a7161e802a09,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-10a7172a-2178-499c-af0e-08a38a8481e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-f9d81406-be17-404f-9c72-5c05c719078a,DISK], DatanodeInfoWithStorage[127.0.0.1:35997,DS-7a6e7c35-1e74-4a06-993f-b17fd7022e01,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-1dc7a0ba-325f-49eb-b348-6be428ac786c,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-d0f89633-90aa-40d5-99d6-065083404686,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-87243344-2780-4a1a-aa74-4c9f16a2edf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-975468444-172.17.0.4-1595932580298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40674,DS-9edbe3ab-fbca-4f6d-ac87-807cb068d85b,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-096a8924-522a-4883-84c5-799871630f36,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-aa8ec65a-548a-4fbe-89a0-0c9469c298e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-4a205382-d87e-42ed-af9f-c1c394c42991,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-3ada0693-d571-4702-a2d3-86f154fbfa7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-f216320d-7753-4a32-a795-193af8589edd,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-7ffbb4d5-27b4-49fd-8e1f-a87b6ecaab97,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-e21a3314-9125-4f50-9c61-9311b8db0485,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-975468444-172.17.0.4-1595932580298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40674,DS-9edbe3ab-fbca-4f6d-ac87-807cb068d85b,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-096a8924-522a-4883-84c5-799871630f36,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-aa8ec65a-548a-4fbe-89a0-0c9469c298e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-4a205382-d87e-42ed-af9f-c1c394c42991,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-3ada0693-d571-4702-a2d3-86f154fbfa7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-f216320d-7753-4a32-a795-193af8589edd,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-7ffbb4d5-27b4-49fd-8e1f-a87b6ecaab97,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-e21a3314-9125-4f50-9c61-9311b8db0485,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-106489866-172.17.0.4-1595934006247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36782,DS-94e0b5c0-fe65-4d30-9c04-d9efc791e23c,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-228841f5-f203-4850-b1c5-ff147d7b89cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-1611c8ab-fc11-4b2f-875c-ec1c511d98df,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-cd03fa22-1481-44aa-ac63-317ee4353d02,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-be5a0267-c365-4fa3-b68b-7d6f591a8269,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-08453b51-5b5f-4701-b024-4eef4c21054e,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-796527c6-3f7f-4ae6-8eff-f5a78ad07977,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-fc2bb5cc-9478-4c80-9a8b-4cce38fd9c0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-106489866-172.17.0.4-1595934006247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36782,DS-94e0b5c0-fe65-4d30-9c04-d9efc791e23c,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-228841f5-f203-4850-b1c5-ff147d7b89cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-1611c8ab-fc11-4b2f-875c-ec1c511d98df,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-cd03fa22-1481-44aa-ac63-317ee4353d02,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-be5a0267-c365-4fa3-b68b-7d6f591a8269,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-08453b51-5b5f-4701-b024-4eef4c21054e,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-796527c6-3f7f-4ae6-8eff-f5a78ad07977,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-fc2bb5cc-9478-4c80-9a8b-4cce38fd9c0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1809052123-172.17.0.4-1595934725358:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35149,DS-298e3a21-7064-4500-a1a5-764ef4efba07,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-925d0a61-37ba-4c53-9d44-d7e20aa250dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45754,DS-71828200-d48e-442f-861c-2c5c842ccb59,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-38740a4b-36fd-4afa-b8b1-d81f983c6e10,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-7edacc12-3af8-4a70-8611-fbeb46397293,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-a35d9455-e809-4c00-9999-a4301aaa4e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-75810547-226b-41bd-ba72-bcaacf36d254,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-781d09ca-6d98-44df-bac8-44d918f2d315,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1809052123-172.17.0.4-1595934725358:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35149,DS-298e3a21-7064-4500-a1a5-764ef4efba07,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-925d0a61-37ba-4c53-9d44-d7e20aa250dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45754,DS-71828200-d48e-442f-861c-2c5c842ccb59,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-38740a4b-36fd-4afa-b8b1-d81f983c6e10,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-7edacc12-3af8-4a70-8611-fbeb46397293,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-a35d9455-e809-4c00-9999-a4301aaa4e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-75810547-226b-41bd-ba72-bcaacf36d254,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-781d09ca-6d98-44df-bac8-44d918f2d315,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1700234675-172.17.0.4-1595934825403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45862,DS-0ce6471c-c756-4031-a227-152618959852,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-ef055fcf-cc17-4c14-94a3-e560b87299d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-5f790447-a0f2-40ce-a7c5-402a2f9b6ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-c89e13dc-6137-4853-99e9-32181c880c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-44c8cfee-6632-4cf1-8653-84e7da099ded,DISK], DatanodeInfoWithStorage[127.0.0.1:44201,DS-18fae037-4a77-40b9-a0ae-db8165a18ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-987662cb-2587-4a9d-a425-f60ca48533a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-78f4b259-2cb8-4ec6-888e-fc170d502917,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1700234675-172.17.0.4-1595934825403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45862,DS-0ce6471c-c756-4031-a227-152618959852,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-ef055fcf-cc17-4c14-94a3-e560b87299d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-5f790447-a0f2-40ce-a7c5-402a2f9b6ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-c89e13dc-6137-4853-99e9-32181c880c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-44c8cfee-6632-4cf1-8653-84e7da099ded,DISK], DatanodeInfoWithStorage[127.0.0.1:44201,DS-18fae037-4a77-40b9-a0ae-db8165a18ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-987662cb-2587-4a9d-a425-f60ca48533a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-78f4b259-2cb8-4ec6-888e-fc170d502917,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-781380647-172.17.0.4-1595934887809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46245,DS-31895269-2481-4cc5-afa6-73f3b4268073,DISK], DatanodeInfoWithStorage[127.0.0.1:38875,DS-ffe66250-27d8-4a85-85f5-f1b2cafb2bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36235,DS-d5619060-f8b9-4368-8b66-927736060d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-a26f47eb-eb21-49de-9033-2caa09367b58,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-ae22ac12-a02f-4685-bce0-9895bbb66d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-259fffbe-11d2-402c-80f3-fd81baa7bdfb,DISK], DatanodeInfoWithStorage[127.0.0.1:35092,DS-29d76bc8-cd94-4c53-87cb-80f6b8e84d00,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-cc4b83fb-c4ef-41b2-8f78-b29d23d06822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-781380647-172.17.0.4-1595934887809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46245,DS-31895269-2481-4cc5-afa6-73f3b4268073,DISK], DatanodeInfoWithStorage[127.0.0.1:38875,DS-ffe66250-27d8-4a85-85f5-f1b2cafb2bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36235,DS-d5619060-f8b9-4368-8b66-927736060d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-a26f47eb-eb21-49de-9033-2caa09367b58,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-ae22ac12-a02f-4685-bce0-9895bbb66d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-259fffbe-11d2-402c-80f3-fd81baa7bdfb,DISK], DatanodeInfoWithStorage[127.0.0.1:35092,DS-29d76bc8-cd94-4c53-87cb-80f6b8e84d00,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-cc4b83fb-c4ef-41b2-8f78-b29d23d06822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1670113498-172.17.0.4-1595934915993:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40470,DS-7d539729-c043-4b7c-8562-0f9896f6fd00,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-fcff674f-221e-4970-a891-7198e7f46e29,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-9b6b337e-97e2-4683-8372-05c36f668592,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-0780946d-1618-444e-a19c-aa2e4d0f20d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-f3c712e3-a3c6-4c4d-99d2-b81d9059ef9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-bc82a995-7464-41ae-a4e9-61c7e9bde8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-1e0363bf-0d08-439b-9d18-25fdfccb0ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:36598,DS-b8318bcb-08b2-4df9-87a8-b1ff71518a54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1670113498-172.17.0.4-1595934915993:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40470,DS-7d539729-c043-4b7c-8562-0f9896f6fd00,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-fcff674f-221e-4970-a891-7198e7f46e29,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-9b6b337e-97e2-4683-8372-05c36f668592,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-0780946d-1618-444e-a19c-aa2e4d0f20d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-f3c712e3-a3c6-4c4d-99d2-b81d9059ef9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-bc82a995-7464-41ae-a4e9-61c7e9bde8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-1e0363bf-0d08-439b-9d18-25fdfccb0ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:36598,DS-b8318bcb-08b2-4df9-87a8-b1ff71518a54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-617867537-172.17.0.4-1595934985819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38063,DS-79d4bec0-f706-4160-af89-bf29ba8530de,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-32f5d654-d37a-4886-84a5-a2250ad02b08,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-8e0366d5-38d7-415f-8dac-ba72bfe0ed90,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-a6835b7b-3d34-40ba-bbbc-b330f104f323,DISK], DatanodeInfoWithStorage[127.0.0.1:36728,DS-8ff4073c-0d4a-4f34-b41f-57d69b72a2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-ae06b8f8-7ffd-4ace-8ffa-4fff9405e5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-6d8c03d7-fa83-476f-92c2-261572894fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-169ccf4f-bd46-49e3-a40c-1e7d1b77e7ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-617867537-172.17.0.4-1595934985819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38063,DS-79d4bec0-f706-4160-af89-bf29ba8530de,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-32f5d654-d37a-4886-84a5-a2250ad02b08,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-8e0366d5-38d7-415f-8dac-ba72bfe0ed90,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-a6835b7b-3d34-40ba-bbbc-b330f104f323,DISK], DatanodeInfoWithStorage[127.0.0.1:36728,DS-8ff4073c-0d4a-4f34-b41f-57d69b72a2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-ae06b8f8-7ffd-4ace-8ffa-4fff9405e5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-6d8c03d7-fa83-476f-92c2-261572894fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-169ccf4f-bd46-49e3-a40c-1e7d1b77e7ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-57266739-172.17.0.4-1595935181986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39048,DS-31f51536-3828-4e60-9130-0ca86e1481b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-fe50516c-dc70-499a-844c-1e7f068c42ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-7fe95122-54cc-4b5d-9554-aa2eece411f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-26dd8d30-44ad-4715-9392-fcc6ef08fdda,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-118946b7-b369-4aee-aa89-22cf9dabe67d,DISK], DatanodeInfoWithStorage[127.0.0.1:36437,DS-319a2fe2-3352-4859-8f36-46083b201562,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-4e5e87b3-070f-4820-b677-499a48574ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-09f00725-903a-41ad-9a16-3c0b7b7811d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-57266739-172.17.0.4-1595935181986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39048,DS-31f51536-3828-4e60-9130-0ca86e1481b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-fe50516c-dc70-499a-844c-1e7f068c42ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-7fe95122-54cc-4b5d-9554-aa2eece411f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-26dd8d30-44ad-4715-9392-fcc6ef08fdda,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-118946b7-b369-4aee-aa89-22cf9dabe67d,DISK], DatanodeInfoWithStorage[127.0.0.1:36437,DS-319a2fe2-3352-4859-8f36-46083b201562,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-4e5e87b3-070f-4820-b677-499a48574ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-09f00725-903a-41ad-9a16-3c0b7b7811d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5382
