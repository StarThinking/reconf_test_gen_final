reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1517423065-172.17.0.9-1596000444001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42397,DS-f7628494-81c6-43a5-8876-e1185da21e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-0b229bb7-dc49-410d-9d58-3c7bcdc3447a,DISK], DatanodeInfoWithStorage[127.0.0.1:35463,DS-2420bfe8-6bca-46ed-a85f-e749f93a3dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-835a94df-b973-4983-9cba-6aa821d8439b,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-420e9417-8478-44ef-8ec8-d18512a01adc,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-a59a4b2b-658e-415f-8eaf-5856c6db0fda,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-f76aa63c-ff75-4ce2-9ef1-3cd88c6d7f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-a28baa0d-cefd-4830-8240-dfbcb6f58eed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1517423065-172.17.0.9-1596000444001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42397,DS-f7628494-81c6-43a5-8876-e1185da21e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-0b229bb7-dc49-410d-9d58-3c7bcdc3447a,DISK], DatanodeInfoWithStorage[127.0.0.1:35463,DS-2420bfe8-6bca-46ed-a85f-e749f93a3dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-835a94df-b973-4983-9cba-6aa821d8439b,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-420e9417-8478-44ef-8ec8-d18512a01adc,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-a59a4b2b-658e-415f-8eaf-5856c6db0fda,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-f76aa63c-ff75-4ce2-9ef1-3cd88c6d7f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-a28baa0d-cefd-4830-8240-dfbcb6f58eed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-850176039-172.17.0.9-1596000584464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34372,DS-796d57f1-6945-4808-96a5-a0915c42e8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-31f4a2fb-a0a8-4add-a844-300989bafc46,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-d320b8a9-b6a1-4839-9b68-ec8ff02e7aff,DISK], DatanodeInfoWithStorage[127.0.0.1:35699,DS-21ce766b-0532-4069-a40f-951ead6f9f14,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-5075ee59-546d-4d8d-873d-167215dda0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-4607c996-4e04-4138-ad2e-91fed44a4549,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-162cda6f-ad1e-46dc-806e-c2cfbab58b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-e6ff7147-55cd-42d5-8be5-d7c1a296abb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-850176039-172.17.0.9-1596000584464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34372,DS-796d57f1-6945-4808-96a5-a0915c42e8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-31f4a2fb-a0a8-4add-a844-300989bafc46,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-d320b8a9-b6a1-4839-9b68-ec8ff02e7aff,DISK], DatanodeInfoWithStorage[127.0.0.1:35699,DS-21ce766b-0532-4069-a40f-951ead6f9f14,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-5075ee59-546d-4d8d-873d-167215dda0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-4607c996-4e04-4138-ad2e-91fed44a4549,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-162cda6f-ad1e-46dc-806e-c2cfbab58b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-e6ff7147-55cd-42d5-8be5-d7c1a296abb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1022367792-172.17.0.9-1596000781916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41724,DS-d6240fd3-87be-4b5a-8fe3-47ed7ac6d9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-efe5ee7a-bd61-4461-8b08-19687ec23597,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-1c64cec5-e1f9-41fc-a11e-89e2c5b83b61,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-4161ff5a-07a6-4fc1-9bec-d426f616c1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-b3bc1ccd-8add-4f46-ba19-bb9376be4591,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-dd8a08ad-b9cf-4030-aae4-2c7a63375359,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-9f7364f8-8069-46db-8ef3-391b3686a5df,DISK], DatanodeInfoWithStorage[127.0.0.1:39292,DS-67aa8333-131b-486b-bad3-a71a1746129c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1022367792-172.17.0.9-1596000781916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41724,DS-d6240fd3-87be-4b5a-8fe3-47ed7ac6d9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-efe5ee7a-bd61-4461-8b08-19687ec23597,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-1c64cec5-e1f9-41fc-a11e-89e2c5b83b61,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-4161ff5a-07a6-4fc1-9bec-d426f616c1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-b3bc1ccd-8add-4f46-ba19-bb9376be4591,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-dd8a08ad-b9cf-4030-aae4-2c7a63375359,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-9f7364f8-8069-46db-8ef3-391b3686a5df,DISK], DatanodeInfoWithStorage[127.0.0.1:39292,DS-67aa8333-131b-486b-bad3-a71a1746129c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-758306397-172.17.0.9-1596001105414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45987,DS-1d6b3246-c6c1-4ec7-a268-8c58249af39d,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-0f725ac6-13cf-48f5-a549-9962427efaa0,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-007613da-0dc8-47fb-ac09-29e9e25ab587,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-3fcb09b8-2c2f-45ed-bacb-e959042f7d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-dcb9dbcb-36a0-4160-81a0-b31cff049dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-abda4d69-e6fa-43da-9f82-7d0b17374eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38684,DS-eeb4ccfa-8425-4341-b893-a87c541dfbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-bf704ebf-58f0-4c90-8bcb-8fc630cf853c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-758306397-172.17.0.9-1596001105414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45987,DS-1d6b3246-c6c1-4ec7-a268-8c58249af39d,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-0f725ac6-13cf-48f5-a549-9962427efaa0,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-007613da-0dc8-47fb-ac09-29e9e25ab587,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-3fcb09b8-2c2f-45ed-bacb-e959042f7d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-dcb9dbcb-36a0-4160-81a0-b31cff049dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-abda4d69-e6fa-43da-9f82-7d0b17374eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38684,DS-eeb4ccfa-8425-4341-b893-a87c541dfbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-bf704ebf-58f0-4c90-8bcb-8fc630cf853c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1568503501-172.17.0.9-1596001146905:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43641,DS-0f5011da-5fcb-45eb-94d9-85acafb093cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-1c0b6347-92b5-49df-92da-adc67ab00dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-88ec094d-1a87-4705-88a9-ffab0c5fefa9,DISK], DatanodeInfoWithStorage[127.0.0.1:32946,DS-70deef3d-54bb-4360-9014-468f85e88f32,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-6f10cf7e-f08a-4575-928b-cc1640845e84,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-3ab0333d-5406-46c2-ac26-5992ea6e7637,DISK], DatanodeInfoWithStorage[127.0.0.1:36288,DS-4b49cb01-9e0f-4d9b-bb2d-968b1d307d47,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-57462449-7ac6-4ae9-906d-0d0036f64d59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1568503501-172.17.0.9-1596001146905:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43641,DS-0f5011da-5fcb-45eb-94d9-85acafb093cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-1c0b6347-92b5-49df-92da-adc67ab00dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-88ec094d-1a87-4705-88a9-ffab0c5fefa9,DISK], DatanodeInfoWithStorage[127.0.0.1:32946,DS-70deef3d-54bb-4360-9014-468f85e88f32,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-6f10cf7e-f08a-4575-928b-cc1640845e84,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-3ab0333d-5406-46c2-ac26-5992ea6e7637,DISK], DatanodeInfoWithStorage[127.0.0.1:36288,DS-4b49cb01-9e0f-4d9b-bb2d-968b1d307d47,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-57462449-7ac6-4ae9-906d-0d0036f64d59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-443699122-172.17.0.9-1596001219995:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34034,DS-c016f739-47ef-4551-844f-9e57b39abeef,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-16406e6c-53fd-4cfa-8ac4-eea8cd3add60,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-f110bd79-43d6-485a-8ec6-bf85d6b4c8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-af916169-fb20-44e8-b4fe-cbc588562f41,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-12e23f0f-e38c-409d-bf2f-044cbfe06635,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-600b153c-1ad2-479b-9aa4-126faab38c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-8ded77ef-84c7-480a-b3f8-881bb293152b,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-948b054c-ed4b-4e21-b808-6c9c016eed7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-443699122-172.17.0.9-1596001219995:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34034,DS-c016f739-47ef-4551-844f-9e57b39abeef,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-16406e6c-53fd-4cfa-8ac4-eea8cd3add60,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-f110bd79-43d6-485a-8ec6-bf85d6b4c8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-af916169-fb20-44e8-b4fe-cbc588562f41,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-12e23f0f-e38c-409d-bf2f-044cbfe06635,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-600b153c-1ad2-479b-9aa4-126faab38c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-8ded77ef-84c7-480a-b3f8-881bb293152b,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-948b054c-ed4b-4e21-b808-6c9c016eed7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1225143789-172.17.0.9-1596001361894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38211,DS-7d756e47-ab32-46bd-9fec-31538b4ab6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-3726a04b-4560-4b3f-be9c-52e992b77fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-536c160b-4f7d-45b3-8f35-f44e23df5536,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-7b69b929-2b91-417e-826f-76e3058d4728,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-b0764125-acbe-4078-b9e0-ef7bf5370728,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-1c268229-c954-4ec1-b126-fee541448aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-8409ffdb-7996-4760-825c-d1111bc7065f,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-898ad72e-1b68-4454-8c7b-917571753eb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1225143789-172.17.0.9-1596001361894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38211,DS-7d756e47-ab32-46bd-9fec-31538b4ab6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-3726a04b-4560-4b3f-be9c-52e992b77fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-536c160b-4f7d-45b3-8f35-f44e23df5536,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-7b69b929-2b91-417e-826f-76e3058d4728,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-b0764125-acbe-4078-b9e0-ef7bf5370728,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-1c268229-c954-4ec1-b126-fee541448aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-8409ffdb-7996-4760-825c-d1111bc7065f,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-898ad72e-1b68-4454-8c7b-917571753eb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1423940394-172.17.0.9-1596001949038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39678,DS-c6e67aff-d5bb-43e3-b93f-fabb620da283,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-d1f1fce3-c6c9-4ea3-a9b5-b8e5b463d13d,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-fb5a25f8-e918-4cf5-8aeb-6cb4d61ca5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-750b192c-6eb4-4736-9dc9-a64c52f45469,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-0953ebff-2508-44cd-9a8a-020a51278acb,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-ff5207f4-c8c5-4dd9-899f-c95d1ac06202,DISK], DatanodeInfoWithStorage[127.0.0.1:36389,DS-2060814e-b0bf-490a-a81b-8fc4397697e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-af3058ff-81f4-432e-b537-e3d5ac5b6ee1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1423940394-172.17.0.9-1596001949038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39678,DS-c6e67aff-d5bb-43e3-b93f-fabb620da283,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-d1f1fce3-c6c9-4ea3-a9b5-b8e5b463d13d,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-fb5a25f8-e918-4cf5-8aeb-6cb4d61ca5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-750b192c-6eb4-4736-9dc9-a64c52f45469,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-0953ebff-2508-44cd-9a8a-020a51278acb,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-ff5207f4-c8c5-4dd9-899f-c95d1ac06202,DISK], DatanodeInfoWithStorage[127.0.0.1:36389,DS-2060814e-b0bf-490a-a81b-8fc4397697e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-af3058ff-81f4-432e-b537-e3d5ac5b6ee1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1011380057-172.17.0.9-1596002611768:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45220,DS-269154cf-635f-413b-96b1-73a0aba891c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-9fb2d442-d07b-47ec-a786-0c24298fee35,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-bc80d987-5852-45bd-abec-7089b284ac5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-43fd450b-3a6d-4c16-95aa-798785109290,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-dbaf957b-36f1-4b0b-9441-8e1b8bff0847,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-9476bbb5-90b7-45f6-8089-e9c6fb532e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-ce600cab-55f4-4dda-94d1-2918b33825ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36791,DS-f33c43d0-efee-468d-8fec-3914dbcca941,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1011380057-172.17.0.9-1596002611768:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45220,DS-269154cf-635f-413b-96b1-73a0aba891c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-9fb2d442-d07b-47ec-a786-0c24298fee35,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-bc80d987-5852-45bd-abec-7089b284ac5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-43fd450b-3a6d-4c16-95aa-798785109290,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-dbaf957b-36f1-4b0b-9441-8e1b8bff0847,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-9476bbb5-90b7-45f6-8089-e9c6fb532e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-ce600cab-55f4-4dda-94d1-2918b33825ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36791,DS-f33c43d0-efee-468d-8fec-3914dbcca941,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1572265378-172.17.0.9-1596002718654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37856,DS-183cb32c-803c-495c-9517-dafac4b7ba3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-0f882594-cda2-4425-b939-0245823781b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-5d51265c-59d1-4b8e-a226-ef547bbbef86,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-245dacb9-78b2-4583-afb6-fa39fcaa72b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-ee75b7a2-3df6-42fb-88a2-8d232b05cf92,DISK], DatanodeInfoWithStorage[127.0.0.1:39464,DS-bd40ca4d-9f8c-4e2e-864d-b8e1dbeea077,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-1ad2cdf2-5599-48ad-917e-6ec8690a65c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-9481dbd4-8e36-4fd4-89cd-b8bf363c42b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1572265378-172.17.0.9-1596002718654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37856,DS-183cb32c-803c-495c-9517-dafac4b7ba3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-0f882594-cda2-4425-b939-0245823781b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-5d51265c-59d1-4b8e-a226-ef547bbbef86,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-245dacb9-78b2-4583-afb6-fa39fcaa72b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-ee75b7a2-3df6-42fb-88a2-8d232b05cf92,DISK], DatanodeInfoWithStorage[127.0.0.1:39464,DS-bd40ca4d-9f8c-4e2e-864d-b8e1dbeea077,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-1ad2cdf2-5599-48ad-917e-6ec8690a65c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-9481dbd4-8e36-4fd4-89cd-b8bf363c42b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-724400269-172.17.0.9-1596002817617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39109,DS-9b374100-381c-4567-b33c-2b0607575aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-96b5f0f0-01c6-4af8-bf64-5ea2d0c754d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-952f1b52-2645-4463-aa59-4438d0786ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-b9da56c5-1b48-4772-af61-7a357f6ae67f,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-82d75ceb-0862-478a-92ef-f2c89aab1c58,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-a3c96e9c-9616-45fa-8db2-5b60ffc2619d,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-a4e42559-b1a9-4a2f-8e58-b53fe340c61d,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-6dad6dfa-1559-451e-9327-43b5d8db9632,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-724400269-172.17.0.9-1596002817617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39109,DS-9b374100-381c-4567-b33c-2b0607575aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-96b5f0f0-01c6-4af8-bf64-5ea2d0c754d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-952f1b52-2645-4463-aa59-4438d0786ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-b9da56c5-1b48-4772-af61-7a357f6ae67f,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-82d75ceb-0862-478a-92ef-f2c89aab1c58,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-a3c96e9c-9616-45fa-8db2-5b60ffc2619d,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-a4e42559-b1a9-4a2f-8e58-b53fe340c61d,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-6dad6dfa-1559-451e-9327-43b5d8db9632,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1678495683-172.17.0.9-1596003873410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46637,DS-4e6b4022-0e9c-4c49-b600-fdf9dd6870cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-0e5269b1-ed16-4620-a860-d0c63a3e660b,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-c4928bd1-da32-4206-a2bf-08e2c233324e,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-d372491b-3401-40b9-88d9-9271d538c213,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-3e4c2f82-4c94-4f15-baea-e6d096a0008e,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-1a08bd6a-ebaf-49a1-af65-7c1507338bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-c0f04e33-065b-47c2-80e1-7ff7cfce18f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46701,DS-65e5308a-637e-4871-8afc-d8ab3f8d362e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1678495683-172.17.0.9-1596003873410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46637,DS-4e6b4022-0e9c-4c49-b600-fdf9dd6870cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-0e5269b1-ed16-4620-a860-d0c63a3e660b,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-c4928bd1-da32-4206-a2bf-08e2c233324e,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-d372491b-3401-40b9-88d9-9271d538c213,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-3e4c2f82-4c94-4f15-baea-e6d096a0008e,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-1a08bd6a-ebaf-49a1-af65-7c1507338bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-c0f04e33-065b-47c2-80e1-7ff7cfce18f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46701,DS-65e5308a-637e-4871-8afc-d8ab3f8d362e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-747675618-172.17.0.9-1596004866768:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45961,DS-525720e2-30fa-44e1-b509-91baeb9e6543,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-69ee59e2-28fb-45b3-b71b-05be27136af0,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-0ffe2d8b-fcd3-4a50-8e87-6a5ea2cdceef,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-0a4be9bf-1f39-4374-a570-9f608b8c10ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-5e5c5a3f-5102-46b1-9587-6cf5218628b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-bf76efe8-27e3-4c0d-9109-e766053bfa04,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-979c76d3-1c59-4533-9d3b-e2028aa8626a,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-b5654277-725b-4565-8eb5-dcb0bdcf697b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-747675618-172.17.0.9-1596004866768:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45961,DS-525720e2-30fa-44e1-b509-91baeb9e6543,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-69ee59e2-28fb-45b3-b71b-05be27136af0,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-0ffe2d8b-fcd3-4a50-8e87-6a5ea2cdceef,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-0a4be9bf-1f39-4374-a570-9f608b8c10ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-5e5c5a3f-5102-46b1-9587-6cf5218628b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-bf76efe8-27e3-4c0d-9109-e766053bfa04,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-979c76d3-1c59-4533-9d3b-e2028aa8626a,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-b5654277-725b-4565-8eb5-dcb0bdcf697b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-751434919-172.17.0.9-1596005037283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36559,DS-3c4affa7-0322-4119-9511-e15fb029fcb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-91479015-1b8f-4202-8854-309622234d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-cea5d277-d512-4eee-81ca-a831b3a7b9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-11b1a2d0-0d8f-48d5-8b69-8f1f540ff71b,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-052ad016-812f-4e0e-a9d5-f3a541c6dad7,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-8b1aa5f4-a0c8-4c5e-9ec7-9feb9a7f700e,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-171abe3e-14d5-4b87-854d-8906d36d97f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-441b41c8-b6bf-4d92-a31f-a2fd013570c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-751434919-172.17.0.9-1596005037283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36559,DS-3c4affa7-0322-4119-9511-e15fb029fcb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-91479015-1b8f-4202-8854-309622234d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-cea5d277-d512-4eee-81ca-a831b3a7b9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-11b1a2d0-0d8f-48d5-8b69-8f1f540ff71b,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-052ad016-812f-4e0e-a9d5-f3a541c6dad7,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-8b1aa5f4-a0c8-4c5e-9ec7-9feb9a7f700e,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-171abe3e-14d5-4b87-854d-8906d36d97f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-441b41c8-b6bf-4d92-a31f-a2fd013570c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1803142482-172.17.0.9-1596005259760:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40269,DS-bb5aee5b-8a47-43c4-ac8d-20e5cccc5ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-d7254478-85b5-4daf-a77d-1b61e6ef36d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-029c5212-5109-47ba-80c2-a599c1307d64,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-ec03d083-d7e3-4847-a1d1-b5524c4e8928,DISK], DatanodeInfoWithStorage[127.0.0.1:34385,DS-820b0374-717a-4612-985c-e677cb21a1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-916e75e8-f88d-4c41-80ef-49212d72f957,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-45e4cbf3-1c42-4dca-a92e-e6eef55d6e95,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-d242037c-cb03-4e61-aaee-bf198319f1e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1803142482-172.17.0.9-1596005259760:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40269,DS-bb5aee5b-8a47-43c4-ac8d-20e5cccc5ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-d7254478-85b5-4daf-a77d-1b61e6ef36d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-029c5212-5109-47ba-80c2-a599c1307d64,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-ec03d083-d7e3-4847-a1d1-b5524c4e8928,DISK], DatanodeInfoWithStorage[127.0.0.1:34385,DS-820b0374-717a-4612-985c-e677cb21a1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-916e75e8-f88d-4c41-80ef-49212d72f957,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-45e4cbf3-1c42-4dca-a92e-e6eef55d6e95,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-d242037c-cb03-4e61-aaee-bf198319f1e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-733187221-172.17.0.9-1596005411051:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35180,DS-3b43e93f-0703-491e-88b0-8c1b697a20a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-76da908c-c3c0-4d0e-8106-c6c69cdbded9,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-630c562f-ffa5-4069-9615-8cdad7db275e,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-ea18cfe2-ccba-4c48-ae31-458eaa17db39,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-c41f1c06-50c6-4c2c-9f1a-8c9ef0f8d1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-718f1470-bb5b-4606-a0df-8e47b88746e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-f9539b77-3c6e-4572-b995-3853fbcab859,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-b6ebf689-b274-4ee0-8d0d-33bfeda97e10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-733187221-172.17.0.9-1596005411051:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35180,DS-3b43e93f-0703-491e-88b0-8c1b697a20a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-76da908c-c3c0-4d0e-8106-c6c69cdbded9,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-630c562f-ffa5-4069-9615-8cdad7db275e,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-ea18cfe2-ccba-4c48-ae31-458eaa17db39,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-c41f1c06-50c6-4c2c-9f1a-8c9ef0f8d1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-718f1470-bb5b-4606-a0df-8e47b88746e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-f9539b77-3c6e-4572-b995-3853fbcab859,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-b6ebf689-b274-4ee0-8d0d-33bfeda97e10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5383
