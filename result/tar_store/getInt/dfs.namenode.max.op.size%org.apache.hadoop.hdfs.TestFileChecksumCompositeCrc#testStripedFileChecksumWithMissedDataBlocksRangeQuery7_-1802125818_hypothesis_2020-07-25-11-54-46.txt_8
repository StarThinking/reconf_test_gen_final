reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1629617569-172.17.0.8-1595678107116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34879,DS-d329c75f-e407-4029-885c-5f1aa2418a56,DISK], DatanodeInfoWithStorage[127.0.0.1:34974,DS-6b625337-a382-457d-a9a5-070545fcca90,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-0cdeae22-b7e9-4c24-a6eb-18a77f3c07bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-400997ec-fe9d-4aa9-8c45-a27381627173,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-32975a05-1f35-4b51-8632-168f4cdad7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45798,DS-dd51d8bd-05b5-4855-ae33-79cf8cbfde0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-24ed51f8-6ce5-4f4b-84d2-29641e472cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-b22e4229-b075-4f7f-b849-6076797a29f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1629617569-172.17.0.8-1595678107116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34879,DS-d329c75f-e407-4029-885c-5f1aa2418a56,DISK], DatanodeInfoWithStorage[127.0.0.1:34974,DS-6b625337-a382-457d-a9a5-070545fcca90,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-0cdeae22-b7e9-4c24-a6eb-18a77f3c07bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-400997ec-fe9d-4aa9-8c45-a27381627173,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-32975a05-1f35-4b51-8632-168f4cdad7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45798,DS-dd51d8bd-05b5-4855-ae33-79cf8cbfde0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-24ed51f8-6ce5-4f4b-84d2-29641e472cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-b22e4229-b075-4f7f-b849-6076797a29f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-450442700-172.17.0.8-1595678392451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44266,DS-598a8f23-b6f0-4b73-bcb7-62e67dfb3f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-9a34ba38-6a8a-44da-b355-5c297fd1975b,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-03338d44-13c2-4b8e-a2dc-02a2233285c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-ef0f344e-f7fe-48c7-bfb1-a7f313abcf50,DISK], DatanodeInfoWithStorage[127.0.0.1:40355,DS-32087449-fcd2-45e8-8e08-6a1393c6e08f,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-d232879a-2fd1-426f-b6e9-9079547bb6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46560,DS-5257c3c2-7477-4ea4-b05b-fa40b0fa19be,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-f188a7c2-baf2-403e-8e2c-c56a1633d222,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-450442700-172.17.0.8-1595678392451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44266,DS-598a8f23-b6f0-4b73-bcb7-62e67dfb3f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-9a34ba38-6a8a-44da-b355-5c297fd1975b,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-03338d44-13c2-4b8e-a2dc-02a2233285c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-ef0f344e-f7fe-48c7-bfb1-a7f313abcf50,DISK], DatanodeInfoWithStorage[127.0.0.1:40355,DS-32087449-fcd2-45e8-8e08-6a1393c6e08f,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-d232879a-2fd1-426f-b6e9-9079547bb6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46560,DS-5257c3c2-7477-4ea4-b05b-fa40b0fa19be,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-f188a7c2-baf2-403e-8e2c-c56a1633d222,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1099283509-172.17.0.8-1595678526982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41147,DS-4d7581bc-df09-4f1c-8de7-2903a35d9621,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-8d2f0736-b269-4a66-a3c0-d34f1008b76d,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-8cae3709-bc1e-4d71-8604-f989684ca785,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-6a58db9e-29f2-4eff-9903-23772d2aefbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38862,DS-897f8aca-8712-42db-af5e-ae2ae3260db7,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-067673e8-7c05-4452-84df-3e22ef88bb43,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-2ec18848-ac89-4d40-9427-9e24e4df8032,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-c1fa4188-066c-43f1-9e41-8b3e72fb9e18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1099283509-172.17.0.8-1595678526982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41147,DS-4d7581bc-df09-4f1c-8de7-2903a35d9621,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-8d2f0736-b269-4a66-a3c0-d34f1008b76d,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-8cae3709-bc1e-4d71-8604-f989684ca785,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-6a58db9e-29f2-4eff-9903-23772d2aefbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38862,DS-897f8aca-8712-42db-af5e-ae2ae3260db7,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-067673e8-7c05-4452-84df-3e22ef88bb43,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-2ec18848-ac89-4d40-9427-9e24e4df8032,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-c1fa4188-066c-43f1-9e41-8b3e72fb9e18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-649677150-172.17.0.8-1595678588636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44884,DS-50532611-e2f0-4148-b908-0e085590ad2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-3aa52d1f-54c2-4e85-af4f-ccf3e35590d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38824,DS-f87db95f-0043-48c3-81a6-60466781ff5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38266,DS-1620afcb-5d7a-4ada-a91d-8907ce281b49,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-ca546dcb-8cc2-45c3-8831-39b53124f957,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-fe334d66-05b2-477e-8d7b-5ac2732c5d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-d11ee6ca-1428-4e32-8405-27a4abc6578e,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-f574cff1-1f98-42c8-94c4-2d7637d4c7e1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-649677150-172.17.0.8-1595678588636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44884,DS-50532611-e2f0-4148-b908-0e085590ad2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-3aa52d1f-54c2-4e85-af4f-ccf3e35590d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38824,DS-f87db95f-0043-48c3-81a6-60466781ff5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38266,DS-1620afcb-5d7a-4ada-a91d-8907ce281b49,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-ca546dcb-8cc2-45c3-8831-39b53124f957,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-fe334d66-05b2-477e-8d7b-5ac2732c5d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-d11ee6ca-1428-4e32-8405-27a4abc6578e,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-f574cff1-1f98-42c8-94c4-2d7637d4c7e1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2094512450-172.17.0.8-1595678711150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39219,DS-63b1be57-c7e6-4d18-b898-53de2091bc84,DISK], DatanodeInfoWithStorage[127.0.0.1:43930,DS-4ad7a92e-a75b-48a8-b680-4e0f7fec64e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-85b4a419-3c19-4e1e-b354-a4174f621af1,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-9d50a745-a8af-4bcb-a87b-23d05267934a,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-011cc958-53fd-4fb3-b9e4-83aa78bebb8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-226f8fce-8b5f-4ec1-850e-607b8b2acc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-527f0647-daed-46d7-a1bd-0fbcfc0967de,DISK], DatanodeInfoWithStorage[127.0.0.1:32900,DS-707fbad3-15b4-459a-9b1c-27b9b0d73f13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2094512450-172.17.0.8-1595678711150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39219,DS-63b1be57-c7e6-4d18-b898-53de2091bc84,DISK], DatanodeInfoWithStorage[127.0.0.1:43930,DS-4ad7a92e-a75b-48a8-b680-4e0f7fec64e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-85b4a419-3c19-4e1e-b354-a4174f621af1,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-9d50a745-a8af-4bcb-a87b-23d05267934a,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-011cc958-53fd-4fb3-b9e4-83aa78bebb8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-226f8fce-8b5f-4ec1-850e-607b8b2acc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-527f0647-daed-46d7-a1bd-0fbcfc0967de,DISK], DatanodeInfoWithStorage[127.0.0.1:32900,DS-707fbad3-15b4-459a-9b1c-27b9b0d73f13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1080788229-172.17.0.8-1595679075459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46849,DS-0da5e80f-c18c-46ec-b308-906ac62fca9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-fe1b9819-4995-4476-9358-354490b1cdf2,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-9995d89c-09b0-4151-aad1-79a3dbe285b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38782,DS-d82a8472-9e37-46da-9917-e628dfa4e4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-088dc385-8b76-4cc0-8004-0abea7acdc88,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-3d504a1c-e149-4190-942b-cc3897fcb356,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-f6a920f5-6af2-4825-981e-0f862a735a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-51754686-fd7d-49c5-9a1c-49cb312eca02,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1080788229-172.17.0.8-1595679075459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46849,DS-0da5e80f-c18c-46ec-b308-906ac62fca9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-fe1b9819-4995-4476-9358-354490b1cdf2,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-9995d89c-09b0-4151-aad1-79a3dbe285b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38782,DS-d82a8472-9e37-46da-9917-e628dfa4e4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-088dc385-8b76-4cc0-8004-0abea7acdc88,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-3d504a1c-e149-4190-942b-cc3897fcb356,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-f6a920f5-6af2-4825-981e-0f862a735a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-51754686-fd7d-49c5-9a1c-49cb312eca02,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-630110807-172.17.0.8-1595679130791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34224,DS-604f5f7a-68d3-4bf3-97fd-d5b19d8e808c,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-9995dc40-ed61-4065-a220-e458c73fe71e,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-fe2b5d3d-2479-4160-9f4a-3adbed12c229,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-3ada0532-447d-4221-a1a0-9fea92fcf29f,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-fbc7f2bd-394d-4919-8f78-8fb488467a70,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-9b4dc0a4-6293-4982-9dc8-6ca4ce40cb82,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-b5fc0e91-c060-4214-b4b3-1687710227e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-b71dc289-308d-427c-8cb0-b48245fa20fe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-630110807-172.17.0.8-1595679130791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34224,DS-604f5f7a-68d3-4bf3-97fd-d5b19d8e808c,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-9995dc40-ed61-4065-a220-e458c73fe71e,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-fe2b5d3d-2479-4160-9f4a-3adbed12c229,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-3ada0532-447d-4221-a1a0-9fea92fcf29f,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-fbc7f2bd-394d-4919-8f78-8fb488467a70,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-9b4dc0a4-6293-4982-9dc8-6ca4ce40cb82,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-b5fc0e91-c060-4214-b4b3-1687710227e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-b71dc289-308d-427c-8cb0-b48245fa20fe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-209498912-172.17.0.8-1595679175341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44403,DS-4b18dde5-9074-448d-89eb-aa6c33414087,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-48d914d1-2255-4628-b3e3-192ea45e6ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-5ae9ed2d-482c-4e65-8b20-8a45ff4cb390,DISK], DatanodeInfoWithStorage[127.0.0.1:33738,DS-6fbe298d-d85c-4d2e-a74b-215c9861daef,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-5d7e52e9-f762-4674-a9d1-974dc6ac926e,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-164d12d1-2783-4ca4-b562-8e3783e88864,DISK], DatanodeInfoWithStorage[127.0.0.1:36996,DS-c610ba3c-1dbd-47b5-a948-3e9e7ea7e8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-eb5ede8d-3740-47fb-bce8-ede54b3e4c02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-209498912-172.17.0.8-1595679175341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44403,DS-4b18dde5-9074-448d-89eb-aa6c33414087,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-48d914d1-2255-4628-b3e3-192ea45e6ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-5ae9ed2d-482c-4e65-8b20-8a45ff4cb390,DISK], DatanodeInfoWithStorage[127.0.0.1:33738,DS-6fbe298d-d85c-4d2e-a74b-215c9861daef,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-5d7e52e9-f762-4674-a9d1-974dc6ac926e,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-164d12d1-2783-4ca4-b562-8e3783e88864,DISK], DatanodeInfoWithStorage[127.0.0.1:36996,DS-c610ba3c-1dbd-47b5-a948-3e9e7ea7e8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-eb5ede8d-3740-47fb-bce8-ede54b3e4c02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-473148349-172.17.0.8-1595679224787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34372,DS-d7b6c061-c3d2-40db-ba88-9c45b05fdaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-e4ba08a8-7a86-470e-abb3-b6097f9262d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39663,DS-6b9c395a-51be-4aa3-8dcc-4bbd9fcff0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-eb1e6e43-7832-4d2e-b15e-9ccf3fd69b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43390,DS-d57398a1-ca55-40d0-823a-0111f0c3e1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-d041e3a3-ecf7-41fc-b0da-02f20e56c218,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-76fc211c-4ac6-44b7-84ad-9dcce012a3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-e4432cd3-5922-4375-b09b-3cd03900d158,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-473148349-172.17.0.8-1595679224787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34372,DS-d7b6c061-c3d2-40db-ba88-9c45b05fdaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-e4ba08a8-7a86-470e-abb3-b6097f9262d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39663,DS-6b9c395a-51be-4aa3-8dcc-4bbd9fcff0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-eb1e6e43-7832-4d2e-b15e-9ccf3fd69b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43390,DS-d57398a1-ca55-40d0-823a-0111f0c3e1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-d041e3a3-ecf7-41fc-b0da-02f20e56c218,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-76fc211c-4ac6-44b7-84ad-9dcce012a3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-e4432cd3-5922-4375-b09b-3cd03900d158,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1608306259-172.17.0.8-1595679414524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37778,DS-c53ead78-8346-49a7-8dfe-4760dc8d714d,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-86261175-ecec-4c8d-ba56-d0c270d0ec84,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-dc09880f-6430-46ef-94e7-aaa037571e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-d2a3ad33-16d2-4313-a5b6-574353ac7816,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-f9adbefd-0e5d-4856-94f2-e2f693986a86,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-71f74d35-8dbe-4b6b-84d7-e3d34aaea1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-25d2d19f-b841-408f-af4d-54ab78770039,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-ebdda46a-20a5-4331-8646-5adbe39d9dc5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1608306259-172.17.0.8-1595679414524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37778,DS-c53ead78-8346-49a7-8dfe-4760dc8d714d,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-86261175-ecec-4c8d-ba56-d0c270d0ec84,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-dc09880f-6430-46ef-94e7-aaa037571e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-d2a3ad33-16d2-4313-a5b6-574353ac7816,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-f9adbefd-0e5d-4856-94f2-e2f693986a86,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-71f74d35-8dbe-4b6b-84d7-e3d34aaea1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-25d2d19f-b841-408f-af4d-54ab78770039,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-ebdda46a-20a5-4331-8646-5adbe39d9dc5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-983239447-172.17.0.8-1595679461033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32787,DS-8604a2a9-85d5-4c23-aa8c-598ff782bd52,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-a0349c9b-b40a-4939-acfa-f7805410b28e,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-cc28d6cc-65fb-4f79-9603-e3e8c8b30139,DISK], DatanodeInfoWithStorage[127.0.0.1:39979,DS-9a2e7a58-e7e7-4dea-8cf6-3490c8e36815,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-71232395-11db-4b73-a8a9-2b4451cb0173,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-07ae4619-f58a-465b-933d-dca05dfd1cad,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-c2df91e0-5889-41dd-894f-8a8a9c7cee92,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-0bd3fc50-4dde-4ce1-8990-8d02011f5317,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-983239447-172.17.0.8-1595679461033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32787,DS-8604a2a9-85d5-4c23-aa8c-598ff782bd52,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-a0349c9b-b40a-4939-acfa-f7805410b28e,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-cc28d6cc-65fb-4f79-9603-e3e8c8b30139,DISK], DatanodeInfoWithStorage[127.0.0.1:39979,DS-9a2e7a58-e7e7-4dea-8cf6-3490c8e36815,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-71232395-11db-4b73-a8a9-2b4451cb0173,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-07ae4619-f58a-465b-933d-dca05dfd1cad,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-c2df91e0-5889-41dd-894f-8a8a9c7cee92,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-0bd3fc50-4dde-4ce1-8990-8d02011f5317,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-769377057-172.17.0.8-1595679553346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33908,DS-93bcd315-1b28-4345-9fee-af40a7b12e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44787,DS-0800ebee-79ed-400d-ac90-845265c0d2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-34e5d371-ddb9-4efb-a027-a22372deec0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-9663a4f2-0a58-411c-857e-f1b52a2851cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-30ebd22a-bf35-4be1-b4c3-50eb981145e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-864568df-0ba4-4aca-bb3c-7013ae24865a,DISK], DatanodeInfoWithStorage[127.0.0.1:37681,DS-75c0a73a-eb3d-4f15-b7f0-69cd4c3e7484,DISK], DatanodeInfoWithStorage[127.0.0.1:45354,DS-50f6c563-4f0e-4baf-a0a8-5d13262946e0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-769377057-172.17.0.8-1595679553346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33908,DS-93bcd315-1b28-4345-9fee-af40a7b12e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44787,DS-0800ebee-79ed-400d-ac90-845265c0d2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-34e5d371-ddb9-4efb-a027-a22372deec0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-9663a4f2-0a58-411c-857e-f1b52a2851cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-30ebd22a-bf35-4be1-b4c3-50eb981145e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-864568df-0ba4-4aca-bb3c-7013ae24865a,DISK], DatanodeInfoWithStorage[127.0.0.1:37681,DS-75c0a73a-eb3d-4f15-b7f0-69cd4c3e7484,DISK], DatanodeInfoWithStorage[127.0.0.1:45354,DS-50f6c563-4f0e-4baf-a0a8-5d13262946e0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-374644819-172.17.0.8-1595679653797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39797,DS-c7183137-703c-4a17-8d65-f7fbaaac0af0,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-0b09fc84-70f5-41e7-beb2-c75444793b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-330bbd67-ffc8-458b-9d12-0b878b333cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-459597a0-6e85-41bd-827e-9e07e11fe02c,DISK], DatanodeInfoWithStorage[127.0.0.1:33455,DS-3bdb2302-89c3-4550-84b7-044e90dd846a,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-67f98346-be58-419b-8d54-38c05daceae4,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-f2a0fe77-7f42-4a79-8a38-15052517675b,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-c703f01b-a819-4c38-bbce-eb68570b4855,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-374644819-172.17.0.8-1595679653797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39797,DS-c7183137-703c-4a17-8d65-f7fbaaac0af0,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-0b09fc84-70f5-41e7-beb2-c75444793b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-330bbd67-ffc8-458b-9d12-0b878b333cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-459597a0-6e85-41bd-827e-9e07e11fe02c,DISK], DatanodeInfoWithStorage[127.0.0.1:33455,DS-3bdb2302-89c3-4550-84b7-044e90dd846a,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-67f98346-be58-419b-8d54-38c05daceae4,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-f2a0fe77-7f42-4a79-8a38-15052517675b,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-c703f01b-a819-4c38-bbce-eb68570b4855,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-188008742-172.17.0.8-1595679707728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43826,DS-3f6dfb9d-a0cf-40b3-9bbf-44da388de535,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-678e1533-07b6-4bc8-a1cd-a5cf60a6e33e,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-a7f1c9cb-7750-4e0e-9935-88fd32024775,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-8ff837f6-6370-495a-aeb9-ddf4767acaca,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-b4a5621b-8066-4afe-9d92-1e48d0fc2a00,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-423bf833-93d6-438d-9158-df4931a23a45,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-d5891a4b-ea8a-40df-98e9-c758a03dc7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-5c8e3c17-a9b3-473e-8669-e7f25fd0e2e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-188008742-172.17.0.8-1595679707728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43826,DS-3f6dfb9d-a0cf-40b3-9bbf-44da388de535,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-678e1533-07b6-4bc8-a1cd-a5cf60a6e33e,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-a7f1c9cb-7750-4e0e-9935-88fd32024775,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-8ff837f6-6370-495a-aeb9-ddf4767acaca,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-b4a5621b-8066-4afe-9d92-1e48d0fc2a00,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-423bf833-93d6-438d-9158-df4931a23a45,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-d5891a4b-ea8a-40df-98e9-c758a03dc7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-5c8e3c17-a9b3-473e-8669-e7f25fd0e2e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1016026248-172.17.0.8-1595680501167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41715,DS-e900295e-8c26-427a-8d59-239e62781bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-68f806e9-8a2e-41b8-a4b7-44c5cd4da239,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-e3a683a1-b435-4632-9789-64aee982a4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-7f7c3ced-f872-4322-a0fb-aa2e2513f2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35371,DS-0ab51d51-4ee9-490e-bdf8-115bdaf70f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-e9ae866a-f303-4881-a9fe-9a35ba1c1d07,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-8769d6a3-cf9d-46ff-97ed-65c054d396a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-48f82fc8-a998-442c-9418-084c011a394d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1016026248-172.17.0.8-1595680501167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41715,DS-e900295e-8c26-427a-8d59-239e62781bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-68f806e9-8a2e-41b8-a4b7-44c5cd4da239,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-e3a683a1-b435-4632-9789-64aee982a4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-7f7c3ced-f872-4322-a0fb-aa2e2513f2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35371,DS-0ab51d51-4ee9-490e-bdf8-115bdaf70f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-e9ae866a-f303-4881-a9fe-9a35ba1c1d07,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-8769d6a3-cf9d-46ff-97ed-65c054d396a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-48f82fc8-a998-442c-9418-084c011a394d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1669076296-172.17.0.8-1595680543098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43560,DS-5eae38e2-756d-4782-86ce-3132d48ad85d,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-7af4f25d-14ac-4e31-ad3a-905f213337c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-bcf58d90-cd9b-42ca-9879-85d48ad612fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-64cd0ca8-9411-4dda-9cf5-bda373998049,DISK], DatanodeInfoWithStorage[127.0.0.1:33838,DS-f2534df1-89ee-4c3e-809a-88354acdd47e,DISK], DatanodeInfoWithStorage[127.0.0.1:33166,DS-b8e545f1-a55f-4187-973a-fe82729646c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-4cfe3f8e-cd6b-4e21-abc3-f031dd59777c,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-b32d200c-eebf-4606-bacc-3cda2fee635d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1669076296-172.17.0.8-1595680543098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43560,DS-5eae38e2-756d-4782-86ce-3132d48ad85d,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-7af4f25d-14ac-4e31-ad3a-905f213337c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-bcf58d90-cd9b-42ca-9879-85d48ad612fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-64cd0ca8-9411-4dda-9cf5-bda373998049,DISK], DatanodeInfoWithStorage[127.0.0.1:33838,DS-f2534df1-89ee-4c3e-809a-88354acdd47e,DISK], DatanodeInfoWithStorage[127.0.0.1:33166,DS-b8e545f1-a55f-4187-973a-fe82729646c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-4cfe3f8e-cd6b-4e21-abc3-f031dd59777c,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-b32d200c-eebf-4606-bacc-3cda2fee635d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-597815799-172.17.0.8-1595680586360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43884,DS-af9531a1-02d2-4a54-b944-fa4d2a21422b,DISK], DatanodeInfoWithStorage[127.0.0.1:46517,DS-5dd5ec16-a6ed-495b-9af5-f870c07b6eef,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-f1661436-3f86-4d12-a540-dd5319b8ec2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-51e3d82d-4c44-4b05-b796-654f0e85b8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-ef89804d-582f-4065-a70c-7c8569099c66,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-d0c4e89d-c5e1-4c22-9449-cb5c239a24ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-995b29b2-4f73-4b6c-950a-98a774d258cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-65db4afc-4c6c-4071-9b63-1568c3895f8d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-597815799-172.17.0.8-1595680586360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43884,DS-af9531a1-02d2-4a54-b944-fa4d2a21422b,DISK], DatanodeInfoWithStorage[127.0.0.1:46517,DS-5dd5ec16-a6ed-495b-9af5-f870c07b6eef,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-f1661436-3f86-4d12-a540-dd5319b8ec2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-51e3d82d-4c44-4b05-b796-654f0e85b8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-ef89804d-582f-4065-a70c-7c8569099c66,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-d0c4e89d-c5e1-4c22-9449-cb5c239a24ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-995b29b2-4f73-4b6c-950a-98a774d258cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-65db4afc-4c6c-4071-9b63-1568c3895f8d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-350433376-172.17.0.8-1595680632466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38101,DS-c3e88e55-4045-4f37-914e-00e90f5d7b66,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-048b5431-4fac-494e-af1b-f193602b01bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-014f6c3d-33b9-4b0c-aee9-f2d782bc9a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-6afd5706-fdfb-4792-b7ad-4f95d3d5df2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-fa389e4c-2790-4ded-a42e-b8003c7458ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-db31c208-9c76-433a-8a87-803d7c74a663,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-76fc4126-91b8-4726-83cb-3825433267b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-0b1415a2-e5ae-4770-97b5-b3fa624c131d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-350433376-172.17.0.8-1595680632466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38101,DS-c3e88e55-4045-4f37-914e-00e90f5d7b66,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-048b5431-4fac-494e-af1b-f193602b01bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-014f6c3d-33b9-4b0c-aee9-f2d782bc9a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-6afd5706-fdfb-4792-b7ad-4f95d3d5df2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-fa389e4c-2790-4ded-a42e-b8003c7458ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-db31c208-9c76-433a-8a87-803d7c74a663,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-76fc4126-91b8-4726-83cb-3825433267b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-0b1415a2-e5ae-4770-97b5-b3fa624c131d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-561503719-172.17.0.8-1595680881782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46150,DS-f9489c83-822b-410f-89c9-5a1e956f2c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-8507d74c-0825-4894-90d9-fe9ec3fcd96a,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-b4de36f0-44aa-462c-b55a-628891ed3463,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-b6eae49b-fe9f-4456-8be7-3f5fb8c06a85,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-082682c6-7d70-4c98-8193-550ec5a27237,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-79fd52f9-3b35-4ced-82ea-d3e58e24d922,DISK], DatanodeInfoWithStorage[127.0.0.1:41876,DS-84f276da-007e-4d59-b42a-641aa84bfacb,DISK], DatanodeInfoWithStorage[127.0.0.1:43308,DS-e3c23e01-2962-4319-a20d-e63893a239d8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-561503719-172.17.0.8-1595680881782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46150,DS-f9489c83-822b-410f-89c9-5a1e956f2c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-8507d74c-0825-4894-90d9-fe9ec3fcd96a,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-b4de36f0-44aa-462c-b55a-628891ed3463,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-b6eae49b-fe9f-4456-8be7-3f5fb8c06a85,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-082682c6-7d70-4c98-8193-550ec5a27237,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-79fd52f9-3b35-4ced-82ea-d3e58e24d922,DISK], DatanodeInfoWithStorage[127.0.0.1:41876,DS-84f276da-007e-4d59-b42a-641aa84bfacb,DISK], DatanodeInfoWithStorage[127.0.0.1:43308,DS-e3c23e01-2962-4319-a20d-e63893a239d8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-954853978-172.17.0.8-1595681027415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39380,DS-acc713b6-e196-4ff9-aab6-9b81ae30002f,DISK], DatanodeInfoWithStorage[127.0.0.1:44343,DS-05cb86b4-b36e-4a4e-b68b-df08779d02c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-5c69034b-a6f9-4527-9589-408f30a31d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-173ec441-d8f4-462d-9526-4b051a642d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-a52e1f82-4734-4fed-ba20-c1f49a1867be,DISK], DatanodeInfoWithStorage[127.0.0.1:40530,DS-b2e7c0c2-1bfd-4587-993d-1201e7a7cddd,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-307758ab-939f-45e1-b360-617c0714a46f,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-99575379-630c-48ea-a7b7-c8a3630b7a98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-954853978-172.17.0.8-1595681027415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39380,DS-acc713b6-e196-4ff9-aab6-9b81ae30002f,DISK], DatanodeInfoWithStorage[127.0.0.1:44343,DS-05cb86b4-b36e-4a4e-b68b-df08779d02c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-5c69034b-a6f9-4527-9589-408f30a31d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-173ec441-d8f4-462d-9526-4b051a642d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-a52e1f82-4734-4fed-ba20-c1f49a1867be,DISK], DatanodeInfoWithStorage[127.0.0.1:40530,DS-b2e7c0c2-1bfd-4587-993d-1201e7a7cddd,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-307758ab-939f-45e1-b360-617c0714a46f,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-99575379-630c-48ea-a7b7-c8a3630b7a98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-310418677-172.17.0.8-1595681094396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43054,DS-ee3c19e8-d3bf-4dd7-a879-25a293ceaa50,DISK], DatanodeInfoWithStorage[127.0.0.1:35348,DS-4626cc97-8383-4192-8667-205b5ff4a18f,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-0c0abc80-209d-4125-a0e8-3b4e1c83f56f,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-4e8e08ce-910b-42ae-9b6d-0d27bd6edee2,DISK], DatanodeInfoWithStorage[127.0.0.1:39790,DS-c2dc1166-35fc-438b-9c3b-6bf2bbb444f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-367cb6a6-9cf6-459d-9591-65b4bb174d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-b9599197-f974-43e2-bd8b-fc3cfa3af52a,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-9cfb277c-f0e5-44fa-af06-de2252d09194,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-310418677-172.17.0.8-1595681094396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43054,DS-ee3c19e8-d3bf-4dd7-a879-25a293ceaa50,DISK], DatanodeInfoWithStorage[127.0.0.1:35348,DS-4626cc97-8383-4192-8667-205b5ff4a18f,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-0c0abc80-209d-4125-a0e8-3b4e1c83f56f,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-4e8e08ce-910b-42ae-9b6d-0d27bd6edee2,DISK], DatanodeInfoWithStorage[127.0.0.1:39790,DS-c2dc1166-35fc-438b-9c3b-6bf2bbb444f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-367cb6a6-9cf6-459d-9591-65b4bb174d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-b9599197-f974-43e2-bd8b-fc3cfa3af52a,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-9cfb277c-f0e5-44fa-af06-de2252d09194,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-100134036-172.17.0.8-1595681145032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38448,DS-d4407f35-1415-411d-98f9-95dd4731d96c,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-f83cacab-0faf-4415-963f-56695001c152,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-48c8f2d6-99bf-444e-a57a-9e1bd652fea9,DISK], DatanodeInfoWithStorage[127.0.0.1:39044,DS-8a8cea41-8ee9-4ff1-a719-bb8535a6d3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-603b4b5d-a792-4017-829c-6d3420a72d15,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-da3ae56d-e97e-4363-a2cb-9f6472989cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-bc9baaf6-0130-4952-a3e5-661a877173a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44936,DS-3c820b3b-df6d-4319-b5a8-fd110e4f0e09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-100134036-172.17.0.8-1595681145032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38448,DS-d4407f35-1415-411d-98f9-95dd4731d96c,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-f83cacab-0faf-4415-963f-56695001c152,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-48c8f2d6-99bf-444e-a57a-9e1bd652fea9,DISK], DatanodeInfoWithStorage[127.0.0.1:39044,DS-8a8cea41-8ee9-4ff1-a719-bb8535a6d3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-603b4b5d-a792-4017-829c-6d3420a72d15,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-da3ae56d-e97e-4363-a2cb-9f6472989cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-bc9baaf6-0130-4952-a3e5-661a877173a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44936,DS-3c820b3b-df6d-4319-b5a8-fd110e4f0e09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-261719002-172.17.0.8-1595681592897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34544,DS-25669af8-dee8-482f-bf1d-2c2055c2f9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35890,DS-834832e4-150d-44bd-ad47-75bc9b14e84f,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-38d17951-e4e6-43dc-a37f-589f86107f71,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-3031503c-c3a4-4a68-82a5-06176d7e0fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-b8d8a463-0c61-40c6-95da-9706f81af573,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-91aedda2-73c9-4f93-a421-c95efc4b0932,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-50a4444b-ae84-41ae-ad7f-b18ca0bb3e95,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-747ca8b1-2feb-4680-9d4b-af807458ca5e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-261719002-172.17.0.8-1595681592897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34544,DS-25669af8-dee8-482f-bf1d-2c2055c2f9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35890,DS-834832e4-150d-44bd-ad47-75bc9b14e84f,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-38d17951-e4e6-43dc-a37f-589f86107f71,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-3031503c-c3a4-4a68-82a5-06176d7e0fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-b8d8a463-0c61-40c6-95da-9706f81af573,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-91aedda2-73c9-4f93-a421-c95efc4b0932,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-50a4444b-ae84-41ae-ad7f-b18ca0bb3e95,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-747ca8b1-2feb-4680-9d4b-af807458ca5e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1662667152-172.17.0.8-1595681684860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39221,DS-209e19e2-32fe-47bc-9f1b-829eeee6a2af,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-31a228ac-491e-4f90-bfb0-d33d709098ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-503f678b-1c4c-451c-897f-de712074eabf,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-d8aa67f6-d49e-4778-a201-ce635aaafe34,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-5a708d7b-ebb5-4426-b82f-54f954a0407c,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-1f7fb520-59db-49fe-b4bc-067ceedc61e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-94dfa562-1781-4f0c-80b3-ecd2a361d129,DISK], DatanodeInfoWithStorage[127.0.0.1:43639,DS-b5609c0e-64ea-4183-987a-888e0844a19f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1662667152-172.17.0.8-1595681684860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39221,DS-209e19e2-32fe-47bc-9f1b-829eeee6a2af,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-31a228ac-491e-4f90-bfb0-d33d709098ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-503f678b-1c4c-451c-897f-de712074eabf,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-d8aa67f6-d49e-4778-a201-ce635aaafe34,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-5a708d7b-ebb5-4426-b82f-54f954a0407c,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-1f7fb520-59db-49fe-b4bc-067ceedc61e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-94dfa562-1781-4f0c-80b3-ecd2a361d129,DISK], DatanodeInfoWithStorage[127.0.0.1:43639,DS-b5609c0e-64ea-4183-987a-888e0844a19f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061523749-172.17.0.8-1595681882595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40651,DS-aa3e7f51-b14e-4b69-b4c7-907994f5d980,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-7e05cc10-c139-49d7-9e5a-1e6ff22998ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-904b4c63-5540-4b09-86d5-91506aab0d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-f2c97604-ebd6-484f-a999-8061fe06c9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-c43b30df-3129-4a98-9231-28134f381e85,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-64942e68-c707-4aa5-813c-b0c68622527d,DISK], DatanodeInfoWithStorage[127.0.0.1:40847,DS-a05e0caa-9d06-46c4-8979-41f349f5bad8,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-ae2518c1-684d-4759-a5c0-6a718ebced13,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061523749-172.17.0.8-1595681882595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40651,DS-aa3e7f51-b14e-4b69-b4c7-907994f5d980,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-7e05cc10-c139-49d7-9e5a-1e6ff22998ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-904b4c63-5540-4b09-86d5-91506aab0d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-f2c97604-ebd6-484f-a999-8061fe06c9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-c43b30df-3129-4a98-9231-28134f381e85,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-64942e68-c707-4aa5-813c-b0c68622527d,DISK], DatanodeInfoWithStorage[127.0.0.1:40847,DS-a05e0caa-9d06-46c4-8979-41f349f5bad8,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-ae2518c1-684d-4759-a5c0-6a718ebced13,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-415472212-172.17.0.8-1595681964119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40829,DS-df90c7bb-e5cd-4fb3-b96f-22a69e21005d,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-456bc581-91b2-444e-9adc-235c9640025f,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-0b517df4-3eb1-4303-996c-db41d5d4285d,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-fde7fa97-9dc1-43cf-9cb8-3179648bf8de,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-23535503-050b-408f-8207-3d85536026d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46288,DS-d194042e-a816-4a8c-aef8-cf812d44707c,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-31b216cb-5aeb-4c82-89f8-63cd6241a426,DISK], DatanodeInfoWithStorage[127.0.0.1:46835,DS-0a437ce5-562f-4af7-b247-73487acfe930,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-415472212-172.17.0.8-1595681964119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40829,DS-df90c7bb-e5cd-4fb3-b96f-22a69e21005d,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-456bc581-91b2-444e-9adc-235c9640025f,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-0b517df4-3eb1-4303-996c-db41d5d4285d,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-fde7fa97-9dc1-43cf-9cb8-3179648bf8de,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-23535503-050b-408f-8207-3d85536026d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46288,DS-d194042e-a816-4a8c-aef8-cf812d44707c,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-31b216cb-5aeb-4c82-89f8-63cd6241a426,DISK], DatanodeInfoWithStorage[127.0.0.1:46835,DS-0a437ce5-562f-4af7-b247-73487acfe930,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1079197224-172.17.0.8-1595682061223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37061,DS-0e8e3207-7b9d-4eee-98db-7509fa7490fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-c66284fd-da56-4a41-a00e-bcbd5c2b5446,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-c98a1235-54fa-423a-903b-fee48221027c,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-f48f12de-bea0-47b9-8c01-bf1400391f21,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-c7524301-4720-45c3-9823-e62cd9f10d70,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-f38671fa-cbe0-49b6-b7c4-47bba7b36dee,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-91971cb5-fdff-4692-b9f1-70ee28cd3338,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-864efcd7-cfb1-4e5c-9959-c5961152e0a1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1079197224-172.17.0.8-1595682061223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37061,DS-0e8e3207-7b9d-4eee-98db-7509fa7490fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-c66284fd-da56-4a41-a00e-bcbd5c2b5446,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-c98a1235-54fa-423a-903b-fee48221027c,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-f48f12de-bea0-47b9-8c01-bf1400391f21,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-c7524301-4720-45c3-9823-e62cd9f10d70,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-f38671fa-cbe0-49b6-b7c4-47bba7b36dee,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-91971cb5-fdff-4692-b9f1-70ee28cd3338,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-864efcd7-cfb1-4e5c-9959-c5961152e0a1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-313631798-172.17.0.8-1595682109158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38911,DS-22290d94-2f8f-4640-b2a5-5d077f587fad,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-1ab28ea6-fbee-4e59-967e-1aac562314b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-9d0e2430-95d1-4284-8d99-387e2e458d39,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-f3f6350a-0f83-4ec7-a9bf-e0f6d182ba39,DISK], DatanodeInfoWithStorage[127.0.0.1:39340,DS-2fd41e54-b948-47f4-9817-c425b81efca6,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-5ca4378e-0277-4d05-a898-7532800e1364,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-edd9c112-5802-4306-ac38-74e8dbf155a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-3c24eff4-95a3-46e9-af1c-90927bb0a612,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-313631798-172.17.0.8-1595682109158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38911,DS-22290d94-2f8f-4640-b2a5-5d077f587fad,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-1ab28ea6-fbee-4e59-967e-1aac562314b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-9d0e2430-95d1-4284-8d99-387e2e458d39,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-f3f6350a-0f83-4ec7-a9bf-e0f6d182ba39,DISK], DatanodeInfoWithStorage[127.0.0.1:39340,DS-2fd41e54-b948-47f4-9817-c425b81efca6,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-5ca4378e-0277-4d05-a898-7532800e1364,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-edd9c112-5802-4306-ac38-74e8dbf155a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-3c24eff4-95a3-46e9-af1c-90927bb0a612,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1341740978-172.17.0.8-1595682199421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43504,DS-0580aed2-bedd-41ae-ab93-f04ab6c52af7,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-d7d3f9b4-941a-4700-8e61-fea867eb169a,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-e5f18997-a9ac-4fc8-8e15-52b887bcb354,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-1bcdb6b1-d7d7-4c52-a0b8-cec3a370499c,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-83cf3201-ed0b-4544-8309-5af4ac0e9a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38444,DS-24040d28-7fae-49cd-8c61-dd54623cfb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-305ea02e-36f3-43bb-9cdc-47d72131586e,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-cf963b04-c2a9-474f-96a6-c8f0258d9048,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1341740978-172.17.0.8-1595682199421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43504,DS-0580aed2-bedd-41ae-ab93-f04ab6c52af7,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-d7d3f9b4-941a-4700-8e61-fea867eb169a,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-e5f18997-a9ac-4fc8-8e15-52b887bcb354,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-1bcdb6b1-d7d7-4c52-a0b8-cec3a370499c,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-83cf3201-ed0b-4544-8309-5af4ac0e9a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38444,DS-24040d28-7fae-49cd-8c61-dd54623cfb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-305ea02e-36f3-43bb-9cdc-47d72131586e,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-cf963b04-c2a9-474f-96a6-c8f0258d9048,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72451103-172.17.0.8-1595682540818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33681,DS-b25da685-affb-4c0b-b1eb-3873f433ce67,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-0ded12bc-1468-4e6d-8eae-b79a59243107,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-736b7d60-177b-4b87-b43d-4170a500823f,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-40a9031e-1b5e-4ebe-9305-5b42f68ce24f,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-a547fe7c-8086-400f-820f-895279393bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-b8f6dc7b-5db6-4afa-bd82-67845c874859,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-adc5efc5-9274-46c6-b3fe-88d699be0347,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-06e99dc8-aa8b-4c02-871a-0f53e934b968,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72451103-172.17.0.8-1595682540818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33681,DS-b25da685-affb-4c0b-b1eb-3873f433ce67,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-0ded12bc-1468-4e6d-8eae-b79a59243107,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-736b7d60-177b-4b87-b43d-4170a500823f,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-40a9031e-1b5e-4ebe-9305-5b42f68ce24f,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-a547fe7c-8086-400f-820f-895279393bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-b8f6dc7b-5db6-4afa-bd82-67845c874859,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-adc5efc5-9274-46c6-b3fe-88d699be0347,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-06e99dc8-aa8b-4c02-871a-0f53e934b968,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258099876-172.17.0.8-1595682635310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39431,DS-f07decc8-45f7-4ed0-bcb1-f6cb0789251f,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-fb7d6f3e-b1c1-4e3b-91a1-984e8ae9b590,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-d2c91c4a-fcaa-43c5-843a-f400a2d6a9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-4c07e540-e4b5-4bc2-871f-af9d2222169f,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-ae3b33c8-28cd-423d-bb40-afb90299447a,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-5aee3593-4889-43ed-9e70-18d26d1481f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-1271cc77-c1a8-4f1b-8ed0-2d4d128cfb21,DISK], DatanodeInfoWithStorage[127.0.0.1:46299,DS-df4d8f6f-a216-48a3-8284-595ae3ca7634,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258099876-172.17.0.8-1595682635310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39431,DS-f07decc8-45f7-4ed0-bcb1-f6cb0789251f,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-fb7d6f3e-b1c1-4e3b-91a1-984e8ae9b590,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-d2c91c4a-fcaa-43c5-843a-f400a2d6a9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-4c07e540-e4b5-4bc2-871f-af9d2222169f,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-ae3b33c8-28cd-423d-bb40-afb90299447a,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-5aee3593-4889-43ed-9e70-18d26d1481f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-1271cc77-c1a8-4f1b-8ed0-2d4d128cfb21,DISK], DatanodeInfoWithStorage[127.0.0.1:46299,DS-df4d8f6f-a216-48a3-8284-595ae3ca7634,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1017717140-172.17.0.8-1595682865461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37466,DS-dc3d8fe6-346a-4e25-8e31-0fc89930ac40,DISK], DatanodeInfoWithStorage[127.0.0.1:36116,DS-4a328a54-bc77-4e86-a125-8641d75967d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-00a1a7e8-10bc-42eb-898b-52bebdb9a686,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-c4615f8f-1b55-44e4-935b-b016db671f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-aa9c56f4-6b7d-4aeb-a658-bfb1d2be141f,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-f537ef0d-02d2-4041-93cd-56540d44f20f,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-9fc04bda-340f-44bb-8809-1b5c9d55a7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-4649238a-911f-4a95-a9b3-6289414327cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1017717140-172.17.0.8-1595682865461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37466,DS-dc3d8fe6-346a-4e25-8e31-0fc89930ac40,DISK], DatanodeInfoWithStorage[127.0.0.1:36116,DS-4a328a54-bc77-4e86-a125-8641d75967d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-00a1a7e8-10bc-42eb-898b-52bebdb9a686,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-c4615f8f-1b55-44e4-935b-b016db671f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-aa9c56f4-6b7d-4aeb-a658-bfb1d2be141f,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-f537ef0d-02d2-4041-93cd-56540d44f20f,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-9fc04bda-340f-44bb-8809-1b5c9d55a7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-4649238a-911f-4a95-a9b3-6289414327cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1152608687-172.17.0.8-1595683002885:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45597,DS-e2378a9e-961e-4e05-80b9-17afb49e9080,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-a152ae6a-f36a-4c5f-a227-bb84b85693e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-05e08084-900b-4727-9014-740a7f816e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-476c37c1-4d1d-4b8b-8155-9c89ce173836,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-0ec283c7-ed8b-40a6-951a-a4a79920c661,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-1ad6ed87-fe66-40f3-9e11-6f955292775e,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-284d361b-ef9d-48c7-882c-6e8fe711515c,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-9ec7e02b-f511-4ac7-b4ce-b4b305ab44b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1152608687-172.17.0.8-1595683002885:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45597,DS-e2378a9e-961e-4e05-80b9-17afb49e9080,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-a152ae6a-f36a-4c5f-a227-bb84b85693e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-05e08084-900b-4727-9014-740a7f816e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-476c37c1-4d1d-4b8b-8155-9c89ce173836,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-0ec283c7-ed8b-40a6-951a-a4a79920c661,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-1ad6ed87-fe66-40f3-9e11-6f955292775e,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-284d361b-ef9d-48c7-882c-6e8fe711515c,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-9ec7e02b-f511-4ac7-b4ce-b4b305ab44b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800858377-172.17.0.8-1595683200572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32921,DS-eeb26564-f16e-47d0-8685-d7c75b940ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-ff6ba69b-757b-4e38-89c6-b6335b6e90a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-076932d2-63f5-49b0-b0e1-35e8c506a6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-aa92fe70-0f23-47c1-bc3d-1788e696b45d,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-78b942d5-c6dc-4cdb-8faf-821b7ffcb2c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-3d7f97a9-36fc-4193-b463-1544dff84e47,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-333dfaec-f359-4788-982b-e1175d1a4d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-22f75c09-7240-456c-833b-76188bc10e3a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800858377-172.17.0.8-1595683200572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32921,DS-eeb26564-f16e-47d0-8685-d7c75b940ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-ff6ba69b-757b-4e38-89c6-b6335b6e90a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-076932d2-63f5-49b0-b0e1-35e8c506a6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-aa92fe70-0f23-47c1-bc3d-1788e696b45d,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-78b942d5-c6dc-4cdb-8faf-821b7ffcb2c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-3d7f97a9-36fc-4193-b463-1544dff84e47,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-333dfaec-f359-4788-982b-e1175d1a4d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-22f75c09-7240-456c-833b-76188bc10e3a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1656868300-172.17.0.8-1595683244942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37154,DS-f44539d4-9c71-4055-ab5c-95dec5d5516e,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-2e4cbf2d-ba77-4ae2-92a7-4ae2a082cbd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-10857466-cc10-406f-9e5d-5247887b6f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-84694b00-fa73-4693-ad7d-9ef558a302d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36408,DS-1ceead30-7255-4cd0-811a-7a6d958bae61,DISK], DatanodeInfoWithStorage[127.0.0.1:43215,DS-9b524a97-63bb-4006-b4fe-b20900a67a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-003e9e30-7098-48bf-9929-8abe574c2382,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-429a78d8-f8f3-4681-aa79-681128c58bdb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1656868300-172.17.0.8-1595683244942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37154,DS-f44539d4-9c71-4055-ab5c-95dec5d5516e,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-2e4cbf2d-ba77-4ae2-92a7-4ae2a082cbd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-10857466-cc10-406f-9e5d-5247887b6f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-84694b00-fa73-4693-ad7d-9ef558a302d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36408,DS-1ceead30-7255-4cd0-811a-7a6d958bae61,DISK], DatanodeInfoWithStorage[127.0.0.1:43215,DS-9b524a97-63bb-4006-b4fe-b20900a67a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-003e9e30-7098-48bf-9929-8abe574c2382,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-429a78d8-f8f3-4681-aa79-681128c58bdb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-46629218-172.17.0.8-1595683286678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46505,DS-2491498b-f1b9-47f7-b4b9-7ef3215086d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-94e3a061-2708-4922-8194-509ca48319b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-056e3d59-57d8-4ef1-86e1-6130a8b76307,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-32319f99-98bd-418d-b90f-e411a7c21bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:35309,DS-340714bf-2ba5-4d14-8db5-7965ce967fef,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-42c3efaf-5867-4e15-a3bd-3ecbfa1e2534,DISK], DatanodeInfoWithStorage[127.0.0.1:44063,DS-f8217623-6a40-43e2-8f87-3d3a0b0a6b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-bbdac396-2fdd-4994-a8b1-d1290399885d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-46629218-172.17.0.8-1595683286678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46505,DS-2491498b-f1b9-47f7-b4b9-7ef3215086d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-94e3a061-2708-4922-8194-509ca48319b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-056e3d59-57d8-4ef1-86e1-6130a8b76307,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-32319f99-98bd-418d-b90f-e411a7c21bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:35309,DS-340714bf-2ba5-4d14-8db5-7965ce967fef,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-42c3efaf-5867-4e15-a3bd-3ecbfa1e2534,DISK], DatanodeInfoWithStorage[127.0.0.1:44063,DS-f8217623-6a40-43e2-8f87-3d3a0b0a6b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-bbdac396-2fdd-4994-a8b1-d1290399885d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1800289385-172.17.0.8-1595683599669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41578,DS-2c60ddbe-806a-463f-a313-95369dc00c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-3b0ff36d-eef7-4c70-a68a-59b723e877a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43469,DS-2daa9527-0ce9-4562-af5b-5c799d07fde2,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-6e0a05d2-f4bc-4450-93df-0491fc4c96d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-f6a4d111-439f-4c60-adff-a4f165bf3cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-48bb703e-2990-4c6c-aaeb-9d4098d12b23,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-2a3c7b6f-3ed8-4853-a03d-695f2910962e,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-c299a8d5-dd49-4418-9bbf-41823af5fb19,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1800289385-172.17.0.8-1595683599669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41578,DS-2c60ddbe-806a-463f-a313-95369dc00c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-3b0ff36d-eef7-4c70-a68a-59b723e877a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43469,DS-2daa9527-0ce9-4562-af5b-5c799d07fde2,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-6e0a05d2-f4bc-4450-93df-0491fc4c96d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-f6a4d111-439f-4c60-adff-a4f165bf3cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-48bb703e-2990-4c6c-aaeb-9d4098d12b23,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-2a3c7b6f-3ed8-4853-a03d-695f2910962e,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-c299a8d5-dd49-4418-9bbf-41823af5fb19,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1242314675-172.17.0.8-1595684300572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38577,DS-55866e54-dbe2-4260-8c30-52e74fcaf745,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-46cb8dfb-8e43-4673-8964-cb60968f0d13,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-0f2dced0-eefd-4fb9-aa4a-055158c561f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-2560eee4-a29c-4f77-acaa-ff44d25fc60f,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-722aad19-bbfa-4440-bdd6-6089e9271b09,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-cb737b38-ba4c-4516-8666-7a5fc9d82b58,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-cccd4eed-14cb-4b16-9cca-9e9137f2c7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-3cac8339-886c-46cf-a0ed-47076f3c9f70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1242314675-172.17.0.8-1595684300572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38577,DS-55866e54-dbe2-4260-8c30-52e74fcaf745,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-46cb8dfb-8e43-4673-8964-cb60968f0d13,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-0f2dced0-eefd-4fb9-aa4a-055158c561f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-2560eee4-a29c-4f77-acaa-ff44d25fc60f,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-722aad19-bbfa-4440-bdd6-6089e9271b09,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-cb737b38-ba4c-4516-8666-7a5fc9d82b58,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-cccd4eed-14cb-4b16-9cca-9e9137f2c7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-3cac8339-886c-46cf-a0ed-47076f3c9f70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183809031-172.17.0.8-1595684528838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40464,DS-775305d6-759b-4cef-af18-80bcb2361c78,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-d8698dfb-63e8-4dba-8ccf-5e97b657ab0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-c1ced267-ad9f-44d9-8a05-c8f579556d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-23269b18-6834-405f-99d1-8705e7c22082,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-d89b7d27-be16-48af-9d9b-1d03dd3f6bde,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-308bdb84-7907-4798-b715-e5e4550b2ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-6a9e04a9-7b84-46e6-ae68-3da2fe4a641f,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-2dea0653-17bd-4998-a8c3-a603860ac1c3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183809031-172.17.0.8-1595684528838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40464,DS-775305d6-759b-4cef-af18-80bcb2361c78,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-d8698dfb-63e8-4dba-8ccf-5e97b657ab0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-c1ced267-ad9f-44d9-8a05-c8f579556d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-23269b18-6834-405f-99d1-8705e7c22082,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-d89b7d27-be16-48af-9d9b-1d03dd3f6bde,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-308bdb84-7907-4798-b715-e5e4550b2ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-6a9e04a9-7b84-46e6-ae68-3da2fe4a641f,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-2dea0653-17bd-4998-a8c3-a603860ac1c3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-686982962-172.17.0.8-1595684573281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34353,DS-d664edd5-0295-4a97-ac1a-034ab082e720,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-7b6d9eea-461b-4756-ae89-d15b2c997ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-0eac509a-77fe-40ff-9d1b-b86d870fc9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38774,DS-2da672d2-af57-41b8-b9ce-d08b977cceca,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-b29e9f80-dc4a-42cf-b23f-1dafafdddd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-ac4ea038-8e7e-4572-b73d-8cbb0bdcd42c,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-f75aba16-44ea-41e0-baea-7ce493eb03f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39332,DS-f5b9a90f-a10c-454d-939c-e91bae44dd7a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-686982962-172.17.0.8-1595684573281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34353,DS-d664edd5-0295-4a97-ac1a-034ab082e720,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-7b6d9eea-461b-4756-ae89-d15b2c997ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-0eac509a-77fe-40ff-9d1b-b86d870fc9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38774,DS-2da672d2-af57-41b8-b9ce-d08b977cceca,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-b29e9f80-dc4a-42cf-b23f-1dafafdddd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-ac4ea038-8e7e-4572-b73d-8cbb0bdcd42c,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-f75aba16-44ea-41e0-baea-7ce493eb03f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39332,DS-f5b9a90f-a10c-454d-939c-e91bae44dd7a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1078544566-172.17.0.8-1595684720728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41637,DS-4a36448c-0b3f-4073-86de-2dea6bd3ffac,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-4525082e-c682-4181-9090-57d1038686a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-fab5d44b-c422-4613-82a8-ab65daf6a367,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-4e390a7f-59e0-485b-9d1f-50846fdabbf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-092c6596-42ef-4990-83e7-af4619d65e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43932,DS-94995a63-ec75-49fb-8162-567c6da814f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-1743c5d1-46ee-4cca-8eda-53f6aab76990,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-580dbf7c-84a3-40ae-9751-fc368e411743,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1078544566-172.17.0.8-1595684720728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41637,DS-4a36448c-0b3f-4073-86de-2dea6bd3ffac,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-4525082e-c682-4181-9090-57d1038686a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-fab5d44b-c422-4613-82a8-ab65daf6a367,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-4e390a7f-59e0-485b-9d1f-50846fdabbf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-092c6596-42ef-4990-83e7-af4619d65e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43932,DS-94995a63-ec75-49fb-8162-567c6da814f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-1743c5d1-46ee-4cca-8eda-53f6aab76990,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-580dbf7c-84a3-40ae-9751-fc368e411743,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-776239504-172.17.0.8-1595684820553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37623,DS-eb39de4d-d896-44cb-83df-ee9f56c9574a,DISK], DatanodeInfoWithStorage[127.0.0.1:42497,DS-2c4dc327-b0d6-4fca-a0a6-a08eee6ec1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-b0fc82d7-e561-4b46-aebf-5a954dda4846,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-c4c5431a-e3f2-4b98-967a-07e86ad95f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-cc59715f-54f6-4851-bb31-97bf39c321b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-70b21387-b8eb-4818-acee-210367faee2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-7fe72bd5-f2d2-4ba3-b1bd-0c03fedf11f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-e4e5a9f0-abf4-44d9-9e8b-958209eeb500,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-776239504-172.17.0.8-1595684820553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37623,DS-eb39de4d-d896-44cb-83df-ee9f56c9574a,DISK], DatanodeInfoWithStorage[127.0.0.1:42497,DS-2c4dc327-b0d6-4fca-a0a6-a08eee6ec1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-b0fc82d7-e561-4b46-aebf-5a954dda4846,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-c4c5431a-e3f2-4b98-967a-07e86ad95f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-cc59715f-54f6-4851-bb31-97bf39c321b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-70b21387-b8eb-4818-acee-210367faee2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-7fe72bd5-f2d2-4ba3-b1bd-0c03fedf11f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-e4e5a9f0-abf4-44d9-9e8b-958209eeb500,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-791297523-172.17.0.8-1595684868424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40872,DS-79771201-421d-4db4-bb08-24c646f44f82,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-02d1c33a-5345-4705-8806-3c575fe55853,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-cb308f89-54a6-4005-bb60-69836187a50a,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-336ddd50-d6ef-4a90-a241-4f086a3bfbbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-f5e9f357-8000-4972-a745-466bf42f8566,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-043e2c83-88e9-4805-b61e-d6362b4b3b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-3381caaf-60d4-42e5-aa53-f78b9cfd04cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-a3132345-3ac1-4e32-ab1c-6bd6a0991e4c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-791297523-172.17.0.8-1595684868424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40872,DS-79771201-421d-4db4-bb08-24c646f44f82,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-02d1c33a-5345-4705-8806-3c575fe55853,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-cb308f89-54a6-4005-bb60-69836187a50a,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-336ddd50-d6ef-4a90-a241-4f086a3bfbbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-f5e9f357-8000-4972-a745-466bf42f8566,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-043e2c83-88e9-4805-b61e-d6362b4b3b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-3381caaf-60d4-42e5-aa53-f78b9cfd04cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-a3132345-3ac1-4e32-ab1c-6bd6a0991e4c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-364022201-172.17.0.8-1595685010441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33248,DS-afbb976b-2c4d-4e28-9205-6932a1ead5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-28e09703-d089-4faa-a354-a191b7c86b83,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-b36c5916-e8f9-4121-851c-7b6e400d492f,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-3818f257-778d-4bb9-923c-dc78c3bc19ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-ac109491-367b-4bc1-812a-5b08d8231868,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-1caea824-3020-41bd-8a9e-e49d8ef62c06,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-e0e2c9c0-9a46-400b-b979-47d233476903,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-d303e9e5-f917-4332-b2cb-1760701bb51f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-364022201-172.17.0.8-1595685010441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33248,DS-afbb976b-2c4d-4e28-9205-6932a1ead5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-28e09703-d089-4faa-a354-a191b7c86b83,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-b36c5916-e8f9-4121-851c-7b6e400d492f,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-3818f257-778d-4bb9-923c-dc78c3bc19ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-ac109491-367b-4bc1-812a-5b08d8231868,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-1caea824-3020-41bd-8a9e-e49d8ef62c06,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-e0e2c9c0-9a46-400b-b979-47d233476903,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-d303e9e5-f917-4332-b2cb-1760701bb51f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 19 out of 50
v1v1v2v2 failed with probability 21 out of 50
result: false positive !!!
Total execution time in seconds : 7035
