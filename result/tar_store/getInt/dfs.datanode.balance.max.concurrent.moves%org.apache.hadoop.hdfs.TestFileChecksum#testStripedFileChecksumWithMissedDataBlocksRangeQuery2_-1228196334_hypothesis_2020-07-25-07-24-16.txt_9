reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-779845611-172.17.0.21-1595661908313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36293,DS-067446fe-dd90-41e8-91de-0481871b5726,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-13f913cc-d609-40fa-b6a8-435851bc443f,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-c45b4a48-8bda-420b-a261-c34d6d5fc312,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-50aabdb8-a5cd-422b-b80a-ac8dfc6fb4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-f31f1b81-f459-4725-a949-c0d71e4361d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-7545b1e6-2548-41bf-8083-80c19972122e,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-ea41303a-24e6-4592-b220-93f03aef17eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-53961173-f206-4311-823b-e9f09886a311,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-779845611-172.17.0.21-1595661908313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36293,DS-067446fe-dd90-41e8-91de-0481871b5726,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-13f913cc-d609-40fa-b6a8-435851bc443f,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-c45b4a48-8bda-420b-a261-c34d6d5fc312,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-50aabdb8-a5cd-422b-b80a-ac8dfc6fb4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-f31f1b81-f459-4725-a949-c0d71e4361d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-7545b1e6-2548-41bf-8083-80c19972122e,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-ea41303a-24e6-4592-b220-93f03aef17eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-53961173-f206-4311-823b-e9f09886a311,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-61324241-172.17.0.21-1595661985961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37509,DS-184b7c99-53e5-417c-89cb-8d27884c7210,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-84f137b8-f71e-46b8-9099-8341a29a87b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-7b5cb95e-84df-4083-92b8-5d1f6bacc8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37356,DS-3daed9a5-1480-4b5b-93d2-6f25049a7de1,DISK], DatanodeInfoWithStorage[127.0.0.1:34246,DS-d3e2143f-0dca-4e18-8664-b2c9b77bebcc,DISK], DatanodeInfoWithStorage[127.0.0.1:43423,DS-46a0a5b7-590a-436c-ae0e-e2320ef29848,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-318f2353-4236-4595-bd52-de8704585f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-9aec42e2-e6b4-4573-8ee5-7fe01698cb22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-61324241-172.17.0.21-1595661985961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37509,DS-184b7c99-53e5-417c-89cb-8d27884c7210,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-84f137b8-f71e-46b8-9099-8341a29a87b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-7b5cb95e-84df-4083-92b8-5d1f6bacc8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37356,DS-3daed9a5-1480-4b5b-93d2-6f25049a7de1,DISK], DatanodeInfoWithStorage[127.0.0.1:34246,DS-d3e2143f-0dca-4e18-8664-b2c9b77bebcc,DISK], DatanodeInfoWithStorage[127.0.0.1:43423,DS-46a0a5b7-590a-436c-ae0e-e2320ef29848,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-318f2353-4236-4595-bd52-de8704585f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-9aec42e2-e6b4-4573-8ee5-7fe01698cb22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1350766881-172.17.0.21-1595662018544:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33276,DS-177aaa80-d15a-4998-bbc7-3fc382077a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-f27203ab-7406-4114-8102-3d1613c6831e,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-d52667a0-c8e3-40d4-8018-7af3f18711d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-f854f3b9-e45b-4ae5-a099-a59bbe746cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-e5befafd-d3aa-49a6-a526-f41e522d3188,DISK], DatanodeInfoWithStorage[127.0.0.1:44674,DS-e60189bb-cf11-4304-9ce5-99840d910f40,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-d61a62a2-3000-41e4-b016-2f2f79fc8213,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-9f8e56fc-3a3c-414a-a2b0-846e3f8239f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1350766881-172.17.0.21-1595662018544:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33276,DS-177aaa80-d15a-4998-bbc7-3fc382077a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-f27203ab-7406-4114-8102-3d1613c6831e,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-d52667a0-c8e3-40d4-8018-7af3f18711d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-f854f3b9-e45b-4ae5-a099-a59bbe746cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-e5befafd-d3aa-49a6-a526-f41e522d3188,DISK], DatanodeInfoWithStorage[127.0.0.1:44674,DS-e60189bb-cf11-4304-9ce5-99840d910f40,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-d61a62a2-3000-41e4-b016-2f2f79fc8213,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-9f8e56fc-3a3c-414a-a2b0-846e3f8239f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1152555491-172.17.0.21-1595662139565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33908,DS-5ae1ebbf-af7b-4015-b2e0-79d2ebd3a20b,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-ba4bbf94-5cc6-48e5-b281-01f7889b7fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39026,DS-695ca155-8f87-4816-8c9f-1b503c6bcb22,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-2ba85dc9-0a12-45d0-97f7-e25741e5e789,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-478721c4-2727-4cb6-9b98-1032f7108929,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-51042699-900a-4b60-9493-fd9ed2fc7313,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-18505b1f-7d47-49fa-80e5-b1031e6659fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-bb0eec19-7e10-4bc2-b216-a13b1e4ab254,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1152555491-172.17.0.21-1595662139565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33908,DS-5ae1ebbf-af7b-4015-b2e0-79d2ebd3a20b,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-ba4bbf94-5cc6-48e5-b281-01f7889b7fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39026,DS-695ca155-8f87-4816-8c9f-1b503c6bcb22,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-2ba85dc9-0a12-45d0-97f7-e25741e5e789,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-478721c4-2727-4cb6-9b98-1032f7108929,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-51042699-900a-4b60-9493-fd9ed2fc7313,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-18505b1f-7d47-49fa-80e5-b1031e6659fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-bb0eec19-7e10-4bc2-b216-a13b1e4ab254,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905894295-172.17.0.21-1595662254252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37081,DS-7da21520-6587-456f-9415-f5802b9e16b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-8491aea9-eaaf-404a-867b-53a49c0c29b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-2ace0dec-b484-494c-a462-98213c276859,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-28eb68ab-5001-404b-b747-0ea99eff70bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-e6a21ef2-255b-46ac-984d-6214b37f452d,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-787f4f4b-af79-4eb3-ac19-908822117720,DISK], DatanodeInfoWithStorage[127.0.0.1:34256,DS-6b2d3304-5dbf-4eca-a9a2-b53b6b848ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-a27e712a-e705-46e9-9fac-4c8dddc9e2a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905894295-172.17.0.21-1595662254252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37081,DS-7da21520-6587-456f-9415-f5802b9e16b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-8491aea9-eaaf-404a-867b-53a49c0c29b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-2ace0dec-b484-494c-a462-98213c276859,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-28eb68ab-5001-404b-b747-0ea99eff70bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-e6a21ef2-255b-46ac-984d-6214b37f452d,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-787f4f4b-af79-4eb3-ac19-908822117720,DISK], DatanodeInfoWithStorage[127.0.0.1:34256,DS-6b2d3304-5dbf-4eca-a9a2-b53b6b848ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-a27e712a-e705-46e9-9fac-4c8dddc9e2a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-991485557-172.17.0.21-1595662405223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44959,DS-3c9b72f0-f770-40ba-8742-54b0430e4f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-afb52b8b-4acd-4dbf-ab2f-ced44678e2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-f72e4336-54f0-4e31-bd92-a93c0c5d304e,DISK], DatanodeInfoWithStorage[127.0.0.1:45182,DS-30ee9fbb-f18d-404e-b113-8f6682bb3f59,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-bf8e31fd-7ae7-47b5-bae7-aefdeac857ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-9ddb8c5b-42f4-4e3f-90d2-c452fd313983,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-775b3335-99df-4b85-80da-c6a5888d86e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-61ea8210-8e01-488d-8d24-61db18cb29eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-991485557-172.17.0.21-1595662405223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44959,DS-3c9b72f0-f770-40ba-8742-54b0430e4f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-afb52b8b-4acd-4dbf-ab2f-ced44678e2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-f72e4336-54f0-4e31-bd92-a93c0c5d304e,DISK], DatanodeInfoWithStorage[127.0.0.1:45182,DS-30ee9fbb-f18d-404e-b113-8f6682bb3f59,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-bf8e31fd-7ae7-47b5-bae7-aefdeac857ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-9ddb8c5b-42f4-4e3f-90d2-c452fd313983,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-775b3335-99df-4b85-80da-c6a5888d86e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-61ea8210-8e01-488d-8d24-61db18cb29eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1664421364-172.17.0.21-1595663182576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44765,DS-e7f358c8-ab1f-4094-b2e7-39cda75062f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-f77dff4d-4e35-49ee-adcb-a8d41ea4f6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-c0baff18-1b82-4413-a842-db47732ce045,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-fb5fe12c-c9f3-47c9-aedf-98b16c54d295,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-1cf994ec-7bdb-47b5-bc6e-9c3334ddcd84,DISK], DatanodeInfoWithStorage[127.0.0.1:36269,DS-00536552-f11d-42a2-81c1-05419164e2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-c19ef125-f3e0-4285-8873-c00f4715e082,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-f08db764-13db-4783-953e-a685a486189e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1664421364-172.17.0.21-1595663182576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44765,DS-e7f358c8-ab1f-4094-b2e7-39cda75062f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-f77dff4d-4e35-49ee-adcb-a8d41ea4f6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-c0baff18-1b82-4413-a842-db47732ce045,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-fb5fe12c-c9f3-47c9-aedf-98b16c54d295,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-1cf994ec-7bdb-47b5-bc6e-9c3334ddcd84,DISK], DatanodeInfoWithStorage[127.0.0.1:36269,DS-00536552-f11d-42a2-81c1-05419164e2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-c19ef125-f3e0-4285-8873-c00f4715e082,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-f08db764-13db-4783-953e-a685a486189e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-567002306-172.17.0.21-1595663448541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46286,DS-3f05adbb-e9ce-44e4-8f3b-6b37a72826d7,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-33345278-e85c-499e-a9e8-015071c256e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-2c7f72bf-2b79-449f-8213-131386cf25e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-c23dca71-2284-43cf-a01c-7974f211de17,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-27d72fc5-2e39-4bed-8cd5-967dd98a57ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-0dc1f724-5d16-447b-a848-db953e624751,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-6f84afe2-0041-42cc-bbda-070bb91ad75b,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-ab03a0f0-223b-449b-8db6-40c1e5983ed6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-567002306-172.17.0.21-1595663448541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46286,DS-3f05adbb-e9ce-44e4-8f3b-6b37a72826d7,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-33345278-e85c-499e-a9e8-015071c256e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-2c7f72bf-2b79-449f-8213-131386cf25e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-c23dca71-2284-43cf-a01c-7974f211de17,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-27d72fc5-2e39-4bed-8cd5-967dd98a57ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-0dc1f724-5d16-447b-a848-db953e624751,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-6f84afe2-0041-42cc-bbda-070bb91ad75b,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-ab03a0f0-223b-449b-8db6-40c1e5983ed6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1255424299-172.17.0.21-1595664168724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39379,DS-2fe63159-e6a6-4a7c-af63-eff27e6df8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-91788665-93a5-4489-b817-8f619ca36fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-ae5ebb3c-77cc-4011-affd-e18b7c04c15e,DISK], DatanodeInfoWithStorage[127.0.0.1:42523,DS-9f275e8e-8530-4b87-aa2d-c6b4fdc3797b,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-ff93fe55-a11a-4b58-93d9-96459ccc8399,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-9f4fa955-99c0-43c7-9f3d-e4f97db67413,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-ae630402-b2b9-4c35-8f5a-82fed16318e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-0f610ecd-c2e1-4f8e-adfd-d040e1613eeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1255424299-172.17.0.21-1595664168724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39379,DS-2fe63159-e6a6-4a7c-af63-eff27e6df8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-91788665-93a5-4489-b817-8f619ca36fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-ae5ebb3c-77cc-4011-affd-e18b7c04c15e,DISK], DatanodeInfoWithStorage[127.0.0.1:42523,DS-9f275e8e-8530-4b87-aa2d-c6b4fdc3797b,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-ff93fe55-a11a-4b58-93d9-96459ccc8399,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-9f4fa955-99c0-43c7-9f3d-e4f97db67413,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-ae630402-b2b9-4c35-8f5a-82fed16318e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-0f610ecd-c2e1-4f8e-adfd-d040e1613eeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-594262803-172.17.0.21-1595664759483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36189,DS-828da09a-2bbe-4514-a634-fe50ee63d2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-7be803a0-bfdd-4a78-91b6-f86b4a40cc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-73707d86-8158-4f20-8e88-95c10296b617,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-1f543fae-82c3-441a-88be-23904b8a7bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-2a14d4de-1755-4e31-b000-08662e76c76d,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-bb7c05f6-3d5c-43fb-a5a6-82042f61cd10,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-6e03587d-d91c-4e5d-87ae-0c18696d102d,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-f7809848-a3e4-48d3-9aa4-2c99c6c91193,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-594262803-172.17.0.21-1595664759483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36189,DS-828da09a-2bbe-4514-a634-fe50ee63d2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-7be803a0-bfdd-4a78-91b6-f86b4a40cc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-73707d86-8158-4f20-8e88-95c10296b617,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-1f543fae-82c3-441a-88be-23904b8a7bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-2a14d4de-1755-4e31-b000-08662e76c76d,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-bb7c05f6-3d5c-43fb-a5a6-82042f61cd10,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-6e03587d-d91c-4e5d-87ae-0c18696d102d,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-f7809848-a3e4-48d3-9aa4-2c99c6c91193,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1633307267-172.17.0.21-1595665221378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44443,DS-64756d20-210e-44c5-94a6-827784225dff,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-75f42aa8-17e1-4860-8253-d40cfececa12,DISK], DatanodeInfoWithStorage[127.0.0.1:36623,DS-7cf98325-7d56-41eb-a98d-c6c55c5fe0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-ffdf334d-4f78-4472-9e26-ca2962a2d672,DISK], DatanodeInfoWithStorage[127.0.0.1:45094,DS-e465e2b0-ad18-4421-ab36-4610a275d9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37285,DS-afc16ce7-6f81-48aa-88f8-7626c3939c88,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-aac74479-5aad-41f6-85d7-1a94569a1742,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-fbf12e66-f36e-4cc3-b244-d3dce840589e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1633307267-172.17.0.21-1595665221378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44443,DS-64756d20-210e-44c5-94a6-827784225dff,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-75f42aa8-17e1-4860-8253-d40cfececa12,DISK], DatanodeInfoWithStorage[127.0.0.1:36623,DS-7cf98325-7d56-41eb-a98d-c6c55c5fe0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-ffdf334d-4f78-4472-9e26-ca2962a2d672,DISK], DatanodeInfoWithStorage[127.0.0.1:45094,DS-e465e2b0-ad18-4421-ab36-4610a275d9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37285,DS-afc16ce7-6f81-48aa-88f8-7626c3939c88,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-aac74479-5aad-41f6-85d7-1a94569a1742,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-fbf12e66-f36e-4cc3-b244-d3dce840589e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-545781859-172.17.0.21-1595665373759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35025,DS-a03c3bb5-17a6-4a5c-9232-4052d85ff33d,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-055ec614-3646-40f2-95ea-4ee97e6ce500,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-9bd7e7f9-34a8-4603-aa9e-4299f4638d78,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-c19aa40e-fe9f-43c3-8155-21b716a0be15,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-c4710787-63db-4dcd-95a1-87a480b45ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-3a424573-d53d-4aa4-9e58-355649ecd4af,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-076c3d63-6195-42a8-a079-28bc78a885c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-8f5bf7a8-f479-4a9f-9ee4-fc038300178b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-545781859-172.17.0.21-1595665373759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35025,DS-a03c3bb5-17a6-4a5c-9232-4052d85ff33d,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-055ec614-3646-40f2-95ea-4ee97e6ce500,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-9bd7e7f9-34a8-4603-aa9e-4299f4638d78,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-c19aa40e-fe9f-43c3-8155-21b716a0be15,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-c4710787-63db-4dcd-95a1-87a480b45ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-3a424573-d53d-4aa4-9e58-355649ecd4af,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-076c3d63-6195-42a8-a079-28bc78a885c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-8f5bf7a8-f479-4a9f-9ee4-fc038300178b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1079678346-172.17.0.21-1595666349314:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41452,DS-1c9ed792-d40b-445d-af75-cb358b5dbc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-b6db4071-ac13-4ae3-8850-b030b96d42db,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-5a916792-92d1-4e04-bedd-02ebdc69530f,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-53ab4163-8501-4a5b-a78c-efdb805c3eae,DISK], DatanodeInfoWithStorage[127.0.0.1:33425,DS-7e8aac1e-6d07-4f3a-b666-44426b2b43f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-82f914d1-6a36-4ec2-b69a-f2d8a1e37aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-448e89f5-1c86-4fb7-bbdb-08f102e51fac,DISK], DatanodeInfoWithStorage[127.0.0.1:35414,DS-3120d352-1366-4299-809e-f29cf40e29bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1079678346-172.17.0.21-1595666349314:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41452,DS-1c9ed792-d40b-445d-af75-cb358b5dbc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-b6db4071-ac13-4ae3-8850-b030b96d42db,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-5a916792-92d1-4e04-bedd-02ebdc69530f,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-53ab4163-8501-4a5b-a78c-efdb805c3eae,DISK], DatanodeInfoWithStorage[127.0.0.1:33425,DS-7e8aac1e-6d07-4f3a-b666-44426b2b43f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-82f914d1-6a36-4ec2-b69a-f2d8a1e37aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-448e89f5-1c86-4fb7-bbdb-08f102e51fac,DISK], DatanodeInfoWithStorage[127.0.0.1:35414,DS-3120d352-1366-4299-809e-f29cf40e29bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-729663652-172.17.0.21-1595666428790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44545,DS-05409239-c36b-4921-8586-c322802bb452,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-7359e46f-13b5-4691-9695-09d87ae96a29,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-f6f2434c-9563-493d-805a-635a12873f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-aa3af2cc-d93b-490b-934c-50d69d110729,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-653719ce-78f8-4831-9367-a228f10af0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-de3234e8-6fd8-49c6-b864-4d8e92c7f066,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-c9ea536e-68fd-4516-b6c7-de49f6546ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-564f4e52-0dee-444a-985f-81bfda0a55ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-729663652-172.17.0.21-1595666428790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44545,DS-05409239-c36b-4921-8586-c322802bb452,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-7359e46f-13b5-4691-9695-09d87ae96a29,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-f6f2434c-9563-493d-805a-635a12873f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-aa3af2cc-d93b-490b-934c-50d69d110729,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-653719ce-78f8-4831-9367-a228f10af0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-de3234e8-6fd8-49c6-b864-4d8e92c7f066,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-c9ea536e-68fd-4516-b6c7-de49f6546ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-564f4e52-0dee-444a-985f-81bfda0a55ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1660742288-172.17.0.21-1595666537527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37795,DS-dc85dee6-2725-45e4-82fe-74c29b8cb305,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-ff5809f0-a198-4a7d-ac6e-bdf179e665fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-17cb951e-536c-44e2-a3ca-358dd5c48d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-73a289bb-5ff5-495a-b02e-d14fb939a88b,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-82dde62e-07f4-4619-8a10-45ea08629805,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-025bb119-bb61-4b1d-8ea7-4647d98c49ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-4b1892bf-a8ff-4d7c-8f6e-331793c272fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-f88d91c3-ac65-494a-b16f-8afefe985c78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1660742288-172.17.0.21-1595666537527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37795,DS-dc85dee6-2725-45e4-82fe-74c29b8cb305,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-ff5809f0-a198-4a7d-ac6e-bdf179e665fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-17cb951e-536c-44e2-a3ca-358dd5c48d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-73a289bb-5ff5-495a-b02e-d14fb939a88b,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-82dde62e-07f4-4619-8a10-45ea08629805,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-025bb119-bb61-4b1d-8ea7-4647d98c49ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-4b1892bf-a8ff-4d7c-8f6e-331793c272fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-f88d91c3-ac65-494a-b16f-8afefe985c78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1244683275-172.17.0.21-1595666579239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37508,DS-fc0c5bc6-e473-4646-8532-6629b69e9154,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-c5d6b19c-516a-4b5b-a726-93db362be36b,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-ddf88924-d824-48e7-a370-a208c4940ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-bbe62999-1294-41ff-a4d4-5e949461415e,DISK], DatanodeInfoWithStorage[127.0.0.1:42351,DS-9a8697e5-9138-4ca7-8033-9506df79596c,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-97bd9f91-6b78-4fc7-b358-9da63976cb37,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-df2eb2ad-bed2-4109-b871-1380f1f1b502,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-e7a08af1-b9b2-4caa-8d3b-007175e6f355,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1244683275-172.17.0.21-1595666579239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37508,DS-fc0c5bc6-e473-4646-8532-6629b69e9154,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-c5d6b19c-516a-4b5b-a726-93db362be36b,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-ddf88924-d824-48e7-a370-a208c4940ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-bbe62999-1294-41ff-a4d4-5e949461415e,DISK], DatanodeInfoWithStorage[127.0.0.1:42351,DS-9a8697e5-9138-4ca7-8033-9506df79596c,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-97bd9f91-6b78-4fc7-b358-9da63976cb37,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-df2eb2ad-bed2-4109-b871-1380f1f1b502,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-e7a08af1-b9b2-4caa-8d3b-007175e6f355,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1189811304-172.17.0.21-1595666746324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40231,DS-d81bf6fc-4fb8-4f8a-a63d-9e199bbbf75e,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-46014654-ae8e-43c0-a626-dbdf77b21d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-58b63eb6-3b36-4b30-884b-66512886d9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-0b5de9a2-0b53-4b83-b466-56b4302ff76e,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-006877eb-5af9-4026-a2b9-6d7ba5b92d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-7d6a7d46-a7d9-4bde-82f8-9e59f54d9c61,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-66520a64-afa9-43b1-a0b9-404d00d020a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-39bc80be-d471-42ba-858b-513ee2308a43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1189811304-172.17.0.21-1595666746324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40231,DS-d81bf6fc-4fb8-4f8a-a63d-9e199bbbf75e,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-46014654-ae8e-43c0-a626-dbdf77b21d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-58b63eb6-3b36-4b30-884b-66512886d9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-0b5de9a2-0b53-4b83-b466-56b4302ff76e,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-006877eb-5af9-4026-a2b9-6d7ba5b92d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-7d6a7d46-a7d9-4bde-82f8-9e59f54d9c61,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-66520a64-afa9-43b1-a0b9-404d00d020a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-39bc80be-d471-42ba-858b-513ee2308a43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1680492925-172.17.0.21-1595666777127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41990,DS-ebb27d1e-7cae-4bfd-9eec-e839ce49f863,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-58823938-524b-4e5d-be01-5cd231347734,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-a8890ada-1f73-44be-83f3-cfb3d5e31cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-505fce4c-034e-4aef-9123-f717a4b17a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-023bb2e6-40b5-4d4d-a6eb-9fe4e7c4d38d,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-05d0e7da-eed2-4ae4-815d-f262f0837615,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-28b17786-9981-4773-97c9-4a9102a44a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-b54b6e22-8d1c-4cb3-b140-819a357a2995,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1680492925-172.17.0.21-1595666777127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41990,DS-ebb27d1e-7cae-4bfd-9eec-e839ce49f863,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-58823938-524b-4e5d-be01-5cd231347734,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-a8890ada-1f73-44be-83f3-cfb3d5e31cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-505fce4c-034e-4aef-9123-f717a4b17a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-023bb2e6-40b5-4d4d-a6eb-9fe4e7c4d38d,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-05d0e7da-eed2-4ae4-815d-f262f0837615,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-28b17786-9981-4773-97c9-4a9102a44a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-b54b6e22-8d1c-4cb3-b140-819a357a2995,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1797423650-172.17.0.21-1595666853687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36599,DS-fb9358fe-ab2e-4131-9d3e-5f19e9fac051,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-2ac31c15-db7d-4266-b803-6f847a9ceeec,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-de752034-5141-4256-ba60-6339a742e28e,DISK], DatanodeInfoWithStorage[127.0.0.1:37284,DS-c7865dd8-a380-4e86-8ed3-92197a3b6075,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-2a94f5f6-c67e-4273-85a6-9e63666d3ead,DISK], DatanodeInfoWithStorage[127.0.0.1:42937,DS-6cd8e80c-8ef2-434d-b99a-01474becf77d,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-69f62d7d-c000-4200-b717-0761906dbce0,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-aed823ef-d070-4529-ae76-6439c7597531,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1797423650-172.17.0.21-1595666853687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36599,DS-fb9358fe-ab2e-4131-9d3e-5f19e9fac051,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-2ac31c15-db7d-4266-b803-6f847a9ceeec,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-de752034-5141-4256-ba60-6339a742e28e,DISK], DatanodeInfoWithStorage[127.0.0.1:37284,DS-c7865dd8-a380-4e86-8ed3-92197a3b6075,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-2a94f5f6-c67e-4273-85a6-9e63666d3ead,DISK], DatanodeInfoWithStorage[127.0.0.1:42937,DS-6cd8e80c-8ef2-434d-b99a-01474becf77d,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-69f62d7d-c000-4200-b717-0761906dbce0,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-aed823ef-d070-4529-ae76-6439c7597531,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1955361346-172.17.0.21-1595667045074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42573,DS-5df4ece4-590b-430c-b042-dad607457bae,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-8a81c578-30b9-427d-a204-8fffb913689e,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-b84f5e3e-e2b4-4d21-bc0f-a08a7e7e2058,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-eef47bed-9748-4b02-a344-17417d2004d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-adf8e4d9-41e3-4f3f-a3f4-5abd0b940a80,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-1fb09285-2272-4fbb-8c82-4d026b29d4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-b60906b5-2e9c-4301-82a8-a489cd6faeba,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-a2c826b6-e5c5-478c-a807-c60f2b981664,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1955361346-172.17.0.21-1595667045074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42573,DS-5df4ece4-590b-430c-b042-dad607457bae,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-8a81c578-30b9-427d-a204-8fffb913689e,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-b84f5e3e-e2b4-4d21-bc0f-a08a7e7e2058,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-eef47bed-9748-4b02-a344-17417d2004d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-adf8e4d9-41e3-4f3f-a3f4-5abd0b940a80,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-1fb09285-2272-4fbb-8c82-4d026b29d4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-b60906b5-2e9c-4301-82a8-a489cd6faeba,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-a2c826b6-e5c5-478c-a807-c60f2b981664,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-655755731-172.17.0.21-1595667128077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37963,DS-ce95cf9e-ba2a-470e-b3f4-27680241822f,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-946603a4-3076-433b-bcd4-a2cffe4ffb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-4b94128a-0f01-4cb9-b01f-37ff37c2ff70,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-2370498a-fc10-4624-aa26-32570449a84b,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-272d0df3-bb9b-4b0f-b4d7-63912d7a55b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-71104958-4bff-4c66-9185-60fe129cc542,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-987a3599-23f3-438d-a235-08c0cecabcb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-b0686716-7cd3-43db-b61b-4c255cb961f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-655755731-172.17.0.21-1595667128077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37963,DS-ce95cf9e-ba2a-470e-b3f4-27680241822f,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-946603a4-3076-433b-bcd4-a2cffe4ffb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-4b94128a-0f01-4cb9-b01f-37ff37c2ff70,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-2370498a-fc10-4624-aa26-32570449a84b,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-272d0df3-bb9b-4b0f-b4d7-63912d7a55b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-71104958-4bff-4c66-9185-60fe129cc542,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-987a3599-23f3-438d-a235-08c0cecabcb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-b0686716-7cd3-43db-b61b-4c255cb961f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1329045603-172.17.0.21-1595667396403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42376,DS-d96cfa13-2d68-4119-9f3f-f7b75068b45d,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-aba3b9d0-33e0-4c0a-b340-e76340bfa00c,DISK], DatanodeInfoWithStorage[127.0.0.1:46535,DS-b980d4f2-7e7f-4f29-bce7-a238c13a606c,DISK], DatanodeInfoWithStorage[127.0.0.1:33759,DS-8f5aea08-208b-4927-9034-ddf3308e43f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-b696e23b-41a0-47a6-aa0e-9f7b87b0065d,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-cfbc7211-b947-4513-9aeb-f758f6ab1e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-f7675fa1-667a-46d3-bb86-f23ad093a250,DISK], DatanodeInfoWithStorage[127.0.0.1:41957,DS-1b2b11ea-fe85-4578-8a57-499a4928497b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1329045603-172.17.0.21-1595667396403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42376,DS-d96cfa13-2d68-4119-9f3f-f7b75068b45d,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-aba3b9d0-33e0-4c0a-b340-e76340bfa00c,DISK], DatanodeInfoWithStorage[127.0.0.1:46535,DS-b980d4f2-7e7f-4f29-bce7-a238c13a606c,DISK], DatanodeInfoWithStorage[127.0.0.1:33759,DS-8f5aea08-208b-4927-9034-ddf3308e43f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-b696e23b-41a0-47a6-aa0e-9f7b87b0065d,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-cfbc7211-b947-4513-9aeb-f758f6ab1e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-f7675fa1-667a-46d3-bb86-f23ad093a250,DISK], DatanodeInfoWithStorage[127.0.0.1:41957,DS-1b2b11ea-fe85-4578-8a57-499a4928497b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752685392-172.17.0.21-1595667437521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42807,DS-d38b362b-5c71-4b82-aa91-483810a7ff2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-5dd08b31-4a62-4813-9e25-a0673060ab7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-6e24ad79-75b8-42d3-802d-23e83dd475ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-43e7c498-6537-4ce3-808a-8181f6a0f36c,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-ecdc8ab1-9a7a-4906-9fd8-7fdd5a863d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-4a1ff82e-b2d7-4969-bc51-521c23e458f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-3ee41a21-e483-49b2-83a0-ae8968663dec,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-c7ba07af-48ad-49e6-9d37-44a17ee272ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752685392-172.17.0.21-1595667437521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42807,DS-d38b362b-5c71-4b82-aa91-483810a7ff2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-5dd08b31-4a62-4813-9e25-a0673060ab7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-6e24ad79-75b8-42d3-802d-23e83dd475ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-43e7c498-6537-4ce3-808a-8181f6a0f36c,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-ecdc8ab1-9a7a-4906-9fd8-7fdd5a863d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-4a1ff82e-b2d7-4969-bc51-521c23e458f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-3ee41a21-e483-49b2-83a0-ae8968663dec,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-c7ba07af-48ad-49e6-9d37-44a17ee272ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2119154451-172.17.0.21-1595667477484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35180,DS-ecb2b970-6fcf-4d31-9622-c5bcfe250fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-9f72f3da-a161-47a1-a860-225cb285e8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-2edc541a-8746-4a30-8c2c-fe35c2aa0241,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-912c53fa-1355-4649-abeb-f3bee7ea3326,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-745cd8b9-3ed2-49ac-ab5d-630b430975c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-b9a708e6-b22d-461c-98b7-47182866a0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-7e283970-2c17-4a02-a624-32aaa4fb6ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-5c83ba84-f2d7-41df-b1dd-1e0ee78241ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2119154451-172.17.0.21-1595667477484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35180,DS-ecb2b970-6fcf-4d31-9622-c5bcfe250fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-9f72f3da-a161-47a1-a860-225cb285e8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-2edc541a-8746-4a30-8c2c-fe35c2aa0241,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-912c53fa-1355-4649-abeb-f3bee7ea3326,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-745cd8b9-3ed2-49ac-ab5d-630b430975c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-b9a708e6-b22d-461c-98b7-47182866a0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-7e283970-2c17-4a02-a624-32aaa4fb6ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-5c83ba84-f2d7-41df-b1dd-1e0ee78241ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1527892652-172.17.0.21-1595667661003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33563,DS-5bd0c3e2-6a8a-4ca3-ad3e-cef63617ce8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39470,DS-f5298083-cbd3-4d8f-8c74-6ae40e1a285e,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-7722b575-ce8b-4fcd-a356-610df576a9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-4806f14c-4649-4c45-b790-3d0b2d281cda,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-4a721eaa-2865-44b0-8a09-8b33c10a181a,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-23cf2562-5e8f-4372-ae2d-519e3dcbdff6,DISK], DatanodeInfoWithStorage[127.0.0.1:38483,DS-d0ae01f2-263d-484f-82f4-2a8690fb2819,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-38ca253a-5e0a-4a81-98ff-e1bbb427b523,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1527892652-172.17.0.21-1595667661003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33563,DS-5bd0c3e2-6a8a-4ca3-ad3e-cef63617ce8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39470,DS-f5298083-cbd3-4d8f-8c74-6ae40e1a285e,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-7722b575-ce8b-4fcd-a356-610df576a9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-4806f14c-4649-4c45-b790-3d0b2d281cda,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-4a721eaa-2865-44b0-8a09-8b33c10a181a,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-23cf2562-5e8f-4372-ae2d-519e3dcbdff6,DISK], DatanodeInfoWithStorage[127.0.0.1:38483,DS-d0ae01f2-263d-484f-82f4-2a8690fb2819,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-38ca253a-5e0a-4a81-98ff-e1bbb427b523,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 5828
