reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1560767808-172.17.0.21-1595909008231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35281,DS-6d121516-eff2-451b-a4ac-aaeeea13f4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-92140bcf-21fb-4b24-a72c-7d9c91dabbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-1ed595d2-1d40-46dc-81da-6cb801bc20d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-25554963-5124-48d2-9988-8c022b6042d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-e7f5dd18-845e-43cf-8ce5-f3b053fa8d22,DISK], DatanodeInfoWithStorage[127.0.0.1:38520,DS-f37a94da-1eb1-48e6-be92-4474430bab17,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-15eb2ef0-ba02-4946-a8eb-986da3102c37,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-481c81eb-f7e3-4560-a4f4-0953951c92a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1560767808-172.17.0.21-1595909008231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35281,DS-6d121516-eff2-451b-a4ac-aaeeea13f4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-92140bcf-21fb-4b24-a72c-7d9c91dabbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-1ed595d2-1d40-46dc-81da-6cb801bc20d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-25554963-5124-48d2-9988-8c022b6042d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-e7f5dd18-845e-43cf-8ce5-f3b053fa8d22,DISK], DatanodeInfoWithStorage[127.0.0.1:38520,DS-f37a94da-1eb1-48e6-be92-4474430bab17,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-15eb2ef0-ba02-4946-a8eb-986da3102c37,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-481c81eb-f7e3-4560-a4f4-0953951c92a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1383136567-172.17.0.21-1595909231181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35867,DS-a39bb566-22e7-4a6a-ba98-e93c98018411,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-c87a00a3-14cb-462d-8178-c60eccba1f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-1be5a1a3-ac05-48c3-8ef0-1def4f0cc32c,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-b2ab7acf-240d-4341-b521-aee335d3f9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-fc822ed2-5769-41e0-9236-3c5b9b2319e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-8da07a03-b354-4054-948d-86eda1ebe028,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-1a9facd4-f0bb-4a86-9393-0ed3976eee72,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-e69f1517-97a7-446d-8a8c-0a8927c9ebab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1383136567-172.17.0.21-1595909231181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35867,DS-a39bb566-22e7-4a6a-ba98-e93c98018411,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-c87a00a3-14cb-462d-8178-c60eccba1f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-1be5a1a3-ac05-48c3-8ef0-1def4f0cc32c,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-b2ab7acf-240d-4341-b521-aee335d3f9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-fc822ed2-5769-41e0-9236-3c5b9b2319e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-8da07a03-b354-4054-948d-86eda1ebe028,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-1a9facd4-f0bb-4a86-9393-0ed3976eee72,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-e69f1517-97a7-446d-8a8c-0a8927c9ebab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1684529130-172.17.0.21-1595909375888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34260,DS-32144333-1e2e-487f-9867-6f40fc12f64a,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-58c1135b-188d-4d95-84fc-1b1af1e60969,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-4f0ce749-ba72-4f85-a784-a2ea20e07753,DISK], DatanodeInfoWithStorage[127.0.0.1:40176,DS-1d6c6e6c-3ef7-419f-9030-739268def850,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-0e3d3bed-3c8c-4e88-a01f-0afe63c2dfc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-66c78101-dd16-40d7-a9e1-c950db470a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-4844272b-d2a5-4bf5-b55e-68eef5f3e4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40643,DS-e950fcb1-c409-4512-8813-482f52087d7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1684529130-172.17.0.21-1595909375888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34260,DS-32144333-1e2e-487f-9867-6f40fc12f64a,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-58c1135b-188d-4d95-84fc-1b1af1e60969,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-4f0ce749-ba72-4f85-a784-a2ea20e07753,DISK], DatanodeInfoWithStorage[127.0.0.1:40176,DS-1d6c6e6c-3ef7-419f-9030-739268def850,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-0e3d3bed-3c8c-4e88-a01f-0afe63c2dfc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-66c78101-dd16-40d7-a9e1-c950db470a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-4844272b-d2a5-4bf5-b55e-68eef5f3e4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40643,DS-e950fcb1-c409-4512-8813-482f52087d7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-161263465-172.17.0.21-1595909411449:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38206,DS-1870ff9e-7627-4b77-8bdf-cd3ef960b698,DISK], DatanodeInfoWithStorage[127.0.0.1:44069,DS-c7df3b39-9d5d-4b77-8e13-aa174f1b0f11,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-11cb959d-72af-4e89-bbaf-eb184f741fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34126,DS-451804f5-f16b-477d-80e5-2664bd46969e,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-d8298be4-5467-487e-99e1-2696ae09867d,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-753dd4d1-2e5a-4b27-8301-662d6c6e3326,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-40de482c-7345-4be5-beb3-8cc20e607d91,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-32a92007-26fd-42f5-8743-9cdf5e89029a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-161263465-172.17.0.21-1595909411449:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38206,DS-1870ff9e-7627-4b77-8bdf-cd3ef960b698,DISK], DatanodeInfoWithStorage[127.0.0.1:44069,DS-c7df3b39-9d5d-4b77-8e13-aa174f1b0f11,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-11cb959d-72af-4e89-bbaf-eb184f741fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34126,DS-451804f5-f16b-477d-80e5-2664bd46969e,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-d8298be4-5467-487e-99e1-2696ae09867d,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-753dd4d1-2e5a-4b27-8301-662d6c6e3326,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-40de482c-7345-4be5-beb3-8cc20e607d91,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-32a92007-26fd-42f5-8743-9cdf5e89029a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2034939526-172.17.0.21-1595909939851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42112,DS-14cd346b-77dd-41ed-8b72-0f22fe636052,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-0594820a-c2fa-4938-bf19-aec20fa14aff,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-65b34e85-ca66-47ff-91ad-217c38ac622e,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-040cf289-4389-4b29-94d6-50b3ec6f178e,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-07ddea18-98c4-475d-8f09-2f243acb7a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40197,DS-b0a8dc3c-33bf-465a-91fd-8c2ec1c7d880,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-7451a381-cd94-4c7d-ac93-462ae16213dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-55c07c13-6a2d-43b3-9ae3-9111b8631126,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2034939526-172.17.0.21-1595909939851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42112,DS-14cd346b-77dd-41ed-8b72-0f22fe636052,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-0594820a-c2fa-4938-bf19-aec20fa14aff,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-65b34e85-ca66-47ff-91ad-217c38ac622e,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-040cf289-4389-4b29-94d6-50b3ec6f178e,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-07ddea18-98c4-475d-8f09-2f243acb7a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40197,DS-b0a8dc3c-33bf-465a-91fd-8c2ec1c7d880,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-7451a381-cd94-4c7d-ac93-462ae16213dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-55c07c13-6a2d-43b3-9ae3-9111b8631126,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-286582557-172.17.0.21-1595909977193:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42561,DS-1097fce0-f91e-48af-a570-925e84d8689a,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-627a1044-a13a-4887-8c3e-176ca980d146,DISK], DatanodeInfoWithStorage[127.0.0.1:40270,DS-6edcf72b-abff-4579-884b-5e69264e3c08,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-b2f6c4bd-1948-4d68-8238-541d4da85ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-af1fda03-0334-4892-9cea-ae9f916a39a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-06a68fe1-326a-419a-8d4d-b4e2913fda64,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-6b595e36-c379-48aa-9175-ddd5b0e186f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-f2288cbe-651d-4afa-b253-877a9ab50274,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-286582557-172.17.0.21-1595909977193:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42561,DS-1097fce0-f91e-48af-a570-925e84d8689a,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-627a1044-a13a-4887-8c3e-176ca980d146,DISK], DatanodeInfoWithStorage[127.0.0.1:40270,DS-6edcf72b-abff-4579-884b-5e69264e3c08,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-b2f6c4bd-1948-4d68-8238-541d4da85ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-af1fda03-0334-4892-9cea-ae9f916a39a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-06a68fe1-326a-419a-8d4d-b4e2913fda64,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-6b595e36-c379-48aa-9175-ddd5b0e186f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-f2288cbe-651d-4afa-b253-877a9ab50274,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1899384397-172.17.0.21-1595910056095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44664,DS-d827c476-0c5f-4ddd-9941-4859a37f69e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-7bfe1c0f-447c-4d1c-b295-a3f9c22d8687,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-f387994a-b8bf-4946-9c84-83c6af97d2be,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-1f583859-9b16-435a-bc9f-ac161e297ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-2e883996-c82b-4e40-a604-b1d23de3521a,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-ef068eda-d53c-49c1-9a43-ae5d80395280,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-3e4e23b3-b563-4240-88d1-7a3d02c8d54d,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-802c35ba-9a09-412d-b662-fc2c31b3e332,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1899384397-172.17.0.21-1595910056095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44664,DS-d827c476-0c5f-4ddd-9941-4859a37f69e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-7bfe1c0f-447c-4d1c-b295-a3f9c22d8687,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-f387994a-b8bf-4946-9c84-83c6af97d2be,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-1f583859-9b16-435a-bc9f-ac161e297ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-2e883996-c82b-4e40-a604-b1d23de3521a,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-ef068eda-d53c-49c1-9a43-ae5d80395280,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-3e4e23b3-b563-4240-88d1-7a3d02c8d54d,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-802c35ba-9a09-412d-b662-fc2c31b3e332,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1738607451-172.17.0.21-1595910344568:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43101,DS-9af068d3-2ef5-4980-a875-3b566c1325a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-c9af3ae5-0775-4580-a6f1-bed1dae7c266,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-466faec0-91e4-47ce-b0cc-73a501fea459,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-0a8f77eb-f278-4a75-8ce7-9a3c0d0a6f85,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-3273b4fc-dcdf-4c85-bebe-709e747e1738,DISK], DatanodeInfoWithStorage[127.0.0.1:40707,DS-fdab6656-8736-4ee3-b25f-f12213457537,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-38b8bf41-7422-4c5e-afd3-19905cadf82a,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-e4cb9767-73ff-44d1-a6a6-d060fad4f22d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1738607451-172.17.0.21-1595910344568:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43101,DS-9af068d3-2ef5-4980-a875-3b566c1325a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-c9af3ae5-0775-4580-a6f1-bed1dae7c266,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-466faec0-91e4-47ce-b0cc-73a501fea459,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-0a8f77eb-f278-4a75-8ce7-9a3c0d0a6f85,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-3273b4fc-dcdf-4c85-bebe-709e747e1738,DISK], DatanodeInfoWithStorage[127.0.0.1:40707,DS-fdab6656-8736-4ee3-b25f-f12213457537,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-38b8bf41-7422-4c5e-afd3-19905cadf82a,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-e4cb9767-73ff-44d1-a6a6-d060fad4f22d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-733508487-172.17.0.21-1595910384785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36527,DS-5d7025e8-dd10-427c-a55f-f1be2c98b185,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-853010cd-5b97-4e73-a94d-e73997a9e5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-276a6aa8-f8be-4df2-9a7a-a12e5a5e8520,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-c1d5340a-5272-4491-9fb1-e05cefe6c810,DISK], DatanodeInfoWithStorage[127.0.0.1:38974,DS-75419c30-7c75-4379-abfe-94a0075a9817,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-df66d43f-5d87-4749-9c44-cc44514b672c,DISK], DatanodeInfoWithStorage[127.0.0.1:36251,DS-31987119-9b4e-4fa0-a44c-8588c7d87897,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-cc87c713-3076-43df-af31-c54daa53e4da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-733508487-172.17.0.21-1595910384785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36527,DS-5d7025e8-dd10-427c-a55f-f1be2c98b185,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-853010cd-5b97-4e73-a94d-e73997a9e5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-276a6aa8-f8be-4df2-9a7a-a12e5a5e8520,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-c1d5340a-5272-4491-9fb1-e05cefe6c810,DISK], DatanodeInfoWithStorage[127.0.0.1:38974,DS-75419c30-7c75-4379-abfe-94a0075a9817,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-df66d43f-5d87-4749-9c44-cc44514b672c,DISK], DatanodeInfoWithStorage[127.0.0.1:36251,DS-31987119-9b4e-4fa0-a44c-8588c7d87897,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-cc87c713-3076-43df-af31-c54daa53e4da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1552462416-172.17.0.21-1595910859199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39248,DS-57d81181-3657-463d-b997-c7b4e2392e96,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-569d070e-fb8e-4b2c-b04c-6bfb5438622f,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-986e4a1e-8a29-43d7-8909-e9925cf51d76,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-31c7c416-45d4-4e89-a638-47ece426c76f,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-17817184-4269-46fa-9b31-8bb92d57674e,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-45a51751-3022-459e-aad2-7e8a3dbca10f,DISK], DatanodeInfoWithStorage[127.0.0.1:44240,DS-5db6495f-7a69-459d-8d76-43c74583fcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41380,DS-ef0e90f6-a4d9-48f0-a072-bca47e879bf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1552462416-172.17.0.21-1595910859199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39248,DS-57d81181-3657-463d-b997-c7b4e2392e96,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-569d070e-fb8e-4b2c-b04c-6bfb5438622f,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-986e4a1e-8a29-43d7-8909-e9925cf51d76,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-31c7c416-45d4-4e89-a638-47ece426c76f,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-17817184-4269-46fa-9b31-8bb92d57674e,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-45a51751-3022-459e-aad2-7e8a3dbca10f,DISK], DatanodeInfoWithStorage[127.0.0.1:44240,DS-5db6495f-7a69-459d-8d76-43c74583fcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41380,DS-ef0e90f6-a4d9-48f0-a072-bca47e879bf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-459791248-172.17.0.21-1595911131157:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34474,DS-ca1b321e-49c4-4af2-8fb9-7e8e07d10100,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-ea017a2e-3b34-46d1-a296-5a4b73db338f,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-f0784b56-ee9a-442b-970d-f2625be3dc0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36303,DS-69e8d75e-4050-4f86-a82b-35f699f75465,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-267566eb-4afc-468e-8218-7890743ccfa7,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-43ae6b4a-470a-4e20-b803-e909df4da6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-3ce6d08c-353c-41f6-95e8-b54e514635bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39847,DS-4faca8ef-3cc9-4b66-822c-c5b8f335c711,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-459791248-172.17.0.21-1595911131157:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34474,DS-ca1b321e-49c4-4af2-8fb9-7e8e07d10100,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-ea017a2e-3b34-46d1-a296-5a4b73db338f,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-f0784b56-ee9a-442b-970d-f2625be3dc0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36303,DS-69e8d75e-4050-4f86-a82b-35f699f75465,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-267566eb-4afc-468e-8218-7890743ccfa7,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-43ae6b4a-470a-4e20-b803-e909df4da6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-3ce6d08c-353c-41f6-95e8-b54e514635bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39847,DS-4faca8ef-3cc9-4b66-822c-c5b8f335c711,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1574188911-172.17.0.21-1595911506212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35778,DS-33d6af47-6832-4b74-8314-6a05512871dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-cc585588-c7d9-46d8-94ff-06005cb52f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-57e0d6e6-7f8a-4ac6-a90b-63c03656dc20,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-cdb10ac8-6e45-417a-9a5c-34a9f7888cce,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-5800caa2-e3a8-4bfa-8319-6e84ad158426,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-688945eb-c331-47c5-a9a1-b3efd42bc0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-83cc6a22-a368-4cbd-bce9-82c17c3e31d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-4f5269f2-a6a1-4459-b366-c70dc48017aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1574188911-172.17.0.21-1595911506212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35778,DS-33d6af47-6832-4b74-8314-6a05512871dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-cc585588-c7d9-46d8-94ff-06005cb52f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-57e0d6e6-7f8a-4ac6-a90b-63c03656dc20,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-cdb10ac8-6e45-417a-9a5c-34a9f7888cce,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-5800caa2-e3a8-4bfa-8319-6e84ad158426,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-688945eb-c331-47c5-a9a1-b3efd42bc0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-83cc6a22-a368-4cbd-bce9-82c17c3e31d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-4f5269f2-a6a1-4459-b366-c70dc48017aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1421814836-172.17.0.21-1595911775526:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40295,DS-a61a3415-f2cd-45fb-8903-06af50849688,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-74029fce-2cf1-4510-9908-2356d63ddcf9,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-b02d5cff-b2e6-48d2-960b-b18cdb8192b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34822,DS-bcbc1800-f258-4b7e-9c3f-dd105d8e6eda,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-5b7772b2-b58a-433b-b63d-d7dd40e2273b,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-2221507d-45ac-4665-958d-03b302c10fab,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-853ffb4f-0c86-4d61-8ce2-adcebce284de,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-b053b13d-6253-4d99-8b17-5713bd2ccca2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1421814836-172.17.0.21-1595911775526:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40295,DS-a61a3415-f2cd-45fb-8903-06af50849688,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-74029fce-2cf1-4510-9908-2356d63ddcf9,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-b02d5cff-b2e6-48d2-960b-b18cdb8192b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34822,DS-bcbc1800-f258-4b7e-9c3f-dd105d8e6eda,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-5b7772b2-b58a-433b-b63d-d7dd40e2273b,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-2221507d-45ac-4665-958d-03b302c10fab,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-853ffb4f-0c86-4d61-8ce2-adcebce284de,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-b053b13d-6253-4d99-8b17-5713bd2ccca2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1746949181-172.17.0.21-1595912131319:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40974,DS-329865f8-d349-45eb-b33a-535d53dc061b,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-21b29f6f-f0f4-43fb-9c09-bfe3cf48c728,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-3e0827bb-7fb2-44c3-99f6-003d82ec82ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-d9b6826e-0e75-43f9-943f-25610f83837a,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-85cffed2-fef7-466d-8f4c-b5a450510218,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-38fdc12f-a83b-4559-a109-cee3d350f0be,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-84b5e581-c426-46c5-981a-f14e9528be85,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-287dc55d-44cd-49d5-a1f4-eb5dd8dd8ff8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1746949181-172.17.0.21-1595912131319:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40974,DS-329865f8-d349-45eb-b33a-535d53dc061b,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-21b29f6f-f0f4-43fb-9c09-bfe3cf48c728,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-3e0827bb-7fb2-44c3-99f6-003d82ec82ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-d9b6826e-0e75-43f9-943f-25610f83837a,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-85cffed2-fef7-466d-8f4c-b5a450510218,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-38fdc12f-a83b-4559-a109-cee3d350f0be,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-84b5e581-c426-46c5-981a-f14e9528be85,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-287dc55d-44cd-49d5-a1f4-eb5dd8dd8ff8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1462552460-172.17.0.21-1595912365947:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43349,DS-ac3b2591-458a-42f5-8303-c9f0deb660e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-8e104383-362f-457c-afb7-89fed9e4fab9,DISK], DatanodeInfoWithStorage[127.0.0.1:34033,DS-895fa3da-53da-4bdb-b6b4-0adbd9988348,DISK], DatanodeInfoWithStorage[127.0.0.1:45430,DS-6d63665d-1c90-417b-82ea-7208cd887656,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-a3647c25-afa5-413a-bec6-d1cd5ee311fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-6f10bd70-9115-4b50-8ebb-27e5ce0f0d95,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-7e4ea212-59b2-43d9-8600-abfc8fa6bf68,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-210640bc-7cae-497b-b52e-9c08d1919b72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1462552460-172.17.0.21-1595912365947:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43349,DS-ac3b2591-458a-42f5-8303-c9f0deb660e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-8e104383-362f-457c-afb7-89fed9e4fab9,DISK], DatanodeInfoWithStorage[127.0.0.1:34033,DS-895fa3da-53da-4bdb-b6b4-0adbd9988348,DISK], DatanodeInfoWithStorage[127.0.0.1:45430,DS-6d63665d-1c90-417b-82ea-7208cd887656,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-a3647c25-afa5-413a-bec6-d1cd5ee311fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-6f10bd70-9115-4b50-8ebb-27e5ce0f0d95,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-7e4ea212-59b2-43d9-8600-abfc8fa6bf68,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-210640bc-7cae-497b-b52e-9c08d1919b72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1475019259-172.17.0.21-1595912465471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42188,DS-f1ecfdae-2ddb-44c4-9cc2-4679b7b7055d,DISK], DatanodeInfoWithStorage[127.0.0.1:38022,DS-d092ee8f-a7ed-44fc-a0b7-fa525bfd159a,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-b0585e54-5c32-49ea-9489-703c8d84b051,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-e59b4304-fd1b-4427-b77b-20cf6539182d,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-227d6842-92cf-482f-8312-dabc6fa9a560,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-ed121ea7-5ad8-4ed7-92c3-9a48d7225268,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-d584a697-ee46-4da8-a8ea-9c5a6c2d4000,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-58805196-0bea-4969-b75b-1d382109e9fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1475019259-172.17.0.21-1595912465471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42188,DS-f1ecfdae-2ddb-44c4-9cc2-4679b7b7055d,DISK], DatanodeInfoWithStorage[127.0.0.1:38022,DS-d092ee8f-a7ed-44fc-a0b7-fa525bfd159a,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-b0585e54-5c32-49ea-9489-703c8d84b051,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-e59b4304-fd1b-4427-b77b-20cf6539182d,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-227d6842-92cf-482f-8312-dabc6fa9a560,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-ed121ea7-5ad8-4ed7-92c3-9a48d7225268,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-d584a697-ee46-4da8-a8ea-9c5a6c2d4000,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-58805196-0bea-4969-b75b-1d382109e9fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-627642100-172.17.0.21-1595912596874:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43180,DS-7f60d651-a3cc-4093-9291-d39e1d6b137f,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-06c9a691-0102-41bf-a7a7-ff0076d9dd2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-fba5134a-a2cb-44b8-b00e-a878ca84b70d,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-304317e2-d310-4d2a-b456-ffda7ecc48e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-d1905d7a-62e4-40f4-a8ad-06bc3ac877d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-4fd056de-c19b-41ee-a772-d0bd5e419abb,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-55d43166-eeaa-467b-8a62-15c7774a4f87,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-d54743ac-5bbc-4b73-8978-0ed6aa637d45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-627642100-172.17.0.21-1595912596874:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43180,DS-7f60d651-a3cc-4093-9291-d39e1d6b137f,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-06c9a691-0102-41bf-a7a7-ff0076d9dd2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-fba5134a-a2cb-44b8-b00e-a878ca84b70d,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-304317e2-d310-4d2a-b456-ffda7ecc48e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-d1905d7a-62e4-40f4-a8ad-06bc3ac877d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-4fd056de-c19b-41ee-a772-d0bd5e419abb,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-55d43166-eeaa-467b-8a62-15c7774a4f87,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-d54743ac-5bbc-4b73-8978-0ed6aa637d45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1638273774-172.17.0.21-1595912670199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40064,DS-0e207adf-a7c0-4877-b355-80805a8f4701,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-793525c4-afd9-47e4-b3a8-45f443c16b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-bae8103a-a0a0-422e-b1f4-b9152af3781a,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-347a1b3a-ea7e-4718-83c6-65afb34e1dba,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-32f3de3e-6990-45a6-9f3b-5cb1abb4be03,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-b07ac14e-c441-40f1-aef5-1f347ad0c8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-d3c95a02-933e-498a-a666-9ab9bd48952b,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-d7e52872-d4e9-4b7b-a505-c42f9a6b503f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1638273774-172.17.0.21-1595912670199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40064,DS-0e207adf-a7c0-4877-b355-80805a8f4701,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-793525c4-afd9-47e4-b3a8-45f443c16b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-bae8103a-a0a0-422e-b1f4-b9152af3781a,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-347a1b3a-ea7e-4718-83c6-65afb34e1dba,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-32f3de3e-6990-45a6-9f3b-5cb1abb4be03,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-b07ac14e-c441-40f1-aef5-1f347ad0c8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-d3c95a02-933e-498a-a666-9ab9bd48952b,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-d7e52872-d4e9-4b7b-a505-c42f9a6b503f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-206068395-172.17.0.21-1595912783221:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40766,DS-7f2eca82-4160-41ee-8b02-a90eb0f8c21d,DISK], DatanodeInfoWithStorage[127.0.0.1:45997,DS-f70353e5-f91a-4e38-9ee3-5b2f04c6d2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-92f6ff2f-e46c-40f9-9e13-2d1ce0d7cea7,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-7a0d015e-d358-4d84-9de6-bff7f4cef54e,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-a0794d59-7a4c-4a36-a09a-1779ced9368d,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-4ba8bf37-34e6-44a0-8f29-00bc67f2b7db,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-797c8c33-ddbf-4ce3-9714-f501fadd1c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-e953e260-e9c3-4161-86d1-85becbd40c7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-206068395-172.17.0.21-1595912783221:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40766,DS-7f2eca82-4160-41ee-8b02-a90eb0f8c21d,DISK], DatanodeInfoWithStorage[127.0.0.1:45997,DS-f70353e5-f91a-4e38-9ee3-5b2f04c6d2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-92f6ff2f-e46c-40f9-9e13-2d1ce0d7cea7,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-7a0d015e-d358-4d84-9de6-bff7f4cef54e,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-a0794d59-7a4c-4a36-a09a-1779ced9368d,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-4ba8bf37-34e6-44a0-8f29-00bc67f2b7db,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-797c8c33-ddbf-4ce3-9714-f501fadd1c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-e953e260-e9c3-4161-86d1-85becbd40c7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1943584463-172.17.0.21-1595913073874:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38318,DS-60d079b5-9247-406e-a3fe-7cfb2617159a,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-0d0011a1-42c6-496d-b6af-98ad3122ba73,DISK], DatanodeInfoWithStorage[127.0.0.1:42578,DS-4471d420-57da-4334-ad54-0c93a7167b41,DISK], DatanodeInfoWithStorage[127.0.0.1:34329,DS-2dbc580d-2361-4a3d-accd-f861b6079401,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-20396632-6eee-49fc-9e41-271447728e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-bafcffc0-50e2-4b0d-acf5-6bcbca9b1d94,DISK], DatanodeInfoWithStorage[127.0.0.1:35309,DS-0e420eca-25c7-45c5-a359-78e6156d26cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34089,DS-e818312d-c1a3-41b0-ba82-2b6a449833f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1943584463-172.17.0.21-1595913073874:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38318,DS-60d079b5-9247-406e-a3fe-7cfb2617159a,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-0d0011a1-42c6-496d-b6af-98ad3122ba73,DISK], DatanodeInfoWithStorage[127.0.0.1:42578,DS-4471d420-57da-4334-ad54-0c93a7167b41,DISK], DatanodeInfoWithStorage[127.0.0.1:34329,DS-2dbc580d-2361-4a3d-accd-f861b6079401,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-20396632-6eee-49fc-9e41-271447728e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-bafcffc0-50e2-4b0d-acf5-6bcbca9b1d94,DISK], DatanodeInfoWithStorage[127.0.0.1:35309,DS-0e420eca-25c7-45c5-a359-78e6156d26cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34089,DS-e818312d-c1a3-41b0-ba82-2b6a449833f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1519633556-172.17.0.21-1595913149774:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33895,DS-8bf8e0bf-7413-435a-9cc8-7d14da2f39a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-d13d925a-cbdf-4730-a0a9-3216872a8573,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-fe6cd211-95a0-4fe0-9639-f458913d1055,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-3419c3cf-237a-4f32-a18c-d29fb634cc4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44795,DS-6c0fa062-aa17-4597-8697-ed31a3f23b13,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-a692d536-7d18-4acb-8276-14fa8f5b1678,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-29494020-9cb9-4539-9a79-14c01a94519f,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-a54a7446-0022-4a38-b4c0-96771c37b748,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1519633556-172.17.0.21-1595913149774:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33895,DS-8bf8e0bf-7413-435a-9cc8-7d14da2f39a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-d13d925a-cbdf-4730-a0a9-3216872a8573,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-fe6cd211-95a0-4fe0-9639-f458913d1055,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-3419c3cf-237a-4f32-a18c-d29fb634cc4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44795,DS-6c0fa062-aa17-4597-8697-ed31a3f23b13,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-a692d536-7d18-4acb-8276-14fa8f5b1678,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-29494020-9cb9-4539-9a79-14c01a94519f,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-a54a7446-0022-4a38-b4c0-96771c37b748,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1832632891-172.17.0.21-1595913372147:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45567,DS-fb0a7faf-3504-4cb3-b7a8-1e4655f32d11,DISK], DatanodeInfoWithStorage[127.0.0.1:34751,DS-f2456a2b-9865-4576-b188-c86fd186325c,DISK], DatanodeInfoWithStorage[127.0.0.1:35891,DS-fc7f6764-c1e4-48fe-bf42-4e7bd453d42b,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-5a44f5e4-b1fd-4ff5-97e9-87cbd3b5bc61,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-f109685a-4102-4e1f-ba4e-d1993704598e,DISK], DatanodeInfoWithStorage[127.0.0.1:35477,DS-d0ec980f-0d3e-4247-96bf-784d8ec74e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-5c0688e4-30c8-4ab6-b489-5fc851e88413,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-4e6628b9-4984-455a-af6d-9f412993f2d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1832632891-172.17.0.21-1595913372147:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45567,DS-fb0a7faf-3504-4cb3-b7a8-1e4655f32d11,DISK], DatanodeInfoWithStorage[127.0.0.1:34751,DS-f2456a2b-9865-4576-b188-c86fd186325c,DISK], DatanodeInfoWithStorage[127.0.0.1:35891,DS-fc7f6764-c1e4-48fe-bf42-4e7bd453d42b,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-5a44f5e4-b1fd-4ff5-97e9-87cbd3b5bc61,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-f109685a-4102-4e1f-ba4e-d1993704598e,DISK], DatanodeInfoWithStorage[127.0.0.1:35477,DS-d0ec980f-0d3e-4247-96bf-784d8ec74e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-5c0688e4-30c8-4ab6-b489-5fc851e88413,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-4e6628b9-4984-455a-af6d-9f412993f2d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2043421614-172.17.0.21-1595913486063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37558,DS-248b8a31-7416-4259-bd02-773157885ace,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-a92a61c1-5be8-4883-8c6c-c2fd5ee53a05,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-366c40af-4fec-4e01-8e52-a0091b38edd6,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-b91867e5-8b28-4001-821c-a1667a5772e9,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-9e487788-659b-4242-82fe-fb2287fd90e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-22dcecb6-9e30-41a3-9a6f-562b97577594,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-fbe629bb-b733-4d9c-a529-89c6398b1e97,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-6ad055f1-89d9-4665-8d56-3167b9c582bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2043421614-172.17.0.21-1595913486063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37558,DS-248b8a31-7416-4259-bd02-773157885ace,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-a92a61c1-5be8-4883-8c6c-c2fd5ee53a05,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-366c40af-4fec-4e01-8e52-a0091b38edd6,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-b91867e5-8b28-4001-821c-a1667a5772e9,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-9e487788-659b-4242-82fe-fb2287fd90e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-22dcecb6-9e30-41a3-9a6f-562b97577594,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-fbe629bb-b733-4d9c-a529-89c6398b1e97,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-6ad055f1-89d9-4665-8d56-3167b9c582bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1469357804-172.17.0.21-1595913773543:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40655,DS-286c273c-8fc7-4cbd-ae31-5aa625bce005,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-e693bff1-5b19-4e4d-8b52-a13e5228e425,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-6e62bc2b-acdc-4aa4-b532-1d6bee59a909,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-7163f509-b93e-4ab5-9340-06c47686dbc1,DISK], DatanodeInfoWithStorage[127.0.0.1:44984,DS-26f2956e-4b15-459d-b72b-050d7ca11711,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-54995bec-e631-461a-9173-deee92044397,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-f7b8a11b-3b08-4247-aa01-051029bdf6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-6b06c37f-499d-4593-b7eb-b961315a2a45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1469357804-172.17.0.21-1595913773543:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40655,DS-286c273c-8fc7-4cbd-ae31-5aa625bce005,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-e693bff1-5b19-4e4d-8b52-a13e5228e425,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-6e62bc2b-acdc-4aa4-b532-1d6bee59a909,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-7163f509-b93e-4ab5-9340-06c47686dbc1,DISK], DatanodeInfoWithStorage[127.0.0.1:44984,DS-26f2956e-4b15-459d-b72b-050d7ca11711,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-54995bec-e631-461a-9173-deee92044397,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-f7b8a11b-3b08-4247-aa01-051029bdf6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-6b06c37f-499d-4593-b7eb-b961315a2a45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-39644790-172.17.0.21-1595914099579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46440,DS-df6c3fc0-d05e-4b79-bcdc-8bc1a5f98961,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-9e376a6a-2fb8-456c-979f-a31e7d8ded47,DISK], DatanodeInfoWithStorage[127.0.0.1:42853,DS-51dcdc5b-39e6-4af4-ad96-573fd6874255,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-827b8690-7c36-4606-8448-9e49b5b646c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-34e2e827-1efc-4020-9aa4-054e464c524a,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-de3bdd0c-c744-4514-86f0-ef6bd348aa32,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-4ef4612b-3f63-4b01-9931-35df8f7bd96e,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-fd95f56e-e538-4d97-9fb2-c5157de77676,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-39644790-172.17.0.21-1595914099579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46440,DS-df6c3fc0-d05e-4b79-bcdc-8bc1a5f98961,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-9e376a6a-2fb8-456c-979f-a31e7d8ded47,DISK], DatanodeInfoWithStorage[127.0.0.1:42853,DS-51dcdc5b-39e6-4af4-ad96-573fd6874255,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-827b8690-7c36-4606-8448-9e49b5b646c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-34e2e827-1efc-4020-9aa4-054e464c524a,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-de3bdd0c-c744-4514-86f0-ef6bd348aa32,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-4ef4612b-3f63-4b01-9931-35df8f7bd96e,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-fd95f56e-e538-4d97-9fb2-c5157de77676,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5336
