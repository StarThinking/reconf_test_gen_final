reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 30
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 30
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-771844870-172.17.0.4-1595546199332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46150,DS-0f1d29ca-72ec-4095-a225-e7e8e905f927,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-12d98844-0288-4b84-882f-bb7be7f6a709,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-82405d72-8065-4fa8-bc9c-323806768b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-a9d8b8b1-4a42-47a0-bfd0-6c02aa824fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-1a916c3d-1cb8-48e0-94ca-37c68e45e570,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-24de0f35-d448-4293-aceb-4bb0a76ea5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-778dbc61-d9c4-46f8-89ce-330ec9479633,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-4d0a5021-24e9-40bd-ae9a-4a289f505647,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-771844870-172.17.0.4-1595546199332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46150,DS-0f1d29ca-72ec-4095-a225-e7e8e905f927,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-12d98844-0288-4b84-882f-bb7be7f6a709,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-82405d72-8065-4fa8-bc9c-323806768b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-a9d8b8b1-4a42-47a0-bfd0-6c02aa824fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-1a916c3d-1cb8-48e0-94ca-37c68e45e570,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-24de0f35-d448-4293-aceb-4bb0a76ea5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-778dbc61-d9c4-46f8-89ce-330ec9479633,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-4d0a5021-24e9-40bd-ae9a-4a289f505647,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 30
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-763943758-172.17.0.4-1595546230328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33501,DS-39f1243f-7186-4d34-8a56-36155b1ccdb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-37ee7003-b221-43b3-a7a5-972fea80617b,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-d386c530-816c-49b5-9e66-de003c0017f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-35a4083c-726f-400c-ae2f-eeecb309ed62,DISK], DatanodeInfoWithStorage[127.0.0.1:40314,DS-dbfb1945-af82-45a8-b773-0822b56b65c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-93061775-5bb5-4715-b6f1-a7a0e7796199,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-e45c3bd1-5411-443a-9463-9144eaf87446,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-2bdaefb5-63ef-44e4-8501-ed966ca8584e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-763943758-172.17.0.4-1595546230328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33501,DS-39f1243f-7186-4d34-8a56-36155b1ccdb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-37ee7003-b221-43b3-a7a5-972fea80617b,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-d386c530-816c-49b5-9e66-de003c0017f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-35a4083c-726f-400c-ae2f-eeecb309ed62,DISK], DatanodeInfoWithStorage[127.0.0.1:40314,DS-dbfb1945-af82-45a8-b773-0822b56b65c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-93061775-5bb5-4715-b6f1-a7a0e7796199,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-e45c3bd1-5411-443a-9463-9144eaf87446,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-2bdaefb5-63ef-44e4-8501-ed966ca8584e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 30
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-244491114-172.17.0.4-1595546643553:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35758,DS-db6bda71-77b5-48ec-8188-4f552daa2b47,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-4e4b9b51-cb7d-4000-9e20-0ecb4926e15e,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-30ca1e2e-09e8-44b3-92c9-b9d44854b874,DISK], DatanodeInfoWithStorage[127.0.0.1:40643,DS-dd9c90de-805c-472e-8a58-455fc31fc396,DISK], DatanodeInfoWithStorage[127.0.0.1:40459,DS-f9d0a7dd-045e-459f-bfc8-1c46fb4c9e93,DISK], DatanodeInfoWithStorage[127.0.0.1:46115,DS-aed1fbd5-bf2c-4c4f-aecc-2f3df9991c72,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-ac6d80d4-3213-4a6e-b26f-d68c27e0be37,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-c74904d0-5d79-4972-804e-17d7f2df6f40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-244491114-172.17.0.4-1595546643553:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35758,DS-db6bda71-77b5-48ec-8188-4f552daa2b47,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-4e4b9b51-cb7d-4000-9e20-0ecb4926e15e,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-30ca1e2e-09e8-44b3-92c9-b9d44854b874,DISK], DatanodeInfoWithStorage[127.0.0.1:40643,DS-dd9c90de-805c-472e-8a58-455fc31fc396,DISK], DatanodeInfoWithStorage[127.0.0.1:40459,DS-f9d0a7dd-045e-459f-bfc8-1c46fb4c9e93,DISK], DatanodeInfoWithStorage[127.0.0.1:46115,DS-aed1fbd5-bf2c-4c4f-aecc-2f3df9991c72,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-ac6d80d4-3213-4a6e-b26f-d68c27e0be37,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-c74904d0-5d79-4972-804e-17d7f2df6f40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 30
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1298225014-172.17.0.4-1595546933490:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41068,DS-3ec2570a-e749-4bb4-8ab1-950be9ede51e,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-e1d44121-a667-448c-885b-822f6a6b6aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-9351a734-b1a7-4fc1-8970-b6d59b092966,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-c89cea35-3226-4b0d-8aa9-f08c03b7be0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-e8f34fb6-63c9-4e91-a998-213ffc2b1f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-8e87cecd-187b-4ae3-ada4-dd6e28a7fbae,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-8e761feb-db08-47fb-b194-a04e6e834f60,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-ef78b4d0-22ec-45d2-8064-5bd73a721066,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1298225014-172.17.0.4-1595546933490:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41068,DS-3ec2570a-e749-4bb4-8ab1-950be9ede51e,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-e1d44121-a667-448c-885b-822f6a6b6aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-9351a734-b1a7-4fc1-8970-b6d59b092966,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-c89cea35-3226-4b0d-8aa9-f08c03b7be0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-e8f34fb6-63c9-4e91-a998-213ffc2b1f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-8e87cecd-187b-4ae3-ada4-dd6e28a7fbae,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-8e761feb-db08-47fb-b194-a04e6e834f60,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-ef78b4d0-22ec-45d2-8064-5bd73a721066,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 30
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1906254287-172.17.0.4-1595547225915:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46856,DS-4f9f4c04-f167-4b61-900d-e6becd37edd2,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-63a20578-3d06-41e8-b5f5-c9be4707dfe5,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-8eb57b55-f3f2-4233-a009-a6497bbe35b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-67802400-3a2c-47c1-918f-afb232ba63d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-3f44d713-9dc9-4830-b5fc-f9e47bd4fda1,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-b44a8151-5bd0-4900-98e4-6cce643496c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-93b003ec-ed23-47d2-9f0d-9f86386e18d5,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-9e022da7-0048-43b7-9dba-795eb1f4ee10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1906254287-172.17.0.4-1595547225915:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46856,DS-4f9f4c04-f167-4b61-900d-e6becd37edd2,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-63a20578-3d06-41e8-b5f5-c9be4707dfe5,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-8eb57b55-f3f2-4233-a009-a6497bbe35b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-67802400-3a2c-47c1-918f-afb232ba63d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-3f44d713-9dc9-4830-b5fc-f9e47bd4fda1,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-b44a8151-5bd0-4900-98e4-6cce643496c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-93b003ec-ed23-47d2-9f0d-9f86386e18d5,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-9e022da7-0048-43b7-9dba-795eb1f4ee10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 30
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2056690179-172.17.0.4-1595547265785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35181,DS-55f84b61-7e4a-459a-9a95-df7bc43839dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-23d2d7b8-99eb-4980-acf5-7c9c9707a31d,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-639a5e68-6c8e-4a14-b76f-b6684987caa5,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-34d5f8b7-3772-47aa-9385-181c90950005,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-908c7f87-4fab-4c75-8574-55bb3c2ef374,DISK], DatanodeInfoWithStorage[127.0.0.1:40860,DS-39f08ba8-66d1-4756-85af-52d181c4f8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-870ccd24-cd9c-43cb-873b-7347446a9ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-5b0b637d-3f9e-445f-aa3f-9e7c1b423ccb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2056690179-172.17.0.4-1595547265785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35181,DS-55f84b61-7e4a-459a-9a95-df7bc43839dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-23d2d7b8-99eb-4980-acf5-7c9c9707a31d,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-639a5e68-6c8e-4a14-b76f-b6684987caa5,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-34d5f8b7-3772-47aa-9385-181c90950005,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-908c7f87-4fab-4c75-8574-55bb3c2ef374,DISK], DatanodeInfoWithStorage[127.0.0.1:40860,DS-39f08ba8-66d1-4756-85af-52d181c4f8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-870ccd24-cd9c-43cb-873b-7347446a9ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-5b0b637d-3f9e-445f-aa3f-9e7c1b423ccb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 30
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-762101442-172.17.0.4-1595547599806:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44603,DS-df5f9cb6-f8dd-4bb7-9306-6431b65baccd,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-b8212030-53a2-4df4-9e2a-a2126494731e,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-a6c93316-d42e-4b2a-9c73-ac3741c2395c,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-c9a9ae08-a0b3-45e9-b08a-48ba4fc5d5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44170,DS-a9c72b4b-60a2-4193-91c5-a5c7f55b4fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-e35879e3-6ec9-4fc6-b173-eccba19f30b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-95e51e71-cfe4-422a-8bf7-a67a22eb6a63,DISK], DatanodeInfoWithStorage[127.0.0.1:44045,DS-acfdbc20-d035-4704-ad58-6571c0d112e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-762101442-172.17.0.4-1595547599806:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44603,DS-df5f9cb6-f8dd-4bb7-9306-6431b65baccd,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-b8212030-53a2-4df4-9e2a-a2126494731e,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-a6c93316-d42e-4b2a-9c73-ac3741c2395c,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-c9a9ae08-a0b3-45e9-b08a-48ba4fc5d5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44170,DS-a9c72b4b-60a2-4193-91c5-a5c7f55b4fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-e35879e3-6ec9-4fc6-b173-eccba19f30b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-95e51e71-cfe4-422a-8bf7-a67a22eb6a63,DISK], DatanodeInfoWithStorage[127.0.0.1:44045,DS-acfdbc20-d035-4704-ad58-6571c0d112e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 30
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1470939971-172.17.0.4-1595547875758:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41718,DS-aedfd238-219b-4c24-aded-1efb31f8a818,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-7ab187d8-40d3-4808-9184-8ba931404fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-97dff32d-840e-4ea8-a6b4-9cbd2b6986fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-fec1804a-cb33-4c85-ab5a-ca5e479119df,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-bbc92379-b9c3-4bd0-ae7d-efa584da2c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40707,DS-a3e72fb8-b71b-408e-b6cd-42072341f6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39902,DS-9832d5a5-ea35-4b21-bc6b-e1d62bb86248,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-e409785a-912e-4b27-81a3-a197d822adca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1470939971-172.17.0.4-1595547875758:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41718,DS-aedfd238-219b-4c24-aded-1efb31f8a818,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-7ab187d8-40d3-4808-9184-8ba931404fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-97dff32d-840e-4ea8-a6b4-9cbd2b6986fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-fec1804a-cb33-4c85-ab5a-ca5e479119df,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-bbc92379-b9c3-4bd0-ae7d-efa584da2c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40707,DS-a3e72fb8-b71b-408e-b6cd-42072341f6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39902,DS-9832d5a5-ea35-4b21-bc6b-e1d62bb86248,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-e409785a-912e-4b27-81a3-a197d822adca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 30
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1732769352-172.17.0.4-1595548654213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39162,DS-c72f8539-434c-4f8b-8f8a-f1120b0bf925,DISK], DatanodeInfoWithStorage[127.0.0.1:39739,DS-53592793-49f7-49a4-b074-ca57412d89ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-8fd3ad3f-f4ab-493b-bf28-5c720e3c3c36,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-85879334-c790-4073-b435-b6564a551d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-9ca969f5-51ab-4ddd-a29c-a0859d36c28d,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-7d879317-f59e-44ba-98bb-9c7bfae26079,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-9526536f-40fb-4246-8e50-36fc7bc38550,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-e2ab5cec-6a85-463a-91aa-b8a2ba33569c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1732769352-172.17.0.4-1595548654213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39162,DS-c72f8539-434c-4f8b-8f8a-f1120b0bf925,DISK], DatanodeInfoWithStorage[127.0.0.1:39739,DS-53592793-49f7-49a4-b074-ca57412d89ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-8fd3ad3f-f4ab-493b-bf28-5c720e3c3c36,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-85879334-c790-4073-b435-b6564a551d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-9ca969f5-51ab-4ddd-a29c-a0859d36c28d,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-7d879317-f59e-44ba-98bb-9c7bfae26079,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-9526536f-40fb-4246-8e50-36fc7bc38550,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-e2ab5cec-6a85-463a-91aa-b8a2ba33569c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 30
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1147992596-172.17.0.4-1595548934042:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45463,DS-64ee60bd-3613-4088-b9e7-3067736ea725,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-407ae08b-9321-4079-a706-34b923357598,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-7237b047-7e3b-46f3-b245-2faf50de4579,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-19636d21-1d34-417f-a240-6039c59d564d,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-cb2f23fe-3f70-4701-af08-711353860d07,DISK], DatanodeInfoWithStorage[127.0.0.1:32826,DS-88271059-f7f5-454f-a23f-06ce16fd3700,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-4be8e9c2-650c-4ed3-9a67-baa957d96fea,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-71343a67-8295-4443-b28b-35848a0f9486,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1147992596-172.17.0.4-1595548934042:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45463,DS-64ee60bd-3613-4088-b9e7-3067736ea725,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-407ae08b-9321-4079-a706-34b923357598,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-7237b047-7e3b-46f3-b245-2faf50de4579,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-19636d21-1d34-417f-a240-6039c59d564d,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-cb2f23fe-3f70-4701-af08-711353860d07,DISK], DatanodeInfoWithStorage[127.0.0.1:32826,DS-88271059-f7f5-454f-a23f-06ce16fd3700,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-4be8e9c2-650c-4ed3-9a67-baa957d96fea,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-71343a67-8295-4443-b28b-35848a0f9486,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 30
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1057244407-172.17.0.4-1595549064343:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33426,DS-6b5015df-e5fe-48dc-82ac-417eb38ed6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-c5b688f4-6906-43fd-a91b-3f2e27413fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:40127,DS-024dec3d-a1b4-4887-8252-496c333c3702,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-68993102-4080-465a-8bcb-2fe44e193ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:42022,DS-d69af0b5-a2d2-4da1-8e38-9ccb55e64529,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-560388ba-6ec3-450e-9de6-d40344a0b2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-47aaeb01-c29d-4940-828b-f1387cc0fa53,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-195dc8bb-3029-4162-8a62-3ece54263d3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1057244407-172.17.0.4-1595549064343:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33426,DS-6b5015df-e5fe-48dc-82ac-417eb38ed6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-c5b688f4-6906-43fd-a91b-3f2e27413fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:40127,DS-024dec3d-a1b4-4887-8252-496c333c3702,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-68993102-4080-465a-8bcb-2fe44e193ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:42022,DS-d69af0b5-a2d2-4da1-8e38-9ccb55e64529,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-560388ba-6ec3-450e-9de6-d40344a0b2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-47aaeb01-c29d-4940-828b-f1387cc0fa53,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-195dc8bb-3029-4162-8a62-3ece54263d3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 30
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1278559568-172.17.0.4-1595549241150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43773,DS-fb7f981d-edfe-4ce4-a352-96d4c842fab5,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-d0b0c818-e524-4846-be88-6521342fb8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-ec2413cd-3968-4114-b193-6e749165dbbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44254,DS-817a7013-e536-427d-b668-4eb3f0d58b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-c25b45bc-7389-412e-8342-31aded939ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-822aabc0-dd87-4ed1-8dee-218a283d3c27,DISK], DatanodeInfoWithStorage[127.0.0.1:41495,DS-403246b9-0760-45d3-a10f-c4c16ae1634a,DISK], DatanodeInfoWithStorage[127.0.0.1:39340,DS-9984a8b4-db19-4d20-879f-8519cde690d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1278559568-172.17.0.4-1595549241150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43773,DS-fb7f981d-edfe-4ce4-a352-96d4c842fab5,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-d0b0c818-e524-4846-be88-6521342fb8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-ec2413cd-3968-4114-b193-6e749165dbbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44254,DS-817a7013-e536-427d-b668-4eb3f0d58b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-c25b45bc-7389-412e-8342-31aded939ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-822aabc0-dd87-4ed1-8dee-218a283d3c27,DISK], DatanodeInfoWithStorage[127.0.0.1:41495,DS-403246b9-0760-45d3-a10f-c4c16ae1634a,DISK], DatanodeInfoWithStorage[127.0.0.1:39340,DS-9984a8b4-db19-4d20-879f-8519cde690d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 30
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1420067760-172.17.0.4-1595549396210:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37632,DS-b970a8b0-b6c6-4ee2-b96f-13bdba850e85,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-b337bb34-c1de-4ded-a0eb-c14c9b476341,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-83f2b7e0-75c2-47e1-aacf-fd9bf1399033,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-00b8bd7d-5cc0-471f-8399-a59b5ed88680,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-59bc00f9-e8a6-405e-88e4-0ebb9d7c9e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-6787b9fa-6cf3-4c00-8805-c34d7216a46b,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-1a23bb1d-e383-4299-a741-7df460341d95,DISK], DatanodeInfoWithStorage[127.0.0.1:35809,DS-1b8dfaa6-d72c-4e8e-ad4d-e2d24c341eac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1420067760-172.17.0.4-1595549396210:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37632,DS-b970a8b0-b6c6-4ee2-b96f-13bdba850e85,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-b337bb34-c1de-4ded-a0eb-c14c9b476341,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-83f2b7e0-75c2-47e1-aacf-fd9bf1399033,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-00b8bd7d-5cc0-471f-8399-a59b5ed88680,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-59bc00f9-e8a6-405e-88e4-0ebb9d7c9e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-6787b9fa-6cf3-4c00-8805-c34d7216a46b,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-1a23bb1d-e383-4299-a741-7df460341d95,DISK], DatanodeInfoWithStorage[127.0.0.1:35809,DS-1b8dfaa6-d72c-4e8e-ad4d-e2d24c341eac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 30
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1487083240-172.17.0.4-1595549461670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42087,DS-8228e65e-f2fd-4d90-a828-9f08fa38668c,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-e4d39f8c-4726-4418-9377-1b148ffcfda2,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-e42b7464-1ac3-4e68-981c-b0b38922020c,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-a5838222-0f1f-4546-a8e9-613ed07c689d,DISK], DatanodeInfoWithStorage[127.0.0.1:44226,DS-cd53737d-50a4-4f9d-a82f-8948612ba6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-e6f2b0cb-a9c3-4f21-a92d-64ac362efb50,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-f5d89f80-4129-430a-b8b0-2fc44168a84d,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-c8ec3faf-3c1b-4485-8777-982bf583e16e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1487083240-172.17.0.4-1595549461670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42087,DS-8228e65e-f2fd-4d90-a828-9f08fa38668c,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-e4d39f8c-4726-4418-9377-1b148ffcfda2,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-e42b7464-1ac3-4e68-981c-b0b38922020c,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-a5838222-0f1f-4546-a8e9-613ed07c689d,DISK], DatanodeInfoWithStorage[127.0.0.1:44226,DS-cd53737d-50a4-4f9d-a82f-8948612ba6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-e6f2b0cb-a9c3-4f21-a92d-64ac362efb50,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-f5d89f80-4129-430a-b8b0-2fc44168a84d,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-c8ec3faf-3c1b-4485-8777-982bf583e16e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 30
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1422586653-172.17.0.4-1595549537049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33016,DS-af11e71a-c835-4f9a-90fa-e2ae8738f5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39356,DS-ad716c7e-df29-4821-89a5-06dccf2e1885,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-4f46b535-c574-48e4-94cd-ec1348c92f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-b0370d2d-a79a-4fa9-971e-74f26e2e76df,DISK], DatanodeInfoWithStorage[127.0.0.1:45217,DS-3b3ce75b-4c75-447a-a981-e1d5c6926022,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-df13af41-410d-47fd-95a1-9e09e304e717,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-e9ccafe8-4e4c-49ab-8968-2655272f36b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-8f8b64ef-8cd6-4702-b77f-740ac9d0fe7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1422586653-172.17.0.4-1595549537049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33016,DS-af11e71a-c835-4f9a-90fa-e2ae8738f5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39356,DS-ad716c7e-df29-4821-89a5-06dccf2e1885,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-4f46b535-c574-48e4-94cd-ec1348c92f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-b0370d2d-a79a-4fa9-971e-74f26e2e76df,DISK], DatanodeInfoWithStorage[127.0.0.1:45217,DS-3b3ce75b-4c75-447a-a981-e1d5c6926022,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-df13af41-410d-47fd-95a1-9e09e304e717,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-e9ccafe8-4e4c-49ab-8968-2655272f36b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-8f8b64ef-8cd6-4702-b77f-740ac9d0fe7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 30
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1336324625-172.17.0.4-1595549643190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33221,DS-2b596a38-748d-4fec-b980-4cc63803f0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-c5250549-da83-4e30-9533-5bc95fa2d8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-7a5784d6-8cf6-4fd9-8b27-cab742888cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-1edc9886-9f2b-405b-bf87-50275bc37e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-a33c288c-3b2c-437b-8f09-4a7d09b32fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-17be5b52-5490-441e-97d6-9d4d37211e37,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-b8fa322e-445e-4afd-b068-9f4b9454d8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-d17ccc69-6f27-40fa-91a9-ed641750fb33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1336324625-172.17.0.4-1595549643190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33221,DS-2b596a38-748d-4fec-b980-4cc63803f0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-c5250549-da83-4e30-9533-5bc95fa2d8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-7a5784d6-8cf6-4fd9-8b27-cab742888cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-1edc9886-9f2b-405b-bf87-50275bc37e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-a33c288c-3b2c-437b-8f09-4a7d09b32fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-17be5b52-5490-441e-97d6-9d4d37211e37,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-b8fa322e-445e-4afd-b068-9f4b9454d8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-d17ccc69-6f27-40fa-91a9-ed641750fb33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 30
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-915084352-172.17.0.4-1595550185584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40984,DS-92aa50a7-3bdb-437a-a8bb-75d3c157fb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-be5d3128-52aa-4227-b01a-4a0af0df037e,DISK], DatanodeInfoWithStorage[127.0.0.1:33455,DS-1e624108-e25b-4fda-a75b-182ca53af869,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-83669b7d-860a-41bd-8d93-30413d6f383c,DISK], DatanodeInfoWithStorage[127.0.0.1:45362,DS-09c0b3d9-9e20-4787-885d-45a249a16b81,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-1239b390-5181-4cfe-93f5-100664f6a382,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-3617f168-724f-46c5-befd-15a9acc928a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-dad4bf07-7e07-454f-bd28-aca3ffc2d912,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-915084352-172.17.0.4-1595550185584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40984,DS-92aa50a7-3bdb-437a-a8bb-75d3c157fb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-be5d3128-52aa-4227-b01a-4a0af0df037e,DISK], DatanodeInfoWithStorage[127.0.0.1:33455,DS-1e624108-e25b-4fda-a75b-182ca53af869,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-83669b7d-860a-41bd-8d93-30413d6f383c,DISK], DatanodeInfoWithStorage[127.0.0.1:45362,DS-09c0b3d9-9e20-4787-885d-45a249a16b81,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-1239b390-5181-4cfe-93f5-100664f6a382,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-3617f168-724f-46c5-befd-15a9acc928a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-dad4bf07-7e07-454f-bd28-aca3ffc2d912,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 30
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1876508551-172.17.0.4-1595550336054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36134,DS-1755c159-7b4c-472b-9196-0a73b03bec29,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-86364156-2cef-4dc9-a307-7c77431c6f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-758fa100-26cb-46f5-8fde-56040ddc550c,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-18169e60-3397-4d65-9d46-6b3d8bd321e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-e4c3af18-d39e-484c-afd3-dc97b3996e14,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-04fc1764-2676-485d-92a7-eff44c2aad0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39396,DS-b0522853-e34a-4d58-aac8-20488d997d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-74104487-6c55-44de-a7a4-8589e13e7c4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1876508551-172.17.0.4-1595550336054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36134,DS-1755c159-7b4c-472b-9196-0a73b03bec29,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-86364156-2cef-4dc9-a307-7c77431c6f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-758fa100-26cb-46f5-8fde-56040ddc550c,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-18169e60-3397-4d65-9d46-6b3d8bd321e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-e4c3af18-d39e-484c-afd3-dc97b3996e14,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-04fc1764-2676-485d-92a7-eff44c2aad0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39396,DS-b0522853-e34a-4d58-aac8-20488d997d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-74104487-6c55-44de-a7a4-8589e13e7c4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 30
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2105594110-172.17.0.4-1595550475065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39637,DS-8f18dca6-62a8-453e-91bf-20934a31dbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-4740f8a3-b283-4e38-9d4b-4a32cb8e1bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-7093bcd4-8ae1-4d91-a876-ea6cd7b2e623,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-f06ba6a9-8aaf-49c4-a78c-634f2dceb9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-a51e634c-c860-4876-acc4-f369d12c790f,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-f9947e5f-703c-425f-b19a-e8d5b43925d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-66fafab5-8958-4741-a2ed-d868865b42f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41693,DS-fc1979a5-3178-4ffc-a442-336f7d134799,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2105594110-172.17.0.4-1595550475065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39637,DS-8f18dca6-62a8-453e-91bf-20934a31dbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-4740f8a3-b283-4e38-9d4b-4a32cb8e1bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-7093bcd4-8ae1-4d91-a876-ea6cd7b2e623,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-f06ba6a9-8aaf-49c4-a78c-634f2dceb9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-a51e634c-c860-4876-acc4-f369d12c790f,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-f9947e5f-703c-425f-b19a-e8d5b43925d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-66fafab5-8958-4741-a2ed-d868865b42f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41693,DS-fc1979a5-3178-4ffc-a442-336f7d134799,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 30
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1408141611-172.17.0.4-1595550757825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39158,DS-0b2ba86e-4c87-4d99-b74d-e4a26671e2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35624,DS-688a96c7-a1f7-43dd-9472-3b3151bd8eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44417,DS-1aa40c6f-ea7a-45be-9d00-c2b2bd2661d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-d9dc05cf-0dbc-487b-b48c-3a22a40ed3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-9273f6e1-c95c-425e-83c3-cb1b0cda7a47,DISK], DatanodeInfoWithStorage[127.0.0.1:37002,DS-9c2e05c4-5ebe-4816-ae70-8b9a6a2ed3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-dafe9f49-7ee2-45f1-957e-16456a30b7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-049b04be-0098-4fa6-8792-892db35aa61a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1408141611-172.17.0.4-1595550757825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39158,DS-0b2ba86e-4c87-4d99-b74d-e4a26671e2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35624,DS-688a96c7-a1f7-43dd-9472-3b3151bd8eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44417,DS-1aa40c6f-ea7a-45be-9d00-c2b2bd2661d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-d9dc05cf-0dbc-487b-b48c-3a22a40ed3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-9273f6e1-c95c-425e-83c3-cb1b0cda7a47,DISK], DatanodeInfoWithStorage[127.0.0.1:37002,DS-9c2e05c4-5ebe-4816-ae70-8b9a6a2ed3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-dafe9f49-7ee2-45f1-957e-16456a30b7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-049b04be-0098-4fa6-8792-892db35aa61a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 30
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-148013412-172.17.0.4-1595550865434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37756,DS-8dffe462-319e-43e7-80c7-ba6316acb5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46730,DS-25ec4c63-1cbd-4ece-a6b5-5e27ec195622,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-32284ffd-24bd-413e-87ff-ef2b54ef0feb,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-e147dbaf-fbe1-480b-a89a-2abb43f7da79,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-46332ba0-d246-4367-987a-c7a7189bd20b,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-9cfb0a0c-037b-4eb7-ac45-87c80428b949,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-ab083830-5de2-44c8-85ab-0108f52f6437,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-072711a8-191e-4285-a06f-446002271674,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-148013412-172.17.0.4-1595550865434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37756,DS-8dffe462-319e-43e7-80c7-ba6316acb5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46730,DS-25ec4c63-1cbd-4ece-a6b5-5e27ec195622,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-32284ffd-24bd-413e-87ff-ef2b54ef0feb,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-e147dbaf-fbe1-480b-a89a-2abb43f7da79,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-46332ba0-d246-4367-987a-c7a7189bd20b,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-9cfb0a0c-037b-4eb7-ac45-87c80428b949,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-ab083830-5de2-44c8-85ab-0108f52f6437,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-072711a8-191e-4285-a06f-446002271674,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 30
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-460540972-172.17.0.4-1595551364893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42954,DS-ef87826a-05ce-4639-b693-d3c59ee1b691,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-a6565ff8-35f7-4608-b527-47df889baeef,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-5947b2af-8288-48f9-9d12-7b82b629d308,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-d30ae9e1-9893-482f-ace7-ed1f4fb2c582,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-940dfbaa-82f4-4b4b-9764-061c1d79b14c,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-c3c0260c-f423-41a6-8a3d-3209b6444a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-214349b1-c424-4eda-8ebc-b829b5c01162,DISK], DatanodeInfoWithStorage[127.0.0.1:38350,DS-92c15543-8d9f-4fe4-950e-372d46b6e103,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-460540972-172.17.0.4-1595551364893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42954,DS-ef87826a-05ce-4639-b693-d3c59ee1b691,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-a6565ff8-35f7-4608-b527-47df889baeef,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-5947b2af-8288-48f9-9d12-7b82b629d308,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-d30ae9e1-9893-482f-ace7-ed1f4fb2c582,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-940dfbaa-82f4-4b4b-9764-061c1d79b14c,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-c3c0260c-f423-41a6-8a3d-3209b6444a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-214349b1-c424-4eda-8ebc-b829b5c01162,DISK], DatanodeInfoWithStorage[127.0.0.1:38350,DS-92c15543-8d9f-4fe4-950e-372d46b6e103,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 30
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-413842449-172.17.0.4-1595551442352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44543,DS-fc34a581-c3d9-43db-a292-af2daeda562a,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-c56b26cd-4e65-4b0d-ac27-209f0ab9ae33,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-35a8b5cb-46e1-484b-a4d8-931f800365ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-01960748-c692-41f5-83c6-878cd12c1889,DISK], DatanodeInfoWithStorage[127.0.0.1:34601,DS-0d700f5e-0ba3-43b5-b61e-1c94bb3ddebd,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-0e0c2ad6-accd-450d-b8da-f6884dc22470,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-f5bdbff8-6cfe-4dcf-aace-f258335d4bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-5c507198-e4d3-482d-a37d-e1c719eca255,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-413842449-172.17.0.4-1595551442352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44543,DS-fc34a581-c3d9-43db-a292-af2daeda562a,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-c56b26cd-4e65-4b0d-ac27-209f0ab9ae33,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-35a8b5cb-46e1-484b-a4d8-931f800365ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-01960748-c692-41f5-83c6-878cd12c1889,DISK], DatanodeInfoWithStorage[127.0.0.1:34601,DS-0d700f5e-0ba3-43b5-b61e-1c94bb3ddebd,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-0e0c2ad6-accd-450d-b8da-f6884dc22470,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-f5bdbff8-6cfe-4dcf-aace-f258335d4bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-5c507198-e4d3-482d-a37d-e1c719eca255,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5336
