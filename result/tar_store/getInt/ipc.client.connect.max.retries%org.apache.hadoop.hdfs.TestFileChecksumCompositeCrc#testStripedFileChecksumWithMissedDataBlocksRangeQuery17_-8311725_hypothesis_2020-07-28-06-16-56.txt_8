reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1386614971-172.17.0.3-1595917234003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35948,DS-6b8a13d7-f81c-4814-b313-8d7aa408a1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34651,DS-c06e9a93-317d-4cbe-ae2f-a88d874f7f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-9a6d346b-182a-4c81-aebc-a7ef54a99558,DISK], DatanodeInfoWithStorage[127.0.0.1:38925,DS-1cf01249-2457-4701-b841-448b0bf500c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-445c8705-8b1a-4508-9543-aadda3d811fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38774,DS-afe7f1bc-54f1-4472-be81-107943437877,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-43c6389c-151c-416d-bbdd-fc978c5da680,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-b7f1c7a7-6439-4001-bada-f08622f0a6eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1386614971-172.17.0.3-1595917234003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35948,DS-6b8a13d7-f81c-4814-b313-8d7aa408a1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34651,DS-c06e9a93-317d-4cbe-ae2f-a88d874f7f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-9a6d346b-182a-4c81-aebc-a7ef54a99558,DISK], DatanodeInfoWithStorage[127.0.0.1:38925,DS-1cf01249-2457-4701-b841-448b0bf500c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-445c8705-8b1a-4508-9543-aadda3d811fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38774,DS-afe7f1bc-54f1-4472-be81-107943437877,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-43c6389c-151c-416d-bbdd-fc978c5da680,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-b7f1c7a7-6439-4001-bada-f08622f0a6eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-569776960-172.17.0.3-1595918749783:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41598,DS-8fb523ad-42df-4a4b-a49c-b7bae4e38723,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-1d662b58-cd37-4a42-b857-35f750d239cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-819b93ee-c459-44ae-9c9e-1e9c9b8b5741,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-81ddd396-3871-4d0f-aee1-b2eb010f3823,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-dfe1659e-1b39-4897-aae0-d5246bdef151,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-52ab08ab-492c-4811-b138-3cc3f5c7f3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-0e3a2c56-917c-4c4f-9e17-0f2814c052c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35763,DS-0a77043e-c6df-4c72-bb6b-397e3dfa3b14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-569776960-172.17.0.3-1595918749783:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41598,DS-8fb523ad-42df-4a4b-a49c-b7bae4e38723,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-1d662b58-cd37-4a42-b857-35f750d239cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-819b93ee-c459-44ae-9c9e-1e9c9b8b5741,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-81ddd396-3871-4d0f-aee1-b2eb010f3823,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-dfe1659e-1b39-4897-aae0-d5246bdef151,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-52ab08ab-492c-4811-b138-3cc3f5c7f3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-0e3a2c56-917c-4c4f-9e17-0f2814c052c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35763,DS-0a77043e-c6df-4c72-bb6b-397e3dfa3b14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2134699125-172.17.0.3-1595918966076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36342,DS-3b92ee3d-b34e-4832-84fc-404907ef6cce,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-170b5a98-4353-4e2d-ae83-1dbcab46c8de,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-4f154e58-9ae9-4a33-91f4-c6969a930b08,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-80ade580-adbd-40ba-b9f9-92ef5edbedb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-4e4ab176-5016-4ab1-a406-d10ac12700ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-e837551c-9ee9-43b8-b72c-72e3d2c41fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-31bb303f-0022-4af0-95eb-ad31e26b42df,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-1d273c67-50eb-404c-987e-63a18be46d2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2134699125-172.17.0.3-1595918966076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36342,DS-3b92ee3d-b34e-4832-84fc-404907ef6cce,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-170b5a98-4353-4e2d-ae83-1dbcab46c8de,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-4f154e58-9ae9-4a33-91f4-c6969a930b08,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-80ade580-adbd-40ba-b9f9-92ef5edbedb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-4e4ab176-5016-4ab1-a406-d10ac12700ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-e837551c-9ee9-43b8-b72c-72e3d2c41fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-31bb303f-0022-4af0-95eb-ad31e26b42df,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-1d273c67-50eb-404c-987e-63a18be46d2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-163829773-172.17.0.3-1595919500585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41353,DS-5102a9e9-0e64-404b-826e-cffe169d6134,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-1e08e504-7e15-4890-92bc-4c029323d383,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-8fd71ed9-9742-46be-b8b6-904bbaa1d730,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-3d6ff7ae-d4be-4846-ae5c-62ee6e90da87,DISK], DatanodeInfoWithStorage[127.0.0.1:40855,DS-18574532-b860-4b2a-a16e-b38293501223,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-f70a84f0-cad3-45aa-93f1-732da36c2af6,DISK], DatanodeInfoWithStorage[127.0.0.1:42167,DS-8f1fdcb8-281b-45af-a0a5-4d2882b0eaf7,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-2a24120b-82f6-4299-81fe-630156bf61f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-163829773-172.17.0.3-1595919500585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41353,DS-5102a9e9-0e64-404b-826e-cffe169d6134,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-1e08e504-7e15-4890-92bc-4c029323d383,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-8fd71ed9-9742-46be-b8b6-904bbaa1d730,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-3d6ff7ae-d4be-4846-ae5c-62ee6e90da87,DISK], DatanodeInfoWithStorage[127.0.0.1:40855,DS-18574532-b860-4b2a-a16e-b38293501223,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-f70a84f0-cad3-45aa-93f1-732da36c2af6,DISK], DatanodeInfoWithStorage[127.0.0.1:42167,DS-8f1fdcb8-281b-45af-a0a5-4d2882b0eaf7,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-2a24120b-82f6-4299-81fe-630156bf61f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-150504245-172.17.0.3-1595919885715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34036,DS-8bf0ffb3-908a-4e66-bf41-6bbd4142768e,DISK], DatanodeInfoWithStorage[127.0.0.1:43503,DS-b1fafd8f-e93e-4977-82d4-4392446c7348,DISK], DatanodeInfoWithStorage[127.0.0.1:44061,DS-e8db42bd-8510-4e52-9e2c-fc0504f390c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-7148644a-67a1-4cb0-b94a-b548a4c0c0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-20e6e3a4-f203-49d6-b25e-83973ad278ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33894,DS-f309aca4-86b8-42ee-b04a-3338801a2350,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-4e400991-43d0-4942-b341-e3f24d861f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-c7d5d1ec-1143-4207-b1fd-d01cc6ed5784,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-150504245-172.17.0.3-1595919885715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34036,DS-8bf0ffb3-908a-4e66-bf41-6bbd4142768e,DISK], DatanodeInfoWithStorage[127.0.0.1:43503,DS-b1fafd8f-e93e-4977-82d4-4392446c7348,DISK], DatanodeInfoWithStorage[127.0.0.1:44061,DS-e8db42bd-8510-4e52-9e2c-fc0504f390c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-7148644a-67a1-4cb0-b94a-b548a4c0c0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-20e6e3a4-f203-49d6-b25e-83973ad278ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33894,DS-f309aca4-86b8-42ee-b04a-3338801a2350,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-4e400991-43d0-4942-b341-e3f24d861f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-c7d5d1ec-1143-4207-b1fd-d01cc6ed5784,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1320540699-172.17.0.3-1595920133968:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37863,DS-65502217-3116-4442-b15d-7d763aead1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-90762fe4-2fc7-4908-ad21-5f442d853944,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-710ea2a7-301a-433a-9b1e-f1036140263c,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-32e80a09-3503-46fb-92af-91f717ac2635,DISK], DatanodeInfoWithStorage[127.0.0.1:33375,DS-4157bbb3-d6f5-4c27-8bdd-840a14f2ca30,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-16a02b43-e969-48c4-9cfe-7073031dab9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-3d531b01-fc9d-4f22-baba-c74b8a72c47f,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-b2160021-81ac-4a2c-822e-cefdd1763020,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1320540699-172.17.0.3-1595920133968:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37863,DS-65502217-3116-4442-b15d-7d763aead1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-90762fe4-2fc7-4908-ad21-5f442d853944,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-710ea2a7-301a-433a-9b1e-f1036140263c,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-32e80a09-3503-46fb-92af-91f717ac2635,DISK], DatanodeInfoWithStorage[127.0.0.1:33375,DS-4157bbb3-d6f5-4c27-8bdd-840a14f2ca30,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-16a02b43-e969-48c4-9cfe-7073031dab9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-3d531b01-fc9d-4f22-baba-c74b8a72c47f,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-b2160021-81ac-4a2c-822e-cefdd1763020,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1605813995-172.17.0.3-1595920275926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33638,DS-90175739-adb8-4f41-8cf5-95b0e8a8c6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39464,DS-af1f28a9-6889-4923-98ec-b6e939028a29,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-5332dca1-6c2a-4676-b724-e0f7e0cfe3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-0f623ca4-db5c-42bf-b6f8-ed7530c07ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-3968f5c2-2d37-4816-8cf8-5fd59d83a1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-db7b3658-53c1-42db-9f3c-d07db94b85af,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-2a59bb99-b66d-401b-882f-ec640da2fb6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37385,DS-b7090b1e-a96d-4960-9a05-b635ca41636e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1605813995-172.17.0.3-1595920275926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33638,DS-90175739-adb8-4f41-8cf5-95b0e8a8c6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39464,DS-af1f28a9-6889-4923-98ec-b6e939028a29,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-5332dca1-6c2a-4676-b724-e0f7e0cfe3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-0f623ca4-db5c-42bf-b6f8-ed7530c07ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-3968f5c2-2d37-4816-8cf8-5fd59d83a1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-db7b3658-53c1-42db-9f3c-d07db94b85af,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-2a59bb99-b66d-401b-882f-ec640da2fb6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37385,DS-b7090b1e-a96d-4960-9a05-b635ca41636e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-258906599-172.17.0.3-1595920449969:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44605,DS-f33f8e6b-10a4-4395-a320-572f4fc717e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-120363ba-1756-4589-bbd4-d1eef624ad5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-063d2fdf-bd62-4e1e-94b1-b81470bd6740,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-cbf76368-6947-4071-83df-1c16458542e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-cef484b8-034b-4551-9f39-20b8f874e060,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-595b273c-3648-4fc4-acc2-d5b17f30a6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-061827e1-bc60-41a8-98ac-d2d7dd4de0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-b2051411-2336-429d-a404-d574edda71db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-258906599-172.17.0.3-1595920449969:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44605,DS-f33f8e6b-10a4-4395-a320-572f4fc717e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-120363ba-1756-4589-bbd4-d1eef624ad5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-063d2fdf-bd62-4e1e-94b1-b81470bd6740,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-cbf76368-6947-4071-83df-1c16458542e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-cef484b8-034b-4551-9f39-20b8f874e060,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-595b273c-3648-4fc4-acc2-d5b17f30a6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-061827e1-bc60-41a8-98ac-d2d7dd4de0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-b2051411-2336-429d-a404-d574edda71db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-393965034-172.17.0.3-1595920727397:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43678,DS-05ae61a6-28d9-417f-b048-e9eb5afaedac,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-bcac6fbb-4180-43f6-bc63-f54536d2166e,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-9cb68611-c7aa-4a68-b037-a7bf63260410,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-593f90e1-360e-4194-8411-6590e8db06a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-c0b3b7a6-dddb-45fc-bd73-e770a0f7f844,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-8cf64eaf-8fb8-4051-8e01-b4b7f6d00b31,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-2deed063-fe90-461d-9677-ae53b824598f,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-3e9abd4c-2e82-42c7-8cc5-4b8324bb9e88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-393965034-172.17.0.3-1595920727397:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43678,DS-05ae61a6-28d9-417f-b048-e9eb5afaedac,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-bcac6fbb-4180-43f6-bc63-f54536d2166e,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-9cb68611-c7aa-4a68-b037-a7bf63260410,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-593f90e1-360e-4194-8411-6590e8db06a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-c0b3b7a6-dddb-45fc-bd73-e770a0f7f844,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-8cf64eaf-8fb8-4051-8e01-b4b7f6d00b31,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-2deed063-fe90-461d-9677-ae53b824598f,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-3e9abd4c-2e82-42c7-8cc5-4b8324bb9e88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-26497590-172.17.0.3-1595920759385:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33853,DS-6632924f-1629-4cbd-af27-618b1ca3591f,DISK], DatanodeInfoWithStorage[127.0.0.1:43229,DS-da6c5297-9572-4205-b7a9-f31449c00640,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-1ec72b4d-5a3f-4df1-a9c6-d35ee53905ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-00fb2db2-a718-49a4-8cec-b684d4ac98d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-66244765-85a5-4e59-99e3-d7a99372560b,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-52e2df48-749f-4955-943b-2d4fd29eff86,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-949553f4-d108-4b61-a900-a0dbe3429a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-f795d7e7-109a-48c9-ad21-e395cfa2fd9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-26497590-172.17.0.3-1595920759385:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33853,DS-6632924f-1629-4cbd-af27-618b1ca3591f,DISK], DatanodeInfoWithStorage[127.0.0.1:43229,DS-da6c5297-9572-4205-b7a9-f31449c00640,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-1ec72b4d-5a3f-4df1-a9c6-d35ee53905ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-00fb2db2-a718-49a4-8cec-b684d4ac98d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-66244765-85a5-4e59-99e3-d7a99372560b,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-52e2df48-749f-4955-943b-2d4fd29eff86,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-949553f4-d108-4b61-a900-a0dbe3429a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-f795d7e7-109a-48c9-ad21-e395cfa2fd9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-45913308-172.17.0.3-1595920837493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40955,DS-825a2b09-131d-4086-b8a4-661f99c7341a,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-aaa3224f-128c-4a52-8262-4539863625d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-152e5ae8-0ad9-484c-95a3-2f7fae4ac9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-189481f9-22ea-43d4-ba7d-139a805fd592,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-3529dc78-42e3-4b3d-8ec1-c97305c632bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-e651d5fb-d00f-4603-892c-0474f7ddabdd,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-03aaadeb-d03a-44c4-ac96-7dc90fc027ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36296,DS-9fbb37eb-f48c-4c8f-8cb3-bb0dce7dbfb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-45913308-172.17.0.3-1595920837493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40955,DS-825a2b09-131d-4086-b8a4-661f99c7341a,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-aaa3224f-128c-4a52-8262-4539863625d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-152e5ae8-0ad9-484c-95a3-2f7fae4ac9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-189481f9-22ea-43d4-ba7d-139a805fd592,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-3529dc78-42e3-4b3d-8ec1-c97305c632bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-e651d5fb-d00f-4603-892c-0474f7ddabdd,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-03aaadeb-d03a-44c4-ac96-7dc90fc027ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36296,DS-9fbb37eb-f48c-4c8f-8cb3-bb0dce7dbfb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-158121765-172.17.0.3-1595920913456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34053,DS-6e7f44ac-577f-4257-8715-126cce5a5618,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-b3464099-999a-4906-b297-442be2bc38be,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-62ac5b3e-6474-403b-90f5-e9cd3797bdf5,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-94a9f1be-4ec7-4eb2-85d8-9a666d82711d,DISK], DatanodeInfoWithStorage[127.0.0.1:39667,DS-3327ebcd-c892-47df-9ac6-7c042002fd25,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-746cc7d4-4f7e-4835-bd95-1d466bd43976,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-46764cd4-3f0a-45c7-a85f-06fbc19217e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-ca325ffe-cd25-4863-a40c-465caec7044a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-158121765-172.17.0.3-1595920913456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34053,DS-6e7f44ac-577f-4257-8715-126cce5a5618,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-b3464099-999a-4906-b297-442be2bc38be,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-62ac5b3e-6474-403b-90f5-e9cd3797bdf5,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-94a9f1be-4ec7-4eb2-85d8-9a666d82711d,DISK], DatanodeInfoWithStorage[127.0.0.1:39667,DS-3327ebcd-c892-47df-9ac6-7c042002fd25,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-746cc7d4-4f7e-4835-bd95-1d466bd43976,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-46764cd4-3f0a-45c7-a85f-06fbc19217e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-ca325ffe-cd25-4863-a40c-465caec7044a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1452479110-172.17.0.3-1595921288425:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32934,DS-44eab04f-1c57-4349-b0cd-e5f40561dbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33048,DS-1812ec94-bb4a-4613-9a3a-cd3477eb26f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-050d8122-33c9-4ca1-9f28-dba05310eef0,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-773d3e3d-2d97-46e9-958a-f49bad88a066,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-29c8223b-8a6b-4ccf-bfb3-8e1f74a2141f,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-9ce13fe6-5577-4783-921a-ce17e66d8d91,DISK], DatanodeInfoWithStorage[127.0.0.1:38607,DS-eb513300-b5ec-48f4-98d5-fca1a0498d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-94781eb9-fd73-42a9-ae9c-89c434e9bd35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1452479110-172.17.0.3-1595921288425:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32934,DS-44eab04f-1c57-4349-b0cd-e5f40561dbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33048,DS-1812ec94-bb4a-4613-9a3a-cd3477eb26f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-050d8122-33c9-4ca1-9f28-dba05310eef0,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-773d3e3d-2d97-46e9-958a-f49bad88a066,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-29c8223b-8a6b-4ccf-bfb3-8e1f74a2141f,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-9ce13fe6-5577-4783-921a-ce17e66d8d91,DISK], DatanodeInfoWithStorage[127.0.0.1:38607,DS-eb513300-b5ec-48f4-98d5-fca1a0498d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-94781eb9-fd73-42a9-ae9c-89c434e9bd35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-610359974-172.17.0.3-1595921797199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36872,DS-e7daee49-fc0e-4588-ad08-08573510eb94,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-9c388f33-7cf7-4b6c-9682-7cfa34654598,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-295163fe-2f2f-4848-8a09-89dc9bf80bad,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-6313f489-6efb-4fa4-b1a2-ce9fa8ab145c,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-5e9faeab-6a02-496e-9472-e216e370e882,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-dbfdf39a-fb7d-4965-961b-115241b11e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-4b1b1d75-4df2-485a-9b6f-dbb99d1c14c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35605,DS-d4a5704d-3dd0-4dd2-9394-05db6ed67a2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-610359974-172.17.0.3-1595921797199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36872,DS-e7daee49-fc0e-4588-ad08-08573510eb94,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-9c388f33-7cf7-4b6c-9682-7cfa34654598,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-295163fe-2f2f-4848-8a09-89dc9bf80bad,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-6313f489-6efb-4fa4-b1a2-ce9fa8ab145c,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-5e9faeab-6a02-496e-9472-e216e370e882,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-dbfdf39a-fb7d-4965-961b-115241b11e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-4b1b1d75-4df2-485a-9b6f-dbb99d1c14c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35605,DS-d4a5704d-3dd0-4dd2-9394-05db6ed67a2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1761414753-172.17.0.3-1595921871051:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36300,DS-03ff5cca-a968-444d-9734-2380ab8f7571,DISK], DatanodeInfoWithStorage[127.0.0.1:44352,DS-63e1f8ea-d8c5-4191-b3ad-fca2a6464048,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-8ccfb0f1-129d-4834-bc6f-39862de3ee88,DISK], DatanodeInfoWithStorage[127.0.0.1:35615,DS-d8a3c99a-a93b-4fc9-ba4c-65b29c65d252,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-8a5d0375-f415-4b89-a133-a1939d750220,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-b1befb25-89d2-4572-a68c-ac2581a094e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-82e5359d-33e9-43cc-9ed6-756b68b6341d,DISK], DatanodeInfoWithStorage[127.0.0.1:39613,DS-937cb507-e359-48c7-ae41-cd4e7e02d7d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1761414753-172.17.0.3-1595921871051:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36300,DS-03ff5cca-a968-444d-9734-2380ab8f7571,DISK], DatanodeInfoWithStorage[127.0.0.1:44352,DS-63e1f8ea-d8c5-4191-b3ad-fca2a6464048,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-8ccfb0f1-129d-4834-bc6f-39862de3ee88,DISK], DatanodeInfoWithStorage[127.0.0.1:35615,DS-d8a3c99a-a93b-4fc9-ba4c-65b29c65d252,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-8a5d0375-f415-4b89-a133-a1939d750220,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-b1befb25-89d2-4572-a68c-ac2581a094e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-82e5359d-33e9-43cc-9ed6-756b68b6341d,DISK], DatanodeInfoWithStorage[127.0.0.1:39613,DS-937cb507-e359-48c7-ae41-cd4e7e02d7d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: might be true error
Total execution time in seconds : 5371
