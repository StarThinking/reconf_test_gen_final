reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-859683013-172.17.0.5-1595801748269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45619,DS-899b158e-cefa-4a51-b3fe-0f8530b7fee5,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-c060907e-ca21-4a9b-ab62-1cfd99e34075,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-1ec0f3ec-d24f-4282-a3bd-1f9bb74297e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38152,DS-ed28055e-f88d-4760-a0b0-be7308b9472a,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-84b16385-0685-43c6-8f5d-2a27f44653f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-ea11e029-6ef2-4d82-8587-4bf0316e4afb,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-874e35aa-f98e-42c0-9d2b-3f3a27a5b777,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-1d7e8a86-13b9-48af-b7e5-017ee4574c55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-859683013-172.17.0.5-1595801748269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45619,DS-899b158e-cefa-4a51-b3fe-0f8530b7fee5,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-c060907e-ca21-4a9b-ab62-1cfd99e34075,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-1ec0f3ec-d24f-4282-a3bd-1f9bb74297e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38152,DS-ed28055e-f88d-4760-a0b0-be7308b9472a,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-84b16385-0685-43c6-8f5d-2a27f44653f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-ea11e029-6ef2-4d82-8587-4bf0316e4afb,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-874e35aa-f98e-42c0-9d2b-3f3a27a5b777,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-1d7e8a86-13b9-48af-b7e5-017ee4574c55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-875227418-172.17.0.5-1595802434875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39166,DS-dcb9fa00-879a-4db6-beff-8c1ff971d462,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-1f7308af-debc-44a3-b121-7623bafbd420,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-b47b503c-7131-4e58-97bc-7bed87b9de9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-41d78c97-70ff-4f09-a231-288f4d3ee934,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-705f02f9-5d2e-4109-b9c9-0d389b2b8062,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-7a06389c-7046-4be0-8cce-18067a9e4dea,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-eab79e9b-7b7c-458d-a5a1-7058bbc4d080,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-b93f7e86-9280-44b2-862f-e817f190a55d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-875227418-172.17.0.5-1595802434875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39166,DS-dcb9fa00-879a-4db6-beff-8c1ff971d462,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-1f7308af-debc-44a3-b121-7623bafbd420,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-b47b503c-7131-4e58-97bc-7bed87b9de9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-41d78c97-70ff-4f09-a231-288f4d3ee934,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-705f02f9-5d2e-4109-b9c9-0d389b2b8062,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-7a06389c-7046-4be0-8cce-18067a9e4dea,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-eab79e9b-7b7c-458d-a5a1-7058bbc4d080,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-b93f7e86-9280-44b2-862f-e817f190a55d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-996675517-172.17.0.5-1595802591796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41122,DS-f6fca4b9-0987-4b4c-86a8-116918ca4edf,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-4ac97508-bad8-4f60-b13f-c7ed3addd65a,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-7d0710da-8943-48cf-8614-176392a9313d,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-64dbc172-5ad8-4e16-8ec4-8c46cd2089fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-66b649e6-8bee-4d50-96e8-289e462920fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-716b4329-4d3f-4a99-81f8-3e2c77b31b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37536,DS-06fa59b2-5bd3-47d3-a48c-199c856d5946,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-b1e8de68-833e-449d-9fc1-e19c227a0ba1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-996675517-172.17.0.5-1595802591796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41122,DS-f6fca4b9-0987-4b4c-86a8-116918ca4edf,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-4ac97508-bad8-4f60-b13f-c7ed3addd65a,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-7d0710da-8943-48cf-8614-176392a9313d,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-64dbc172-5ad8-4e16-8ec4-8c46cd2089fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-66b649e6-8bee-4d50-96e8-289e462920fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-716b4329-4d3f-4a99-81f8-3e2c77b31b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37536,DS-06fa59b2-5bd3-47d3-a48c-199c856d5946,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-b1e8de68-833e-449d-9fc1-e19c227a0ba1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-987345272-172.17.0.5-1595802704035:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41445,DS-f157189d-e256-4ce2-8ff5-61a44fe54482,DISK], DatanodeInfoWithStorage[127.0.0.1:37355,DS-9d78c182-6f7d-41c7-840a-3901e03fa0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-f8d9b81b-23ad-429b-ace9-0e12e07911a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-7f1f06c2-afe1-4e3c-b323-50c84ccaee2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-04abb0b7-803b-4054-95c4-7fa2b57c8bec,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-14d4a110-9155-4fe5-8be1-b37cd6643f82,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-fa8b8456-2dc3-40f2-a628-de2a1d8b23a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-c8d3fcef-0c4c-404a-81c1-b54d23af55e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-987345272-172.17.0.5-1595802704035:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41445,DS-f157189d-e256-4ce2-8ff5-61a44fe54482,DISK], DatanodeInfoWithStorage[127.0.0.1:37355,DS-9d78c182-6f7d-41c7-840a-3901e03fa0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-f8d9b81b-23ad-429b-ace9-0e12e07911a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-7f1f06c2-afe1-4e3c-b323-50c84ccaee2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-04abb0b7-803b-4054-95c4-7fa2b57c8bec,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-14d4a110-9155-4fe5-8be1-b37cd6643f82,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-fa8b8456-2dc3-40f2-a628-de2a1d8b23a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-c8d3fcef-0c4c-404a-81c1-b54d23af55e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1273889360-172.17.0.5-1595802858868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35350,DS-c007bcb0-ee7e-4118-ab80-0c70785b78d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-a20ba8f6-d262-45a4-a18f-69fad4d06328,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-2949df1e-9655-41b2-815a-dcf9bc544db9,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-9f7440ec-8142-442d-960a-373e0d9d0a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-671eedb6-d2b6-4caf-9b7c-467a06b075ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-9f33d064-de82-45ee-8249-4fc5e7c3bf1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-b1eff4a8-121c-42d7-b2c2-f4a464039593,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-ca434988-2138-4de3-92db-7abac9c4d415,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1273889360-172.17.0.5-1595802858868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35350,DS-c007bcb0-ee7e-4118-ab80-0c70785b78d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-a20ba8f6-d262-45a4-a18f-69fad4d06328,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-2949df1e-9655-41b2-815a-dcf9bc544db9,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-9f7440ec-8142-442d-960a-373e0d9d0a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-671eedb6-d2b6-4caf-9b7c-467a06b075ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-9f33d064-de82-45ee-8249-4fc5e7c3bf1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-b1eff4a8-121c-42d7-b2c2-f4a464039593,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-ca434988-2138-4de3-92db-7abac9c4d415,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894878723-172.17.0.5-1595803480163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33827,DS-a90e2688-0581-4c2d-814d-567288914845,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-630e608a-c7d2-460f-b578-a1040c8d1732,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-fd33c576-0da0-4c97-9177-ba1d5d6e1395,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-2813e1eb-7855-4e77-8cc6-72de7e832bab,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-f2cfd12c-738d-4265-b3e1-24bb5c74f357,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-bd32c38b-70dc-4af4-af95-05953f364d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36258,DS-1a165deb-091c-4510-8317-92dcdc72e500,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-2f7b3d7b-12e2-41d0-9d95-b28cf4daba24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894878723-172.17.0.5-1595803480163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33827,DS-a90e2688-0581-4c2d-814d-567288914845,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-630e608a-c7d2-460f-b578-a1040c8d1732,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-fd33c576-0da0-4c97-9177-ba1d5d6e1395,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-2813e1eb-7855-4e77-8cc6-72de7e832bab,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-f2cfd12c-738d-4265-b3e1-24bb5c74f357,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-bd32c38b-70dc-4af4-af95-05953f364d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36258,DS-1a165deb-091c-4510-8317-92dcdc72e500,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-2f7b3d7b-12e2-41d0-9d95-b28cf4daba24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-572178910-172.17.0.5-1595803560722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37446,DS-4aa390fb-cd5e-429c-b66d-36180723bc36,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-6f44c501-a285-4452-8f09-40bd6e9f298f,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-d1c9a3de-1b0c-4a2e-bee3-fc5c8e19627f,DISK], DatanodeInfoWithStorage[127.0.0.1:46015,DS-3ed78312-c16a-4332-99ad-7615a4f31083,DISK], DatanodeInfoWithStorage[127.0.0.1:34796,DS-8022967a-16d9-435a-957b-bda8e7b33c72,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-5bce7488-b196-4c77-a6c1-7d19cfa987ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-1cb65d26-0afe-421b-a722-80ead8e23102,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-bcecda9c-2f8c-4be6-97d0-652bd3672b87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-572178910-172.17.0.5-1595803560722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37446,DS-4aa390fb-cd5e-429c-b66d-36180723bc36,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-6f44c501-a285-4452-8f09-40bd6e9f298f,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-d1c9a3de-1b0c-4a2e-bee3-fc5c8e19627f,DISK], DatanodeInfoWithStorage[127.0.0.1:46015,DS-3ed78312-c16a-4332-99ad-7615a4f31083,DISK], DatanodeInfoWithStorage[127.0.0.1:34796,DS-8022967a-16d9-435a-957b-bda8e7b33c72,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-5bce7488-b196-4c77-a6c1-7d19cfa987ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-1cb65d26-0afe-421b-a722-80ead8e23102,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-bcecda9c-2f8c-4be6-97d0-652bd3672b87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-413013164-172.17.0.5-1595803973107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36098,DS-5d2f111f-740c-4650-98ce-e992cf471bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-0a4bda20-eeef-464a-85bf-988b6933ebc1,DISK], DatanodeInfoWithStorage[127.0.0.1:34923,DS-36f38634-6ed2-4056-9c75-0ff6416c31d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-304ea05e-88b1-4b14-94dc-95d8ed2d1968,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-98b5111d-57d9-48e1-a762-7926806f05cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-86a7a4fa-cce2-4242-bae7-361b1d6caf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-2acfafca-e82e-4a07-ab08-833fe187054d,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-eeb10d93-974d-480f-b4c2-ad5ab24688a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-413013164-172.17.0.5-1595803973107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36098,DS-5d2f111f-740c-4650-98ce-e992cf471bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-0a4bda20-eeef-464a-85bf-988b6933ebc1,DISK], DatanodeInfoWithStorage[127.0.0.1:34923,DS-36f38634-6ed2-4056-9c75-0ff6416c31d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-304ea05e-88b1-4b14-94dc-95d8ed2d1968,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-98b5111d-57d9-48e1-a762-7926806f05cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-86a7a4fa-cce2-4242-bae7-361b1d6caf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-2acfafca-e82e-4a07-ab08-833fe187054d,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-eeb10d93-974d-480f-b4c2-ad5ab24688a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-564075708-172.17.0.5-1595804101317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37467,DS-6b22bf6f-9262-4d27-8dfe-37476ed989fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36082,DS-d9871074-e687-45c3-9197-98d419d12faf,DISK], DatanodeInfoWithStorage[127.0.0.1:35988,DS-0f6db730-6119-4b20-9d21-6eb1c3d1ac99,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-f8240cd5-4f0c-4161-a169-bbe29944d146,DISK], DatanodeInfoWithStorage[127.0.0.1:37239,DS-17dd3b4e-0bd8-4b15-900e-f3cab6dafcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-4c0920e6-1558-42d4-8d4a-e5a4c1d71762,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-39377db7-7798-4cef-b2ff-3b45e9ee5d46,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-8231225b-0ca8-4bcf-aa1e-12451f335f44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-564075708-172.17.0.5-1595804101317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37467,DS-6b22bf6f-9262-4d27-8dfe-37476ed989fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36082,DS-d9871074-e687-45c3-9197-98d419d12faf,DISK], DatanodeInfoWithStorage[127.0.0.1:35988,DS-0f6db730-6119-4b20-9d21-6eb1c3d1ac99,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-f8240cd5-4f0c-4161-a169-bbe29944d146,DISK], DatanodeInfoWithStorage[127.0.0.1:37239,DS-17dd3b4e-0bd8-4b15-900e-f3cab6dafcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-4c0920e6-1558-42d4-8d4a-e5a4c1d71762,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-39377db7-7798-4cef-b2ff-3b45e9ee5d46,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-8231225b-0ca8-4bcf-aa1e-12451f335f44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-359014799-172.17.0.5-1595804597261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44455,DS-9c7b1122-f877-4203-97be-f30966fc9108,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-4ddcf9bb-a5d0-4afd-bd2f-ea3b5f595dec,DISK], DatanodeInfoWithStorage[127.0.0.1:46641,DS-08770148-41bf-4e5f-92f1-88e1fec3d5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38190,DS-fe630b1d-4256-41a7-86f2-9dc3deefc67a,DISK], DatanodeInfoWithStorage[127.0.0.1:42528,DS-00f2fda5-6300-4069-9476-d3a34ff5e92c,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-bd8d8f96-c4a4-49f4-9b5e-08ccac6633e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42762,DS-572eb687-3e36-42dc-8e40-d095d1d6e617,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-e9263ed9-134a-4b00-aea5-9cf0f866b1e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-359014799-172.17.0.5-1595804597261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44455,DS-9c7b1122-f877-4203-97be-f30966fc9108,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-4ddcf9bb-a5d0-4afd-bd2f-ea3b5f595dec,DISK], DatanodeInfoWithStorage[127.0.0.1:46641,DS-08770148-41bf-4e5f-92f1-88e1fec3d5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38190,DS-fe630b1d-4256-41a7-86f2-9dc3deefc67a,DISK], DatanodeInfoWithStorage[127.0.0.1:42528,DS-00f2fda5-6300-4069-9476-d3a34ff5e92c,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-bd8d8f96-c4a4-49f4-9b5e-08ccac6633e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42762,DS-572eb687-3e36-42dc-8e40-d095d1d6e617,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-e9263ed9-134a-4b00-aea5-9cf0f866b1e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2057690523-172.17.0.5-1595805253235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45835,DS-a4f9a240-b093-4340-ab6a-f4aa6fce1819,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-1a7e06ff-7b2b-451d-8e7a-99758fd904a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-4b0ba3d5-d412-4f8e-bf13-40994de9203b,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-9ebd3639-9cd3-41d6-a4aa-8955eb9f6797,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-eaa692af-0373-4466-b3cc-fa116f7b6a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-9e5e4afe-776c-4c83-8333-10592e285446,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-48b65866-085f-4699-b5f2-d77ac6aa8f20,DISK], DatanodeInfoWithStorage[127.0.0.1:34994,DS-4a5fbd07-73a4-445c-bc8a-900bc626b4d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2057690523-172.17.0.5-1595805253235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45835,DS-a4f9a240-b093-4340-ab6a-f4aa6fce1819,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-1a7e06ff-7b2b-451d-8e7a-99758fd904a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-4b0ba3d5-d412-4f8e-bf13-40994de9203b,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-9ebd3639-9cd3-41d6-a4aa-8955eb9f6797,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-eaa692af-0373-4466-b3cc-fa116f7b6a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-9e5e4afe-776c-4c83-8333-10592e285446,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-48b65866-085f-4699-b5f2-d77ac6aa8f20,DISK], DatanodeInfoWithStorage[127.0.0.1:34994,DS-4a5fbd07-73a4-445c-bc8a-900bc626b4d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251278520-172.17.0.5-1595805450673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45965,DS-3662c88e-ba2f-4ec3-bbd0-58d85d9a91f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-cdd10f1d-011c-4382-81a1-f23eb31329cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46047,DS-98ae7a46-c237-461f-9a6e-6985452c4e95,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-1e549dbd-4357-4b89-8930-89c193f3d019,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-fcb8d628-0161-46e8-93db-7a48df36a2de,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-08db1e36-1240-4aa6-8632-d1ab0c894c28,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-3ad45fb7-8789-47b2-8901-78a1e32b006c,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-1ce303fb-6ae1-4f85-95e7-88b527b0eaca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251278520-172.17.0.5-1595805450673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45965,DS-3662c88e-ba2f-4ec3-bbd0-58d85d9a91f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-cdd10f1d-011c-4382-81a1-f23eb31329cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46047,DS-98ae7a46-c237-461f-9a6e-6985452c4e95,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-1e549dbd-4357-4b89-8930-89c193f3d019,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-fcb8d628-0161-46e8-93db-7a48df36a2de,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-08db1e36-1240-4aa6-8632-d1ab0c894c28,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-3ad45fb7-8789-47b2-8901-78a1e32b006c,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-1ce303fb-6ae1-4f85-95e7-88b527b0eaca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-780087089-172.17.0.5-1595805596410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33151,DS-7ce9b5b6-4d8d-4765-9bce-4084292d03b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43135,DS-e47c7ff0-4ec3-4a64-af35-5fdf0f0dde94,DISK], DatanodeInfoWithStorage[127.0.0.1:32787,DS-40df211a-662a-4ce9-b738-82e18ba3d3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-32332053-2af3-4827-9ca6-91108a38197a,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-6a1bdf59-b563-4618-ad63-7d6736c0bc94,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-aac8c7fe-691d-4c31-9f4b-bb39e35fd774,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-00568dbf-c4d8-46f0-80d3-6798a5502260,DISK], DatanodeInfoWithStorage[127.0.0.1:40648,DS-889ae3c6-8d81-46b2-9463-28971853340e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-780087089-172.17.0.5-1595805596410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33151,DS-7ce9b5b6-4d8d-4765-9bce-4084292d03b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43135,DS-e47c7ff0-4ec3-4a64-af35-5fdf0f0dde94,DISK], DatanodeInfoWithStorage[127.0.0.1:32787,DS-40df211a-662a-4ce9-b738-82e18ba3d3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-32332053-2af3-4827-9ca6-91108a38197a,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-6a1bdf59-b563-4618-ad63-7d6736c0bc94,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-aac8c7fe-691d-4c31-9f4b-bb39e35fd774,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-00568dbf-c4d8-46f0-80d3-6798a5502260,DISK], DatanodeInfoWithStorage[127.0.0.1:40648,DS-889ae3c6-8d81-46b2-9463-28971853340e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-307756834-172.17.0.5-1595806851277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37077,DS-c6287d2a-46eb-4471-b233-0b0f14e0959e,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-ccc5ed26-53fb-4357-9720-cb0fbad67d63,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-f0f23fc3-aa8b-4da5-8993-54779218f2fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-20984c3c-1b66-477c-af84-8fc24930db9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-e7adc0e2-bdd8-474e-9a83-d267f55555f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-bbc06d50-8966-4438-8132-7d3f8d0acdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-11e1a57c-7e27-47c7-a508-c03900f33eba,DISK], DatanodeInfoWithStorage[127.0.0.1:38572,DS-56744896-d69c-439d-8fb2-f8975525a4c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-307756834-172.17.0.5-1595806851277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37077,DS-c6287d2a-46eb-4471-b233-0b0f14e0959e,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-ccc5ed26-53fb-4357-9720-cb0fbad67d63,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-f0f23fc3-aa8b-4da5-8993-54779218f2fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-20984c3c-1b66-477c-af84-8fc24930db9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-e7adc0e2-bdd8-474e-9a83-d267f55555f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-bbc06d50-8966-4438-8132-7d3f8d0acdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-11e1a57c-7e27-47c7-a508-c03900f33eba,DISK], DatanodeInfoWithStorage[127.0.0.1:38572,DS-56744896-d69c-439d-8fb2-f8975525a4c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-878336849-172.17.0.5-1595806968711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39791,DS-061bd3e1-4074-4ae1-a9b7-504e6f7a1166,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-ff15580e-c617-45fe-bf84-227c704e31d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-e7860d87-9ba1-44dc-a5ec-e42ffc06b5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-0f66fa76-343d-4a7c-b60a-eb573177799e,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-78b6f88f-6021-4a64-b16a-8eae1dde147d,DISK], DatanodeInfoWithStorage[127.0.0.1:40508,DS-02abaea2-b869-408c-abbb-fb093e497c41,DISK], DatanodeInfoWithStorage[127.0.0.1:40498,DS-cc013cd1-1e0f-4052-9d2d-da19cedb4461,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-dc5a46f9-d244-471c-ace9-42d0c739754a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-878336849-172.17.0.5-1595806968711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39791,DS-061bd3e1-4074-4ae1-a9b7-504e6f7a1166,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-ff15580e-c617-45fe-bf84-227c704e31d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-e7860d87-9ba1-44dc-a5ec-e42ffc06b5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-0f66fa76-343d-4a7c-b60a-eb573177799e,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-78b6f88f-6021-4a64-b16a-8eae1dde147d,DISK], DatanodeInfoWithStorage[127.0.0.1:40508,DS-02abaea2-b869-408c-abbb-fb093e497c41,DISK], DatanodeInfoWithStorage[127.0.0.1:40498,DS-cc013cd1-1e0f-4052-9d2d-da19cedb4461,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-dc5a46f9-d244-471c-ace9-42d0c739754a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1073561578-172.17.0.5-1595807116913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37501,DS-cc5e6fc6-e2fb-4c50-8633-07846f4367d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46428,DS-3f0db3e1-ec8f-439c-8de3-2b49d158da9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33508,DS-8447c9c8-550e-4183-9d44-1d4b81919e59,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-4c3f67f3-b3bd-4953-b89d-77069de2d0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33762,DS-bd2fd88e-7aeb-49a5-956c-1da3fb5ae7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-59f57269-938a-4b4b-8b20-04a2eebe7d67,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-efa498c5-3eb3-4752-9332-c45fe129c4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-684161e2-e2b6-4eaa-97ac-119350c807e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1073561578-172.17.0.5-1595807116913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37501,DS-cc5e6fc6-e2fb-4c50-8633-07846f4367d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46428,DS-3f0db3e1-ec8f-439c-8de3-2b49d158da9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33508,DS-8447c9c8-550e-4183-9d44-1d4b81919e59,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-4c3f67f3-b3bd-4953-b89d-77069de2d0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33762,DS-bd2fd88e-7aeb-49a5-956c-1da3fb5ae7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-59f57269-938a-4b4b-8b20-04a2eebe7d67,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-efa498c5-3eb3-4752-9332-c45fe129c4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-684161e2-e2b6-4eaa-97ac-119350c807e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5705
