reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-775087062-172.17.0.12-1595883560652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41192,DS-c6ddbace-325f-4953-922b-4830fcbb1733,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-3a4fea86-48f9-45ab-af94-b627c2224ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-d92c5c99-6413-4f77-8440-5178a2549df9,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-ecb0790f-6b89-4961-ba2b-35cb1aad2735,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-85604d0b-c831-40df-98f9-45e01e0a2deb,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-d55c8b79-4cc3-4c05-83e5-1aa8f0dc2fae,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-62a4774d-d1b4-400b-97ca-6134993e392f,DISK], DatanodeInfoWithStorage[127.0.0.1:43711,DS-06990e8a-bb08-4ba4-b2a8-aa77eb815bfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-775087062-172.17.0.12-1595883560652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41192,DS-c6ddbace-325f-4953-922b-4830fcbb1733,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-3a4fea86-48f9-45ab-af94-b627c2224ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-d92c5c99-6413-4f77-8440-5178a2549df9,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-ecb0790f-6b89-4961-ba2b-35cb1aad2735,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-85604d0b-c831-40df-98f9-45e01e0a2deb,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-d55c8b79-4cc3-4c05-83e5-1aa8f0dc2fae,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-62a4774d-d1b4-400b-97ca-6134993e392f,DISK], DatanodeInfoWithStorage[127.0.0.1:43711,DS-06990e8a-bb08-4ba4-b2a8-aa77eb815bfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-373420537-172.17.0.12-1595884023482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46124,DS-22a9808f-830f-4210-a8e9-aa7e435a1b82,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-cfdcdf9e-f913-4e7b-86ac-8b27d2fbaf7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-26484eb8-8d72-4917-bf2a-c75a0a146ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-46df7416-f683-48e5-b02e-c14312efba26,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-ef4484de-1d14-4625-90e9-a5d93a35cece,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-6aa44620-d4a4-41ba-ad4b-0914b54fd305,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-96e718a9-650b-4323-aa9c-41d7bd557dab,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-420b88c9-8271-435c-afa5-1fcc891c5bf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-373420537-172.17.0.12-1595884023482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46124,DS-22a9808f-830f-4210-a8e9-aa7e435a1b82,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-cfdcdf9e-f913-4e7b-86ac-8b27d2fbaf7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-26484eb8-8d72-4917-bf2a-c75a0a146ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-46df7416-f683-48e5-b02e-c14312efba26,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-ef4484de-1d14-4625-90e9-a5d93a35cece,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-6aa44620-d4a4-41ba-ad4b-0914b54fd305,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-96e718a9-650b-4323-aa9c-41d7bd557dab,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-420b88c9-8271-435c-afa5-1fcc891c5bf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2124852197-172.17.0.12-1595884212833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33493,DS-28a0485d-5908-4e86-ad08-bad68a7d3599,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-347e8a77-40cb-493f-a4b9-d422be63b7a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-4b2c66b8-61a8-41cb-8d50-08d68dc575d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-4c4854e8-cb88-4d35-912d-99a5d2f6d6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-38da4311-8137-4a12-997d-5a25182db675,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-86c57216-bb08-4837-9bbc-a363825e5bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-4ff4abdd-1dd9-494c-bf79-81b4bdb5b0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-21c50c7b-7fda-4716-a809-5b0d2beefd04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2124852197-172.17.0.12-1595884212833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33493,DS-28a0485d-5908-4e86-ad08-bad68a7d3599,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-347e8a77-40cb-493f-a4b9-d422be63b7a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-4b2c66b8-61a8-41cb-8d50-08d68dc575d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-4c4854e8-cb88-4d35-912d-99a5d2f6d6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-38da4311-8137-4a12-997d-5a25182db675,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-86c57216-bb08-4837-9bbc-a363825e5bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-4ff4abdd-1dd9-494c-bf79-81b4bdb5b0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-21c50c7b-7fda-4716-a809-5b0d2beefd04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-176623810-172.17.0.12-1595884294758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38828,DS-2b3c8df1-4330-469c-952d-c1c23711f1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-5aa0c767-8366-4376-bd05-a346ea5992cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-c8e7a70c-7b37-4f28-aef8-21ff33c19e07,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-5a85f64a-9b15-4c23-a473-6b3e00ef0610,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-feb05b32-7c97-4c13-9d28-b9f824bd046b,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-51d86564-8852-41c5-9ac9-c2acf9f48290,DISK], DatanodeInfoWithStorage[127.0.0.1:41606,DS-1a773262-e4b4-4831-be1b-2455a7eae67a,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-6093dca4-f514-4623-b132-7a572b78f2a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-176623810-172.17.0.12-1595884294758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38828,DS-2b3c8df1-4330-469c-952d-c1c23711f1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-5aa0c767-8366-4376-bd05-a346ea5992cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-c8e7a70c-7b37-4f28-aef8-21ff33c19e07,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-5a85f64a-9b15-4c23-a473-6b3e00ef0610,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-feb05b32-7c97-4c13-9d28-b9f824bd046b,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-51d86564-8852-41c5-9ac9-c2acf9f48290,DISK], DatanodeInfoWithStorage[127.0.0.1:41606,DS-1a773262-e4b4-4831-be1b-2455a7eae67a,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-6093dca4-f514-4623-b132-7a572b78f2a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1154626093-172.17.0.12-1595884778104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36333,DS-7ca4d073-c8c7-43d8-8097-4b862d55fa5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-3aff0706-6463-4f29-8a42-a7b97760910d,DISK], DatanodeInfoWithStorage[127.0.0.1:44667,DS-3691a6c6-ad4d-4a63-91ba-dedb6dcf27ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-fc5d5039-8465-461f-b3df-d5a96c3ec110,DISK], DatanodeInfoWithStorage[127.0.0.1:39485,DS-ecb2c44b-f6ef-4a88-ac84-0ddee0a1546d,DISK], DatanodeInfoWithStorage[127.0.0.1:41779,DS-b9d48006-38a8-4b97-9cdd-3043a07efcc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-bbcd47b6-0fe7-45fa-ac57-9df7262e31d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-4fb7164c-67a7-4ead-bfe7-cea5cbe9159f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1154626093-172.17.0.12-1595884778104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36333,DS-7ca4d073-c8c7-43d8-8097-4b862d55fa5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-3aff0706-6463-4f29-8a42-a7b97760910d,DISK], DatanodeInfoWithStorage[127.0.0.1:44667,DS-3691a6c6-ad4d-4a63-91ba-dedb6dcf27ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-fc5d5039-8465-461f-b3df-d5a96c3ec110,DISK], DatanodeInfoWithStorage[127.0.0.1:39485,DS-ecb2c44b-f6ef-4a88-ac84-0ddee0a1546d,DISK], DatanodeInfoWithStorage[127.0.0.1:41779,DS-b9d48006-38a8-4b97-9cdd-3043a07efcc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-bbcd47b6-0fe7-45fa-ac57-9df7262e31d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-4fb7164c-67a7-4ead-bfe7-cea5cbe9159f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-959188979-172.17.0.12-1595885082321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39307,DS-1776b1b7-122b-4348-a359-f7d4748549bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-6fbc9e24-b8e8-4814-a268-d12460158da0,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-3a01694b-0c03-4952-8eb1-de00f53e8f74,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-1cc85232-a4a5-4d6b-a6d6-57900ec2cea9,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-ef354f16-d9b1-493d-9f72-daf601937c15,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-104b47c5-7d98-4764-a6d9-fd93a3ff57e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-02b49553-5310-4d23-a9b0-30aab1f86bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-70cda921-155d-4cc0-b85c-1a31094db89a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-959188979-172.17.0.12-1595885082321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39307,DS-1776b1b7-122b-4348-a359-f7d4748549bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-6fbc9e24-b8e8-4814-a268-d12460158da0,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-3a01694b-0c03-4952-8eb1-de00f53e8f74,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-1cc85232-a4a5-4d6b-a6d6-57900ec2cea9,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-ef354f16-d9b1-493d-9f72-daf601937c15,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-104b47c5-7d98-4764-a6d9-fd93a3ff57e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-02b49553-5310-4d23-a9b0-30aab1f86bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-70cda921-155d-4cc0-b85c-1a31094db89a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1811495184-172.17.0.12-1595886496914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40918,DS-96e25190-4975-47bc-87a8-faf74ed8caea,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-9cfb1568-bcad-4985-9aad-adee64f53c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-b5c99bb6-3768-457f-9e23-97c8789b9783,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-2e84d968-9d3a-4057-b519-4228cb9d2b35,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-76c1a650-4842-44a8-b126-ec13532da8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-008d329b-39ef-4e07-a8cc-9bf3dc80b12c,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-914f9999-c7b0-41b1-a53c-e05df1fafd37,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-3f0cdb7b-f3a7-4805-8a44-355ccdfdba78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1811495184-172.17.0.12-1595886496914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40918,DS-96e25190-4975-47bc-87a8-faf74ed8caea,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-9cfb1568-bcad-4985-9aad-adee64f53c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-b5c99bb6-3768-457f-9e23-97c8789b9783,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-2e84d968-9d3a-4057-b519-4228cb9d2b35,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-76c1a650-4842-44a8-b126-ec13532da8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-008d329b-39ef-4e07-a8cc-9bf3dc80b12c,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-914f9999-c7b0-41b1-a53c-e05df1fafd37,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-3f0cdb7b-f3a7-4805-8a44-355ccdfdba78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178932384-172.17.0.12-1595886541955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36170,DS-cc235598-9835-4892-be8d-0d6ea5452078,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-113f00fc-259a-4fed-8f73-48a2eacb25cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-118efc6f-b98b-41ce-957e-2af362326ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-3370d9a1-dbcc-406e-93f7-74c36ced379a,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-7803b0ca-d275-46ba-89d4-269040bfcebd,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-03cb4614-a706-4696-ab47-f88b6023893e,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-789f0d1f-514c-4846-8461-29fbe3b2b943,DISK], DatanodeInfoWithStorage[127.0.0.1:33590,DS-2401e1bd-aa15-4540-a56a-dc29df97e175,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178932384-172.17.0.12-1595886541955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36170,DS-cc235598-9835-4892-be8d-0d6ea5452078,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-113f00fc-259a-4fed-8f73-48a2eacb25cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-118efc6f-b98b-41ce-957e-2af362326ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-3370d9a1-dbcc-406e-93f7-74c36ced379a,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-7803b0ca-d275-46ba-89d4-269040bfcebd,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-03cb4614-a706-4696-ab47-f88b6023893e,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-789f0d1f-514c-4846-8461-29fbe3b2b943,DISK], DatanodeInfoWithStorage[127.0.0.1:33590,DS-2401e1bd-aa15-4540-a56a-dc29df97e175,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1463919161-172.17.0.12-1595886757469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35258,DS-df255c7f-5c5c-4be0-a0fe-7ec99480ec63,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-0078f8c2-bcc6-43f3-b589-0ff20c17c562,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-513aad12-29f5-4c1d-94aa-0e6f02d83f09,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-c1aba609-f20e-4d3d-9bac-5065d01129db,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-e373b0ba-a3c9-4f60-8281-4c7dd25f86c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-e4fe6f83-b9f4-4792-9be0-17308cf2f942,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-c578547b-9ea6-4d7c-8fc5-0f0e1f6a4d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-3ec0b8bc-5813-4ff7-858e-48fcb9d507ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1463919161-172.17.0.12-1595886757469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35258,DS-df255c7f-5c5c-4be0-a0fe-7ec99480ec63,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-0078f8c2-bcc6-43f3-b589-0ff20c17c562,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-513aad12-29f5-4c1d-94aa-0e6f02d83f09,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-c1aba609-f20e-4d3d-9bac-5065d01129db,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-e373b0ba-a3c9-4f60-8281-4c7dd25f86c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-e4fe6f83-b9f4-4792-9be0-17308cf2f942,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-c578547b-9ea6-4d7c-8fc5-0f0e1f6a4d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-3ec0b8bc-5813-4ff7-858e-48fcb9d507ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-935314938-172.17.0.12-1595886927109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44348,DS-59e94766-cddc-471d-abe3-1e23ce1510d5,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-cc44fcf7-5aa7-43c3-8e14-0c20775e1e74,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-b1da85f6-66d7-4a72-b123-86cbbc02e459,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-8f529d1c-886f-45a4-80db-02a746abceaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33739,DS-87f5103d-383c-4744-8a8a-c51b671248d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-6dc5f188-bc88-4209-ae3c-543730ebf1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-e8c7f420-6703-4d26-8f0e-5c582e6ea856,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-165dfea7-4c38-489d-a482-0d347f283a1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-935314938-172.17.0.12-1595886927109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44348,DS-59e94766-cddc-471d-abe3-1e23ce1510d5,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-cc44fcf7-5aa7-43c3-8e14-0c20775e1e74,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-b1da85f6-66d7-4a72-b123-86cbbc02e459,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-8f529d1c-886f-45a4-80db-02a746abceaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33739,DS-87f5103d-383c-4744-8a8a-c51b671248d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-6dc5f188-bc88-4209-ae3c-543730ebf1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-e8c7f420-6703-4d26-8f0e-5c582e6ea856,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-165dfea7-4c38-489d-a482-0d347f283a1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1936679547-172.17.0.12-1595887003646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43892,DS-a41d684e-9eb7-44e6-9a34-c9b297e42058,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-29c897bc-f5be-424d-9192-54499acf7fae,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-b8eacd5e-a4d2-4b3e-bd78-d841916ab4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-a1b238b0-90d9-4df4-8db9-0cec796887a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-ba710ff0-01ce-4c7e-afcf-0736ed901102,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-4a8a0dbc-f449-458a-91d3-f7dbf1474fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-2568321a-0108-4ad7-b9f3-ce5e16c7c225,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-89b05bb9-593e-48d3-a0fa-b2133876891c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1936679547-172.17.0.12-1595887003646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43892,DS-a41d684e-9eb7-44e6-9a34-c9b297e42058,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-29c897bc-f5be-424d-9192-54499acf7fae,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-b8eacd5e-a4d2-4b3e-bd78-d841916ab4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-a1b238b0-90d9-4df4-8db9-0cec796887a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-ba710ff0-01ce-4c7e-afcf-0736ed901102,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-4a8a0dbc-f449-458a-91d3-f7dbf1474fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-2568321a-0108-4ad7-b9f3-ce5e16c7c225,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-89b05bb9-593e-48d3-a0fa-b2133876891c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1760619786-172.17.0.12-1595887248842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44061,DS-4114e348-eb35-4e9b-afe2-df30c7c2ec0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-38c34a30-9c1d-4b81-a462-29925b65e725,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-98e894d5-a13a-4ac4-b940-323afbf0a100,DISK], DatanodeInfoWithStorage[127.0.0.1:40627,DS-01fc1c46-5f78-498d-b007-33d0defe5e57,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-2532a1bf-40c0-41b8-888c-0339308d76cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37869,DS-e33a4b90-811c-42f0-906a-97a9ece49e93,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-da8532a2-fce4-42d6-aa6e-f8ebf60e4cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:46496,DS-daab648f-e316-4362-b910-e1f809f96ade,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1760619786-172.17.0.12-1595887248842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44061,DS-4114e348-eb35-4e9b-afe2-df30c7c2ec0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-38c34a30-9c1d-4b81-a462-29925b65e725,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-98e894d5-a13a-4ac4-b940-323afbf0a100,DISK], DatanodeInfoWithStorage[127.0.0.1:40627,DS-01fc1c46-5f78-498d-b007-33d0defe5e57,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-2532a1bf-40c0-41b8-888c-0339308d76cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37869,DS-e33a4b90-811c-42f0-906a-97a9ece49e93,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-da8532a2-fce4-42d6-aa6e-f8ebf60e4cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:46496,DS-daab648f-e316-4362-b910-e1f809f96ade,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-447975780-172.17.0.12-1595887293126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35220,DS-7adc4de9-2b42-4d8f-b135-7a20c0bb2190,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-77f55c1b-aede-410b-8b26-2570059f7b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38296,DS-4a3a5dad-c114-4196-b3b3-a96ddb6e6e59,DISK], DatanodeInfoWithStorage[127.0.0.1:36477,DS-242ae744-1725-43d3-83f8-92f65c9ac0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41671,DS-5320dcae-2e00-4e9b-9b44-7193b6500051,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-03e35dc1-e900-4327-9a5b-442a2550a981,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-dc65a440-f4bc-4209-bf3f-5a72f4a3a9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-c1e665aa-2f5f-49ed-8dbc-50ca4aa0f520,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-447975780-172.17.0.12-1595887293126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35220,DS-7adc4de9-2b42-4d8f-b135-7a20c0bb2190,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-77f55c1b-aede-410b-8b26-2570059f7b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38296,DS-4a3a5dad-c114-4196-b3b3-a96ddb6e6e59,DISK], DatanodeInfoWithStorage[127.0.0.1:36477,DS-242ae744-1725-43d3-83f8-92f65c9ac0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41671,DS-5320dcae-2e00-4e9b-9b44-7193b6500051,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-03e35dc1-e900-4327-9a5b-442a2550a981,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-dc65a440-f4bc-4209-bf3f-5a72f4a3a9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-c1e665aa-2f5f-49ed-8dbc-50ca4aa0f520,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1494904585-172.17.0.12-1595888121109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43603,DS-d8a974a3-b683-4010-9330-ddfecb24885e,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-dfc937eb-c179-4c8a-a357-f984d399cc80,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-22ffe2be-174c-44f6-8863-0e9f5aa9f5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-d3f07806-dc83-4dc2-9599-54c8e058747c,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-f68e24f2-f2dd-46ef-8f27-8879e7217a94,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-0771ad20-4d27-4f90-a456-01b10efa55e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-f6b7a387-209f-41c3-9dd6-11ca59fa3d01,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-3bc96754-f68f-4bd9-9999-5ccfd926f29a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1494904585-172.17.0.12-1595888121109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43603,DS-d8a974a3-b683-4010-9330-ddfecb24885e,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-dfc937eb-c179-4c8a-a357-f984d399cc80,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-22ffe2be-174c-44f6-8863-0e9f5aa9f5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-d3f07806-dc83-4dc2-9599-54c8e058747c,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-f68e24f2-f2dd-46ef-8f27-8879e7217a94,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-0771ad20-4d27-4f90-a456-01b10efa55e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-f6b7a387-209f-41c3-9dd6-11ca59fa3d01,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-3bc96754-f68f-4bd9-9999-5ccfd926f29a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1322061165-172.17.0.12-1595888287730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35127,DS-d99435d2-001a-4281-ae35-3b15bcbb0ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-d8d6f5ce-a9f9-461b-83d3-2c9bcc78505c,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-3827d04b-d7f6-45fe-8e38-95d5fec34c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-323bea83-6ee7-4ca1-866b-e30cbca5dd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-bf5e7375-9e14-49bb-964a-a721818280f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38552,DS-3001648f-ce6a-4424-bcd5-351b2d75a15b,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-3c540bbb-4738-4f5e-93d4-77df2ca1490d,DISK], DatanodeInfoWithStorage[127.0.0.1:35821,DS-d9d09526-b043-461d-bb26-1bcec2927a7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1322061165-172.17.0.12-1595888287730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35127,DS-d99435d2-001a-4281-ae35-3b15bcbb0ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-d8d6f5ce-a9f9-461b-83d3-2c9bcc78505c,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-3827d04b-d7f6-45fe-8e38-95d5fec34c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-323bea83-6ee7-4ca1-866b-e30cbca5dd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-bf5e7375-9e14-49bb-964a-a721818280f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38552,DS-3001648f-ce6a-4424-bcd5-351b2d75a15b,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-3c540bbb-4738-4f5e-93d4-77df2ca1490d,DISK], DatanodeInfoWithStorage[127.0.0.1:35821,DS-d9d09526-b043-461d-bb26-1bcec2927a7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5593
