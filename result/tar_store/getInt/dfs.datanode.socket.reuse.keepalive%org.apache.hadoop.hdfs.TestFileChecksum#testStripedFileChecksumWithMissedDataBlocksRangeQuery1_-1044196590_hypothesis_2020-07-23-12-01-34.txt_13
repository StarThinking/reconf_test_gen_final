reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1056957597-172.17.0.2-1595505782210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39960,DS-4e2bc20d-8bb4-41b5-888e-fc2be6c45805,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-aac4bda4-6b35-44c8-93cd-3b6204c08848,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-4335a7ac-8e83-4b1d-a9e1-4adf849bc60a,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-f86d7eb0-ca95-4d0e-a6b4-ec1356d40730,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-89d23201-bfd1-4382-b118-104ab2e228bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-f18d3663-f78d-463c-93d5-a3c504a13c81,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-eafdd707-811d-4bf2-a394-7f0be8b8eed5,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-72ad28c7-77ed-4e70-b3d8-1dd8e0541790,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1056957597-172.17.0.2-1595505782210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39960,DS-4e2bc20d-8bb4-41b5-888e-fc2be6c45805,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-aac4bda4-6b35-44c8-93cd-3b6204c08848,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-4335a7ac-8e83-4b1d-a9e1-4adf849bc60a,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-f86d7eb0-ca95-4d0e-a6b4-ec1356d40730,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-89d23201-bfd1-4382-b118-104ab2e228bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-f18d3663-f78d-463c-93d5-a3c504a13c81,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-eafdd707-811d-4bf2-a394-7f0be8b8eed5,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-72ad28c7-77ed-4e70-b3d8-1dd8e0541790,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1430332284-172.17.0.2-1595505958723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39886,DS-9cb62f8a-c11c-4cb5-9fea-4087b3903411,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-2f6feefc-64b6-4c14-a7b7-8be30cb0cf01,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-13f2471d-f6f7-4227-bbc5-a17249ac603f,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-9b6e2397-6f82-4e9a-a11b-7c755a2b690c,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-31a601b8-0ece-49fc-8240-1e85f752c140,DISK], DatanodeInfoWithStorage[127.0.0.1:34657,DS-d80d6aa1-a320-4f23-a990-c445e6333c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-9e364edf-d842-4c30-ad38-7541ef4f0b52,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-ebf3c419-6926-4dd1-b8c2-a4dc42d7876d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1430332284-172.17.0.2-1595505958723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39886,DS-9cb62f8a-c11c-4cb5-9fea-4087b3903411,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-2f6feefc-64b6-4c14-a7b7-8be30cb0cf01,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-13f2471d-f6f7-4227-bbc5-a17249ac603f,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-9b6e2397-6f82-4e9a-a11b-7c755a2b690c,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-31a601b8-0ece-49fc-8240-1e85f752c140,DISK], DatanodeInfoWithStorage[127.0.0.1:34657,DS-d80d6aa1-a320-4f23-a990-c445e6333c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-9e364edf-d842-4c30-ad38-7541ef4f0b52,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-ebf3c419-6926-4dd1-b8c2-a4dc42d7876d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1270486185-172.17.0.2-1595505996388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34745,DS-47305b78-4a8e-4fff-849d-595218c32c44,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-7b82b13f-b541-4b6c-8681-e7ced1265c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-5bcdf63a-489e-4710-8932-dd0cf372d0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-3ff4134c-6fd3-4433-9f79-706c9fb2455f,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-4fcbebcb-96d8-4baf-87a0-4ed269623340,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-ff2033ea-505c-440d-8618-2c2468780671,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-6f0bf7a1-2e4f-44c5-9a1e-50e8dee83548,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-10e0b885-f780-435a-b9c2-0f426066273a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1270486185-172.17.0.2-1595505996388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34745,DS-47305b78-4a8e-4fff-849d-595218c32c44,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-7b82b13f-b541-4b6c-8681-e7ced1265c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-5bcdf63a-489e-4710-8932-dd0cf372d0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-3ff4134c-6fd3-4433-9f79-706c9fb2455f,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-4fcbebcb-96d8-4baf-87a0-4ed269623340,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-ff2033ea-505c-440d-8618-2c2468780671,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-6f0bf7a1-2e4f-44c5-9a1e-50e8dee83548,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-10e0b885-f780-435a-b9c2-0f426066273a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1175663038-172.17.0.2-1595506143151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39351,DS-01ee4f8b-d925-4417-a43d-88e477b8fe70,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-ba396a05-61fb-4b97-824f-7e6e0a8105fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-da67ca01-7411-4925-abb8-ddbfaffa678b,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-c96defd0-75ed-4fd1-8e78-3b3624f861dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-c533553a-3482-4832-a4e1-a4395b39d2be,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-7aaf11d0-e65b-45d0-a1ee-81c268e2e3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44542,DS-0a9b123c-703a-451d-868a-9d36edc19a36,DISK], DatanodeInfoWithStorage[127.0.0.1:35015,DS-2cab1dfe-b552-4f01-973d-1ffc40029af0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1175663038-172.17.0.2-1595506143151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39351,DS-01ee4f8b-d925-4417-a43d-88e477b8fe70,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-ba396a05-61fb-4b97-824f-7e6e0a8105fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-da67ca01-7411-4925-abb8-ddbfaffa678b,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-c96defd0-75ed-4fd1-8e78-3b3624f861dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-c533553a-3482-4832-a4e1-a4395b39d2be,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-7aaf11d0-e65b-45d0-a1ee-81c268e2e3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44542,DS-0a9b123c-703a-451d-868a-9d36edc19a36,DISK], DatanodeInfoWithStorage[127.0.0.1:35015,DS-2cab1dfe-b552-4f01-973d-1ffc40029af0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1675894212-172.17.0.2-1595506183004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37676,DS-8346f2dc-627f-4e60-a70c-e965aeec52d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-d98ba24f-25bb-43c6-9f0f-83b3c496891c,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-dee857c3-83d9-47fc-bf88-d8625c6479bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-ed50e130-aee9-4119-9c47-6699d82bf3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-a0fc6183-1a1b-49bc-8e59-3b01cf26f27c,DISK], DatanodeInfoWithStorage[127.0.0.1:42269,DS-e4ae1c96-127a-4ede-bacb-a61aa1029eba,DISK], DatanodeInfoWithStorage[127.0.0.1:37570,DS-1ef3f45a-35e7-4d30-be3a-3088993505f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-70b0e2b0-6503-48c7-8115-ce8659121880,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1675894212-172.17.0.2-1595506183004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37676,DS-8346f2dc-627f-4e60-a70c-e965aeec52d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-d98ba24f-25bb-43c6-9f0f-83b3c496891c,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-dee857c3-83d9-47fc-bf88-d8625c6479bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-ed50e130-aee9-4119-9c47-6699d82bf3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-a0fc6183-1a1b-49bc-8e59-3b01cf26f27c,DISK], DatanodeInfoWithStorage[127.0.0.1:42269,DS-e4ae1c96-127a-4ede-bacb-a61aa1029eba,DISK], DatanodeInfoWithStorage[127.0.0.1:37570,DS-1ef3f45a-35e7-4d30-be3a-3088993505f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-70b0e2b0-6503-48c7-8115-ce8659121880,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1415474888-172.17.0.2-1595506518801:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42566,DS-39ebdcf1-7ce2-49c5-bcff-ffb15e0eec98,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-15ac1871-74fb-44b0-b34e-2f8c613818de,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-928e4d68-c784-42b0-9b0f-8b3f939080fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-e606d47a-4ff8-44ec-92a4-de83e2d0dab7,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-d871a9be-293f-43a0-a2ae-c30c8ad0a82d,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-8b4c94cf-c8ed-41b8-a1fa-c0ada9a13238,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-8d8cb090-58b1-4bea-9d6c-eb95d6f25b13,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-29ee326e-2fb5-4f4a-8464-7cf77db74c91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1415474888-172.17.0.2-1595506518801:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42566,DS-39ebdcf1-7ce2-49c5-bcff-ffb15e0eec98,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-15ac1871-74fb-44b0-b34e-2f8c613818de,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-928e4d68-c784-42b0-9b0f-8b3f939080fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-e606d47a-4ff8-44ec-92a4-de83e2d0dab7,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-d871a9be-293f-43a0-a2ae-c30c8ad0a82d,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-8b4c94cf-c8ed-41b8-a1fa-c0ada9a13238,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-8d8cb090-58b1-4bea-9d6c-eb95d6f25b13,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-29ee326e-2fb5-4f4a-8464-7cf77db74c91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663135546-172.17.0.2-1595506931931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34281,DS-29d518a9-3caf-498e-ba2b-6126f48af999,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-38065146-d329-4709-9edb-f3c96cd17ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-53d82900-5b2c-4945-b701-d90d60688397,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-f2f784fe-00ad-4825-9eb3-cd647a82402b,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-820a1542-22ae-4481-aa38-bc284b4e9b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-bddcdde6-d3af-447c-a3a6-768dd3dccae8,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-9be0432d-5cd7-436c-ab9f-c9ada379069c,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-73fd2d15-fb9a-4577-a957-79557a78fa43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663135546-172.17.0.2-1595506931931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34281,DS-29d518a9-3caf-498e-ba2b-6126f48af999,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-38065146-d329-4709-9edb-f3c96cd17ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-53d82900-5b2c-4945-b701-d90d60688397,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-f2f784fe-00ad-4825-9eb3-cd647a82402b,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-820a1542-22ae-4481-aa38-bc284b4e9b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-bddcdde6-d3af-447c-a3a6-768dd3dccae8,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-9be0432d-5cd7-436c-ab9f-c9ada379069c,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-73fd2d15-fb9a-4577-a957-79557a78fa43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2006238903-172.17.0.2-1595507278415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44215,DS-5c58e042-b5ef-4445-9b3d-959986676429,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-59350cb1-b862-41e2-873a-bc44ae34fb23,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-b40f6566-e40b-4730-ba38-589e116e1be8,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-dab5c86b-09aa-41ee-bf37-496a5cecca49,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-28b4312b-4b2d-4780-bbed-7cd1a537f2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-97ed319f-dd14-4506-9786-2ab37cc15f02,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-72f26ff0-ba1f-473a-aa0c-37f28865d183,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-e60928eb-a55a-4fc8-ab23-636a703b2e2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2006238903-172.17.0.2-1595507278415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44215,DS-5c58e042-b5ef-4445-9b3d-959986676429,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-59350cb1-b862-41e2-873a-bc44ae34fb23,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-b40f6566-e40b-4730-ba38-589e116e1be8,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-dab5c86b-09aa-41ee-bf37-496a5cecca49,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-28b4312b-4b2d-4780-bbed-7cd1a537f2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-97ed319f-dd14-4506-9786-2ab37cc15f02,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-72f26ff0-ba1f-473a-aa0c-37f28865d183,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-e60928eb-a55a-4fc8-ab23-636a703b2e2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-230164105-172.17.0.2-1595507598340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35827,DS-41fcb328-16d8-4289-9386-1f331b01cdb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-f2343b0c-c076-49aa-9c23-d2c37b1d508b,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-5b0679e1-8ed1-4a91-a163-e80feda0c502,DISK], DatanodeInfoWithStorage[127.0.0.1:38925,DS-3f2e1def-d3e9-40b0-ae06-2bfead63433a,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-c4be3d6e-b9ef-490e-b443-7904c19003c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-b91cd36f-ee7a-4279-8bc7-57ff15d6dded,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-89ff4356-2c14-48b2-8c13-a698527749c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-16245e7f-b941-4685-82df-679bbe770870,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-230164105-172.17.0.2-1595507598340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35827,DS-41fcb328-16d8-4289-9386-1f331b01cdb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-f2343b0c-c076-49aa-9c23-d2c37b1d508b,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-5b0679e1-8ed1-4a91-a163-e80feda0c502,DISK], DatanodeInfoWithStorage[127.0.0.1:38925,DS-3f2e1def-d3e9-40b0-ae06-2bfead63433a,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-c4be3d6e-b9ef-490e-b443-7904c19003c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-b91cd36f-ee7a-4279-8bc7-57ff15d6dded,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-89ff4356-2c14-48b2-8c13-a698527749c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-16245e7f-b941-4685-82df-679bbe770870,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2002563626-172.17.0.2-1595507751680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38874,DS-9283232d-775a-4823-a659-58624a6bda88,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-a3b113f9-1f54-4701-88a6-ff9a5815848b,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-54e5c9e2-7753-4cb3-862d-f46649db1737,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-491334a4-f947-4731-8b73-c89caeb79e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-915def42-c03c-4abf-bca1-ab71ea6a4ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-af59af32-c1c3-4ff3-b58f-03f3070574ff,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-1fa2c494-f9c9-4bbd-a062-0e43ad6a8be3,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-32942453-3ac0-40cf-ba63-564784e854b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2002563626-172.17.0.2-1595507751680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38874,DS-9283232d-775a-4823-a659-58624a6bda88,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-a3b113f9-1f54-4701-88a6-ff9a5815848b,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-54e5c9e2-7753-4cb3-862d-f46649db1737,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-491334a4-f947-4731-8b73-c89caeb79e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-915def42-c03c-4abf-bca1-ab71ea6a4ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-af59af32-c1c3-4ff3-b58f-03f3070574ff,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-1fa2c494-f9c9-4bbd-a062-0e43ad6a8be3,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-32942453-3ac0-40cf-ba63-564784e854b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1179701426-172.17.0.2-1595508003279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40971,DS-2b29b201-81cd-4fba-838d-9278f77f39cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38724,DS-09ff8357-7112-4540-a9c3-5640ea52398a,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-e0589f58-d7be-43f9-950b-63ea61a36671,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-785e051d-d3ff-46d6-8c4d-ebce8227dd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-3e791a3d-b915-4cc7-878b-4b524310ee4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-dbfb2952-91bd-4fe6-b0ce-f1c8c9434c57,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-e3bc340f-bc35-4b16-956a-18f31e4a0c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-406f0c8d-5f7e-448a-9f7b-5f5ec60a6319,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1179701426-172.17.0.2-1595508003279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40971,DS-2b29b201-81cd-4fba-838d-9278f77f39cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38724,DS-09ff8357-7112-4540-a9c3-5640ea52398a,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-e0589f58-d7be-43f9-950b-63ea61a36671,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-785e051d-d3ff-46d6-8c4d-ebce8227dd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-3e791a3d-b915-4cc7-878b-4b524310ee4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-dbfb2952-91bd-4fe6-b0ce-f1c8c9434c57,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-e3bc340f-bc35-4b16-956a-18f31e4a0c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-406f0c8d-5f7e-448a-9f7b-5f5ec60a6319,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1707004698-172.17.0.2-1595508141370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36266,DS-7deba544-dfae-4dc2-a2ba-d251d3cac2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-6adede26-061f-4436-b972-c7c2011c7249,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-69d40fa6-9825-4800-9547-adeb4029c4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37401,DS-83133892-6bca-4393-8e39-f4be856f6eae,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-94077b8a-1bee-499e-96c5-64f546d0fa0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-22c54a47-5c5f-4373-b49f-9b9138198c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-4bd833ea-8ed4-4eee-b14e-bad7346d618d,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-183fb2b7-c197-408c-9bbb-1b09f32b9f8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1707004698-172.17.0.2-1595508141370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36266,DS-7deba544-dfae-4dc2-a2ba-d251d3cac2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-6adede26-061f-4436-b972-c7c2011c7249,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-69d40fa6-9825-4800-9547-adeb4029c4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37401,DS-83133892-6bca-4393-8e39-f4be856f6eae,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-94077b8a-1bee-499e-96c5-64f546d0fa0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-22c54a47-5c5f-4373-b49f-9b9138198c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-4bd833ea-8ed4-4eee-b14e-bad7346d618d,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-183fb2b7-c197-408c-9bbb-1b09f32b9f8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211027273-172.17.0.2-1595508275147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42489,DS-6c5f73af-a509-4cc0-8bba-016eaba0cd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-e27b88e8-3c11-4bdf-8feb-b59c549b33a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-8f1d9310-54b2-44e0-a410-49358f322297,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-aead0c43-68d6-4ef9-b30d-09f3715d23e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38152,DS-d54b607a-065d-41b7-8e97-98b350cb958f,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-cc71154a-9b81-4211-9b21-d77662308cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-11b19800-2a31-4b6a-86a4-185d3e557292,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-242921b8-1751-476f-ab76-b67865357f12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211027273-172.17.0.2-1595508275147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42489,DS-6c5f73af-a509-4cc0-8bba-016eaba0cd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-e27b88e8-3c11-4bdf-8feb-b59c549b33a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-8f1d9310-54b2-44e0-a410-49358f322297,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-aead0c43-68d6-4ef9-b30d-09f3715d23e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38152,DS-d54b607a-065d-41b7-8e97-98b350cb958f,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-cc71154a-9b81-4211-9b21-d77662308cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-11b19800-2a31-4b6a-86a4-185d3e557292,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-242921b8-1751-476f-ab76-b67865357f12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-213189662-172.17.0.2-1595508719786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36393,DS-3bec8902-45c3-4c96-9274-25460bf1d9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-75a7649b-42bb-4f4a-8bfe-d7e32297fd66,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-9dbd8322-a41d-4191-b8b8-8d6b5d3433d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-c8c49db2-191d-41b3-b239-9c01a9c95f10,DISK], DatanodeInfoWithStorage[127.0.0.1:44846,DS-f01db968-a472-49d4-bfdb-ae8e6bd3890f,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-e946fcc6-09f1-4bb3-8ec8-97084f5c1d07,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-fb500b80-16c8-4ebb-9720-9f1b0b1f67d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-e3c06cb0-e4ae-46d7-866b-7d7aa2db8c64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-213189662-172.17.0.2-1595508719786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36393,DS-3bec8902-45c3-4c96-9274-25460bf1d9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-75a7649b-42bb-4f4a-8bfe-d7e32297fd66,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-9dbd8322-a41d-4191-b8b8-8d6b5d3433d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-c8c49db2-191d-41b3-b239-9c01a9c95f10,DISK], DatanodeInfoWithStorage[127.0.0.1:44846,DS-f01db968-a472-49d4-bfdb-ae8e6bd3890f,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-e946fcc6-09f1-4bb3-8ec8-97084f5c1d07,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-fb500b80-16c8-4ebb-9720-9f1b0b1f67d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-e3c06cb0-e4ae-46d7-866b-7d7aa2db8c64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-317003868-172.17.0.2-1595508788580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43847,DS-34a29505-5bd8-4f3b-b97e-0db7f0bcd412,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-601259fd-51a8-423a-a344-5471d750e2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-539a5904-5745-4556-b826-15182cefb3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-e302e339-365a-4a6c-8110-f523e79ba6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-cf0d02fb-2e1c-4e6a-bf83-cc95a8a59c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-57309819-ba24-43f5-9785-858aece00ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-52e4e60a-a8be-4d53-8e5f-f8a6458fcc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-b692f102-e77b-4df2-8d18-1edf54f264c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-317003868-172.17.0.2-1595508788580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43847,DS-34a29505-5bd8-4f3b-b97e-0db7f0bcd412,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-601259fd-51a8-423a-a344-5471d750e2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-539a5904-5745-4556-b826-15182cefb3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-e302e339-365a-4a6c-8110-f523e79ba6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-cf0d02fb-2e1c-4e6a-bf83-cc95a8a59c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-57309819-ba24-43f5-9785-858aece00ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-52e4e60a-a8be-4d53-8e5f-f8a6458fcc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-b692f102-e77b-4df2-8d18-1edf54f264c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2045774101-172.17.0.2-1595509001167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39114,DS-55070b8d-d6a3-4d4a-b944-b70d610f68d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-7d9daebf-95ad-4f33-86b4-cb6470bd6d84,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-c0760aef-284d-4e0d-bb85-37ad90fd05fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-0333c629-1ba9-4427-981b-1940fb2aa193,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-4f374b0a-fd43-4a89-b966-117492745c83,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-24ec7860-5552-4f29-a06f-0d680010d542,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-f7ced349-c800-4f6f-b3ae-8755f4772e35,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-a711c3f3-471c-4e62-be0b-fd388f83155d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2045774101-172.17.0.2-1595509001167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39114,DS-55070b8d-d6a3-4d4a-b944-b70d610f68d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-7d9daebf-95ad-4f33-86b4-cb6470bd6d84,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-c0760aef-284d-4e0d-bb85-37ad90fd05fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-0333c629-1ba9-4427-981b-1940fb2aa193,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-4f374b0a-fd43-4a89-b966-117492745c83,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-24ec7860-5552-4f29-a06f-0d680010d542,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-f7ced349-c800-4f6f-b3ae-8755f4772e35,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-a711c3f3-471c-4e62-be0b-fd388f83155d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-294166721-172.17.0.2-1595509305346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45991,DS-ba91d500-4285-4986-b96b-7281863bd2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-a5012e6d-dcbb-49b5-ba87-79da7dc86d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-20b69301-3c34-4249-ad56-8b68c8cddd12,DISK], DatanodeInfoWithStorage[127.0.0.1:35618,DS-d76d593b-6b1f-4587-898f-6cdec45d1447,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-2a6b1637-2066-4d50-967d-68e678deae51,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-98dcf3e1-ad93-4086-a9ff-144108ee7b62,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-7521a4ee-c858-454b-98ad-a801a6febe21,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-3c121603-99f3-4a51-b543-23e9b4e04450,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-294166721-172.17.0.2-1595509305346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45991,DS-ba91d500-4285-4986-b96b-7281863bd2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-a5012e6d-dcbb-49b5-ba87-79da7dc86d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-20b69301-3c34-4249-ad56-8b68c8cddd12,DISK], DatanodeInfoWithStorage[127.0.0.1:35618,DS-d76d593b-6b1f-4587-898f-6cdec45d1447,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-2a6b1637-2066-4d50-967d-68e678deae51,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-98dcf3e1-ad93-4086-a9ff-144108ee7b62,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-7521a4ee-c858-454b-98ad-a801a6febe21,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-3c121603-99f3-4a51-b543-23e9b4e04450,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1294724702-172.17.0.2-1595509377586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44256,DS-c1377e24-d21a-4960-adfb-bfdcfb12cc56,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-0d44ba8d-0cd9-4323-a507-c4a3c2a353da,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-6311f987-33c7-467a-b003-d308e93effdf,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-a8a074cc-c9e4-446c-893e-9627bf31c95e,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-f6bdcf71-4c75-4284-a454-03e4291164e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43457,DS-8a8eca04-a035-426f-87e4-b3114f8b88a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-41334e96-f1ec-4864-aeb9-620979a1cbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-23db852d-24da-4484-9f0c-76f17ca92f60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1294724702-172.17.0.2-1595509377586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44256,DS-c1377e24-d21a-4960-adfb-bfdcfb12cc56,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-0d44ba8d-0cd9-4323-a507-c4a3c2a353da,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-6311f987-33c7-467a-b003-d308e93effdf,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-a8a074cc-c9e4-446c-893e-9627bf31c95e,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-f6bdcf71-4c75-4284-a454-03e4291164e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43457,DS-8a8eca04-a035-426f-87e4-b3114f8b88a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-41334e96-f1ec-4864-aeb9-620979a1cbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-23db852d-24da-4484-9f0c-76f17ca92f60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-155517549-172.17.0.2-1595509720790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45132,DS-d758cdcd-f774-496b-84ee-b373e14caf74,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-0b3184df-c32f-4522-83cb-5503df98b4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-8debe2b0-8171-47a2-84c5-5af5e8dbbdaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-afc38103-b9ff-4e63-b348-f52b466e617e,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-73a45a7f-b418-4a95-bf37-6c279becd299,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-c8590840-2db2-4e2c-8001-5ae8de2a33e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-9ca0a183-4d37-4dc6-8382-9ef0cb4259ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-860db3d7-d37f-4bb4-9741-1a9f4d222bfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-155517549-172.17.0.2-1595509720790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45132,DS-d758cdcd-f774-496b-84ee-b373e14caf74,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-0b3184df-c32f-4522-83cb-5503df98b4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-8debe2b0-8171-47a2-84c5-5af5e8dbbdaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-afc38103-b9ff-4e63-b348-f52b466e617e,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-73a45a7f-b418-4a95-bf37-6c279becd299,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-c8590840-2db2-4e2c-8001-5ae8de2a33e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-9ca0a183-4d37-4dc6-8382-9ef0cb4259ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-860db3d7-d37f-4bb4-9741-1a9f4d222bfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-66226439-172.17.0.2-1595510145948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33839,DS-1aac4ee6-e814-41fe-abc8-a486f745f8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-31cfc379-f68e-47fb-9e8f-fc0eb5a2a609,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-1e45fc3a-2a3b-4d70-bf7e-07606c9fdad2,DISK], DatanodeInfoWithStorage[127.0.0.1:32952,DS-78fa329f-67f5-454c-96e2-41e5f4bb7946,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-bf628975-34bf-4d55-91e8-0c38d99504d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-6ced092e-3eb2-4343-91a7-b8e7e580874f,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-974d30d5-9a1a-4a23-b839-f26e4ce1e7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-50a01763-94b8-4ed4-8edc-e7d69fbd4f78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-66226439-172.17.0.2-1595510145948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33839,DS-1aac4ee6-e814-41fe-abc8-a486f745f8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-31cfc379-f68e-47fb-9e8f-fc0eb5a2a609,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-1e45fc3a-2a3b-4d70-bf7e-07606c9fdad2,DISK], DatanodeInfoWithStorage[127.0.0.1:32952,DS-78fa329f-67f5-454c-96e2-41e5f4bb7946,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-bf628975-34bf-4d55-91e8-0c38d99504d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-6ced092e-3eb2-4343-91a7-b8e7e580874f,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-974d30d5-9a1a-4a23-b839-f26e4ce1e7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-50a01763-94b8-4ed4-8edc-e7d69fbd4f78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2060854564-172.17.0.2-1595510185684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45496,DS-c07759f5-f7ae-4262-9523-4573321a0dac,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-9838531a-3a5e-40db-911b-d77d550649ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-23f25145-5454-4f5f-b67f-7f11201cd395,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-6e646b19-7c71-4c2f-9270-0fac1e383e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-b84a9ef1-e406-4056-90e7-1f6851a38fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-5c28b576-2331-482e-b972-eabc26971e32,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-44b2afbc-8134-4a34-854b-f651efc2196a,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-2f1d6b70-57fb-4d71-a4aa-bc44997e4f4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2060854564-172.17.0.2-1595510185684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45496,DS-c07759f5-f7ae-4262-9523-4573321a0dac,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-9838531a-3a5e-40db-911b-d77d550649ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-23f25145-5454-4f5f-b67f-7f11201cd395,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-6e646b19-7c71-4c2f-9270-0fac1e383e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-b84a9ef1-e406-4056-90e7-1f6851a38fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-5c28b576-2331-482e-b972-eabc26971e32,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-44b2afbc-8134-4a34-854b-f651efc2196a,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-2f1d6b70-57fb-4d71-a4aa-bc44997e4f4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1429991744-172.17.0.2-1595510530086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41734,DS-643ea75f-ae71-436d-bf4e-d5897d52f76d,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-2e6ef7a9-a69b-4679-9e5e-2c3f2b80e8b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-ceb63487-9c93-49da-a310-aacdf9bf0468,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-ede57150-9a44-4755-9200-e18ace051268,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-600fd0fe-6972-4230-909b-3e39e5c98151,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-06b15087-dc24-4d65-ac4e-b728729135b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-e356d1ab-154e-4f4a-a79c-945fd2b525ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44159,DS-f6eb9d9f-3feb-4b0d-8cb0-ac0f99f227d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1429991744-172.17.0.2-1595510530086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41734,DS-643ea75f-ae71-436d-bf4e-d5897d52f76d,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-2e6ef7a9-a69b-4679-9e5e-2c3f2b80e8b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-ceb63487-9c93-49da-a310-aacdf9bf0468,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-ede57150-9a44-4755-9200-e18ace051268,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-600fd0fe-6972-4230-909b-3e39e5c98151,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-06b15087-dc24-4d65-ac4e-b728729135b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-e356d1ab-154e-4f4a-a79c-945fd2b525ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44159,DS-f6eb9d9f-3feb-4b0d-8cb0-ac0f99f227d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1036888324-172.17.0.2-1595510674783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35468,DS-2344cee3-1225-4011-b870-3b62b0e28eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-41a7cb15-9ef0-4382-acc4-06cf11b720de,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-152853ef-b39d-422f-996f-daf3ef59728b,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-4742dd3e-b4ec-4ff0-a15f-db0c4a4dd8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-8be96dd8-5638-40f8-b8b8-56de4503e8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-ce2c5e9e-b007-4233-a541-6bba40c56239,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-dc92f162-12b9-4fe9-bf66-3c8f18166f10,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-a90104f8-4473-470d-93b4-5c68fe512795,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1036888324-172.17.0.2-1595510674783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35468,DS-2344cee3-1225-4011-b870-3b62b0e28eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-41a7cb15-9ef0-4382-acc4-06cf11b720de,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-152853ef-b39d-422f-996f-daf3ef59728b,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-4742dd3e-b4ec-4ff0-a15f-db0c4a4dd8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-8be96dd8-5638-40f8-b8b8-56de4503e8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-ce2c5e9e-b007-4233-a541-6bba40c56239,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-dc92f162-12b9-4fe9-bf66-3c8f18166f10,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-a90104f8-4473-470d-93b4-5c68fe512795,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-12450349-172.17.0.2-1595510786594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40323,DS-cf71df59-37f4-4699-a8f8-6fe48287f51e,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-cff24ad7-5bd1-4b27-a786-e044b3cf4145,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-dff566ad-02a5-49b0-8a72-21bbec6c3749,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-ee18320a-bc81-4c8d-a6eb-fb8708328f50,DISK], DatanodeInfoWithStorage[127.0.0.1:37320,DS-6cf2d662-f2fa-4425-b451-f4e97a85cfd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-f7fe796d-7f99-4c90-a0a7-5f386d177435,DISK], DatanodeInfoWithStorage[127.0.0.1:40632,DS-4aca48c4-7f76-44ed-87aa-3bfcb583f595,DISK], DatanodeInfoWithStorage[127.0.0.1:34001,DS-5c1adb16-731c-4d25-b066-0f3c2de22ab4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-12450349-172.17.0.2-1595510786594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40323,DS-cf71df59-37f4-4699-a8f8-6fe48287f51e,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-cff24ad7-5bd1-4b27-a786-e044b3cf4145,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-dff566ad-02a5-49b0-8a72-21bbec6c3749,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-ee18320a-bc81-4c8d-a6eb-fb8708328f50,DISK], DatanodeInfoWithStorage[127.0.0.1:37320,DS-6cf2d662-f2fa-4425-b451-f4e97a85cfd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-f7fe796d-7f99-4c90-a0a7-5f386d177435,DISK], DatanodeInfoWithStorage[127.0.0.1:40632,DS-4aca48c4-7f76-44ed-87aa-3bfcb583f595,DISK], DatanodeInfoWithStorage[127.0.0.1:34001,DS-5c1adb16-731c-4d25-b066-0f3c2de22ab4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 5230
