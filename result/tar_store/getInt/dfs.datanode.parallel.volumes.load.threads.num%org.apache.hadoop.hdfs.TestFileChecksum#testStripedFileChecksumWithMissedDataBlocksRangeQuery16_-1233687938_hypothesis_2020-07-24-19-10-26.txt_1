reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-707468020-172.17.0.7-1595618417588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42292,DS-130003e7-95ee-4f2d-8cb5-66b73b1989e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-22847bd8-8726-417f-9039-ed6d3e59e1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-dde4d1d4-6c5d-4af3-9e9f-2de68a05b134,DISK], DatanodeInfoWithStorage[127.0.0.1:36496,DS-298e0646-24e2-4baa-bc90-f80d971ac004,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-e8400eff-b714-4b4c-8adb-cebb3b7d4c64,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-c77f2618-4d44-4f68-b090-92b978b7ed52,DISK], DatanodeInfoWithStorage[127.0.0.1:33263,DS-4c8e8ef9-54d0-4453-9a79-1c1f9d150c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-e99365fc-7722-49ef-81a4-ccce5049b1fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-707468020-172.17.0.7-1595618417588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42292,DS-130003e7-95ee-4f2d-8cb5-66b73b1989e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-22847bd8-8726-417f-9039-ed6d3e59e1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-dde4d1d4-6c5d-4af3-9e9f-2de68a05b134,DISK], DatanodeInfoWithStorage[127.0.0.1:36496,DS-298e0646-24e2-4baa-bc90-f80d971ac004,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-e8400eff-b714-4b4c-8adb-cebb3b7d4c64,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-c77f2618-4d44-4f68-b090-92b978b7ed52,DISK], DatanodeInfoWithStorage[127.0.0.1:33263,DS-4c8e8ef9-54d0-4453-9a79-1c1f9d150c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-e99365fc-7722-49ef-81a4-ccce5049b1fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-465817951-172.17.0.7-1595619092356:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32925,DS-1020886e-9f43-4c30-9ab3-8bba5580a782,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-55d52f43-5c8a-4473-8cad-4acb0d1273da,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-bc537549-9116-4d6f-ac6b-a1bf7580b5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-b816e86b-aef6-43c4-9c35-046b97560468,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-5010f1a4-e803-4905-811e-53de1b3ae252,DISK], DatanodeInfoWithStorage[127.0.0.1:36915,DS-d54d49cc-003f-4fa7-9119-e276ad038b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42297,DS-09a0e5e2-6520-428d-9fa8-3d59baf1c52f,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-e52c7119-9b0f-418b-9abd-7463ed274608,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-465817951-172.17.0.7-1595619092356:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32925,DS-1020886e-9f43-4c30-9ab3-8bba5580a782,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-55d52f43-5c8a-4473-8cad-4acb0d1273da,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-bc537549-9116-4d6f-ac6b-a1bf7580b5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-b816e86b-aef6-43c4-9c35-046b97560468,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-5010f1a4-e803-4905-811e-53de1b3ae252,DISK], DatanodeInfoWithStorage[127.0.0.1:36915,DS-d54d49cc-003f-4fa7-9119-e276ad038b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42297,DS-09a0e5e2-6520-428d-9fa8-3d59baf1c52f,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-e52c7119-9b0f-418b-9abd-7463ed274608,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1536252238-172.17.0.7-1595619744629:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44361,DS-39df7070-7ad1-4f09-9595-09391c93f8de,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-0849cece-3984-4a0b-9af7-eebe7ee0ebdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-da787a40-f891-4129-ad0f-e3a8c6a539f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36862,DS-73d453de-9480-4207-9201-73ea936cf97a,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-7ef14a78-7a38-4521-ad4f-315c13022142,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-38ff0be0-6e8c-4f2a-9bec-3abd2402835c,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-16a6b15e-5201-4a63-a054-cc41dd7b70b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-e9f00ee1-5c7e-460f-acb4-ab9b368063c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1536252238-172.17.0.7-1595619744629:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44361,DS-39df7070-7ad1-4f09-9595-09391c93f8de,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-0849cece-3984-4a0b-9af7-eebe7ee0ebdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-da787a40-f891-4129-ad0f-e3a8c6a539f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36862,DS-73d453de-9480-4207-9201-73ea936cf97a,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-7ef14a78-7a38-4521-ad4f-315c13022142,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-38ff0be0-6e8c-4f2a-9bec-3abd2402835c,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-16a6b15e-5201-4a63-a054-cc41dd7b70b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-e9f00ee1-5c7e-460f-acb4-ab9b368063c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1040710906-172.17.0.7-1595619851451:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35215,DS-5729f774-db08-4034-ad25-12509a6ec80b,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-634b88a5-69c6-4345-aa96-8bdabe4e62c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-81d26bdc-858a-4221-98ae-e059bb651aad,DISK], DatanodeInfoWithStorage[127.0.0.1:38775,DS-b91a423d-9a47-4a5b-85e3-692daa8c1f13,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-a98aae3d-a935-4f2b-a606-9e0fc5f4da68,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-a745592a-e585-491d-bf71-8feefd718e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-181ef681-df7d-4a0a-b259-72a3c15ddfed,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-b0c4770f-3adf-4bd4-a5bd-f96f108a741b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1040710906-172.17.0.7-1595619851451:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35215,DS-5729f774-db08-4034-ad25-12509a6ec80b,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-634b88a5-69c6-4345-aa96-8bdabe4e62c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-81d26bdc-858a-4221-98ae-e059bb651aad,DISK], DatanodeInfoWithStorage[127.0.0.1:38775,DS-b91a423d-9a47-4a5b-85e3-692daa8c1f13,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-a98aae3d-a935-4f2b-a606-9e0fc5f4da68,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-a745592a-e585-491d-bf71-8feefd718e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-181ef681-df7d-4a0a-b259-72a3c15ddfed,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-b0c4770f-3adf-4bd4-a5bd-f96f108a741b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1590781762-172.17.0.7-1595621518452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34562,DS-26bd2e6f-8f8b-44f7-aef4-a3ec253452aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-9fb11ec9-fb05-407f-823d-3e4a1d8ea6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-a6635ae4-cf33-456d-ae7c-1eec04741943,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-44fdae90-87a5-43ed-b359-767f0a72db07,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-9f8dd6ce-1fc2-44b9-a57a-5daf9280257a,DISK], DatanodeInfoWithStorage[127.0.0.1:46499,DS-df7f1712-48ca-4e71-92f7-b49b9e603e34,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-ba83a009-e186-4af3-b4de-8b1723f4ccb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-29ddf167-d67d-4367-ab93-81d8766dcc13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1590781762-172.17.0.7-1595621518452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34562,DS-26bd2e6f-8f8b-44f7-aef4-a3ec253452aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-9fb11ec9-fb05-407f-823d-3e4a1d8ea6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-a6635ae4-cf33-456d-ae7c-1eec04741943,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-44fdae90-87a5-43ed-b359-767f0a72db07,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-9f8dd6ce-1fc2-44b9-a57a-5daf9280257a,DISK], DatanodeInfoWithStorage[127.0.0.1:46499,DS-df7f1712-48ca-4e71-92f7-b49b9e603e34,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-ba83a009-e186-4af3-b4de-8b1723f4ccb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-29ddf167-d67d-4367-ab93-81d8766dcc13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-726372060-172.17.0.7-1595621904427:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45228,DS-52296202-b599-4d6b-96db-1b6cc3f26ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-541c8d94-558d-4532-acae-b82da3c3d236,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-e90c28a7-503f-460d-9230-1892c9c8cd60,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-3cda0964-7c2a-42f5-b35b-9e851a23b05e,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-198b29ec-403e-4231-81e4-dd36a593f386,DISK], DatanodeInfoWithStorage[127.0.0.1:32782,DS-bdb54adc-bf00-4820-b4e0-54bbaa9dd4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-031f15c8-fafb-4cb5-a51e-00a1d7033cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-4ebe7b6c-0014-450e-899f-01810d82da98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-726372060-172.17.0.7-1595621904427:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45228,DS-52296202-b599-4d6b-96db-1b6cc3f26ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-541c8d94-558d-4532-acae-b82da3c3d236,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-e90c28a7-503f-460d-9230-1892c9c8cd60,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-3cda0964-7c2a-42f5-b35b-9e851a23b05e,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-198b29ec-403e-4231-81e4-dd36a593f386,DISK], DatanodeInfoWithStorage[127.0.0.1:32782,DS-bdb54adc-bf00-4820-b4e0-54bbaa9dd4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-031f15c8-fafb-4cb5-a51e-00a1d7033cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-4ebe7b6c-0014-450e-899f-01810d82da98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-963883729-172.17.0.7-1595622507935:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43922,DS-11622010-5ec4-4542-9f69-f4d729879646,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-c89fd5f1-20ef-4bfe-ac81-3b4586f62195,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-81dd47b2-2217-48a7-a9b2-3c36f7f3cd78,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-fd7f8e7d-5702-4ec1-ae79-5af849d861fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-619c492e-3ef6-4c8e-bc7e-97db6c69165f,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-e9f9a848-5424-408f-b7d0-df7c3852b8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-8c6f6397-e239-4d29-bee2-95f22a65f0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-d8e1349a-028d-4cea-ab7a-a9b0c9fd2bc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-963883729-172.17.0.7-1595622507935:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43922,DS-11622010-5ec4-4542-9f69-f4d729879646,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-c89fd5f1-20ef-4bfe-ac81-3b4586f62195,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-81dd47b2-2217-48a7-a9b2-3c36f7f3cd78,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-fd7f8e7d-5702-4ec1-ae79-5af849d861fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-619c492e-3ef6-4c8e-bc7e-97db6c69165f,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-e9f9a848-5424-408f-b7d0-df7c3852b8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-8c6f6397-e239-4d29-bee2-95f22a65f0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-d8e1349a-028d-4cea-ab7a-a9b0c9fd2bc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1259010711-172.17.0.7-1595622614414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42443,DS-09aefaa2-ab15-439b-adb6-47752e81e388,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-8eed9ba9-bf06-42d8-94d2-b7ef6ae2ff4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-d2b7327f-f6c5-4ced-bb77-01856f740227,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-0a29b22b-39f1-4d72-861f-4c47953ebe81,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-fd7375e8-a3f7-4b26-b05a-fcaef3ba0bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45790,DS-ac25bb88-4697-4e9d-a978-79ecfd0d60ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-5c85de45-b905-4a7b-96c7-af0863eca746,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-a4c70703-5827-4b3a-a4c1-c96e66cc51c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1259010711-172.17.0.7-1595622614414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42443,DS-09aefaa2-ab15-439b-adb6-47752e81e388,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-8eed9ba9-bf06-42d8-94d2-b7ef6ae2ff4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-d2b7327f-f6c5-4ced-bb77-01856f740227,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-0a29b22b-39f1-4d72-861f-4c47953ebe81,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-fd7375e8-a3f7-4b26-b05a-fcaef3ba0bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45790,DS-ac25bb88-4697-4e9d-a978-79ecfd0d60ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-5c85de45-b905-4a7b-96c7-af0863eca746,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-a4c70703-5827-4b3a-a4c1-c96e66cc51c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-565391536-172.17.0.7-1595622893225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46303,DS-d69f5377-ed1e-4074-b10d-4dc8b909a9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-039d7ace-f144-402c-8c0b-b665247dcc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-605fd9f2-33f4-4e61-baad-45d5bd20abfe,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-7e714fdc-dae1-4247-87b1-56f5f91c57ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-1ce45107-c90c-4c30-8616-8f658ef04d31,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-b1797d08-f7bc-43b6-9ea1-500ab3301d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-bbbf27fb-241d-4b75-86cd-ae7991499239,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-aa0daa08-b889-42e0-bc0e-be474ce1f568,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-565391536-172.17.0.7-1595622893225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46303,DS-d69f5377-ed1e-4074-b10d-4dc8b909a9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-039d7ace-f144-402c-8c0b-b665247dcc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-605fd9f2-33f4-4e61-baad-45d5bd20abfe,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-7e714fdc-dae1-4247-87b1-56f5f91c57ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-1ce45107-c90c-4c30-8616-8f658ef04d31,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-b1797d08-f7bc-43b6-9ea1-500ab3301d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-bbbf27fb-241d-4b75-86cd-ae7991499239,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-aa0daa08-b889-42e0-bc0e-be474ce1f568,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5198
