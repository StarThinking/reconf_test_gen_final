reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-500265653-172.17.0.12-1595900700363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44639,DS-5bb1fcfa-e049-4a2a-ad83-060441e1e2db,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-1446b6d6-4e96-476b-a231-a592cd49a76d,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-26345437-7a14-4280-b291-9c1a3d43d8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-d8c573d3-b0ba-468e-a50a-953d34042520,DISK], DatanodeInfoWithStorage[127.0.0.1:38163,DS-df5ae73f-e783-433a-b5f9-261081adc9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-7e03266e-6246-4616-90e9-132c3734d9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-914e1954-1312-41e9-807b-492c764baace,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-f9d37554-f98b-4641-ad5e-9517fd1f35f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-500265653-172.17.0.12-1595900700363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44639,DS-5bb1fcfa-e049-4a2a-ad83-060441e1e2db,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-1446b6d6-4e96-476b-a231-a592cd49a76d,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-26345437-7a14-4280-b291-9c1a3d43d8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-d8c573d3-b0ba-468e-a50a-953d34042520,DISK], DatanodeInfoWithStorage[127.0.0.1:38163,DS-df5ae73f-e783-433a-b5f9-261081adc9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-7e03266e-6246-4616-90e9-132c3734d9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-914e1954-1312-41e9-807b-492c764baace,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-f9d37554-f98b-4641-ad5e-9517fd1f35f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-636687778-172.17.0.12-1595902991109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40935,DS-ab817657-ca34-4131-9b90-670a2683c117,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-46333bec-a0f3-408a-a9c5-e3b2900bdc26,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-8733b31a-0684-4e62-90ab-0a444de663df,DISK], DatanodeInfoWithStorage[127.0.0.1:46067,DS-35195fc4-7a78-446e-821b-5b9e1787c4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-274c1f4b-0d24-46a3-b9e1-61a622aa3507,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-44c50db4-ddb6-4fdd-8ac3-0b3c5da3fdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-2b313bce-21d5-45ce-a3f8-0f5210abd3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-e447c738-3fbd-4ece-a141-ef01221d7d10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-636687778-172.17.0.12-1595902991109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40935,DS-ab817657-ca34-4131-9b90-670a2683c117,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-46333bec-a0f3-408a-a9c5-e3b2900bdc26,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-8733b31a-0684-4e62-90ab-0a444de663df,DISK], DatanodeInfoWithStorage[127.0.0.1:46067,DS-35195fc4-7a78-446e-821b-5b9e1787c4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-274c1f4b-0d24-46a3-b9e1-61a622aa3507,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-44c50db4-ddb6-4fdd-8ac3-0b3c5da3fdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-2b313bce-21d5-45ce-a3f8-0f5210abd3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-e447c738-3fbd-4ece-a141-ef01221d7d10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-865381317-172.17.0.12-1595903139152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43734,DS-7798cb52-cc84-4ec9-8e8a-9c35fd2debde,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-c90c04a0-69e8-4986-8584-48c7617eef57,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-fbe9870f-61dc-499c-8f6e-2dfe8267ff80,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-0b989859-969a-49e9-98b1-f8f7009b6c30,DISK], DatanodeInfoWithStorage[127.0.0.1:43906,DS-c5038e30-e226-4071-82de-7afeb34ba6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-869d1ed7-bf34-450f-a226-ef3bb4736ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-31a4d37f-4d14-4c6f-8b7b-d2c94133c684,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-281e283c-5bbd-466b-ac74-bc367cc1b901,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-865381317-172.17.0.12-1595903139152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43734,DS-7798cb52-cc84-4ec9-8e8a-9c35fd2debde,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-c90c04a0-69e8-4986-8584-48c7617eef57,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-fbe9870f-61dc-499c-8f6e-2dfe8267ff80,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-0b989859-969a-49e9-98b1-f8f7009b6c30,DISK], DatanodeInfoWithStorage[127.0.0.1:43906,DS-c5038e30-e226-4071-82de-7afeb34ba6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-869d1ed7-bf34-450f-a226-ef3bb4736ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-31a4d37f-4d14-4c6f-8b7b-d2c94133c684,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-281e283c-5bbd-466b-ac74-bc367cc1b901,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-311246666-172.17.0.12-1595903526168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37259,DS-6f09c0f5-c273-46e0-92f8-4d6104454189,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-4f37ecac-4ac7-4256-b864-d8a7875fe00e,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-d7f5bf17-6102-4928-86ad-2630b37dbe92,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-6babee9a-df3b-478d-9728-563206b474ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36561,DS-b3418192-a789-445a-8163-53241b3b750e,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-97738f3e-1f28-4def-babc-962c66bb1343,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-f4254b2a-0d7f-4eef-8cf0-ae999c427275,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-9d6512ce-f45e-4f24-878c-cae2e54af8ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-311246666-172.17.0.12-1595903526168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37259,DS-6f09c0f5-c273-46e0-92f8-4d6104454189,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-4f37ecac-4ac7-4256-b864-d8a7875fe00e,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-d7f5bf17-6102-4928-86ad-2630b37dbe92,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-6babee9a-df3b-478d-9728-563206b474ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36561,DS-b3418192-a789-445a-8163-53241b3b750e,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-97738f3e-1f28-4def-babc-962c66bb1343,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-f4254b2a-0d7f-4eef-8cf0-ae999c427275,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-9d6512ce-f45e-4f24-878c-cae2e54af8ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1656734420-172.17.0.12-1595903790412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32824,DS-45e4af48-1432-488b-96b7-9ab201c03ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:39955,DS-21c62ae0-c744-42ca-b1a1-65fb88317003,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-e99bb729-762f-45b9-9170-2ee198174e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-4730c111-839a-4bec-a8fc-7de04b0134f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-1e805ffd-357a-413a-b0e1-36071f935a65,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-3b941535-5881-43f4-815b-3b507cd19999,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-2a9aeb8c-1413-4503-87e4-444a56e3662d,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-b9c84496-6e8a-486e-9401-135a066963fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1656734420-172.17.0.12-1595903790412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32824,DS-45e4af48-1432-488b-96b7-9ab201c03ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:39955,DS-21c62ae0-c744-42ca-b1a1-65fb88317003,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-e99bb729-762f-45b9-9170-2ee198174e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-4730c111-839a-4bec-a8fc-7de04b0134f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-1e805ffd-357a-413a-b0e1-36071f935a65,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-3b941535-5881-43f4-815b-3b507cd19999,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-2a9aeb8c-1413-4503-87e4-444a56e3662d,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-b9c84496-6e8a-486e-9401-135a066963fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-578846221-172.17.0.12-1595903963415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41738,DS-8b0e66fa-88cd-487e-822d-c59f3046b233,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-ad40913c-0d56-440d-bd84-5a3151cb9187,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-9168949d-287a-4cbf-b656-2840d2d9fe36,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-becb2fab-a021-4018-b837-c11d531fc3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-24b5646b-360d-4edb-b539-4dcbd85fe648,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-3c900b8e-211c-4eab-aa3d-898cdf168d83,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-bea553e9-dee0-4246-bee6-61527c5b2a17,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-5cf5c05d-b6d0-483f-9bad-dfb32dee00c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-578846221-172.17.0.12-1595903963415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41738,DS-8b0e66fa-88cd-487e-822d-c59f3046b233,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-ad40913c-0d56-440d-bd84-5a3151cb9187,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-9168949d-287a-4cbf-b656-2840d2d9fe36,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-becb2fab-a021-4018-b837-c11d531fc3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-24b5646b-360d-4edb-b539-4dcbd85fe648,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-3c900b8e-211c-4eab-aa3d-898cdf168d83,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-bea553e9-dee0-4246-bee6-61527c5b2a17,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-5cf5c05d-b6d0-483f-9bad-dfb32dee00c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1517187223-172.17.0.12-1595904369509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37428,DS-b4488413-68eb-4bc5-a0e3-bf31ba0c1d97,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-e93f9bca-b668-4130-b168-523d4c0867d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34043,DS-c9083ad5-8801-4d1f-ab3f-91f487795f84,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-c7e612ef-03b5-4846-bf5e-ce76574a0ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-bf204143-3f44-4b3e-b60b-747527d04f11,DISK], DatanodeInfoWithStorage[127.0.0.1:33854,DS-b3ee2532-f147-4cde-9251-2a12695e2e10,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-a96fc23c-9561-4fb2-8ac7-377c6f3a39af,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-3f98d287-37fd-4d24-8d15-338600955828,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1517187223-172.17.0.12-1595904369509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37428,DS-b4488413-68eb-4bc5-a0e3-bf31ba0c1d97,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-e93f9bca-b668-4130-b168-523d4c0867d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34043,DS-c9083ad5-8801-4d1f-ab3f-91f487795f84,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-c7e612ef-03b5-4846-bf5e-ce76574a0ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-bf204143-3f44-4b3e-b60b-747527d04f11,DISK], DatanodeInfoWithStorage[127.0.0.1:33854,DS-b3ee2532-f147-4cde-9251-2a12695e2e10,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-a96fc23c-9561-4fb2-8ac7-377c6f3a39af,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-3f98d287-37fd-4d24-8d15-338600955828,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2049424001-172.17.0.12-1595904704683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43318,DS-fce519e5-3f88-4310-9932-bbe781ca8e34,DISK], DatanodeInfoWithStorage[127.0.0.1:35379,DS-d506de5c-cd4f-442f-9b56-2b88b8514b66,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-00fa8c87-6621-4d39-9134-f5a660e9d50d,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-2ae9b8f5-26e4-4a37-8b0c-748d7b2f9d11,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-b98f5288-9f64-496c-8b5b-325099af1c37,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-e3adc473-76d7-481d-8d27-d9fae71d107e,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-1e1299a2-07c9-4d28-98f9-fff042ecfa70,DISK], DatanodeInfoWithStorage[127.0.0.1:42026,DS-440b4444-86dc-4a8d-a497-bda0df82b9ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2049424001-172.17.0.12-1595904704683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43318,DS-fce519e5-3f88-4310-9932-bbe781ca8e34,DISK], DatanodeInfoWithStorage[127.0.0.1:35379,DS-d506de5c-cd4f-442f-9b56-2b88b8514b66,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-00fa8c87-6621-4d39-9134-f5a660e9d50d,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-2ae9b8f5-26e4-4a37-8b0c-748d7b2f9d11,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-b98f5288-9f64-496c-8b5b-325099af1c37,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-e3adc473-76d7-481d-8d27-d9fae71d107e,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-1e1299a2-07c9-4d28-98f9-fff042ecfa70,DISK], DatanodeInfoWithStorage[127.0.0.1:42026,DS-440b4444-86dc-4a8d-a497-bda0df82b9ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2054032461-172.17.0.12-1595904765193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41871,DS-87f4d103-c2bc-4b70-b1a9-9a0e40c0df99,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-545b3cea-6aa7-4e93-a2f5-15a2f0510c78,DISK], DatanodeInfoWithStorage[127.0.0.1:38595,DS-fc15e380-0504-4acb-805e-d468ade38ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-90d5aa6a-52d4-47c0-827d-637dbb9f60fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45877,DS-c088843d-055f-42bf-9e82-1b1d7be95539,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-830c7b92-15ce-4c19-bf8a-5f51910c1399,DISK], DatanodeInfoWithStorage[127.0.0.1:46264,DS-0ddebf8b-8b6f-46c4-b416-16d86951fb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-2ccf46b7-ccba-4b4f-bd77-5f997d5dcfcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2054032461-172.17.0.12-1595904765193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41871,DS-87f4d103-c2bc-4b70-b1a9-9a0e40c0df99,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-545b3cea-6aa7-4e93-a2f5-15a2f0510c78,DISK], DatanodeInfoWithStorage[127.0.0.1:38595,DS-fc15e380-0504-4acb-805e-d468ade38ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-90d5aa6a-52d4-47c0-827d-637dbb9f60fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45877,DS-c088843d-055f-42bf-9e82-1b1d7be95539,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-830c7b92-15ce-4c19-bf8a-5f51910c1399,DISK], DatanodeInfoWithStorage[127.0.0.1:46264,DS-0ddebf8b-8b6f-46c4-b416-16d86951fb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-2ccf46b7-ccba-4b4f-bd77-5f997d5dcfcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1565890511-172.17.0.12-1595905035091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36886,DS-8420db76-c867-40bf-aeec-4edf640709a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-f4033c75-478e-4454-a0f5-938ba87e5813,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-a5157182-536a-4621-abd0-78d5d07189fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-3988c307-115f-40b0-b30e-a3eaae41bc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-4824a5ba-7afd-4291-ae7e-d7e409bd7e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-a4fd101b-aad1-4869-9eca-d9beca06e973,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-735a8c6a-4854-4a9b-9f17-130be299fcde,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-884c1671-92c8-4f80-9dd4-4ff341a70946,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1565890511-172.17.0.12-1595905035091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36886,DS-8420db76-c867-40bf-aeec-4edf640709a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-f4033c75-478e-4454-a0f5-938ba87e5813,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-a5157182-536a-4621-abd0-78d5d07189fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-3988c307-115f-40b0-b30e-a3eaae41bc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-4824a5ba-7afd-4291-ae7e-d7e409bd7e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-a4fd101b-aad1-4869-9eca-d9beca06e973,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-735a8c6a-4854-4a9b-9f17-130be299fcde,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-884c1671-92c8-4f80-9dd4-4ff341a70946,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5469
